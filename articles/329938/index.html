<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>New compiler "buns" - safer, faster, more perfect</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As stated in all of our favorite movie: "Fly, hurry, buy a painting." The latter, of course, has nothing to do with it, but the time has come to ‚Äúfly‚Äù...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>New compiler "buns" - safer, faster, more perfect</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/f52/c61/d74/f52c61d7447e49d6a22b08c3e617d59a.png"><br>  As stated in all of our favorite movie: "Fly, hurry, buy a painting."  The latter, of course, has nothing to do with it, but the time has come to ‚Äúfly‚Äù on a new Beta version of the compiler.  Today I will talk about what's new in the <i>Intel Parallel Studio XE 2018 Beta</i> package, and in particular, in its compiler component.  And there really is a lot of things added, because standards do not stand still - <i>C ++ 14, C ++ 17, Fortran 2008, 2015, OpenMP 4.5</i> and <i>5.0</i> , and the compiler must not only support them, but also generate perfect, productive and safe code.  In addition, the new <i>AVX512</i> instruction <i>sets</i> , which allow "skimming" off the latest <i>Skylake</i> and <i>KNL processors</i> , are increasingly entering the arsenal of modern compilers.  But the most delicious is the new keys, which allow you to get even more performance without straining.  So let's go! <br><a name="habracut"></a><br>  I must say that you can download the <i>Beta</i> version here: <br><br>  <a href="http://intelcustomer.az1.qualtrics.com/jfe/form/SV_09AEJgAYdKezL6d">Intel Parallel Studio XE 2018 Pre-Beta survey</a> <br><br>  Everything I‚Äôll talk about is included in this version of compilers and <i>Update 1</i> , which will be available very soon.  What then will be in the final product is a difficult question, but, ‚Äúwangooe,‚Äù almost everything.  What do we have in the new version <i>18.0 Beta</i> ? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  <font color="#0071c5">Code Security</font> </h2><br>  Microsoft is trying hard to resist hackers and come up with more and more new technologies.  To begin with, they made in their C ++ compiler the default maximum level of stack protection through the <i>/ GS: strong</i> option, which allows you to deal with buffer overflow.  This is done at the expense of performance, but safety is paramount.  Since Intel for Windows is trying to be fully compatible with the Microsoft compiler, starting from the new version we also include <i>/ GS: strong</i> by default.  You can limit its effect and slightly improve performance using <i>/ GS: partial</i> . <br><br>  In addition, the development of a new technology <a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a> (Control-Flow Enforcement Technology) is underway, which allows you to fight against attacks using the method of reciprocation-oriented programming ( <i>ROP</i> and <i>JOP</i> attacks).  One of the ideas of protection is that another protected <i>shadow</i> stack appears in which the return address will be written / duplicated.  When we reach the return from the function, the correctness of the address returned by the procedure and the address that we put in the <i>shadow</i> stack is checked.  In addition, a new instruction <i>ENDBRANCH is added</i> in order to designate areas in the program to which indirect transitions can be made via <i>call / jmp</i> . <br><br>  The state machine is implemented, and as soon as the processor processes one of the <i>call / jmp</i> instructions, it goes from the <i>IDLE</i> state to <i>WAIT_FOR_ENDBRANCH</i> .  Actually, in this state, the next instruction to execute must be <i>ENDBRANCH</i> .  Much more details are written in the above article, and Intel compilers for C / C ++ and Fortran have added support for CET through the <i>-cf-protection</i> option.  By default, it is not enabled and, of course, can affect performance when used. <br><br>  Who is ready to test the new protection?  An important note is that in order for CET to work properly, OS and RTL support is required, but it is not there yet. <br><br><h2>  <font color="#0071c5">Performance</font> </h2><br>  Now let's talk about new compiler options that will make your applications even faster and more productive. <br><br>  There is a compiler optimization called <i>function splitting</i> .  In order to understand why it is needed, it is worth remembering about embedding the code and the fact that one of the effects is to increase its size.  Therefore, <i>inlining</i> does not make sense for large sizes of the function itself, which we want to build into the place of the call.  In these cases, splitting the function and partial <i>inlining</i> will help us to prevent an excessive increase in the size of the code, while retaining its advantages.  As a result, our function will be divided into two parts, one of which ( <i>hot</i> ) will be built in, and the other ( <i>cold</i> ) will not. <br><br>  In fact, this optimization has been present for a long time in Intel 32-bit compilers for Windows, using <i>Profile-Guided Optimization</i> ( <i>PGO</i> ).  Here, by the way, is an interesting <a href="https://habrahabr.ru/post/138132/">post</a> about this optimization in <i>gcc</i> .  The idea is simple - compile our application, do the instrumentation, then run it and collect data on how it was executed (profile), and, already taking into account this data from runtime, reassemble the code again, applying the knowledge gained for more powerful optimization. <br><br>  Now it is clear why it was possible to use <i>function splitting</i> with <i>PGO</i> , because we know well for each function, what part of it was running and what needs to be inline. <br><br>  Now we already allow developers to control this optimization by ‚Äúhandles‚Äù by adding the key <i>-ffnsplit [= n]</i> (Linux) or <i>-Qfnsplit [= n]</i> (Windows), which tells the compiler to split the function with the probability of execution of blocks equal to <i>n</i> or less.  It does not matter if <i>PGO is</i> enabled or not, but we need to specify this parameter <i>n</i> .  If you do not specify it, then this optimization will be performed only if there is dynamic information from the <i>PGO</i> .  The values ‚Äã‚Äãof <i>n</i> can be from <i>0</i> to <i>100</i> , but the most interesting for us are in the first half.  For example, with <i>PGO</i> and a 32-bit compiler on Windows, a value of <i>5 was used</i> , meaning that if the probability of execution is less than <i>5%</i> , then this block will not be inline. <br><br>  If we started talking about <i>PGO</i> , then you should definitely say that here, in the new version of the Studio, there have been pleasant changes.  Previously, this optimization worked only with tools, but now it is possible to work using sampling from the <i>VTune</i> profiler.  The implementation of such a feature was prompted by the impossibility of using traditional <i>PGO</i> on <i>real time</i> and <i>embedded</i> systems, where there are restrictions on the size of data and code, and the instrumentation could significantly increase it.  In addition, on such systems it is impossible to perform <i>I / O</i> operations.  <i>VTune</i> hardware self-allocation from <i>VTune</i> can significantly reduce the overhead of executing an application, without increasing memory usage.  This method gives statistical data (they are exact with the instrumentation), but at the same time it is applicable on systems where the traditional <i>PGO</i> ‚Äúslips‚Äù. <br><br>  The scheme of work with the new PGO mode can be represented as a diagram: <br><br><img src="https://habrastorage.org/web/bb0/16c/e7f/bb016ce7f64e4d3f9b270e073e752080.png"><br><br>  As before, we need to compile our code for the subsequent collection of statistical data.  Only now this is done using the option <i>-prof-gen-sampling</i> (Linux) or <i>/ Qprof-gen-samplig</i> (Windows). <br><br>  At the output, we will get binaries with extended debug information (which will increase the size by the allowable <i>5-10%</i> ), but without instrumentation.  And then we need a special script from <i>VTune</i> to run the application and generate a profile.  After that (if you don‚Äôt need to merge several profiles), simply rebuild our code with the received data with the <i>-prof-use-sampling</i> (Linux) or <i>/ Qprof-use-sampling</i> (Windows) key.  To work with these options, we need VTune, so we need to install not only the compiler, but also the profiler.  The Beta package has both. <br><br>  Now let's talk about working with mathematical functions from the <i>SVML (Short Vector Math Library)</i> library, which provides vector analogs of scalar mathematical functions. <br><br>  Just a few changes touched <i>SVML</i> with the release of the new version.  In order to remove the overhead during dynamic dispatch, now at the compilation stage a direct call to the necessary function will be generated using the specified values ‚Äã‚Äãof the <i>-x</i> key.  Prior to this, we ran to check what our processor, and called the desired version of the function.  And although <i>overhead is</i> not great for ordinary functions, with intensive work with mathematical functions (for example, an exponent), it can be weighty <i>10%</i> .  This will be especially popular when calculating in the financial segment of applications. <br><br>  However, if we need to return the "old" behavior of the compiler, then the <i>-fimf-force-dynamic-target</i> (Linux) or <i>/ Qimf-force-dynamic-target</i> (Windows) option will help us. <br><br>  From the same financial area came another change.  When working with mathematics, not only performance is important, but also reproducibility of results.  I already <a href="https://habrahabr.ru/company/intel/blog/160747/">wrote</a> about the great options to take care of this <i>-fp-model</i> (Linux) and <i>/ fp</i> (Windows).  So, by <i>defining a</i> floating-point <i>model</i> as <i>precise</i> ( <i>-fp-model-precise</i> (Linux) or <i>/ fp: precise</i> (Windows)), we were deprived of the satisfaction of using vector mathematical functions from <i>SVML</i> , which, of course, had a negative effect on performance but very positive on reproducible results.  Now the developers made sure that the performance does not affect the stability of the numerical results.  Using the key <i>-fimf-use-svml</i> (Linux) or <i>/ Qimf-use-svml</i> (Windows) you can tell the compiler to use scalar functions from <i>SVML</i> instead of their calls from the standard <i>LIBM</i> library.  And since they made sure that the scalar and vector versions of <i>SVML</i> gave the same results, now when using a <i>precise</i> model, you can use vector mathematical functions. <br><br>  When working with different buffers, a large number of functions are used, such as <i>memcpy</i> , <i>memset</i> , etc.  If they have calls, the compiler uses its own internal logic and can go various ways: call the appropriate library function, generate a <i>rep</i> instruction, or expand the operation into a loop, provided that it knows the size at compile time.  It so happened that he did not always correctly guess the right approach, so now there is an option <i>-mstringop-strategy</i> (Linux) or / <i>Qstringop-strategy</i> (Windows), with which you can tell the compiler what to do with such functions working with buffers / strings ( <i>strings</i> , hence the name of the key).  You can specify <i>libcall</i> , <i>rep,</i> or <i>const_size_loop</i> , respectively, as an argument to the option.  For example, when compiling with the <i>-Os</i> key (we care about the size of our binaries), the option <i>-mstringop-strategy = rep</i> will be used implicitly. <br><br>  For more productive code on systems supporting <i>AVX-512</i> , the option <i>-opt-assume-safe-padding</i> (Linux) or <i>/ Qopt-assume-safe-padding</i> (Windows) has appeared. <br><br>  It allows the compiler to assume that it can safely access <i>64</i> bytes after each array or variable allocated by the application.  Previously, this option was available for <i>KNC</i> , but now it can also be used for the latest architectures with support for <i>AVX-512</i> .  In certain cases, such a ‚Äúliberty‚Äù will allow the compiler to generate unmasked download operations instead of masked, for example, when using <i>G2S (gather to shuffle)</i> optimization.  But it is important to align data by <i>64</i> bytes. <br><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  These are perhaps the most important of the new "magic" options that appeared in the latest version of the compiler.  But besides all this, support was added for almost the entire <i>OpenMP 4.5</i> standard (there are not only <i>user defined reductions</i> ), as well as part of the new generation of <i>OpenMP 5.0</i> (for example, reductions in <i>task</i> 'ah). <br><br>  Standards <i>C ++ 11</i> and <i>C ++ 14 are</i> fully supported since version <i>17.0</i> , but full support for <i>Fortran 2008 has</i> appeared only now.  Yes, and the last standard <i>C ++ 17</i> will be supported much more, and considering this, it has not yet been finally adopted. <br><br>  The bottom line is that we have the next version of the compiler, which gives us even more opportunities to optimize our code and get better code performance and security, while still having wide support for the latest standards.  Ida test? </div><p>Source: <a href="https://habr.com/ru/post/329938/">https://habr.com/ru/post/329938/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../329926/index.html">[updated] How the load testing of the processing cost us ‚Ç¨ 157,000 and why nobody was fired</a></li>
<li><a href="../329928/index.html">Lectures Technopark. Databases (Spring 2017)</a></li>
<li><a href="../329930/index.html">Machine learning - magic or science?</a></li>
<li><a href="../329932/index.html">The most interesting reports from the conference Analyst Days 2017</a></li>
<li><a href="../329936/index.html">TOP 100 English-speaking IT sites</a></li>
<li><a href="../329940/index.html">Startups and abnormal programming. Tbd</a></li>
<li><a href="../329942/index.html">Review of changes in the new major release Node 8</a></li>
<li><a href="../329944/index.html">GitHub goes to GraphQL</a></li>
<li><a href="../329946/index.html">How many technologies does Yandex need for a search to find fresh documents almost instantly</a></li>
<li><a href="../329948/index.html">Non-recursive algorithm for generating all partitions and compositions of an integer</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>