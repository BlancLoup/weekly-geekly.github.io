<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Qt Augmented Reality</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Now augmented reality is one of the most interesting directions. That's why I took up the study, and the result was my own implementation of cross-pla...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Qt Augmented Reality</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/e2f/ded/c7a/e2fdedc7a7364291888664455005c33c.png"><br><br>  Now augmented reality is one of the most interesting directions.  That's why I took up the study, and the result was my own implementation of cross-platform markerless augmented reality on Qt.  This article is about how it was implemented (or how to implement it yourself).  Under the cut, you can find a demo and a link to the project on the githaba. <br><a name="habracut"></a><br>  For the operation of augmented reality does not require any markers, any picture will do.  It is only necessary to perform initialization: point the camera at a point on the picture, press the start button and move the camera around the selected point. <br>  <a href="https://github.com/DistinctVision/Augmented-Reality-on-Qt/releases/tag/Samples">Here you can download demos for Windows and Android</a> (for some reason it does not work on windows 10). <br><br><h4>  about the project </h4><br>  The project is divided into three parts: <br>  AR is all about augmented reality.  Everything is hidden in the namespace AR, ARSystem - the main object of the system, in which all calculations are carried out. <br>  QScrollEngine is a graphics engine for Qt.  Is in the namespace - QScrollEngine.  There is a separate <a href="https://github.com/DistinctVision/QScrollEngine">project on the githaba</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      App - actually described here is an application using the augmented reality system and the graphics engine. <br>  Everything described below is based on the <a href="http://www.youtube.com/watch%3Fv%3DY9HMn6bd-v8">PTAM</a> and <a href="http://www.youtube.com/watch%3Fv%3D2YnIMfw6bJY">SVO</a> projects <a href="http://www.youtube.com/watch%3Fv%3D2YnIMfw6bJY">: Fast Semi-Direct Monocular Visual Odometry</a> . <br><br><h5>  Input data </h5><br>  Our input data is a video stream.  By video stream, in this case, we mean a sequence of frames, where information from frame to frame does not change very much (which allows us to determine the correspondence between frames). <br><br>  Qt has defined classes for working with a video stream, but they do not work on mobile platforms.  But you can make it work.  <a href="http://habrahabr.ru/post/254625/">It</a> describes how, in this article I will not dwell on this. <br><br><h4>  General work algorithm </h4><br>  Most often, for the work of augmented reality, some markers are used to help determine the position of the camera in space.  This limits its use, because, firstly, the markers must be constantly in the frame, and secondly, they must first be prepared (printed out).  However, there is an alternative - the structure from motion technique, in which the data on the camera position are found only by the movement of image points through the frames of the video stream. <br><br>  It is difficult to work with all points of the image at once (although it is quite possible ( <a href="http://www.youtube.com/watch%3Fv%3DDf9WhgibCQA">DTAM</a> )), but to work on mobile platforms you need to simplify.  Therefore, we will simply select individual ‚Äúspecial‚Äù points on the image and monitor their movements.  Find "special" points in <a href="http://habrahabr.ru/post/244541/">different ways</a> .  I used FAST.  This algorithm has a disadvantage - it only finds angles of a given size (9, 10 pixels).  In order to find points of different scale, a pyramid of images is used.  In short, the image pyramid is a set of images, where the first image (base) is the original image, and the next image is two times smaller.  Finding singular points at different levels of the pyramid, we find ‚Äúspecial‚Äù points of different scale.  And the pyramid itself is also used in the optical flow to obtain the trajectories of the movements of our points.  You can read about it <a href="http://habrahabr.ru/post/201406/">here</a> and <a href="http://habrahabr.ru/post/169055/">here</a> . <br><br>  So, we have the trajectories of the points and now we need to somehow determine the position of the camera in space.  To do this, as can be understood from the application, first initialization is performed on two frames in which the camera is directed at approximately the same point, only at different angles.  At this moment, the position of the camera in these frames and the position of ‚Äúspecial‚Äù points are calculated.  Further, using the known three-dimensional coordinates of points, you can already calculate the camera positions in each subsequent frame of the video stream.  For more stable operation, we add new points to the tracking process, making a map of the space that the camera sees. <br><br><h4>  Converting to screen coordinates </h4><br>  To begin with, let's look at how the three-dimensional coordinates of ‚Äúspecial‚Äù points pass into screen ones.  For this we use this formula (we denote it as formula 1): <br><img src="https://habrastorage.org/files/fc6/13e/597/fc613e59761846c98364f2e342b31212.png"><br>  <i>world [i]</i> are ‚Äúspecial‚Äù points in world coordinates.  In order not to complicate your life, suppose that these coordinates do not change throughout the time.  Prior to initialization, these coordinates are not known. <br>  <i>screen [i]</i> - the x and y components are the coordinates of the ‚Äúsingular‚Äù point in the image (they are given by the optical flow), z is the depth relative to the camera.  All these coordinates will already be their own on each frame of the video stream. <br>  <i>mProj</i> is a 3 by 3 projection matrix and looks like <img src="https://habrastorage.org/files/4b3/684/852/4b368485203a467cb6cd59f219d5097f.png">  , here <i>pf</i> is the focal distance of the camera in pixels, <i>pc</i> is the optical center of the camera also in pixels (usually approximately the center of the image).  It is clear that this matrix should be formed under the parameters of the camera (its viewing angle). <br>  <i>mWorld</i> is a matrix describing the transformation of 3 by 4 points (i.e. the last world matrix from which the last line was removed ( <i>0 0 0 1</i> ). This matrix contains information on camera movement and rotation. And this is what we are primarily looking at every frame. <br>  In this case, the <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D1%2582%25D0%25BE%25D1%2580%25D1%2581%25D0%25B8%25D1%258F">distortion</a> is not taken into account, but we will assume that it has almost no effect, and it can be neglected. <br><br>  We can simplify the formula by getting rid of the <i>mProj</i> matrix (in formula 1): <br><img src="https://habrastorage.org/files/88a/be4/45e/88abe445e3664bbdbe3f937005e54c26.png"><br><img src="https://habrastorage.org/files/9c2/815/615/9c28156159d742d0aaa961d0177ae923.png">  . <br>  We introduce <img src="https://habrastorage.org/files/439/747/730/43974773072542df922d44972bc63d18.png">  which we consider in advance.  Then formula 1 is simplified to <img src="https://habrastorage.org/files/c0a/c2b/daf/c0ac2bdafebc42f5aa14ae224645c568.png">  (let it be formula 2). <br><br><h4>  Initialization </h4><br>  As already mentioned, initialization occurs in two frames.  Let's designate them as A and B. So we will have matrices <img src="https://habrastorage.org/files/5c4/acd/35b/5c4acd35bef44a2c818cbe4c84893f19.png">  and <img src="https://habrastorage.org/files/265/2f5/6fd/2652f56fd068452aa86156a5cae0c407.png">  .  Points <i>c [i]</i> on frames A and B are denoted as <i>cA [i]</i> and <i>cB [i]</i> .  Since we are free to choose the origin, let us assume that the camera in frame A is just there, therefore <img src="https://habrastorage.org/files/5c4/acd/35b/5c4acd35bef44a2c818cbe4c84893f19.png">  - this is the identity matrix (only in 3 by 4 size).  But the matrix <img src="https://habrastorage.org/files/265/2f5/6fd/2652f56fd068452aa86156a5cae0c407.png">  will still have to calculate.  And it can be done with the help of points located on one plane.  For them, the following formula will be true: <br><img src="https://habrastorage.org/files/6c9/f69/3b8/6c9f693b85634004a89a28a46655e42e.png">  where the matrix <i>H</i> is a <a href="http://locv.ru/wiki/11.2.3_%25D0%2593%25D0%25BE%25D0%25BC%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%258F">flat homography</a> . <br>  Rewrite the expression in this way (removing the index i for clarity): <br><br><img src="https://habrastorage.org/files/c41/4d9/72d/c414d972de3a4828a97ee70e812dce0e.png"><br><br>  And now we turn to this view, getting rid of <img src="https://habrastorage.org/files/264/23d/e4b/26423de4b3104cdd8b37fcc6b40fb007.png">  : <br><br><img src="https://habrastorage.org/files/b5a/73e/d7d/b5a73ed7d85544bf800207719aff7080.png"><br><br>  Representing the matrix <i>H</i> as a vector <img src="https://habrastorage.org/files/17f/b8a/1a2/17fb8a1a206b4304b7d5cb3bcdf0eedd.png">  , we can present these equations in matrix form: <br><br><img src="https://habrastorage.org/files/285/877/1ac/2858771ac4f740bea299b1267689c3b3.png">  . <br><br>  Let's denote the new matrix as M. We get M * <i>H '</i> = 0. All this was written for only one point, therefore there are only 2 rows in the matrix M.  In order to find the matrix <i>H '</i> , it is necessary that the matrix M has the number of rows greater than or equal to the number of columns.  If we have only four points, then we can simply add another line of zeros, a 9 by 9 matrix will come out. Then, using a <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%25A1%25D0%25B8%25D0%25BD%25D0%25B3%25D1%2583%25D0%25BB%25D1%258F%25D1%2580%25D0%25BD%25D0%25BE%25D0%25B5_%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">singular decomposition,</a> we find the vector <i>H '</i> (by itself, it should not be zero).  The vector <i>H '</i> is, as we recall, the vector representation of the matrix <i>H</i> , so that we now have this matrix. <br>  But as mentioned above, all this is true only for points located on the same plane.  And which of them are located and which are not, we do not know in advance, but we can assume using the <a href="https://ru.wikipedia.org/wiki/RANSAC">Ransac</a> method <a href="https://ru.wikipedia.org/wiki/RANSAC">in</a> this way: <br><ol><li>  In a loop, with a predetermined number of iterations (say 500), perform the following actions: <br><ul><li>  Randomly select four pairs of points of frames A and B. </li><li>  Find the matrix <i>H.</i> </li><li>  Consider how many points give an error less than the specified value, i.e., let <img src="https://habrastorage.org/files/17a/012/da2/17a012da22a449d8b706e92e30e6f585.png">  and then the condition - <img src="https://habrastorage.org/files/7a7/381/7a3/7a73817a342742d187104b0d4440e69a.png">  . </li></ul><br></li><li>  Choose <i>H</i> at the iteration in which the most points are obtained. </li></ol><br><br>  The <i>H</i> matrix can be obtained using the function from the OpenCV library - cvFindHomography. <br><br>  From matrix <i>H,</i> we now obtain the position transition matrix from frame A to frame B and call it <i>mMotion</i> . <br>  To begin with, we perform the singular decomposition of the matrix <i>H.</i>  We get three matrices: <img src="https://habrastorage.org/files/5be/704/c73/5be704c73390453bb509cb18c34d0d2b.png">  .  We introduce in advance some values: <br><img src="https://habrastorage.org/files/724/9c3/fe3/7249c3fe300944f7a2a8d2569a99570c.png">  - in the end, should be equal to ¬± 1; <br><br><img src="https://habrastorage.org/files/305/524/8a7/3055248a73ac4bfead23627f75987954.png"><br><br><img src="https://habrastorage.org/files/d8d/250/7eb/d8d2507eb6ac40be9905914f1740e8fe.png"><br><br>  Arrays (well, or vector), indicating the desired character: <br><img src="https://habrastorage.org/files/10e/7de/46c/10e7de46c34e419e902c94b4aa7edb4b.png"><br><br>  And then we can get 8 possible options for <i>mMotion</i> : <br><img src="https://habrastorage.org/files/dd7/13c/adb/dd713cadbbf94fcca5a3ee40dbede20a.png"><br><br><img src="https://habrastorage.org/files/307/3ef/bc2/3073efbc200d49118ea1e6b6e6808513.png"><br><br><img src="https://habrastorage.org/files/3de/3f8/a47/3de3f8a476084773b8288a9b46b460a5.png">  ; <br><br><img src="https://habrastorage.org/files/b1b/693/fdb/b1b693fdb44b4fcd95a8c28ee41e4065.png">  where <i>R [i]</i> is the rotation matrix, <br>  <i>t [i]</i> is the displacement vector. <br><br>  And matrices <img src="https://habrastorage.org/files/35d/a77/d90/35da77d9065b49ddbe8d7df931439790.png">  .  The parameter <i>i</i> = 0, ..., 7, and accordingly we get 8 variants of the <i>mMotion</i> matrix. <br>  In general, we have the following relation: <img src="https://habrastorage.org/files/265/2f5/6fd/2652f56fd068452aa86156a5cae0c407.png">  = <i>mMotion [i]</i> * <img src="https://habrastorage.org/files/5c4/acd/35b/5c4acd35bef44a2c818cbe4c84893f19.png">  , because <img src="https://habrastorage.org/files/5c4/acd/35b/5c4acd35bef44a2c818cbe4c84893f19.png">  - this is the identity matrix, it comes out <img src="https://habrastorage.org/files/265/2f5/6fd/2652f56fd068452aa86156a5cae0c407.png">  = <i>mMotion [i]</i> . <br>  It remains to choose one matrix of 8 <i>mMotion [i]</i> .  It is clear that if rays are released from the points of the first and second frames, they must intersect, and in front of the camera, both in the first and in the second case.  So, we count the number of intersection points in front of the camera in the first and in the second frame using the resulting <i>mMotion [i]</i> , and discard options for which the number of points will be smaller.  Leaving a couple of matrices in the end, choose the one that gives less errors. <br>  So, we have matrices <img src="https://habrastorage.org/files/5c4/acd/35b/5c4acd35bef44a2c818cbe4c84893f19.png">  and <img src="https://habrastorage.org/files/265/2f5/6fd/2652f56fd068452aa86156a5cae0c407.png">  , now knowing them you can find the world coordinates of the points by their projections. <br><br><h4>  Calculation of world coordinates of a point by several projections </h4><br>  It would be possible to use the least squares method, but in practice the following method worked better for me: <br>  Let's go back to formula 2. We need to find the point <i>world</i> , which we denote as <i>a</i> .  Suppose we have frames in which the <i>mWorld</i> matrices are known (we denote them as <i>mW [0], mW [1], ...</i> ) and the coordinates of the projections of the point <i>a are</i> known (take immediately <i>from [0], from [1], ...</i> ). <br>  And then we have the following system of equations: <br><img src="https://habrastorage.org/files/8f0/c61/9d0/8f0c619d0fc4465cbd880f290bdd9e84.png"><br><br>  But you can imagine them in this form, getting rid of <img src="https://habrastorage.org/files/bb2/fb7/98a/bb2fb798a16b426fb0fc32620189be53.png">  (just like they did before): <br><img src="https://habrastorage.org/files/d70/543/09f/d7054309f6ea438bab11a43b9e0e6154.png"><br><br><img src="https://habrastorage.org/files/7c1/343/3cf/7c13433cf104437cb0be8d4bf4051e92.png">  where <i>s is</i> any non-zero number, <br><img src="https://habrastorage.org/files/ee8/e9b/b39/ee8e9bb39bfc4e99b7b95077f52b393e.png">  - system of equations in matrix form.  <i>T</i> is known, <i>f</i> is necessary to calculate to find a. <br>  Solving this equation using a singular value decomposition (as well as <i>H 'was</i> found), we obtain the vector <i>f</i> .  And accordingly the point <img src="https://habrastorage.org/files/ded/c2b/a54/dedc2ba54e004eb68c76d31d6ad307b2.png">  . <br><br><h4>  Calculating the camera position using known world coordinates of points </h4><br>  An iterative algorithm is used.  The initial approximation is the previous result of the determination.  At each iteration: <br><ol><li>  We carry more points <img src="https://habrastorage.org/files/27d/926/7d2/27d9267d2ae14cd2aaa3a8ab4b67c658.png">  .  Ideally, the points <i>c [i]</i> should be equal to the points <i>b [i]</i> , since the current mWorld approximation is only as long as the approximation (plus other computation errors), they will differ.  Calculate the error vector as follows: <img src="https://habrastorage.org/files/83b/754/bd9/83b754bd9f094b0eadb186ac32201503.png">  .  Solve the system of equations using the least squares method: <br><img src="https://habrastorage.org/files/311/35b/2f5/31135b2f54ab499b98dafb16ef708ad5.png"><br><br>  Find the necessary six-dimensional vector <img src="https://habrastorage.org/files/a54/7ad/979/a547ad979c4d4ca389b092b062fb483b.png">  - vector exhibitors. </li><li>  Find the displacement matrix of the vector <img src="https://habrastorage.org/files/a54/7ad/979/a547ad979c4d4ca389b092b062fb483b.png">  : dT = exp_transformMatrix (mu). <br><div class="spoiler">  <b class="spoiler_title">The code for this function is:</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">TMatrix </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">exp_transformMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> TVector&amp; mu)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// mu - 6-  TMatrix result(4, 4);//  4  4 static const float one_6th = 1.0f / 6.0f; static const float one_20th = 1.0f / 20.0f; TVector w = mu.slice(3, 3);//  3   mu TVector mu_3 = mu.slice(0, 3);//  3   mu float theta_square = dot(w, w);//dot -    float theta = std::sqrt(theta_square); float A, B; TVector crossVector = cross3(w, mu.slice(3));//cross3   2 3-  if (theta_square &lt; 1e-4) { A = 1.0f - one_6th * theta_square; B = 0.5f; result.setColumn(3, mu_3 + 0.5f * crossVector);// 4   } else { float C; if (theta_square &lt; 1e-3) { C = one_6th * (1.0f - one_20th * theta_square); A = 1.0f - theta_square * C; B = 0.5f - 0.25f * one_6th * theta_square; } else { float inv_theta = 1.0f / theta; A = std::sin(theta) * inv_theta; B = (1.0f - std::cos(theta)) * (inv_theta * inv_theta); C = (1.0f - A) * (inv_theta * inv_theta); } result.setColumn(3, mu_3 + B * crossVector + C * cross3(w, crossVector)); } exp_rodrigues(result, w, A, B); result(3, 0) = 0.0f; result(3, 1) = 0.0f; result(3, 2) = 0.0f; result(3, 3) = 1.0f; return result; } void exp_rodrigues(TMatrix&amp; result, const TVector&amp; w, float A, float B) { float wx2 = w(0) * w(0); float wy2 = w(1) * w(1); float wz2 = w(2) * w(2); result(0, 0) = 1.0f - B * (wy2 + wz2); result(1, 1) = 1.0f - B * (wx2 + wz2); result(2, 2) = 1.0f - B * (wx2 + wy2); float a, b; a = A * w(2); b = B * (w(0) * w(1)); result(0, 1) = b - a; result(1, 0) = b + a; a = A * w(1); b = B * (w(0) * w(2)); result(0, 2) = b + a; result(2, 0) = b - a; a = A * w(0); b = B * (w(1) * w(2)); result(1, 2) = b - a; result(2, 1) = b + a; }</span></span></code> </pre> <br></div></div></li><li>  We update the matrix <img src="https://habrastorage.org/files/0ff/618/3b8/0ff6183b87824660bda2f4aebd161a5b.png">  . </li></ol><br>  10-15 iterations are enough.  However, you can insert some additional condition that removes from the loop if the value of <i>mWorld is</i> already close enough to the desired value. <br>  As the position is determined at each frame, some points will be lost, which means that it is necessary to look for lost points.  Also, it will not interfere with the search for new points to which you can navigate. <br><br><h4>  Bonus - three-dimensional reconstruction </h4><br>  If you can find the position of individual points in space, so why not try to determine the position of all visible points in space?  In real time, doing this is too expensive.  But you can try to make a record, and the reconstruction to perform later.  Actually, I tried to implement it.  The result is clearly not perfect, but something comes out: <br><br><img src="https://habrastorage.org/files/f24/6be/991/f246be9917b7486093e20208c199cd3d.jpg"><br><br>  <a href="https://github.com/DistinctVision/Augmented-Reality-on-Qt">Link to github source code</a> . <br><br>  <b>UPD:</b> Updated version for windows, so if the previous version did not work for you, then this version will probably work.  Plus added the ability to select the camera (if there are several). </div><p>Source: <a href="https://habr.com/ru/post/265713/">https://habr.com/ru/post/265713/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../265695/index.html">7 not the most common problems of mobile applications and how to solve them</a></li>
<li><a href="../265697/index.html">Wi-Fi network security: attack detection</a></li>
<li><a href="../265703/index.html">HP Flexible Thin Clients - practice</a></li>
<li><a href="../265709/index.html">We check all pages of a site in the html validator</a></li>
<li><a href="../265711/index.html">R01 + Timeweb, your sites are at risk</a></li>
<li><a href="../265715/index.html">The digest of interesting materials for the mobile developer # 118 (August 24-30)</a></li>
<li><a href="../265723/index.html">Navigation between screens using xib files</a></li>
<li><a href="../265725/index.html">How to write a beautiful code and fill up the project</a></li>
<li><a href="../265727/index.html">Grokayem RxJava, Part Three: Reactivity with Benefit</a></li>
<li><a href="../265729/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ174 (August 23 - 30, 2015)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>