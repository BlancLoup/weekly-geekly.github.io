<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We put Selenium Grid on Apache Mesos wheels</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! My name is Nastya, and I do not like queues. Therefore, I will tell you, using the example of Alpha Laboratories and our research, how we ca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We put Selenium Grid on Apache Mesos wheels</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  My name is Nastya, and I do not like queues.  Therefore, I will tell you, using the example of Alpha Laboratories and our research, how we can organize the infrastructure and architecture for running tests in order to get the result several times faster.  For example, we managed to achieve such a figure as 5 minutes of total test time for an application.  To do this, we had to change the approach to launch Selenium Grid. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/775/58f/e84/77558fe84e1e48ebbdf6ffad1101053c.jpg"></div><br><br>  Before I start talking about the selenium grid itself and everything related to it, I want to clarify the essence of the problem that we were trying to solve. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Last year, we implemented DevOps as a process.  And at one moment, automating everything and everything, we realized that the time to market for each artifact at the testing stage should not exceed 30 minutes.  Conceptually, we wanted some releases to pass the authentication if they do not need acceptance testing.  For those artifacts that need to be checked by hand, 30 minutes is the time for which the tester receives the results of the autotest run, analyzes them, and also does acceptance testing.  At the same time autotests should be automatically launched within our pipeline. <br><a name="habracut"></a><br>  To achieve this goal, we needed to speed up the run of autotests.  But in addition to speeding up autotests, it was necessary to make sure that with all the abundance of projects we did not have a queue for their launch. <br><br>  Most often, the task of accelerating the AutoTest run is solved in two ways: <br><br><ul><li>  The approach of the rich is to flood problems with money: buying additional iron, clouds, hiring new people. </li><li>  The approach for commoners is an engineering way to solve this problem. </li></ul><br>  We in our company adhere to the second approach, but not because we have no money.  I am an engineer, and, like many engineers, lazy about such matters.  Therefore, I decided to take a more difficult and interesting path.  And at the same time save the bank that same bag of money. <br><br>  So, the goal is clear: to <b>speed up and eliminate the queues to run autotests without raising additional funding.</b> <br><br>  At the very beginning we had a rather small park consisting of 15 virtual machines. <br><br><ul><li>  The average configuration of the machine was as follows: 4RAM / 2 core / 50 HDD </li><li>  And at one point in time on one machine without a loss in speed, we could perform no more than 2 test flows.  Those.  run no more than 2 sessions with browsers.  Otherwise - the speed of the tests sagged. </li><li>  All the machines were Windows, which also imposed certain restrictions on us (for example, we did not test the cross-browser compatibility) </li><li>  And the machines were in different subnets of the Bank (different data centers).  Therefore, it was extremely difficult to manage their configurations, since the re-creation and management took place on the side of the system administrators. </li></ul><br>  In total, we have about 20 projects with autotests, which are launched at different times and with different frequencies. <br><br>  Our teams: <br><br><ul><li>  want to be released from 3 to 5 times a day </li><li>  release releases no more than once every 1-2 weeks </li></ul><br>  And all teams focus on delivering value to the customer quickly.  Of course, no one wants to ‚Äúhang‚Äù in the queue to run autotests. <br><br>  Resources sorely lacked.  Why?  Let's look at a specific example: <br><br><ol><li>  We have a project in which about 30 tests (this is an average figure) </li><li>  If we run tests in one thread, then this is at least 30 minutes. </li><li>  Our goal is to meet in 10 minutes - it means that we need to parallelize the test run on several browsers, and accordingly - on several machines. </li><li>  So, we run these tests in parallel in at least 3 threads.  In practice, it turns out that each project generates from 5 to 10 threads. </li><li>  And now let's remember our 20 projects.  If we have a situation when everyone wants to run autotests at the same time, in order to avoid a queue, at least 60 sessions with tests should be raised. </li><li>  40 still rise, given the fact that 2 sessions per virtualku. </li><li>  And the rest will be in the queue - at least 10 minutes. </li></ol><br>  Notice, we have considered a very positive case, when there are few tests in a project, and only 3 streams.  Iron is not enough, you need to think about how to ease the load on the virtual.  What if we move from virtual machines to docker containers? <br><br>  Counted: <br><br><ul><li>  Let's take our 15 machines and build a single space out of them, where we will create docker containers in which our tests will be run. </li><li>  15 virtual machines = these are 60 RAM, 30 core and 750 HDD, and all this is in three data centers, i.e.  we can create a failover space. </li></ul><br>  Let's look at the configuration of one docker-container, which will allow us to run tests into 1 stream, and compare with what we had when using virtual machines: <br>  500 RAM, 0.01% core, and HDD 400 mb. <br><br><img src="https://habrastorage.org/web/e20/e56/5f8/e20e565f8f0645e4bf02644a819ab8b7.jpeg"><br><br>  <b>It turns out that at one point in time we can create 120 containers!</b> <br><br>  This not only covers our requests in 60 sessions, but also insures for the future.  After all, the number of teams is growing, which means that the number of projects launched is also constantly growing.  So, it became quite obvious that we need to take the available resources and combine them into a single computing power space, this is also called the sandbox.  Combining, we do not want to think about it in the paradigm of some hosts / virtual machines.  We just want to have a space to which we can connect using some api, and create our own docker containers in it, on which we will then run tests. <br><br><h3>  Dynamic sandbox </h3><br>  So, we need to create a sandbox for computing resources.  However, it should be dynamic: i.e.  We should be able at any time to connect / disconnect from it the resources that we have.  Moreover, all the hosts that we connect can have different configurations and be on different subnets, for us it‚Äôs just the main thing that between them it was possible to establish communication over certain ip and ports.  A dynamic sandbox is also called a cloud or cluster, and in it we have an interface for creating and managing docker containers. <br><br>  When we understood how we wanted to solve the problem, we built our sandbox by combining our hosts into a cluster using Apache Mesos and Marathon. <br><br><img src="https://habrastorage.org/web/cac/7bf/520/cac7bf5205f6443e9f896c5d4c80a2dd.jpeg"><br><br>  Thus, we get a common space with computational resources, which has its api.  The API is provided by Marathon, and Apache Mesos unites the hosts. <br><br><h3>  Test orchestrator: Selenium grid to the rescue </h3><br>  We decided that we need a cluster, and even created it.  But the question is, how are we going to run tests in a cluster?  You remember that in any case we want to receive test results in no more than 10 minutes? <br><br>  And here the parallelization of test run should come to our aid. <br><br>  To solve this problem, we need a centralized tool that will allow running and parallelizing tests in several threads for each project.  There are several popular tools. <br><br><ul><li>  Jenkins </li><li>  native orchestrator Selenium </li></ul><br>  Although my story is about how we ran the selenium grid in docker containers - first we will look at how the grid works in virtual machines. <br><br><img src="https://habrastorage.org/web/4fa/5f6/816/4fa5f681620344bd8a1b3116d923e296.jpeg"><br><br>  <b>In fact, the whole procedure consists of 3 actions:</b> <br><br>  1. We copy Selenium Standalone Server (the version we need) to some directory. <br>  2. Then we execute the command that launches this server in the mode we need: hub or node mode.  Please note that the same physical jar-nickname that you duplicate to different hosts is responsible for these two functions. <br><br><pre><code class="bash hljs">$ java -jar selenium-server-standalone.jar -role hub</code> </pre> <br>  3. Configure the node.  Either through the command line, or in the json-file we specify a set of browsers and their parameters. <br><br><pre> <code class="bash hljs">$ java \ -jar selenium-server-standalone.jar \ -role node \ -hub http://host1:4444/grid/register</code> </pre> <br><h4>  What makes the hub after the start of the grid </h4><br><ul><li>  Creates new sessions with nodes </li><li>  Sends test requests to the queue if all nodes are busy; </li><li>  It is an error if it does not have a node or node with specific parameters. </li></ul><br><h4>  What does the node </h4><br><ul><li>  After we started the server in node mode on the virtual machine and specified the hub address in the command parameters, the node's task is to register on the hub.  That is, to inform him that she is in his grid, and about what browsers with drivers she has. </li><li>  The registration itself looks like an HTTP-request sending with sending a json-array, which contains all the information on the node. </li><li>  The next task of the node is to fulfill those requests that it receives through the hub after it has created a session with this node. </li><li>  By requests I mean those commands that are sent by our jar-nick with autotests.  As an example, the command will be some step like ‚ÄúFind me a button on this page with the following id‚Äù.  Accordingly, in order for the hub to perform such a test step, it is necessary to know to which test this step applies.  Indeed, at one moment he can perform several tests.  And this step implies that the one who will execute this command has already completed some kind of background history from other teams, for example, just went to the corresponding page.  That's exactly what the unique session identifier with a browser in the node that creates a hub and then uses the ID for which node to distribute requests to is needed for this. </li><li>  Noda simply waits for the command from the hub, and when it receives http requests that it redirects to it, it executes them. </li></ul><br><h3>  What is the difference between starting grid in docker containers? </h3><br>  1. The node at the time of start is already configured. <br><br>  Let's look at the contents of the node.  The json-config file for the node is in the container with it, then we rename it, and our server will learn about its parameters from this file: <br><br><pre> <code class="bash hljs">/opt/selenium/generate_config &gt; /opt/selenium/config.json</code> </pre> <br>  Moreover, if we look at the contents of the Dockerfile node itself, we will see that when we configure the node environment, we immediately set the environment variables, which are then written to this config.  Thus, we don‚Äôt need to go into the ‚Äúguts‚Äù of the container itself to change the launch parameters of the node, we just need to override the values ‚Äã‚Äãof the specified variables in the Dockerfile.  And that's all. <br><br>  2. When we start a node in a container, we can always be sure that our environment already has a browser and a driver for it.  Because all this is configured and installed at the time of the assembly of the image itself. <br><br><pre> <code class="bash hljs">$ /opt/selenium$ ls chromedriver-2.29 selenium-server-standalone.jar config.json</code> </pre><br>  3. We also have a sh script that runs after the container has started.  And in this script we see that after the container has risen - our java server starts right away. <br><br><pre> <code class="bash hljs">$ java <span class="hljs-variable"><span class="hljs-variable">${JAVA_OPTS}</span></span> -jar /opt/selenium/selenium-server-standalone.jar \ -role node \ -hub http://<span class="hljs-variable"><span class="hljs-variable">$HUB_HOST</span></span>:<span class="hljs-variable"><span class="hljs-variable">$HUB_PORT</span></span>/grid/register \ -nodeConfig /opt/selenium/config.json \ <span class="hljs-variable"><span class="hljs-variable">${SE_OPTS}</span></span> &amp;</code> </pre><br>  Similarly, all in relation to the hub. <br><br>  As a result, the launch of the selenium grid in the container is reduced to one team - the start of the docker container. <br><br><h3>  Static grid problem </h3><br>  Despite the fact that the hub is well able to work with queues and timeouts, at the very beginning of using a static grid, we experienced problems due to timeouts.  If the hub and node were not used for a long time, then during the subsequent connection we caught situations when, when creating a session at the node, this very session fell off precisely because of time-outs or because remotewebdriver could not lift the browser.  And all these problems were treated with a grid restart, it was then that we realized that for us on-demand the selenium grid would be the solution. <br><br>  We also didn‚Äôt want the static grid to just occupy a place in a cluster that is already small in our case.  How to solve the situation when for different projects we need different grid configurations?  When for one project need one version of the browser, for another - another?  Obviously, keeping grids on is not a good idea. <br><br><h3>  Selenium Grid On-Demand </h3><br>  Therefore, we wanted to raise the selenium grid on request: I will explain with an example <br><br><ul><li>  Suppose we want to run tests for a project with 30 tests, which are decomposed into 3 test suites. </li><li>  So, we run the job, which first creates a selenium grid in the cluster for this run, and it passes the number of our test suite as the value of the parameter about the number of nodes in the grid.  That is, for each project - the grid configuration is different. </li><li>  After the selenium grid lift command has completed its work, the tests are run. </li><li>  After running the tests, the grid is deleted. </li></ul><br>  It would seem an ideal concept.  We use this approach to solve two problems at once: both with the degradation of the grid, and with the lack of space in the cluster to store various configurations of the grid. <br><br><h3>  Automation of the creation of Selenium Grid On-Demand </h3><br>  To solve this problem, it was necessary to write an automated grid creation script.  We solved it with the help of ansible, having written the necessary roles.  I will not tell what is ansible.  But I can say that you can also write such a script in bash-e or in another programming language, which gives you two commands to create and delete a grid. <br><br>  Remember that starting a grid consists of running a couple of commands.  And each team has its own parameters.  And in order to automate the launch of these commands, these parameters need only be automatically calculated before the command is launched.  Or hardcode. <br><br>  We cannot hardcode, because we a priori do not know on which host and port the components of the Selenium Grid go up, since Apache Mesos decides for us. <br><br>  Of course, we can dodge and manually monitor the open ports and hosts on which we are raising the Selenium Grid, but then why do we need Apache Mesos and Marathon at all if we do everything manually? <br><br>  So, it was necessary to automate the calculation of the following parameters: <br><br><ul><li>  the number of nodes we raise </li><li>  determining the address of the hub (its host and port on which it rose) to transmit this value to the node, otherwise it will not be able to register. </li></ul><br>  Api Marathon helped us in this, and with its help we obtained data on which host and port the hub went up to.  And then this value was transferred before the start of the node.  So, what we have: <br><br>  <b>Deploy Selenium Grid</b> <br><pre> <code class="bash hljs">$ ansible-playbook -i inventory play-site.yml \ -e test_id=mytest \ -e nodes_type=chrome \ -e nodes_count=4</code> </pre> <br> <code>test_id:      <br> nodes_count:   <br> nodes_type:   [chrome|firefox] <br></code> <br>  <b>Delete Selenium Grid</b> <br><pre> <code class="bash hljs">$ ansible-playbook -i inventory play-site.yml \ -e test_id=mytest \ -e clean=<span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br>  Shell scripts executed on Jenkins, before running the ansible playbook, are calculated automatically and pass the value of the variable.  The test run is built into the pipeline using job dsl. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> grid_name=testproject <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> nodes_count=$(find tests -name <span class="hljs-string"><span class="hljs-string">"*feature"</span></span> \ | grep -v build | grep -v classes | grep features | wc -l) <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ansible ansible-playbook -i inventory play-site.yml \ -e test_id=<span class="hljs-variable"><span class="hljs-variable">$grid_name</span></span> \ -e nodes_type=chrome \ -e nodes_count=<span class="hljs-variable"><span class="hljs-variable">$nodes_count</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> hub_url=$(cat hub.url) currentdir=$(<span class="hljs-built_in"><span class="hljs-built_in">pwd</span></span>) <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ../tests ./gradlew clean generateCucumberReport \ -i -Pbrowser=<span class="hljs-variable"><span class="hljs-variable">$browser</span></span> -PremoteHub=<span class="hljs-variable"><span class="hljs-variable">$hub_url</span></span></code> </pre><br>  As soon as we solved this problem and learned to raise the selenium grid in our cluster, we hurried to run the tests, and this was where we were disappointed.  Tests do not run, moreover - the hub does not even raise the session with the node. <br><br><h3>  The problem of raising Selenium Grid On-Demand in a distributed cluster </h3><br>  Let's see what our scripts lacked. <br><br>  Take another look at what the command would look like if we ran the nodes in the Docker container for the selenium grid every time: <br><br><pre> <code class="bash hljs">$ docker run -d -p 6666:5555 selenium/node-chrome</code> </pre> <br>  Do you see two ports?  Probably some of you wondering where the second port came from.  So, the docker has an internal port and an external port.  The external port listens to the container itself.  And the internal port is monitored by the selenium server standalone process itself, which runs in the -node mode. <br><img src="https://habrastorage.org/web/2b9/a5c/718/2b9a5c718534444e8dd53e5560797ded.jpeg"><br>  In this example, all requests for port 6666 of the container will be forwarded to port 5555 of the node inside it. <br><br><h4>  Running a node in Marathon </h4><br>  When configuring an Apache Mesos cluster, we specify a range of ports for each host.  This range is used for containers that are lifted by Marathon. <br><img src="https://habrastorage.org/web/01c/37a/35c/01c37a35c7d840f294861b8fbf36226c.jpeg"><br>  For example, if we set a range of 20000-21000, then our containers will receive a random port from this range. <br><br>  A marathon agent runs something like this. <br><br><pre> <code class="bash hljs">$ docker run -d -p &lt;?&gt;:5555 selenium/node-chrome</code> </pre> <br>  When the container is launched, it selects the next free port and substitutes it for the question mark.  Thus, at the time of the start of the node in the network bridge mode, we have a mapping of ports. <br><br><pre> <code class="bash hljs">$ docker run -d -p 20345:5555 selenium/node-chrome</code> </pre> <br>  <b>Marathon starts a container on a random host and a random port.</b> <br><br><h4>  The node sends the wrong coordinates. </h4><br>  Docker containers, by default, run in bridge mode.  What does this mean for us?  And the fact that the node will not see your real IP and port!  Suppose that Apache Mesos has raised to us a node on host 192.168.1.5 and port 20345. But the process of the node in the container will think that it goes up on some 172.17.0.2;  and its port is 5555. <br><br><pre> <code class="java hljs">host = <span class="hljs-number"><span class="hljs-number">172.17</span></span>.0.2 port = <span class="hljs-number"><span class="hljs-number">5555</span></span></code> </pre> <br>  And she will register on the hub with the return address.  Naturally, the hub at this address will not find it.  And when running tests, the hub will not be able to raise the browser session. <br><img src="https://habrastorage.org/web/c3d/46a/cc6/c3d46acc62fe4aefaf1ad5fcce31f587.jpeg"><br><br><h4>  Solving the problem of registering nodes on the hub </h4><br>  But there is also a host mode.  When a container uses the host ports directly and there is no such thing as an internal port. <br><br>  When we thought about solving this problem, naturally, we thought, why do we need to start the container and at the same time create a network bridge, and why not use the host mode?  We indicate one port on which we rise, and the container, and the selenium server immediately looks at it. <br><br>  But it was not there.  In order for our tests to be performed in a docker-container, which as such has no display, we also need to take screenshots, we use an xvfb-server, which also occupies a certain port when the container starts.  By the way, so the host mode does not suit us at all.  We'll have to somehow twist the bridge mode. <br><br><h4>  Container environment variables </h4><br>  When Marathon started the container, it sets the actual host and ports on which it picked up the container in the environment variables of this container. <br><br>  That is, the container has the values ‚Äã‚Äãof the variables HOST and PORT0. <br>  This means that inside the container there is information on which host it is deployed on and what external ports it has. <br><br>  In order for us to get everything working, it is necessary that the values ‚Äã‚Äãof the host and Port variables sent in the registration request contain the values ‚Äã‚Äãof the container's HOST and PORT0 variables. <br><br><pre> <code class="hljs perl">{ ‚Ä¶ <span class="hljs-string"><span class="hljs-string">"host"</span></span>: <span class="hljs-string"><span class="hljs-string">"$HOST"</span></span>, <span class="hljs-string"><span class="hljs-string">"port"</span></span>: <span class="hljs-string"><span class="hljs-string">"$PORT0"</span></span>, ‚Ä¶ }</code> </pre> <br>  The HOST parameter is easy to specify - Selenium has a special setting. <br><br>  With port harder.  If you transfer this PORT0, then Selenium will not only register with it on the hub, but also rise on it!  Why is this a problem? <br><br>  For example, Apache Mesos gave us an external port 20765. At the start of the container it makes the mapping: 20765: 5555.  The second number we ask immediately, hard, in the config.  And the docker will expect that inside the container the node will hang on 5555. And it will forward connections from the external port 20765 there. <br><br>  But if we pass the -port 20765 parameter to the node, then it will listen to 20765 from the inside!  Not 5555. And all requests from the outside will not be processed. <br><img src="https://habrastorage.org/web/9ae/8da/3bc/9ae8da3bc99d41c8a20f5380515197d6.jpeg"><br><br>  You may have already guessed that the problem can be solved by dividing the port concept into two separate ones.  The port on which the node rises, and the port, which it must inform the hub.  In the docker-environment, these values ‚Äã‚Äãusually do not match. <br><br>  How to tell the node about these ports? <br>  No <br><br>  Out of the box Selenium Standalone Server does not know how. <br>  Need to patch Selenium. <br><br><h4>  Patches Selenium Server </h4><br>  The code for Selenium itself is on GitHub.  And we decided to add some more ... wonderful code to the selenium standalone server. <br><br>  Added advertisePort parameter. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Expose</span></span>( serialize = <span class="hljs-keyword"><span class="hljs-keyword">false</span></span> ) <span class="hljs-meta"><span class="hljs-meta">@Parameter</span></span>( names = <span class="hljs-string"><span class="hljs-string">"-advertisePort"</span></span>, description = <span class="hljs-string"><span class="hljs-string">"&lt;Integer&gt; : advertise port of Node. "</span></span> + <span class="hljs-string"><span class="hljs-string">"This port is sent to Hub for backward communication with this node."</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> Integer advertisePort;</code> </pre><br>  And the condition in the registration method on the server. <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (registrationRequest.getConfiguration().advertisePort != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { registrationRequest.getConfiguration().port = registrationRequest.getConfiguration().advertisePort; }</code> </pre><br>  Now, if the advertisePort parameter is set when the node is started, then it is used instead of the standard port during registration on the hub.  This is a local patch, we have not done a pull request to the selenium repository yet.  When we run to the end of our scheme, let's do it. <br><br>  With this parameter, nodes are correctly registered on the hub.  Checked works.  Tests are run. <br><br>  And yes, we used Marathon, as it is used by our developers.  This is essentially a proof of concept.  But in general, this framework is not ideal for running the selenium grid, as it is focused on long running tasks.  Such as services, UI-applications. <br><br><h3>  findings </h3><br>  In a dynamic organizational environment, dynamic resource management is required.  Statics will break about process problems. <br><br>  Therefore, our test run system consists of the following components: <br><br><ul><li>  cluster in which docker containers are created </li><li>  selenium grid as an application that consists of the following components: hub and node </li><li>  Jenkins as an application that executes our job </li><li>  and scripts that automate some work.  These include ansible and sh-scripts. </li></ul><br>  We did not need additional funding.  And we accelerated the test run not even up to 10 minutes, but up to 5 minutes.  The average metric for our projects began to equal exactly 5 minutes.  2 minutes for all procedures for lifting / removing a grid, project assembly, etc.  And 3 minutes to complete test suites. <br><br>  Was the result of the effort worth the effort?  Of course, because in the dry residue, we accelerated the test run at least twice. <br><br>  If you do not like queues too much and are trying to speed up the run of tests, perhaps our experience will be useful to you. <br><br>  By the way, if from the posts about testing your heart beats more often and there is a desire to do something like this - please note that we have a <a href="https://moikrug.ru/vacancies/1000020904">vacancy for the</a> tester. <br><br>  And if there are any questions and clarifications - be sure to write in the comments. </div><p>Source: <a href="https://habr.com/ru/post/331434/">https://habr.com/ru/post/331434/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../331422/index.html">Welcome to Science Slam Digital July 7</a></li>
<li><a href="../331426/index.html">Videos: Android meetup at Badoo office</a></li>
<li><a href="../331428/index.html">The final of the SAP contest Koder 2017 will be held live</a></li>
<li><a href="../331430/index.html">"Gonochki" on SVG</a></li>
<li><a href="../331432/index.html">SIP: this growth does not stop</a></li>
<li><a href="../331436/index.html">Monitoring System Delays with JHiccup</a></li>
<li><a href="../331438/index.html">Artificial Intelligence Half-Life SDK: Retrospective</a></li>
<li><a href="../331440/index.html">Medici effect or is it possible to cross a peach and melon or Windows and iOs</a></li>
<li><a href="../331442/index.html">Consider Kotlin more closely</a></li>
<li><a href="../331444/index.html">Dynamic Apache NiFi cluster creation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>