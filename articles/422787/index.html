<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Major changes in leading chip architectures</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The introduction of AI at the chip level allows you to process locally more data, because the increase in the number of devices no longer gives the sa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Major changes in leading chip architectures</h1><div class="post__text post__text-html js-mediator-article"><h4>  <font color="gray">The introduction of AI at the chip level allows you to process locally more data, because the increase in the number of devices no longer gives the same effect</font> </h4><br>  Chip makers are working on new architectures that significantly increase the amount of data processed per watt and clock.  The ground is being prepared for one of the largest revolutions in chip architecture over the past decades. <br><br>  All major manufacturers of chips and systems change the direction of development.  They entered the architecture race, which involves changing the paradigm in everything: from reading and writing to memory, processing them and, ultimately, assembling the various elements on the chip.  Although the miniaturization continues, no one relies on scaling to cope with the explosive growth of sensor data and the increase in traffic between machines. <br><a name="habracut"></a><br>  Among the changes in new architectures are: <br><br><ul><li>  New methods for processing more data per cycle, sometimes with less accuracy or by prioritizing certain operations, depending on the application. </li><li>  New memory architectures that change the way data is stored, read, written and accessed. </li><li>  More specialized processing modules, located throughout the system close to the memory.  Instead of a central processor, accelerators are selected depending on the type of data and the application. </li><li>  In the field of AI, work is underway to combine different types of data in the form of templates, which effectively increases the data density while minimizing the differences between different types. </li><li>  Now the package layout is the main component of the architecture, with more and more attention being paid to the simplicity of modifying these structures. </li></ul><br>  ‚ÄúThere are several trends that influence technical progress,‚Äù said Steven Wu, an outstanding engineer at Rambus.  - In data centers, you squeeze the maximum out of hardware and software.  From this angle, data center owners look at the economy.  Implementing something new is expensive.  But bottlenecks are changing, so specialized chips are being introduced for more efficient calculations.  And if you reduce data flows back and forth to I / O and memory, this can have a big impact. ‚Äù 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Changes are more obvious at the edge of the computing infrastructure, that is, among the terminal sensors.  Manufacturers have suddenly realized that tens of billions of devices will generate too much data: this amount cannot be sent to the cloud for processing.  But processing all this data on the edge introduces other problems: it requires major improvements in performance without a strong increase in power consumption. <br><br>  ‚ÄúThere is a noticeable trend towards lower accuracy,‚Äù said Robert Ober, lead architect of the Tesla platform at Nvidia.  - This is not just computational cycles.  This is more intensive packing of data in memory, where the format of 16-bit commands is used. ‚Äù <br><br>  Ober believes that, thanks to a series of architectural optimizations, it is possible in the foreseeable future to double the processing speed every couple of years.  ‚ÄúWe‚Äôll see a dramatic increase in productivity,‚Äù he said.  - For this you need to do three things.  The first is computing.  The second is memory.  The third area is host and I / O bandwidth.  Much work needs to be done to optimize storage and network stack. ‚Äù <br><br>  Something is already being implemented.  In a presentation at the 2018 Hot Chips conference, Jeff Ruppley, lead architect at Samsung Research Center in Austin, pointed out several major architectural changes in the M3 processor.  One includes more instructions per clock ‚Äî six instead of four in the past M2 chip.  In addition, the prediction of branching on neural networks is implemented and the queue of instructions has been doubled. <br><br>  Such changes shift the point of innovation from the direct manufacture of microchips to architecture and design on the one hand and to the layout of elements on the other side of the production chain.  And although in technological processes innovations will also continue, but it is incredibly difficult to achieve increased productivity and power by 15‚Äì20% in each new chip model, and this is not enough to cope with the rapid growth of data. <br><br>  ‚ÄúChanges are happening at an exponential rate,‚Äù said Victor Pen, president and CEO of Xilinx, in a speech at the Hot Chips conference. ‚ÄúEach year, 10 zettabytes [10 <sup>21</sup> bytes] of data will be generated, and most of it will be generated in an unstructured form.‚Äù <br><br><h1>  New approaches to memory </h1><br>  Dealing with so much data requires rethinking every component in the system, from data processing methods to storage. <br><br>  ‚ÄúThere have been many attempts to create new memory architectures,‚Äù said Carlos Machin, senior director of innovation, eSilicon EMEA.  - The problem is that you need to read all the lines and select one bit in each.  One option is to create a memory that can be read from left to right, as well as up and down.  You can go even further and add computation to memory. ‚Äù <br><br>  These changes include changing the memory reading methods, the location and type of processing elements, and the introduction of AI to determine the priorities for storing, processing, and moving data throughout the system. <br><br>  ‚ÄúWhat if, in the case of sparse data, we can read from this array only one byte at a time - or maybe eight consecutive bytes from the same byte path, without wasting energy on other bytes or byte paths that we are not interested in ?  - asks Mark Greenberg, director of product marketing for Cadence.  - In the future this is possible.  If you look at the HBM2 architecture, for example, then the stack is organized in 16 virtual channels of 64 bits each, and you only need to get 4 consecutive 64-bit words to access any virtual channel.  Thus, it is possible to create data arrays with a width of 1024 bits, to write horizontally, but to read vertically four 64-bit words at a time. ‚Äù <br><br>  Memory is one of the main components of the von Neumann architecture, but now it has also become one of the main arenas for experimentation.  "The main enemy is virtual memory systems, where data is moved in more unnatural ways," said Dan Bouvier, chief architect of AMD client products.  - This is a broadcast broadcast.  We are used to this in the field of graphics.  But if we eliminate conflicts in the DRAM memory bank, we will get much more efficient streaming.  Then a separate GPU can use DRAM in the range of 90% efficiency, which is very good.  But if you streamline streaming without interruptions, the CPU and APU will also fall in the efficiency range from 80% to 85%. ‚Äù <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6af/814/e8c/6af814e8c5d0a2f4b9274d165aa8f622.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Architecture von Neumann.</font></i>  <i><font color="gray">Source: Semiconductor Engineering</font></i> <br><br>  IBM is developing a different type of memory architecture, which is essentially an upgraded version of disk aggregation.  The goal is that instead of using a single disk, the system can arbitrarily use any available memory through a connector, which Jeff Stucheli, the architect of IBM's hardware systems, calls the "Swiss Army Knife" for the connectivity of the elements.  The advantage of the approach is that it allows you to mix and combine different types of data. <br><br>  ‚ÄúThe processor is becoming the center of a high-performance signaling interface,‚Äù says Stucheli.  ‚ÄúIf you change the micro-architecture, then the core performs more operations per cycle on the same frequency.‚Äù <br><br>  Connectivity and bandwidth should ensure the processing of a dramatically increased amount of generated data.  ‚ÄúThe main bottlenecks are now in the data movement sites,‚Äù said Wu from Rambus.  - The industry has done a lot of work, increasing the speed of calculations.  But if you are expecting data or specialized data patterns, then you need to run memory faster.  Thus, if you look at DRAM and NVM, performance depends on the traffic pattern.  If the data is streaming, the memory will provide very good performance.  But if the data comes in random drops, it is less effective.  And whatever you do, with increasing volume, you still have to do it faster. ‚Äù <br><br><h1>  More calculations, less traffic </h1><br>  The problem is exacerbated by the fact that there are several different types of data generated at different frequencies and speeds by devices on the edge.  In order for this data to move freely between different processing modules, management must become much more efficient than in the past. <br><br>  ‚ÄúThere are four basic configurations: many-to-many (many-to-many), memory subsystems, low-power IO, as well as grids and ring topologies,‚Äù says Charlie Janak, chairman and CEO of Arteris IP.  - You can place all four on one chip, which is what happens with key IoT chips.  Or you can add high bandwidth HBM subsystems.  But the complexity is enormous, because some of these workloads are very specific, and the chip has several different work tasks.  If you look at some of these microcircuits, they get huge amounts of data.  This is in systems such as car radar and lidar.  They cannot exist without some advanced interconnections. ‚Äù <br><br>  The challenge is how to minimize the movement of data, but at the same time maximize the flow of data when it is required - and somehow find a balance between local and centralized processing without excessive growth of energy consumption. <br><br>  ‚ÄúOn the one hand, this is a bandwidth problem,‚Äù said Rajesh Ramanujam, product marketing manager for NetSpeed ‚Äã‚ÄãSystems.  - You want to reduce traffic whenever possible, so transfer the data closer to the processor.  But if you still need to move the data, it is desirable to maximize their data.  But nothing exists by itself.  Everything must be planned from the system level.  At each step, several interdependent axes must be considered.  They determine whether you are using the memory in the traditional way of reading or writing, or you are using new technologies.  In some cases, it may be necessary to change the way the data itself is stored.  If you need higher performance, it usually means an increase in the area of ‚Äã‚Äãthe chip, which affects heat dissipation.  And now, taking into account functional safety, data overload cannot be allowed. ‚Äù <br><br>  That is why so much attention is paid to data processing at the edge and throughput of channels by various data processing modules.  But as far as the development of different architectures is very different, how and where this data processing is implemented. <br><br>  For example, Marvell introduced an SSD controller with integrated AI to cope with the large computational load on the edge.  The AI ‚Äã‚Äãengine can be used for analytics right inside the SSD drive. <br><br>  ‚ÄúYou can load models directly into the hardware and perform hardware processing on the SSD controller,‚Äù said Nedarnica, chief engineer of Marvell.  - Today it makes the server in the cloud (host).  But if each drive sends data to the cloud, it will create a huge amount of network traffic.  It is better to perform processing on the edge, and the host issues only the command, which is simply metadata.  The more drives you have, the more processing power.  This is a huge benefit from reducing traffic. ‚Äù <br><br>  In this approach, it is particularly interesting that it adapts to different data depending on the application.  Thus, a host can generate a task and send it to a storage device for processing, after which only metadata or calculation results are sent back.  In another scenario, the storage device can store data, pre-process it, and generate metadata, tags, and indexes, which are then retrieved by the host as needed for further analytics. <br><br>  This is one of the possible options.  There are others.  Samsung Rupley emphasized the importance of processing and merging idioms, which can decode two instructions and combine them into one operation. <br><br><h1>  AI is in control and optimization. </h1><br>  Artificial Intelligence is applied at all optimization levels - this is one of the truly new elements in the chip architecture.  Instead of letting the operating system and middleware manage functions, this monitoring function is distributed across the chip, between chips, and at the system level.  In some cases, hardware neural networks are being introduced. <br><br>  ‚ÄúIt's not so much about packing more elements together as changing traditional architecture,‚Äù says Mike Gianfanya, vice president of marketing for eSilicon.  - With the help of AI and machine learning, you can distribute elements across the system, getting more efficient processing with prediction.  Or you can use separate chips, independently functioning in the system or in the module. " <br><br>  ARM has developed its first machine learning chip, which it plans to launch at the end of this year for several markets.  ‚ÄúThis is a new type of processor,‚Äù said Ian Bratt, honored ARM engineer.  - It includes a fundamental unit - it is a computational engine, as well as a MAC engine, a DMA engine with a control module and a broadcast network.  In total there are 16 cores made using the 7 nm process technology, which provide 4 TeraOps at 1 GHz. ‚Äù <br><br>  Since ARM works with a partner ecosystem, its chip is more versatile and customizable than other AI / ML chips that are being developed.  Instead of a monolithic structure, it divides processing into functions, so each computational module operates on a separate feature map.  Bratt named four key ingredients: static planning, effective coagulation, band narrowing mechanisms, and programmed adaptation to future design changes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbe/7e4/ab1/fbe7e4ab11731ad3dafebc992b9c7bf2.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. ML processor architecture from ARM.</font></i>  <i><font color="gray">Source: ARM / Hot Chips</font></i> <br><br>  Meanwhile, Nvidia chose a different tactic: creating a dedicated deep learning engine next to the GPU to optimize image and video processing. <br><br><h1>  Conclusion </h1><br>  Using some or all of these approaches, chip manufacturers expect to double their performance every couple of years, keeping up with the explosive growth of data, while remaining in the tight framework of energy consumption budgets.  But this is not just more computation.  This is a change in the design platform of chips and systems, when the main factor is the growing amount of data, and not the limitations of hardware and software. <br><br>  ‚ÄúWhen computers appeared in companies, it seemed to many that the world around us accelerated,‚Äù said Aart de Gees, chairman and one of the executive directors of Synopsys.  - They made accounting on pieces of paper with piles of books.  Ledger turned into a stack of punch cards for printing and calculation.  There has been a tremendous change, and we see it again.  With the advent of simple computing computers, the algorithm of actions has not changed mentally: you could follow every step.  But now something else is happening that could lead to a new acceleration.  It's like on an agricultural field to turn on watering and apply a certain type of fertilizer only on a certain day, when the temperature reaches the desired level.  This use of machine learning is an optimization that was not obvious in the past. ‚Äù <br><br>  He is not alone in this assessment.  ‚ÄúNew architectures will be adopted,‚Äù said Wally Rains, president and CEO of Mentor, Siemens Business.  - They will be designed.  Machine learning will be used in many or most cases because your brain learns from experience.  I have visited 20 or more companies that develop specialized AI processors of one sort or another, and each one has its own little niche.  But you will increasingly see their use in specific applications, and they will complement the traditional von Neumann architecture.  Neuromorphic calculations will become mainstream.  This is a big step in computing efficiency and cost reduction.  Mobile devices and sensors will start doing the work that servers are doing today. ‚Äù </div><p>Source: <a href="https://habr.com/ru/post/422787/">https://habr.com/ru/post/422787/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422775/index.html">Conference DEFCON 22. Andrew "Zoz" Brooks. Don't screw it up! Part 1</a></li>
<li><a href="../422777/index.html">A simple introduction to the ALU for neural networks: an explanation, physical meaning and implementation</a></li>
<li><a href="../422781/index.html">Fintech-digest: SWIFT will continue to work in the Russian Federation, VISA will allow you to transfer funds by phone number, expensive biometrics</a></li>
<li><a href="../422783/index.html">Better, faster, more powerful: styled-components v4</a></li>
<li><a href="../422785/index.html">Digitization of the plant: a look from the front</a></li>
<li><a href="../422789/index.html">@Pythonetc compilation, august 2018</a></li>
<li><a href="../422791/index.html">How not to learn English: common mistakes</a></li>
<li><a href="../422793/index.html">Conference DEFCON 22. Andrew "Zoz" Brooks. Don't screw it up! Part 2</a></li>
<li><a href="../422795/index.html">Technology and business: a new model of cooperation with Zyxel in Russia</a></li>
<li><a href="../422797/index.html">How we made a small-sized cloud DVR from a regular IP camera</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>