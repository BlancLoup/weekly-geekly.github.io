<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Installing Facebook image recognition package. All rake in one place</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, Facebook released its open-source image recognition project. Of course, I immediately wanted to touch him, see how he works and what can be ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Installing Facebook image recognition package. All rake in one place</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/fs/yp/zb/fsypzbjcdcmy5cxri0zvkapwyyk.jpeg">  Recently, Facebook released its open-source image recognition project.  Of course, I immediately wanted to touch him, see how he works and what can be obtained with it.  We decided to deal with its installation and empirically check whether it is so easy to use it, as the developers write about it in the instructions. </p><br><p>  This project is not the easiest, so the question arises, why is it needed if there are ready-made frameworks such as Keras, TensorFlow and Caffe, where, as they say, ‚Äúsat down and went‚Äù?  And the answer is simple: you need a flexible tool with the ability to expand, which will make friends with Python.  We have learned how to distinguish a whale from a seagull, but what will it give us?  IFunny seriously makes a fun application and wants to surprise users with new features, so why not explore such a rich direction and apply? </p><br><p>  After reading this analysis, you will be one step closer to enlightenment.  Ready?  Then grab a pen, paper and proceed! </p><br><p>  And yes, you can safely consider this article as a manual for installation, and step by step, but you can also refer to it if an error has come out, and Google looks away to the side or gives utter nonsense in a search engine. </p><a name="habracut"></a><br><h2>  Getting started </h2><br><p>  A little before reaching the moment when you need to write the first git clone for their project, let's stop at the stage of iron and environment. </p><br><p>  It seems to be all transparent and beautiful.  But.  Let's start with iron.  The project is very, very demanding.  Especially memory, swap and video card.  Initially, the build was done on an AWS instance with a configuration: </p><br><ul><li>  OS: Linux Redhat 2017.09 (EC2) ‚Üí Ubuntu 16.04 LTS </li><li>  CPU: 16 x Intel¬Æ Xeon¬Æ CPU E5-2686 v4 @ 2.30GHz; </li><li>  HDD: 1 Tb; </li><li>  Swap: 16 Gb ‚Üí 128 Gb (!!!); </li><li>  RAM: 122 Gb (7 x 16 Gb, 1 x 10 Gb); </li><li>  Graphic adapter: GRID K520 ‚Üí Tesla M60. </li></ul><br><div class="spoiler">  <b class="spoiler_title">Why Ubuntu LTS?</b> <div class="spoiler_text"><p>  It is better to immediately use Ubuntu LTS, because it already has all the necessary basic compilers of the latest versions, or it is easy to upgrade to the latest versions.  During the build and launch process, it will be clear why we jumped so drastically from one system to another, changed the video card and threw a swap. </p></div></div><br><p>  If you want to collect all this out of curiosity, to see how it works and play, then acquire at least a video card with CUDA technology.  Without it, trying to start is useless.  To understand what kind of graphics card that can - here is a link to the wiki. </p><br><p>  GRID K520 video card belongs to CUDA capability 3.0+.  It is already possible to work with her, but not as quickly as we would like. </p><br><h2>  Go?  Or stand a little bit ... </h2><br><h3>  We put the package from Nvidia </h3><br><p>  We proceed directly to the environment.  To begin with, make sure that we have a g ++ version not lower than 4.9, otherwise at the very end we may suffer a fiasco.  Take the newest, freshest g ++, just from the repository.  Next put fresh drivers from Nvidia. </p><br><pre><code class="bash hljs">sudo yum install nvidia <span class="hljs-comment"><span class="hljs-comment">#- ,     sudo yum install cuda #,  ,   nvcc --version # CUDA</span></span></code> </pre> <br><p>  Register at <a href="http://developers.nvidia.com/">http://developers.nvidia.com</a> and download the cuDNN library for your version of CUDA. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qy/og/wn/qyogwnconnjl3dml8xki8pfo6sg.png" width="350"></div><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ tar -xzvf cudnn-<span class="hljs-variable"><span class="hljs-variable">$VERSION</span></span>-linux-x64-v7.tgz</code> </pre> <br><p>  For Ubuntu 16.04, everything looks simpler: </p><br><pre> <code class="bash hljs">sudo apt-get install nvidia-384* sudo apt-get install nvidia-cuda-dev sudo apt-get install nvidida-cuda-toolkit</code> </pre> <br><p>  And here you can do differently.  The official <a href="http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html">manual</a> requires that we copy the files to different places.  You can agree with the manual and copy as indicated.  But you can do it easier.  From cuda / include copy the libraries to <code>/usr/local/cuda/lib64</code> . </p><br><h3>  Installing Lua and LuaRocks </h3><br><p>  Farther.  We need Lua and LuaRocks (another package manager - not enough for us, not enough).  Everything is simple for both OSs: </p><br><pre> <code class="bash hljs">curl -R -O http://www.lua.org/ftp/lua-5.3.4.tar.gz tar zxf lua-5.3.4.tar.gz <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> lua-5.3.4 make linux <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ wget luarocks-2.4.3.tar.gz tar -xvf luarocks-2.4.3.tar.gz <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> luarocks-2.4.3 ./configure make build sudo make install <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/</code> </pre> <br><h3>  Install Torch7 and its dependencies </h3><br><p>  We already have a luarocks dependency manager.  And now the most interesting thing: you need to put some of the dependencies through LuaRocks (everything will not work, otherwise delivered and will not take off at all).  In general, when installing these dependencies, there should not be any problems, but there are many, many small grabelles (and what about without them). </p><br><ol><li><p>  Torch (should install Torch7). </p><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/torch/distro.git ~/torch --recursive <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/torch; bash install-deps; <span class="hljs-comment"><span class="hljs-comment"># ./install.sh ‚Äî    ,  LUAJIT21    #    TORCH_LUA_VERSION=LUA52 ./install.sh #  lua52  :  #  ,  warning    source ~/.bashrc #    torch  th    #  </span></span></code> </pre> <br><p>  In theory, nothing will stop you at this moment, except for the error with the 'half'.  This problem is solved as follows: first we execute the command in the console. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> TORCH_NVCC_FLAGS=<span class="hljs-string"><span class="hljs-string">"-D__CUDA_NO_HALF_OPERATORS__"</span></span>.</code> </pre> <br><p>  Then run the installation again. </p><br></li><li><p>  COCO API: is collected only from source, but at least it is installed without problems. </p><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/cocodataset/cocoapi.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> cocoapi luarocks make LuaAPI/rocks/coco-scm-1.rockspec</code> </pre> <br></li><li><p>  image: no problem.  We put through luarocks: <code>luarocks install image</code> </p><br></li><li><p>  tds: all of a sudden it is not a package and generally you need to install lua ffi </p><br><pre> <code class="bash hljs">luarocks install --server=http://luarocks.org/dev luaffi</code> </pre> <br></li><li><p>  cjson: in theory, there are no problems, except that the package is called json. </p><br><pre> <code class="bash hljs">luarocks install json</code> </pre> <br></li><li><p>  nnx: and here is an ambush.  You are already happy with the Torch framework?  Then we clone the repository into the torch root and RETRIEVE it entirely.  Here it is necessary to clarify that it will not be possible to assemble immediately with nnx, COCO API, image, tds and cjson packages are indicated in its dependencies. </p><br></li><li><p>  optim: no problems found, put directly <code>luarocks install optim</code> . </p><br></li><li><p>  inn: similar to <code>luarocks install inn</code> . </p><br></li><li>  cutorch, cunn, cudnn - put in exactly this sequence <br><pre> <code class="bash hljs">luarocks install cutorch luarocks install cunn luarocks install cudnn</code> </pre> </li></ol><br><p>  It seems to be all set.  But it does not leave the feeling that something is forgotten ... Something important ... So it is.  The project itself who will clone? </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebookresearch/deepmask.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> deepmask</code> </pre> <br><h3>  We set up models for training </h3><br><p>  Tightened?  Well done.  And now it will be the longest part.  Download training packs and grids.  And we have two ways.  The first way is to download ready-made models and, without training the network, immediately start checking your picture (here you can safely skip the neural network training step and immediately add dependencies further). </p><br><div class="spoiler">  <b class="spoiler_title">Download and run</b> <div class="spoiler_text"><pre> <code class="bash hljs">mkdir -p pretrained/deepmask; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> pretrained/deepmask wget https://s3.amazonaws.com/deepmask/models/deepmask/model.t7 mkdir -p pretrained/sharpmask; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> pretrained/sharpmask wget https://s3.amazonaws.com/deepmask/models/sharpmask/model.t7 <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/deepmask/ th computeProposals.lua pretrained/deepmask <span class="hljs-comment"><span class="hljs-comment"># run DeepMask th computeProposals.lua pretrained/sharpmask # run SharpMask th computeProposals.lua pretrained/sharpmask -img /path/to/image.jpg</span></span></code> </pre> </div></div><br><p>  As already mentioned, downloaded models are enough for a quick start.  This can be done not to train the neural network for several days, but this is not enough for something more serious.  The second path begins here.  Therefore, we continue. </p><br><pre> <code class="bash hljs">mkdir -p pretrained wget https://s3.amazonaws.com/deepmask/models/resnet-50.t7 <span class="hljs-comment"><span class="hljs-comment">#   , 250 . mkdir -p ~/deepmask/data; cd ~/deepmask/data wget http://msvocds.blob.core.windows.net/annotations-1-0-3/instances_train-val2014.zip # ~158 Mb wget http://msvocds.blob.core.windows.net/coco2014/train2014.zip # ~13 Gb &gt;85k  wget http://msvocds.blob.core.windows.net/coco2014/val2014.zip # ~6.2 Gb &gt;40k </span></span></code> </pre> <br><h3>  We solve mistakes with CUDA </h3><br><p>  Now we have the necessary kits for training the neural network and training validation.  It seems that there is. </p><br><pre> <code class="bash hljs">th train.lua --<span class="hljs-built_in"><span class="hljs-built_in">help</span></span> .... THCudaCheck FAIL file=/home/ubuntu/torch/extra/cutorch/lib/THC/THCGeneral.c line=70 error=30 : unknown error /home/ubuntu/torch/install/bin/lua: /home/ubuntu/torch/install/share/lua/5.2/trepl/init.lua:389: cuda runtime error (30) : unknown error at /home/ubuntu/torch/extra/cutorch/lib/THC/THCGeneral.c:70</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gl/vh/nj/glvhnj8qg1cbrvzjfhmvznotfda.png" width="420"></div><br><div class="spoiler">  <b class="spoiler_title">When not enough CWRAP module</b> <div class="spoiler_text"><p>  We look trace.  Hmm ... It is very similar to the fact that there are not enough established dependencies: cunn, cudnn was established crookedly.  Okay, reinstall.  But it's not about them.  Let's make an investigation!  Check further.  We try to install cutorch again and ... Bingo!  The cwrap module was not found. </p><br><p>  Installing, what else is left to do. </p><br><pre> <code class="hljs sql">luarockt <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> cwrap luarockt <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> cutorch</code> </pre> <br><p>  And here we again get the error that the cwrap module is not installed.  WTF?  I will not delve into the mechanics of LuaRocks, but the cwrap package cannot be put just like that, right away.  We dig in the assistant and find the following: ‚Äúin case the package is installed, but in fact it is not there, apply the --local directive‚Äù.  Schr√∂dinger package.  It seems to have, but it is not.  Okay. </p><br><pre> <code class="bash hljs">luarockt install --<span class="hljs-built_in"><span class="hljs-built_in">local</span></span> wrap</code> </pre> <br><p><img src="https://habrastorage.org/webt/xe/jq/kq/xejqkq1nnrjcz-niaozwerppb_y.jpeg" width="120" align="left">  And again the same rake.  But this is not funny.  I categorically do not recommend putting all this under sudo.  Well, why the math package superuser?  Several steps that help install this package from the rockspec file.  Check the paths LUA_PATH and LUA_CPATH and run the following commands: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/torch git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/torch/cwrap.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> cwrap cmake . <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> .. TORCH_LUA_VERSION=LUA52 ./install.sh <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> cwrap luarocks make rocks/cwrap-scm-1.rockspec luarocks install cutorch luarocks install inn luarocks install cunn luarocks install cudnn</code> </pre> </div></div><br><h3>  We teach the neural network (if the models were downloaded - skip this step) </h3><br><p>  Coped.  It's time to start learning neural network.  Further actions may take several days!  Carefully look at the options with which you start training and validation! </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/deepmask th train.lua --<span class="hljs-built_in"><span class="hljs-built_in">help</span></span> ```bash ,       .   ,       . ```bash -nthreads <span class="hljs-comment"><span class="hljs-comment">#    ‚Äî   . #    (!)  (!) , #      ‚Äî 16 -batch #    .   32 -maxload #     ,       #.   4000 -testmaxload #    .    , # ,       ,  #;   500 -maxepoch #  .   300 .   , #   </span></span></code> </pre> <br><p>  So let's get started.  Since we got such a powerful instance, what prevents us from loading the maximum processors? </p><br><pre> <code class="bash hljs">th train.lua -nthreads 16 -batch 500</code> </pre> <br><p>  Oops ... But Nvidia installed its libraries and dismisses all vcc --version with the correct info.  Only here the libraries are in <code>/home/ubuntu/cuda/lib64/libcudnn.so.5</code> .  And this means that at the very end of the .bashrc file we add the directive: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> CUDNN_PATH=<span class="hljs-string"><span class="hljs-string">"/home/ubuntu/cuda/lib64/libcudnn.so.5"</span></span></code> </pre> <br><p>  In theory, we are waiting for happiness, but no.  We can step on the rake again.  Serious enough. <br>  In case the rake was not found, you will see a text similar to the text in the screenshot. </p><br><img src="https://habrastorage.org/webt/p2/ad/cx/p2adcxokmk7fs19lzbs-zchhnwy.png"><br><p>  Either one of the error messages.  The errors themselves and their solution methods are described in detail under the spoilers. </p><br><pre> <code class="bash hljs">th train.lua -nthreads 16 -batch 500</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Output to console with error</b> <div class="spoiler_text"><pre> <code class="lua hljs">Found Environment variable CUDNN_PATH = /home/ubuntu/cuda/lib64/libcudnn.so<span class="hljs-number"><span class="hljs-number">.5</span></span><span class="hljs-comment"><span class="hljs-comment">-- ignore option dm -- ignore option reload -- ignore option datadir nthreads 16 2 -- ignore option rundir -- ignore option gpu batch 500 32 | running in directory /home/ubuntu/deepmask/exps/deepmask/exp,batch=500,nthreads=16 | number of paramaters trunk: 15198016 | number of paramaters mask branch: 1608768 | number of paramaters score branch: 526337 | number of paramaters total: 17333121 convert: data//annotations/instances_train2014.json --&gt; .t7 [please be patient] convert: data//annotations/instances_train2014.json --&gt; .t7 [please be patient] convert: data//annotations/instances_train2014.json --&gt; .t7 [please be patient] convert: data//annotations/instances_train2014.json --&gt; .t7 [please be patient] convert: data//annotations/instances_train2014.json --&gt; .t7 [please be patient] /home/ubuntu/torch/install/bin/lua: ...e/ubuntu/torch/install/share/lua/5.2/threads/threads.lua:183: [thread 16 callback] /home/ubuntu/torch/install/share/lua/5.2/coco/CocoApi.lua:142: Expected value but found T_END at character 1</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">If models with error T_END have not been converted</b> <div class="spoiler_text"><p>  If you have suffered such a wonderful mistake, then you just need to make a series of wonderful steps: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~ rm -rf torch/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/torch/distro.git ~/torch --recursive <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/torch; bash install-deps; TORCH_LUA_VERSION=LUA52 ./install.sh git checkout 5961f52a65fe33efa675f71e5c19ad8de56e8dad ./clean.sh bash install-reps TORCH_LUA_VERSION-LUA52 ./install.sh luarocks install cudnn luarocks install cutorch <span class="hljs-comment"><span class="hljs-comment">#  !   .     luarocks install cunn luarocks install inn luarocks install tds luarocks install optim luarocks install nnx luarocks install image cd ~/coco/ luarocks make LuaAPI/rocks/coco-scm-1.rockspec</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">If models are not converted due to lack of memory</b> <div class="spoiler_text"><p>  Rebuilt.  Reinstalled.  Run again with the same options and see: </p><br><pre> <code class="bash hljs">th train.lua -nthreads 16 -batch 500 -- ignore option rundir -- ignore option dm -- ignore option reload -- ignore option gpu -- ignore option datadir nthreads 1 2 | running <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> directory /Users/ryan/mess/2016/34/deepmask/exps/deepmask/exp,nthreads=1 | number of paramaters trunk: 15198016 | number of paramaters mask branch: 1608768 | number of paramaters score branch: 526337 | number of paramaters total: 17333121 convert: data//annotations/instances_train2014.json --&gt; .t7 [please be patient] FATAL THREAD PANIC: (write) not enough memory   .  ? ! Workaround     .     .       .      . ```bash <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/deepmask/ th coco = require <span class="hljs-string"><span class="hljs-string">'coco'</span></span> coco.CocoApi(<span class="hljs-string"><span class="hljs-string">"data/annotations/instances_train2014.json"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># ,   #convert: data/annotations/instances_train2014.json --&gt; .t7 [please be patient] #converting: annotations #converting: categories #converting: images #convert: building indices #convert: complete [57.22 s] #CocoApi coco.CocoApi("data/annotations/instances_val2014.json") # ,   #convert: data/annotations/instances_val2014.json --&gt; .t7 [please be patient] #converting: annotations #converting: categories #converting: images #convert: building indices #convert: complete [26.07 s] #CocoApi</span></span></code> </pre> </div></div><br><h3>  We teach neural network </h3><br><p>  Now the preparations are complete.  All models are there, there are networks, there are images for training and validation.  Run again.  Let's try to load as much as possible. </p><br><pre> <code class="bash hljs">th train.lua -batch 500 -nthreads 16</code> </pre> <br><p>  In parallel, we look at htop (not the best idea, since it will not show the division of consumed memory by type). </p><br><img src="https://habrastorage.org/webt/0j/a5/l0/0ja5l09s4cmpd_m68hwzbizgnom.png"><br><p>  To put it mildly, it's hot.  I remind you: 16 physical processors, each with 8 cores, with virtualization.  And memory.  It is not surprising that after a few minutes of operation, the terminal issued "Killed"! </p><br><p>  We try again, we make the conditions "easier": </p><br><pre> <code class="bash hljs">th train.lua -maxepoch 2 -nthreads 4</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Output from the console here</b> <div class="spoiler_text"><pre> <code class="bash hljs">Found Environment variable CUDNN_PATH = /home/ubuntu/cuda/lib64/libcudnn.so.5maxepoch 2 300 -- ignore option datadir -- ignore option gpu -- ignore option dm nthreads 4 2 -- ignore option rundir -- ignore option reload | running <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> directory /home/ubuntu/deepmask/exps/deepmask/exp,maxepoch=2,nthreads=4 | number of paramaters trunk: 15198016 | number of paramaters mask branch: 1608768 | number of paramaters score branch: 526337 | number of paramaters total: 17333121 | start training</code> </pre> </div></div><br><p>  Again.  The 154 GB of memory used are all RAM banks, part of the swap, and part of the virtual memory.  Stop.  Stop through kill or Ctrl + C is not critical at all.  When restarting training, all old models are overwritten. </p><br><p>  Even on the Amazon machine, you can safely leave the script to work and go about your business for an hour and a half or two. </p><br><div class="spoiler">  <b class="spoiler_title">How not to lose session when working with an Amazon instance</b> <div class="spoiler_text"><p>  By the way, an important note: to see that something happened, the results of training the neural network, etc., when working through ssh, use the screen.  Did the connection suddenly disappear and so on?  No problem.  Reconnected to the car, entered screen -r - and we again see what we took off on. </p></div></div><br><p>  The <code>-nthreads 4</code> option is forced by restarting and timing the neural network training time.  Because with a larger load, the competition for RAM begins, and we have very, very many parameters (in the amount of 17 million). </p><br><p>  On the training sample in 85K images.  By the way, each even step of learning the script validates the neural network. </p><br><div class="spoiler">  <b class="spoiler_title">Output to the console information on training, 16 streams, 12 eras</b> <div class="spoiler_text"><pre> <code class="bash hljs">th train.lua -nthreads 16 -maxepoch 12 Found Environment variable CUDNN_PATH = /home/ubuntu/cuda/lib64/libcudnn.so.5-- ignore option reload -- ignore option dm maxepoch 12 300 -- ignore option gpu nthreads 16 2 -- ignore option datadir -- ignore option rundir | running <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> directory /home/ubuntu/deepmask/exps/deepmask/exp,maxepoch=12,nthreads=16 | number of paramaters trunk: 15198016 | number of paramaters mask branch: 1608768 | number of paramaters score branch: 526337 | number of paramaters total: 17333121 | start training [train] | epoch 00001 | s/batch 0.67 | loss: 0.31743 [train] | epoch 00002 | s/batch 0.67 | loss: 0.18296 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00002 | IoU: mean 054.60 median 061.36 suc@.5 062.63 suc@.7 036.53 | acc 092.91 | bestmodel * [train] | epoch 00003 | s/batch 0.67 | loss: 0.16256 [train] | epoch 00004 | s/batch 0.67 | loss: 0.15217 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00004 | IoU: mean 059.10 median 065.86 suc@.5 068.97 suc@.7 043.31 | acc 093.93 | bestmodel * [train] | epoch 00005 | s/batch 0.67 | loss: 0.14583 [train] | epoch 00006 | s/batch 0.67 | loss: 0.14183 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00006 | IoU: mean 056.79 median 064.92 suc@.5 065.88 suc@.7 042.34 | acc 094.27 | bestmodel x [train] | epoch 00007 | s/batch 0.67 | loss: 0.13739 [train] | epoch 00008 | s/batch 0.67 | loss: 0.13489 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00008 | IoU: mean 059.53 median 067.17 suc@.5 069.44 suc@.7 045.33 | acc 094.69 | bestmodel * [train] | epoch 00009 | s/batch 0.67 | loss: 0.13417 [train] | epoch 00010 | s/batch 0.67 | loss: 0.13290 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00010 | IoU: mean 061.80 median 069.41 suc@.5 072.71 suc@.7 048.92 | acc 094.67 | bestmodel * [train] | epoch 00011 | s/batch 0.67 | loss: 0.13070 [train] | epoch 00012 | s/batch 0.67 | loss: 0.12711 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00012 | IoU: mean 060.16 median 067.43 suc@.5 070.71 suc@.7 046.34 | acc 094.85 | bestmodel x</code> </pre> </div></div><br><p>  Conducted training and you can proceed to the next stage.  Based on the received DeepMask-models, you need to generate SharpMask. </p><br><pre> <code class="bash hljs">th train.lua -dm ~/deepmask/exps/deepmask/exp\,maxepoch\=2\,nthreads\=4/ <span class="hljs-comment"><span class="hljs-comment">#    ,    </span></span></code> </pre> <br><p>  If the training was started with other parameters, then the name of the model folder will be different.  But the main way to it is the same.  While we are learning DeepMask or building SharpMask, we will continue the installation. </p><br><h3>  We put google-glog </h3><br><p>  There were no problems with him, because he was really simple and trouble-free. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/google/glog.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> glog ./autogen.sh ./configure make sudo make install</code> </pre> <br><h3>  Multipathnet, fbpython and a whole bunch of dependencies </h3><br><p>  Now all we have to do is to clone a multipathnet project, install dependencies on it, and start recognition.  It seems that I have already heard somewhere that everything is "easy and simple." </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebookresearch/multipathnet.git luarocks install torchnet luarocks install class luarocks install fbpython</code> </pre> <br><p>  Do not attempt to install fbpython via Conda or Anaconda and others.  As Facebook expresses in the instruction:  If we translate roughly and with a bit of humor, then "this is their own barge, with its own troubles and its own captain." </p><br><p>  So, someone again kept silent about dependencies. </p><br><pre> <code class="bash hljs">... -- Found Torch7 <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /home/ubuntu/torch/install -- REQUIRED_ARGS (missing: THPP_INCLUDE_DIR THPP_LIBRARIES) -- Looking <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pthread.h ...</code> </pre> <br><p>  We googling in all directions, what are these variables and why we still do not have them. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebook/folly.git git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebook/fbthrift.git git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebook/thpp git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebookarchive/fblualib.git <span class="hljs-comment"><span class="hljs-comment">#   ,   ,   </span></span></code> </pre> <br><p>  I find it wonderful.  Another small zoo.  Okay.  For those on Ubuntu: </p><br><div class="spoiler">  <b class="spoiler_title">There are a lot of commands and console output here.</b> <div class="spoiler_text"><pre> <code class="bash hljs">sudo apt-get install zlib1g-dev binutils-dev libjemalloc-dev libssl-dev sudo apt-get install libevent-dev sudo apt-get install libsnappy-dev sudo apt-get install libboost-all-dev libgoogle-glog-dev libgflags-dev liblz4-dev liblzma-dev libsnappy-dev Linux: <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/gflags/gflags.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> gflags mkdir build &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> build $ ccmake .. - Press <span class="hljs-string"><span class="hljs-string">'c'</span></span> to configure the build system and <span class="hljs-string"><span class="hljs-string">'e'</span></span> to ignore warnings. <span class="hljs-comment"><span class="hljs-comment">#   SHARED_LIB - Set CMAKE_INSTALL_PREFIX and other CMake variables and options. #  'c'   - Continue pressing 'c' until the option 'g' is available. #  'g'   - Then press 'g' to generate the configuration files for GNU Make. cd .. cmake -fpic -shared configure . make sudo make install cd ~/ git clone https://github.com/google/glog.git export LDFLAGS='-L/usr/local/lib' cd glog autoreconf -ivf ./configure make sudo make install cd ~/ git clone https://github.com/google/double-conversion.git cd double-conversion cmake . -DBUILD_SHARED_LIBS=ON #  .    # cmake   -fpic -shared make sudo make install   : wget https://github.com/google/googletest/archive/release-1.8.0.tar.gz &amp;&amp; \ tar zxf release-1.8.0.tar.gz &amp;&amp; \ rm -f release-1.8.0.tar.gz &amp;&amp; \ cd googletest-release-1.8.0 &amp;&amp; \ cmake configure . &amp;&amp; \ make &amp;&amp; \ sudo make install cd ~/folly cmake -fpic -shared configure .. make (optionally -j$(proc)) sudo make install</span></span></code> </pre> </div></div><br><p>  Then everything goes only for Ubuntu, since it was pointless on RHEL to try to update the whole environment.  At the time of writing this article, it was simply impossible to advance further into RHEL, the limitation on the maximum version of packages for Amazon instances is to blame. </p><br><p>  Linux users can continue installing packages on their own, but you will need to search for the necessary packages (and if you run into a rake in the process, welcome to the comments, I will be happy to help solve problems). </p><br><h3>  We put fbthrift </h3><br><p>  NEVER touch build_folly_fbthrift.sh.  Otherwise, you will have to roll back to the moment when there is nothing except the training of the model. </p><br><div class="spoiler">  <b class="spoiler_title">All installation commands</b> <div class="spoiler_text"><pre> <code class="bash hljs">sudo apt-get install flex bison git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/no1msd/mstch.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> mstch cmake . make sudo make install <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebook/wangle.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> wangle/wangle cmake . make sudo make install <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/facebook/zstd.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> zstd make sudo make install <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/krb5/krb5.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> krb5/src autoreconf -ivf ./configure make sudo make install <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/fbthrift/build cmake -fpic -shared configure . make sudo make install</code> </pre> </div></div><br><p>  And now you think that there is happiness and you can install thpp.  As practice has shown - no.  Resting in a thousand shoals ... Fbthrift!  To start: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/fbthrift/thrift/compiler/py sudo python setup.py install</code> </pre> <br><p>  This will install the missing thrift_compiler.  Then it turns out that there is no frontend.so at all.  Lost compile and put in a folder.  Well, okay (for reference: below is the generation line frontend.so for g ++ ~ v5.4). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/fbthrift/thrift/compiler/py g++ -I /usr/include/python2.7 -I ~/fbthrift -std=c++1y -fpic -shared -o frontend.so compiler.cc -lboost_python -lpython2.7 -L/build/lib -lcompiler_base -lcompiler_ast -lboost_system -lboost_filesystem -lssl -lcrypto sudo cp frontend.so /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/lib/python2.7/dist-packages/thrift_py-0.9.0-py2.7.egg/thrift_compiler/</code> </pre> <br><p>  If you are missing something, compile yourself.  It feels like you‚Äôll have to add code for them further.  And the premonition was not deceived. </p><br><h3>  If you catch an error calling methods with the wrong number of parameters </h3><br><p>  Vooot, now we are waiting for happiness.  Almost.  Good Samaritans from Facebook changed the function calls in torch7, but between times they forgot to make the correct call in thpp.  How cute. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/thpp/thpp/detail/ nano TensorGeneric.h</code> </pre> <br><p>  It is necessary to correct the following calls (cap prompts: after dim the part ", 0" was added): </p><br><pre> <code class="lua hljs">static void _max(THTensor* values, THLongTensor* indices, THTensor* t, int dim) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> THTensor_(<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>)(values, indices, t, dim, <span class="hljs-number"><span class="hljs-number">0</span></span>); } static void _min(THTensor* values, THLongTensor* indices, THTensor* t, int dim) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> THTensor_(<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>)(values, indices, t, dim, <span class="hljs-number"><span class="hljs-number">0</span></span>); } static void _sum(THTensor* r, THTensor* t, int dim) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> THTensor_(sum)(r, t, dim, <span class="hljs-number"><span class="hljs-number">0</span></span>); } static void _prod(THTensor* r, THTensor* t, int dim) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> THTensor_(prod)(r, t, dim, <span class="hljs-number"><span class="hljs-number">0</span></span>); }</code> </pre> <br><p>  We collect the package again, but that's not all ... </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/thpp/thpp ccmake . <span class="hljs-comment"><span class="hljs-comment">#  NO_TEST = ON,  'c',  'g' cmake . make sudo make install</span></span></code> </pre> <br><h3>  We put fblualib </h3><br><p>  Now in line fblualib.  You can deal with it easily and simply.  I repeat: in no case do not use their scripts, which are the tempting names of install-all.sh.  Cover all your dancing, and you have to start almost from scratch. </p><br><pre> <code class="bash hljs">sudo apt-get install \ libedit-dev \ libmatio-dev \ libpython-dev \ python-numpy</code> </pre> <br><p>  Put, suddenly missed.  No wonder with such a "simple" instruction from the developers.  Check that we have numpy for ALL python versions. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/fblualib/fblualib cmake -fpic -shared configure . make sudo make install</code> </pre> <br><p>  And again a lot of mistakes.  And why?  Yes, because someone did not edit the function calls in rocks-packages.  So, rule calls hands.  We just wrote instructions for Lua version below 5.2, and we already have 5.2, and there‚Äôs no point in looking for the old version you need.  Easier to fix the call functions. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/fblualib/fblualib/python luarocks make rockspec/*</code> </pre> <br><p>  Will give an error when compiling the type "underdefined".  It's simple.  In the file with the error, we correct the definition of the type luaL_reg to luaL_Reg (WHY change the call, I do not know!) </p><br><p>  Files with an error will be two.  Edits should be made on lines 191 and 341 in two files that will be in the error message. </p><br><p>  Corrected call - tried.  Compiled?  You can rejoice. </p><br><p>  In principle, after these manipulations, it would be possible to simply call <code>./build.sh</code> again from <code>~/fblualib/fblualib</code> <code>./build.sh</code> , but this is already a matter of taste - with more reliable hands. </p><br><p>  We continue the torment: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/coco luarocks make LuaAPI/rocks/coco-scm-1.rockspec <span class="hljs-comment"><span class="hljs-comment">#      sudo pip install Cython cd PythonAPI make sudo make install</span></span></code> </pre> <br><h3>  Run the construction of SharpMask for the trained neural network </h3><br><p>  In theory, we have already reached the bottom, in the sense - we reached the end of the installation instructions.  Remained the most enjoyable part.  By the way, the process of creating SharpMask has just ended. </p><br><pre> <code class="bash hljs">th train.lua -dm exps/deepmask/exp\,maxepoch\=2\,nthreads\=4/ -maxepoch 2 -nthreads 4 Found Environment variable CUDNN_PATH = /home/ubuntu/cuda/lib64/libcudnn.so.5gSz 160 112 nthreads 4 2 -- ignore option gpu -- ignore option reload maxepoch 2 300 -- ignore option datadir -- ignore option dm hfreq 0 0.5 -- ignore option rundir | running <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> directory /home/ubuntu/deepmask/exps/sharpmask/exp,gSz=160,hfreq=0,maxepoch=2,nthreads=4 | number of paramaters net h: 1090466 | number of paramaters net v: 1660050 | number of paramaters total: 2750516 | start training [train] | epoch 00001 | s/batch 1.95 | loss: 0.16018 [train] | epoch 00002 | s/batch 1.95 | loss: 0.13267 [<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>] | epoch 00002 | IoU: mean 059.74 median 065.92 suc@.5 069.00 suc@.7 043.39 | bestmodel *</code> </pre> <br><p>  Quite good data for further work with models.     LUA_PATH /home//?.lua   .bashrc .         ,     multipathnet  deepmask/data   sharpmask/model.t7  deepmask/model.t7     . <br></p><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/deepmask mkdir data &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> data mkdir models &amp;&amp; mkdir proposals ln -s ~/deepmask/data ~/multipathnet/data <span class="hljs-comment"><span class="hljs-comment">#deepMask  sharpMask ‚Äî     , #     ln -s ~/deepmask/exps/deepmask/exp,maxepoch=2,nthreads=4/model.t7 ~/deepmask/data/models/deepmask.t7 ln -s ~/deepmask/exps/sharpmask/exp,gSz=160,hfreq=0,maxepoch=2,nthreads=4/model.t7 ~/deepmask/data/models/sharpmask.t7</span></span></code> </pre> <br><h3>    -    </h3><br><p>   fbcoco.lua   : </p><br><pre> <code class="lua hljs"><span class="hljs-built_in"><span class="hljs-built_in">require</span></span> <span class="hljs-string"><span class="hljs-string">'testCoco.init'</span></span> <span class="hljs-built_in"><span class="hljs-built_in">require</span></span> <span class="hljs-string"><span class="hljs-string">'Tester_FRCNN'</span></span></code> </pre> <br><p>       . </p><br><h3>  ! </h3><br><p>   ! </p><br><pre> <code class="bash hljs">th demo.lua -img data/test6.jpg</code> </pre> <br><div class="spoiler"> <b class="spoiler_title">  </b> <div class="spoiler_text"><pre> <code class="lua hljs">Found Environment variable CUDNN_PATH = /home/ubuntu/cuda/lib64/libcudnn.so<span class="hljs-number"><span class="hljs-number">.5</span></span>nn.Sequential { [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">6</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ParallelTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): NoBackprop: nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">3</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>x7, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>) without bias | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialMaxPooling(<span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) | (<span class="hljs-number"><span class="hljs-number">5</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">64</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">64</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | | } | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Identity | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">64</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">64</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | | } | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Identity | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | } | } | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">64</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">128</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | | } | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">64</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>x1, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) without bias | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">128</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">128</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | | } | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Identity | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | } | } | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">128</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">256</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | | } | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">128</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>x1, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) without bias | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">256</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">256</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | | } | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Identity | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | } | } | } `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Identity ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ROIPooling (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.Sequential { [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">256</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | } `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">256</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>x1, <span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) without bias ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU } (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | (<span class="hljs-number"><span class="hljs-number">2</span></span>): inn.ConstAffine | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU | (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.SpatialConvolution(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>x3, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) without bias | (<span class="hljs-number"><span class="hljs-number">5</span></span>): inn.ConstAffine | } `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Identity ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.CAddTable (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.ReLU } } (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.SpatialAveragePooling(<span class="hljs-number"><span class="hljs-number">7</span></span>x7, <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">512</span></span>) } (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.ConcatTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">81</span></span>) |`-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">81</span></span>) |`-&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">81</span></span>) |`-&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">81</span></span>) |`-&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">81</span></span>) |`-&gt; (<span class="hljs-number"><span class="hljs-number">6</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">81</span></span>) `-&gt; (<span class="hljs-number"><span class="hljs-number">7</span></span>): nn.Linear(<span class="hljs-number"><span class="hljs-number">512</span></span> -&gt; <span class="hljs-number"><span class="hljs-number">324</span></span>) ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } (<span class="hljs-number"><span class="hljs-number">5</span></span>): nn.ModeSwitch { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ConcatTable { | <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> | |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SelectTable(<span class="hljs-number"><span class="hljs-number">4</span></span>) | `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.SelectTable(<span class="hljs-number"><span class="hljs-number">7</span></span>) | ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> | } `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.ParallelTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SoftMax | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>) | } |`-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SoftMax | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>) | } |`-&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SoftMax | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>) | } |`-&gt; (<span class="hljs-number"><span class="hljs-number">4</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SoftMax | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>) | } |`-&gt; (<span class="hljs-number"><span class="hljs-number">5</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SoftMax | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>) | } |`-&gt; (<span class="hljs-number"><span class="hljs-number">6</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.SoftMax | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.View(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>) | } `-&gt; (<span class="hljs-number"><span class="hljs-number">7</span></span>): nn.Identity ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.ConcatTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Sequential { | [<span class="hljs-built_in"><span class="hljs-built_in">input</span></span> -&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">3</span></span>) -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>] | (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.NarrowTable | (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.JoinTable | (<span class="hljs-number"><span class="hljs-number">3</span></span>): nn.Mean | } `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.SelectTable(<span class="hljs-number"><span class="hljs-number">7</span></span>) ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } } ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } (<span class="hljs-number"><span class="hljs-number">6</span></span>): nn.ParallelTable { <span class="hljs-built_in"><span class="hljs-built_in">input</span></span> |`-&gt; (<span class="hljs-number"><span class="hljs-number">1</span></span>): nn.Identity `-&gt; (<span class="hljs-number"><span class="hljs-number">2</span></span>): nn.BBoxNorm ... -&gt; <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> } } { <span class="hljs-number"><span class="hljs-number">1</span></span> : { <span class="hljs-number"><span class="hljs-number">1</span></span> : CudaTensor - size: <span class="hljs-number"><span class="hljs-number">2</span></span>x81 <span class="hljs-number"><span class="hljs-number">2</span></span> : CudaTensor - size: <span class="hljs-number"><span class="hljs-number">2</span></span>x324 } } { <span class="hljs-number"><span class="hljs-number">1</span></span> : { <span class="hljs-number"><span class="hljs-number">1</span></span> : CudaTensor - size: <span class="hljs-number"><span class="hljs-number">2</span></span>x3x224x224 <span class="hljs-number"><span class="hljs-number">2</span></span> : CudaTensor - size: <span class="hljs-number"><span class="hljs-number">2</span></span>x5 } } { <span class="hljs-number"><span class="hljs-number">1</span></span> : <span class="hljs-number"><span class="hljs-number">0.17677669529664</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> : <span class="hljs-number"><span class="hljs-number">0.25</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> : <span class="hljs-number"><span class="hljs-number">0.35355339059327</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> : <span class="hljs-number"><span class="hljs-number">0.5</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span> : <span class="hljs-number"><span class="hljs-number">0.70710678118655</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span> : <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> : <span class="hljs-number"><span class="hljs-number">1.4142135623731</span></span> }</code> </pre> </div></div><br><pre> <code class="lua hljs"><span class="hljs-number"><span class="hljs-number">0.66218614578247</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span> dog | done</code> </pre> <br><img src="https://habrastorage.org/webt/wl/v3/sd/wlv3sd1sh7irichr6so6q46lhho.jpeg"><br><p> <em>,   !   .</em> </p><br><h2>     </h2><br><p>   !       .         (    ,      ), , ,                  . </p><br><p>     ,         ,      . </p><br><p>  :          ,            .           ,  , ,    .  ,  ,     . </p><br><p>              ,          -. </p><br><p>   ,        .     :      CUDA 9.1, cuDNN 7,                . ,        (,  inn, cunn, cudnn, cutorch  LuaRocks   ). </p><br><p>      ,      ,    ! </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/352068/">https://habr.com/ru/post/352068/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../352056/index.html">Why does the Heap32Next () function work so slowly on Windows 7?</a></li>
<li><a href="../352060/index.html">Accelerating the enumeration of processes and threads in Windows</a></li>
<li><a href="../352062/index.html">How to explain to relatives who you are in the IT world on the example of buns</a></li>
<li><a href="../352064/index.html">Bluebird: belt with tools for the asynchronist</a></li>
<li><a href="../352066/index.html">New solution for maintaining the availability of IT infrastructure: Veeam Availability Orchestrator</a></li>
<li><a href="../352070/index.html">Apache Ignite: in-memory distributed computing</a></li>
<li><a href="../352072/index.html">The end of procrastination or what is ICIGAI?</a></li>
<li><a href="../352074/index.html">A tale about how an HTTP / 2 Client engineer overclocked</a></li>
<li><a href="../352076/index.html">Immigration in Chile: finding a job and obtaining a residence permit</a></li>
<li><a href="../352078/index.html">How to make a report on the identified vulnerability</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>