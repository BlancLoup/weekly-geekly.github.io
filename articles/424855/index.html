<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Machine Learning: Room Elephant Fight</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="One is zero in favor of the human brain. In a new study , computer scientists have found that artificial intelligence systems fail to pass the test fo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Machine Learning: Room Elephant Fight</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/webt/z_/dt/lt/z_dtlta9hixvv2wmckf9fsaxzpo.jpeg"></div><br>  One is zero in favor of the human brain.  In a <a href="https://arxiv.org/abs/1808.03305">new study</a> , computer scientists have found that artificial intelligence systems fail to pass the test for visual recognition of objects that any child can easily cope with. <br><br>  ‚ÄúThis qualitative and important research reminds us that‚Äú deep learning ‚Äùcannot really boast of the depth attributed to it,‚Äù says Gary Marcus, a neuroscientist from New York University who is not associated with this work. <br><br>  The results of the study relate to the field of computer vision, when artificial intelligence systems are trying to detect and categorize objects.  For example, they may be asked to find all pedestrians in a street scene or simply to distinguish a bird from a bicycle ‚Äî an assignment that has already become famous for its complexity. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The stakes are high: computers are gradually beginning to perform important operations for people, such as automatic video surveillance and autonomous driving.  And for successful work it is necessary that the ability of AI to visual processing at least not inferior to human. <br><br>  The task is not easy. <a name="habracut"></a>  The new study focuses on the sophistication of human vision and the difficulties in creating systems that mimic it.  Scientists checked the accuracy of the computer vision system using the example of a living room.  The AI ‚Äã‚Äãdid well, correctly defining the chair, the person and the book on the shelf.  But when scientists added an unusual object to the scene - an image of an elephant - the very fact of its appearance made the system forget all previous results.  Suddenly, she began to call the chair a sofa, the elephant - a chair, and ignore all other objects. <br><br>  ‚ÄúThere were a variety of oddities showing the fragility of modern object detection systems,‚Äù says Amir Rosenfeld, a scientist at York University in Toronto, and co-author of a study that he conducted with colleagues <a href="http://www.cse.yorku.ca/~tsotsos/Tsotsos/Home.html">John Tsotsos</a> , also from York, and <a href="http://www.cs.toronto.edu/~zemel/inquiry/home.php">Richard Zemel</a> from the University of Toronto. <br><br>  Researchers are still trying to clarify the reasons why the computer vision system is so easily confused, and they already have a good guess.  The point is in human skill, which AI does not have, is the ability to realize that the scene is incomprehensible, and you need to look at it more closely again. <br><br><h3>  Elephant in the room </h3><br>  Looking at the world, we perceive a staggering amount of visual information.  The human brain processes it on the go.  ‚ÄúWe open our eyes, and everything happens by itself,‚Äù says Totsos. <br><br>  Artificial intelligence, on the contrary, painstakingly creates visual impressions, as if reading a description in Braille.  He runs his pixels on his algorithmic fingertips, gradually forming more and more complex representations out of them.  A variety of AI systems that performs such processes is neural networks.  They pass the image through a series of "layers".  As each layer passes, individual parts of the image are processed, such as the color and brightness of individual pixels, and based on this analysis, an increasingly abstract description of the object is formed. <br><br>  "The results of the processing of the previous layer are transmitted to the next, and so on, as in a conveyor," explains Tsotsos. <br><br><img src="https://habrastorage.org/webt/fs/y6/bk/fsy6bkburvogjselmt3vj45lwye.jpeg"><br>  <i>By Lucy Reading-Ikkanda / Quanta Magazine</i> <br><br>  Neural networks are experts in specific routine tasks in the field of visual processing.  They are better able to cope with highly specialized tasks such as determining the breed of dogs and other sorting of objects into categories better than people.  These successful examples gave rise to the hope that computer vision systems will soon become so clever that they will be able to drive a car in crowded city streets. <br><br>  It also prompted experts to explore their vulnerabilities.  Over the past few years, researchers have made a whole series of attempts to imitate hostile attacks ‚Äî they invented scenarios forcing neural networks to make mistakes.  In one experiment, computer scientists <a href="https://www.labsix.org/physical-objects-that-fool-neural-nets/">deceived the</a> network, forcing it to take a turtle for a gun.  Another success story was that next to ordinary objects like a banana, researchers <a href="https://arxiv.org/abs/1712.09665">placed a</a> psychedelic-colored toaster on the image. <br><br>  In the new work, scientists chose the same approach.  Three researchers showed a neural network a photograph of the living room.  It captures a man who plays a video game, sitting on the edge of an old chair and leaning forward.  Having ‚Äúdigested‚Äù this scene, the AI ‚Äã‚Äãquickly recognized several objects: a person, a sofa, a TV, a chair, and a couple of books. <br><br>  Then the researchers added an object unusual for such scenes: the image of an elephant in a semi-profile.  And the neural network is confused.  In some cases, the appearance of an elephant forced her to take a chair for a sofa, and sometimes the system stopped seeing certain objects, with the recognition of which there had been no problems before.  This is, for example, a book series.  And misses happened even with objects located far from the elephant. <br><br><img src="https://habrastorage.org/webt/j9/bv/bj/j9bvbj3ovfqo2utjxnif5roeinc.jpeg"><br>  <i>On the original left, the neural network correctly and with high confidence identified many of the objects located in the drawing room filled with various things.</i>  <i>But it was enough to add an elephant (image on the right), and the program began to fail.</i>  <i>The chair in the lower left corner turned into a sofa, the cup next to it disappeared, and the elephant became the chair.</i> <br><br>  Such system errors are completely unacceptable for the same autonomous driving.  The computer will not be able to drive a car if it does not notice pedestrians simply because a few seconds before that, he saw a turkey on the side of the road. <br><br>  As for the elephant itself, the results of its recognition also differed from the attempt to attempt.  The system then determined it correctly, then called it a sheep, then did not notice it at all. <br><br>  ‚ÄúIf an elephant really does appear in the room, anyone will probably notice it,‚Äù says Rosenfeld.  ‚ÄúAnd the system did not even record his presence.‚Äù <br><br><h3>  Close relationship </h3><br>  When people see something unexpected, they look at it better.  No matter how simple it sounds, ‚Äútake a closer look‚Äù, this has real cognitive consequences and explains why the AI ‚Äã‚Äãmakes mistakes when something unusual appears. <br><br>  The best modern neural networks in processing and recognizing objects pass information through themselves only in the forward direction.  They start by selecting pixels at the input, go to curves, shapes, and scenes, and make the most likely guesses at each stage.  Any misconceptions in the early stages of the process lead to errors at the end, when the neural network puts together its ‚Äúthoughts‚Äù to guess what it is looking at. <br><br>  ‚ÄúIn neural networks, all processes are closely interrelated with each other, so there is always a chance that any feature in any place can affect any possible result,‚Äù says Tsotsos. <br><br>  The human approach is better.  Imagine that you were given a glimpse of an image with a circle and a square, one red, the other blue.  After that, you were asked to name the color of the square.  One short glance may not be enough to memorize colors correctly.  Immediately comes the understanding that you are not sure, and you need to look again.  And, which is very important, during the second viewing you will already know what needs to be focused on. <br><br>  ‚ÄúThe human visual system says:‚Äú I can‚Äôt give the right answer yet, so I‚Äôll go back and check where the error could have happened, ‚Äùexplains Tsotsos, who develops a theory called‚Äú <a href="http://www.cse.yorku.ca/~tsotsos/Selective_Tuning/Selective_Tuning.html">Electoral Tuning</a> ‚Äùexplaining this feature of visual perception. <br><br>  Most neural networks lack the ability to go back.  This feature is very difficult to design.  One of the advantages of unidirectional networks is that it is relatively easy to train them - it is enough to ‚Äúskip‚Äù images through the above six layers and get a result.  But if neural networks should ‚Äúlook more closely‚Äù, they also need to distinguish between a fine line, when it is better to go back, and when to continue.  The human brain easily and naturally switches between so different processes.  And neural networks need a new theoretical base so that they can do the same. <br><br>  Leading researchers from around the world are working in this direction, but they also need help.  Recently, the Google AI project <a href="https://ai.googleblog.com/2018/09/introducing-unrestricted-adversarial.html">announced a</a> crowdsourcing <a href="https://ai.googleblog.com/2018/09/introducing-unrestricted-adversarial.html">competition</a> for image classifiers that can distinguish between cases of deliberate image distortion.  Wins the decision that can uniquely distinguish the image of a bird from the image of a bicycle.  This will be a modest, but very important first step. <br><br> <a href="https://wirexapp.com/ru/"><img src="https://habrastorage.org/files/4bd/bf6/597/4bdbf659775744b1bdbb4d8a00a0a980.png" alt="image"></a> </div><p>Source: <a href="https://habr.com/ru/post/424855/">https://habr.com/ru/post/424855/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../424845/index.html">We calculate the "magic squares" using the GPU</a></li>
<li><a href="../424847/index.html">MNaaS and eSIM - the pros and cons of virtualization for mobile operators and their customers</a></li>
<li><a href="../424849/index.html">What is interesting about the new UCS C480 ML M5 - a server for machine learning from Cisco?</a></li>
<li><a href="../424851/index.html">What is wrong with hiring in IT?</a></li>
<li><a href="../424853/index.html">The story of one controller view that wanted to show off beautifully</a></li>
<li><a href="../424857/index.html">CloudFlare has implemented support for Encrypted SNI</a></li>
<li><a href="../424859/index.html">Simplest Arduino Game with Display 1602 - Part # 1</a></li>
<li><a href="../424861/index.html">The snake in the mailbox and what's with F #</a></li>
<li><a href="../424865/index.html">Found elementary design particles</a></li>
<li><a href="../424867/index.html">Developing a hexapod from scratch (part 1) - designing</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>