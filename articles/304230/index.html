<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Game of Thrones. Search for dialog authors in books</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi Habrahabr, 

 Based on the result of the vote in the article Theory of Graphs in the Game of Thrones , I translate the teaching material of Erik Ge...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Game of Thrones. Search for dialog authors in books</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/63c/212/734/63c212734d4b484ca661f03554276207.jpg"><br><br>  Hi Habrahabr, <br><br>  Based on the result of the vote in the article <a href="https://habrahabr.ru/post/302936/">Theory of Graphs in the Game of Thrones</a> , I translate the teaching material of Erik Germani, who received a social link graph from the first 5 books of the Song of Ice and Flame series, which formed the basis of the above article.  The article does not contain a detailed description of machine learning methods, but rather describes how in practice existing tools can be used to search for authors of dialogues in the text.  Careful, many letters!  Go. <br><a name="habracut"></a><br>  This training material is aimed at newcomers to machine learning, such as myself, when I started this project a year ago.  (And I still am, although now I‚Äôm just green, not bright green in this topic.) We‚Äôll build a model that can tell who speaks the line of dialogue in the books of George R.R.  Martina "A Song of Ice and Flame".  For this, we will use the CRF conditional random field method ( <i>note from Conditional Random Fields</i> ) and the wonderful <a href="http://www.chokkan.org/software/crfsuite/">CRFsuite</a> utility from Naoaki Okazaki.  For text processing, we use Python 2.7 and NLTK (Natural Language Toolkit). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I will try to explain everything as detailed as possible.  I hope that when describing each step of my actions, you will be able to extract new tools and methods that will be useful in your own projects.  Explanations of the code will be from a beginner and for a beginner, one who understands the syntax of Python and knows about the abstraction of lists, but no more.  If you feel my code clarifications are draining your soul, skip them. <br><br>  <b>Important:</b> If you wanted to find here a theory about the method of conditional random fields, then this material is not for you.  For me, CRFsuite is a beautiful black box that I touch with my monkey paws.  We will spend some time improving the model‚Äôs performance, but this will prove to be an erroneous attempt.  If this upsets you, keep in mind: <br><ul><li>  I managed to achieve a good result (~ 75% accuracy) with CRFsuite out of the box <br></li><li>  There will be no LaTeX <br></li></ul><br>  Our game plan is simple.  As with any other algorithm for machine learning, we need to prepare data for training and verification.  Then we select the properties that the algorithm will use for classification.  After we process the text using these properties, we will feed the result to CRFsuite and congratulate ourselves on a job well done.  (or burden ourselves with the hard work of checking the guesses of the machine). <br><br>  Let's start. <br><br><h1>  Loading text </h1><br>  First of all, we need to find a copy of the source of the text and I will leave the choice to you, whether you will pay an iron price for it or not. <br><br>  If you are new to natural language processing, then perhaps you underestimate how difficult the source text may be.  Each .txt file has an encoding that determines how each character will be described.  ASCII, the format in which I read the passing game Ocarina of Time, was supplanted by UTF-8, which can handle all the special characters.  (ASCII can represent 128 characters.) My copy of the PLIP (approx. Song of Ice and Flame) is in UTF-8, which is a minor inconvenience, but is actually a bonus. <br><br>  We will load this text into the NLTK to more easily manipulate it.  NLTK can do a lot of tasks, and this is how I learned Python, if it turns out to be interesting for you, take a look at their excellent <a href="http://www.nltk.org/book/">online book</a> .  For our purposes, use this tool to break the text into tokens.  This implies the division of sentences into words and punctuation marks, which is often done in natural language processing projects. <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk nltk.word_tokenize(<span class="hljs-string"><span class="hljs-string">"NLTK is ready to go."</span></span>)</code> </pre> <pre>  ['NLTK', 'is', 'ready', 'to', 'go', '.'] </pre><br>  NLTK has preloaded chassis, but we need to load our own. <br><br>  Create a folder and paste the PLIP text files there.  Since the books are very large, the source text will be almost 10 MB.  Not ideal for search and replace text.  I divided the text into books, but real professionals, who are going to analyze more, would rather divide each book by chapters and enumerate them sequentially. <br>  But we will not complicate things now!  Once the text is in the folder, we can run the following: <br><pre> <code class="python hljs">corpus = nltk.corpus.PlaintextCorpusReader(<span class="hljs-string"><span class="hljs-string">r'corpus'</span></span>, <span class="hljs-string"><span class="hljs-string">'George.*\.txt'</span></span>, encoding = <span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>)</code> </pre> <br>  Here <i>r</i> indicates not to process the string.  Here it does not matter, tk.  I directly refer to the ‚Äúcorpus‚Äù folder, but if in your case the folder has a complex location, it is better not to forget about it. <br><br>  The second argument is a regular expression that tells NLTK to take all the files in the folder that have ‚ÄúGeorge‚Äù in their names and with the extension ‚Äú.txt‚Äù. <br><br>  The encoding parameter is very important - if the encoding of the text does not match the specified one, then errors will sprinkle. <br><br>  The body in NLTK is very useful, with it you can get information from the text at different levels. <br><pre> <code class="python hljs">corpus.words(<span class="hljs-string"><span class="hljs-string">"George RR Martin - 01 - A Game Of Thrones.txt"</span></span>)[<span class="hljs-number"><span class="hljs-number">-5</span></span>:]</code> </pre>  [u'the ', u'music', u'of ', u'dragons', u '.'] <br><pre> <code class="python hljs">corpus.words()[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre>  u'PROLOGUE ' <br><pre> <code class="python hljs">corpus.sents()[<span class="hljs-number"><span class="hljs-number">1</span></span>][:<span class="hljs-number"><span class="hljs-number">6</span></span>]</code> </pre> <pre>  [u '\ u201c', u'We ', u'should', u'start ', u'back', u ', \ u201d'] </pre><br>  Here we hear the doomed Gared from the Game of Thrones prologue and see some Unicode characters presented in Python.  You see that all Unicode strings begin with <i>u</i> , and contain special characters.  \ u201c is the left quote, \ u201d is the right quote.  I mentioned that UTF-8 is more of a bonus, and here's why.  Let's see what happens if we open the same file without specifying the encoding. <br><pre> <code class="python hljs">bad_corpus = nltk.corpus.PlaintextCorpusReader(<span class="hljs-string"><span class="hljs-string">r'corpus'</span></span>, <span class="hljs-string"><span class="hljs-string">'.*\.txt'</span></span>) bad_corpus.sents()[<span class="hljs-number"><span class="hljs-number">1</span></span>][:<span class="hljs-number"><span class="hljs-number">9</span></span>]</code> </pre> <pre>  ['\ xe2', '\ x80 \ x9c', 'We', 'should', 'start', 'back', ',', '\ xe2', '\ x80 \ x9d'] </pre><br>  Just like \ u points to a string in Unicode format, \ x points to a hexadecimal string, so NLTK gives us 3 hexadecimal bytes - \ xe2, \ x80, \ x9c - and tries to split them.  You can see that he does not know how to do it. <br><br>  We will work with paragraphs, so let's take a look at one of them: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> corpus.paras()[<span class="hljs-number"><span class="hljs-number">1</span></span>]</code> </pre> <pre>  [[u '\ u201c', u'We ', u'should', u'start ', u'back', u ', \ u201d', u'Gared ', u'urged', u'as', u'the ', u'woods', u'began', u'to ', u'grow', u'dark ', u'around', u'them ', u'. '], [u' \ u201c ', u'The', u'wildlings', u'are ', u'dead', u '. \ u201d']] </pre><br>  You may notice how NLTK structures data.  Offers are a list of tokens, and a paragraph is a list of offers.  Easy enough! <br><br><h1>  Tags </h1><br>  Next, we need to prepare data for training, but in order to do this, we need to decide on the labels that we will use.  When parsing text, the algorithm knows that each token belongs to a lexical category, each of which has its own label.  JJ is an adjective, NN is a noun, IN is a preposition.  These tags play a key role in the credibility of our model.  <a href="https://www.cis.upenn.edu/~treebank/">The Penn Treebank</a> ( <i>note the project on a text label</i> ) allocates 36 such tags. <br><br>  What are our labels?  The simplest option is the names of the characters.  This will not work for several reasons: <br><br><ol><li>  PLIP contains more than a thousand characters.  This is too much choice for our poor model.  We need to weed out as many tags as possible in order to properly classify relying on banal luck. <br></li><li>  To the characters are treated differently.  Joffrey can be either ‚ÄúJoffrey‚Äù or ‚ÄúJoff‚Äù, ‚ÄúPrince‚Äù or even just ‚Äúhe‚Äù. <br></li><li>  If we use the names of characters as labels, they must be defined in the training data.  Otherwise, our model will not be aware of their existence and therefore can not determine them. <br></li><li>  All characters sound just the same.  (I realized this from a different machine learning experience, where I tried to separate characters according to their vocabulary).  Some have some catchy phrases such as ‚Äúregrettable‚Äù ( <i>grievous note</i> ) for <i>Varys</i> and ‚ÄúHodor‚Äù for Hodor, but this is rare.  In addition, for many, there is not enough time for conversations to distinguish them from the rest. <br></li></ol><br><br>  Although the definition of the names of the characters sounds very tempting, let's discard this idea and think about the process that occurs in the head of the reader when solving a similar problem. <br><br>  Take the book closest to you, open a random page, and try to determine who is talking there.  How do you do this?  You look at the nearest proper names next to the dialogue. <br><br><blockquote>  "Will saw them," answered Gared. <br><br>  [...] <br><br>  Sir Weimar Royce looked at the sky without any interest.  ‚ÄúNight comes every day around the same time.  Does darkness really take away your courage, Gared? ‚Äù </blockquote><br>  Although not every line of the dialogue is marked.  Look further and see: <br><br><blockquote>  "Have you noticed the position of the bodies?" </blockquote><br>  You will look at the paragraphs above and below.  Here are 2 on top: <br><br><blockquote>  "And the weapon?" <br><br>  ‚ÄúSeveral swords and bows.  One had an ax, heavy like that, with two blades ... cruel iron.  He was lying on the ground near this man, right by the hand. ‚Äù </blockquote><br>  Not a drop of hint.  Two paragraphs below: <br><br><blockquote>  Will shrugged.  ‚ÄúOne sat near the rock.  The rest were on the ground, fell, or something. " <br><br>  "Or slept," suggested Royce. </blockquote><br>  We know that Will would not ask himself, so we can say that he is not the author of this speech, and since many dialogues stretch into several paragraphs, we will assume that Royce is the first line author. <br><br>  This scheme will help mark our model.  We will teach her to identify her own names next to the text, and if there are no such names, search in nearby paragraphs.  Then, our labels will be: <br><br>  PS ¬± 2, FN ¬± 2, NN ¬± 2, Other. <br><br>  PS - after speaking.  If the label of the paragraph is PS -2, then this will mean that the name, speaking part of the dialogue, is located two paragraphs above.  If FN is 1, then the first name is in the next paragraph.  NN 0 means at least 2 names precede the dialogue and we need the one closest to the dialogue. <br><br>  I will also define ADR ¬± 2 for characters addressed in the dialogue text. <br><br><h1>  Mark </h1><br>  Now we will prepare the training data.  SublimeText will help us in this.  I opened the text ‚ÄúGame of Thrones‚Äù, selected the left quote, chose Find -&gt; Quick Find All, and twice pressed the Home key.  Now the cursor is near the beginning of each paragraph with a dialogue.  Then I typed "{}".  Since  there are no curly braces in the text, then we can use them to leave notes that we will use in the future. <br><br>  We will use a regular expression (? &lt;= \ {) (? = \}) To jump around curly braces.  If you have not met with this design, they are called positive retrospective and advanced checks.  The first expression in parentheses will cause SublimeText to start highlighting the lines that have an opening brace (escaped with a backslash) at the beginning.  The following expression will say stop when there is a closing brace.  As you can see, both expressions consist of the construction? =, Only the first one also contains &lt;. <br><br>  Now you can go through the brackets by pressing F3, which is a hot key to search for the next in SublimeText under Windows.  This kind of optimization is important because  you will be tagging approximately thousands of dialogs.  At least I did so much.  It was not so hard and time consuming as I expected.  (Although maybe I'm lying, because I finished only a year later). <br><br>  Before you begin, I want to make one remark: think about whether you want to use positional labels (PS, FN, NN) or all the same names of characters.  I know that I have already said that we will not use names, but if you decide to use positional labels, then you associate this training data with the appropriate model.  If you mark John‚Äôs dialogs with the label ‚ÄúJon‚Äù, then in the future you will have the opportunity to change the label to the positional one, or use other labels if you find it better. <br><br>  I think that there is no definite answer.  Last year I tagged characters.  Now I need to make preliminary manipulations that add ambiguity.  If Eddard's name appears 2 paragraphs above and one paragraph below, which one to choose?  This will directly affect the behavior of the model and doing this automatically makes the process even more inaccurate.  Therefore, I am not sure what to advise.  It seems to me that from the point of view of a manual tag, it is easier to write the name of the character, but, from the point of view of automation, it is much more convenient to have positional tags. <br><br><h1>  Retrieving Properties </h1><br>  Well, you've tagged some text.  I applaud you for your commitment to natural language processing.  All we need to do now is to write several functions that will take a paragraph as an argument and mark them with properties that interest us. <br><br>  Remind what properties?  The workhorses responsible for the accuracy of the model are the following functions: whether they exist in the current or in the adjacent paragraphs PS, FN or NN. <br><br><h2>  Search for names </h2><br>  Our first function is to find proper names.  This can be done by defining parts of speech. <br><br><pre> <code class="python hljs">sentence = corpus.paras()[<span class="hljs-number"><span class="hljs-number">33</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">" "</span></span>.join(sentence) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> nltk.pos_tag(sentence)</code> </pre> <pre>  "Such eloquence, Gared," Ser Waymar observed.
 [(u '\ u201c', 'NN'), (u'Such ',' JJ '), (u'eloquence', 'NN'), (u ',', ','), (u'Gared ',' NNP '), (u', \ u201d ',' NNP '), (u'Ser', 'NNP'), (u'Waymar ',' NNP '), (u'observed', 'VBD '), (u'. ','. ')] </pre><br>  NPP near Ser and Waymar means that these are proper names.  But there are also disadvantages: <br><ol><li>  Errors happen.  Noticed how the closing quote became a proper name? <br></li><li>  Identifying parts of speech takes time. <br></li></ol><br><pre> <code class="python hljs">%timeit nltk.pos_tag(sentence)</code> </pre> <pre>  100 loops, best of 3: 8.93 ms per loop </pre><br><pre> <code class="python hljs">asoiaf_sentence_count = <span class="hljs-number"><span class="hljs-number">143669</span></span> ( asoiaf_sentence_count * <span class="hljs-number"><span class="hljs-number">19.2</span></span> ) / <span class="hljs-number"><span class="hljs-number">1000</span></span> / <span class="hljs-number"><span class="hljs-number">60</span></span></code> </pre> <pre>  45.974079999999994 </pre><br>  There are many paragraphs for processing in PLIP and more than 45 minutes to determine parts of speech will delay the process of testing and refactoring.  Of course, it would be possible to analyze everything once and continue to work with what happened.  But for this, we would have to deal with another data structure, and such a definition would have to be redone every time the source text changes.  (And this is inevitable.) <br><br>  Fortunately, it is not necessary to contact parts of speech to determine the names of the characters.  This is one of the advantages of choosing a PLIP for analysis: there are tons of data that have already been received.  Let's scrape some of them. <br><br><h2>  Existing Information </h2><br>  It was a very useful Wiki Song of Ice and Flame, I received an almost exhaustive list of character names by literally copying a page with a <a href="http://awoiaf.westeros.org/index.php/List_of_characters">list of heroes</a> .  The result can be found <a href="http://atseajournal.com/resources/asoiaf_name_particles.txt">here</a> .  If this is enough for you, then we will meet in the <a href="https://habr.com/ru/post/304230/">next chapter of the article</a> .  For those who are interested in how you can automatically extract data from the page, I will give a couple of ways that I used in other projects. <br><br><h3>  Wget </h3><br>  <a href="http://www.delorie.com/gnu/docs/wget/wget_toc.html">Excellent utility</a> that is very simple if you need to go through previously known links.  You do not have to think about how to bypass links, you just need to create a file with a list and pass it using the <i>-i</i> flag, like this: <br><pre> <code class="bash hljs">wget -i list_of_links.txt</code> </pre> <br><h3>  Requests </h3><br>  Python has a library of <a href="http://docs.python-requests.org/en/latest/">requests</a> , which is well suited for working with individual pages. <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests r = requests.get(<span class="hljs-string"><span class="hljs-string">"http://awoiaf.westeros.org/index.php/List_of_characters"</span></span>) html = r.text <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> html[:<span class="hljs-number"><span class="hljs-number">100</span></span>]</code> </pre> <pre>  &lt;! DOCTYPE html&gt;
 &lt;html lang = "en" dir = "ltr" class = "client-nojs"&gt;
 &lt;head&gt;
 &lt;meta charset = "UTF-8" /&gt;
 &lt;title </pre><br><h2>  Parsing </h2><br>  After downloading the html, we need to peel off the page from the extra tags to get to the links.  <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> is an HTML parser that allows you to get links without any fuss.  After installation and parsing, you can find all the links by simply running: <br><pre> <code class="python hljs">parsed_html.find_all(<span class="hljs-string"><span class="hljs-string">"a"</span></span>)</code> </pre> <br>  <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">Here you can read more about it</a> . <br><br>  I would like to tell about one more method in which the <a href="http://lxml.de/lxmlhtml.html">lxml</a> library is <a href="http://lxml.de/lxmlhtml.html">used</a> .  With this library you can work with Xpath.  I'm new to Xpath, but this is a powerful way to move through a tree structure. <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lxml.html tree = lxml.html.fromstring(html) character_names = tree.xpath(<span class="hljs-string"><span class="hljs-string">"//ul/li/a[1]/@title"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> character_names[:<span class="hljs-number"><span class="hljs-number">5</span></span>]</code> </pre> <pre>  ['Abelar Hightower', 'Addam', 'Addam Frey', 'Addam Marbrand', 'Addam Osgrey'] </pre><br>  If you look askance at the Xpath expression from above, this is what it does: <br><pre> <code class="python hljs">tree.xpath(<span class="hljs-string"><span class="hljs-string">"//ul        #                 /li        #               /a[1]      #     .            /@title    #   title          "</span></span>)</code> </pre> <br>  Now, you need to select names among the result and delete what has nothing to do with the name.  Just running through the PLIP page, I noticed elements of the form "Taena of Myr".  We do not want our model to associate the dialogues with the ‚Äúof‚Äù particle. <br><br>  NLTK will help with this.  It has a body of text with ‚Äúbad‚Äù words - stopwords.  Those that occur so often that they do not make any sense to characterize the text. <br><pre> <code class="python hljs">particles = <span class="hljs-string"><span class="hljs-string">' '</span></span>.join(character_names).split(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> len(set(particles)) stopwords = nltk.corpus.stopwords.words(<span class="hljs-string"><span class="hljs-string">'english'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> stopwords[:<span class="hljs-number"><span class="hljs-number">5</span></span>] particles = set(particles) - set(stopwords) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> len(particles) <span class="hljs-comment"><span class="hljs-comment">#     . .. Aegon I   ,   #  I    .    . "I" in particles</span></span></code> </pre> <pre>  2167
 ['i', 'me', 'my', 'myself', 'we']
 2146
 True </pre><br>  And at the end you need to add some more, perhaps, missed nicknames, such as Deni, Black Fish or Joff.  If you are satisfied with the list of names, then save it in a file for future use. <br><br><h2>  Search for names.  Part 2 </h2><a name="finding_names_part_2"></a><br>  We abandoned the idea of ‚Äã‚Äãsearching for names using parts of speech and got a list of names.  We will extract the token sequences and see if we can find them in our list of names.  Finally it is time to write the code. <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> operator <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itemgetter particles = [particle.rstrip(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> particle <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> open(<span class="hljs-string"><span class="hljs-string">'asoiaf_name_particles.txt'</span></span>)] tokens = [<span class="hljs-string"><span class="hljs-string">u'\u201c'</span></span>, <span class="hljs-string"><span class="hljs-string">u'Such'</span></span>, <span class="hljs-string"><span class="hljs-string">u'eloquence'</span></span>, <span class="hljs-string"><span class="hljs-string">u','</span></span>, <span class="hljs-string"><span class="hljs-string">u'Gared'</span></span>, <span class="hljs-string"><span class="hljs-string">u',\u201d'</span></span>, <span class="hljs-string"><span class="hljs-string">u'Ser'</span></span>, <span class="hljs-string"><span class="hljs-string">u'Waymar'</span></span>, <span class="hljs-string"><span class="hljs-string">u'observed'</span></span>, <span class="hljs-string"><span class="hljs-string">u'.'</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">roll_call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(tokens, particles)</span></span></span><span class="hljs-function">:</span></span>   speakers = {}   particle_indices = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i, w) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tokens) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> particles]   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k, g <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> itertools.groupby(enumerate(particle_indices), <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> (i,x): ix):       index_run = map(itemgetter(<span class="hljs-number"><span class="hljs-number">1</span></span>), g)       speaker_name = <span class="hljs-string"><span class="hljs-string">' '</span></span>.join(tokens[i] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> index_run)       speakers[min(index_run)] = speaker_name   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> speakers</code> </pre> <br>  This function uses lambda expressions that I could not use last year when I did this project.  The script that I used then is so terrible and we don‚Äôt read that I did not dare to publish it.  In addition, I think that in this script, beginners can learn something new, so a little more about it. <br><br>  <a href="https://docs.python.org/2/library/itertools.html">Itertools</a> is a <a href="https://docs.python.org/2/library/itertools.html">worthwhile</a> tool.  I often use it to get rid of nesting or for permutations.  We need the <i>groupby</i> function in <i>it</i> .  Due to the release of the new version of this function at the time of writing the material, I completely preferred <i>groupby</i> , rather than dropwhile and takewhile, which I used in a recursive manner. <br><br>  When programming, I thought that the <i>roll_call</i> function should know the position of the names that it found.  So I decided to keep all the serial numbers of the names.  This can be seen in the 3rd line of the function code. <br><br><pre> <code class="python hljs">particle_indices = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i, w) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tokens) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> particles]</code> </pre> <br>  Enumerate helped me a lot when I got acquainted with Python.  It takes a list and for each element returns a bunch of the sequence number and the element itself. <br><br>  The 4th line is the trickiest part of the code in all the material and I did not write it.  <a href="https://docs.python.org/2.6/library/itertools.html">It is taken directly from the library documentation</a> . <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k, g <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> itertools.groupby(enumerate(particle_indices), <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> (i,x): ix):</code> </pre> <br>  Groupby goes through the list and groups the elements depending on the result of the lambda function.  Lambda - anonymous functions.  Unlike roll_call, they do not need to be predefined.  This is only part of the code that takes arguments and returns a value.  In our case, it simply subtracts the number from the sequence number. <br><br>  Let's take a look at how this works. <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> tokens particle_indices = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i, w) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tokens) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> particles] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> particle_indices <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> index, location <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(particle_indices):   lambda_function = index-location   <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">"{} - {} = {}"</span></span>.format(index, location, lambda_function)</code> </pre> <pre>  [u '\ u201c', u'Such ', u'eloquence', u ',', u'Gared ', u', \ u201d ', u'Ser', u'Waymar ', u'observed', u '.']
 [4, 6, 7]
 0 - 4 = -4
 1 - 6 = -5
 2 - 7 = -5 </pre><br>  This is the trick with <i>groupby</i> : the indexes are numbered sequentially, so if the items in the list also follow each other, then the result of the lambda will be the same for them. <br><br>  <i>groupby</i> sees -4 and assigns the value 4 to the group.  The 6th and 7th elements both have -5 and are grouped accordingly. <br><br>  Now we know where the compound names are and should use them.  What does <i>groupby</i> return?  The key is the result of our lambda, and the group itself, the <i>grouper</i> object.  Next, we use the <i>map</i> function to apply <i>itemgetter (1)</i> , which extracts an element from the bundle, to all elements of the group and in this way we will create a list of the name positions in the initial list of tokens. <br><br>  After <i>groupby,</i> we just need to extract the found names and store them in the associative array of <i>speakers</i> . <br><pre> <code class="python hljs">roll_call(tokens, particles)</code> </pre> <pre>  {4: u'Gared ', 6: u'Ser Waymar'} </pre><br><h2>  Optimization </h2><br>  Let's compare the speed of this function with the method in which we used parts of speech. <br><br><pre> <code class="hljs matlab"><span class="hljs-comment"><span class="hljs-comment">%timeit roll_call(tokens, particles)</span></span></code> </pre> <pre>  100 loops, best of 3: 3.85 ms per loop </pre><br>  Not bad, 5-6 times faster.  But we can improve the result using <i>set</i> .  Set <i>sets</i> almost instantly check if an item is in the list. <br><pre> <code class="python hljs">set_of_particles = set(particle.rstrip(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> particle <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> open(<span class="hljs-string"><span class="hljs-string">'asoiaf_name_particles.txt'</span></span>)) %timeit roll_call(tokens, set_of_particles)</code> </pre> <pre>  10,000 loops, best of 3: 22.6 ¬µs per loop </pre><br>  You understand that they are good when you see Greek letters in speed. <br><br><h2>  Name search regarding conversations </h2><br>  Now we need to write a program that will call the above function in the right places, so that we can find the names of the characters before, in and after the text of the dialogues.  We will collect all this into a class that will be able to collect a complete list of the positions of character names for us, which we will pass on to another algorithm to extract the properties and then to CRFsuite. <br><br>  But first, I would like to put our data in order. <br><br><h3>  XML parser </h3><br>  After a successful single-line command with Xpath, I decided to write an XML parser for our text files.  There is a ton of meaning in choosing this format.  A PLIP is a set of books in which there are chapters, which in turn consist of paragraphs, and some of them contain dialogues - and we need to mark them unnoticed.  If I hadn‚Äôt translated the text to XML (and at first I didn‚Äôt do it), the tags would have littered the text itself. <br><br>  I prefer to keep silent about the script below: it reminds me of my first steps in Python, huge functions, crutches, and variables with long names. <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lxml <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> etree <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> codecs <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ASOIAFtoXML</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#   input           . root = etree.Element("root") for item in input:   title = item["title"]   current_book = etree.Element("book", title=item["title"])   root.append(current_book)   with codecs.open(item["contents"], "r", encoding="utf-8") as book_file:       #  ,      .       current_chapter = etree.Element("chapter", title="Debug")       for paragraph in book_file:           paragraph = paragraph.strip()           if paragraph != "":               title_match = re.match("\A[AZ\W ]+\Z", paragraph)               if title_match:                   current_chapter = etree.Element("chapter", title=title_match.group())                   current_book.append(current_chapter)               else:                   current_graf = etree.SubElement(current_chapter, "paragraph")                   while paragraph != "":                       current_dialogue = current_graf.xpath('./dialogue[last()]')                       speaker_match = re.search("(\{(.*?)\} )", paragraph)                       if speaker_match:                           speaker_tag = speaker_match.group(1)                           speaker_name = speaker_match.group(2)                           paragraph = paragraph.replace(speaker_tag, "")                       open_quote = paragraph.find(u"\u201c")                       if open_quote == -1:                           if current_dialogue:                               current_dialogue[0].tail = paragraph                           else:                               current_graf.text = paragraph                           paragraph = ""                       elif open_quote == 0:                           current_dialogue = etree.SubElement(current_graf, "dialogue")                           if speaker_name:                               current_dialogue.attrib["speaker"] = speaker_name                           close_quote = paragraph.find(u"\u201d") + 1                           if close_quote == 0:                               #  find  -1   ,    0                               #        .                                 #      .                               close_quote = len(paragraph)                           current_dialogue.text = paragraph[open_quote: close_quote]                           paragraph = paragraph[close_quote:]                       else:                           if current_dialogue:                               current_dialogue[0].tail = paragraph[:open_quote]                           else:                               current_graf.text = paragraph[:open_quote]                           paragraph = paragraph[open_quote:]   return root tree = ASOIAFtoXML([{"title": "AGOT", "contents": "corpus/train_asoiaf_tagged.txt"}]) #      . # et = etree.ElementTree(tree) # et.write(codecs.open("asoiaf.xml", "w", encoding="utf-8"), pretty_print=True)</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The essence of the code is above: we use lxml to create a tree, then line by line go over the text. If the string is recognized as a chapter name (capital letters, punctuation, and spaces), we add a new chapter to the top of the current book. As soon as we are in the text of the chapter, we make our way through the paragraphs, using another regular expression to determine who spoke the dialogue and add it to the appropriate vertex of the dialogue. They should already be pre-marked, of course. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An interesting note on XML. This is a hierarchical structure, so it by its nature requires strict branching, apex at the top. But it is not so in prose. In prose, the dialogues are inside the text. lxml provides a solution: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">text</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tail</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Thus, the XML vertex stores text, but this text is interrupted after another vertex has been added.</font></font><br><pre> <code class="hljs vhdl">markup = '''&lt;paragraph&gt;Worse <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> worse, Catelyn thought <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> despair. My brother <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a fool. Unbidden, unwanted, tears filled her eyes. &lt;dialogue speaker=<span class="hljs-string"><span class="hljs-string">"Catelyn Stark"</span></span>&gt; ‚Äú<span class="hljs-keyword"><span class="hljs-keyword">If</span></span> this was an escape,‚Äù&lt;/dialogue&gt; she said softly, &lt;dialogue speaker=<span class="hljs-string"><span class="hljs-string">"Catelyn Stark"</span></span>&gt;‚Äú<span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> an exchange <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> hostages, why should the Lannisters give my daughters <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> Brienne?‚Äù&lt;/dialogue&gt;&lt;/paragraph&gt;''' graf = lxml.etree.fromstring(markup) print graf.<span class="hljs-literal"><span class="hljs-literal">text</span></span></code> </pre> <pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Worse and worse, Catelyn thought in despair. </font><font style="vertical-align: inherit;">My brother is a fool.</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unbidden, unwanted, tears filled her eyes. </font></font></pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> graf[<span class="hljs-number"><span class="hljs-number">0</span></span>].text</code> </pre> <pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "If this was an escape," </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What happens to the remaining ‚Äúshe said softly‚Äù? </font><font style="vertical-align: inherit;">We will save in the variable vertices of </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tail</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> graf[<span class="hljs-number"><span class="hljs-number">0</span></span>].tail</code> </pre> <pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> she said softly, </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And so on, adding to each vertex of the dialogue the rest of the text. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As a result, this greatly simplifies our search for the authors of the dialogues when we need them. </font><font style="vertical-align: inherit;">And we need them right now!</font></font><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">feature_extractor_simple</span></span></span><span class="hljs-class">:</span></span>   <span class="hljs-string"><span class="hljs-string">"""Analyze dialogue features of a paragraph. Paragraph should be an lxml node."""</span></span>   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, paragraph_node, particles, tag_distance=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>       self.paragraph = paragraph_node       self.particles = set(particles)       self.tag_distance = tag_distance       self.raw = <span class="hljs-string"><span class="hljs-string">''</span></span>.join(t <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.paragraph.itertext())       self.tokens = self.tokenize(self.raw)   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">tokenize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, string)</span></span></span><span class="hljs-function">:</span></span>       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nltk.wordpunct_tokenize(string)   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">find_speakers</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, tokens)</span></span></span><span class="hljs-function">:</span></span>       speakers = {}       particle_indices = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i, w) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(tokens) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.particles]       <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k, g <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> itertools.groupby(enumerate(particle_indices), <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> (i,x): ix):           index_run = map(itemgetter(<span class="hljs-number"><span class="hljs-number">1</span></span>), g)           speaker_name = <span class="hljs-string"><span class="hljs-string">' '</span></span>.join(tokens[i] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> index_run)           speakers[min(index_run)] = speaker_name       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> speakers   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pre_speak</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, prior_tag=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"FN"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, near_tag=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"NN"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>       <span class="hljs-comment"><span class="hljs-comment">#   .       features = {}       if self.paragraph.text is not None:           speakers = self.find_speakers(self.tokenize(self.paragraph.text))           if len(speakers) &gt; 0:               features.update({"{} {}".format(prior_tag,self.tag_distance): speakers.values()[0]})           if len(speakers) &gt; 1:               features.update({"{} {}".format(near_tag,self.tag_distance): speakers[max(speakers.keys())]})       return features   def dur_speak(self, tag="ADR"):       #  .       features = {}       for dialogue in self.paragraph.itertext("dialogue", with_tail=False):           tokens = self.tokenize(dialogue)           named = self.find_speakers(tokens)           addressed = {k: v for (k, v) in named.items() if tokens[k-1] == "," or tokens[k + 1 + v.count(" ")].startswith(",")}           if len(addressed) &gt; 0:               features.update({"{} {}".format(tag, self.tag_distance): addressed[max(addressed.keys())]})       return features   def post_speak(self, tag="PS"):       features = {}       #   .       tails = [line.tail for line in self.paragraph.iterfind("dialogue") if line.tail is not None]       for tail in tails:           tokens = self.tokenize(tail)           speakers = {k: v for (k, v) in self.find_speakers(tokens).items() if k &lt;= 1}           if len(speakers) &gt; 0:               features.update({"{} {}".format(tag, self.tag_distance): speakers[min(speakers.keys())]})               break       return features</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A few words about these features. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you're new to Python, then don't be afraid of classes. </font><font style="vertical-align: inherit;">You just need to write ordinary functions, passing them </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">self</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> as an argument </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">This will allow Python to know which object the function is currently working with. </font><font style="vertical-align: inherit;">Class is like a clone factory, and the object is a clone. </font><font style="vertical-align: inherit;">All clones have the same DNA, these are methods and variables, but because of their life experience, their personalities differ, which in this context is the data transmitted to them. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classes also have a special function </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">__init__</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which allows you to initialize object variables.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now you can relax, because </font><font style="vertical-align: inherit;">your data is in the hands of a specialized class. </font><font style="vertical-align: inherit;">And once you have abstracted his behavior, you can get the information he processed by clicking on his finger.</font></font><br><pre> <code class="python hljs">paragraph = tree.xpath(<span class="hljs-string"><span class="hljs-string">".//paragraph"</span></span>)[<span class="hljs-number"><span class="hljs-number">32</span></span>] example_extractor = feature_extractor_simple(paragraph, particles) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> example_extractor.raw <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> example_extractor.pre_speak() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> example_extractor.dur_speak() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> example_extractor.post_speak()</code> </pre> <pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Such eloquence, Gared," Ser Waymar observed. </font><font style="vertical-align: inherit;">"I never suspected you had it in you."
</font></font> {}<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{'ADR 0': u'Gared '}</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{'PS 0': 'Ser Waymar'} </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you are confused by the work of some functions, I will briefly explain what they are doing. </font><font style="vertical-align: inherit;">If everything from above looks acceptable to you, then you know what to do, see you in the next chapter. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Awkward manipulation of the associative array occurs here, and this is because they are not ordered in Python. </font><font style="vertical-align: inherit;">It reminds me of a feeling when leaving your home you feel that there are no keys in your pocket, locking the door. </font><font style="vertical-align: inherit;">I had to constantly check whether we get the first or last character, depending on the case, I look at the value of the keys and select the minimum / maximum.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pre_speak </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As I said above, the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">text</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> attribute </font><font style="vertical-align: inherit;">contains all the text up to the first line of the dialog. </font><font style="vertical-align: inherit;">We just need to find the names of the characters in it.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dur_speak </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In the case when the name is in the body of the dialogue, which may consist of multiple lines, we need to run through them all: </font></font><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> dialogue <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.paragraph.itertext(<span class="hljs-string"><span class="hljs-string">"dialogue"</span></span>, with_tail=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">itertext</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> function </font><font style="vertical-align: inherit;">in </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lxml</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> allows you to get all the vertex text. </font><font style="vertical-align: inherit;">We also set the flag </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">with_tail = False</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to search for only vertices without a ‚Äútail‚Äù, which means only the text of the dialog. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Once we find the names of the characters, we need to select in them only those that are separated by a comma, which will allow us to find the appeal. </font><font style="vertical-align: inherit;">(for example, ‚ÄúNed, promise me.‚Äù / ‚ÄúPromise me, Ned.‚Äù) In </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">my heart I feel that the last name found in the dialogue will most likely answer in the next paragraph, so we will rewrite the addressee with the last mentioned name.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> post_speak </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For this function, we need only the first character after the dialogue. </font><font style="vertical-align: inherit;">Therefore, we interrupt the cycle as soon as we find one. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The function looks in the first 2 tokens after the closing quotation mark. </font><font style="vertical-align: inherit;">So you will find dialogs like:</font></font><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "Goodbye," said John. </font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tip for novice programmers: you can call the fetch function when building a list. </font></font><br><pre> <code class="python hljs">tails = [line.tail <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.paragraph.iterfind(<span class="hljs-string"><span class="hljs-string">"dialogue"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line.tail <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This allowed to get the dialogues in one line. </font><font style="vertical-align: inherit;">(you just need to specify a condition to remove all results without a ‚Äútail‚Äù)</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CRFsuite </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perhaps this is the most curious part for you. </font><font style="vertical-align: inherit;">It contains conditionally random fields, whatever they might mean, and is launched from the command line, but you can‚Äôt see how it works from the inside. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But in fact, CRFsuite is a very simple and interesting part of all this. </font><font style="vertical-align: inherit;">While writing material, I discovered that he has a library for Python, but now we will not complicate everything and will use the executable file using the command line. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(I plan to update the model when the next book, Winds of Winter, will see the light. But I have a couple more years until it happens) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">All that is needed is a CRFsuite text with some tab-separated properties, like these for example:</font></font><br><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> FN 0 Graf Sent Len = 4 FN 1 = True FN -2 = True FN 0 = True NN 1 = True </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is the format for the training data. </font><font style="vertical-align: inherit;">The first attribute is the correct answer. </font><font style="vertical-align: inherit;">All subsequent properties. </font><font style="vertical-align: inherit;">They may look like you want, but do not use a colon ‚Äî this is for weighted properties, and therefore may lead to a false interpretation. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You need to open a command prompt where crfsuite.exe is located and type the following there:</font></font><br><pre> <code class="bash hljs">crfsuite learn -m asoiaf.model train.txt</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This will create a model that is the brain of everything. </font><font style="vertical-align: inherit;">You can call it whatever you like, I called my asoiaf. </font><font style="vertical-align: inherit;">To look at the accuracy of the model, type this:</font></font><br><pre> <code class="bash hljs">crfsuite tag -qt -m asoiaf.model test.txt</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> To actually run the model for tagging type </font></font><br><pre> <code class="bash hljs">crfsuite tag -m asoiaf.model untagged.txt</code> </pre><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untagged.txt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> should look the same as </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">train.txt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , but without the attribute of the correct answer at the beginning, i.e. </font><font style="vertical-align: inherit;">approximately like this:</font></font><br><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> NN -1 = True FN 0 = True FN 2 = True FN -1 = True NN 0 = True </font></font></pre><br> <a href="http://www.chokkan.org/software/crfsuite/tutorial.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> you can learn more about it. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's play now with a variety of properties that can improve the accuracy of the model. </font><font style="vertical-align: inherit;">We start with the simplest: with boolean values ‚Äã‚Äãthat determine the location of the positional labels in and near the paragraph. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And again our class for extracting properties, only now with a few new features at the beginning.</font></font><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">feature_extractor</span></span></span><span class="hljs-class">:</span></span>   <span class="hljs-string"><span class="hljs-string">"""Analyze dialogue features of a paragraph. Paragraph should be an lxml node."""</span></span>   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, paragraph_node, particles, tag_distance=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>       self.paragraph = paragraph_node       self.particles = set(particles)       self.tag_distance = tag_distance       self.raw = <span class="hljs-string"><span class="hljs-string">''</span></span>.join(t <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.paragraph.itertext())       self.tokens = self.tokenize(self.raw)       self.speaker = self.xpath_find_speaker()   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span>       features = {}       features.update(self.pre_speak())       features.update(self.dur_speak())       features.update(self.post_speak())       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> features   <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">local_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span>       <span class="hljs-comment"><span class="hljs-comment">#               features = []       if self.tokens.count(u"\u201c") == 0:           features.append("NoQuotes=True")       prior = self.paragraph.getprevious()       try:           last_dialogue = list(prior.itertext("dialogue", with_tail=False))[-1].lower()           hits = [w for w in ['who', 'you', 'name', '?'] if w in last_dialogue]           if len(hits) &gt; 2:               features.append("Who Are You?=True:10.0")       except (AttributeError, IndexError):           pass       try:           dialogue = list(self.paragraph.itertext("dialogue", with_tail=False))[0].lower()           for token in ['name', 'i am', u'i\u2019m']:               if token in dialogue:                   features.append("My Name=True:10.0")                   break       except (AttributeError, IndexError):           pass       if self.tokens[0] in self.particles:           features.append("FirstSpeakerIndex0=True")       if self.paragraph.text is not None:           name_precount = len(self.find_speakers(self.tokenize(self.paragraph.text)))           if name_precount &gt; 2:               features.append("Many Names Before=True")           conjunctions = set([w.lower() for w in self.tokenize(self.paragraph.text)]).intersection(set(['and', 'but', 'while', 'then']))           if len(conjunctions) &gt; 0 and self.paragraph.find("dialogue") is not None:               features.append("Conjunction in Head=True")       short_threshold = 10       if len(self.tokens) &lt;= short_threshold:           features.append("Short Graf=True")       dialogue_length = sum(map(len, self.paragraph.xpath(".//dialogue/text()")))       dialogue_ratio = dialogue_length / len(self.raw)       if dialogue_ratio == 1:           features.append("All Talk=True")       elif dialogue_ratio &gt;= 0.7:           features.append("Mostly Talk=True")       elif dialogue_ratio &lt; 0.3 and not self.tokens &lt; short_threshold:           features.append("Little Talk=True")       return features   def feature_booleans(self):       bool_features = []       for tag in ["PS", "FN", "NN", "ADR", ]:           label = "{} {}".format(tag, self.tag_distance)           if label in self.features().keys():               bool_features.append("{}=True".format(label))           else:               bool_features.append("{}=False".format(label))       return bool_features   def tokenize(self, string):       return nltk.wordpunct_tokenize(string)   def find_speakers(self, tokens):       speakers = {}       particle_indices = [i for (i, w) in enumerate(tokens) if w in self.particles]       for k, g in itertools.groupby(enumerate(particle_indices), lambda (i,x): ix):           index_run = map(itemgetter(1), g)           speaker_name = ' '.join(tokens[i] for i in index_run)           speakers[min(index_run)] = speaker_name       return speakers   def xpath_find_speaker(self):       speakers = self.paragraph.xpath(".//@speaker")       if speakers == []:           return "NULL"       else:           return speakers[0]   def pre_speak(self, prior_tag="FN", near_tag="NN"):       #          features = {}       if self.paragraph.text is not None:           speakers = self.find_speakers(self.tokenize(self.paragraph.text))           if len(speakers) &gt; 0:               features.update({"{} {}".format(prior_tag,self.tag_distance): speakers.values()[0]})           if len(speakers) &gt; 1:               features.update({"{} {}".format(near_tag,self.tag_distance): speakers[max(speakers.keys())]})       return features   def dur_speak(self, tag="ADR"):       #          features = {}       for dialogue in self.paragraph.itertext("dialogue", with_tail=False):           tokens = self.tokenize(dialogue)           named = self.find_speakers(tokens)           addressed = {k: v for (k, v) in named.items() if tokens[k-1] == "," or tokens[k + 1 + v.count(" ")].startswith(",")}           if len(addressed) &gt; 0:               features.update({"{} {}".format(tag, self.tag_distance): addressed[max(addressed.keys())]})       return features   def post_speak(self, tag="PS"):       features = {}       #          tails = [line.tail for line in self.paragraph.iterfind("dialogue") if line.tail is not None]       for tail in tails:           tokens = self.tokenize(tail)           speakers = {k: v for (k, v) in self.find_speakers(tokens).items() if k &lt;= 1}           if len(speakers) &gt; 0:               features.update({"{} {}".format(tag, self.tag_distance): speakers[min(speakers.keys())]})               break       return features paragraph = tree.xpath(".//paragraph")[-1] example_extractor = feature_extractor(paragraph, particles) print example_extractor.raw print example_extractor.features() print example_extractor.local_features() print example_extractor.feature_booleans()</span></span></code> </pre> <pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And in their hands, the daggers.
</font></font> {}<font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
['NoQuotes = True', 'Short Graf = True', 'Little Talk = True']</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
['PS 0 = False', 'FN 0 = False', 'NN 0 = False', 'ADR 0 = False'] </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Last night, during an undocumented machine learning insanity, I tried to improve on a number of properties. </font><font style="vertical-align: inherit;">Below are some sketches acceptable for publication. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 1: True Positional Boolean Values ‚Äã‚ÄãOnly</font></font></b> <br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font>
PS 0  207    0.9949<font></font>
FN 0   185    0.95<font></font>
NULL   118    0.3492<font></font>
OTHER  56     0.3939<font></font>
PS - 2 44     0.5238<font></font>
Item accuracy: 430 / 678 (0.6342) </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Next, we will meet a lot of similar statistics, and therefore let's immediately determine what they mean. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Imagine that we are at dinner, looking at people. I asked you to determine if a bystander is an illuminati. You, as a person who completely believes in conspiracy theories, finish eating dumplings and start tagging passersby. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Accuracy ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">note Precision</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), the value that will not be considered here, shows the frequency of errors of the first kind. In other words, how often you mistakenly ranked a person to the Illuminati. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Completeness ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">approx. Recall</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) measures the number of labels in the verification data that the model has identified correctly.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And F1 is a combination of both tags. </font><font style="vertical-align: inherit;">You can see that if you classify all people as Illuminati, this will ensure maximum completeness and insignificant accuracy.</font></font><br><br>  Since<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Everything is marked by me, I am not very interested in the accuracy of the model. </font><font style="vertical-align: inherit;">I need completeness and accuracy. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the first version of the properties, I considered only true boolean values.</font></font> Those.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in the paragraph above, all sets were of the form ‚ÄúADR 0 = True‚Äù and ‚ÄúPS 0 = True‚Äù. </font><font style="vertical-align: inherit;">Accuracy ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">approx. Item accuracy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) was 63.4%. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">63.4% is good? </font><font style="vertical-align: inherit;">Given that NULL, PS 0 and FN 0 make up three-quarters of our verification data, and they are naturally easy to find, we definitely can do better. </font><font style="vertical-align: inherit;">Now add the rest of the positional boolean values, false. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 2: all positional boolean values</font></font></b> <br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NULL 254 0.9048</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 0 204 0.9899</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FN 0,149 0.975</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OTHER 24 0.2273</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS - 2 19 0.2857</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Item accuracy: 515/678 (0.7596) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now we perfectly define simple cases and get decent accuracy. </font><font style="vertical-align: inherit;">75% means that you only need to mark the first book, Game of Thrones, and one third of Battle of Kings and the model to determine the remaining three-quarters of the books itself. </font><font style="vertical-align: inherit;">This requires many hours of work, but within reason. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And yet, I see no reason why not define NULL tags with a full 98% +, so let's add a property aimed at this. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 3: quotes?</font></font></b> <br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 0 218 0.9907</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NULL 180 0.9119</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FN 0 167 0.9118</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OTHER 63 0.3784</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 2 25 0.5</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Item accuracy: 550/710 (0.7746) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We count the number of opening quotes in a paragraph. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I want to say that I am surprised that NULL did not become more accurate. </font><font style="vertical-align: inherit;">Need to work on this. </font><font style="vertical-align: inherit;">Further I would like to improve FN 0. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 4: the index of the first name?</font></font></b> <br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 0 218 0.9907</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NULL 183 0.9057</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FN 0 157 0.8971</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OTHER 68 0.4189</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS - 2 23 0.5484</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Item accuracy: 551/710 (0.7761) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This property contains the index of the first name. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hmm ... maybe too complicated, let's go back to the boolean values ‚Äã‚Äãagain. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 5: index 0 name? </font><font style="vertical-align: inherit;">+ redundancy</font></font></b> <br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 0 216 0.986</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FN 0 166 0.9265</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NULL 160 1</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OTHER 85 0.5811</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 2 32 0.7143</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Item accuracy: 578/710 (0.8141) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here it is! </font><font style="vertical-align: inherit;">I did not correctly count the number of opening quotes, thereby spoiling the result. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As soon as I fixed this, NULL is perfectly defined ... but now we‚Äôve run out of easy ways to improve the model. </font><font style="vertical-align: inherit;">I now really need to contrive to further improve the result! </font><font style="vertical-align: inherit;">Let's see if it works ... </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 6: After the speaker (PS) + and - 2</font></font></b> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Here we will use the boolean value if the speaker is in two paragraphs above or below the current one. </font><font style="vertical-align: inherit;">In theory, this should increase the PS -2 result.</font></font><br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 0 216 0.986</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FN 0 166 0.9265</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NULL 160 1</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OTHER 84 0.5676</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 2 32 0.7143</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Item accuracy: 578/710 (0.8141) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No effect! </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Option 7: sequences ??</font></font></b> <br><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Label Count Recall</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 0 217 0.986</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FN 0 168 0.9265</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NULL 160 1</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OTHER 82 0.5541</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS 2 30 0.6429</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Item accuracy: 576/710 (0.8113) Instance accuracy: 56/142 (0.3944) </font></font></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wait! </font><font style="vertical-align: inherit;">It turned out that CRF can work with sequences, and in fact this is its meaning. </font><font style="vertical-align: inherit;">I ignored the value of the accuracy of the instance ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">approx. Instance accuracy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), because </font><font style="vertical-align: inherit;">it was always 0/1, which means that the model viewed the entire text as one long dialogue. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sorry, I need to slap myself. </font><font style="vertical-align: inherit;">Assuming that we will increase accuracy ‚Äî and this is an open question ‚Äî how will we use this functionality? </font><font style="vertical-align: inherit;">I tried to specify the length of each sequence in 5 paragraphs, but this does not seem to me correct. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perhaps if there are two consecutive NULLs, this will be a sequence, assuming that the conversation is over.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">After I played with this, I still could not build a model that would work with conversations. As I understand it, it should have a lot of special transition weights ( </font><font style="vertical-align: inherit;">depending on </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">transition weights</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), depending on the position in the sequence. Thus, the model will make different decisions, depending on our position, in the beginning, in the middle or at the end of the conversation.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But nothing in the behavior of the model shows that this happens. </font><font style="vertical-align: inherit;">In the near future, I will play a little more with other properties. </font><font style="vertical-align: inherit;">Oh yes, let's take a look at the script that generates our training and verification data. </font><font style="vertical-align: inherit;">It is not optimized, because </font><font style="vertical-align: inherit;">calculate properties for each paragraph 5 times. </font><font style="vertical-align: inherit;">I will leave it as it is for this material, but keep in mind that it can be accelerated if you use one cycle to preserve the boolean properties of the paragraphs and the second to add to the existing ones.</font></font><br><pre> <code class="python hljs">tree = ASOIAFtoXML([{<span class="hljs-string"><span class="hljs-string">"title"</span></span>: <span class="hljs-string"><span class="hljs-string">"ASOIAF"</span></span>, <span class="hljs-string"><span class="hljs-string">"contents"</span></span>: <span class="hljs-string"><span class="hljs-string">"corpus/train_asoiaf_pos_tagged.txt"</span></span>}]) paragraphs = tree.xpath(<span class="hljs-string"><span class="hljs-string">".//paragraph"</span></span>) In [<span class="hljs-number"><span class="hljs-number">29</span></span>]: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prep_test_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(paragraphs)</span></span></span><span class="hljs-function">:</span></span>   max_index = len(paragraphs)   results = []   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> index, paragraph <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(paragraphs):       extractor = feature_extractor(paragraph, set_of_particles)       all_features = extractor.local_features() + extractor.feature_booleans()       <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-number"><span class="hljs-number">-2</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>]:           <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> &lt;= n+index &lt; max_index:               neighbor_features = feature_extractor(paragraphs[index + n], set_of_particles, tag_distance = n).feature_booleans()               <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> neighbor_features:                   all_features += neighbor_features            all_features.insert(<span class="hljs-number"><span class="hljs-number">0</span></span>, extractor.speaker)       results.append(<span class="hljs-string"><span class="hljs-string">"\t"</span></span>.join(all_features))   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> results results = prep_test_data(paragraphs) In [<span class="hljs-number"><span class="hljs-number">31</span></span>]: max_index = len(results) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> codecs.open(<span class="hljs-string"><span class="hljs-string">r"new_test.txt"</span></span>, <span class="hljs-string"><span class="hljs-string">"w"</span></span>, <span class="hljs-string"><span class="hljs-string">"utf-8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> output:   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> results[:int(max_index/<span class="hljs-number"><span class="hljs-number">2</span></span>)]:           output.write(line + <span class="hljs-string"><span class="hljs-string">'\n'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> codecs.open(<span class="hljs-string"><span class="hljs-string">r"new_train.txt"</span></span>, <span class="hljs-string"><span class="hljs-string">"w"</span></span>, <span class="hljs-string"><span class="hljs-string">"utf-8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> output:   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> results[int(max_index/<span class="hljs-number"><span class="hljs-number">2</span></span>):]:           output.write(line + <span class="hljs-string"><span class="hljs-string">'\n'</span></span>)</code> </pre> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> More properties </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I tried several other properties: </font></font><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Counting the number of names to the first line of the dialogue. </font><font style="vertical-align: inherit;">In theory, this is the place where NN is most. </font><font style="vertical-align: inherit;">There is no result.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A property that notes that a paragraph is in whole or in part a dialogue. </font><font style="vertical-align: inherit;">This helped to improve the situation with PS -2 and FN -2, but the difference was not significant.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Short / long paragraphs. </font><font style="vertical-align: inherit;">Little use.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"And" or "but" in the text before the dialogue. </font><font style="vertical-align: inherit;">(in an attempt to focus on NN 0, where they were ignored)</font></font><br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I thought that the latter is a very clever move, but it did not work and we did not get any accuracy above 81%. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I tried to change the training data with the verification data and it gave 84%. </font><font style="vertical-align: inherit;">You should not spend a lot of time improving the set of properties for certain data, because </font><font style="vertical-align: inherit;">this leads to retraining. </font><font style="vertical-align: inherit;">In fact, mixing the training and verification data is a good idea. </font><font style="vertical-align: inherit;">I did not mix them, because </font><font style="vertical-align: inherit;">I thought that this would damage the sequences, but we no longer use them, so why not? </font><font style="vertical-align: inherit;">We mix them up. </font></font><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Slightly mixed data.</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Received 82%. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Okay! </font><font style="vertical-align: inherit;">I think here we have reached the limit of my skills.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And there will be no continuation? </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Let's summarize and talk about what can be done next. </font></font><br><ul><li>   .     700     .    40000. ,    1.7%     80%. (    80%,        75%.)      10000   ?           ,    ,  ADR,    700 . <br></li><li>    CRFsuite.    ,   . <br></li><li>    . <br></li><li>    . <br></li><li>    Python.       ,       . ,   ‚Ä¶ <br></li><li>  .      ,     OTHER.   OTHER,    , ,         ,        .       OTHER  ‚Äî        . <br></li><li>  .       .        . ,        , ,  ,              ¬´¬ª.     ;     ¬´¬ª              ,   . <br></li></ul><br><br><h1>  Conclusion </h1><br>  Good!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I hope this was useful to someone. </font><font style="vertical-align: inherit;">Thank you for reading and if you want to contact me, then I am on Twitter. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Also, I would like to point out that all of the above was made for a large critical study of the Game of Thrones. </font><font style="vertical-align: inherit;">If you are a fan of these books and would like to read the analysis that was possible thanks to the label of the dialogues, then I will publish everything soon.</font></font></div><p>Source: <a href="https://habr.com/ru/post/304230/">https://habr.com/ru/post/304230/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../304218/index.html">Harvard CS50 course in Russian: second lecture appeared</a></li>
<li><a href="../304220/index.html">Building a chain of trust in PKI, is it all so simple</a></li>
<li><a href="../304222/index.html">Organization of access to the Moscow metro WI-FI network from a security point of view</a></li>
<li><a href="../304226/index.html">How to become a specialist in the field of "big data"?</a></li>
<li><a href="../304228/index.html">MQTT and Modbus: a comparison of the protocols used in IoT gateways</a></li>
<li><a href="../304232/index.html">How does a little bird find a golden ‚Äúcage‚Äù? Advice to freelancers in finding employment in the office</a></li>
<li><a href="../304234/index.html">In the wake of WWDC 2016. Practical Guide</a></li>
<li><a href="../304236/index.html">Azure Service Fabric: Second Steps</a></li>
<li><a href="../304238/index.html">Decide in your mind: What you need to know when starting a business in e-commerce</a></li>
<li><a href="../304242/index.html">Why do you need to model individual and sample scenarios?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>