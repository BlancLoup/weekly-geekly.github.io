<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The logic of consciousness. Part 9. Artificial neural networks and minicolumns of the real cortex.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Veterinarian comes to the therapist. Therapist: - What are you complaining about? Veterinarian: - No, well, so everyone can! 

 Artificial neural netw...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The logic of consciousness. Part 9. Artificial neural networks and minicolumns of the real cortex.</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/1ed/e57/03e/1ede5703ecda43a0a3a07dd233ae785b.jpg" width="400" align="left">  <i>Veterinarian comes to the therapist.</i>  <i>Therapist: - What are you complaining about?</i>  <i>Veterinarian: - No, well, so everyone can!</i> <br><br>  Artificial neural networks are capable of learning.  Perceiving many examples, they can independently find patterns in the data and highlight the signs hidden in them.  Artificial neural networks in many tasks show very good results.  The logical question is how neural networks resemble a real brain?  The answer to this question is important mainly in order to understand whether it is possible, by developing the ideology of artificial neural networks, to achieve the same thing that the human brain is capable of?  It is important to understand whether the differences are cosmetic or ideological. <br><br>  Surprisingly, it is very likely that the real brain contradicts all the basic principles of artificial neural networks.  This is doubly surprising, given that initially artificial neural networks were created as an attempt to reproduce just biological mechanisms.  But the insidiousness of such situations.  Very often, what seems plausible at first glance turns out to be the exact opposite of what it really is. <br><a name="habracut"></a><br><h3>  Artificial Neural Networks </h3><br>  Before describing the learning mechanisms of real neurons, we list the basic principles on which artificial neural networks are based.  There are several of these principles.  They are all very closely related.  Violation of any of them breaks the whole concept of the work of artificial neural networks.  After that, we will show that none of these principles is implemented in ‚Äútrue neural networks‚Äù. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>Principle 1. Each neuron is a detector of a certain property.</b> <br><br>  A real neuron, if simplified to describe it, looks simple enough.  On the dendrites are located synapses.  Synapses are in contact with other neurons.  Signals from other neurons through the synapses enter the body of the neuron, where they are summed up.  If the sum exceeds a certain threshold, then a neuron's own signal arises - the spike, which is also the action potential.  The spike extends along the axon and enters other neurons.  Synapses can change their sensitivity.  Thus, the neuron can be configured to respond to certain combinations of the activity of other neurons. <br><br>  All of this, although it looks plausible enough, is very far from the work of real neurons.  But for the time being we are describing a classic model and will follow this logic. <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/279/45d/806/27945d806a1349a69eee6c55f7b3f52c.jpg" width="400"></div><br>  <i>Simplified diagram of a real neuron</i> <br><br>  The formal model of the McCulloch-Pitts artificial neuron developed in the early 1940s follows inevitably from the above described (McCulloh J., W. Pitts, 1956). <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a50/3e3/6c0/a503e36c03083b9a77c93e9cdb35ec89.png" width="500"></div><br>  <i>McCulloch-Pitts Formal Neuron</i> <br><br>  The inputs of such a neuron signals.  These signals are weightedly summed.  Further, a certain nonlinear activation function, for example, sigmoidal, is applied to this linear combination.  Often the logistic function is used as sigmoidal: <br><img src="https://habrastorage.org/files/273/dc6/cf6/273dc6cf668e4f00adf49239c51c9d54.png" width="123"><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/61a/a7b/757/61aa7b757b3cc2bd7b19b9b294c20413.jpg" width="300"></div><br>  <i>Logistic function</i> <br><br>  In this case, the activity of the formal neuron is recorded as <br><img src="https://habrastorage.org/files/3d0/bbb/b0e/3d0bbbb0ea064a3aaf36b4fb5be68ef1.png" width="135"><br>  As a result, such a neuron turns into a threshold adder.  With a fairly steep threshold function, the neuron's output signal is either 0 or 1. The weighted sum of the input signal and the neuron weights is a comparison of two images: the image of the input signal and the image described by the weights of the neuron.  The result of the comparison is the higher, the more accurate the correspondence of these images.  That is, the neuron, in fact, determines how much of the signal supplied is similar to the image recorded on its synapses.  When the value of the weighted sum exceeds a certain level, and the threshold function switches to one, this can be interpreted as a neuron‚Äôs resolute statement that it has recognized the imaged image. <br><br>  In different models there are various variations on how the artificial neuron should work.  If we remove the threshold function, the neuron will turn into a linear adder.  It is possible, instead of comparing with a template that sets weights, to check the input signal for compliance with the multidimensional normal distribution with certain parameters, this is used in networks based on radial basis functions.  You can give signals distributed in time, and enter time parameters for synapses, thus setting the neuron for sensitivity to specific sequences.  Other options are possible.  The common thing between all of them is the correspondence of the neuron to the famous concept of ‚Äúgrandmother's neuron. <br><br>  The key point for all neural networks is the perception of neurons as detectors of any properties.  Something appears in the description - a neuron that corresponds to this ‚Äúsomething‚Äù responds to it with its activity.  Variations of neural networks are variations of the methods for detecting and teaching this detection. <br><br>  <b>Principle 2. Information in the neural network is a sign description.</b> <br><br>  In the classic view, each neuron sees a picture of the activity of other neurons that create its input signal.  In addition, each neuron is a detector of something.  If we collect the input signal into a vector, we get the so-called <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25B8%25D0%25B7%25D0%25BD%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25B2%25D0%25BE%25D0%25B5_%25D0%25BE%25D0%25BF%25D0%25B8%25D1%2581%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5">feature description</a> . <br><br>  In the attribute description, as the name implies, each element of the description vector corresponds to a specific attribute.  It does not matter how the element is defined.  This may be a binary value - a sign is present or not.  There may be a quantitative value - how expressed is the sign in the description.  Ordinal or nominal value - as this feature was realized in the description. <br><br>  For example, take a binary 32-bit vector.  We will encode the letters of the English alphabet. <br><br>  First option.  Zero bit - the letter "A", the first bit the letter "B" and so on.  26 bits will advise 26 letters.  Then make a bit - capital letter or uppercase.  Bit - italic or non italic, bit for thickness, bit for underline, and so on.  If you encode one letter at a time, then you can encode one of the 26 letters in different spellings.  This is a typical trait description.  Every bit is a certain sign. <br><br>  The second option.  Machine coding, type, unicode.  Characters are encoded with unique binary codes.  But individual bits are no longer signs.  In the codes of different letters not connected with each other there may be common units.  Such coding is no longer an indicative description, although externally both there and there a 32 bit binary vector. <br><br>  The information that neural networks deal with is always a trait description.  And this follows from the first principle, according to which neurons are feature detectors. <br><br>  <b>Principle 3. A neural network, as a rule, is a converter of feature descriptions.</b> <br><br>  The input of the neural network is an indicative description.  The result of the work is also an indicative description, but consisting of other features.  For example, if we want to make a network that recognizes numbers by their image, then the input signs can be the brightness values ‚Äã‚Äãof the image points, and the output characters are recognized numbers. <br><br>  When transforming one attribute description into another, it may be useful to use intermediate features that are not found in either the input or the output description.  You can make several layers of such intermediate features.  Such neural networks look like what is shown in the figure below. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/613/981/c7c/613981c7cf338073ddfa929e6325f29f.png" width="500"></div><br>  <i>Multilayer perceptron with two hidden layers (Heikin, 2006)</i> <br><br>  A typical example of a neural network with hidden signs is a layered network of direct distribution.  Each layer of such a network, except for the input, consists of neuron detectors.  These neurons are tuned to recognize certain signs.  Each layer repeats the original description, but in its characteristic features of this layer. <br><br>  If the output of the network is fed back to the input, then we obtain a dynamic recurrent network.  In the forward propagation network, the output state is determined immediately after activation of all neurons.  In a recurrent network, only with time does a steady state arise, which is the result of its work. <br><br>  Regardless of the type of network on each layer, we are dealing with an attribute description made up of neuron detectors. <br><br>  <b>Principle 4. The number of neurons in a network determines the number of signs with which this network can operate.</b> <br><br>  The number of neurons on any layer of the network determines how many maximal signs are available to highlight this layer.  Usually the number of neurons in the network is set initially before the start of training.  Since it is not known in advance how many useful signs can stand out, the optimal number of neurons in the layers is selected iteratively. <br><br>  In principle, it is possible, if necessary, to add new neurons on the fly, but this requires a special approach to training and is associated with significant difficulties. <br><br>  <b>Principle 5. Network training is the setting of the weights of the connections connecting neurons.</b> <br><br>  The detector of which property is one or another artificial neuron is determined by what values ‚Äã‚Äãtake its weight.  Training of the neural network occurs due to such a change in the weights of the neurons, which optimizes the requirements that we make to this network. <br><br>  The two main types of learning are learning without a teacher and learning with a teacher. <br><br>  <b>Teaching without a teacher</b> <br><br>  When learning without a teacher, the neural network observes the input data, without having any idea in advance about which output signal should correspond to certain events.  But since data may contain certain patterns, it is possible to adjust the behavior of the network in such a way that its neurons each respond to their own pattern. <br>  For example, you can take a single-layer network consisting of linear adders and make it select the <a href="https://habrahabr.ru/post/214241/">main components of the supplied data set</a> .  To do this, you can initiate a network with random weights, when giving a signal, determine the winner and then shift its weights in the direction of the given signal.  As a result, the neurons themselves ‚Äúdrag‚Äù among themselves the main factors contained in the input information. <br><br>  You can make an <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25B2%25D1%2582%25D0%25BE%25D0%25BA%25D0%25BE%25D0%25B4%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D1%2589%25D0%25B8%25D0%25BA">auto encoder</a> .  Create a network of three layers with the condition that the middle layer should be smaller than the input layer, and the output layer should be equal to the input layer.  The task of the autocoder is to reproduce the pattern of the input layer as accurately as possible on the output layer. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95b/b6d/1a3/95bb6d1a33895f8b0dc27895070236d2.png" width="200"></div><br>  <i>Autocoder</i> <br><br>  Since there is a layer with a smaller dimension on the way from the entrance to the exit, the autocoder will have to learn how to compress the data, that is, select the most significant factors on the neurons of the middle layer.  The middle layer in the future and will be the working output of the network. <br><br>  For auto-coder training, you can read the error between the first and third layers at each step and adjust the network weights in the direction of reducing this error.  This allows you to do, for example, the <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F_%25D0%25BE%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8">method of back propagation of error</a> . <br><br>  There may be other methods.  For example, a <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%25A1%25D0%25B5%25D1%2582%25D1%258C_%25D1%2580%25D0%25B0%25D0%25B4%25D0%25B8%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D1%258B%25D1%2585_%25D0%25B1%25D0%25B0%25D0%25B7%25D0%25B8%25D1%2581%25D0%25BD%25D1%258B%25D1%2585_%25D1%2584%25D1%2583%25D0%25BD%25D0%25BA%25D1%2586%25D0%25B8%25D0%25B9">network of radial basis functions</a> , based on the ideas of the EM algorithm, can solve the problem of classification.  In such a network, the neurons of the hidden layer do not evaluate the conformity of the supplied image and the image defined by the weights of the neuron, but the probability that the input signal corresponds to normal distributions, the parameters of which are stored in these neurons. <br><br>  <b>Teaching with a teacher</b> <br><br>  When training with a teacher, we determine in advance which output signal we want to receive from the network in each of the training examples.  The task of training is to adjust the weights so that the network most accurately guesses the answers from the training set.  Then there is hope that the network has caught patterns and will be able to guess the output signal for data that was not in the training. <br><br>  For the direct distribution network, training is as follows.  Initially, the network is initiated by random weights.  A training example is provided and the network activity is calculated.  An error is formed, that is, the difference between what should be on the output layer and what happened to the network.  Further weights are adjusted to reduce this error. <br><br>  For a single-layer perceptron, you can use the <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B5%25D0%25BB%25D1%258C%25D1%2582%25D0%25B0-%25D0%25BF%25D1%2580%25D0%25B0%25D0%25B2%25D0%25B8%25D0%25BB%25D0%25BE">delta rule</a> . <br>  The delta rule is very similar to Hebb's rule, which has a very simple meaning: the connections of neurons that are activated together must be strengthened, and the connections of neurons that operate independently must weaken.  But Hebb's rule was originally formulated for learning without a teacher and allows neurons to tune themselves to the allocation of factors.  When learning with a teacher, joint activity should be understood somewhat differently.  In this case, the Hebba rule takes the form: <br><br><ul><li>  The first rule - If the output signal of the perceptron is incorrect and equal to zero, then it is necessary to increase the weights of those inputs to which the unit was applied. <br></li><li>  The second rule - If the output signal of the perceptron is incorrect and equal to one, then it is necessary to reduce the weights of those inputs to which the unit was fed. <br></li></ul><br>  If <i><b>Y</b></i> is the vector of the real output of the perceptron, and <i><b>D</b></i> is the vector that we expect to receive, then the error vector: <br><br><img src="https://habrastorage.org/files/c24/05b/e06/c2405be06f9e45cdb29ef95d7d8052d2.png" width="85"><br>  Delta rule for changing the connection between i and j neurons: <br><br><img src="https://habrastorage.org/files/9bb/88b/dda/9bb88bdda7784059bd5cf45a409ebe1b.png" width="277"><br><br>  In fact, in a single-layer network, we are trying to build portraits of output features on neurons of the output layer in terms of input features.  With weights of connections, we set the most characteristic, typical portrait of the output feature. <br><br>  Difficulties begin when it turns out that an unambiguous portrait may not exist.  For example, when we try to recognize letters, we can use both upper and lower case letters when learning.  With this, if we do not make a difference between them, then the output neuron responsible for the letter ‚ÄúA‚Äù will have to respond immediately to two images - the image ‚ÄúA‚Äù and the image ‚Äúa‚Äù.  Similarly, the writing of letters can be completely different in different handwritings.  If you try to combine all these portraits on one neuron, then nothing good will work.  The image will be so blurred that it may be almost useless. <br><br>  In such cases, a multilayer network with hidden layers helps.  On the neurons of the hidden layers can be formed independent portraits of various realizations of the output signs.  In addition, factors that are common to different output neurons can be distinguished in the hidden layers and are thus useful for differentiating one output feature from the other. <br><br>  For teaching a multilayer network, <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F_%25D0%25BE%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8">the backpropagation method is used</a> .  The method consists of two passes: direct and reverse.  With a direct pass, a training signal is given and the activity of all network nodes, including the activity of the output layer, is calculated.  By subtracting the resulting activity from what was required to receive, an error signal is determined.  During the back pass, the error signal propagates in the opposite direction, from the output to the input.  At the same time, synaptic weights are adjusted in order to minimize this error. <br><br>  <b>Principle 6. Finite learning.</b>  <b>Stability-plasticity dilemma.</b> <br><br>  When teaching a neural network, each time after submitting a new training example, a certain correction to the link weights is calculated.  At the same time, gradients are calculated, which indicate in which direction this or that connection should be changed, strengthened or weakened. <br><br>  At the beginning of training, you can behave quite boldly and relatively strongly correct the connections of neurons.  But as far as learning, it turns out that abrupt changes are already unacceptable, as they begin to retrain the network, adjusting it to a new experience, while erasing the previous experience.  The output is fairly obvious.  The learning speed parameter is entered into the algorithms.  As we learn, the speed decreases and the new experience no longer radically changes the weight, but only slightly corrects them. <br><br>  The disadvantage of this approach is that, from a certain point in time, the network ‚Äústiffens‚Äù and ceases to change.  For this reason, traditional networks are difficult to train.  If such a need arises, it is easier to re-start from scratch to train the network on an extended data set that includes both old and new experiences. <br><br>  The issue of additional training rests on the fact that the new experience begins to change the weights of the network and thereby changes the old training.  The problem of the destruction of the old experience of new information is called the dilemma of stability-plasticity. <br><br>  A solution is proposed by Stefan Grossberg (Grossberg, 1987) as the ‚Äútheory of adaptive resonance‚Äù.  The essence of this theory is that the incoming information is divided into classes.  Each class has its own prototype - the image that most closely matches this class.  For new information, it is determined whether it belongs to one of the existing classes, or whether it is unique, unlike any previous one.  If the information is not unique, then it is used to refine the class prototype.  If this is something fundamentally new, then a new class is created, the prototype of which lays down this image.  This approach allows, on the one hand, to create new detectors, and on the other hand, not to destroy already created ones. <br><br>  But the ideology of adaptive resonance is poorly compatible with other learning methods, since, in fact, requires the addition of new neurons directly in the process of learning the network. <br><br><h3>  Active Memory Learning Model </h3><br>  There are two approaches to learning - adaptive and batch.  In adaptive learning, new experience is used to slightly change the previously achieved state of the weights of the network in order to adapt them to this new experience.  In this case, it is assumed that the weights of the network already take into account all that is associated with previously acquired experience.  In the batch approach, it is assumed that when receiving a new example, all previous experience remains available to us and when training we can not adapt the weights, but simply calculate them again. <br><br>  Keeping previous experience greatly simplifies the issue of network stability-plasticity. <br>  Consider the task of recognizing numbers, for example, the <a href="https://ru.wikipedia.org/wiki/MNIST_(%25D0%25B1%25D0%25B0%25D0%25B7%25D0%25B0_%25D0%25B4%25D0%25B0%25D0%25BD%25D0%25BD%25D1%258B%25D1%2585)">MNIST</a> set.  The images of handwritten numbers are fed to the input of the neural network, the output is monitored by the reaction of neurons corresponding to numbers from 0 to 9. The input images are 28 by 28 pixels in size, 784 points in total. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3c1/5a1/bfe/3c15a1bfee0bdbf9c127385c8238e9d6.png" width="300"></div><br>  <i>Example of handwritten numbers set MNIST</i> <br><br>  Usually, convolution networks and a multilevel architecture are used to solve such problems.  We will consider the work of such networks in more detail later.  Due to the simplicity and preliminary preparation of the MNIST kit (all figures are the same size and centered), good results are obtained even with a simple single-layer or double-layer perceptron. <br><br>  The figure below shows the simplest single-layer network.  The input of this network is 784 image points.  Output - the neurons corresponding to the numbers. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dce/87d/1e0/dce87d1e0954ac1d6641eff8b47d5130.png" width="300"></div><br>  <i>Single-layer network for handwriting recognition</i> <br><br>  You can train such a network, for example, with a delta rule.  As a result of training, the weights of the output neurons will tune into some averaged-schematic images of numbers.  Blurred enough to ‚Äúcover‚Äù their prototypes as much as possible, but not to ‚Äúcrawl‚Äù into other numbers.  The learning speed parameter here has a very specific interpretation.  Since a kind of averaging of images of a single digit occurs, the contribution of each following example to the formation of averaging should be inversely proportional to the number of examples that have already passed. <br><br>  In the training set the same numbers are in a different spelling.  For example, the deuce is ‚Äúsimple‚Äù and the deuce with a ‚Äúloop‚Äù at the bottom (figure below).  A simple network is nothing but to build a hybrid portrait, which, of course, does not improve the quality of its work. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/91e/2d0/311/91e2d031188e66d20c293444c877f670.png" width="150"></div><br>  <i>Options "two"</i> <br><br>  In a multilayer network, there is a hope that in the hidden layers, the variants of the base of two are distinguished by separate features.  Then the output layer will be able to more confidently recognize the two, focusing on the appearance of one of these signs. <br><br>  Creating averaged blurred portraits allows you to successfully recognize images in most cases, but imposes a limit on the achievable quality of recognition.  Blur inevitably leads to loss of information. <br><br>  When learning the neurons of the output layer, ‚Äúgood‚Äù classifiers are created for each of the digits.  Their weights are the best that can be obtained from the ideology of "let's make a portrait of a class." <br><br>  When computers were weak or, God forbid, it was necessary to count manually, it was very important to use such methods that would allow to obtain good results with minimal calculations.  Many ideas of "good" algorithms come precisely from such a saving of computations.  It is necessary to make a certain discriminant function, which will allow to calculate the belonging of an object to a class.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Or it is necessary to calculate the main factors and operate the description in them instead of the original data. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For any "good" basic algorithm, there is a limit of attainable accuracy, which is determined by what percentage of information was lost in the process of constructing factors or creating a discriminant function. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The overall result can be improved by using several different classifiers at once. From several classifiers it is possible to create a committee that will decide on the classification of an object by vote. This approach is called </font></font><a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%2591%25D1%2583%25D1%2581%25D1%2582%25D0%25B8%25D0%25BD%25D0%25B3"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">boosting</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When boosting, it is not necessary to use "good" classifiers. Any non-random, that is, those with a probability of correct assignment above the probability of a random choice, are suitable. The most interesting thing is that in many cases, by increasing the number of ‚Äúbad‚Äù, but non-random classifiers, you can achieve an arbitrarily accurate result. Such reasoning is true for artificial neural networks. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The ideology of neuron-detectors trained in a blurry-averaged image is in many respects a tribute to the "economical" methods of calculation. True, learning itself is not always economical and fast, but the result is a network with a relatively small number of neurons.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An alternative to the concept of ‚Äúgood‚Äù neuron detectors may be the concept of ‚Äúactive memory‚Äù. Each individual learning example is an image that can independently act as a classifier. That is, for each teaching example, you can create a separate neuron, the weights of which will copy the input signal. Such a neuron can work, for example, in the linear adder mode, then its response will be the stronger, the more the supplied signal looks like the image it has memorized. From such detector memories, you can assemble the network shown in the figure below.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6ee/343/ee5/6ee343ee5672876c8dc92b11ba142bdc.png" width="300"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neural network with memories-detectors. The connection between memories and output neurons is more complicated than just summation.</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In the network shown in the figure, the input layer of neurons transmits its signal to the elements of the second middle layer. The elements of the second layer will not be called neurons, but called memories. Each teaching example creates a new memory. When setting the example, the newly created memory stamps on itself the exact image of the signal of the input layer. The output of the memory element closes at the neuron of the output layer corresponding to what the correct answer prescribes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teaching such a network with a teacher comes down to memorizing examples and creating example-response connections.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In recognition mode, each memory independently determines the degree of its similarity to the current image. From the cumulative triggering of memories, information is created for the output layer, which allows us to understand which neuron should be activated. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">With the external simplicity of the network with memory, its operation is not as simple as it may seem. Elements of this network require significantly more complex logic of operation than from traditional formal neurons. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comparison mechanism</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The mechanism for comparing memories and images depends on the form of the description. It must be said that the indicative description is a rather unfortunate form. For example, two adjacent in the picture points in the attribute description give a zero match if the scalar product of the corresponding vector descriptions is used for comparison. It is for this reason that when encoding a picture through a vector describing the brightness of individual points, the ‚Äúfuzzy‚Äù description is preferable to the ‚Äúclear‚Äù one. In blurry pictures instead of a single point, a ‚Äúspot‚Äù appears. Accordingly, close points start to give a certain match when comparing (figure below).</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d7c/6b8/4ff/d7c6b84ff6bc875c23fed12068efb915.png" width="800"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A single offset results in a complete absence of coincidence (left). A similar situation after blurring gives a significant coincidence (right) (Fukushima K., 2013)</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The idea of ‚Äã‚Äã‚Äúblurring‚Äù is suitable not only for images, but also for any feature descriptions. To do this, you need to set the matrix of proximity signs description. Then, for any input signal before comparing, it is possible to create its ‚Äúblurring‚Äù and use it already in a scalar product. For pictures, the proximity of features is determined by the proximity of points in the image. For arbitrary signals, specifying the proximity of features is somewhat more difficult. Sometimes the statistics of their joint manifestation can help.</font></font><br><br>  ¬´¬ª     ¬´¬ª    ¬´¬ª ,     . ,   -  ¬´¬ª ,   .       . <br><br> <b> </b> <br><br>   MNIST    ,         .                .              ,   ,            ,      . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When recognizing digits, it is necessary to estimate to which digit the current image is closer. To do this, you can calculate the average value of the match between the current image and the memories related to each of the numbers. Such an assessment of the averaged coincidence, although it will carry a certain meaning, will be bad for making a decision. For example, the class of twos contains at least two spellings - with and without the ‚Äúloop‚Äù below. The situation is even worse, for example, with writing letters. Both uppercase and lowercase spellings of one letter can belong to one class. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In such cases, it is reasonable to average the examples separately for each of the spellings. That is, it makes sense to pre-cluster among the memories belonging to the same class, and divide them into appropriate groups.</font></font><br><br>  ,      ,     .  ,       ¬´¬ª ,   ,    . ,    MNIST  ,        ,   ,  .    ,       .      ,    .      ,   ,  ,        . <br><br> <b>  </b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Each output neuron receives information about what memories are, in which there was something in common with the input signal, and information about the level of these coincidences. </font><font style="vertical-align: inherit;">From this information it is necessary to conclude that there is a probability that we have the image for which the training took place. </font><font style="vertical-align: inherit;">From the comparison of the probability for all output neurons, it is necessary to decide which of them is preferable and whether the level of the attained probability for the appearance of the output signal is sufficient.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Binary network output coding </font></font></h3><br> ,             ,          .    ‚Äì       ?        ,    ,   ‚Äì ,    . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Earlier we said that in the real brain, one minicolumn of the cortex, consisting of about one hundred neurons, performs the functions of a context computing module. That is, it analyzes what the information looks like in the context of this particular mini column. Each minicolumn has its own copy of memory and is able to conduct complete processing of information independently of the other minicolumns. This means that one minicolumn must perform all the functions that are characteristic of neural networks. At the same time, the number of signs that a minicolumn encounters is much more than a hundred and can be tens or hundreds of thousands.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One hundred neurons encode one hundred signs when talking about neuron detectors and feature descriptions. But we proceed from the fact that neurons do not form feature descriptions, but by their activity they create signals of a binary code that encode certain concepts.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It is easy to modify the neural network so that its output encodes not the indicative description, but the binary code of the feature. For this, it is necessary to ‚Äúconnect‚Äù the memories not with one output neuron, but with several forming the corresponding code. For example, digits from 0 to 9 can be encoded with a five-bit code so that each code contains exactly two units (figure below). Then each memory will affect not one, but two neurons. The result of such a network is not the activity of a single neuron corresponding to a digit, but a neural binary code of a digit. With such coding, neurons cease to be neurons of the grandmother, since their activity can manifest itself in completely different concepts.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/763/214/16b/76321416b2c845d09c0f33f71700f9bf.JPG" width="500"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Encoding the output of the network with a binary code</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If we look at the network that was obtained as a result, it turns out that it already has little resemblance to traditional neural networks, although it fully retains all their functionality. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's look at the resulting network in the context of the previously formulated six principles of the classical neural network: </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 1. Each neuron is a detector of a certain property.</font></font></b> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not satisfied. The output neurons are not the grandmother's neurons. The same neuron is triggered by different signs. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 2. Information in the neural network is a sign description.</font></font></b> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not satisfied. Network output is the concept code, not a feature set. The network input can also work with codes, and not with feature vectors.</font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 3. A neural network, as a rule, is a converter of feature descriptions.</font></font></b> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not satisfied. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 4. The number of neurons in a network determines the number of signs with which this network can operate.</font></font></b> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not satisfied. The output layer, containing a hundred neurons, when encoding a signal with ten active neurons, can display 1.7x10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">13</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> different concepts. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 5. Network training is the setting of the weights of the connections connecting neurons.</font></font></b> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not satisfied. Memories are ‚Äúlinked‚Äù to neurons, but no adaptive change in weights occurs. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 6. Finite learning. Stability-plasticity dilemma.</font></font></b> <br>  .              .       .     .  ,     ¬´ ¬ª.           .         ,        -. <br><br><h3>   </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The main informational processes of our brain occur in its cortex. </font><font style="vertical-align: inherit;">The cerebral cortex is divided into zones. </font><font style="vertical-align: inherit;">Each zone consists of hundreds of thousands of minicolumns of the same structure. </font><font style="vertical-align: inherit;">The number of neurons in a minicolumn, depending on the type of zone, is from 100 to 200. The </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">neurons of one minicolumn are located one under another. </font><font style="vertical-align: inherit;">Most of their connections are concentrated in the vertical direction, that is, with the neurons of their own minicolumn.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e51/5d8/a35/e515d8a35f25e1446678c82e74ee2496.png" width="300"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minicolumns of the cat's primary visual cortex (left) and monkey (right) (Peters and Yilmaze, 1993).</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> It was previously assumed that each mini-column of the cortex corresponds to a different context. </font><font style="vertical-align: inherit;">Minicolumns of any bark zone allow us to consider the same input information in all possible contexts for this zone and to determine which of them is better suited for the interpretation of the information received.</font></font><br><br>       , ,           ,   .         .     .         .   , ,    . <br><br>         .    ,        .         ,    ¬´¬ª   . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As a result, a binary vector arises in each minicolumn, which is a description of how the source information looks in the context of a minicolumn. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">From this point on, what happens in every minicolumn is a lot like the behavior of the memory network just described. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fixing the feature code</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In order for the minicolumn to work with the memory network mechanism, it is necessary to show how to remember the binary vector of the description and how to link this memory with the code of the corresponding feature.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In our biological model, memory is a kind of fixation of the ‚Äúinterference‚Äù of two patterns. Earlier, it was shown how to memorize the pairs ‚Äúidentifier - description‚Äù. Now we need to remember a pair of "code of the sign - description." The trait code is a combination of the activity of neurons of a minicolumn. Description is the activity of dendritic segments inside the same mini-column. To fix the interference of two patterns is to memorize the pattern of the second pattern on the elements of the first pattern. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suppose that somehow we managed to ‚Äútag‚Äù the neurons that form the trait code. Then, in order to fix a memory of the type ‚Äúattribute code - description‚Äù it is necessary to memorize the description picture on each of the marked neurons.</font></font><br><br>       ‚Äì  ,    .        .          .  ‚Äì      .             . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We will not try to guess in detail how the process of memorization proceeds, we will describe its ideology. The description signal triggers the release of neurotransmitters in certain synapses related to the minicolumn. It is possible that this happens through the creation of a hash that causes the activity of a part of the neurons. It is possible that other mechanisms will be involved. Now it does not matter. Just assume that the pattern of dendritic activity led to a picture of the release of neurotransmitters. Moreover, the ejection picture turned out to be strictly dependent on the information picture. This means that different informational patterns create different patterns of neurotransmitter emission distribution. The conversation is about neurotransmitters and modulators that fall into extra-synaptic space.</font></font><br><br>   ,        ,        .              .                    . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For any signal such places in the minicarrier will be many. So with a probability close to one, at least one such place exists on each dendritic segment. This means that there will be several dozen of such places on the dendrite of one neuron. But each of the places will not be sensitive to the whole signal, but only to its specific fragment. If we present an information signal with a binary vector, then one chosen place is a place that reacts not to the whole vector, but to several specific significant bits of this vector. The figure below shows an example when each of the selected places highlighted in red captures four of the nine active bits in the input signal.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b71/d23/77c/b71d2377cdc0f21eb7c84c13e56aefdc.png" width="400"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Places on the dendrite surface of a single neuron selected with respect to a specific signal.</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> To fix the memory on a selected neuron, it is necessary to take clusters of receptors sensitive to the combination of mediators that have arisen there, and place them in the "active" state. The active state implies that from now on, if the neurotransmitter release pattern recurs, the receptor cluster will recognize this and open the nearby ion channel, resulting in a miniature excitatory postsynaptic potential in this place. In other words, the repetition of the signal will cause a small, of the order of 1 mV, shift of the membrane potential towards the excitation side. This shift will be a point and will affect only the chosen location.</font></font><br><br>                    . ,   ,         .             .             ,       . <br><br>    ,        ,      .           ,           . <br><br>         .    ,      . ,   ,       15   100,      15    ,    .            ,       ,      . <br><br><h3>   </h3><br>       ABC,      ( ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/540/3af/018/5403af018b780ccc35eaf184f5fedf4c.png" width="100"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Binary codes of three concepts and total binary code</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Each of the selected places captures the trace of not the entire signal, but only its random fragment. </font><font style="vertical-align: inherit;">This means that among the selected places there may be places that are more sensitive to the combination of any part of the source code attributes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now suppose that we have given a signal containing only two signs AB. </font><font style="vertical-align: inherit;">Its code will be as shown below.</font></font><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d39/bc8/e9b/d39bc8e9bdf0cece4078f52a912dcce7.png" width="70"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Binary codes of two concepts and total binary code</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> For the same neuron that was at the beginning, a new signal will give only one selected place. </font><font style="vertical-align: inherit;">In the image below, it is highlighted in red. </font><font style="vertical-align: inherit;">This location will be common to AB and ABC signals. </font><font style="vertical-align: inherit;">Creating an AB signal there will cause the response to any signal containing AB to be stronger at this location than in other selected locations.</font></font><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b9e/3da/2d1/b9e3da2d1908f131db63e63cc3efeb5e.png" width="400"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reduction of the reaction of selected sites for a partial signal</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> As a result of such combinatorial memorization, it turns out that if the incoming signals contain patterns, that is, stable combinations of features, then there may be places into which ‚Äúpartial‚Äù memories associated with these combinations will start to fall. Such places can be called resonant points. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The more often in different examples with the same training code there is a certain combination of signs, the more memories will be in the corresponding resonance point and the more active its reaction will be. Memories from ABD, ABFG, and the like will fall into the resonance point corresponding to the signal AB.</font></font><br><br>       ,     .     ¬´¬ª     ,   ,            . <br><br>  ,       ,    .     ,        .    ,     ,    . <br><br>      ,  , ,        ,   .   ,      , ,       ,         .           ,     . <br><br>  , ,  ,    ,        . ,       . <br><br><h2>    </h2><br>  In the process of learning with the teacher, the input images are supplied to the network input and it is indicated what output signal we want to receive.  As experience is gained, the network can identify patterns in the input data and compare them with output features.  But this only works if the input descriptions can be ‚Äúnormalized‚Äù.  Before looking for patterns, it is required to bring all input descriptions to a ‚Äúcommon denominator‚Äù.  If we are dealing with images, then before attempting to compare them, it is necessary to convert them to a common scale, rotation and find an offset at which the desired images in different examples will coincide as much as possible.  In the classical approach, this is solved using a convolutional layer; we do this using the context space.  That is, before memorizing a new ‚Äútwo‚Äù, you first need to transform it so that it coincides as much as possible with the previous ‚Äútwo‚Äù. <br><br>  When a context is found in which a new description is consistent with previous experience, we say that the interpretation in this context implements the meaning of the information.  It is in this interpretation that the memory of this experience is created.  This applies not only to visual, but also to any other information.  Such a memory is convenient in that when it is ‚Äúsuperimposed‚Äù on previous memories, the common between them appears. <br><br>  Since a copy of the same memory must be kept in all contexts, when the necessary interpretation is in one of the contexts, it must also be remembered in all the others.  In the real crust, this means that at the moment of memorization, all contexts will have to ‚Äúabandon‚Äù their own interpretations, reproduce the chosen interpretation and remember it.  If there is training with the teacher and the required code of the characteristic is known, then remember with this code. <br><br>  Earlier we said that organizing the context space requires that each minicolumn keep the transformation rules not only for its own, but also for all other contexts.  This allows you to move minicolumns simply by changing the pointer to which context the minicolumn should be used.  Such a total memory for transformations allows realizing not only the movement of contexts, but also synchronous memorization. <br><br>  For memorization, it is enough that the code of the context in which the meaning of the information is determined and the characteristic code required for learning is spread throughout the cortex.  Then each minicolumn can independently reproduce the necessary interpretation and perform memorization. <br><br>  In this section, we have considered a learning mechanism with a teacher that is possible for the cortex.  This mechanism is quite simple, as is the very simple formulation of the problem - by examples learn how to correctly assign objects to the desired class.  The task of self-learning is much more interesting and more complicated - there are data, there are patterns in them, it is required to single out these patterns.  The difficulty is that in the brief statement of the problem nothing is said about what patterns we are interested in, how many patterns need to be highlighted, whether we are interested in particular rare patterns or whether we need to look for the most general rules, whether we want to build an orthogonal basis or whether we are satisfied with the description in oblique factors.  The next part will talk about what a universal solution the brain can offer to solve this problem. <br><br>  Alexey Redozubov <br><br><blockquote>  <a href="https://habrahabr.ru/post/308370/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/308370/">Part 1. Waves in the cellular automaton</a> <br>  <a href="https://habrahabr.ru/post/308878/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/308878/">Part 2. Dendritic waves</a> <br>  <a href="https://habrahabr.ru/post/308972/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/308972/">Part 3. Holographic memory in a cellular automaton</a> <br>  <a href="https://habrahabr.ru/post/309366/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/309366/">Part 4. The secret of brain memory</a> <br>  <a href="https://habrahabr.ru/post/309626/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/309626/">Part 5. The semantic approach to the analysis of information</a> <br>  <a href="https://habrahabr.ru/post/310214/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/310214/">Part 6. The cerebral cortex as a space for calculating meanings.</a> <br>  <a href="https://habrahabr.ru/post/310960/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/310960/">Part 7. Self-organization of the context space</a> <br>  <a href="https://habrahabr.ru/post/312060/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/312060/">Explanation "on the fingers"</a> <br>  <a href="https://habrahabr.ru/post/312740/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/312740/">Part 8. Spatial maps of the cerebral cortex</a> <br>  <a href="https://habrahabr.ru/post/317712/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/317712/">Part 9. Artificial neural networks and minicolumns of the real cortex.</a> <br>  <a href="https://habrahabr.ru/post/320866/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/320866/">Part 10. The task of generalization</a> <br>  <a href="https://habrahabr.ru/post/321256/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/321256/">Part 11. Natural coding of visual and sound information</a> <br>  <a href="https://habrahabr.ru/post/326334/">The logic of consciousness.</a>  <a href="https://habrahabr.ru/post/326334/">Part 12. The search for patterns.</a>  <a href="https://habrahabr.ru/post/326334/">Combinatorial space</a> <br></blockquote></div><p>Source: <a href="https://habr.com/ru/post/317712/">https://habr.com/ru/post/317712/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../317702/index.html">Books recommended Y Combinator for the winter holidays 2016-2017</a></li>
<li><a href="../317704/index.html">Co-location: data centers vs small and medium business?</a></li>
<li><a href="../317706/index.html">Android Fingerprint API: we assign fingerprint authentication</a></li>
<li><a href="../317708/index.html">Landing Page as a replacement for the entire site</a></li>
<li><a href="../317710/index.html">Survival Guide for a Western IT Company</a></li>
<li><a href="../317714/index.html">Immigration with the Crimea to Russia</a></li>
<li><a href="../317716/index.html">Gogland: JetBrains New Go IDE</a></li>
<li><a href="../317718/index.html">Russian software in the offices of companies - current realities and prospects, opinions and experience of experts</a></li>
<li><a href="../317720/index.html">Exotic HTTP Headers</a></li>
<li><a href="../317722/index.html">Instructions: How to choose the right indicators for monitoring and optimization, so that IT businesses grow faster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>