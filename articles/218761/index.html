<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Capture video in OpenGL applications using Intel INDE Media Pack</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="From past articles, you already know what Intel INDE and its Intel INDE Media Pack component are, providing a variety of video capabilities. This time...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Capture video in OpenGL applications using Intel INDE Media Pack</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/c59/352/4a8/c593524a8ec4ec989bbd3d01211f8266.png" alt="image" align="left">  From past articles, you already know what <a href="http://habrahabr.ru/company/intel/blog/216495/">Intel INDE</a> and its <a href="http://habrahabr.ru/company/intel/blog/216545/">Intel INDE Media Pack</a> component are, providing a variety of video capabilities.  This time I want to elaborate on the possibility of capturing video in applications that use OpenGL, in more detail at the Intel INDE Media Pack. <br><br>  I will start not with examples and a story about how it all works, but with answers to the questions that developers most often ask when it comes to capturing video in the Media Pack: ‚ÄúWhy should I even do the ability to capture video in my application?‚Äù and "Why use Media Pack, if Android 4.4 has the ability to capture video via ADB?" <br><a name="habracut"></a><br><h5>  Why is it for the developer and users </h5><br>  1. This is a usage model that can form the basis of an application, such as, for example, <a href="https://play.google.com/store/apps/details%3Fid%3Dcom.disneydigitalbooks.toystorytheater_goo">Toy Story: Story Theater</a> .  The user performs actions with objects on the screen, the application captures the video, writes it to a file, then gives the opportunity to view it, save, share on social networks. <br><br>  2. A new opportunity for the user - to record and save a good game moment, a way to pass the level, which he can also share on social networks.  For the developer, this will be one of the ways to popularize the application. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  Capture video via ADB </h5><br>  The main difference from this method is that there is no need to connect a mobile device to the host, the capture takes place directly on the device, without having to ‚Äú <i>root</i> ‚Äù the device, standard mechanisms are used.  The output is MP4 video, ready for viewing or uploading to the network. <br><br>  The second difference is the ability to capture not only video, but also audio from the built-in microphone, which makes it possible to capture sound from the application, plus the ability to comment on what is happening on the screen. <br><br><h5>  Capture video in OpenGL applications using media pack </h5><br>  The first thing you need to download and install INDE Media Pack, about how this is done, I described in detail in <a href="http://habrahabr.ru/company/intel/blog/216545/">this article</a> . <br><br>  Inside there are two libraries that you need to include in your application - <i>android- &lt;version number&gt; .jar</i> and <i>domain- &lt;version number&gt; .jar</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fad/d42/93c/fadd4293cef82ad854ee44d4716b704e.png" alt="image"><br><br>  All the work on capturing video is done by the <i>GLCapture</i> class.  The principle of its operation is simple: it has its own surface ( <i>Surface</i> ), the contents of which it encodes into frames and writes in the video.  The application first draws the current frame to the screen, then switches the context to the <i>GLCapture</i> surface and draws the scene again, when the context is restored, the current surface content is encoded and written to the resulting video. <br><br>  Before you can start using <i>GLCapture,</i> you need to prepare it, namely: <br><br><ul><li>  Set video options </li><li>  Audio (if you need to write sound) </li><li>  Specify where the video will be saved (file path) </li><li>  Configure surface </li></ul><br><br><pre><code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//  GLCapture capturer; ‚Ä¶ //   capturer = new GLCapture(new AndroidMediaObjectFactory());</span></span></code> </pre> <br><br><h5>  Video settings </h5><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      //   String videoMimeType = ‚Äúvideo/avc‚Äù; //   int videoFrameWidth = 640; //   int videoFrameHeight = 480; //    int videoBitRate = 5000; //     int videoFrameRate = 30; //    int videoIFrameInterval = 1; VideoFormatAndroid videoFormat = new VideoFormatAndroid(videoMimeType, videoFrameWidth, videoFrameHeight); videoFormat.setVideoBitRateInKBytes(videoBitRate); videoFormat.setVideoFrameRate(videoFrameRate); videoFormat.setVideoIFrameInterval(videoIFrameInterval); //    apturer.setTargetVideoFormat(videoFormat);</span></span></code> </pre> <br><br><h5>  Audio settings </h5><br>  If you do not need to write sound, you can skip this step. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      //  Audio String audioMimeType = ‚Äúaudio/mp4a-latm‚Äù; //    int audioSampleRate = 44100; //    int audioChannelCount = 1; AudioFormatAndroid audioFormat = new AudioFormatAndroid(audioMimeType , audioSampleRate, audioChannelCount); //    apturer.setTargetAudioFormat(audioFormat);</span></span></code> </pre> <br><br><h5>  Path to the resulting video </h5><br><pre> <code class="java hljs">String dstPath = ‚Äú‚Ä¶‚Äù; capture.setTargetFile(dstPath);</code> </pre> <br><br><h5>  Surface initialization </h5><br>  Before first use it is necessary to initialize the surface, this is done by calling <br><br><pre> <code class="java hljs">capture.setSurfaceSize(videoFrameWidth, videoFrameHeight)</code> </pre> <br><br>  One condition - the call must be made from a function with an active OpenGL context, i.e.  somewhere in <br><br><pre> <code class="java hljs">onSurfaceChanged(GL10 gl, <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> width, <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> height)  onDrawFrame(GL10 gl)</code> </pre> <br><br>  After the parameters are set, the surface is configured, we can start saving frames in the video. <br><br>  In the simplest case, you can draw a scene twice - first on the screen, then on the surface. <br><br><h5>  Method one: double rendering </h5><br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//     render(); //   capturer.beginCaptureFrame(); //     GLCapture render(); //   capturer.endCaptureFrame();</span></span></code> </pre> <br><br>  In some cases, this approach may affect performance, for example, in the case of scenes with a large number of objects, textures, and post processing a frame.  To avoid double rendering, you can use a frame buffer ( <i>frame buffer</i> ). <br><br><h5>  Method two: frame buffer </h5><br>  In this case, the algorithm looks like this: <br><br><ul><li>  Create framebuffer and texture attached to it. </li><li>  Draw a scene on the texture </li><li>  We draw a full-screen texture on the screen </li><li>  Switch the context and draw the texture onto the <i>GLCapture</i> surface </li></ul><br><br>  In order to save time for developers to implement this method, we have included in the library all the necessary components for working with the frame buffer. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// - FrameBuffer frameBuffer; //       FullFrameTexture texture; // -     OpenGL ,  public void onSurfaceChanged(GL10 gl, int width, int height) { frameBuffer = new FrameBuffer(EglUtil.getInstance()); frameBuffer.setResolution(new Resolution(width, height)); texture = new FullFrameTexture(); }</span></span></code> </pre> <br><br>  As you can see - a minimum of code for creating and initializing.  If desired, our implementation can be replaced with our own, no restrictions. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//    public void onDrawFrame(GL10 gl) { //     frameBuffer.bind(); //   renderScene(); //   frameBuffer.unbind(); //     texture.draw(frameBuffer.getTextureId()); //   capture.beginCaptureFrame(); //     texture.draw(frameBuffer.getTextureId()); //   capture.endCaptureFrame(); }</span></span></code> </pre> <br><br>  In order to simplify the example, I excluded a part of the code that calculates and sets the <i>view port</i> , which is a prerequisite for correctly displaying video capture in cases where the screen size and the resolution of the resulting video do not match. <br><br>  You can find the full version of the example in the <i>samples</i> application, supplied as part of the <a href="http://software.intel.com/en-us/intel-inde">Intel INDE Media Pack</a> , <i>GameRenderer</i> class. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b44/ef8/83a/b44ef883acd2fd7dc7946fd75cf9fd4f.png" alt="image"><br><br>  This example demonstrates the ability to capture both using double rendering, and using a frame buffer, and also allows you to evaluate the performance of each method, displaying the number of frames per second. <br><br>  <b>The <a href="http://habrahabr.ru/company/google/blog/218253/">annual Droidcon conference</a> will take place on April 11-12 in Moscow at <i>Digital October</i> , at which Intel will present samples of mobile devices based on IA at its booth.</b>  <b>In addition, we will present a report (on Friday the 11th) and a workshop (on Saturday the 12th) on the subject of <i>Intel INDE</i> .</b>  <b>If you plan to attend this event - do not forget to visit us, it will be interesting!</b> </div><p>Source: <a href="https://habr.com/ru/post/218761/">https://habr.com/ru/post/218761/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../218749/index.html">JoysMaker R2 Black - 3D printer for the inexperienced</a></li>
<li><a href="../218751/index.html">We work asynchronously in PHP or the story of another chat</a></li>
<li><a href="../218753/index.html">Variation in programming</a></li>
<li><a href="../218757/index.html">Another migration of PROXMOX to softRAID1, but now already 3.2 and on GPT partitions, installing FreeNAS 9.2 on a virtual machine and forwarding a physical disk to it</a></li>
<li><a href="../218759/index.html">Windows command line subtleties</a></li>
<li><a href="../218763/index.html">The sound on the chip AY-3-8910 (or Yamaha YM2149F) comes from the ZX Spectrum on the PC via LPT-port</a></li>
<li><a href="../218765/index.html">Have you seen your printed circuit boards under the microscope?</a></li>
<li><a href="../218767/index.html">Using the PerfView utility in customer support</a></li>
<li><a href="../218769/index.html">Curiosity photographed a mysterious bright glow on Mars</a></li>
<li><a href="../218771/index.html">What is behind the print resolution? How does multibit technology work</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>