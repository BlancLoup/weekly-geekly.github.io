<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The main functions of ETL-systems</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ETL is an abbreviation for Extract, Transform, Load. These are enterprise-class systems that are used to generate single directories and load data fro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The main functions of ETL-systems</h1><div class="post__text post__text-html js-mediator-article">  ETL is an abbreviation for Extract, Transform, Load.  These are enterprise-class systems that are used to generate single directories and load data from several different accounting systems into DWH and EPM. <br><br>  Probably, the principles of ETL work are well known to most of those interested, but I haven‚Äôt found Habr√© as such an article describing the concept of ETL without being tied to a specific product.  This was the reason to write a separate text. <br><a name="habracut"></a><br>  I want to make a reservation that the description of the architecture reflects my personal experience with ETL tools and my personal understanding of the ‚Äúnormal‚Äù use of ETL - an intermediate layer between the OLTP systems and the OLAP system or corporate repository. <br>  Although in principle there are ETL, which can be placed between any systems, it is better to solve the integration between accounting systems with a bunch of MDM and ESB.  If you need ETL functionality to integrate two dependent accounting systems, then this is a design error that needs to be corrected by reworking these systems. <br><br><h4>  Why ETL system is needed </h4><br>  The problem, which basically resulted in the need to use ETL solutions, is in the business needs to obtain reliable reporting from the mess that is created in the data of any ERP system. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      This mess is always there, it is of two types: <br><ol><li>  As random errors that occurred at the level of input, data transfer, or due to bugs; </li><li>  Like differences in reference books and data specification between adjacent IT systems. </li></ol><br>  Moreover, if the first type of mess can be overcome, then the second type is mostly not an error - controlled differences in the data structure, this is a normal optimization for the goals of a particular system. <br><br>  Because of this feature, ETL systems should ideally solve not one, but two tasks: <br><ol><li>  Bring all the data to a single system of values ‚Äã‚Äãand detail, simultaneously ensuring their quality and reliability; </li><li>  To provide an audit trail when converting (Transform) data so that after the conversion it can be understood from which source data and amounts each line of transformed data is collected. </li></ol><br>  Remembering these two tasks can be very useful, especially if you are writing the ETL process manually, or doing it using low-availability frameworks that do not specify the structure of the intermediate tables. <br>  It is easy to miss the second task and have a lot of problems finding the causes of errors in the transformed data. <br><br><h4>  How the ETL system works </h4><br>  All the main functions of the ETL system fit into the following process: <br><br><img src="https://habrastorage.org/files/558/1ea/a8b/5581eaa8b87e46dea3cdcbb2c9eaf664.PNG"><br><br>  In terms of data flow, there are several source systems (usually OLTP) and a receiver system (usually OLAP), as well as five stages of conversion between them: <br><br><img src="https://habrastorage.org/files/ed2/92b/c13/ed292bc138b349a0a0296f0378bb089c.PNG"><br><br><ol><li>  Loading process - Its task is to tighten data of arbitrary quality in ETL for further processing, at this stage it is important to check the amounts of incoming lines, if the source system has more lines than in RawData, then - the download went wrong; </li><li>  The process of data validation - at this stage, the data are sequentially checked for correctness and completeness, an error report is compiled for correction; </li><li>  The process of mapping data with the target model - at this stage, n-columns are added to the validated table by the number of directories of the target data model, and then by the mapping tables in each attached cell, each line contains the values ‚Äã‚Äãof the target directories.  Values ‚Äã‚Äãcan be put as 1: 1, and *: 1, and 1: * and *: *, for setting the last two options, use the formulas and mapping scripts implemented in the ETL tool; </li><li>  The process of data aggregation - this process is needed because of the difference in data granularity in OLTP and OLAP systems.  OLAP systems are, in fact, a fully denormalized fact table and the reference table tables surrounding it (asterisk / snowflake), the maximum detail of OLAP amounts is the number of permutations of all elements of all directories.  A OLTP system may contain several amounts for the same set of reference elements.  It would have been possible to kill the OLTP detailing at the entrance to the ETL, but then we would have lost the ‚Äúaudit trail‚Äù.  This trace is needed to build a Drill-down report, which shows - from which lines of OLTP, the sum was formed in the cell of the OLAP system.  Therefore, firstly, a mapping on OLTP details is done, and then in a separate table, the data is ‚Äúcollapsed‚Äù for loading into OLAP; </li><li>  Uploading to a target system is a technical process of using a connector and transferring data to the target system. </li></ol><br><br><h4>  Architecture features </h4><br>  The implementation of processes 4 and 5 from the point of view of architecture is trivial, all the difficulties are technical in nature, but the implementation of processes 1, 2 and 3 requires further explanation. <br><br><h5>  Boot process </h5><br>  When designing the data loading process, you need to remember that: <br><br><ol><li>  It is necessary to take into account the requirements of the business for the duration of the entire process.  For example: If data is to be loaded within a week from the moment it is ready in the source systems, and 40 download iterations occur until the normal quality is obtained, then the package loading time cannot be longer than 1 hour.  ( <i>Moreover, if <b>on average</b> there are no more than 40 downloads, then the download process cannot be more than 30 minutes, because in half of the cases there will be more than 40 iterations, well, or more precisely, we should consider the probabilities :)</i> ) The main <i>thing is</i> if you do not fit your calculation, Do not rely on a miracle - demolish everything, re-do it.  you do not fit; </li><li>  The data can be downloaded by the oncoming wave - with the sequential updating of the data of the same period in the future for several successive periods.  ( <i>for example: updating the forecast for the end of the year every month</i> ).  Therefore, in addition to the ‚ÄúPeriod‚Äù directory, the ‚ÄúDownload period‚Äù technical reference book must be provided, which will allow you to isolate the data loading processes in different periods and not to lose the history of changing numbers </li><li>  The data tend to be reloaded many times, and it is good if there is a technical version ‚ÄúVersion‚Äù with at least two elements ‚ÄúWorking‚Äù and ‚ÄúFinal‚Äù to separate the cleared data.  In addition, the creation of personal versions, one total and one final, allows good control over the download in several streams; </li><li>  The data always contains errors: Rebooting the entire package in [50GB -&gt; +8] is not very economical in terms of resources and you most likely do not fit into the schedule, therefore, you need to correctly divide the downloadable file package and design the system so that it allows updating package in small pieces.  In my experience, the best way is technical analytics ‚Äúsource file‚Äù, and an interface that allows you to pull down all the data from just one file and insert updated ones instead.  And it is reasonable to divide the package itself into files by the number of executors responsible for filling them ( <i>either administrators of systems preparing unloading or users filling in manually</i> ); </li><li>  When designing the division of a package into parts, it is necessary to take into account the possibility of so-called ‚Äúenrichment‚Äù of data ( <i>for example: When last year‚Äôs January 12 taxes are considered according to management accounting rules, and in March-April they overload amounts calculated by accounting</i> ), this is solved correct design of dividing a data packet into parts so that for enrichment it was necessary to overload an integer number of files ( <i>not 2,345 files</i> ), but on the other hand the introduction of another technical reference with enrichment periods, which  would not lose the change history for these reasons). </li></ol><br><br><h5>  Validation process </h5><br>  This process is responsible for identifying errors and gaps in the data transferred to ETL. <br>  The actual programming or customization of the verification formulas does not raise questions, the main question is how to calculate possible types of errors in the data, and by what indicators should they be identified? <br>  The possible types of data errors depend on the type of scale applicable to this data.  ( <i>A link to a wonderful post explaining what types of scales exist</i> - <a href="http://habrahabr.ru/post/246983/">http://habrahabr.ru/post/246983/</a> ). <br><br>  Closer to the practice in each of the transmitted data types in 95% of cases the following errors are possible: <br><br><table><tbody><tr><th>  Data types </th><th>  Inside the field </th><th>  In relation to other fields </th><th>  Compatibility of formats for transfer between systems </th></tr><tr><th>  Listing and text </th><td><ol><li>  Not from the list of allowed values </li><li>  No required values </li><li>  Non-compliance with the format ( <i>All contracts must be numbered "DGVxxxx .."</i> ) </li></ol><br></td><td><ol><li>  Not from the list of allowed values ‚Äã‚Äãfor a related item </li><li>  Missing required items for the associated item </li><li>  Non-compliance with the format for the associated element ( <i>for example: for the product "AIS" all contracts must be numbered "AISxxxx .."</i> ) </li></ol><br></td><td><ol><li>  Characters allowed in one format are not allowed in another </li><li>  Encoding </li><li>  Backward compatibility ( <i>Directory element was changed in the target system without adding mapping</i> ) </li><li>  New values ‚Äã‚Äã( <i>no mapping</i> ) </li><li>  Obsolete values ‚Äã‚Äã( <i>not from allowed list on target system</i> ) </li></ol><br></td></tr><tr><th>  Numbers and orders </th><td><ol><li>  Not a number </li><li>  Not within the allowed range of values </li><li>  The ordinal value is missing ( <i>for example: the data did not reach</i> ) </li></ol><br></td><td><ol><li>  The relation y = ax + b is not fulfilled ( <i>for example: VAT and Revenue, or Counter-sums are equal</i> ) </li><li>  Element "A" is assigned the wrong sequence number. </li><li>  Differences due to different rounding rules ( <i>for example, the calculated VAT never converges in 1C and SAP</i> ) </li></ol><br></td><td><ol><li>  Overflow </li><li>  Loss of accuracy and marks </li><li>  Incompatible formats when converting to a non-number </li></ol><br></td></tr><tr><th>  Dates and periods </th><td></td><td><ol><li>  Day of the week does not match the date </li><li>  The sum of time units does not correspond due to the difference of working / non-working / holiday / short days </li></ol><br></td><td><ol><li>  Date format incompatibility when transferring text ( <i>for example: ISO 8601 to UnixTime, or different formats to ISO 8601</i> ) </li><li> Error of reference point and accuracy when transmitting by number ( <i>for example: TimeStamp in DateTime</i> ) </li></ol><br></td></tr></tbody></table><br><br>  Accordingly, error checks are implemented either by formulas or by scripts in the editor of a specific ETL tool. <br>  And if at all, by and large, then most of your validations will be for matching directories, and this is [select * from a where a.field not in (select ...)] <br>  At the same time, in order to preserve the audit trail, it is reasonable to keep two separate tables in the system - rawdata and cleandata with 1: 1 connection support between the rows. <br><br><h5>  Mapping process </h5><br>  The mapping process is also implemented using the appropriate formulas and scripts, there are three good rules for its design: <br><br><ol><li>  The table of jammed data must include two sets of fields at the same time ‚Äî old and new analytics, so that you can make a select from the original analytics and see which target analysts are assigned to them, and vice versa: <br><br><img src="https://habrastorage.org/files/117/b45/d8d/117b45d8d76244d6a8060db8c56fee02.PNG"><br><br></li><li>  The table of locked elements must have a separate PK-field so that when connecting 1: * and *: * you can create many lines in MappedData for one line in CleanData and save the audit trail </li><li>  The MappedData table must be separate from CleanData for the same reasons as clause 2. </li></ol><br><br><h4>  Conclusion </h4><br>  In principle, these are all architectural techniques that I liked in the ETL tools I used. <br><br>  In addition, of course, there are also service processes in real systems ‚Äî authorization, access control to data, automated change reconciliation, and all solutions are of course a compromise with performance requirements and the maximum amount of data. <br><br>  I hope this information will be useful to you. </div><p>Source: <a href="https://habr.com/ru/post/248231/">https://habr.com/ru/post/248231/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../248217/index.html">Try / Catch / Finally</a></li>
<li><a href="../248219/index.html">Home automation with openHAB: lighting and remote control of heaters. Part 1</a></li>
<li><a href="../248225/index.html">Yandex investigation: full disclosure about the virus on Facebook</a></li>
<li><a href="../248227/index.html">Pivotal stops developing Groovy & Grails from March 31</a></li>
<li><a href="../248229/index.html">Binary operations on unordered sets</a></li>
<li><a href="../248235/index.html">I offer a custom .Net questionnaire</a></li>
<li><a href="../248239/index.html">Project Migration from StarTeam to SVN</a></li>
<li><a href="../248241/index.html">Books by Yii2</a></li>
<li><a href="../248243/index.html">Full customization of select without using JS</a></li>
<li><a href="../248249/index.html">Ubuntu Make - a developer to help</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>