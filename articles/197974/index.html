<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Investigation of the method of principal components and linear discriminant analysis on the change in the angle and conditions of the person‚Äôs illumination as an object of recognition</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day everyone. I am a graduate student. The topic of my dissertation is ‚ÄúDevelopment of image identification methods for providing individual acce...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Investigation of the method of principal components and linear discriminant analysis on the change in the angle and conditions of the person‚Äôs illumination as an object of recognition</h1><div class="post__text post__text-html js-mediator-article">  Good day everyone.  I am a graduate student.  The topic of my dissertation is ‚ÄúDevelopment of image identification methods for providing individual access in real time‚Äù. <br>  In my <a href="http://habrahabr.ru/post/197942/">first post</a> I wrote, not from the very beginning.  Here I start from the beginning. <br><br>  The recognition of a person by an image of a person is distinguished from biometric systems by the fact that, firstly, special or expensive equipment is not required, and secondly, physical contact with devices is not needed.  However, the recognition of a person by the image of the person does not provide 100% reliable identification. <br><br>  The peculiarity is to recognize a person by the image of a person, regardless of the change in angle and lighting conditions when shooting. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Such tasks do not have an exact analytical solution.  This requires the selection of key features that characterize the visual image, the determination of the relative importance of signs by selecting their weights and taking into account the relationship between signs.  Initially, these tasks were performed by a human expert, which took a lot of time and did not guarantee quality.  In new methods, the selection of key features is carried out by automatic analysis of the training set, but nevertheless, most of the information about the features is set manually.  For automatic application of such analyzers, the sample should be large enough and cover all possible situations. <br><br><a name="habracut"></a>  Neural network methods offer a different approach to solving the pattern recognition problem.  Weights in the neural network are not calculated by solving analytical equations, but are adjusted by various methods during training.  Neural networks are trained on a set of training examples.  A trained NA can be successfully used for recognizing a person under various conditions.  T.O.  the use of neural networks for the task of recognizing a person from the face is a promising direction. <br><br>  <b>Methods of identifying a person by a face</b> <br><br>  With all the variety of different algorithms and methods for image recognition, a typical recognition method consists of three components (Fig. 1): <br><br>  1. transformation of the original image into the initial representation (may include both preprocessing and mathematical transformations, for example, the computation of principal components); <br><br>  2. selection of key characteristics (for example, the first n principal components or coefficients of the discrete cosine transform are taken); <br><br>  3. classification mechanism (simulation): cluster model, metric, neural network, etc. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5d2/f9c/2f6/5d2f9c2f6e94cdfd6d88472ceaba6af5.png" alt="image"><br>  Fig.1.  The scheme of interrelation of structural elements of a typical image recognition method <br><br>  The established approaches to the identification of persons based on images of human faces are practically well established.  It is necessary to improve the existing algorithms in order to optimize the time and accuracy characteristics of the search that they provide by using key features extracted automatically from the person‚Äôs image (for example, gender, beard, glasses, face angle, etc.), and thus increase speed and accuracy of search. <br><br>  <b>Principal component method</b> <br><br>  The Principal Component Analysis (PCA) method is used to compress information without significant loss of information.  It consists in a linear orthogonal transformation of the input vector X of dimension N to the output vector Y of dimension M, where N&gt; M. <br><br>  <u>Benefits:</u> <br><br>  - if there are variations in a set of facial images, such as race, gender, emotions, lighting, components will appear, the magnitude of which is mainly determined by these factors.  Therefore, the values ‚Äã‚Äãof the respective principal components can be used to determine, for example, the race or sex of a person; <br><br>  - storage and search of images in large databases, image reconstruction. <br><br>  The underlying difficulty lies in the high demands on the conditions for shooting images.  Images should be obtained in similar lighting conditions, the same angle (decided by adding images to different training angles to the training sample) and high-quality pre-processing should be carried out, leading the images to standard conditions. <br><br>  <b>Method of linear discriminant analysis</b> <br><br>  Using the method of linear discriminant analysis (Linear Discriminant Analysis, LDA), choose the projection of the image space on the feature space in such a way as to minimize the intraclass and maximize the interclass distance in the feature space.  In these methods it is assumed that the classes are linearly separable. <br><br>  <u>Benefits:</u> <br><br>  - High recognition accuracy (about 94%) is noted for a wide range of lighting conditions, various facial expressions and the presence or absence of glasses. <br><br>  <u>Method problems:</u> <br><br>  - however, questions remain unclear whether this method is applicable to search in large databases, whether the method can work, when in the training sample for some individuals there is an image only in some light conditions; <br><br>  - there was also no change in the angle, and experiments with changing lighting were carried out without changing other factors.  Whether this method will work with such combinations is also unknown.  As in the method of own persons, there is also a need for high-quality pre-processing, which leads to images in standard conditions. <br><br>  The main goal of this work is to develop methods for identifying and building information retrieval systems for special applications (IPS SP), which provide automatic identification of a person‚Äôs identity in real time based on the image of his face. <br><br>  <u>Achieving the goal set in the work dictates the need to solve a number of the following main tasks:</u> <br><br>  - development of ‚Äúfast‚Äù algorithms for recognition and selection of the main characteristics of the image of a human face, ensuring high accuracy of identification of the object of search; <br><br>  - development of a storage and coding algorithm for auxiliary information characterizing the search object that provides acceptable volumetric-temporal indicators of the operation of the IPS SP; <br><br>  - development of an algorithm for reliable identification of persons based on information stored in the database of IPS SP; <br><br>  - development of a prototype IPS SP that implements the above algorithms in order to verify in practice the correctness of the theoretical conclusions made in this work and to issue recommendations for its further improvement based on the results of IPS SP pilot testing. <br>  The task was to compare the principal component method and the linear discriminant analysis (LDA) method.  The principal component method and the LDA method should be verified. <br><br>  To conduct research, programs in the C ++ Builder language have been developed that implement the principal component method and the LDA method.  Experimental studies were conducted using the ORL base, the FERET base and its own base of 15 people.  All bases contained images of different registration angles, with arbitrary facial expressions, different scale and registration conditions.  The purpose of this experiment was to assess the effectiveness of the recognition method for various number of K classes in the database (K = 4, 15, 40, 100, 200 and 395).  Evaluation of recognition efficiency for a small number of classes (K = 4, 15) showed that the minimum number of images in each class should not be less than 5, since the covariance matrices used in the PCA and LDA methods in this case become special and in this case cannot guarantee the stability of the reduction of the source feature space. <br><br>  The first and second components of the reduced features ƒπ (vxvy) are ‚Äúresponsible‚Äù for the turn and posture of the head, and the third is for the facial expression itself.  In this case, the influence of a component in the recognition process (as a result of choosing a close image) is the higher, the lower the sequence number of the component. <br><br>  The PCA and LDA methods were tested for the case when the source database is composed of two or more heterogeneous databases.  For this, 355 classes from the FERET database were added to 40 classes of the ORL database.  It should be noted that the added images had a lower resolution, a dark background, different lighting and size, as well as significant variations in the rotation of the face. <br><br>  Due to this difference in the source data in the space of reduced features, new features have appeared, grouped in a separate area regarding the features of the ORL database. <br><br>  The research results are summarized in table 1. <br><br>  Table 1. <br><br><table border="1"><tbody><tr><td rowspan="2">  The number of recognizable people </td><td rowspan="2">  Number of images of each person </td><td rowspan="2">  Number of images used for training </td><td colspan="2">  Error of the second kind (FRR) when using the correlation coefficient </td></tr><tr><td>  PCA </td><td>  Lda </td></tr><tr><td>  four </td><td>  ten </td><td>  five </td><td>  0,000 </td><td>  0,000 </td></tr><tr><td rowspan="2">  15 </td><td rowspan="2">  15 </td><td>  five </td><td>  0.333 </td><td>  0.063 </td></tr><tr><td>  ten </td><td>  0.230 </td><td>  0.133 </td></tr><tr><td rowspan="3">  40 </td><td rowspan="3">  ten </td><td>  3 </td><td>  0.330 </td><td>  0.122 </td></tr><tr><td>  five </td><td>  0.250 </td><td>  0.155 </td></tr><tr><td>  7 </td><td>  0.184 </td><td>  0.033 </td></tr><tr><td rowspan="2">  100 </td><td rowspan="2">  20 </td><td>  five </td><td>  0.197 </td><td>  0.056 </td></tr><tr><td>  7 </td><td>  0.176 </td><td>  0.104 </td></tr><tr><td rowspan="2">  200 </td><td rowspan="2">  20 </td><td>  five </td><td>  0.173 </td><td>  0.102 </td></tr><tr><td>  7 </td><td>  0.104 </td><td>  0.083 </td></tr><tr><td rowspan="2">  395 </td><td rowspan="2">  20 </td><td>  five </td><td>  0.083 </td><td>  0.064 </td></tr><tr><td>  7 </td><td>  0.080 </td><td>  0.046 </td></tr></tbody></table><br><br>  <u><b>Conclusion</b></u> <br><br>  From the above analysis it follows that to increase the probability of recognition, it is advisable to use a combination of both methods.  This requires further research. <br><br>  Literature <br>  1. Golovko V.A.  Neurointelligence: Theory and Applications.  Book 1. Organization and training of neural networks with direct and feedback - Brest: BPI, 1999, - 260s. <br>  2. Samal D.I., Starovoytov V.V.  - Approaches and methods of recognizing people by portraits.  - Minsk, ITK NASB, 1998. - 54s. <br>  3. Samal D.I., Starovoytov V.V.  Methods of automated recognition of people on portraits // Digital image processing.  - Minsk: ITK, 1999.-P.81-85. <br>  4. Voronovsky G.K., Makhotilo K.V., Petrashev S.N., Sergeev S.A.  - Genetic algorithms, artificial neural networks and virtual reality problems.  - Kharkov: Basis, 1997. <br><br>  Wait for the following articles :) </div><p>Source: <a href="https://habr.com/ru/post/197974/">https://habr.com/ru/post/197974/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../197960/index.html">Test of the world's first window cleaning robot Windoro</a></li>
<li><a href="../197962/index.html">The introduction of high-performance Pony ORM in the project Django</a></li>
<li><a href="../197964/index.html">The history of "Silk Road" gets on the big screen</a></li>
<li><a href="../197970/index.html">Fresh results of Techempower framework performance testing became available.</a></li>
<li><a href="../197972/index.html">Windows 8.1 in release</a></li>
<li><a href="../197976/index.html">Windows 8.1 and Visual Studio 2013 are available for download.</a></li>
<li><a href="../197978/index.html">Test on the knowledge of the agency digital market</a></li>
<li><a href="../197980/index.html">VMware Conference "Virtual Russia" (October 30) - Let's give two tickets in good hands</a></li>
<li><a href="../197982/index.html">A couple of interesting books for revolutionary startups</a></li>
<li><a href="../197984/index.html">JavaFX, HelloWorld + CSS + FXML. Ending</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>