<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Search Mediawiki with Sphinx</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, reader! 

 Some time ago, I was tasked with implementing MediaWiki in a corporate network. 
 And the main problem with this implementation was ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Search Mediawiki with Sphinx</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/f09/073/b8e/f09073b8e21d005d7b6feb0a7407ec06.jpg" alt="image"><br>  Hello, reader! <br><br>  Some time ago, I was tasked with implementing MediaWiki in a corporate network. <br>  And the main problem with this implementation was the search for information contained in the wiki. <br>  In this article, I would like to talk about how to make Sphinx search friendly with MediaWiki. <br>  The reason I would like to write this is the lack of Russian-language documentation and more or less decent guidance or description that would help my colleagues quickly and simply start using this excellent search engine. <br>  Maybe I just do not know how to use Google ... <br><a name="habracut"></a><br><h4>  Why do you need it </h4><br>  The purpose of this implementation in our organization is to transfer the corporate knowledge base to a more convenient format for presenting and correcting / adding. <br><br>  By the way - our company implements projects for the automation of documents in the complex. <br>  Customers are large, solutions are complex and sometimes non-standard. <br>  And articles on the wiki are supposed to have not only about projects, but also about technical solutions, features, etc., innovative methods and technologies. <br>  And also plans to use it as a source of information for new employees ‚Äî they have to study a fairly decent amount of information and the convenience of accessing it at the moment leaves much to be desired. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As mentioned above, the popular MediaWiki engine was taken as a basis.  And the key problem that I predicted at the very beginning was the problem of information retrieval. <br>  Everyone knows that the standard search is completely bad.  And the question became natural - how to correct this misunderstanding. <br><br><h4>  Training </h4><br>  So, everything is deployed on Windows Server 2012 R2 64bit, IIS is naturally raised: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/012/d14/4bc/012d144bcba52d642c8958159820f80c.jpg" alt="image"><br><br>  The latest version at the time of installation.  The SphinxSearch extension on the screenshot is already connected.  How to do this I will write below. <br><br>  It is necessary to download the search engine itself <a href="http://sphinxsearch.com/downloads/">from the official site</a> .  I chose 2.1.9-release (July 2014). <br>  You also need to download the extension for MediaWiki. <br>  I took it <a href="https://git.wikimedia.org/tree/mediawiki%252Fextensions%252FSphinxSearch">on GIT WikiMedia</a> <br>  Version 0.9.0 was up to date. <br><br><h4>  Installing and configuring the search engine Sphinx </h4><br>  After downloading the engine, I unpacked it in C: \ inetpub \ wwwroot \ mw \ sphinx). <br>  The next step is to prepare the config.  As a basis, I took the file sphinx.conf.in <br>  I got this kind of work, which I quote here with comments. <br><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta"># data source definition for the main index source src_wiki_main { type = mysql # data source sql_host= 127.0.0.1 # localhost      Win7+  sql_user= mwuser sql_pass= sql_db= sql_port= 3306# optional, default is 3306 # pre-query, executed before the main fetch query.      sql_query_pre= SET NAMES utf8 # main document fetch query - change the table names </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> you are using a prefix #        . sql_query= SELECT page_id, page_title, page_namespace, page_is_redirect, old_id, old_text FROM page, revision, text WHERE rev_id=page_latest AND old_id=rev_text_id # attribute columns sql_attr_uint= page_namespace sql_attr_uint= page_is_redirect sql_attr_uint= old_id # collect all category ids for category filtering sql_attr_multi = uint category from query; SELECT cl_from, page_id AS category FROM categorylinks, page WHERE page_title=cl_to AND page_namespace=14 # used by command-</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> search utility to display document information sql_query_info= SELECT page_title, page_namespace FROM page WHERE page_id=$id } # data source definition for the incremental index source src_wiki_incremental : src_wiki_main { # adjust this query based on the time you run the full index # in this case, full index runs at 7 AM UTC sql_query= SELECT page_id, page_title, page_namespace, page_is_redirect, old_id, old_text FROM page, revision, text WHERE rev_id=page_latest AND old_id=rev_text_id AND page_touched&gt;=DATE_FORMAT(CURDATE(), </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">'%Y%m%d070000'</span></span></span><span class="hljs-meta">) #     plain type = plain } # main index definition index wiki_main { type = plain # which document source to index source= src_wiki_main # this is path and index file name without extension # you may need to change this path or create this folder path= C:/inetpub/wwwroot/mw/sphinx/data/wiki_main # docinfo (ie. per-document attribute values) storage strategy docinfo= extern # morphology morphology= stem_en, stem_ru # stopwords file #stopwords= /var/data/sphinx/stopwords.txt # minimum word length min_word_len= 1 # allow wildcard (*) searches min_infix_len = 1 enable_star = 1 # charset encoding type charset_type= utf-8 # charset definition and case folding rules </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"table"</span></span></span><span class="hljs-meta"> #       .        . charset_table= 0..9, A..Z-&gt;a..z, a..z, \ U+C0-&gt;a, U+C1-&gt;a, U+C2-&gt;a, U+C3-&gt;a, U+C4-&gt;a, U+C5-&gt;a, U+C6-&gt;a, \ U+C7-&gt;c,U+E7-&gt;c, U+C8-&gt;e, U+C9-&gt;e, U+CA-&gt;e, U+CB-&gt;e, U+CC-&gt;i, \ U+CD-&gt;i, U+CE-&gt;i, U+CF-&gt;i, U+D0-&gt;d, U+D1-&gt;n, U+D2-&gt;o, U+D3-&gt;o, \ U+D4-&gt;o, U+D5-&gt;o, U+D6-&gt;o, U+D8-&gt;o, U+D9-&gt;u, U+DA-&gt;u, U+DB-&gt;u, \ U+DC-&gt;u, U+DD-&gt;y, U+DE-&gt;t, U+DF-&gt;s, \ U+E0-&gt;a, U+E1-&gt;a, U+E2-&gt;a, U+E3-&gt;a, U+E4-&gt;a, U+E5-&gt;a, U+E6-&gt;a, \ U+E7-&gt;c,U+E7-&gt;c, U+E8-&gt;e, U+E9-&gt;e, U+EA-&gt;e, U+EB-&gt;e, U+EC-&gt;i, \ U+ED-&gt;i, U+EE-&gt;i, U+EF-&gt;i, U+F0-&gt;d, U+F1-&gt;n, U+F2-&gt;o, U+F3-&gt;o, \ U+F4-&gt;o, U+F5-&gt;o, U+F6-&gt;o, U+F8-&gt;o, U+F9-&gt;u, U+FA-&gt;u, U+FB-&gt;u, \ U+FC-&gt;u, U+FD-&gt;y, U+FE-&gt;t, U+FF-&gt;s, U+410..U+42F-&gt;U+430..U+44F, \ U+430..U+44F, U+0400-&gt;U+0435, U+0401-&gt;U+0435, U+0402-&gt;U+0452, \ U+0452, U+0403-&gt;U+0433, U+0404-&gt;U+0454, U+0454, U+0405-&gt;U+0455, \ U+0455, U+0406-&gt;U+0456, U+0407-&gt;U+0456, U+0457-&gt;U+0456, U+0456, \ U+0408..U+040B-&gt;U+0458..U+045B, U+0458..U+045B, U+040C-&gt;U+043A, \ U+040D-&gt;U+0438, U+040E-&gt;U+0443, U+040F-&gt;U+045F, U+045F, \ U+0450-&gt;U+0435, U+0451-&gt;U+0435, U+0453-&gt;U+0433, U+045C-&gt;U+043A, \ U+045D-&gt;U+0438, U+045E-&gt;U+0443, U+0460-&gt;U+0461, U+0461, U+0462-&gt;U+0463, \ U+0463, U+0464-&gt;U+0465, U+0465, U+0466-&gt;U+0467, U+0467, U+0468-&gt;U+0469, \ U+0469, U+046A-&gt;U+046B, U+046B, U+046C-&gt;U+046D, U+046D, U+046E-&gt;U+046F, \ U+046F, U+0470-&gt;U+0471, U+0471, U+0472-&gt;U+0473, U+0473, U+0474-&gt;U+0475, \ U+0476-&gt;U+0475, U+0477-&gt;U+0475, U+0475, U+0478-&gt;U+0479, U+0479, \ U+047A-&gt;U+047B, U+047B, U+047C-&gt;U+047D, U+047D, U+047E-&gt;U+047F, U+047F, \ U+0480-&gt;U+0481, U+0481, U+048A-&gt;U+0438, U+048B-&gt;U+0438, U+048C-&gt;U+044C, \ U+048D-&gt;U+044C, U+048E-&gt;U+0440, U+048F-&gt;U+0440, U+0490-&gt;U+0433, \ U+0491-&gt;U+0433, U+0490-&gt;U+0433, U+0491-&gt;U+0433, U+0492-&gt;U+0433, \ U+0493-&gt;U+0433, U+0494-&gt;U+0433, U+0495-&gt;U+0433, U+0496-&gt;U+0436, \ U+0497-&gt;U+0436, U+0498-&gt;U+0437, U+0499-&gt;U+0437, U+049A-&gt;U+043A, \ U+049B-&gt;U+043A, U+049C-&gt;U+043A, U+049D-&gt;U+043A, U+049E-&gt;U+043A, \ U+049F-&gt;U+043A, U+04A0-&gt;U+043A, U+04A1-&gt;U+043A, U+04A2-&gt;U+043D, \ U+04A3-&gt;U+043D, U+04A4-&gt;U+043D, U+04A5-&gt;U+043D, U+04A6-&gt;U+043F, \ U+04A7-&gt;U+043F, U+04A8-&gt;U+04A9, U+04A9, U+04AA-&gt;U+0441, U+04AB-&gt;U+0441, \ U+04AC-&gt;U+0442, U+04AD-&gt;U+0442, U+04AE-&gt;U+0443, U+04AF-&gt;U+0443, U+04B0-&gt;U+0443, \ U+04B1-&gt;U+0443, U+04B2-&gt;U+0445, U+04B3-&gt;U+0445, U+04B4-&gt;U+04B5, U+04B5, \ U+04B6-&gt;U+0447, U+04B7-&gt;U+0447, U+04B8-&gt;U+0447, U+04B9-&gt;U+0447, U+04BA-&gt;U+04BB, \ U+04BB, U+04BC-&gt;U+04BD, U+04BE-&gt;U+04BD, U+04BF-&gt;U+04BD, U+04BD, U+04C0-&gt;U+04CF, \ U+04CF, U+04C1-&gt;U+0436, U+04C2-&gt;U+0436, U+04C3-&gt;U+043A, U+04C4-&gt;U+043A, \ U+04C5-&gt;U+043B, U+04C6-&gt;U+043B, U+04C7-&gt;U+043D, U+04C8-&gt;U+043D, U+04C9-&gt;U+043D, \ U+04CA-&gt;U+043D, U+04CB-&gt;U+0447, U+04CC-&gt;U+0447, U+04CD-&gt;U+043C, U+04CE-&gt;U+043C, \ U+04D0-&gt;U+0430, U+04D1-&gt;U+0430, U+04D2-&gt;U+0430, U+04D3-&gt;U+0430, U+04D4-&gt;U+00E6, \ U+04D5-&gt;U+00E6, U+04D6-&gt;U+0435, U+04D7-&gt;U+0435, U+04D8-&gt;U+04D9, U+04DA-&gt;U+04D9, \ U+04DB-&gt;U+04D9, U+04D9, U+04DC-&gt;U+0436, U+04DD-&gt;U+0436, U+04DE-&gt;U+0437, \ U+04DF-&gt;U+0437, U+04E0-&gt;U+04E1, U+04E1, U+04E2-&gt;U+0438, U+04E3-&gt;U+0438, \ U+04E4-&gt;U+0438, U+04E5-&gt;U+0438, U+04E6-&gt;U+043E, U+04E7-&gt;U+043E, U+04E8-&gt;U+043E, \ U+04E9-&gt;U+043E, U+04EA-&gt;U+043E, U+04EB-&gt;U+043E, U+04EC-&gt;U+044D, U+04ED-&gt;U+044D, \ U+04EE-&gt;U+0443, U+04EF-&gt;U+0443, U+04F0-&gt;U+0443, U+04F1-&gt;U+0443, U+04F2-&gt;U+0443, \ U+04F3-&gt;U+0443, U+04F4-&gt;U+0447, U+04F5-&gt;U+0447, U+04F6-&gt;U+0433, U+04F7-&gt;U+0433, \ U+04F8-&gt;U+044B, U+04F9-&gt;U+044B, U+04FA-&gt;U+0433, U+04FB-&gt;U+0433, U+04FC-&gt;U+0445, \ U+04FD-&gt;U+0445, U+04FE-&gt;U+0445, U+04FF-&gt;U+0445, U+0410..U+0418-&gt;U+0430..U+0438, \ U+0419-&gt;U+0438, U+0430..U+0438, U+041A..U+042F-&gt;U+043A..U+044F, U+043A..U+044F, } # incremental index definition index wiki_incremental : wiki_main { type = plain path= C:/inetpub/wwwroot/mw/sphinx/data/wiki_incremental } # indexer settings indexer { # memory limit (default is 32M) mem_limit= 64M } # searchd settings searchd { # IP address and port on which search daemon will bind and accept listen= 127.0.0.1:9312 # searchd run info is logged here - create or change the folder log= C:/inetpub/wwwroot/mw/sphinx/log/searchd.log # all the search queries are logged here query_log= C:/inetpub/wwwroot/mw/sphinx/log/query.log # client read timeout, seconds read_timeout= 5 # maximum amount of children to fork max_children= 30 # a file which will contain searchd process ID pid_file= C:/inetpub/wwwroot/mw/sphinx/log/searchd.pid # maximum amount of matches this daemon would ever retrieve # from each index and serve to client max_matches= 1000 workers = threads } # --eof--</span></span></code> </pre> <br><br>  This completes the configuration of the Sphinx. <br><br><h4>  Install Search Service </h4><br>  Now we install our service. <br>  To do this, write the command line <br> <code>C:/inetpub/wwwroot/mw/sphinx/bin/searchd --install --config C:/inetpub/wwwroot/mw/sphinx/bin/sphinx.conf --servicename SphinxSearch</code> <br>  Everything should go without errors and the service should be installed and become visible through the Administration - Services under the name SphinxSearch. <br>  While it is not worth running it because  the data is not indexed yet and we get an error when starting the service. <br>  It is worth noting that the slashes are used exactly such /, and not such \.  Otherwise, there will be an error of access to the log files and PID files of the search engine processes. <br>  I also note that the conf file is in the folder with binaries (bin), so that when running through the console, do not write the path to the config. <br>  But when installing the service, it is better to write the path the config is. <br><br>  Now in the command line, go to the folder with binaries (bin) and write <br> <code>indexer --all</code> <br>  We get a result like this: <br><pre> <code class="cpp hljs"> Sphinx <span class="hljs-number"><span class="hljs-number">2.1</span></span><span class="hljs-number"><span class="hljs-number">.9</span></span>-release (r4761) Copyright (c) <span class="hljs-number"><span class="hljs-number">2001</span></span><span class="hljs-number"><span class="hljs-number">-2014</span></span>, <span class="hljs-function"><span class="hljs-function">Andrew Aksyonoff </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Copyright</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(c)</span></span></span><span class="hljs-function"> 2008-2014, Sphinx Technologies </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Inc</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(http:</span></span><span class="hljs-comment"><span class="hljs-function"><span class="hljs-params"><span class="hljs-comment">//sphinxsearch.com) using config file './sphinx.conf'... indexing index 'wiki_main'... collected 159 docs, 0.5 MB collected 0 attr values sorted 0.0 Mvalues, 100.0% done sorted 1.6 Mhits, 100.0% done total 159 docs, 494176 bytes total 0.596 sec, 827807 bytes/sec, 266.34 docs/sec indexing index 'wiki_incremental'... collected 159 docs, 0.5 MB collected 0 attr values sorted 0.0 Mvalues, 100.0% done sorted 1.6 Mhits, 100.0% done total 159 docs, 494176 bytes total 0.584 sec, 844808 bytes/sec, 271.81 docs/sec total 4 reads, 0.005 sec, 2107.7 kb/call avg, 1.4 msec/call avg total 38 writes, 0.022 sec, 479.7 kb/call avg, 0.5 msec/call avg</span></span></span></span></span></span></code> </pre><br>  Everything, the index is created. <br><br><h4>  Check the operation of the search engine </h4><br>  As it turned out, the index was created.  In the command line, we are still in the binary directory.  Now we start our SphinxSearch service and on the command line we write something like: <br><br> <code>search wiki</code> <br> <br>  I got this result: <br><br><pre> <code class="cpp hljs"> Sphinx <span class="hljs-number"><span class="hljs-number">2.1</span></span><span class="hljs-number"><span class="hljs-number">.9</span></span>-release (r4761) Copyright (c) <span class="hljs-number"><span class="hljs-number">2001</span></span><span class="hljs-number"><span class="hljs-number">-2014</span></span>, <span class="hljs-function"><span class="hljs-function">Andrew Aksyonoff </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Copyright</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(c)</span></span></span><span class="hljs-function"> 2008-2014, Sphinx Technologies </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Inc</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(http:</span></span><span class="hljs-comment"><span class="hljs-function"><span class="hljs-params"><span class="hljs-comment">//sphinxsearch.com) using config file './sphinx.conf'... index 'wiki_main': query 'wiki ': returned 13 matches of 13 total in 0.004 sec displaying matches: 1. document=76, weight=1719, page_namespace=0, page_is_redirect=0, old_id=929, c ategory=() page_title=???????_CompanyNameWiki page_namespace=0 2. document=77, weight=1670, page_namespace=0, page_is_redirect=0, old_id=1136, category=() page_title=FAQ_CompanyNameWiki page_namespace=0 3. document=79, weight=1670, page_namespace=0, page_is_redirect=0, old_id=864, c ategory=() page_title=CompanyNameWiki:_????? page_namespace=0 4. document=81, weight=1670, page_namespace=12, page_is_redirect=0, old_id=939, category=() page_title=C???????_?????_?????? page_namespace=12 5. document=128, weight=1670, page_namespace=0, page_is_redirect=0, old_id=1075, category=() page_title=????? page_namespace=0 6. document=1, weight=1648, page_namespace=0, page_is_redirect=0, old_id=1091, c ategory=() page_title=?????????_???????? page_namespace=0 7. document=4, weight=1648, page_namespace=0, page_is_redirect=0, old_id=10, cat egory=() page_title=?????????_???????? page_namespace=0 8. document=5, weight=1648, page_namespace=0, page_is_redirect=0, old_id=181, ca tegory=() page_title=?????????_?????????_????_(???????_??????) page_namespace=0 9. document=2, weight=1608, page_namespace=8, page_is_redirect=0, old_id=1135, c ategory=() page_title=Sidebar page_namespace=8 10. document=12, weight=1608, page_namespace=0, page_is_redirect=0, old_id=719, category=() page_title=?????????_CRM page_namespace=0 11. document=71, weight=1608, page_namespace=0, page_is_redirect=0, old_id=701, category=() page_title=??????_??????? page_namespace=0 12. document=80, weight=1608, page_namespace=12, page_is_redirect=0, old_id=862, category=() page_title=?????????_CompanyNameWiki page_namespace=12 13. document=129, weight=1608, page_namespace=0, page_is_redirect=0, old_id=1085 , category=() page_title=???? page_namespace=0 words: 1. 'wiki': 13 documents, 37 hits index 'wiki_incremental': query 'wiki ': returned 13 matches of 13 total in 0.00 0 sec displaying matches: 1. document=76, weight=1719, page_namespace=0, page_is_redirect=0, old_id=929, c ategory=() page_title=???????_CompanyNameWiki page_namespace=0 2. document=77, weight=1670, page_namespace=0, page_is_redirect=0, old_id=1136, category=() page_title=FAQ_CompanyNameWiki page_namespace=0 3. document=79, weight=1670, page_namespace=0, page_is_redirect=0, old_id=864, c ategory=() page_title=CompanyNameWiki:_????? page_namespace=0 4. document=81, weight=1670, page_namespace=12, page_is_redirect=0, old_id=939, category=() page_title=C???????_?????_?????? page_namespace=12 5. document=128, weight=1670, page_namespace=0, page_is_redirect=0, old_id=1075, category=() page_title=????? page_namespace=0 6. document=1, weight=1648, page_namespace=0, page_is_redirect=0, old_id=1091, c ategory=() page_title=?????????_???????? page_namespace=0 7. document=4, weight=1648, page_namespace=0, page_is_redirect=0, old_id=10, cat egory=() page_title=?????????_???????? page_namespace=0 8. document=5, weight=1648, page_namespace=0, page_is_redirect=0, old_id=181, ca tegory=() page_title=?????????_?????????_????_(???????_??????) page_namespace=0 9. document=2, weight=1608, page_namespace=8, page_is_redirect=0, old_id=1135, c ategory=() page_title=Sidebar page_namespace=8 10. document=12, weight=1608, page_namespace=0, page_is_redirect=0, old_id=719, category=() page_title=?????????_CRM page_namespace=0 11. document=71, weight=1608, page_namespace=0, page_is_redirect=0, old_id=701, category=() page_title=??????_??????? page_namespace=0 12. document=80, weight=1608, page_namespace=12, page_is_redirect=0, old_id=862, category=() page_title=?????????_CompanyNameWiki page_namespace=12 13. document=129, weight=1608, page_namespace=0, page_is_redirect=0, old_id=1085 , category=() page_title=???? page_namespace=0 words: 1. 'wiki': 13 documents, 37 hits</span></span></span></span></span></span></code> </pre><br><br>  Due to the fact that there is a difference in encodings, we received "?????", and not Russian letters.  But the main thing is present issue.  So the search works! <br><br>  That's all, we installed sphinx, indexed our database and have a working search engine! <br><br><h4>  Index Update Automation </h4><br>  For the full work of the search, it is also necessary to ensure regular updating of the index - after all, articles are added and it is necessary to ensure their availability in search results including. <br><br>  To do this, in the task scheduler we will create a task with the launch frequency (I have 5 minutes) a bat file with the following content: <br> <code>c:\inetpub\wwwroot\mw\sphinx\bin\indexer --all --config c:\inetpub\wwwroot\mw\sphinx\bin\sphinx.conf --rotate</code> <br> <br>  I did a job launch on behalf of a local administrator.  You must first explicitly assign rights to the entire sphinx folder. <br><br><h4>  Connect Search Sphinx in Mediawiki </h4><br>  Now you need to connect the search engine to Mediawiki.  Otherwise, the latter doesn‚Äôt know in any way what to look for without the built-in mechanism, but with the help of the sphinx. <br><br>  Go to the file LocalSettings.php (It lies in the folder with the media) and add there: <br><br><pre> <code class="cpp hljs"> #Sphinx search $wgSearchType = <span class="hljs-string"><span class="hljs-string">'SphinxMWSearch'</span></span>; require_once <span class="hljs-string"><span class="hljs-string">"$IP/extensions/SphinxSearch/SphinxSearch.php"</span></span>; $wgSphinxSearch_host = <span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span>; $wgSphinxSearch_port = <span class="hljs-number"><span class="hljs-number">9312</span></span>; $wgSphinxSearch_matches = <span class="hljs-number"><span class="hljs-number">50</span></span>; $wgEnableSphinxPrefixSearch = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; $wgFooterIcons[<span class="hljs-string"><span class="hljs-string">'poweredby'</span></span>][<span class="hljs-string"><span class="hljs-string">'sphinxsearch'</span></span>] = <span class="hljs-built_in"><span class="hljs-built_in">array</span></span>( <span class="hljs-string"><span class="hljs-string">'src'</span></span> =&gt; <span class="hljs-string"><span class="hljs-string">"$wgScriptPath/extensions/SphinxSearch/skins/images/Powered_by_sphinx.png"</span></span>, <span class="hljs-string"><span class="hljs-string">'url'</span></span> =&gt; <span class="hljs-string"><span class="hljs-string">'http://www.mediawiki.org/wiki/Extension:SphinxSearch'</span></span>, <span class="hljs-string"><span class="hljs-string">'alt'</span></span> =&gt; <span class="hljs-string"><span class="hljs-string">'Search Powered by Sphinx'</span></span>, );</code> </pre><br><br>  Create a new folder in the extensions folder named SphinxSearch. <br>  important note left <a href="https://habrahabr.ru/users/vedmaka/" class="user_link">vedmaka</a> : <br>  Add: after installing sphinx you need to go to <a href="http://sphinxsearch.com/downloads/archive/">http://sphinxsearch.com/downloads/archive/</a> , download the source version of the corresponding version from there and upload the sphinxapi.php file to the directory with the SphinxSearch extension. <br><br>  We save.  Restart the site through the IIS manager.  We check the search by hand through the Mediawiki webpage.  Everything should work. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b4/0d5/750/6b40d5750b1943d28d5bbdf50de184eb.jpg" alt="image"><br>  Issuance when typing in the search box. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0ca/55b/14c/0ca55b14c4f48c836186ad622f6b4020.jpg" alt="image"><br>  And the search results itself. <br><br><h4>  Conclusion </h4><br>  As a result, we received a better search through the materials in our wiki. <br>  In the default output, the sort is set to SPH_SORT_RELEVANCE. <br>  If desired, it can be changed by explicitly specifying the <code>LocalSettings.php</code> file through the parameter <br><br> <code>$wgSphinxSearch_sortby</code> <br> <br>  More information about the various options for sorting the issue can be found <a href="http://sphinxsearch.com/docs/current.html">in this section of the documentation</a> . <br><br>  In this article, I used not only personal insights, but also information gathered in the process of implementing work with this search engine. <br><br>  I did not consider possible errors that may occur in the process.  I considered it right to share a working configuration, as well as a sequence of actions that ultimately lead to the work of the decision as a whole.  And these errors were the sea, starting from the lack of rights to the files, "not those" with slashes and ending with the inoperability of the Sphinx configuration supplied with the extension. </div><p>Source: <a href="https://habr.com/ru/post/230073/">https://habr.com/ru/post/230073/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../230055/index.html">Google announces Project Zero</a></li>
<li><a href="../230057/index.html">Coursera in Russian: about achievements and awards</a></li>
<li><a href="../230059/index.html">Creating a project management system at Yandex Tolstoy Camp</a></li>
<li><a href="../230063/index.html">Email: Email Tracking Services</a></li>
<li><a href="../230065/index.html">Creating a new module for open-source CRM EspoCRM</a></li>
<li><a href="../230075/index.html">Latent semantic analysis and artificial intelligence (LSA and AI)</a></li>
<li><a href="../230079/index.html">JSON Recording</a></li>
<li><a href="../230081/index.html">Create game character</a></li>
<li><a href="../230083/index.html">What is wrong with Angara-1.2PP</a></li>
<li><a href="../230085/index.html">Remote access for mobile devices: managed and cloud VPN services</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>