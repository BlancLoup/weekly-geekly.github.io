<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hacker's guide to neural networks. Chapter 2: Machine Learning. Binary classification</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content: 
 Chapter 1: Real Value Schemes  Part 1: 


 : ‚Ññ1:   
 Part 2: 


  ‚Ññ2:  
 Part 3: 


  ‚Ññ3:  
 Part 4: 


   
 Part 5: 


  ¬´¬ª " " 
 Part 6: ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hacker's guide to neural networks. Chapter 2: Machine Learning. Binary classification</h1><div class="post__text post__text-html js-mediator-article">  Content: <br><div class="spoiler">  <b class="spoiler_title">Chapter 1: Real Value Schemes</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/paysto/blog/244723/">Part 1:</a> <br><pre><code class="html hljs xml">  :        ‚Ññ1:   </code> </pre> <br>  <a href="http://habrahabr.ru/company/paysto/blog/244935/">Part 2:</a> <br><pre> <code class="html hljs xml">  ‚Ññ2:  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/245051/">Part 3:</a> <br><pre> <code class="html hljs xml">  ‚Ññ3:  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/245403/">Part 4:</a> <br><pre> <code class="javascript hljs">        </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246093/">Part 5:</a> <br><pre> <code class="javascript hljs">   ¬´¬ª   <span class="hljs-string"><span class="hljs-string">" "</span></span></code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246397/">Part 6:</a> <br><pre> <code class="javascript hljs">     </code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Chapter 2: Machine Learning</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/paysto/blog/246523/">Part 7:</a> <br><pre> <code class="javascript hljs">  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246849/">Part 8:</a> <br><pre> <code class="javascript hljs">        (SVM)</code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246973/">Part 9:</a> <br><pre> <code class="javascript hljs">  SVM   </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/247033/">Part 10:</a> <br><pre> <code class="javascript hljs">   :  </code> </pre><br></div></div><br><br>  In the last chapter, we looked at schemes with real values ‚Äã‚Äãthat computed complex expressions of their original values ‚Äã‚Äã(pass forward), and also we were able to calculate the gradients of these expressions from the original original values ‚Äã‚Äã(back pass).  In this chapter we will understand how useful this rather simple mechanism in learning a machine can be. <br><a name="habracut"></a><br>  <b>Binary classification</b> <br><br>  As before, let's start with a simple one.  The most simple, standard and quite common machine learning problem is binary classification.  Many interesting and important problems can be reduced to it.  For example, we are given a data set of N vectors and each of them is labeled with the value +1 or -1.  In a two-dimensional form, our data set may look like this: <br>  vector -&gt; label <br><pre> <code class="javascript hljs">--------------- [<span class="hljs-number"><span class="hljs-number">1.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.7</span></span>] -&gt; +<span class="hljs-number"><span class="hljs-number">1</span></span> [<span class="hljs-number"><span class="hljs-number">-0.3</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>] -&gt; <span class="hljs-number"><span class="hljs-number">-1</span></span> [<span class="hljs-number"><span class="hljs-number">-3</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>] -&gt; +<span class="hljs-number"><span class="hljs-number">1</span></span> [<span class="hljs-number"><span class="hljs-number">0.1</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>] -&gt; <span class="hljs-number"><span class="hljs-number">-1</span></span> [<span class="hljs-number"><span class="hljs-number">3.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.1</span></span>] -&gt; <span class="hljs-number"><span class="hljs-number">-1</span></span> [<span class="hljs-number"><span class="hljs-number">2.1</span></span>, <span class="hljs-number"><span class="hljs-number">-3</span></span>] -&gt; +<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Here we have N = 6 data entry points, where each point has two characteristics (D = 2).  Three data points have a +1 mark, and the other three have a -1 mark.  This is the simplest example, but in practice, a data set of + 1 / -1 can be really useful: for example, identifying spam / not spam among emails, in which vectors somehow evaluate various characteristics of the content of letters, such as the number of mentions of a certain magic tool . <br><br>  Purpose.  Our goal in binary classification is to deal with a function that accepts a two-dimensional vector and predicts a label.  This function is usually parameterized by a specific set of parameters, and we need to adjust the parameters of this function so that its results match the labels in the given data set.  Ultimately, we can discard the data set and use the detected parameters to predict labels for previously unknown vectors. <br><br>  <b>Training protocol</b> <br><br>  We will finally start building whole neural networks and complex expressions, but let's start with a simple one and teach a linear classifier that is very similar to one neuron that we looked at at the end of Chapter 1. The only difference is that we will give up sigmoids, because it unnecessarily complicates everything (I used it only as an example in Chapter 1, since historically sigmoid neurons are popular, although modern neural networks rarely use non-linearity sigmoids).  In any case, let's take a simple linear function: <b>f (x, y) = ax + by + c</b> <br><br>  In this expression, we consider <b>x</b> and <b>y</b> as the initial values ‚Äã‚Äã(two-dimensional vectors), and <b>a, b, c</b> as the function parameters that we need to know.  For example, if a = 1, b = -2, c = -1, then the function will take the first data entry point ([1.2, 0.7]) and the result will be 1 * 1.2 + (-2) * 0.7 + (-1) = -1.2.  This is how the training will work: <br><br>  1. We select an arbitrary data entry point and draw it through the circuit. <br><br>  2. We interpret the result of the scheme to ensure that the data entry point has a class of +1 (that is, very high values: the scheme is absolutely sure that the data entry point has a class of +1, and very low values: the scheme is absolutely sure that data entry point has class -1). <br><br>  3. We measure how well the forecast builds the presented labels.  To show clearly - for example, if a positive example gives out very low values, we will need to pull it up in a positive direction according to the scheme, requiring it to give a higher value for this data entry point.  Notice that this is an example for the first data entry point: it has a +1 mark, but our prediction function assigns it a value of -1.2.  Therefore, we push it according to a scheme in a positive direction.  We need the value to be higher. <br><br>  4. The scheme will take a push and respond back to the error to calculate the push to the original values <b>a, b, c, x, y</b> . <br><br>  5. Since we consider x, y as (fixed) data entry points, we will ignore the tension in relation to x, y.  If you like my physical analogies, then imagine these original values ‚Äã‚Äãas pegs driven into the ground. <br><br>  6. On the other hand, we will take the parameters a, b, c and make them respond to their push (i.e. we will perform the so-called update of the parameters).  This, of course, can cause the circuit to produce slightly higher values ‚Äã‚Äãat this particular data entry point in the future. <br><br>  7. Repeat!  Go back to step 1. <br><br>  The learning scheme I described above generally relates to the Stochastic Gradient Descent.  An interesting point that I would like to repeat once again is that <b>a, b, c, x, y</b> consist of the same elements, as far as the scheme can provide: they are the initial values ‚Äã‚Äãof the scheme, and the scheme will push them all in a certain way. direction.  She does not know the difference between the parameters and data entry points.  However, after the completion of the back pass, we ignore all the jolts at the data points (x, y) and continue to load and unload them as our examples in the data set repeat.  On the other hand, we save the parameters (a, b, c) and continue to push them every time we measure a data entry point.  Over time, the tension with respect to these parameters will adjust these values ‚Äã‚Äãin such a way that the function will produce high values ‚Äã‚Äãfor positive examples and low values ‚Äã‚Äãfor negative ones. </div><p>Source: <a href="https://habr.com/ru/post/246523/">https://habr.com/ru/post/246523/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../246511/index.html">MultiCAD.NET: calculation of the total length of the segments in the drawing</a></li>
<li><a href="../246515/index.html">How I was looking for an idea for a startup in Silicon Valley</a></li>
<li><a href="../246517/index.html">We connect NTFS to write to Mac OS X Yosemite 10.10</a></li>
<li><a href="../246519/index.html">How we did cashback service kubish.ru</a></li>
<li><a href="../246521/index.html">LIVR - ‚Äúlanguage independent validation rules‚Äù or data validation without ‚Äúproblems‚Äù</a></li>
<li><a href="../246525/index.html">ReactOS Tech Talk at the faculty of the VMK MSU</a></li>
<li><a href="../246527/index.html">Redmine task requests. How we improved them and how we use them</a></li>
<li><a href="../246533/index.html">Trends iOS development 2014</a></li>
<li><a href="../246537/index.html">Announcement of new services and increased performance of the Azure cloud platform</a></li>
<li><a href="../246545/index.html">Interkassa: beware of hidden fees, PayPal conversion is now more attractive than conversion rates of many banks</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>