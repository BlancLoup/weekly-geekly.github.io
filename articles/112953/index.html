<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What you need to know about floating-point arithmetic</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the distant past, for the IT industry in the 70s of the last century, mathematics scientists (as programmers used to be called) fought like Don Qui...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What you need to know about floating-point arithmetic</h1><div class="post__text post__text-html js-mediator-article"><img align="left" src="https://habrastorage.org/getpro/habr/post_images/200/96c/9dd/20096c9dd85a9a34da4a5b34f2af0a07.jpg"><br><br>  In the distant past, for the IT industry in the 70s of the last century, mathematics scientists (as programmers used to be called) fought like Don Quixote in an unequal battle with computers that were then the size of small windmills.  The tasks were serious: the search for enemy submarines in the ocean from images from orbit, the calculation of the ballistics of long-range missiles, and so on.  To solve them, the computer must operate with real numbers, which, as is known, are a continuum, while memory is finite.  Therefore, it is necessary to map this continuum to a finite set of zeros and ones.  In search of a compromise between speed, size and accuracy of presentation, scientists proposed floating point numbers (or floating point, if in bourgeois). <br><br>  For some reason, floating-point arithmetic is considered an exotic field of computer science, given that the corresponding data types are present in every programming language.  I myself, to be honest, never attached much importance to computer arithmetic, while solving the same problem on the CPU and the GPU got a different result.  It turned out that very curious and strange phenomena are hidden in the hidden corners of this area: non-commutative and non-associative arithmetic operations, signed zero, the difference of unequal numbers gives zero, and so on.  The roots of this iceberg go deep into mathematics, and under the cut I will try to describe only what lies on the surface. <br><a name="habracut"></a><br><h4>  1. Basics </h4><br>  The set of integers is infinite, but we can always choose such a number of bits to represent any integer that occurs when solving a specific problem.  The set of real numbers is not only infinite, but also continuous, therefore, no matter how many bits we take, we will inevitably encounter numbers that do not have an exact representation.  Floating-point numbers are one of the possible ways of representing real numbers, which is a compromise between accuracy and the range of accepted values. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      A floating-point number consists of a set of individual digits, conditionally divided into a sign, an <s>exponential</s> order, and a mantissa.  The order and the mantissa are integers, which together with the sign give the representation of a floating-point number as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd5/b22/fbd/cd5b22fbd1c81ee793f03c95193a4477.gif"><br><br>  Mathematically, this is written like this: <br><br>  (-1) <sup>s</sup> √ó M √ó B <sup>E</sup> , where s is a sign, B is a base, E is order, and M is a mantissa. <br><br>  The base determines the number numeration system.  Mathematically, floating-point numbers with a base B = 2 (binary representation) are most resistant to rounding errors, so in practice there are only bases 2 and, less often, 10. For further discussion, we will always assume B = 2, and the formula with floating point will be: <br><br>  (-1) <sup>s</sup> √ó M √ó 2 <sup>E</sup> <br><br>  What is a mantissa and order?  <i>A mantissa</i> is a fixed-length integer that represents the most significant bits of a real number.  Suppose our mantissa consists of three bits (| M | = 3).  Take, for example, the number "5", which in the binary system will be equal to 101 <sub>2</sub> .  The most significant bit corresponds to 2 <sup>2</sup> = 4, the middle one (which is zero here) is 2 <sup>1</sup> = 2, and the least significant bit 2 <sup>0</sup> = 1.  <i>Order</i> is the degree of the base (2) of the highest order.  In our case, E = 2.  Such numbers are conveniently written in the so-called <s>"scientific"</s> standard form, for example, "1.01e + 2".  It is immediately evident that the mantissa consists of three characters, and the order is equal to two. <br><br>  Suppose we want to get a fractional number using the same 3 bits of mantissa.  We can do this if we take, say, E = 1.  Then our number will be equal to <br><br>  1.01e + 1 = 1 √ó 2 <sup>1</sup> + 0 √ó 2 <sup>0</sup> + 1 √ó 2 <sup>-1</sup> = 2 + 0.5 = 2.5 <br><br>  Here, since E = 1, the power of two of the first digit (which goes before the comma) is equal to "1".  Two other digits, located to the right (after the comma), provide the contribution of 2 <sup>E-1</sup> and 2 <sup>E-2</sup> (2 <sup>0</sup> and 2 <sup>-1,</sup> respectively).  Obviously, adjusting E to the same number can be represented in different ways.  Consider an example with the mantissa length | M | = 4.  The number "2" can be represented as follows: <br><br>  2 = 10 (in binary) = 1.000e + 1 = 0.100e + 2 = 0.010e + 3.  (E = 1, E = 2, E = 3, respectively) <br><br>  Please note that the same number has several representations.  This is not convenient for equipment, since  you need to take into account the multiplicity of representations when comparing numbers and when performing arithmetic operations on them.  Moreover, it is not economical, since the number of representations is finite, and repetitions reduce the set of numbers that can be represented at all.  Therefore, in the very first machines they began to use the trick, making the first bit of the mantissa always positive.  Such a preposition was called <i>normalized</i> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a6f/d22/c2c/a6fd22c2c3af3ab0139273b1f25b1f54.gif"><br><br>  This saves one bit, since an implicit unit does not need to be stored in memory, and provides a unique representation of the number.  In our example, ‚Äú2‚Äù has a single normalized representation (‚Äú1.000e + 1‚Äù), and the mantissa is stored in memory as ‚Äú000‚Äù, since  senior unit implicitly implied.  But in the normalized representation of numbers, a new problem arises - it is impossible to imagine zero in this form. <br><br>  Strictly speaking, the normalized number is as follows: <br><br>  (-1) <sup>s</sup> √ó 1.M √ó 2 <sup>E.</sup> <br><br>  The quality of problem solving depends on the choice of the representation of numbers with a floating point.  We smoothly approached the problem of standardization of such a presentation. <br><br><h4>  2. A bit of history </h4><br>  In the 60s and 70s there was no single standard for representing floating-point numbers, rounding methods, and arithmetic operations.  As a result, the programs were not extremely portable.  But an even bigger problem was that different computers had their own ‚Äúweirdness‚Äù and they needed to be known and taken into account in the program.  For example, the difference of two non-equal numbers returned zero.  As a result, the expressions ‚ÄúX = Y‚Äù and ‚ÄúXY = 0‚Äù conflicted.  The craftsmen bypassed this problem with very tricky tricks, for example, they made assignment ‚ÄúX = (XX) + X‚Äù before multiplication and division operations to avoid problems. <br><br>  The initiative to create a single standard for representing floating-point numbers suspiciously coincided with attempts in 1976 by Intel to develop the ‚Äúbest‚Äù arithmetic for new co-processors for 8086 and i432.  Scientists in this area, prof.  John Palmer and William Kahan.  The latter in his interview expressed the opinion that the seriousness with which Intel developed its arithmetic made other companies unite and begin the process of standardization. <br><br>  All were serious, because it is very profitable to promote their architecture and make it standard.  DEC, National Superconductor, Zilog, Motorola presented their proposals.  Mainframe makers Cray and IBM watched from the sidelines.  Intel, of course, also introduced its new arithmetic.  William Kahan, Jeromy Coonen, and Harold Stone, and their proposal, were immediately nicknamed ‚ÄúKCS‚Äù by the authors of the proposed specification. <br><br>  Almost immediately, all offers were rejected, except for two: VAX from DEC and ‚ÄúKCS‚Äù from Intel.  The VAX specification was much simpler, it was already implemented in PDP-11 computers, and it was clear how to get maximum performance from it.  On the other hand, KCS contained a lot of useful functionality, such as ‚Äúspecial‚Äù and ‚Äúdenormalized‚Äù numbers (details below). <br><br>  In KCS, all arithmetic algorithms are given strictly and it is required that in the implementation the result coincides with them.  This allows you to display strict calculations within this specification.  If earlier a mathematician solved a problem by numerical methods and proved the properties of a solution, there was no guarantee that these properties would remain in the program.  The rigor of KCS arithmetic made it possible to prove theorems based on floating-point arithmetic. <br><br>  DEC has done everything to make its specification standard.  She even gained the support of some reputable scientists in that the arithmetic of "KCS" in principle can not achieve the same performance as that of DEC.  The irony is that Intel knew how to make its specification as productive, but these tricks were a trade secret.  If Intel did not yield and did not reveal some of the secrets, it would not have been able to hold back the onslaught of DEC. <br><br>  For more information about standardization battles, see <a href="http://www.eecs.berkeley.edu/~wkahan/ieee754status/754story.html">Professor Kahan‚Äôs interview</a> , and we‚Äôll look at how the floating-point representation looks like now. <br><br><h4>  3. Representation of floating-point numbers today </h4><br>  The developers of KCS have won and now their offspring has been embodied in the IEEE754 standard.  The floating point numbers in it are represented as a sign (s), a mantissa (M) and an order (E) as follows: <br><br>  (-1) <sup>s</sup> √ó 1.M √ó 2 <sup>E</sup> <br><br>  <i>Comment.</i>  In the new standard IEE754-2008, in addition to the numbers with base 2, there are numbers with base 10, the so-called <i>decimal</i> (floating point) numbers. <br><br>  In order not to overload the reader with excessive information that can be found on <a href="http://en.wikipedia.org/wiki/IEEE_754-2008">Wikipedia</a> , consider only one type of data, with single precision (float).  The numbers with half, double and extended precision have the same features, but have a different range of order and mantissa.  In single-precision numbers (float / single), the order consists of 8 bits, and the mantissa - of 23. The effective order is defined as E-127.  For example, the number 0.15625 will be stored in memory as <br><br><img src="https://habrastorage.org/getpro/habr/post_images/112/403/33b/11240333b7f7b8cc9fe2d3339ca06bfa.gif"><br>  <i>Picture taken from Wikipedia</i> <br><br>  In this example: <br><ul><li>  Sign s = 0 (positive number) </li><li>  Order E = 01111100 <sub>2</sub> -127 <sub>10</sub> = -3 </li><li>  Mantissa M = 1.01 <sub>2</sub> (the first unit is not explicit) </li><li>  As a result, our number is F = 1.01 <sub>2</sub> e-3 = 2 <sup>-3</sup> + 2 <sup>-5</sup> = 0.125 + 0.03125 = 0.15625 </li></ul><br><div class="spoiler">  <b class="spoiler_title">Slightly more detailed explanation</b> <div class="spoiler_text">  Here we are dealing with a binary representation of the number ‚Äú101‚Äù with a comma offset a few bits to the left.  1.01 is a binary representation meaning 1 √ó 2 <sup>0</sup> + 0 √ó 2 <sup>-1</sup> + 1 √ó 2 <sup>-2</sup> .  Moving the comma three positions to the left we get 1.01e-3 = 1 √ó 2 <sup>-3</sup> + 0 √ó 2 <sup>-4</sup> + 1 √ó 2 <sup>-5</sup> = 1 √ó 0.125 + 0 √ó 0.0625 + 1 √ó 0.03125 = 0.125 + 0 , 03125 = 0.15625. </div></div><br><br><h5>  3.1 Special Numbers: Zero, Infinity, and Uncertainty </h5><br>  In IEEE754, the number "0" is represented by a value with an order equal to E = E <sub>min</sub> -1 (for single it is -127) and a zero mantissa.  The introduction of zero as an independent number (since zero cannot be represented in a normalized representation) made it possible to avoid many oddities in arithmetic.  And although operations with zero need to be processed separately, they are usually performed faster than with ordinary numbers. <br><br>  IEEE754 also provides a representation for special numbers, the work with which causes an exception.  These numbers include infinity (¬± ‚àû) and uncertainty (NaN).  These numbers allow you to return an adequate value in case of overflow.  Infinities are represented as numbers with the order E = E <sub>max</sub> +1 and the zero mantissa.  You can get infinity with overflow and when dividing a non-zero number by zero.  Infinity in the division of the developers determined on the basis of the existence of limits, when the dividend and divisor to strive for some number.  Accordingly, c / 0 == ¬± ‚àû (for example, 3/0 = + ‚àû, and -3 / 0 = -‚àû), since if the dividend tends to a constant and the divisor is zero, the limit is infinity.  At 0/0, the limit does not exist, so the result will be uncertainty. <br><br>  <i>Uncertainty</i> or NaN (from not a number) is a concept invented so that an arithmetic operation can always return some meaningless meaning.  In IEEE754, NaN is represented as a number in which E = E <sub>max</sub> +1, and the mantissa is not zero.  Any operation with NaN returns NaN.  If desired, the mantissa can record information that the program can interpret.  The standard is not specified and the mantissa is often ignored. <br><br>  How can I get NaN?  One of the following ways: <br><ul><li>  ‚àû + (- ‚àû) </li><li>  0 √ó ‚àû </li><li>  0/0, ‚àû / ‚àû </li><li>  sqrt (x), where x &lt;0 </li></ul><br>  By definition, NaN ‚â† NaN, therefore, to check the value of a variable, you just need to compare it with yourself. <br><br><h5>  What is the zero sign (or +0 vs -0) </h5><br>  The inquisitive reader has probably already noticed that in the described representation of floating-point numbers, there are two zeros, which differ only in sign.  So, 3 ¬∑ (+0) = + 0, and 3 ¬∑ (-0) = - 0.  But when comparing + 0 = -0.  In the standard, the sign was preserved intentionally so that expressions that, as a result of overflow or loss of significance, turn into infinity or zero, while multiplying and dividing, can still represent the most correct result.  For example, if zero had no sign, the expression 1 / (1 / x) = x would not hold true for x = ¬± ‚àû, since 1 / ‚àû and 1 / -‚àû are equal to 0. <br><br>  One more example: <br>  (+ ‚àû / 0) + ‚àû = + ‚àû, while (+ ‚àû / -0) + ‚àû = NaN <br><br>  How is infinity better in this case than NaN?  The fact that if NaN appeared in the arithmetic expression, the result of the whole expression will always be NaN.  If infinity is encountered in the expression, then the result can be zero, infinity, or a regular floating point number.  For example, 1 / ‚àû = 0. <br><br><h5>  3.3 Denormalized numbers </h5><br>  What is <s>subnormal</s> denormalized (subnormal) numbers consider a simple example.  Suppose we have a normalized representation with the mantissa length | M | = 2 bits (+ one normalization bit) and a range of values ‚Äã‚Äãof the order of -1‚â§E‚â§2.  In this case, we get 16 numbers: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dec/2be/c45/dec2bec45d6b80c08df0fe1d0557e299.gif"><br><br>  Large strokes indicate numbers with a mantissa equal to 1.00.  It is seen that the distance from zero to the nearest number (0 - 0.5) is greater than from this number to the next (0.5 - 0.625).  This means that the difference of any two numbers from 0.5 to 1 will give 0, even if these numbers are not equal.  Worse, the difference between numbers greater than 1 falls into the gap between 0.5 and 0. For example, "1.5-1.25 = 0" (see picture). <br><br>  Not every program falls into the ‚Äúnear-zero hole‚Äù.  According to the statistics of the 70s, on average, every computer encountered such a problem once a month.  Considering that computers acquired mass character, the developers of KCS considered this problem serious enough to solve it at the hardware level.  Their proposed solution was as follows.  We know that when E = E <sub>min</sub> -1 (for float it is ‚Äú-127‚Äù) and the zero mantissa, the number is considered to be zero.  If the mantissa is not zero, then the number is considered non-zero, its order is assumed to be E = E <sub>min</sub> , and the implicit high bit of the mantissa is assumed to be zero.  Such numbers are called <i>denormalized</i> . <br><br>  Strictly speaking, floating-point numbers now look like: <br><br>  (-1) <sup>s</sup> √ó 1.M √ó 2 <sup>E</sup> if E <sub>min</sub> ‚â§ E‚â§E <sub>max</sub> (normalized numbers) <br><br>  (-1) <sup>s</sup> √ó 0.M √ó 2 <sup>Emin</sup> if E = E <sub>min</sub> -1.  (denormalized numbers) <br><br>  Let's go back to the example.  Our E <sub>min</sub> = -1.  We introduce a new order value, E = -2, at which the numbers are denormalized.  As a result, we get a new representation of numbers: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/41c/ac3/7b4/41cac37b433960bc63776d81645bb8b7.gif"><br><br>  The interval from 0 to 0.5 fill in the denormalized numbers, which makes it possible not to fall into the 0 examples discussed above (0.5‚Äì0.25 and 1.5‚Äì1.25).  This made the presentation more robust to round-off errors for numbers close to zero. <br><br>  But the luxury of using a denormalized representation of numbers in the processor is not free.  Due to the fact that such numbers need to be processed differently in all arithmetic operations, it is difficult to make the work in such arithmetic effective.  This imposes additional difficulties in the implementation of the ALU in the processor.  And although the denormalized numbers are very useful, they are not a panacea and should still be monitored when rounding to zero.  Therefore, this functionality has become a stumbling block in the development of the standard and met the strongest resistance. <br><br><h5>  3.4 The order of numbers in IEEE754 </h5><br>  One of the surprising features of the representation of numbers in the IEEE754 format is that the order and the mantissa are arranged one behind the other in such a way that together they form a sequence of integers {n} for which it is executed: <br><br>  n &lt;n + 1 ‚áí F (n) &lt;F (n + 1), where F (n) is a floating point number formed from the integer n, splitting its bits into an order and the mantissa. <br><br>  Therefore, if we take a positive floating point number, convert it to a whole, add ‚Äú1‚Äù, we get the following number, which is representable in this arithmetic.  In C, you can do this: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> a=<span class="hljs-number"><span class="hljs-number">0.5</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> n = *((<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>*) &amp;a); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> b = *((<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) &amp;(++n)); <span class="hljs-built_in"><span class="hljs-built_in">printf</span></span>(<span class="hljs-string"><span class="hljs-string">" %e  : %e,  (%e)\n"</span></span>, a, b, ba);</code> </pre> <br>  This code will only work on a 32-bit int architecture. <br><br><h4>  4. Pitfalls in floating point arithmetic </h4><br>  Now - to practice.  Consider the features of floating-point arithmetic, to which you need to take special care when programming. <br><br><h5>  4.1 Rounding </h5><br>  With errors due to rounding errors in modern floating-point arithmetic, it is difficult to meet, especially if you use double precision.  The rounding rule in IEEE754 says that the result of any arithmetic operation must be as if it were performed on exact values ‚Äã‚Äãand rounded to the nearest number that can be represented in this format.  This requires additional efforts from the ALU and some compiler options (such as ‚Äú-ffast-math‚Äù in gcc) can disable this behavior.  Features rounding in IEEE754: <br><ul><li>  Rounding up to the closest one in the standard is not done as we are used to.  Mathematically, it is shown that if 0.5 is rounded to 1 (up), then there is a set of operations in which the rounding error will increase to infinity.  Therefore, IEEE754 applies the rounding rule to even.  So, 12.5 will be rounded up to 12, and 13.5 - to 14. </li><li>  The most dangerous operation in terms of rounding in floating point arithmetic is subtraction.  When subtracting close numbers, significant digits may be lost, which is <br>  may increase the relative error at times. </li><li>  For many common mathematical formulas, mathematics have developed a special form that can significantly reduce the error in rounding.  For example, the calculation of the formula "x <sup>2</sup> -y <sup>2</sup> " is better calculated using the formula "(xy) (x + y)". </li></ul><br><h5>  4.2 Nonassociative arithmetic operations </h5><br>  In floating point arithmetic, the rule (a * b) * c = a * (b * c) is not executed for any arithmetic operation.  For example, <br><br>  (10 <sup>20</sup> +1) -10 <sup>20</sup> = 0 ‚â† (10 <sup>20</sup> -10 <sup>20</sup> ) + 1 = 1 <br><br>  Suppose we have a program for summing numbers. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> s = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;n; i++) s = s + t[i];</code> </pre><br>  Some default compilers can rewrite the code to use several ALUs at the same time (we assume that n is divisible by 2): <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> sa[<span class="hljs-number"><span class="hljs-number">2</span></span>], s; sa[<span class="hljs-number"><span class="hljs-number">0</span></span>]=sa[<span class="hljs-number"><span class="hljs-number">1</span></span>]=<span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;n/<span class="hljs-number"><span class="hljs-number">2</span></span>; i++) {    sa[<span class="hljs-number"><span class="hljs-number">0</span></span>]=sa[<span class="hljs-number"><span class="hljs-number">0</span></span>]+t[i*<span class="hljs-number"><span class="hljs-number">2</span></span>+<span class="hljs-number"><span class="hljs-number">0</span></span>];    sa[<span class="hljs-number"><span class="hljs-number">1</span></span>]=sa[<span class="hljs-number"><span class="hljs-number">1</span></span>]+t[i*<span class="hljs-number"><span class="hljs-number">2</span></span>+<span class="hljs-number"><span class="hljs-number">1</span></span>]; } S=sa[<span class="hljs-number"><span class="hljs-number">0</span></span>]+sa[<span class="hljs-number"><span class="hljs-number">1</span></span>];</code> </pre><br>  Since summation operations are not associative, these two programs may produce different results. <br><br><h5>  4.3 Numeric Constants </h5><br>  Remember that not all decimal numbers have binary floating point representations.  For example, the number ‚Äú0.2‚Äù will be represented as ‚Äú0.20000003‚Äù in single precision.  Accordingly, "0.2 + 0.2 ‚âà 0.4".  Absolute error in a separate <br>  the case may not be high, but if we use such a constant in the cycle, we can get the accumulated error. <br><br><h5>  4.4 Selecting the minimum of two values </h5><br>  Suppose we need to choose the minimum of two values.  In C, this can be done in one of the following ways: <br><ol><li>  x &lt;y?  x: y </li><li>  x &lt;= y?  x: y </li><li>  x&gt; y?  y: x </li><li>  x&gt; = y?  y: x </li></ol><br>  Often the compiler considers them equivalent and always uses the first option, since it is executed in a single processor instruction.  But if we take into account ¬± 0 and NaN, these operations are in no way equivalent: <br><table><tbody><tr><td>  x </td><td>  y </td><td>  x &lt;y?  x: y </td><td>  x &lt;= y?  x: y </td><td>  x&gt; y?  y: x </td><td>  x&gt; = y?  y: x </td></tr><tr><td>  +0 </td><td>  -0 </td><td>  -0 </td><td>  +0 </td><td>  +0 </td><td>  -0 </td></tr><tr><td>  NaN </td><td>  one </td><td>  one </td><td>  one </td><td>  NaN </td><td>  NaN </td></tr></tbody></table><br><h5>  4.5 Comparing Numbers </h5><br>  A very common mistake when working with floats occurs when testing for equality.  For example, <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> fValue = <span class="hljs-number"><span class="hljs-number">0.2</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (fValue == <span class="hljs-number"><span class="hljs-number">0.2</span></span>) DoStuff();</code> </pre><br>  The error here is, firstly, that 0.2 does not have an exact binary representation, and secondly, 0.2 is a double precision constant, and the variable fValue is single, and there is no guarantee about the behavior of this comparison. <br><br>  The best, but still an erroneous way, is to compare the difference with the permissible absolute error: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-built_in"><span class="hljs-built_in">fabs</span></span>(fValue ‚Äì fExpected) &lt; <span class="hljs-number"><span class="hljs-number">0.0001</span></span>) DoStuff(); <span class="hljs-comment"><span class="hljs-comment">// fValue=fExpected?</span></span></code> </pre> <br><br>  The disadvantage of this approach is that the error in representing the number increases with the growth of this number itself.  So, if the program expects "10,000", then the reduced equality will not be performed for the nearest neighboring number (10,000,000977).  This is especially true if the program has a conversion from single precision to double precision. <br><br>  Choosing the right comparison procedure is difficult and interested readers I refer to the article by <a href="http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm">Bruce Dawson</a> .  It proposes comparing floating-point numbers with conversions to an integer variable.  This is the best, though not portable way: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">AlmostEqual2sComplement</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> A, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> B, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> maxUlps)</span></span></span><span class="hljs-function"> </span></span>{    <span class="hljs-comment"><span class="hljs-comment">// maxUlps        ,     // NaN          assert(maxUlps &gt; 0 &amp;&amp; maxUlps &lt; 4 * 1024 * 1024);    int aInt = *(int*)&amp;A;    //    aInt,  ,         if (aInt &lt; 0) aInt = 0x80000000 - aInt;    //aInt &amp;= 0x7fffffff; //(.   Vayun)    //   bInt    int bInt = *(int*)&amp;B;    if (bInt &lt; 0) bInt = 0x80000000 - bInt;    /*aInt &amp;= 0x7fffffff;*/    unsigned int intDiff = abs(aInt - bInt); /*(.   Vayun)*/    if (intDiff &lt;= maxUlps)        return true;    return false; }</span></span></code> </pre> <br><br>  In this program, maxUlps (from Units-In-Last-Place) is the maximum number of floating-point numbers that can lie between the value being checked and the expected value.  Another meaning of this variable is the number of binary digits (starting from the youngest) in the compared numbers is allowed to miss.  For example, maxUlps = 16, means that the lower 4 bits (log <sub>2</sub> 16) may not coincide, and the numbers will still be considered equal.  In this case, when compared with the number 10,000, the absolute error will be equal to 0.04646, and when compared with 0.001, the error will be less than 0.00000001 (10 <sup>-8</sup> ). <br><br><h4>  5. Check the completeness of IEE754 support </h4><br>  Do you think that if the processors fully comply with the IEEE754 standard, then any program using standard data types (such as float / double in C) will produce the same result on different computers?  You are mistaken.  Compiler and optimization options affect portability and compliance.  William Kahan wrote a C program (there is also a version for Fortran), which allows you to check whether the combination ‚Äúarchitecture + compiler + options‚Äù of IEEE754 satisfies.  It is called ‚ÄúFloating point paranoia‚Äù and its source code is available for <a href="http://orion.math.iastate.edu/burkardt/c_src/paranoia/paranoia.html">download</a> .  A similar program is available for the <a href="http://www.cs.unc.edu/~ibr/projects/paranoia/">GPU</a> .  For example, the Intel compiler (icc) by default uses the ‚Äúrelaxed‚Äù IEEE754 model, and as a result, not all tests are performed.  The ‚Äú-fp-model precise‚Äù option allows you to compile a program with exact compliance with the standard.  In the GCC compiler there is an option ‚Äú-ffast-math‚Äù, the use of which leads to an IEEE754 mismatch. <br><br><h4>  Conclusion </h4><br>  Finally, a cautionary tale.  When I was working on a test project on a GPU, I had a serial and parallel version of one program.  Comparing the runtime, I was very pleased, since I received the acceleration 300 times.  But later it turned out that the calculations on the GPU "collapsed" and turned to NaN, and working with them in the GPU was faster than with ordinary numbers.  It was interesting to the other - the same program on the GPU emulator (on the CPU) produced the correct result, but not on the GPU itself.  Later it turned out that the problem was that this GPU did not fully support the IEEE754 standard and the direct approach did not work. <br><br>  Now floating point arithmetic is almost perfect.  Almost always the naive approach will work, and the program, which does not take into account all its features, will produce the correct result, and the described pitfalls concern only exotic cases.  But one must always remain vigilant: in such a matter as computer mathematics it is easy to step on a rake. <br><br>  PS Thanks to the user <a href="http://habrahabr.ru/blogs/cpp/112953/">uqlock</a> for an important note.  Money cannot be stored as a floating point number, since  in this case, significant digits cannot be distinguished.  If in a programming language there are no data types with a fixed comma, you can get out of the situation and store money as an integer, implying pennies (sometimes fractions of kopecks). <br><br>  PPS Thanks for typos and errors to users: <a href="http://gribozavr.habrahabr.ru/">gribozavr</a> , <a href="http://kurokikaze.habrahabr.ru/">kurokikaze</a> , <a href="http://cenness.habrahabr.ru/">Cenness</a> , <a href="http://theshock.habrahabr.ru/">TheShock</a> , <a href="http://perl_demon.habrahabr.ru/">perl_demon</a> , <a href="http://gordtremor.habrahabr.ru/">GordTremor</a> , <a href="http://fader44.habrahabr.ru/">fader44</a> , <a href="http://draculadis.habrahabr.ru/">DraculaDis</a> , <a href="http://icc.habrahabr.ru/">icc</a> , <a href="http://f0rbidik.habrahabr.ru/">f0rbidik</a> , <a href="http://harkonnen.habrahabr.ru/">Harkonnen</a> , <a href="http://alexanderyastrebov.habrahabr.ru/">AlexanderYastrebov</a> , <a href="http://vayun.habrahabr.ru/">Vayun</a> , <a href="http://habrahabr.ru/users/EvilsInterrupt/">EvilsInterrupt</a> ! <br><br><h5>  Literature </h5><br><ol><li>  <a href="http://www.eecs.berkeley.edu/~wkahan/ieee754status/754story.html">Interview with William Kahan on the development of the IEE754 standard</a> . </li><li>  <a href="http://www.validlab.com/goldberg/paper.pdf">Floating Point Arithmetic, David Goldberg</a> - a book with mathematical calculations. </li><li>  <a href="http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm">Comparing floating point numbers, Bruce Dowson</a> . </li></ol></div><p>Source: <a href="https://habr.com/ru/post/112953/">https://habr.com/ru/post/112953/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../112946/index.html">Microsoft Quality Assurance Day</a></li>
<li><a href="../112947/index.html">Experiment with Augmented Reality, multitouch and Vuzix glasses</a></li>
<li><a href="../112948/index.html">Java hangs on 2.2250738585072012e-308</a></li>
<li><a href="../112949/index.html">The last provider is disabled in Egypt</a></li>
<li><a href="../112950/index.html">The administrator of the UA zone, ‚ÄúHostmaster,‚Äù closes public access to information on domain owners.</a></li>
<li><a href="../112957/index.html">Issued latest IPv4 / 8 blocks</a></li>
<li><a href="../112958/index.html">Accuracy of meteorological forecasts</a></li>
<li><a href="../112960/index.html">Using Deferred Objects in jQuery 1.5</a></li>
<li><a href="../112961/index.html">Microsoft Data Center Security</a></li>
<li><a href="../112962/index.html">Prefixes for Microsoft business critical applications</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>