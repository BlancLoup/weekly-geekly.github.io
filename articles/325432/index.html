<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep Learning Libraries: Keras</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! We already talked about Theano and Tensorflow (and also a lot about what else), and today it's time to talk about Keras. 


 Keras originall...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep Learning Libraries: Keras</h1><div class="post__text post__text-html js-mediator-article"><p>  Hi, Habr!  We already talked about <a href="https://habrahabr.ru/company/ods/blog/323272/">Theano</a> and <a href="https://habrahabr.ru/company/ods/blog/324898/">Tensorflow</a> (and also a lot about what else), and today it's time to talk about Keras. </p><br><p>  Keras originally grew up as a handy add-on to Theano.  Hence, his Greek name is Œ∫Œ≠œÅŒ±œÇ, which means "horn" in Greek, which, in turn, is a reference to Homer's Odyssey.  Although, a lot of water has flowed since then, and Keras began to maintain Tensorflow first, and then became a part of it.  However, our story will be devoted not to the difficult fate of this framework, but to its capabilities.  If it is interesting to you, welcome under kat. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/68f/fc1/d69/68ffc1d69c10d1ede103288c779c8f4e.jpg" alt="image"></div><a name="habracut"></a><br><p>  It is worth starting from the stove, that is, from the table of contents. </p><br><ul><li>  [Installation] </li><li>  [Backends] </li><li>  [Practical example] <br><ul><li>  [Data] </li><li>  [Model] <br><ul><li>  [Sequential API] </li><li>  [Functional API] </li></ul></li><li>  [Preparing the model for work] </li><li>  [Custom loss] </li><li>  [Training and Testing] </li><li>  [Callbacks] <br><ul><li>  [Tensorboard] </li></ul></li></ul></li><li>  [Advanced Graphs] </li><li>  [Conclusion] </li></ul><br><h2 id="ustanovka">  Installation </h2><br><p>  Installing Keras is extremely easy.  it is the usual python package: </p><br><pre><code class="bash hljs">pip install keras</code> </pre> <br><p>  Now we can proceed to his analysis, but first we will talk about backends. </p><br><p>  <strong>ATTENTION:</strong> To work with Keras, you must already have at least one of the frameworks installed - Theano or Tensorflow. </p><br><h2 id="bekendy">  Backends </h2><br><p>  Backends are what made Keras famous and popular (among other things, which we‚Äôll discuss below).  Keras allows you to use various other frameworks as a backend.  In this case, the code you write will be executed regardless of the backend used.  Development began, as we have said, with Theano, but over time Tensorflow was added.  Keras now works with it by default, but if you want to use Theano, then there are two options for how to do it: </p><br><ol><li>  Edit the keras.json configuration file, which lies along the path of <code>$HOME/.keras/keras.json</code> (or <code>%USERPROFILE%\.keras\keras.json</code> for Windows operating systems).  We need a <code>backend</code> field: <br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"image_data_format"</span></span>: <span class="hljs-string"><span class="hljs-string">"channels_last"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"epsilon"</span></span>: <span class="hljs-number"><span class="hljs-number">1e-07</span></span>, <span class="hljs-attr"><span class="hljs-attr">"floatx"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"backend"</span></span>: <span class="hljs-string"><span class="hljs-string">"theano"</span></span> }</code> </pre> </li><li>  The second way is to set the environment variable <code>KERAS_BACKEND</code> , for example, like this: <br><pre> <code class="bash hljs">KERAS_BACKEND=theano python -c <span class="hljs-string"><span class="hljs-string">"from keras import backend"</span></span> Using Theano backend.</code> </pre> </li></ol><br><p>  It is worth noting that work is currently underway on writing binding for CNTK from Microsoft, so after a while another available backend will appear.  Watch this <a href="https://github.com/Microsoft/CNTK/issues/797">here</a> . </p><br><p>  There is also the <a href="https://github.com/dmlc/mxnet/issues/4173">MXNet Keras backend</a> , which does not yet have all the functionality, but if you use MXNet, you can pay attention to this possibility. </p><br><p>  There is also an interesting project <a href="https://github.com/transcranial/keras-js">Keras.js</a> , which makes it possible to run the trained models of Keras from a browser on machines with a GPU. </p><br><p>  So the Keras backends are spreading and eventually will take over the world!  (But it is not exactly.) </p><br><h2 id="prakticheskiy-primer">  Practical example </h2><br><p>  In previous articles, much attention was paid to the description of the work of classical models of machine learning on the frameworks described.  It seems that now we can take as an example a [not very] deep neural network. </p><br><h3 id="dannye">  Data </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/740/39f/eda/74039feda6fca05afd8419cd1c8d6071.png"></div><br><p>  Learning any model in machine learning begins with data.  Keras has several training datasets inside, but they are already in a convenient form and do not allow showing the full power of Keras.  Therefore we will take more crude.  It will be dataset 20 newsgroups - 20 thousand news messages from Usenet groups (this is such a mail exchange system from the 1990s, akin to FIDO, which, perhaps, is a little better familiar to the reader) is approximately equally distributed in 20 categories.  We will teach our network how to correctly distribute messages to these newsgroups. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> fetch_20newsgroups newsgroups_train = fetch_20newsgroups(subset=<span class="hljs-string"><span class="hljs-string">'train'</span></span>) newsgroups_test = fetch_20newsgroups(subset=<span class="hljs-string"><span class="hljs-string">'test'</span></span>)</code> </pre> <br><p>  Here is an example of the content of the document from the training set: </p><br><div class="spoiler">  <b class="spoiler_title">newsgroups_train ['data'] [0]</b> <div class="spoiler_text"><p>  From: lerxst@wam.umd.edu (where's my thing) <br>  Subject: WHAT car is this !? <br>  Nntp-Posting-Host: rac3.wam.umd.edu <br>  Organization: University of Maryland, College Park <br>  Lines: 15 </p><br><p>  I couldn‚Äôt help <br>  the other day.  It was a 2-door sports car, <br>  early 70s.  It was called a bricklin.  The doors were really small.  In addition <br>  the front bumper was separate from the rest of the body.  This is <br>  all I know.  If you can tell me a model name, engine specs, years <br>  of production, where this car is made, history, or whatever info you <br>  have this funky looking car, please email. </p><br><p>  Thanks, </p><br><ul><li>  IL <br>  - Lerxst ---- </li></ul></div></div><br><h3 id="preprocessing">  Preprocessing </h3><br><p>  Keras contains tools for conveniently preprocessing texts, images and time series, in other words, the most common data types.  Today we work with texts, so we need to break them into tokens and bring them into matrix form. </p><br><pre> <code class="python hljs">tokenizer = Tokenizer(num_words=max_words) tokenizer.fit_on_texts(newsgroups_train[<span class="hljs-string"><span class="hljs-string">"data"</span></span>]) <span class="hljs-comment"><span class="hljs-comment">#         x_train = tokenizer.texts_to_matrix(newsgroups_train["data"], mode='binary') x_test = tokenizer.texts_to_matrix(newsgroups_test["data"], mode='binary')</span></span></code> </pre> <br><p>  At the output we have got binary matrices of such sizes: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">x_train</span></span> shape: (<span class="hljs-number"><span class="hljs-number">11314</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>) x_test shape: (<span class="hljs-number"><span class="hljs-number">7532</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>)</code> </pre> <br><p>  The first number is the number of documents in the sample, and the second is the size of our dictionary (one thousand in this example). </p><br><p>  We will also need to convert class labels to a matrix form for learning using cross-entropy.  To do this, we will translate the class number into the so-called one-hot vector, i.e.  vector consisting of zeros and one unit: </p><br><pre> <code class="python hljs">y_train = keras.utils.to_categorical(newsgroups_train[<span class="hljs-string"><span class="hljs-string">"target"</span></span>], num_classes) y_test = keras.utils.to_categorical(newsgroups_test[<span class="hljs-string"><span class="hljs-string">"target"</span></span>], num_classes)</code> </pre> <br><p>  At the output, we also get binary matrices of such sizes: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">y_train</span></span> shape: (<span class="hljs-number"><span class="hljs-number">11314</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>) y_test shape: (<span class="hljs-number"><span class="hljs-number">7532</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>)</code> </pre> <br><p>  As we can see, the sizes of these matrices partially coincide with the data matrices (according to the first coordinate - the number of documents in the training and test samples), and partially - not.  In the second coordinate, we have the number of classes (20, as the name implies). </p><br><p>  Everything, now we are ready to teach our network to classify news! </p><br><h3 id="model">  Model </h3><br><p>  The model in Keras can be described in two main ways: </p><br><h4 id="sequential-api">  Sequential api </h4><br><p>  The first is a consistent description of the model, for example, like this: </p><br><pre> <code class="python hljs">model = Sequential() model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, input_shape=(max_words,))) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)) model.add(Dense(num_classes)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>))</code> </pre> <br><p>  or like this: </p><br><pre> <code class="python hljs">model = Sequential([ Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, input_shape=(max_words,)), Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>), Dense(num_classes), Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><h4 id="functional-api">  Functional API </h4><br><p>  Some time ago it became possible to use a functional API to create a model - the second way: </p><br><pre> <code class="python hljs">a = Input(shape=(max_words,)) b = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>)(a) b = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(b) b = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(b) b = Dense(num_classes)(b) b = Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(b) model = Model(inputs=a, outputs=b)</code> </pre> <br><p>  There are no principal differences between the methods; choose which one you prefer. <br>  The <code>Model</code> class (and the <code>Sequential</code> inherited from it) has a convenient interface that allows you to see which layers are included in the model ‚Äî <code>model.layers</code> , inputs ‚Äî <code>model.inputs</code> , and outputs ‚Äî <code>model.outputs</code> . </p><br><p>  Also a very convenient method for displaying and saving the model is <code>model.to_yaml</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Under the spoiler his conclusion for our model.</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">backend: tensorflow class_name: Model config: input_layers: - [input_4, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] layers: - class_name: InputLayer config: batch_input_shape: !!python/tuple [<span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>] dtype: float32 <span class="hljs-type"><span class="hljs-type">name</span></span>: input_4 sparse: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span> inbound_nodes: [] <span class="hljs-type"><span class="hljs-type">name</span></span>: input_4 - class_name: Dense config: activation: linear activity_regularizer: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> bias_constraint: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> bias_initializer: class_name: Zeros config: {} bias_regularizer: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> kernel_constraint: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> kernel_initializer: class_name: VarianceScaling config: {distribution: uniform, mode: fan_avg, scale: <span class="hljs-number"><span class="hljs-number">1.0</span></span>, seed: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>} kernel_regularizer: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span>: dense_10 trainable: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span> units: <span class="hljs-number"><span class="hljs-number">512</span></span> use_bias: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span> inbound_nodes: - - - input_4 - <span class="hljs-number"><span class="hljs-number">0</span></span> - <span class="hljs-number"><span class="hljs-number">0</span></span> - {} <span class="hljs-type"><span class="hljs-type">name</span></span>: dense_10 - class_name: Activation config: {activation: relu, <span class="hljs-type"><span class="hljs-type">name</span></span>: activation_9, trainable: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>} inbound_nodes: - - - dense_10 - <span class="hljs-number"><span class="hljs-number">0</span></span> - <span class="hljs-number"><span class="hljs-number">0</span></span> - {} <span class="hljs-type"><span class="hljs-type">name</span></span>: activation_9 - class_name: Dropout config: {<span class="hljs-type"><span class="hljs-type">name</span></span>: dropout_5, rate: <span class="hljs-number"><span class="hljs-number">0.5</span></span>, trainable: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>} inbound_nodes: - - - activation_9 - <span class="hljs-number"><span class="hljs-number">0</span></span> - <span class="hljs-number"><span class="hljs-number">0</span></span> - {} <span class="hljs-type"><span class="hljs-type">name</span></span>: dropout_5 - class_name: Dense config: activation: linear activity_regularizer: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> bias_constraint: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> bias_initializer: class_name: Zeros config: {} bias_regularizer: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> kernel_constraint: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> kernel_initializer: class_name: VarianceScaling config: {distribution: uniform, mode: fan_avg, scale: <span class="hljs-number"><span class="hljs-number">1.0</span></span>, seed: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>} kernel_regularizer: <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span>: dense_11 trainable: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span> units: !!python/<span class="hljs-keyword"><span class="hljs-keyword">object</span></span>/apply:numpy.core.multiarray.scalar - !!python/<span class="hljs-keyword"><span class="hljs-keyword">object</span></span>/apply:numpy.dtype args: [i8, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>] state: !!python/tuple [<span class="hljs-number"><span class="hljs-number">3</span></span>, &lt;, <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] - !!binary | FAAAAAAAAAA= use_bias: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span> inbound_nodes: - - - dropout_5 - <span class="hljs-number"><span class="hljs-number">0</span></span> - <span class="hljs-number"><span class="hljs-number">0</span></span> - {} <span class="hljs-type"><span class="hljs-type">name</span></span>: dense_11 - class_name: Activation config: {activation: softmax, <span class="hljs-type"><span class="hljs-type">name</span></span>: activation_10, trainable: <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>} inbound_nodes: - - - dense_11 - <span class="hljs-number"><span class="hljs-number">0</span></span> - <span class="hljs-number"><span class="hljs-number">0</span></span> - {} <span class="hljs-type"><span class="hljs-type">name</span></span>: activation_10 <span class="hljs-type"><span class="hljs-type">name</span></span>: model_1 output_layers: - [activation_10, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] keras_version: <span class="hljs-number"><span class="hljs-number">2.0</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span></code> </pre> </div></div><br><p>  This allows you to save models in a human-readable form, as well as instantiate models from the following description: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model_from_yaml yaml_string = model.to_yaml() model = model_from_yaml(yaml_string)</code> </pre> <br><p>  It is important to note that the model saved in text form (by the way, it is possible to save also in JSON) does not contain weights.  To save and load weights, use the <code>save_weights</code> and <code>load_weights</code> respectively. </p><br><h3 id="vizualizaciya-modeli">  Model visualization </h3><br><p>  You can not ignore the visualization.  Keras has built-in visualization for models: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plot_model plot_model(model, to_file=<span class="hljs-string"><span class="hljs-string">'model.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  This code will save the following image under the name <code>model.png</code> : </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/f93/a8d/d5f/f93a8dd5f0d64105ab2335595136d176.png"></div><br><p>  Here we additionally display the sizes of the inputs and outputs for the layers.  <code>None</code> , the first in a tuple of sizes, is the dimension of the batch.  Since  costs <code>None</code> , the batch can be arbitrary. </p><br><p>  If you want to display it in a <code>jupyter</code> laptop, you need a slightly different code: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> IPython.display <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SVG <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils.vis_utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model_to_dot SVG(model_to_dot(model, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>).create(prog=<span class="hljs-string"><span class="hljs-string">'dot'</span></span>, format=<span class="hljs-string"><span class="hljs-string">'svg'</span></span>))</code> </pre> <br><p>  It is important to note that for visualization you need the <a href="http://www.graphviz.org/">graphviz</a> package, as well as the python pydot package.  There is a subtle point that the <code>pydot</code> package will not work from the repository for the visualization to work correctly, you need to get its updated version of <code>pydot-ng</code> . </p><br><pre> <code class="bash hljs">pip install pydot-ng</code> </pre> <br><p>  The <code>graphviz</code> package in Ubuntu is set up like this (in other Linux distributions it is the same): </p><br><pre> <code class="bash hljs">apt install graphviz</code> </pre> <br><p>  On MacOS (using the HomeBrew package system): </p><br><pre> <code class="bash hljs">brew install graphviz</code> </pre> <br><p>  Installation instructions for Windows can be found <a href="http://www.graphviz.org/Download_windows.php">here</a> . </p><br><h3 id="podgotovka-modeli-k-rabote">  Preparing the model for work </h3><br><p>  So, we have formed our model.  Now you need to prepare it for work: </p><br><pre> <code class="python hljs">model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><p>  What do the parameters of the <code>compile</code> function mean?  <code>loss</code> is a function of error, in our case it is cross-entropy, just for it we prepared our labels in the form of matrices;  <code>optimizer</code> is the <code>optimizer</code> used, there might be a regular stochastic gradient descent, but Adam shows the best convergence on this problem;  Metrics - metrics by which the quality of a model is considered, in our case, is accuracy (accuracy), that is, the proportion of correctly guessed answers. </p><br><h3 id="custom-loss">  Custom loss </h3><br><p>  Although Keras contains most of the popular error functions, your task may require something unique.  To make your own <code>loss</code> , you need a bit: just define a function that takes vectors of correct and predicted answers and gives one number to the output.  For training we will do our function of calculating the cross-entropy.  To make it something different, we introduce the so-called clipping - cutting the values ‚Äã‚Äãof the vector above and below.  Yes, another important note: non-standard <code>loss</code> may be necessary to describe in terms of the underlying framework, but we can do with Keras tools. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K epsilon = <span class="hljs-number"><span class="hljs-number">1.0e-9</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_objective</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''Yet another cross-entropy'''</span></span> y_pred = K.clip(y_pred, epsilon, <span class="hljs-number"><span class="hljs-number">1.0</span></span> - epsilon) y_pred /= K.sum(y_pred, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) cce = categorical_crossentropy(y_pred, y_true) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cce</code> </pre> <br><p>  Here, <code>y_true</code> and <code>y_pred</code> are tensors from Tensorflow, so Tensorflow functions are used to process them. </p><br><p>  To use another loss function, it is enough to change the <code>loss</code> parameter of the <code>compile</code> function, passing the object to our loss function (in the python, functions are also objects, although this is a completely different story): </p><br><pre> <code class="python hljs">model.compile(loss=custom_objective, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h3 id="obuchenie-i-testirovanie">  Training and Testing </h3><br><p>  Finally, it's time to learn the model: </p><br><pre> <code class="python hljs">history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br><p>  The <code>fit</code> method does just that.  It accepts a training sample together with tags - <code>x_train</code> and <code>y_train</code> , <code>y_train</code> size, which limits the number of examples given at a time, the number of epochs learning <code>epochs</code> (one epoch is a fully completed training sample once), as well as what proportion of the training sample to give for validation is <code>validation_split</code> . </p><br><p>  Returns this method. <code>history</code> is an error history at each step of learning. </p><br><p>  Finally, testing.  The <code>evaluate</code> method receives a test sample at the entrance along with labels for it.  The metric was set during preparation for work, so nothing else is needed.  (But we will also indicate the size of the batch). </p><br><pre> <code class="python hljs">score = model.evaluate(x_test, y_test, batch_size=batch_size)</code> </pre> <br><h3 id="callbacks">  Callbacks </h3><br><p>  It is also necessary to say a few words about such an important feature of Keras, as kolbek.  Through them implemented a lot of useful functionality.  For example, if you have been training your network for a very long time, you need to understand when it‚Äôs time to stop, if the error on your dataset has ceased to decrease.  In English, the described functionality is called "early stopping".  Let's see how we can apply it when training our network: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EarlyStopping early_stopping=EarlyStopping(monitor=<span class="hljs-string"><span class="hljs-string">'value_loss'</span></span>) history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, callbacks=[early_stopping])</code> </pre> <br><p>  Do an experiment and check how quickly early stopping works in our example? </p><br><h4 id="tensorboard">  Tensorboard </h4><br><p>  Even as a callback, you can use the preservation of logs in a format convenient for Tensorboard (there was a conversation about it in the article about Tensorflow, in short it is a special utility for processing and visualizing information from Tensorflow logs). </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TensorBoard tensorboard=TensorBoard(log_dir=<span class="hljs-string"><span class="hljs-string">'./logs'</span></span>, write_graph=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, callbacks=[tensorboard])</code> </pre> <br><p>  After the training is completed (or even in the process!), You can run <code>Tensorboard</code> , specifying the absolute path to the directory with logs: </p><br><pre> <code class="bash hljs">tensorboard --logdir=/path/to/logs</code> </pre> <br><p>  There you can see, for example, how the target metric changed on the validation sample: <br><img src="https://habrastorage.org/files/d17/209/d25/d17209d255384483ae77a4a78f9cf062.png" alt="image"><br>  (By the way, here you can see that our network is being retrained.) </p><br><h2 id="prodvinutye-grafy">  Advanced graphs </h2><br><p>  Now consider building a slightly more complex computation graph.  A neural network can have multiple inputs and outputs; input data can be transformed by various mappings.  To reuse parts of complex graphs (in particular, for <code>transfer learning</code> ), it makes sense to describe the model in a modular style, allowing you to conveniently extract, save and apply to the new input data pieces of the model. </p><br><p>  It is most convenient to describe the model by mixing both methods - the <code>Functional API</code> and the <code>Sequential API</code> described earlier. </p><br><p>  Consider this approach on the example of the model Siamese Network.  Similar models are widely used in practice to obtain vector representations with useful properties.  For example, a similar model can be used to learn how to display photos of faces in a vector, so that vectors for similar faces will be close to each other.  In particular, image search applications such as FindFace use this. </p><br><p>  An illustration of the model can be seen in the diagram: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/4e5/44d/19b/4e544d19b390ef696b5a36f8723a2f1b.png" alt="image"></p><br><p>  Here, the <code>G</code> function turns the input image into a vector, after which the distance between the vectors for a pair of images is calculated.  If the pictures are from the same class, the distance should be minimized; if from different ones - maximized. </p><br><p>  After such a neural network is trained, we will be able to present an arbitrary picture as a vector <code>G(x)</code> and use this representation either to search for the nearest images or as a vector of signs for other machine learning algorithms. </p><br><p>  We will describe the model in the code accordingly, making it as easy as possible to extract and reuse parts of the neural network. </p><br><p>  First, we define a function on Keras that displays the input vector. </p><br><pre> <code class="hljs cs"><span class="hljs-function"><span class="hljs-function">def </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_base_network</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">input_dim</span></span></span><span class="hljs-function">): seq</span></span> = Sequential() seq.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, input_shape=(input_dim,), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) seq.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(Dropout(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) seq.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) seq.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(Dropout(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) seq.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> seq</code> </pre> <br><p>  Note: we described the model using the <code>Sequential API</code> , however we wrapped its creation into a function.  Now we can create such a model by calling this function and apply it using the <code>Functional API</code> to the input data: </p><br><pre> <code class="hljs lisp">base_network = create_base_network(<span class="hljs-name"><span class="hljs-name">input_dim</span></span>) input_a = Input(<span class="hljs-name"><span class="hljs-name">shape=</span></span>(<span class="hljs-name"><span class="hljs-name">input_dim</span></span>,)) input_b = Input(<span class="hljs-name"><span class="hljs-name">shape=</span></span>(<span class="hljs-name"><span class="hljs-name">input_dim</span></span>,)) processed_a = base_network(<span class="hljs-name"><span class="hljs-name">input_a</span></span>) processed_b = base_network(<span class="hljs-name"><span class="hljs-name">input_b</span></span>)</code> </pre> <br><p>  Now the <code>processed_a</code> and <code>processed_b</code> variables <code>processed_a</code> vector representations obtained by applying a network, defined earlier, to the input data. </p><br><p>  It is necessary to calculate the distance between them.  To do this, Keras has a <code>Lambda</code> wrapper function that represents any expression as a layer.  Do not forget that we process the data in batch data, so that all tensors always have an extra dimension, which is responsible for the size of the batch. </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K def euclidean_distance(<span class="hljs-title"><span class="hljs-title">vects</span></span>): x, y = vects return K.sqrt(<span class="hljs-type"><span class="hljs-type">K</span></span>.<span class="hljs-title"><span class="hljs-title">sum</span></span>(<span class="hljs-type"><span class="hljs-type">K</span></span>.<span class="hljs-title"><span class="hljs-title">square</span></span>(<span class="hljs-title"><span class="hljs-title">x</span></span> - <span class="hljs-title"><span class="hljs-title">y</span></span>), axis=1, keepdims=True)) distance = Lambda(<span class="hljs-title"><span class="hljs-title">euclidean_distance</span></span>)([<span class="hljs-title"><span class="hljs-title">processed_a</span></span>, <span class="hljs-title"><span class="hljs-title">processed_b</span></span>])</code> </pre> <br><p>  Great, we got the distance between the internal views, now it remains to collect the entrances and the distance in one model. </p><br><pre> <code class="hljs swift">model = <span class="hljs-type"><span class="hljs-type">Model</span></span>([input_a, input_b], <span class="hljs-built_in"><span class="hljs-built_in">distance</span></span>)</code> </pre> <br><p>  Thanks to the modular structure, we can use <code>base_network</code> separately, which is especially useful after training the model.  How can I do that?  Let's look at the layers of our model: </p><br><pre> <code class="hljs cs">&gt;&gt;&gt; model.layers [&lt;keras.engine.topology.InputLayer <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fdacb38</span></span>&gt;, &lt;keras.engine.topology.InputLayer <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fdc34a8</span></span>&gt;, &lt;keras.models.Sequential <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f239127c3c8</span></span>&gt;, &lt;keras.layers.core.Lambda <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fddc4a8</span></span>&gt;]</code> </pre> <br><p>  We see the third object in the list of the type <code>models.Sequential</code> . <code>models.Sequential</code> .  This is the model that displays the input image in the vector.  To extract and use it as a full-fledged model (you can train, validate, embed in another graph) you just need to pull it out of the list of layers: </p><br><pre> <code class="hljs cs">&gt;&gt;&gt; embedding_model = model.layers[<span class="hljs-number"><span class="hljs-number">2</span></span>] &gt;&gt;&gt; embedding_model.layers [&lt;keras.layers.core.Dense <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f23c4e557f0</span></span>&gt;, &lt;keras.layers.core.Dropout <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fe97908</span></span>&gt;, &lt;keras.layers.core.Dense <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fe44898</span></span>&gt;, &lt;keras.layers.core.Dropout <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fe449e8</span></span>&gt;, &lt;keras.layers.core.Dense <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> at <span class="hljs-number"><span class="hljs-number">0x7f238fe01f60</span></span>&gt;]</code> </pre> <br><p>  For example, for a Siamese network already trained on MNIST data with a <code>base_model</code> output of two, you can visualize vector representations as follows: </p><br><p>  Load the data and bring the images of size <code>28x28</code> to flat vectors. </p><br><pre> <code class="hljs matlab">(x_train, y_train), (x_test, y_test) = mnist.load_data() x_test = x_test.<span class="hljs-built_in"><span class="hljs-built_in">reshape</span></span>(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>)</code> </pre> <br><p>  Display the images using the previously extracted model: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">embeddings</span></span> = embedding_model.predict(x_test)</code> </pre> <br><p>  Now in the <code>embeddings</code> are two-dimensional vectors, they can be drawn on the plane: <br><img src="https://habrastorage.org/getpro/habr/post_images/9a8/90c/857/9a890c8574428c6f1ae28d11bfad5522.png" alt="image"></p><br><p>  A full example of the Siamese network can be seen <a href="https://github.com/fchollet/keras/blob/master/examples/mnist_siamese_graph.py">here</a> . </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  That's it, we made the first models on Keras!  We hope that the opportunities provided to them interested you, so that you will use it in your work. </p><br><p>  It's time to discuss the pros and cons of Keras.  The obvious advantages include the simplicity of creating models, which translates into high speed prototyping.  For example, the authors of a recent article <a href="https://habrahabr.ru/company/ods/blog/325096/">about satellites</a> used exactly Keras.  In general, this framework is becoming more and more popular: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/88e/c33/d75/88ec33d7522f6063732d6833b9ecdb9a.png" alt="image"></p><br><p>  Keras caught up with Torch for a year, which has been under development for 5 years, judging by references in scientific articles.  It seems his goal - ease of use - Francois Chollet (Fran√ßois Chollet, author Keras) achieved.  Moreover, his initiative did not go unnoticed: after just a few months of development, Google invited him to do this in the team developing Tensorflow.  And also with the version Tensorflow 1.2 Keras will be included in the TF (tf.keras). </p><br><p>  Also need to say a few words about the shortcomings.  Unfortunately, Keras‚Äôs idea of ‚Äã‚Äãcode universality is not always fulfilled: Keras 2.0 broke compatibility with the first version, some functions were renamed differently, some moved, in general, the story is similar to the second and third python.  The difference is that in the case of Keras, only the second version was chosen for development.  Also, the Keras code works on Tensorflow while slower than on Theano (although for the native code, the frameworks are at least <a href="https://arxiv.org/abs/1511.06435">comparable</a> ). </p><br><p>  In general, you can recommend Keras for use when you need to quickly build and test a network for a specific task.  But if you need some complicated things, like a non-standard layer or code parallelization on several GPUs, then it is better (and sometimes simply inevitable) to use the underlying framework. </p><br><p>  Almost all the code from the article is in the form of a single laptop <a href="https://gist.github.com/madrugado/63c068b52a135c6fdbbb6fe17acbc0c8">here</a> .  We also highly recommend you the Keras: <a href="http://keras.io/">keras.io documentation</a> , as well as the <a href="https://github.com/fchollet/keras/tree/master/examples">official examples</a> on which this article is largely based. </p><br><p>  Post written in collaboration with <a href="https://habrahabr.ru/users/wordbearer/" class="user_link">Wordbearer</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/325432/">https://habr.com/ru/post/325432/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../325412/index.html">The first of April 2017 on the Internet</a></li>
<li><a href="../325416/index.html">Bayesian multi-armed gangsters against A / B tests</a></li>
<li><a href="../325422/index.html">Open machine learning course. Theme 6. Construction and selection of signs</a></li>
<li><a href="../325426/index.html">Getting rid of ConcurrentModificationException</a></li>
<li><a href="../325428/index.html">Round Canvas Chart</a></li>
<li><a href="../325434/index.html">How I create a database for my applications</a></li>
<li><a href="../325436/index.html">How we did secure telephony for Wheely, a world-wide personal driver service.</a></li>
<li><a href="../325438/index.html">Continuous delivery with Travis CI and Ansible</a></li>
<li><a href="../325440/index.html">The digest of interesting materials for the mobile # 197 developer (March 27 - April 2)</a></li>
<li><a href="../325442/index.html">‚ÄúGood external restrictions are the basis for creativity‚Äù: Oleg Chirukhin on Sberbank Technologies, Java and Novosibirsk</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>