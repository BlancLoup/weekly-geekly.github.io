<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Comparing the same project in Rust, Haskell, C ++, Python, Scala and OCaml</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the last semester of the university, I chose the CS444 compiler course . There, each group of 1-3 people had to write a compiler from a substantial...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Comparing the same project in Rust, Haskell, C ++, Python, Scala and OCaml</h1><div class="post__text post__text-html js-mediator-article">  In the last semester of the university, I chose <a href="https://www.student.cs.uwaterloo.ca/~cs444/">the CS444 compiler course</a> .  There, each group of 1-3 people had to write a compiler from a substantial Java subset in x86.  Language to choose from.  It was a rare opportunity to compare the implementation of large programs of the same functionality, written by very competent programmers in different languages, and compare the difference in the design and choice of language.  Such a comparison has generated a lot of interesting thoughts.  It is rare to find such a controlled comparison of languages.  It is not perfect, but much better than most of the subjective stories on which people's opinions about programming languages ‚Äã‚Äãare based. <br><br>  We made our compiler on Rust, and at first I compared it with the project of the Haskell team.  I expected their program to be much shorter, but it was the same size or larger.  Same for OCaml.  Then I compared it with the compiler in C ++, and there, as expected, the compiler was about 30% more, mainly because of headers, the lack of sum types, and pattern matching.  The following comparison was with my girlfriend, who made the compiler independently in Python and used less than half of the code, compared to us, because of the power of metaprogramming and dynamic types.  Another companion program on Scala was also less than ours.  Most of all I was surprised by the comparison with another team that also used Rust, but they had three times more code due to different design decisions.  In the end, the biggest difference in the amount of code was within the same language! <br><a name="habracut"></a><br>  I will tell you why I consider this a good comparison, give some information about each project and explain some reasons for differences in the compiler size.  Also draw conclusions from each comparison.  Feel free to use these links to go to the section of interest: <br><br><h1>  Content </h1><br><ul><li>  Why I think it is meaningful. <br></li><li>  <a href="https://habr.com/ru/post/456638/">Rust (basis for comparison)</a> <br></li><li>  <a href="https://habr.com/ru/post/456638/">Haskell</a> : 1.0-1.6 sizes depending on how you count, for interesting reasons. <br></li><li>  <a href="https://habr.com/ru/post/456638/">C ++</a> : 1.4 sizes for obvious reasons <br></li><li>  <a href="https://habr.com/ru/post/456638/">Python</a> : 0.5 size due to bizarre metaprogramming! <br></li><li>  <a href="https://habr.com/ru/post/456638/">Rust (another group)</a> : triple size due to a different design! <br></li><li>  <a href="https://habr.com/ru/post/456638/">Scala</a> : 0.7 size <br></li><li>  <a href="https://habr.com/ru/post/456638/">OCaml</a> : 1.0-1.6 sizes, depending on how you count, is similar to Haskell </li></ul><br><h1>  Why I think it is meaningful. </h1><br>  Before you say that the amount of code (I compared both strings and bytes) is a terrible metric, I want to note that in this case it can provide a good understanding.  At the very least, this is the most well-controlled example when different teams write the same great program I have heard or read about. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  No one (including me) knew that I would measure this parameter, so no one tried to play metrics, everyone just tried to finish the project quickly and correctly. <br></li><li>  All (with the exception of the Python project, which I will talk about later) implemented the program with the sole purpose of passing the same automated test suite in the same time frame, so the results cannot be greatly distorted by groups that solve different problems. <br></li><li>  The project was completed within a few months, with the team, and had to gradually expand and pass both known and unknown tests.  This means that it was useful to write clean, clear code. <br></li><li>  In addition to passing the tests of the course, the code will not be used for anything else, no one will read it and, being a compiler for a limited subset of Java into a text assembler, it will not be useful. <br></li><li>  No libraries other than the standard library are allowed, and no parsing helpers, even if they are in the standard library.  This means that the comparison cannot be distorted by the powerful compiler libraries that only some commands have. <br></li><li>  There were not only public, but also secret tests.  They were run once after the final delivery.  This meant that there was an incentive to write your own test code and make sure that the compiler is reliable, correct, and handles complex border situations. <br></li><li>  Although all participants are students, but I consider them to be quite competent programmers.  Every at least two years passed an internship, mainly in high-tech companies, sometimes even worked on compilers.  Almost all of them program for 7-13 years and are enthusiasts who read a lot on the Internet beyond their courses. <br></li><li>  The generated code was not taken into account, but the grammar files and the code that generated the other code were taken into account. </li></ul><br>  Thus, I think that the amount of code provides a decent understanding of how much effort it will take to support each project, if it were long-term.  I think that not too much difference between the projects also allows you to refute some extraordinary statements that I read, for example, that the Haskell compiler will be more than half the size of C ++ due to the language. <br><br><a name="1"></a><h1>  Rust (basis for comparison) </h1><br>  I and one of my comrades used to write more than 10k lines on Rust, and a third colleague wrote, perhaps 500 lines on some hackathons.  Our compiler came out in 6806 lines of <code>wc -l</code> , 5900 lines of source code (without spaces and no comments), and 220 KB of <code>wc -c</code> . <br><br>  I found that in other projects these proportions are approximately respected, with a few exceptions, which I will note.  For the rest of the article, when I refer to strings or a sum, I mean <code>wc -l</code> , but it doesn‚Äôt matter (if I don‚Äôt notice the difference), and you can convert with a factor. <br><br>  I wrote <a href="http://thume.ca/2019/04/18/writing-a-compiler-in-rust/">another article describing our design</a> , which passed all public and secret tests.  It also contains several additional functions that we did for fun, not for passing tests, which probably added about 400 lines.  There are also about 500 lines of our unit tests. <br><br><a name="2"></a><h1>  Haskell </h1><br>  The Haskell team included two of my friends who wrote perhaps a couple of thousand lines of Haskell each, plus read a lot of online content about Haskell and other similar functional languages, such as OCaml and Lean.  They had another teammate whom I didn‚Äôt know very well, but it seems that a strong programmer used Haskell before. <br><br>  Their compiler was 9750 lines for <code>wc -l</code> , 357 KB and 7777 lines of code (SLOC).  This command also has the only significant differences between these ratios: their compiler is 1.4 times larger than ours in rows, 1.3 times in SLOC and 1.6 times in bytes.  They did not implement any additional functions, passed 100% of public and secret tests. <br><br>  It is important to note that the inclusion of tests most affected this team.  Since they carefully approached the correctness of the code, they included 1600 lines of tests.  They caught several borderline situations that our team did not catch, but these cases were simply not verified by course tests.  So without tests on both sides (6.3 thousand lines versus 8.1 thousand lines) their compiler is only 30% more than ours. <br><br>  Here I tend to bytes as a more reasonable measure of volume comparison, because in the Haskell project, on average, longer lines, since it does not have a large number of lines from one closing bracket, and <code>rustfmt</code> does not break single-line chains of functions into several lines. <br><br>  Having rummaged with one of my teammates, we came up with the following explanation for this difference: <br><br><ul><li>  We used the handwritten lexical analyzer and the recursive descent method, and they used the generator on <a href="https://en.wikipedia.org/wiki/Nondeterministic_finite_automaton">NFA</a> and <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton">DFA</a> and <a href="https://en.wikipedia.org/wiki/LR_parser">LR parser</a> , and then the pass to convert the parse tree to AST ( <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">abstract syntax tree</a> , more convenient code presentation).  This gave them significantly more code: 2677 lines compared to our 1705, about 1000 lines more. <br></li><li>  They used the fancy AST generic, which shifted to different type parameters as more information was added in each pass.  This and more rewriting support functions probably explain why their AST code is about 500 lines longer than our implementation, where we collect struct literals and mutate <code>Option&lt;_&gt;</code> fields to add information as we go. <br></li><li>  They also have about 400 lines of code during generation, which are mainly related to the larger abstraction needed to generate and combine the code in a purely functional way, where we simply use mutation and string writing. </li></ul><br>  These differences plus tests explain all differences in volume.  In fact, our files for the folding of constants and the resolution of the context are very close in size.  But still, there is still some difference in bytes due to longer lines: probably because more code is needed to rewrite the whole tree on each pass. <br><br>  In the end, postponing the design decisions, in my opinion, Rust and Haskell are equally expressive, perhaps with a slight advantage of Rust due to the ability to easily use mutation when it is convenient.  It was also interesting to know that my choice of the recursive descent method and the handwritten lexical analyzer paid off: it was a risk that contradicted the recommendations and instructions of the professor, but I decided that it was easier and that was right. <br><br>  Haskell fans will argue that the team probably did not take full advantage of Haskell‚Äôs capabilities, and if they knew the language better, they could have done a project with less code.  I agree, someone like <a href="https://github.com/ekmett">Edward Kmett</a> can write the same compiler in a much smaller volume.  Indeed, my friend's team did not use many fancy super-abstractions and fancy combinator libraries such as <a href="http://hackage.haskell.org/package/lens">lens</a> .  However, all this affects the readability of the code.  All the people in the team are experienced programmers, they knew that Haskell is capable of very fancy things, but decided not to use them, because they decided that their understanding would take longer than they would save, and would make the code harder for others to understand.  This seems like a real compromise to me, and the statement that Haskell is magically suitable for compilers goes into something like ‚ÄúHaskell requires extremely high qualifications for writing compilers if you do not care about supporting code with people who are also not very skilled at Haskell.‚Äù <br><br>  It is also interesting to note that at the beginning of each project, the professor says that students can use any language that runs on the university server, but warns that the Haskell teams are different from the others: they have the largest variation in grades.  Many people overestimate their abilities and the Haskell teams have the most bad grades, while others do great, like my friends. <br><br><a name="3"></a><h1>  C ++ </h1><br>  Then I talked to my friend from the C ++ team.  I knew only one person in this team, but C ++ is used in several courses at our university, so probably everyone on the team had C ++ experience. <br><br>  Their project consisted of 8733 lines and 280 KB, not including the test code, but including about 500 lines of additional functions.  What makes it 1.4 times the size of our code without tests, which also has about 500 lines of additional functions.  They passed 100% of public tests, but only 90% of secret tests.  Presumably because they did not implement the fancy vtables arrays required by the specification, which may take 50-100 lines of code. <br><br>  I didn‚Äôt delve very deeply into these differences in size.  I guess this is mainly due to: <br><br><ul><li>  They use LR parser and tree rewriter instead of recursive descent method. <br></li><li>  The lack of sum types and pattern matching in C ++, which we used extensively and which were very useful. <br></li><li>  The need to duplicate all the signatures in the header files, which is not in Rust. </li></ul><br>  We also compared the compile time.  On my laptop, the net debug build of our compiler takes 9.7 seconds, the net release is 12.5 seconds, and the incremental debug build is 3.5 seconds.  My friend did not have the timings on hand for their C ++ build (using parallel make), but he said that the numbers are similar, with the proviso that they put the implementations of many small functions in the header files to reduce duplication of signatures at the cost of a longer time ( therefore, I cannot measure the net overhead of lines in header files). <br><br><a name="4"></a><h1>  Python </h1><br>  My friend, a very good programmer, decided to do the project alone in Python.  She also implemented more advanced features (for fun) than any other command, including an intermediate SSA representation with register allocation and other optimizations.  On the other hand, since it worked alone and implemented many additional functions, it paid the least attention to the quality of the code, for example, throwing undifferentiated exceptions for all errors (relying on backtracks for debugging) instead of implementing error types and corresponding messages like us. <br><br>  Its compiler consisted of 4581 lines and passed all public and secret tests.  She also implemented more additional functions than any other command, but it‚Äôs hard to determine how much additional code it took because many of the additional functions were more powerful versions of simple things that everyone needed to implement, such as folding constants and generating code.  Additional functions are probably 1000-2000 lines, at least, so I am sure that its code is at least twice as expressive as ours. <br><br>  One big part of this difference is probably dynamic typing.  Only in our <code>ast.rs</code> 500 lines of type definitions, and many more types defined elsewhere in the compiler.  We are also always limited by the type system itself.  For example, we need infrastructure for ergonomic addition of new information to AST as it passes and access to it later.  While in Python you can simply set new fields on the AST nodes. <br><br>  Powerful metaprogramming also explains some of the difference.  For example, although she used the LR parser instead of the recursive descent method, in her case, I think it took less code, because instead of going overwriting the tree, her LR grammar included Python code fragments to build AST, which the generator could turn into Python functions using <code>eval</code> .  Part of the reason why we did not use the LR parser is that building an AST without overwriting a tree will require a lot of ceremonies (creating either Rust files or procedural macros) to link the grammar with Rust code fragments. <br><br>  Another example of the power of metaprogramming and dynamic typing is the 400-line <code>visit.rs</code> file, which is basically a repeating pattern code that implements the visitor on a heap of AST structures.  In Python, this may be a short function of about 10 lines, which recursively introspect the fields of the AST node and visit them (using the <code>__dict__</code> attribute). <br><br>  As a fan of Rust and statically typed languages ‚Äã‚Äãin general, I tend to point out that the type system is very useful for preventing errors and for performance.  Unusual metaprogramming can also make it difficult to understand how code works.  However, this comparison surprised me that I did not expect that the difference in the amount of code would be so big.  If the difference in general is really close to having to write twice as much code, I still think that Rust is a suitable compromise, but still half the code is an argument, and in the future I tend to do something in Ruby / Python if you just need to quickly build something alone, and then throw it away. <br><br><a name="5"></a><h1>  Rust (another group) </h1><br>  The most interesting comparison for me was with my friend, who also did a project in Rust with one teammate (whom I did not know).  My friend had a good Rust experience.  He contributed to the development of the compiler Rust and read a lot.  I know nothing about his friend. <br><br>  Their project consisted of 17,211 raw lines, 15k source lines and 637 KB, not including the test code and the generated code.  He had no additional functions, and he passed only 4 of 10 secret tests and 90% of public tests for code generation, because they didn‚Äôt have enough time before the deadline to implement more fancy parts of the specification.  Their program is three times larger than ours, written in the same language, and with less functionality! <br><br>  This result was really amazing for me and overshadowed all the differences between the languages ‚Äã‚Äãthat I have studied so far.  Therefore, we compared the lists of file sizes <code>wc -l</code> , and also checked how each of us implemented some specific things that resulted in a different code size. <br><br>  It seems that it all comes down to the consistent adoption of various design decisions.  For example, their frontend (lexical analysis, parsing, AST building) took 7597 lines against our 2164. They used the lexical analyzer on DFA and the parser LALR (1), but other groups did similar things without so much code.  Looking at their weeder file, I noticed a number of design solutions that were different from ours: <br><br><ul><li>  They decided to use a fully typed parse tree instead of the standard homogeneous string-based parse tree.  This probably required much more type definitions and additional conversion code at the parsing stage or a more complex parser generator. <br></li><li>  They used tryfrom implementations of traits to convert between the types of the parse tree and the AST types when checking their correctness.  This results in a set of 10‚Äì20-line <code>impl</code> blocks.  We used for this purpose functions that return <code>Result</code> types, which generates fewer lines, and also frees us a bit from the type structure, simplifying parameterization and reuse.  Some of the things that for us were single-line branches of <code>match</code> , they had 10-line <code>impl</code> blocks. <br></li><li>  Our types are structured to reduce copy-paste.  For example, they used separate fields <code>is_abstract</code> , <code>is_native</code> and <code>is_static</code> , where the constraint-check code had to be copied twice: once for void-typed methods and once for methods with a return type, with minor changes.  While our <code>void</code> was just a special type, we came up with a modifier taxonomy with <code>mode</code> and <code>visibility</code> that applied constraints at the type level, and the constraint errors were generated by default for the match operator, which translated the modifier sets into <code>mode</code> and <code>visibility</code> . </li></ul><br>  I did not look at the code for analyzing their compiler passes, but they are great too.  I talked to my friend, and it seems that they did not implement anything similar to the visitor infrastructure like ours.  I suppose that this, along with some other smaller differences in design, explains the difference in the size of this part.  The visitor allows our analysis passes to focus only on the parts of the AST they need, instead of matching the pattern across the entire AST structure.  It saves a lot of code. <br><br>  Their part for generating code consists of 3594 lines, and ours is 1560. I looked at their code and it seems that almost all the difference is that they chose an intermediate data structure for assembler instructions, where we just used string formatting to directly assembler output .  They had to define the types and output functions for all the instructions used and the types of the operands.  It also meant that building the assembler instructions took more code.  Where we had a format statement with short instructions, such as <code>mov ecx, [edx]</code> , they needed a giant <code>rustfmt</code> operator, broken up into 6 lines, which built instructions with a bunch of intermediate nested types for operands that included up to 6 levels of nested brackets.  We could also output blocks of related instructions, such as the preamble of a function, in one format statement, where they had to specify the complete structure for each instruction. <br><br>  Our team considered the possibility of using such an abstraction as theirs.  It was easier to be able to either output the text assembly or directly output the machine code, but this was not a requirement of the course.  The same could be done with less code and better performance, using X86Writer <code>X86Writer</code> with methods like <code>push(reg: Register)</code> .  We also took into account that this could simplify debugging and testing, but we realized that viewing the generated text assembler is actually easier to read and test with the help of <a href="https://docs.rs/insta/0.8.1/insta/">testing snapshots</a> , if liberal comments are inserted.  But we (apparently, correctly) predicted that it would take a lot of additional code, and there was no real benefit, considering our real needs, so we did not worry. <br><br>  It is good to compare this with the intermediate representation, which the C ++ team used as an additional function, which robbed them of only 500 additional lines.  They used a very simple structure (for simple type definitions and build code) that used operations close to what Java required.  This meant that their intermediate representation was much smaller (and, therefore, required less build code) than the resulting assembler, since many language operations, such as calls and casts, were extended to many assembly instructions.  They also say that it really helped debug, since it cut a lot of garbage and improved readability.  The presentation of a higher level also made it possible to do some simple optimizations on their intermediate presentation.  The C ++ team came up with a really good design that brought them much more benefit with a lot less code. <br><br>  In general, it seems that the common cause of the threefold difference in volume is due to the consistent adoption of various design decisions, both large and small, in the direction of a larger amount of code.  They implemented a number of abstractions that we didn't do ‚Äî they added more code, and missed some of our abstractions, which reduce the amount of code. <br><br>  This result really surprised me.  I knew that design decisions matter, but I wouldn‚Äôt have guessed in advance that they would lead to any differences of this size, given that I only examined people I consider to be strong, competent programmers.  Of all the comparison results, this is the most significant for me.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It probably helped me that I read a lot about how to write compilers before I took this course, so I could use clever projects that other people invented and found to work well, like AST visitors and the recursive descent method, although they were not taught we have on the course.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What really made me think is the cost of abstraction. Abstractions can facilitate expansion in the future or protect against some types of errors, but they need to be taken into account given that you can get three times more code for understanding and refactoring, three times more places for errors and less time for testing and further development Our training course was different from the real world: we knew for sure that we would never touch the code after it was developed, this eliminates the advantages of proactive abstraction. However, if I had to choose which compiler to expand with an arbitrary function that you will say later, I would choose ours, even without considering my familiarity with it. Just because it has a lot less code to understand, and I could potentially choose the best abstraction for the requirements (for example,intermediate presentation of the C ++ team when I know the specific requirements.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Also in my view the taxonomy of abstractions has strengthened: there are those that shorten the code, considering only current requirements, like our visitor template, and there are abstractions that add code, but provide the advantages of extensibility, debugging, or correctness. </font></font><br><br><a name="6"></a><h1>  Scala </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I also talked with a friend who was doing a Scala project in the previous semester, but the project and tests were exactly the same. </font><font style="vertical-align: inherit;">Their compiler consisted of 4141 lines and ~ 160 KB of code, not counting the tests. </font><font style="vertical-align: inherit;">They passed 8 of 10 secret tests and 100% of open tests and did not implement any additional functions. </font><font style="vertical-align: inherit;">Thus, in comparison with our 5906 lines without additional functions and tests, their compiler is 30% less.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One of the factors of small-scale design was a different approach to parsing. The course allowed the use of the command line tool for the LR table generator. Nobody used it except this command. This eliminated the need to implement the LR table generator. They also managed to avoid writing the LR grammar using a 150-line Python script that scraped the Java grammar web page they found on the Internet and translated it into generator input format. They still needed to do some kind of tree in Scala, but on the whole the parsing stage was 1073 lines compared to our 1443, although our gradient descent method here gave an advantage in terms of volume compared to all other teams.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The rest of their compiler was also smaller than ours, without any obvious big differences in design, although I didn‚Äôt delve into the code. </font><font style="vertical-align: inherit;">I suspect that this is due to differences in the expressiveness of Scala and Rust. </font><font style="vertical-align: inherit;">Scala and Rust have similar programming functionality, useful for compilers, such as pattern matching, but Scala managed memory saves the code needed for borrow borrower in Rust. </font><font style="vertical-align: inherit;">In addition, Scala has more varied syntactic sugar than Rust.</font></font><br><br><a name="7"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ocaml </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since all members of our team are interning at </font></font><a href="https://www.janestreet.com/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jane Street</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (technology computational trading company - approx. Lane.), I was particularly interested to see the results of other former Jane Street interns who chose OCaml to write the compiler. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Their compiler was 10914 lines and 377 KB, including a small amount of test code and no additional functions. They passed 9/10 secret tests and all public tests.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Like other groups, it seems that the main difference in size is associated with using the LR parser and tree rewriting for parsing, as well as the regex-&gt; NFA-&gt; DFA conversion pipeline for lexical analysis. Their frontend (lexical analysis, syntax analysis, AST construction) is 5548 lines, and ours is 2164, with similar ratios for bytes. They also used </font></font><a href="https://blog.janestreet.com/testing-with-expectations/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">testing</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> for their parser </font><a href="https://blog.janestreet.com/testing-with-expectations/"><font style="vertical-align: inherit;">with the expectation</font></a><font style="vertical-align: inherit;"> that looks like our snapshot tests, which put the expected output out of the code, so their tests of the parser were ~ 600 lines of the total, and ours were about 200.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This leaves for the rest of the compiler 5366 lines for them (461 lines of which are interface files with type declarations) and 4642 for us, the difference is only 15% if their interface files are counted, and almost the same size if not counted. </font><font style="vertical-align: inherit;">It seems that, apart from our design solutions for parsing, Rust and OCaml seem equally expressive, except that OCaml needs interface files, but Rust does not.</font></font><br><br><h1>  Conclusion </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In general, I am very glad that I made this comparison, I learned a lot and was surprised many times. </font><font style="vertical-align: inherit;">I think the general conclusion is that design decisions are much more important than language, but language matters because it gives you the tools to implement different designs.</font></font></div><p>Source: <a href="https://habr.com/ru/post/456638/">https://habr.com/ru/post/456638/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../456618/index.html">Larabeer Moscow - June 21</a></li>
<li><a href="../456622/index.html">How to create an OS certified for I class of protection</a></li>
<li><a href="../456624/index.html">Useful Python Tools</a></li>
<li><a href="../456632/index.html">We are building the fourth floor of C ++ templates in RESTinio. Why and how?</a></li>
<li><a href="../456634/index.html">Nginx recipes: CAS (central authorization service)</a></li>
<li><a href="../456640/index.html">Reviewing the Competitive Intelligence Competition on PHDays 9</a></li>
<li><a href="../456642/index.html">The first issue of the corporate master program of JetBrains and ITMO University</a></li>
<li><a href="../456644/index.html">On Kickstarter appeared budget photopolymer 3D-printer Longer</a></li>
<li><a href="../456646/index.html">Indulgence - how to get rid of debts on tasks</a></li>
<li><a href="../456654/index.html">Not so terrible ERP project, as he is painted</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>