<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Learning OpenCV Cascade Haar</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="On Habr√© there are already several articles about the cascade of Haar ( one , two , three ). There is even one where the learning process is affected,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Learning OpenCV Cascade Haar</h1><div class="post__text post__text-html js-mediator-article">  On Habr√© there are already several articles about the cascade of Haar ( <a href="http://habrahabr.ru/post/133826/">one</a> , <a href="http://habrahabr.ru/post/134857/">two</a> , <a href="http://habrahabr.ru/post/67937/">three</a> ).  There is even one where the learning process is affected, but in relation to the task described.  There are a couple of good articles in English on the topic of education ( <a href="http://note.sonots.com/SciSoftware/haartraining.html">first</a> , <a href="http://opencvuser.blogspot.be/2011/08/creating-haar-cascade-classifier-aka.html">second</a> , <a href="http://coding-robin.de/2013/07/22/train-your-own-opencv-haar-classifier.html">third</a> ), but, in my opinion, they are confused: they either tell very little or too much and about everything - it‚Äôs difficult to select the right idea. <br><img src="https://habrastorage.org/getpro/habr/post_images/bb9/97f/9cf/bb997f9cf7a3fd5510f3bfa57d7c5151.jpg" alt="image"><br>  In this article I will try to show how to train a cascade from scratch in a few hours, having trained to search for a simple object in a video stream (an example would be a charming owl from a photo).  All training samples and programs will be attached. <br>  Why is all this necessary?  Cascade Haar is one of the easiest ways to recognize classes of objects with high speed.  These include the faces and hands of people, car numbers, and pedestrians.  With the Haar detector, it‚Äôs easy to find animals in the frame (by the way, surprisingly, I haven‚Äôt seen any automatic tits feeder on a raspberry pi).  In addition, there are ready-made OpenCV implementations for most of the existing systems (I even met it for blackfin).  All this makes Haar one of the most convenient methods for solving video processing tasks even for people who have never worked with video processing. <br><a name="habracut"></a><br><h5>  Process </h5><br>  The entire sample learning process does not require programming skills.  For this there are ready-made console programs that are present in the main assembly of OpenCV.  The use of a cascade requires a minimum programming skill, it is enough to change a couple of lines already in the finished example, which are under C, C ++, C #, Java, Python, etc. <br><br><h5>  What will we need? </h5><br><ul><li>  Photos of the subject in real habitat.  The more similar the sample is to what we recognize, the better the results will be.  If you train the face recognizer from photographs of people from the studio, then on the street the recognition level will be lower than in the studio.  This is influenced by shadows, clothing, and facial expression. </li><li>  A selection of negative photographs in which there is no recognition object.  Photos must be taken in the same environment where the recognition will be.  If a sample of counterexamples is made from photographs at the north pole, and you recognize it in the tropical jungle, it will not work. </li><li>  OpenCV.  This article uses current 2.4.7.  All examples of programs located here will work with him.  But if you make a project from scratch - better download the new OpenCV. </li></ul><br><h5>  Where to get examples and counterexamples? </h5><br>  There are several ways: <br><ul><li>  Take the camera yourself. </li><li>  Use the ready base, if it is on the Internet.  For individuals, rooms, eyes, emotions, people, etc.  There are many such bases. </li><li>  Turn on the camcorder and take a set of pictures from the video stream. </li><li>  Use the software attached to OpenCV and generate new samples from the existing 2-3 images.  This option is described in detail here, I will not dwell on it.  It works badly, for serious purposes it is no good. </li></ul><br>  For options 1-3 there are several programs that simplify life.  First of all, these are programs that allow you to mark up photos.  Articles in English use a self-written program " <a href="https://code.google.com/p/imageclipper/">imageclipper</a> ".  I did not like it, because it does not work correctly with large photos.  For myself, I wrote a program that was convenient for me to work with.  The source code and code are attached in the ‚ÄúDownloads‚Äù section of this article (PictureCropper). <br><br><h5>  How many photos do you need? </h5><br>  For a stable face detector, this is 3000-4000 positive examples and as many negative ones.  From 500 positive and 1000 negative I made a stable number detector.  For the detector shown in this article, I took 250 positive and 500 negative photos. <br>  The larger and more diverse the sample, the more stable it is and the longer it takes. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  Getting to work. </h5><br>  In order to start learning, we need to have 2 folders with examples.  ‚ÄúGood‚Äù is a folder with positive images, ‚ÄúBad‚Äù is with negative images.  <b>IMPORTANT</b> !  At least in one of the previous versions of the training program, it did not respond well to the presence of spaces and dots in the file names.  Russian does not accept any version.  Try to call the image "0.bmp", "1.  bmp ‚Äùitd  The formats "bmp" and "jpg" work stably, with the rest did not check. <br>  For each folder you need to have a text file that describes the images used.  Let's call them ‚ÄúGood.dat‚Äù and ‚ÄúBad.dat‚Äù.  <b>IMPORTANT</b> !  This file should be at the same file system level as the folder. <br><pre><code class="bash hljs">\Good \1. bmp \2. bmp \.... bmp \N. bmp \Bad \1. bmp \2. bmp \.... bmp \N. bmp Good.dat Bad.dat</code> </pre> <br>  Description files for negative and positive objects have different structure.  For a file of negative examples, this is simply a list of relative paths to the images: <br><pre> <code class="bash hljs">Bad\1. bmp Bad\2. bmp Bad\.... bmp Bad\N. bmp</code> </pre><br>  For files with positive examples, the record is a bit trickier.  In addition to the path, the position of the object and its size must be indicated.  In principle, each positive image may contain several examples of objects.  But I do not advise.  Best of all: one frame - one object. <br><pre> <code class="bash hljs">Good \0.bmp 1 0 0 414 148 Good \1.bmp 1 0 0 568 164 Good \....bmp 1 0 0 440 144 Good \N.bmp 1 0 0 590 182</code> </pre><br>  "Good \ 0.bmp" is the address of the object relative to the description file.  "1" - the number of positive objects in the image.  "0 0 414 148" - coordinates of the rectangle on the image in which the object is located.  If there are several objects, the record takes the form: "Good \ 0.bmp 2 100 200 50 50 300 300 25 25". <br>  I repeat that it is most convenient when each object is a separate frame, while the coordinates of the object are equal to the frame size. <br><br>  Example of a positive sample: <br><img src="https://habrastorage.org/getpro/habr/post_images/5ed/798/c7d/5ed798c7d4f3514b8aed75b9f6690865.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/2fa/3ab/ee3/2fa3abee3fbd6baee0455099266128c6.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/9f3/8a8/4ce/9f38a84ce01339d43b2468f8a37656a1.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/979/1fb/ff0/9791fbff030f21a0111744d6d2ecd999.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/137/979/e19/137979e19cd0350d58e50f2e46471b16.jpg" alt="image"><br><br>  An example of a negative sample: <br><img src="https://habrastorage.org/getpro/habr/post_images/9d6/ed2/c12/9d6ed2c1284b7aa5c11d3c2d4ee81309.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/981/cdf/c52/981cdfc52390b9a9241f415bb8431193.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/87a/76c/bd9/87a76cbd9f6625e86f0645c803cecb2e.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/e1b/dc2/adb/e1bdc2adb4539f180742a517d778b271.jpg" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/718/6dd/d15/7186ddd151638cf0c4fde9e0b58f3255.jpg" alt="image"><br><br><h5>  Begin to train! </h5><br>  The learning itself takes place in two stages.  The first stage - all positive images are reduced to a common format.  This should be done by a program located in the OpenCV folder.  Take the one that fits your system.  I have this "opencv \ build \ x64 \ vc10 \ bin".  The program is called opencv_createsamples.exe. <br>  To create a bundle of these positive images, run opencv_createsamples through the console: <br><pre> <code class="bash hljs">opencv_createsamples.exe -info E:\BAZAS\Sova\Good.dat -vec samples.vec -w 20 -h 20</code> </pre><br>  -info E: \ BAZAS \ Sova \ Good.dat - description file for positive images.  Either the full address is specified or relative to the opencv_createsamples.exe program. <br>  -vec samples.vec - file in which the base of positive images reduced to a common format will be saved.  The address must be specified relative to the opencv_createsamples.exe program (suppose the full path in the system). <br>  -w 20 -h 20 - the size of the template.  Must approximately reflect the proportions of the desired object.  For example, for persons or for an owl the most suitable proportion of height to width is 1 * 1.  For numbers it is 3 * 1.  And to search for a pencil it is logical to put something like 8 * 1.  The size of the template should be quite small.  Ideally set it so that the person himself could distinguish the depicted object, but not more than that.  The larger the pattern, the longer the learning. <br>  The result of the program is the samples.vec file, which will contain all your positive images in a format close to bmp and with the size w * h. <br><br><h5>  Create a final cascade </h5><br>  To calculate the final cascade, use the opencv_traincascade.exe program, which is located in the same folder as opencv_createsamples.exe.  It works for a long time.  Even very long.  Training a cascade of 500-1000 objects takes almost a whole day.  The example was trained for 2 hours. When calling: <br><pre> <code class="bash hljs">opencv_traincascade.exe -data haarcascade -vec samples.vec -<span class="hljs-built_in"><span class="hljs-built_in">bg</span></span> E:\BAZAS\Sova\Bad.dat -numStages 16 -minhitrate 0.999 -maxFalseAlarmRate 0.4 -numPos 200 -numNeg 500 -w 20 -h 20 -mode ALL -precalcValBufSize 1024 -precalcIdxBufSize 1024</code> </pre><br>  -data haarcascade - the address of the folder where to put the results.  Counted from the root folder of the program.  You need to create in advance, otherwise it will fly out. <br>  -vec samples.vec - the address of the file counted in the last paragraph with positive examples <br>  -bg E: \ BAZAS \ Sova \ Bad.dat - the address of the file describing negative examples <br>  -numStages 16 - the number of cascade levels that the program will train.  The more levels, the more accurate, but the longer.  Their normal amount is from 16 to 25. <br>  -minhitrate 0.999 - coefficient determining the quality of training.  In essence, this is the percentage of ‚Äúcorrect‚Äù detections.  If set to .999, that is, the initial sample will be no more than 1- 0.999 = 0.1% target omission.  The higher the ratio, the higher the false alarm rate.  In principle, if the sample is good, you can set 0.99-0.999.  If the bad (few objects, they are mixed with the background) - then it should be omitted. <br>  -maxFalseAlarmRate 0.4 - false alarm level.  AdaBoost is an algorithm that can pull any level of a false alarm on a sample.  But it is better to do something reasonable.  By default, all set to 0.5.  But perhaps it will make sense to play.  In case the sample is very good, the level of the required alarm will be quickly reached and the training will be stopped. <br>  -numPos 200 - the number of positive examples.  IMPORTANT!  It would seem that there should be the number of files that you had.  But this is not the case (in most manuals this is not noted).  The lower the minhitrate factor, the more your files will be considered unusable.  In most cases, it is enough to put numPos 80% of the positive files you have.  It is better to be safe so that after a day of work the program does not crash with an error :) <br>  -numNeg 500 - the number of negative examples you have.  What we have is what we write. <br>  -w 20 -h 20 - the size of the primitive from the last item. <br>  -mode ALL - to use or not the full set of Haar-signs.  The speed and accuracy of the algorithm depends on this.  But there are situations when a complete set of features is not needed (for example, if your object does not change its orientation). <br>  -precalcValBufSize 1024 -precalcIdxBufSize 1024 is the memory allocated to the process.  It seems that in the latest version of OpenCV, as I said, about as much the program ate, but slightly earlier versions ate about 2 times more.  If during training you plan to use a computer, then put so much memory so that you have enough for further work. <br><br><h5>  Known bugs </h5><br>  It must be said that learning does not suffer from usability.  There are a lot of bugs.  But slowly OpenCV is fixed.  In the latest OpenCV, most of the reasons why the program crashes are explained in some detail.  As a rule, this is a lack of positive or negative examples, unreachable characteristics, crookedly written addresses.  True, there was some kind of glitch with the suspension of training, when I was teaching an owl sample.  Judging from everything, there were too few test cases (I then used 150 owls and 200 counter-examples). <br><br><h5>  results </h5><br>  An example of the algorithm on the video.  It is seen that there are gaps.  But for a sample with only two hundred examples, this is a good result. <br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/nkeGh8Hmz9U%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700191,15700253&amp;usg=ALkJrhjUaDdJOMKwPqWoBjn7zJn7cJ1TPw" frameborder="0" allowfullscreen=""></iframe><br><br><h5>  Sources </h5><br>  As promised, an example of the project and several programs that make life easier.  You can download it entirely either <a href="http://yadi.sk/d/Vhfl1tf0FQxvH">here</a> (rar-archive on Yandex disk), or <a href="https://github.com/ZlodeiBaal/BuboBubo">here</a> (github).  But on githabe, the maximum file size is 100 megs, and the Emgu build (OpenCV for C #), which I use, pulls two large OpenCV files that are not used, but which cannot be excluded from the project.  Both of these files are inside the Bin \ x86 folder, archived in the ‚Äúlagedll.rar‚Äù archive, you just need to pull them out. <br>  The whole project on VS2010, Windows 7. All executable programs are in the "Bin" folder. <br>  <b>VideoCropper</b> - A program for creating sequences from a video camera.  At the start you need to specify the folder to save and mode of operation (creating a positive or negative sample).  The mouse highlights the area to be saved, the space is saved by a space. <br>  <b>PictureCropper</b> - Program for cutting existing database of photos.  At startup, the working folder is indicated.  Creates a subfolder with sliced ‚Äã‚Äãimages.  The mouse is allocated an area that must be saved.  By "s" is saved.  By "r" - save and move to the next image.  By space - just go to the next image. <br>  <b>OwlDetector</b> - the final program looking for an owl <br>  <b>Bad, Good</b> - folders with negative and positive examples <br>  <b>haarcascade</b> - Final cascades obtained during training <br>  <b>Bad.dat, Good.dat</b> - image description files <br>  <b>samples.vec</b> - a file with a set of positive images, prepared for training </div><p>Source: <a href="https://habr.com/ru/post/208092/">https://habr.com/ru/post/208092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../208080/index.html">Winamp will not die: there was a buyer on the player</a></li>
<li><a href="../208082/index.html">Do not rely on color when designing interfaces</a></li>
<li><a href="../208086/index.html">NSA is working on creating a quantum computer for hacking any type of encryption (but so far away from success)</a></li>
<li><a href="../208088/index.html">Solomon's Sort</a></li>
<li><a href="../208090/index.html">A few words about pattern recognition</a></li>
<li><a href="../208094/index.html">Making a simple level editor based on the Inkscape plugin.</a></li>
<li><a href="../208096/index.html">Disable RC4 encryption in Firefox</a></li>
<li><a href="../208100/index.html">How to choose a name for an IT product and IT company</a></li>
<li><a href="../208104/index.html">Restoring open files but deleted from the linux file system</a></li>
<li><a href="../208106/index.html">Introducing Cisco TelePresence</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>