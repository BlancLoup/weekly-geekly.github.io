<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>In-depth training in the garage - Return smiles</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This is the third article in the series about the definition of a smile on the face. 

 In-depth training in the garage - Data Brotherhood 
 In-depth ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>In-depth training in the garage - Return smiles</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/b21/d87/b48/b21d87b481594969b292350f9f688f41.png" width="520" alt="An example of the system"><br>  This is the third article in the series about the definition of a smile on the face. <br><br>  <a href="https://habrahabr.ru/post/277267/">In-depth training in the garage - Data Brotherhood</a> <br>  <a href="https://habrahabr.ru/post/277345/">In-depth training in the garage - Two networks</a> <br>  In-depth training in the garage - Return smiles <br><br><h2>  So what about the smiles? </h2><br>  Fuh, well, finally, face detection works, you can learn the smile recognition network.  But what to learn?  There are no open data sets.  And from how long in the previous part I got to, in fact, the training of models, you should have already understood that in in-depth training the data is everything.  And they need a lot. <br><a name="habracut"></a><br>  There are open data sets with marked up emotions.  But this does not suit me, because I want to understand not facial expressions, but caricature, specially constructed facial expressions, and this is not at all like real emotions. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Well, it is necessary to collect your training sample!  Photograph yourself?  But one person is definitely not enough.  After wandering through the pictures of Google and Yandex, I went to YouTube.  And here, among the hordes of cats and latspleyev I came across this video: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/hCxv7TxbNxo%3Ffeature%3Doembed&amp;xid=17259,15700002,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhikXDOmEi28GrtH03N_mrF12V2mAw" frameborder="0" allowfullscreen=""></iframe><br>  Hooray!  What you need!  As a result of a brief search, I dug out a couple of similar videos and started on the markup, which is also quite fun, and gave reason to deal with OpenCV for python, but yes the article is not about that. <br><br>  The result was such a dataset that I absolutely did not believe in the success of the operation: <br><br><ol><li>  It is very small (about three thousand pictures). </li><li>  Only about twenty people. </li><li>  Only girls (this was a plus during the markup, but the network does not understand the result of the men at all) </li><li>  I marked up the face on almost every frame, so it turned out a dozen or a half of very similar pictures of each pair (girl, smile). </li><li>  Quite a lot of classes for such a number of photos: 17. </li><li>  There are similar smilies.  In fact, as a result, the network periodically confuses them. </li></ol><br>  But since the work is done, why not try?  I took the architecture of a large network from the detection module, replaced the classifier at the top from two classes to seventeen and went to teach. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_net_smiles</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input)</span></span></span><span class="hljs-function">:</span></span> network = lasagne.layers.InputLayer(shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">48</span></span>, <span class="hljs-number"><span class="hljs-number">48</span></span>), input_var=input) network = lasagne.layers.dropout(network, p=<span class="hljs-number"><span class="hljs-number">.1</span></span>) network = conv(network, num_filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, filter_size=(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), nolin=relu) network = batchnorm.batch_norm(network) network = max_pool(network) network = conv(network, num_filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, filter_size=(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), nolin=relu) network = batchnorm.batch_norm(network) network = max_pool(network) network = conv(network, num_filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, filter_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), nolin=relu) network = batchnorm.batch_norm(network) network = max_pool(network) network = conv(network, num_filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, filter_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), nolin=relu) network = batchnorm.batch_norm(network) network = max_pool(network) network = DenseLayer(lasagne.layers.dropout(network, p=<span class="hljs-number"><span class="hljs-number">.3</span></span>), num_units=<span class="hljs-number"><span class="hljs-number">256</span></span>, nolin=relu) network = batchnorm.batch_norm(network) network = DenseLayer(lasagne.layers.dropout(network, p=<span class="hljs-number"><span class="hljs-number">.3</span></span>), num_units=<span class="hljs-number"><span class="hljs-number">17</span></span>, nolin=linear) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> network</code> </pre> <br>  And I was right!  I will not even show the picture, it turned out terribly.  However, having learned from experience, I didn‚Äôt despair right away, but with a python I was ready to encode the most varied augmentation of data, trying to at least get closer to the ‚Äúeffectively infinite‚Äù data set paradigm, similar to augmentation for detection.  I will not give the algorithm, it is exactly the same as it was for detection.  I‚Äôll say right away that the efficiency of the supplement is much lower here than for detection, because in fact there are very few unique photos, and all those three thousand are neighboring frames that differ little and, in fact, are similar to this very augmentation. <br><br>  And again, the failure: on validation girls (i.e., girls allocated entirely to the validation set) is very poorly defined.  As I expected, 20 girls are too few for everything to work well, so I decided to slightly weaken the requirements and not allocate whole girls to a validation set, as a result of which the model is expected to retrain for specific people from the training sample and it will work poorly on other people what happened;  but do not retrain for specific images (there is a lot of data with augmentation!). <br><br>  In such conditions it turned out even well: <br><img src="https://habrastorage.org/files/90e/c94/f87/90ec94f876aa4b7fba036a31632bd63b.png" height="264" alt="Mistake"><img src="https://habrastorage.org/files/108/a51/7c1/108a517c12a6449ebe9a5f064ede49b3.png" height="264" alt="Accuracy"><br><br>  It can be seen that the split saver converges, and my previous experiments suggest that increasing the amount of data is the most kosher way to fix it, but, alas, I don‚Äôt have any more data: they are rather difficult to find and even harder to mark. <br><br><h2>  System </h2><br>  Well, finally, the whole pipeline.  One picture instead of a thousand words: <br><br><img src="https://habrastorage.org/files/7a4/8f2/8ae/7a48f28aeb4341a59a9be3ba4f15b8a2.png" alt="Work example"><br>  Here I will note that at the end of the detection of faces, two squares turned out, and not one, because the areas of their intersection are not enough for the algorithm to understand that they belong to the same person.  I am still working on this and there is no definite solution.  It is necessary to come up with an algorithm for the task, which I did for the demo: I chose one best square to classify the smiley on it. <br><br>  Also, if you just take the square found by the detector and get a smile on it, it turns out bad: after all, this grid was trained on too little data, and it is very sensitive to changes in inputs.  And the detector can very well produce very different results: covering the face, and the center of the face, and sometimes even just a piece of the face.  This classifier of smiles reacts very badly, so instead of taking one square, I take 45 people standing next to each other and hold a vote.  The number at the bottom left is just what percentage of the maximum this smiley scored.  For each of the 45 windows, the classifier gives the distribution by smiles, which I simply vectorially summarize over all windows and divide by the sum over all smiles (which should be equal to 45, since the sum of smiles from each window, being the probability distribution, is equal to 1 ). <br><br><pre> <code class="python hljs">smile_probs_sum = T.sum(lasagne.layers.get_output(net_smiles, deterministic=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># sum probabilities over all windows classify_smiles = theano.function([T.tensor4("input")], [T.argmax(smile_probs_sum), T.max(smile_probs_sum)]) # get best class and its score def score(frames): smile_cls, smile_val = classify_smiles(*frames) smile_val = float(smile_val) return smile_cls, smile_val / 17</span></span></code> </pre> <br><h2>  Show the result already! </h2><br>  As a test of the system, I drove it to the original video, one of those I studied (yes, this is not full of wines, but it was conceived, for a complete wine, you need to collect a lot of data from a large number of people).  At the same time, the video was slowed down several times to keep up with the work of the network: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/yJrHcoQhBJI%3Ffeature%3Doembed&amp;xid=17259,15700002,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhiXQAyzbUWfe1pH7M_AzK5sK3YV4w" frameborder="0" allowfullscreen=""></iframe><br><h2>  Bonus </h2><br>  As I said above, I have not collected enough data for training to train a full-fledged model that would work on arbitrary people.  Therefore, it was decided to make a crowdfunding platform for collecting this data <i>(ha ha, what a great name)</i> ! <br><br>  So, a <a href="https://95.213.131.138:3000/">small service</a> was made <a href="https://95.213.131.138:3000/">on Go called Smielfy v0.1</a> , which invites you to portray a smiley, shows an example of how it was done before you in a video on YouTube and gives you the opportunity to take a photo and send your favorite photos to the server, where it will be carefully put into a folder that I, if I have enough data to accumulate, can be used to train a cooler model that will already honestly be able to cope with the definition of a smiley on any person and which can be inserted into a (non-commercial) application! <br><br>  The service uses a self-signed SSL certificate, which is needed only for the browser to allow using the webcam API. <br><br><h2>  Thanks </h2><br>  Thanks to <a href="https://habrahabr.ru/users/zoberg/" class="user_link">Zoberg</a> , who made the service Smielfy literally in one day yesterday and who helped me to mark out smiles. <br>  Thanks to <a href="https://habrahabr.ru/users/geniyx/" class="user_link">GeniyX</a> , which is currently redesigning Smielfy and who was the main developer of DeepEvent v2.0 - a new version of the system for monitoring and visualizing learning of neural networks. <br></div><p>Source: <a href="https://habr.com/ru/post/277403/">https://habr.com/ru/post/277403/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../277393/index.html">Round-robin default gateway breaks source routing for OpenVPN server</a></li>
<li><a href="../277395/index.html">Axure 7 for beginners in 100 minutes</a></li>
<li><a href="../277397/index.html">Introducing the Intel RealSense Driver for Linux & OS X</a></li>
<li><a href="../277399/index.html">My rules for a good interface design</a></li>
<li><a href="../277401/index.html">Storage for 100 thousand or how to save on expensive projects</a></li>
<li><a href="../277405/index.html">Reverse of the AC48 RS485 protocol from Perco. Keep the lines of your access control system from invasion</a></li>
<li><a href="../277407/index.html">Evaluation and optimization of computing performance on multi-core systems</a></li>
<li><a href="../277411/index.html">I have an idea: Android data protection with eCryptfs</a></li>
<li><a href="../277413/index.html">Creating ontology in Prot√©g√© 5.0</a></li>
<li><a href="../277415/index.html">Welcome to the ice rink</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>