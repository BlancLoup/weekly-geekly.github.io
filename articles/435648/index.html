<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Bot generates textbooks from Wikipedia articles</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Example wikibooks (illustration from a scientific article ) 

 Everyone knows that Wikipedia is a valuable information resource. You can spend hours s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Bot generates textbooks from Wikipedia articles</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/webt/zb/zk/si/zbzksik2xkxxrvrznvl4717mr0o.png" width="450"></div><br>  <i><font color="gray">Example wikibooks (illustration from a <a href="https://arxiv.org/abs/1812.10937">scientific article</a> )</font></i> <br><br>  Everyone knows that Wikipedia is a valuable information resource.  You can spend hours studying the topic, moving from one link to another to get the context of the subject of interest.  But it is not always obvious how to collect all the content on any one common topic.  For example, how to combine all the articles on inorganic chemistry or the history of the Middle Ages, summarizing the most important?  Approximately Shahar Admati and his colleagues from Ben-Gurion in the Negev (Israel), the developers of the machine learning program <a href="https://arxiv.org/abs/1812.10937">Wikibook-Bot,</a> tried to do this. <br><a name="habracut"></a><br>  Wikipedia and the textbook are different things.  That is why the <a href="https://ru.wikibooks.org/wiki/%25D0%2597%25D0%25B0%25D0%25B3%25D0%25BB%25D0%25B0%25D0%25B2%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B8%25D1%2586%25D0%25B0">Wikibooks</a> project was created, where people are jointly trying to summarize the most important thing on a topic.  For example, you can find a textbook on machine learning for more than 6,000 pages, with updated sections on neural networks, genetic algorithms, and machine vision. <br><br>  Wikibook-Bot solves several machine learning problems.  First, this is the task of <b>classification</b> , that is, it is necessary to determine whether the article belongs to a particular Wikibooks.  Secondly, it is necessary to divide the selected articles into chapters - this is the task of <b>clustering</b> .  It was solved by known algorithms.  Finally, the task of <b>systematization</b> , which includes two subtasks: the order of the articles in each chapter and the order of the chapters themselves. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/2n/rz/8h/2nrz8hnhkey_vm38nb2v3stbjeg.png"><br><br>  In fact, the program works relatively simply.  The principle is clear to all who are faced with the training of neural networks.  The first step is to create a training data set.  Of approximately 6,700 existing English language books, books with more than 1000 views and 10 or more articles were selected. <br><br><img src="https://habrastorage.org/webt/yk/ph/gd/ykphgde63sclodusgshyojtvilc.png"><br><br>  Since these wikibooks form a kind of gold standard for both learning and testing, the developers took it as a quality standard.  After the neural network was trained, further work was divided into several steps listed above: classification, clustering and systematization.  The work begins with the textbook name generated by the person.  The name describes any arbitrary concept.  For example, "Machine Learning: A Complete Guide." <br><br>  The first task is to sort the entire set of articles and determine which of them are relevant enough for inclusion in this topic.  ‚ÄúThis task is difficult because of the huge amount of articles on Wikipedia and the need to choose the most relevant articles from the millions available,‚Äù the authors write in a scientific paper.  To solve, they used the Wikipedia network structure, because some articles often refer to others.  It is reasonable to assume that the related article will also be on the topic. <br><br>  So, the work begins with a small core of articles, in the title of which the given title is mentioned.  Then all articles are determined that are at a distance of up to three transitions from the core.  But how many of the articles found are included in the textbook?  The answer to this question is given by wikibooks created by people.  Automatic analysis of their content allows you to determine how much Wikipedia content in human-created books is included in the textbook. <br><br>  Each person-created wikibook has a network structure defined by the number of links pointing to other articles, a certain number of links pointing to pages, ranking of the articles included, and so on.  The developed algorithm analyzes each automatically selected article for a given topic and answers the question: if you include it in the wikibooks, will its network structure become more similar to human-created books or not.  If not, the article is omitted. <br><br>  Based mainly on learning data and existing methods of machine learning, other problems are solved.  Thus, the team was able to automatically generate Wikibooks that have already been created by people.  The effectiveness of the proposed method was evaluated by comparing automatically generated books with 407 real wikibooks.  It is said that for all the tasks we managed to get high and statistically significant results when comparing.  But still, the true efficiency of the algorithm can be assessed after generating wikibooks on other topics, and not only on those on which it was trained. <br><br>  The description of the bot is published in the form of a scientific article <a href="https://arxiv.org/abs/1812.10937">‚ÄúWikibook-Bot - automatic generation of books from Wikipedia‚Äù</a> on the site of preprints arXiv.org. </div><p>Source: <a href="https://habr.com/ru/post/435648/">https://habr.com/ru/post/435648/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../435638/index.html">About the happiness of developers and where to find it</a></li>
<li><a href="../435640/index.html">The event digest for HR-specialists in the field of IT in January 2019</a></li>
<li><a href="../435642/index.html">Pentax Auto 110: ‚Äúin which cam the camera?‚Äù</a></li>
<li><a href="../435644/index.html">Zoo afl phasers</a></li>
<li><a href="../435646/index.html">NB-IoT, Narrow Band Internet of Things. General information, technology features</a></li>
<li><a href="../435650/index.html">How to embed C-library in Swift-framework</a></li>
<li><a href="../435652/index.html">How not to continue passwords in Python scripts</a></li>
<li><a href="../435654/index.html">Pitfalls of custom CSS properties</a></li>
<li><a href="../435656/index.html">Rolls-Royce among scooters - Ninebot KickScooter ES4 by Segway</a></li>
<li><a href="../435658/index.html">Chinese internet censoring</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>