<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>High Availability Cluster on Red Hat Cluster Suite</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In search of a solution for building a HA cluster on linux, I came across a rather interesting product that, according to my observations, was unfairl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>High Availability Cluster on Red Hat Cluster Suite</h1><div class="post__text post__text-html js-mediator-article">  In search of a solution for building a HA cluster on linux, I came across a rather interesting product that, according to my observations, was unfairly deprived of the attention of a respected community.  Judging by the Russian-language articles, if you need to organize fault tolerance at the service level, the use of heartbeat and pacemaker is more popular.  Neither the first nor the second solution has taken root in our company, I don‚Äôt know why.  The complexity of configuration and use, low stability, lack of detailed and updated documentation, support, may have played a role. <br><br>  After the next update of centos, we discovered that the pacemaker developer stopped supporting the repository for this OS, and in the official repositories there was an assembly implying a completely different configuration (cman instead of corosync).  There was no desire to reconfigure pacemaker, and we began to look for another solution.  On one of the English-speaking forums, I read about the Red Hat Cluster Suite, we decided to try it. <br><br><h5>  general information </h5><br><img align="right" src="https://habrastorage.org/storage2/ba1/0c9/071/ba10c9071d3a0bb15bc86cf5aa9a8787.jpg"><br>  RHCS consists of several main components: <br><ul><li>  <b>cman</b> - responsible for clustering, interaction between nodes, quorum.  In essence, it collects the cluster. </li><li>  <b>rgmanager</b> is a cluster resource manager, is engaged in adding, monitoring, managing cluster resource groups. </li><li>  <b>ricci</b> - daemon for remote cluster management </li><li>  <b>luci</b> is a beautiful web interface that connects to ricci on all nodes and provides centralized control through a web interface. </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As in heartbeat and pacemaker, cluster resources are managed by standardized scripts (resource agents, RA).  The cardinal difference from pacemaker is that redhat does not mean adding custom custom RAs to the system.  But this is more than compensated by the fact that there is a universal resource agent for adding ordinary init scripts, it is called script. <br><br>  Resource management is only at the level of service groups.  The resource itself cannot be turned on or off.  To allocate resources among the nodes and prioritize startup on certain nodes, failover domains are used, the domain represents the rules for launching groups of resources on certain nodes, prioritization and failback.  One resource group can be tied to one domain. <br><br><a name="habracut"></a><br><h5>  Setup Guide: </h5><br>  This instruction was tested on centos 6.3 - 6.4. <br><ol><li>  The entire set of packages that will be necessary for the full operation of one node is conveniently grouped into the High Availability group in the repository.  Put them using yum, separately put luci.  At the time of this writing, luci should be installed from the base repository, if installed with epel enabled, an incorrect version of python-webob is installed and luci starts incorrectly. <br><pre><code class="bash hljs">yum groupinstall <span class="hljs-string"><span class="hljs-string">"High Availability"</span></span> yum install --disablerepo=epel* luci</code> </pre> <br></li><li>  To initially launch the first node, you need to set the cluster.conf config (in centos, the default is /etc/cluster/cluster.conf).  For the initial launch we have enough of this configuration: <br><pre> <code class="xml hljs"><span class="hljs-meta"><span class="hljs-meta">&lt;?xml version="1.0"?&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">cluster</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">config_version</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"1"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"cl1"</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">clusternodes</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">clusternode</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"node1"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">nodeid</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"1"</span></span></span><span class="hljs-tag">/&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">clusternodes</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">cluster</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br>  Where node1 is the FQDN of the node where other nodes will communicate with it. <br>  This is the only config that I rules from the console when setting up this system. <br></li><li>  We set the password for the user ricci.  This user is created when the ricci package is installed, and will be used to connect the nodes in the luci web interface. <br><pre> <code class="bash hljs">passwd ricci</code> </pre><br></li><li>  We start services: <br><pre> <code class="bash hljs">service cman start service rgmanager start service modclusterd start service ricci start service luci start</code> </pre><br>  Here it should be noted that it is better to install luci on a separate server that is not clustered in a cluster, so that when the node is unavailable, luci is available. <br><br>  It is also convenient to immediately enable services in autoload: <br><pre> <code class="bash hljs">chkconfig ricci on chkconfig cman on chkconfig rgmanager on chkconfig modclusterd on chkconfig luci on</code> </pre><br></li><li>  Now you can log in to the luci web interface, which, if you start the service properly, goes up via https on port 8084. You can log in as root. <br>  We see a rather beautiful web interface: <br><img src="https://habrastorage.org/storage2/f07/f36/4b7/f07f364b7a52d3d1c874958f0046789e.png"><br>  In which we add our cluster from one node, click Manage clusters -&gt; Add, specify the node name, ricci user password and click Add cluster.  It remains only to add nodes. <br></li><li>  To add a server as a node, it must have the ‚ÄúHigh Availability‚Äù package group installed and ricci launched.  Nodes are added to the cluster management on the Nodes tab, the server name and the password of the ricci user are indicated on it.  After adding the node, ricci synchronizes cluster.conf to it, and then starts all the necessary services on it. <br></li></ol><br><br>  If there is interest, in the next article I can write about using shared storage and fencing on this system. </div><p>Source: <a href="https://habr.com/ru/post/175653/">https://habr.com/ru/post/175653/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../17564/index.html">Patsansky WEB 2.0</a></li>
<li><a href="../175643/index.html">Important points when linking to your site</a></li>
<li><a href="../175645/index.html">OwnCloud installation and configuration</a></li>
<li><a href="../17565/index.html">Startup Idea: Betting</a></li>
<li><a href="../175651/index.html">Problems of long PHP scripts</a></li>
<li><a href="../175655/index.html">How we improved the work of the support service in Yandex.Mail</a></li>
<li><a href="../175657/index.html">Code as an argument in Cach√© ObjectScript</a></li>
<li><a href="../175659/index.html">Globals MUMPS: Extreme Database Programming. Part 1</a></li>
<li><a href="../17566/index.html">RSS and web bookmarks import</a></li>
<li><a href="../175661/index.html">Windows Phone and continuous integration into TeamCity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>