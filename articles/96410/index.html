<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>RSS feeds and torrents</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="RSS feeds for torrent files allowed replacing good old Fido file echo conferences. According to them, new files on a pre-selected topic ‚Äúcame themselv...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>RSS feeds and torrents</h1><div class="post__text post__text-html js-mediator-article">  RSS feeds for torrent files allowed replacing good old Fido file echo conferences.  According to them, new files on a pre-selected topic ‚Äúcame themselves‚Äù, i.e.  it was possible to find out about the updates not by the reviews on the sites, but by sorting the incoming files. <br><br>  The convenience of this is difficult to describe.  Consider the same YouTube, but with real FullHD (which is FullHD, and not what YouTube HD calls), in its convenient player, without lags and advertisements ... In his free time, the computer downloads all the new items itself, and you only choose what to watch from this (and what to kill).  An unacceptable waste of the Internet, a luxury that has become available only in recent years with an increase in speed and an almost universal abolition of traffic tariffing. <br><br><h1>  How it works? </h1><br>  The site accompanying the tracker (mononova, rutracker, bakabt, thepiratebay, animesuki, demonoid, etc.) has the ability to create <em>feeds</em> - pages in the <a href="http://ru.wikipedia.org/wiki/RSS">RSS</a> [wiki] format containing links to new torrent files. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Usually, it is possible to filter (directly on the site, when selecting the desired RSS) what interests you.  For example, tokyotosho allows you to create the correct RSS link with a choice of file types of interest: <a href="http://tokyotosho.info/rss_customize.php">tokyotosho.info/rss_customize.php</a> . <br><br>  In a good case, the link will be a torrent file.  In the bad - a link to the html-page, which will already be a link to the torrent-file.  (we will talk about this subtlety in the implementation section). <br><br>  Then everything is simple: a certain client (torrent client with built-in RSS or a specialized program) periodically downloads RSS, downloads torrent-files from it, downloads the contents of torrents (well, or sends a torrent client to download).  RSS is downloaded every N minutes (I have once an hour), files appear on the disk by themselves. <br><a name="habracut"></a><br><br><h1>  Potential problems </h1><br><ul><li>  The file can be laid out on several trackers.  If we have downloaded a torrent file several times, then we need to download it several times.  Most torrent clients can track this, however, for this they need to remember all downloaded torrent files.  After a year or two, the story becomes too extensive and slow (yes, even in ŒºTorrent).  If the torrents are ‚Äúforgotten‚Äù, they will either swing several times, or (if the torrent client is smart enough) to be in the ‚Äúdownloaded‚Äù and sit.  This raises the problem of lack of peers, and the file sits for a very long time.  Moreover, the second or third time. </li><li>  Torrents can be from different releasers, and we want to have a file in the singular, you need to catch repeats </li><li>  I want to make the torrents swing without the participation of a person (even when he logged out) </li><li>  I want to have a graphical full-featured face and the ability to observe the process when necessary </li><li>  Among the downloaded feeds are likely to be uninteresting torrents, I want to configure the filter so as not to download too much </li><li>  The feed may contain indirect links (i.e. links to the html page, from which you can already download the torrent file) </li><li>  The tracker can be private and require a cookie (login / password) for the feed download and / or torrent files </li></ul><br><br><h1>  Theoretical model </h1><br>  I have never seen this anywhere in its full form, so this can be considered a ‚Äúspherical model in vacuum‚Äù. <br><br><ol><li>  The RSS server downloads all feeds, separately for each user.  Feeds are sent to the download client. </li><li>  Client download downloads torrent files. </li><li>  The client sends the downloaded torrent files to filter on the basis of repetition, undesirability </li><li>  After filtering, the torrent files are transferred to the torrent client in server mode, supporting multiple queues for users and able to find ‚Äúidentical‚Äù things from different users, so as not to download them twice. </li><li>  After the download is complete, hardlink files are put into the "incoming" user, with the copy saved in the personal details of the torrent client until the final siding </li><li>  The torrent client provides each user with either a web-snout or a rich-application interface (better this and that) </li></ol><br><br><h1>  Practical implementation </h1><br>  (under linux) <br><br>  Immediately I say, my current implementation is quite far from the desired, and is a compromise on the amount of work, functionality and convenience. <br><br>  So first: RSS.  I use the rsstail package for this with the -N1l key (just output the tail of the RSS).  Next, I solve the ‚Äúhtml-link‚Äù problem - this is wget, which can download everything recursively by reference (the nesting depth is 1, so we won‚Äôt go far, if the link is a torrent, then there will be no recursion).  I also solve one stupid problem that nyaatorrents created, giving away torrents not in the form of files, but forming them dynamically with the Content-Disposition header. <br><br>  The general line looks like this: <br><br><pre> rsstail -u http://www.nyaatorrents.org/?page=rss\&amp;catid=1\&amp;subcat=37 -N1l | grep http | wget -i - -r -l 1 -nd --content-disposition -A torrent &gt; / dev / null 2&gt; / dev / null
</pre><br>  Due to the natural laziness to write processing the feed list, it was lazy.  Although necessary.  So in the script the same type of lines for all trackers, differing only in address. <br><br>  I do not use private trackers (as far as possible) and I do not have several users on the machine (at least, torrent users), so this functionality is enough for me. <br><br>  All torrents are downloaded to / srv / unsorted-torrents.  From here, they are filtered (as long as I have very primitive filtering by find) using the ‚Äúdelete excess‚Äù method.  And carry. <br><br>  Here is the process of catching replays a little more interesting.  I use the singlemv self-writing program, which in a very compact form looks to see whether such a file was before or not.  And transfers only under the condition that the file was not (after each transfer, the repetition base is updated). <br><br>  After that, all the excess in / srv / unsorted-torrents is nailed. <br><br>  Torrents are transferred to the / srv / torrents-queue directory, which is assigned to the pickup-folder for the torrent client.  In my case, this is a deluge, but, in principle, the scheme should work with any torrent client. <br><br><h1>  Future plans </h1><br>  It is already written in C <a href="http://code.google.com/p/lstorrent/">lstorrent</a> , although without a proper binding (compared to the Python version - threefold savings in memory and 10-fold in speed), allowing you to watch the contents of torrents. <br><br>  In the long run, the gattai project (never crawled to the alpha version), which will determine files with different releasers / translators with the same name and will automatically choose the best quality among them. <br><br>  Not solved the issue in the face.  On the one hand, I want to have a full-fledged download server, on the other hand, I don‚Äôt want to lose a very nice deluge face. <br><br><h1>  Why all these difficulties? </h1><br>  It is better to lose a day, then fly in an hour. <br><br>  After I finished making this system in my area around the month of February, for almost half a year the system has been working without any problems and complaints, neatly folding new items into the incoming.  Moreover, if for some reason there are problems with deluge (for example, plugging due to a pack of slow torrents that cannot be downloaded for weeks), then the torrent files will continue to be collected, i.e.  loss in the "feed" does not occur.  (This is exactly what makes this scheme more interesting than the feed pump that is built into the torrent client). <br><br>  UPD: forgot the most important thing is the singlemv script: <br><br><pre><code class="hljs pgsql">#!/usr/bin/python <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys,os, cPickle #minimalistic command <span class="hljs-type"><span class="hljs-type">line</span></span>: #<span class="hljs-number"><span class="hljs-number">1</span></span>st argument - memory file #<span class="hljs-number"><span class="hljs-number">2</span></span>nd - pre-last - files <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> be moved #last - destignation (<span class="hljs-keyword"><span class="hljs-keyword">where</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> be moved) def singlemv(memory,from_list,<span class="hljs-keyword"><span class="hljs-keyword">to</span></span>): #<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> memory mode to_move=frozenset(from_list) - memory errors=<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> to_move: try: os.<span class="hljs-keyword"><span class="hljs-keyword">rename</span></span>(f, os.path.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">to</span></span>,os.path.basename(f))) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print "error move %s to %s", f, <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> errors.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(f) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> memory|(to_move-errors) def __main__(): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(sys.argv)&lt;<span class="hljs-number"><span class="hljs-number">4</span></span>: print "Usage: singlemv.py memory_file from to" <span class="hljs-keyword"><span class="hljs-keyword">exit</span></span>(<span class="hljs-number"><span class="hljs-number">-1</span></span>) try: memory_file=file(sys.argv[<span class="hljs-number"><span class="hljs-number">1</span></span>],"r") memory=cPickle.<span class="hljs-keyword"><span class="hljs-keyword">load</span></span>(memory_file) memory_file.<span class="hljs-keyword"><span class="hljs-keyword">close</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">type</span></span>(memory) != <span class="hljs-keyword"><span class="hljs-keyword">type</span></span> (frozenset()): print "bad memory file" <span class="hljs-keyword"><span class="hljs-keyword">exit</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> IOError, OSError: memory=frozenset() newmem=singlemv(memory,sys.argv[<span class="hljs-number"><span class="hljs-number">2</span></span>:<span class="hljs-number"><span class="hljs-number">-1</span></span>],sys.argv[<span class="hljs-number"><span class="hljs-number">-1</span></span>]) memory_file=file(sys.argv[<span class="hljs-number"><span class="hljs-number">1</span></span>],"w") cPickle.dump(newmem,memory_file) memory_file.<span class="hljs-keyword"><span class="hljs-keyword">close</span></span>() __main__()</code> </pre> <br>  All the beauty of the program - in the line <code>to_move=frozenset(from_list) - memory</code> (set difference). </div><p>Source: <a href="https://habr.com/ru/post/96410/">https://habr.com/ru/post/96410/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../96399/index.html">Protecting images from copying without the "watermark" - protection against a fool</a></li>
<li><a href="../96405/index.html">Twitter bought Smallthought Systems</a></li>
<li><a href="../96407/index.html">Safari Reader for Chrome</a></li>
<li><a href="../96408/index.html">Warning about hacking Debian-systems</a></li>
<li><a href="../96409/index.html">New time kill widget and a small contest from Opera</a></li>
<li><a href="../96411/index.html">Effective search engine optimization for web designers</a></li>
<li><a href="../96412/index.html">MakeMap - show yourself on the map</a></li>
<li><a href="../96414/index.html">About the style of answers on the forums</a></li>
<li><a href="../96416/index.html">Dingoo A320 - a fruitful year!</a></li>
<li><a href="../96417/index.html">SCSS - a new portion of glaze from Sass</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>