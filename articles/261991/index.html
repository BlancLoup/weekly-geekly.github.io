<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The magic of tensor algebra: Part 5 - Action on tensors and some other theoretical questions</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content 


1. What is a tensor and what is it for? 
2. Vector and tensor operations. Ranks of tensors 
3. Curved coordinates 
4. Dynamics of a point i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The magic of tensor algebra: Part 5 - Action on tensors and some other theoretical questions</h1><div class="post__text post__text-html js-mediator-article"><h1>  Content </h1><br><ol><li>  <a href="http://habrahabr.ru/post/261421/">What is a tensor and what is it for?</a> </li><li>  <a href="http://habrahabr.ru/post/261615/">Vector and tensor operations.</a>  <a href="http://habrahabr.ru/post/261615/">Ranks of tensors</a> </li><li>  <a href="http://habrahabr.ru/post/261717/">Curved coordinates</a> </li><li>  <a href="http://habrahabr.ru/post/261803/">Dynamics of a point in the tensor representation</a> </li><li>  <a href="http://habrahabr.ru/post/261991/">Actions on tensors and some other theoretical questions</a> </li><li>  <a href="http://habrahabr.ru/post/262129/">Kinematics of free solid.</a>  <a href="http://habrahabr.ru/post/262129/">Nature of angular velocity</a> </li><li>  <a href="http://habrahabr.ru/post/262263/">The final turn of a solid.</a>  <a href="http://habrahabr.ru/post/262263/">Rotation tensor properties and method for calculating it</a> </li><li>  <a href="http://habrahabr.ru/post/262497/">On convolutions of the Levi-Civita tensor</a> </li><li>  <a href="http://habrahabr.ru/post/262801/">Conclusion of the angular velocity tensor through the parameters of the final rotation.</a>  <a href="http://habrahabr.ru/post/262801/">Apply head and maxima</a> </li><li>  <a href="http://habrahabr.ru/post/262957/">Get the angular velocity vector.</a>  <a href="http://habrahabr.ru/post/262957/">We work on the shortcomings</a> </li><li>  <a href="http://habrahabr.ru/post/263345/">Acceleration of the point of the body with free movement.</a>  <a href="http://habrahabr.ru/post/263345/">Solid Corner Acceleration</a> </li><li>  <a href="http://habrahabr.ru/post/263533/">Rodrig ‚Äì Hamilton parameters in solid kinematics</a> </li><li>  <a href="http://habrahabr.ru/post/263565/">SKA Maxima in problems of transformation of tensor expressions.</a>  <a href="http://habrahabr.ru/post/263565/">Angular velocity and acceleration in the parameters of Rodrig-Hamilton</a> </li><li>  <a href="http://habrahabr.ru/post/263687/">Non-standard introduction to solid body dynamics</a> </li><li>  <a href="http://habrahabr.ru/post/263853/">Non-free rigid motion</a> </li><li>  <a href="http://habrahabr.ru/post/264007/">Properties of the inertia tensor of a solid</a> </li><li>  <a href="http://habrahabr.ru/post/264099/">Sketch of nut Janibekov</a> </li><li>  <a href="http://habrahabr.ru/post/264381/">Mathematical modeling of the Janibekov effect</a> </li></ol><br><br><h1>  Introduction </h1><br>  Before continuing the story about the applied aspects of the use of tensor calculus, it is absolutely necessary to touch on the topic indicated by the title.  These questions surfaced implicitly in all previous parts of the cycle.  However, I made some inaccuracies, in particular, the tensor forms of the scalar and vector product in articles <a href="http://habrahabr.ru/post/261421/">1</a> and <a href="http://habrahabr.ru/post/261615/">2</a> were called ‚Äúconvolution‚Äù by me, although in reality they are a combination of convolution and multiplication of tensors.  On addition, multiplication of tensors by number, the tensor product was mentioned only in passing.  About symmetric, antisymmetric tensors in general, there was no talk. <br><br>  In this post we will talk about tensor operations in more detail.  For further exercises, we will need to navigate them well. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In addition, the concept of symmetric and antisymmetric tensors is important.  We learn that any tensor can be decomposed into symmetric and antisymmetric parts, as well as learn about the fact that the antisymmetric part of the tensor can be associated with a pseudovector.  Many physical quantities (for example, angular velocity) are pseudovectors.  And it is the tensor approach to the description of physical phenomena that allows us to reveal the true nature of certain quantities. <br><a name="habracut"></a><br><h1>  1. Four basic actions on tensors </h1><br><h2>  1.1.  Multiplication of a tensor by a scalar and addition of tensors (linear combination) </h2><br>  By multiplication by a number is meant multiplying by this number of each component of the original tensor.  The result is a tensor of the same rank as the original. <br><br>  To add the same, you can only tensors with the same rank.  In non-component writing, the linear combination of tensors looks like this <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BC%7D%20%3D%20%5Clambda%20%5C%2C%20%5Cmathbf%7BA%7D%20%2B%20%5Cmu%20%5C%2C%20%5Cmathbf%7BB%7D" alt="\ mathbf {C} = \ lambda \, \ mathbf {A} + \ mu \, \ mathbf {B}"></div><br>  Where <img src="https://tex.s2cms.ru/svg/%5Clambda%2C%20%5C%2C%20%5Cmu" alt="\ lambda, \, \ mu">  - scalars.  If we go to the component record, then, for example, for tensors of the second rank, this operation looks as follows <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/c_%7Bij%7D%20%3D%20%5Clambda%20%5C%2C%20a_%7Bij%7D%20%2B%20%5Cmu%20%5C%2C%20b_%7Bij%7D" alt="c_ {ij} = \ lambda \, a_ {ij} + \ mu \, b_ {ij}"></div><br><h2>  1.2.  Multiplication of tensors </h2><br>  Multiplication is performed on tensors of any rank.  The result is a total rank tensor.  Let, for example <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Ba%7D" alt="\ mathbf {a}">  - rank tensor (0,1), and <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BB%7D" alt="\ mathbf {B}">  - rank tensor (0,2).  Then the result of their multiplication is the tensor <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BC%7D" alt="\ mathbf {C}">  rank (0.3) <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Ba%7D%20%5C%2C%20%5Cmathbf%7BB%7D%20%3D%20%5Cmathbf%7BC%7D" alt="\ mathbf {a} \, \ mathbf {B} = \ mathbf {C}"></div><br>  or, in component form <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/a_%7Bi%7D%20%5C%2C%20B_%7Bjk%7D%20%3D%20C_%7Bijk%7D" alt="a_ {i} \, B_ {jk} = C_ {ijk}"></div><br>  We have already come across the tensor product in the <a href="http://habrahabr.ru/post/261615/">second article</a> , considering the dyad.  Let's return to this again by multiplying two vectors <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bc%7D%20%3D%20%5Cmathbf%7Ba%7D%20%5C%2C%20%5Cmathbf%7Bb%7D" alt="\ mathbf {c} = \ mathbf {a} \, \ mathbf {b}"></div><br>  what is in component form <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/c%5E%7Bij%7D%20%3D%20a%5E%7B%5C%2Ci%7D%20%5C%2C%20b%5E%7B%5C%2Cj%7D" alt="c ^ {ij} = a ^ {\, i} \, b ^ {\, j}"></div><br>  gives a matrix representation of the resulting dyad <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bc%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%20a%5E1%20%5C%2C%20b%5E1%20%26%26%20a%5E1%20%5C%2C%20b%5E2%20%26%26%20a%5E1%20%5C%2C%20b%5E3%20%5C%5C%20a%5E2%20%5C%2C%20b%5E1%20%26%26%20a%5E2%20%5C%2C%20b%5E2%20%26%26%20a%5E2%20%5C%2C%20b%5E3%20%5C%5C%20a%5E3%20%5C%2C%20b%5E1%20%26%26%20a%5E3%20%5C%2C%20b%5E2%20%26%26%20a%5E3%20%5C%2C%20b%5E3%20%5Cend%7Bbmatrix%7D" alt="\ mathbf {c} = \ begin {bmatrix} a ^ 1 \, b ^ 1 &amp; amp; &amp; amp; a ^ 1 \, b ^ 2 &amp; amp; &amp; amp; a ^ 1 \, b ^ 3 \\ a ^ 2 \, b ^ 1 &amp; amp &amp; amp; a ^ 2 \, b ^ 2 &amp; amp; &amp; amp; a ^ 2 \, b ^ 3 \\ a ^ 3 \, b ^ 1 &amp; amp &amp; amp; a ^ 3 \, b ^ 2 &amp; amp; &amp; amp; a ^ 3 \, b ^ 3 \ end {bmatrix}"></div><br>  From the last examples, in particular, it is clear that in the general case the tensor product is not commutative <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Ba%7D%20%5C%2C%20%5Cmathbf%7Bb%7D%20%5Cne%20%5Cmathbf%7Bb%7D%20%5C%2C%20%5Cmathbf%7Ba%7D" alt="\ mathbf {a} \, \ mathbf {b} \ ne \ mathbf {b} \, \ mathbf {a}"></div><br>  which is very easy to check by writing multiplication in component form and writing out the matrix representation of the dyad <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/d%5E%7B%5C%2Cij%7D%20%3D%20b%5E%7B%5C%2Ci%7D%20%5C%2C%20a%5E%7B%5C%2Cj%7D" alt="d ^ {\, ij} = b ^ {\, i} \, a ^ {\, j}"></div><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bd%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%20b%5E1%20%5C%2C%20a%5E1%20%26%26%20b%5E1%20%5C%2C%20a%5E2%20%26%26%20b%5E1%20%5C%2C%20a%5E3%20%5C%5C%20b%5E2%20%5C%2C%20a%5E1%20%26%26%20b%5E2%20%5C%2C%20a%5E2%20%26%26%20b%5E2%20%5C%2C%20a%5E3%20%5C%5C%20b%5E3%20%5C%2C%20a%5E1%20%26%26%20b%5E3%20%5C%2C%20a%5E2%20%26%26%20b%5E3%20%5C%2C%20a%5E3%20%5Cend%7Bbmatrix%7D" alt="\ mathbf {d} = \ begin {bmatrix} b ^ 1 \, a ^ 1 &amp; amp; &amp; amp; b ^ 1 \, a ^ 2 &amp; amp; &amp; amp; b ^ 1 \, a ^ 3 \\ b ^ 2 \, a ^ 1 &amp; amp &amp; amp; b ^ 2 \, a ^ 2 &amp; amp; &amp; amp; b ^ 2 \, a ^ 3 \\ b ^ 3 \, a ^ 1 &amp; amp &amp; amp; b ^ 3 \, a ^ 2 &amp; amp; &amp; amp; b ^ 3 \, a ^ 3 \ end {bmatrix}"></div><br>  It's obvious that <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bc%7D%20%5Cne%20%5Cmathbf%7Bd%7D" alt="\ mathbf {c} \ ne \ mathbf {d}">  but it‚Äôs also obvious that <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bd%7D%20%3D%20%5Cmathbf%7Bc%7D%5E%7B%5C%2CT%7D" alt="\ mathbf {d} = \ mathbf {c} ^ {\, T}"></div><br>  This is a consequence of performing another action on the tensors. <br><br><h2>  1.3.  Rearrangement of tensor indices </h2><br>  In this case, a new set of quantities is formed from the components of the original tensor, with a different order of indices.  The rank of the tensor does not change.  For example, from the tensor <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BA%7D" alt="\ mathbf {A}">  rank (0.3), you can get three other tensors <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BB%7D" alt="\ mathbf {B}">  , <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BC%7D" alt="\ mathbf {C}">  and <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BD%7D" alt="\ mathbf {D}">  such that <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/B_%7Bijk%7D%20%3D%20A_%7Bjik%7D%2C%20%5Cquad%20C_%7Bijk%7D%20%3D%20A_%7Bkji%7D.%20%5Cquad%20D_%7Bijk%7D%20%3D%20A_%7Bikj%7D" alt="B_ {ijk} = A_ {jik}, \ quad C_ {ijk} = A_ {kji}. \ quad D_ {ijk} = A_ {ikj}"></div><br>  For tensors of second rank, only one permutation is possible, called transposition <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/d_%7Bij%7D%20%3D%20c_%7Bji%7D%20%5Cquad%20%5CRightarrow%20%5Cquad%20%5Cmathbf%7Bd%7D%20%3D%20%5Cmathbf%7Bc%7D%5E%7B%5C%2CT%7D" alt="d_ {ij} = c_ {ji} \ quad \ Rightarrow \ quad \ mathbf {d} = \ mathbf {c} ^ {\, T}"></div><br>  Above, when we looked at the non-commutativity of the tensor product and rearranged the vectors forming the dyad, we just performed the permutation of the indices, because permutation of the factors leads to the permutation of the indices of the resulting tensor <br><br><h2>  1.4.  Convolution </h2><br>  Convolution is the summation of the components of a tensor over a pair of indices.  This action is performed on one tensor and, at the output, gives a tensor with a smaller one by two.  Say, for a second rank tensor, convolution gives a scalar, called, the <em>first principal invariant</em> or <em>trace of the</em> tensor <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7Bii%7D%20%3D%20I_1(%5Cmathbf%7BA%7D)%20%3D%20%5Cmathop%7B%5Crm%20tr%7D%20%5Cmathbf%7BA%7D" alt="A_ {ii} = I_1 (\ mathbf {A}) = \ mathop {\ rm tr} \ mathbf {A}"></div><br>  Convolution is always performed on a pair of <em>differently variable</em> indices (one index must be upper and the other lower). <br><br>  Very often, convolution is combined with the product of tensors.  Sometimes this combination is called the inner product of tensors.  In this case, the tensors first multiply, and then fold the resulting tensor of the total rank.  An example is the scalar product record we used earlier. <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/c%20%3D%20a_%7B%5C%2Ci%7D%20%5C%2C%20a%5E%7B%5C%2Ci%7D" alt="c = a _ {\, i} \, a ^ {\, i}"></div><br>  equivalent to no index <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/c%20%3D%20%5Cmathbf%7Ba%7D%20%5Ccdot%20%5Cmathbf%7Bb%7D" alt="c = \ mathbf {a} \ cdot \ mathbf {b}"></div><br>  The point resembling a scalar product in the index-free record just means the combination of multiplication with convolution.  Convolution is performed on neighbors with a point pair of indices.  We show the whole process deployed.  Covector <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Ba%7D" alt="\ mathbf {a}">  and vectors <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bb%7D" alt="\ mathbf {b}">  multiply form a tensor <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7Bc%7D" alt="\ mathbf {c}">  rank (1,1) <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/c_i%5E%7B%5C%2Cj%7D%20%3D%20a_i%20%5C%2C%20b%5Ej" alt="c_i ^ {\, j} = a_i \, b ^ j"></div><br>  or <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BC%7D%20%3D%20%5Cmathbf%7Ba%7D%20%5C%2C%20%5Cmathbf%7Bb%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%20a_1%20%5C%2C%20b%5E1%20%26%26%20a_2%20%5C%2C%20b%5E1%20%26%26%20a_3%20%5C%2C%20b%5E1%20%5C%5C%20a_1%20%5C%2C%20b%5E2%20%26%26%20a_2%20%5C%2C%20b%5E2%20%26%26%20a_3%20%5C%2C%20b%5E2%20%5C%5C%20a_1%20%5C%2C%20b%5E3%20%26%26%20a_2%20%5C%2C%20b%5E3%20%26%26%20a_3%20%5C%2C%20b%5E3%20%5Cend%7Bbmatrix%7D" alt="\ mathbf {C} = \ mathbf {a} \, \ mathbf {b} = \ begin {bmatrix} a_1 \, b ^ 1 &amp; &amp;; a_2 \, b ^ 1 &amp; amp; a_3 \, b ^ 1 \\ a_1 \, b ^ 2 &amp; amp &amp; amp; a_2 \, b ^ 2 &amp; amp; &amp; amp; a_3 \, b ^ 2 \\ a_1 \, b ^ 3 &amp; amp &amp; amp; a_2 \, b ^ 3 &amp; amp &amp; amp; a_3 \, b ^ 3 \ end {bmatrix}"></div><br>  We turn the resulting tensor on its single pair of indices <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/C_k%5Ek%20%3D%20a_1%20%5C%2C%20b%5E1%20%2B%20a_2%20%5C%2C%20b%5E2%20%2B%20a_3%20%5C%2C%20b%5E3%20%3D%20c" alt="C_k ^ k = a_1 \, b ^ 1 + a_2 \, b ^ 2 + a_3 \, b ^ 3 = c"></div><br>  However, you should not consider this point as a scalar product, because, for example, such an operation <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7Bij%7D%20%3D%20B_%7Bik%7D%20%5C%2C%20C_j%5Ek" alt="A_ {ij} = B_ {ik} \, C_j ^ k"></div><br>  same multiplication combined with convolution <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BA%7D%20%3D%20%5Cmathbf%7BB%7D%20%5Ccdot%20%5Cmathbf%7BC%7D" alt="\ mathbf {A} = \ mathbf {B} \ cdot \ mathbf {C}"></div><br>  but in the sense of the actions performed, it is equivalent to the product of matrices that represent the components of the tensors. <br><br><h2>  2. Symmetric and antisymmetric tensors </h2><br>  We formulate the definition <br><blockquote>  A tensor is said to be symmetric with respect to a pair of indices if it does not change with the interchange of these indices. <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/B_%7Bij%20%5Ccdots%7D%20%3D%20B_%7Bji%20%5Ccdots%7D" alt="B_ {ij \ cdots} = B_ {ji \ cdots}"></div><br>  If the tensor does not change when rearranging any two indices, then it is <em>absolutely symmetric</em> <br></blockquote><br>  And one more definition <br><blockquote>  A tensor is called antisymmetric with respect to a pair of indices if, when they are rearranged, the tensor changes sign <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/B_%7Bij%20%5Ccdots%7D%20%3D%20B_%7Bji%20%5Ccdots%7D" alt="B_ {ij \ cdots} = B_ {ji \ cdots}"></div><br>  If the tensor changes sign when rearranging any two indices, then it is <em>absolutely antisymmetric.</em> <br></blockquote><br>  Any tensor can be decomposed into symmetric and antisymmetric, according to the selected pair of indices, parts.  It is very easy to prove, let tensor be given <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BA%7D" alt="\ mathbf {A}">  .  Let's do equivalent transformations on it. <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7Bij%5Ccdots%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20A_%7Bij%5Ccdots%7D%20%2B%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20A_%7Bij%5Ccdots%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20A_%7Bij%5Ccdots%7D%20%2B%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20A_%7Bij%5Ccdots%7D%20%2B%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20A_%7Bji%5Ccdots%7D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20A_%7Bji%5Ccdots%7D%20%3D" alt="A_ {ij \ cdots} = \ frac {1} {2} \, A_ {ij \ cdots} + \ frac {1} {2} \, A_ {ij \ cdots} = \ frac {1} {2} \ , A_ {ij \ cdots} + \ frac {1} {2} \, A_ {ij \ cdots} + \ frac {1} {2} \, A_ {ji \ cdots} - \ frac {1} {2} \, A_ {ji \ cdots} ="></div><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(A_%7Bij%5Ccdots%7D%20%2B%20A_%7Bji%5Ccdots%7D%20%5Cright%20)%20%2B%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(A_%7Bij%5Ccdots%7D%20-%20A_%7Bji%5Ccdots%7D%20%5Cright%20)%20%3D%20A_%7B(ij)%5Ccdots%7D%20%2B%20A_%7B%5Bij%5D%5Ccdots%7D" alt="= \ frac {1} {2} \ left (A_ {ij \ cdots} + A_ {ji \ cdots} \ right) + \ frac {1} {2} \ left (A_ {ij \ cdots} - A_ {ji \ cdots} \ right) = A _ {(ij) \ cdots} + A _ {[ij] \ cdots}"></div><br>  where is the symmetric part of the tensor <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7B(ij)%5Ccdots%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(A_%7Bij%5Ccdots%7D%20%2B%20A_%7Bji%5Ccdots%7D%20%5Cright%20)%2C" alt="A _ {(ij) \ cdots} = \ frac {1} {2} \ left (A_ {ij \ cdots} + A_ {ji \ cdots} \ right),"></div><br>  and its antisymmetric part <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7B%5Bij%5D%5Ccdots%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(A_%7Bij%5Ccdots%7D%20-%20A_%7Bji%5Ccdots%7D%20%5Cright%20)." alt="A _ {[ij] \ cdots} = \ frac {1} {2} \ left (A_ {ij \ cdots} - A_ {ji \ cdots} \ right)."></div><br>  In order to leave no doubt, we prove, for the tensors we received, symmetry <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7B(ji)%5Ccdots%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(A_%7Bji%5Ccdots%7D%20%2B%20A_%7Bij%5Ccdots%7D%20%5Cright%20)%20%3D%20A_%7B(ij)%5Ccdots%7D" alt="A _ {(ji) \ cdots} = \ frac {1} {2} \ left (A_ {ji \ cdots} + A_ {ij \ cdots} \ right) = A _ {(ij) \ cdots}"></div><br>  and antisymmetry <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/A_%7B%5Bji%5D%5Ccdots%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(A_%7Bji%5Ccdots%7D%20-%20A_%7Bij%5Ccdots%7D%20%5Cright%20)%20%3D%20-%5Cfrac%7B1%7D%7B2%7D%20%5Cleft(%20A_%7Bij%5Ccdots%7D%20-%20A_%7Bji%5Ccdots%7D%20%5Cright%20)%20%3D%20-%20A_%7B%5Bij%5D%5Ccdots%7D" alt="A _ {[ji] \ cdots} = \ frac {1} {2} \ left (A_ {ji \ cdots} - A_ {ij \ cdots} \ right) = - \ frac {1} {2} \ left (A_ {ij \ cdots} - A_ {ji \ cdots} \ right) = - A _ {[ij] \ cdots}"></div><br>  If we talk about tensors of the second rank, then if such a tensor is symmetric, then it is absolutely symmetric too.  The same applies to the antisymmetric tensor of the second rank.  These properties follow directly from our definitions - the second rank tensor has only one pair of indices. <br><br>  Antisymmetric tensor has a curious property.  Let the tensor of the second rank <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BB%7D" alt="\ mathbf {B}">  - antisymmetric.  Then its components satisfy the condition <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/B_%7Bij%7D%20%3D%20-B_%7Bji%7D" alt="B_ {ij} = -B_ {ji}"></div><br>  This condition is feasible only if the diagonal components of the tensor are zeros, since when the indices are rearranged (and the matrix component is transposed), the diagonal components go into themselves.  And the only number that is opposite to itself is zero.  Components symmetrical with respect to the main diagonal have opposite signs. <br><br>  Thus, of the nine components of the antisymmetric tensor of the second rank, only three are independent (this is, of course, a three-dimensional space).  Three independent components form a vector (or covector).  It is logical to assume that there may be a certain vector that uniquely depends on a given antisymmetric tensor.  Let's try to find such a vector. <br><br><h2>  3. Companion vector of the second rank tensor </h2><br>  In order to deal with this issue, I carefully, before the keys on the keyboard overheat, ‚Äúgoogle‚Äù.  I did not find an sensible and at the same time elegant answer to the question formulated by the paragraph, so I offer my answer, which is in some way a compilation and processing of the information I received. <br><br>  Recall the Levi-Civita tensor, about which I have already written in detail <a href="http://habrahabr.ru/post/261615/">here</a> , and build such a tensor <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/C_%7Bij%7D%20%3D%20%5Cvarepsilon_%7Bijk%7D%20%5C%2C%20a%5E%7B%5C%2Ck%7D%20%5Cquad%20(1)" alt="C_ {ij} = \ varepsilon_ {ijk} \, a ^ {\, k} \ quad (1)"></div><br>  We prove that the tensor (1) is antisymmetric.  Rearrange the indexes in it <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/C_%7Bji%7D%20%3D%20%5Cvarepsilon_%7Bjik%7D%20%5C%2C%20a%5E%7B%5C%2Ck%7D%20%3D%20-%5Cvarepsilon_%7Bijk%7D%20%5C%2C%20a%5E%7B%5C%2Ck%7D%20%3D%20-C_%7Bij%7D%20%5Cquad%20(2)" alt="C_ {ji} = \ varepsilon_ {jik} \, a ^ {\, k} = - \ varepsilon_ {ijk} \, a ^ {\, k} = -C_ {ij} \ quad (2)"></div><br>  The minus in (2) emerged due to the fact that the Levi-Civita tensor is an absolutely antisymmetric third-rank tensor.  Permutation of indices in it leads to permutation of the basis vectors, on the mixed product of which the given tensor is built.  Thus, the tensor (1) is really antisymmetric.  Then we can easily find a vector <img src="https://tex.s2cms.ru/svg/a%5E%7B%5C%2Ck%7D" alt="a ^ {\, k}"><br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cvarepsilon%5E%7B%5C%2Cijl%7D%20%5C%2C%20C_%7B%5C%2Cij%7D%20%3D%20%5Cvarepsilon%5E%7B%5C%2Cijl%7D%20%5C%2C%20%5Cvarepsilon_%7B%5C%2Cijk%7D%20%5C%2C%20a%5E%7B%5C%2Ck%7D%20%3D%202%20%5C%2C%20%5Cdelta_%7Bk%7D%5E%7B%5C%2Cl%7D%20%5C%2C%20a%5E%7B%5C%2Ck%7D%20%3D%202%20%5C%2C%20a%5E%7B%5C%2Cl%7D" alt="\ varepsilon ^ {\, ijl} \, C _ {\, ij} = \ varepsilon ^ {\, ijl} \, \ varepsilon _ {\, ijk} \, a ^ {\, k} = 2 \, \ delta_ { k} ^ {\, l} \, a ^ {\, k} = 2 \, a ^ {\, l}"></div><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/a%5E%7B%5C%2Cl%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7B%5C%2Cijl%7D%20%5C%2C%20C_%7B%5C%2Cij%7D%20%5Cquad%20(3)" alt="a ^ {\, l} = \ frac {1} {2} \, \ varepsilon ^ {\, ijl} \, C _ {\, ij} \ quad (3)"></div><br>  <strong>Note</strong> : where two Kronecker deltas came from in (3) can be found in the <a href="http://habrahabr.ru/post/262497/">eighth article of the</a> cycle. <br><br>  antisymmetric tensor <img src="https://tex.s2cms.ru/svg/C_%7Bij%7D" alt="C_ {ij}">  .  The third rank tensor in (3) is a contravariant Levi-Civita tensor, which repeats the properties of a covariant fellow with the only difference that <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cvarepsilon%5E%7Bijk%7D%20%3D%20%5Cbegin%7Bcases%7D%20%2B%20%5Ccfrac%7B1%7D%7B%5Csqrt%20g%7D%2C%20%5Cquad%20P(i%2C%20j%2C%20k)%20%3D%20%2B1%20%5C%5C%20-%5Ccfrac%7B1%7D%7B%5Csqrt%20g%7D%2C%20%5Cquad%20P(i%2C%20j%2C%20k)%20%3D%20-1%20%5C%5C%20%5Cquad%200%2C%20%5Cquad%20i%20%3D%20j%20%5Cvee%20j%20%3D%20k%20%5Cvee%20k%20%3D%20i%20%5Cend%7Bcases%7D%20%5Cquad%20(4)" alt="\ varepsilon ^ {ijk} = \ begin {cases} + \ cfrac {1} {\ sqrt g}, \ quad P (i, j, k) = +1 \\ - \ cfrac {1} {\ sqrt g} , \ quad P (i, j, k) = -1 \\ \ quad 0, \ quad i = j \ vee j = k \ vee k = i \ end {cases} \ quad (4)"></div><br>  - for the right coordinate system (for the left one it is necessary to change the sign of nonzero components to the opposite one).  The components of the vector (3), taking into account the properties of the tensor (4) are determined uniquely <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/a%5E%7B%5C%2C1%7D%20%3D%20%5Cfrac%7B1%7D%7B2%5C%2C%5Csqrt%20g%7D%20%5C%2C%20c_%7B%5C%2C23%7D%20%5Cquad%20a%5E%7B%5C%2C2%7D%20%3D%20%5Cfrac%7B1%7D%7B2%5C%2C%5Csqrt%20g%7D%20%5C%2C%20c_%7B%5C%2C31%7D%20%5Cquad%20a%5E%7B%5C%2C3%7D%20%3D%20%5Cfrac%7B1%7D%7B2%5C%2C%5Csqrt%20g%7D%20%5C%2C%20c_%7B%5C%2C12%7D" alt="a ^ {\, 1} = \ frac {1} {2 \, \ sqrt g} \, c _ {\, 23} \ quad a ^ {\, 2} = \ frac {1} {2 \, \ sqrt g} \, c _ {\, 31} \ quad a ^ {\, 3} = \ frac {1} {2 \, \ sqrt g} \, c _ {\, 12}"></div><br>  or, if we present the matrix component of the antisymmetric tensor <img src="https://tex.s2cms.ru/svg/C_%7Bij%7D" alt="C_ {ij}">  then we will see such a record <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BC%7D%20%3D%20%5Cbegin%7Bbmatrix%7D%200%20%26%26%202%5C%2C%5Csqrt%20g%20%5C%2C%20a%5E3%20%26%26%20-2%5C%2C%5Csqrt%20g%20%5C%2C%20a%5E2%20%5C%5C%20-2%5C%2C%5Csqrt%20g%20%5C%2C%20a%5E3%20%26%26%200%20%26%26%202%5C%2C%5Csqrt%20g%20%5C%2C%20a%5E1%20%5C%5C%202%5C%2C%5Csqrt%20g%20%5C%2C%20a%5E2%20%26%26%20-2%5C%2C%5Csqrt%20g%20%5C%2C%20a%5E1%20%26%26%200%20%5Cend%7Bbmatrix%7D" alt="\ mathbf {C} = \ begin {bmatrix} 0 &amp; amp; &amp; amp; 2 \, \ sqrt g \, a ^ 3 &amp; amp; &amp; amp; -2 \, \ sqrt g \, a ^ 2 \\ -2 \, \ sqrt g \, a ^ 3 &amp; amp; &amp; amp; 0 &amp; amp; &amp; amp; 2 \, \ sqrt g \, a ^ 1 \\ 2 \, \ sqrt g \, a ^ 2 &amp; amp; &amp; amp; -2 \, \ sqrt g \, a ^ 1 &amp; amp; &amp; amp; 0 \ end {bmatrix}"></div><br>  We note one more fact, which is impossible not to mention, but leaving a rigorous proof beyond the scope of this article (we will return to this later).  If tensor <img src="https://tex.s2cms.ru/svg/%D0%A1_%7Bij%7D" alt="C_ {ij}">  /&gt; is a <em>true tensor</em> , then the corresponding vector (3) is a <em>pseudovector</em> or <em>axial</em> vector.  The pseudovector is transformed as a vector when the coordinate axes are rotated, but when the basis changes from right to left (or from left to right), it changes its direction to the opposite (all its components change sign). <br><br>  If in (1) a vector <img src="https://tex.s2cms.ru/svg/a%5E%7B%5C%2Ck%7D" alt="a ^ {\, k}">  - a true vector, the antisymmetric tensor formed from it is a <em>pseudo</em> - <em>tensor</em> - the components of such a tensor are transformed in the same way as the components of a true tensor when the axes of the coordinate system are rotated, but they change sign to the opposite when the basis orientation changes. <br><br>  Thus, any antisymmetric tensor can be put in accordance with the pseudovector obtained in accordance with the expression (3). <br><br>  Now we show that the symmetric tensor does not have a corresponding pseudovector, or rather, this pseudovector is zero.  Suppose we are given a symmetric tensor <img src="https://tex.s2cms.ru/svg/%5Cmathbf%7BG%7D" alt="\ mathbf {G}">  equality is true <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/G_%7Bij%7D%20%3D%20G_%7Bji%7D%20%5Cquad%20(5)" alt="G_ {ij} = G_ {ji} \ quad (5)"></div><br>  Suppose there is a vector <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/b%5E%7B%5C%2Ck%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7B%5C%2Cijk%7D%20%5C%2C%20G_%7Bij%7D%20%5Cquad%20(6)" alt="b ^ {\, k} = \ frac {1} {2} \, \ varepsilon ^ {\, ijk} \, G_ {ij} \ quad (6)"></div><br>  Rearrange the indices in (6) given the symmetry (5) <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/b%5E%7B%5C%2Ck%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7B%5C%2Cjik%7D%20%5C%2C%20G_%7Bji%7D%20%3D%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7B%5C%2Cijk%7D%20%5C%2C%20G_%7Bij%7D%20%3D%20-b%5E%7B%5C%2Ck%7D%20%5Cquad%20(7)" alt="b ^ {\, k} = \ frac {1} {2} \, \ varepsilon ^ {\, jik} \, G_ {ji} = - \ frac {1} {2} \, \ varepsilon ^ {\, ijk} \, G_ {ij} = -b ^ {\, k} \ quad (7)"></div><br>  Expression (7) is valid only in one case, if <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/b%5E%7B%5C%2Ck%7D%20%3D%20-b%5E%7B%5C%2Ck%7D%20%3D%200%20%5Cquad%20(8)" alt="b ^ {\, k} = -b ^ {\, k} = 0 \ quad (8)"></div><br>  That is, if we multiply the symmetric tensor by the Levi-Civita tensor followed by convolution over two pairs of indices, we get the zero vector.  If we do the same with an arbitrary second rank tensor <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7Bijk%7D%20%5C%2C%20T_%7Bij%7D%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7Bijk%7D%20%5Cleft(T_%7Bij%7D%5E%7B%5C%2CS%7D%20%2B%20T_%7Bij%7D%5E%7B%5C%2CA%7D%20%5Cright%20)%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%2C%20%5Cvarepsilon%5E%7Bijk%7D%20%5C%2C%20T_%7Bij%7D%5E%7B%5C%2CA%7D" alt="\ frac {1} {2} \, \ varepsilon ^ {ijk} \, T_ {ij} = \ frac {1} {2} \, \ varepsilon ^ {ijk} \ left (T_ {ij} ^ {\, S} + T_ {ij} ^ {\, A} \ right) = \ frac {1} {2} \, \ varepsilon ^ {ijk} \, T_ {ij} ^ {\, A}"></div><br>  the output will be a pseudovector corresponding to its antisymmetric part. <br><br><h1>  Conclusion </h1><br>  It turned out another immersion in the theory of tensor calculus.  But immersion is undoubtedly necessary, because we use the results collected in this article in further articles of the cycle.  Thank you readers for your attention! <br><br>  <a href="http://habrahabr.ru/post/262129/">To be continued‚Ä¶</a> </div><p>Source: <a href="https://habr.com/ru/post/261991/">https://habr.com/ru/post/261991/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../261981/index.html">From data management to incident management: how to embed Varonis correctly in the Incident Management process</a></li>
<li><a href="../261983/index.html">Built for ages: understanding earthquake engineering</a></li>
<li><a href="../261985/index.html">"Killer Bootstrap" - Material Design Lite. Version 1.0.0</a></li>
<li><a href="../261987/index.html">"Pixel gallop - part two" - perspective, color, anatomy and applied exercises</a></li>
<li><a href="../261989/index.html">All clouds in one window</a></li>
<li><a href="../261993/index.html">Call Center Analysis</a></li>
<li><a href="../261995/index.html">How to remove UIPickerView freezes in iOS simulator</a></li>
<li><a href="../261997/index.html">RailsClub Ruby Mitap # 2 at Rambler & Co office</a></li>
<li><a href="../262001/index.html">The Evolution of Emails in Email Microsites</a></li>
<li><a href="../262003/index.html">Free summer school on HPC in scientific and engineering problems - applications are accepted until July 24</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>