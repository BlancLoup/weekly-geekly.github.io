<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Scalable fault tolerant file service based on CTDB, GlusterFS</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The article is a step-by-step guide to building a scalable fault-tolerant file storage, which will be accessed using the Samba, NFS protocols. As a fi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Scalable fault tolerant file service based on CTDB, GlusterFS</h1><div class="post__text post__text-html js-mediator-article">  The article is a step-by-step guide to building a scalable fault-tolerant file storage, which will be accessed using the Samba, NFS protocols.  As a file system that will be directly responsible for the preservation and scaling of the file balls, we will use GlusterFS, which was already enough <a href="http:">written by the</a> Chabs community.  Since GlusterFS is part of <a href="https://access.redhat.com/site/documentation/en-US/Red_Hat_Storage/2.0/pdf/Administration_Guide/Red_Hat_Storage-2.0-Administration_Guide-en-US.pdf">Red Hat Storage</a> , the tutorial is written for RH-like systems. <br><img src="https://habrastorage.org/storage4/cb1/8c9/215/cb18c9215566cf47c2a58436eae7e84c.png"><br><a name="habracut"></a><br><br><h5>  How do these services interact? </h5><br><h6>  GlusterFS </h6><br>  I use version 3.3.1, rpm-ki downloaded from the official site.  After creating the volume, the client can access it in several ways: <br><ul><li><code># mount.glusterfs</code> </li> <li> <code># mount -o mountproto=tcp,async -t nfs</code> </li> <li> <code># mount.cifs</code> </li> </ul><br>  We will use the first option, since in this case the client establishes connection with all servers and in case of server failure to which we mounted, we receive data from the working servers: <br><img src="https://habrastorage.org/storage3/6c3/afa/226/6c3afa226f062f6140ad307787c9dbcd.jpg"><br><br><h6>  CTDB </h6><br>  Excellent mechanics work described in <a href="http://habrahabr.ru/post/91188/">this</a> post.  I would like to add that the cluster load distribution using LVS is written in the documentation only for the NAT network; therefore, we will use Round Robbin DNS.  Available in standard repositories, as well as SMB, NFS: <br> <code># yum install ctdb samba nfs-utils cifs-utils</code> <br> <br><h5>  Let's get started </h5><br>  Suppose we have 2 nodes: <br> <code>gluster1, 192.168.122.100</code> <br> <code>gluster2, 192.168.122.101</code> <br> <br>  You still need a couple of IPs that will implement fault tolerance - migrate between servers. <br> <code>192.168.122.200</code> <br> <code>192.168.122.201</code> <br> <br>  RR DNS for the data domain looks like this: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <code>; zone file fragment</code> <br> <code>data. 86400 IN A 192.168.122.200</code> <br> <code>data. 86400 IN A 192.168.122.201</code> <br> <br>  In the creation of volume for GlusterFS I will not go deep.  I will say that we need a distributed - replication partition (distributed + replicated volume).  Call it <strong>smb</strong> .  First, we mount it locally for <strong>each</strong> node: <br><br> <code># mount.glusterfs gluster1:smb /mnt/glustersmb</code> <br> <br>  Each server uses its own <strong>hostname</strong> as an option.  Do not forget to make an entry in / etc / fstab. <br>  Now we reign Samba configuration <strong>(on each server)</strong> . <br><br> <code># vim /etc/samba/smb.conf</code> <br>  ... <br> <code>[global]</code> <br>  # The main parameter is responsible for clustering. <br> <code>clustering = yes</code> <br>  # Communication with the database that stores user requests (see the link for the mechanics of work) <br> <code>idmap backend = tdb2</code> <br>  # Folder with configuration files <br> <code>private dir = /mnt/glustersmb/lock</code> <br> <br>  And there we will add a section of the balls itself: <br> <code>[pub]</code> <br> <code>path = /mnt/glustersmb/lock</code> <br> <code>browseable = YES</code> <br> <code>force user = smbcli</code> <br> <code>force group = smbcli</code> <br> <code>writable = yes</code> <br> <code>guest ok = yes</code> <br> <code>guest account = smbcli</code> <br> <code>guest only = yes</code> <br> <br>  The folder will turn out for general use, access from the user of smbcli without authorization.  Let us create it and assign rights. <br>  Now <strong>on one</strong> of the servers we create a folder in which we will place some configuration files CTDB <br><br> <code># mkdir /mnt/glustersmb/lock</code> <br>  And add the file: <br> <code># touch /mnt/glustersmb/lock/lockfile</code> <br> <br>  The CTDB configuration file <strong>on each</strong> server is converted <strong>to</strong> : <br> <code># vim /etc/sysconfig/ctdb</code> <br> <code>CTDB_RECOVERY_LOCK=/mnt/glustersmb/lock/lockfile</code> <br> <code>CTDB_PUBLIC_ADDRESSES=/etc/ctdb/public_addresses</code> <br> <code>CTDB_MANAGES_SAMBA=yes</code> <br> <code>CTDB_NODES=/etc/ctdb/nodes</code> <br> <code>CTDB_MANAGES_NFS=yes</code> <br>  # File that is executed every time when the node of the CTDB cluster changes its status (for example, send a letter) <br> <code>CTDB_NOTIFY_SCRIPT=/etc/ctdb/notify.sh</code> <br> <br>  We specify our public adresses <strong>(on each server)</strong> : <br> <code># vim /etc/ctdb/public_addesses</code> <br> <code>192.168.122.200/24 eth0</code> <br> <code>192.168.122.201/24 eth0</code> <br> <br>  Specify the nodes of the CTDB cluster <strong>(on each server)</strong> : <br> <code># vim /etc/ctdb/nodes</code> <br> <code>192.168.122.100</code> <br> <code>192.168.122.101</code> <br> <br>  I disable SElinux, IPtables look like this (of course, <strong>for each</strong> server): <br> <code># vim /etc/sysconfig/iptables</code> <br> <code>-A INPUT -p tcp --dport 4379 -j ctdb</code> <br> <code>-A INPUT -p udp --dport 4379 -j ctdb</code> <br> <code>-A INPUT -p tcp -m multiport --ports 137:139,445 -m comment --comment "SAMBA" -j SMB</code> <br> <code>-A INPUT -p udp -m multiport --ports 137:139,445 -m comment --comment "SAMBA" -j SMB</code> <br> <code>-A INPUT -p tcp -m multiport --ports 111,2049,595:599 -j NFS</code> <br> <code>-A INPUT -p udp -m multiport --ports 111,2049,595:599 -j NFS</code> <br> <code>-A INPUT -p tcp -m tcp --dport 24007:24220 -m comment --comment "Gluster daemon" -j ACCEPT</code> <br> <code>-A INPUT -p tcp -m tcp --dport 38465:38667 -m comment --comment "Gluster daemon(nfs ports)" -j ACCEPT</code> <br>  # Instead of the name of the chains, you can simply specify ACCEPT. <br><br>  Let's return to Samba and the smbcli user <strong>(on each server)</strong> : <br> <code># useradd smbcli</code> <br> <code># chown -R smbcli.smbcli /mnt/glustersmb/pub</code> <br> <br>  The penultimate strokes: <br> <code># chkconfig smbd off</code> <br> <code># chkconfig ctdb on</code> <br> <code># service ctdb start</code> <br> <br>  Now you can watch <br> <code># ctdb status</code> <br> <code>Number of nodes:2</code> <br> <code>pnn:0 192.168.122.100 OK (THIS NODE)</code> <br> <code>pnn:1 192.168.122.101 OK</code> <br> <code>Generation:1112747960</code> <br> <code>Size:2</code> <br> <code>hash:0 lmaster:0</code> <br> <code>hash:1 lmaster:1</code> <br> <code>Recovery mode:NORMAL (0)</code> <br> <code>Recovery master:0</code> <br> <br>  The list of public migrating IPs and their accession to servers is obtained by the command <br> <code># ctdb ip</code> <br> <code>Public IPs on node 0</code> <br> <code>192.168.122.200 node[1] active[] available[eth0] configured[eth0]</code> <br> <code>192.168.122.201 node[0] active[eth0] available[eth0] configured[eth0]</code> <br> <br>  We mount the client using the SMB or NFS protocol with the commands: <br> <code># mount.cifs data:smb /mnt</code> <br> <code># mount -o mountproto=tcp,async -t nfs data:smb /mnt</code> <br> <br>  From personal experience I will say that I still test network drops, the result is very bearable.  Breakage of the connection is almost not noticeable.  All explains <a href="https://habrahabr.ru/users/andreykirov/" class="user_link">AndreyKirov</a> <div class="spoiler">  <b class="spoiler_title">Likbez</b> <div class="spoiler_text"><blockquote>  The host that took over the IP address of the other knows only what they were about old TCP connections and does not know the ‚ÄúTCP squence number‚Äù connections.  Accordingly, they can not continue.  As well as the client, he knows nothing about the fact that connections are now made with another node. <br><br>  In order to avoid delays associated with switching the connection, the following method is used.  To understand this technique, you need to understand the basic principles of the TCP protocol. <br><br>  The new node, receiving its ip address, sends the client a packet with the ACK flag and the obviously ‚Äús / sequence number‚Äù equal to zero.  In response, the client, in accordance with the rules of the TCP protocol, sends back an ACK Reply packet with the correct ‚Äúsquence number‚Äù.  Having received the correct "squence number" node forms a packet with the RST flag and this "squence number".  Having received it, the client immediately restarts the connection. </blockquote></div></div><br><br>  Enjoy your coding! </div><p>Source: <a href="https://habr.com/ru/post/194970/">https://habr.com/ru/post/194970/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../194958/index.html">Disputes about nominal domains</a></li>
<li><a href="../194960/index.html">As we did the cellular coverage inside a large building with a variety of metal structures</a></li>
<li><a href="../194962/index.html">RailsClub'Moscow 2013. Interview with Dmitry Vorotilin</a></li>
<li><a href="../194966/index.html">Myths about clouds</a></li>
<li><a href="../194968/index.html">The asset_path method in javascript application rails code</a></li>
<li><a href="../194972/index.html">Password hashing in PHP 5.5 using the new API</a></li>
<li><a href="../194974/index.html">Django doesn't work the way you think</a></li>
<li><a href="../194978/index.html">The State Duma opened the electronic Veche. A set of experts and the beginning of the discussion of bills</a></li>
<li><a href="../194980/index.html">We monitor CPU cores in Zabbix and create random counters in Low-level discovery</a></li>
<li><a href="../194982/index.html">Winners of Duke's Choice Awards 2013</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>