<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Internal mechanisms of TCP, affecting the download speed: part 2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the first part, we disassembled the ‚Äútriple handshake‚Äù of TCP and some technologies - TCP Fast Open, flow control and overload and window scaling. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Internal mechanisms of TCP, affecting the download speed: part 2</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/691/39e/d79/69139ed79de54f9b8ba07f35227f0358.png"><br><br>  <a href="https://habrahabr.ru/company/webo/blog/326258/">In the first part, we disassembled the ‚Äútriple handshake‚Äù of TCP</a> and some technologies - TCP Fast Open, flow control and overload and window scaling.  In the second part, we learn what TCP Slow Start is, how to optimize the data transfer rate and increase the initial window, and also collect all the recommendations for optimizing the TCP / IP stack together. <br><a name="habracut"></a><br><h2>  Slow start (Slow-Start) </h2><br>  Despite the presence of flow control in TCP, network collapse accumulation was a real problem in the mid-80s.  The problem was that although the flow control did not allow the sender to ‚Äúdrown‚Äù the recipient in the data, there was no mechanism that would not allow it to be done with the network.  After all, neither the sender nor the recipient know the width of the channel at the time of the beginning of the connection, and therefore they need some kind of mechanism to adapt the speed to changing conditions in the network. <br><br>  For example, if you are at home and download a large video from a remote server that has downloaded all your downlink to ensure maximum speed.  Then another user from your home decided to download a voluminous software update.  The available channel for video suddenly becomes much smaller, and the server sending the video should change its data sending speed.  If it continues at the same speed, the data will simply ‚Äúpile up‚Äù on some intermediate gateway, and the packets will be ‚Äúdropped‚Äù, which means inefficient use of the network. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In 1988, Van Jacobson and Michael J. Karels developed several algorithms to combat this problem: slow start, overload prevention, fast retransmission, and fast recovery.  They soon became an indispensable part of the TCP specification.  It is believed that thanks to these algorithms, it was possible to avoid global problems with the Internet in the late 80s / early 90s, when traffic grew exponentially. <br><br>  To understand how a slow start works, let‚Äôs go back to the example of a client in New York trying to download a file from a server in London.  First, a triple handshake is performed, during which the parties exchange their values ‚Äã‚Äãof reception windows in ACK packets.  When the last ACK packet has gone to the network, you can begin the exchange of data. <br><br>  The only way to estimate the channel width between the client and server is to measure it during data exchange, and this is exactly what a slow start does.  First, the server initializes a new window overload variable (cwnd) for a TCP connection and sets its value conservatively, according to the system value (on Linux, this is initcwnd). <br><br>  The value of the variable cwnd does not exchange between the client and the server.  This will be the local variable for the server in London.  Next, a new rule is introduced: the maximum amount of data ‚Äúin transit‚Äù (not confirmed via ACK) between the server and the client should be the smallest value of rwnd and cwnd.  But how can the server and the client "agree" on the optimal values ‚Äã‚Äãof their windows overload.  After all, the conditions in the network are constantly changing, and I would like the algorithm to work without the need to adjust each TCP connection. <br><br>  Solution: start the transfer with a slow speed and increase the window as the reception of packets is confirmed.  This is a slow start. <br><br>  The initial value of cwnd was initially set to 1 network segment.  In RFC 2581, this was changed to 4 segments, and then to RFC 6928 - up to 10 segments. <br><br>  Thus, the server can send up to 10 network segments to the client, after which it must stop sending and wait for confirmation.  Then, for each received ACK, the server can increase its cwnd value by 1 segment.  That is, for each package confirmed through the ACK, two new packages can be sent.  This means that the server and client quickly ‚Äúoccupy‚Äù the available channel. <br><br><img src="https://habrastorage.org/files/691/39e/d79/69139ed79de54f9b8ba07f35227f0358.png"><br>  <em>Fig.</em>  <em>1. Control overloading and its prevention.</em> <br><br>  How does the slow start affect the development of browser applications?  Since every TCP connection must go through a slow start phase, we cannot immediately use the entire available channel.  It all starts with a small window of overload, which gradually grows.  Thus, the time it takes to reach a given transmission rate is a function of the round-trip delay and the initial value of the overload window. <br><br>  The time to reach the value of cwnd equal to N. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6f7/2b9/bd1/6f72b9bd1e2e4c7cb486588079ab3432.png"></div><br>  To experience how this will be in practice, let's take the following assumptions: <br><br><ul><li>  Client and server reception windows: 65,535 bytes (64 KB) </li><li>  The initial value of the window overload: 10 segments </li><li>  Circular delay between London and New York: 56 milliseconds </li></ul><br>  Despite the receive window of 64 KB, the bandwidth of a TCP connection is initially limited to the overload window.  To reach the limit of 64 KB, the overload window should grow to 45 segments, which will take 168 milliseconds. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e2c/0e7/af3/e2c0e7af35364e6eb6f97e02d4268748.png"></div><br>  The fact that the client and server can be able to exchange megabits per second between themselves does not matter for a slow start. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/8d6/ee4/1f1/8d6ee41f15da4ec2bbd18a83a4e32b25.png"></div><br>  <em>Fig.</em>  <em>2. The growth of the window overload.</em> <br><br>  To reduce the time it takes to reach the maximum overload window, you can reduce the time required for packets on the round trip ‚Äî that is, locate the server geographically closer to the client. <br><br>  A slow start has little effect on downloading large files or streaming video, since the client and server have reached the maximum overload window for a few tens or hundreds of milliseconds, but this will be a single TCP connection. <br><br>  However, for many HTTP requests, when the target file is relatively small, the transfer may end before the maximum congestion window is reached.  That is, web application performance is often limited by the round-trip time between the server and the client. <br><br><h2>  Restart Slow Start (Slow-Start Restart - SSR) </h2><br>  In addition to controlling the transmission speed in new connections, TCP also provides a slow start restart mechanism, which resets the congestion window value if the connection has not been used for a specified period of time.  The logic here is that the network conditions could change during the inactivity of the connection, and to avoid overloading, the window value is reset to a safe value. <br><br>  Not surprisingly, SSR can have a serious impact on the performance of long-lived TCP connections that may temporarily be "idle", for example, due to user inactivity.  Therefore, it is better to disable SSR on the server in order to improve the performance of long-lived connections.  On Linux, you can check the SSR status and disable it with the following commands: <br><br><blockquote><pre>  $&gt; sysctl net.ipv4.tcp_slow_start_after_idle 
 $&gt; sysctl -w net.ipv4.tcp_slow_start_after_idle = 0 </pre></blockquote><br>  To demonstrate the effect of a slow start on transferring a small file, let's imagine that a client from New York requested a 64 KB file from a server in London over a new TCP connection with the following parameters: <br><br><ul><li>  Circular delay: 56 milliseconds </li><li>  Client and server throughput: 5 Mbps </li><li>  Client and server reception window: 65,535 bytes </li><li>  The initial value of the window overload: 10 segments (10 x 1460 bytes = ~ 14 KB) </li><li>  Processing time on the server to generate a response: 40 milliseconds </li><li>  Packages are not lost, ACK per packet, GET request fits into 1 segment </li></ul><br><img src="https://habrastorage.org/files/df9/0e0/072/df90e0072d7e48499301a3228a1a1b26.png"><br>  <em>Fig.</em>  <em>3. Downloading a file through a new TCP connection.</em> <br><br><ul><li>  0 ms: client starts TCP handshake with SYN packet </li><li>  28 ms: the server sends a SYN-ACK and sets its size rwnd </li><li>  56 ms: the client confirms the SYN-ACK, sets its size rwnd and immediately sends an HTTP GET request </li><li>  84 ms: the server receives an HTTP request </li><li>  124 ms: the server finishes creating a 64 KB response and sends 10 TCP segments, then waits for an ACK (the initial value of cwnd is 10) </li><li>  152 ms: the client receives 10 TCP segments and responds with an ACK to each </li><li>  180 ms: the server increases cwnd for each received ACK and sends 20 TCP segments </li><li>  208 ms: the client receives 20 TCP segments and responds with an ACK to each </li><li>  236 ms: the server increases cwnd for each received ACK and sends the 15 remaining TCP segments </li><li>  264 ms: the client receives 15 TCP segments and responds with an ACK to each </li></ul><br>  264 milliseconds takes the transfer of the file size of 64 KB through a new TCP connection.  Now let's imagine that the client reuses the same connection and makes the same request again. <br><br><img src="https://habrastorage.org/files/495/9a6/e30/4959a6e305bb4852b5179c743b19f647.png"><br>  <em>Fig.</em>  <em>4. Downloading a file through an existing TCP connection.</em> <br><br><ul><li>  0 ms: the client sends an HTTP request </li><li>  28 ms: server receives an HTTP request </li><li>  68 ms: the server generates a 64 KB response, but the value of cwnd is already greater than the 45 segments required to send this file.  Therefore, the server sends all segments at once. </li><li>  96 ms: the client receives all 45 segments and responds with an ACK to each </li></ul><br>  The same request made through the same connection, but without spending time on the handshake and increasing the bandwidth through a slow start, is now executed in 96 milliseconds, that is, 275% faster! <br><br>  In both cases, the fact that the client and server use a channel with a bandwidth of 5 Mbit / s did not have any effect on the download time of the file.  Only overload window sizes and network latency were limiting factors.  Interestingly, the difference in performance when using new and existing TCP connections will increase if the network delay increases. <br><br>  As soon as you are aware of the problems with delays when creating new connections, you will immediately want to use such optimization methods as keepalive, pipelining of packages (R) and multiplexing. <br><br><h2>  Increasing the initial value of the TCP overload window </h2><br>  This is the easiest way to increase performance for all users or applications using TCP.  Many operating systems already use the new value of 10 in their updates.  For Linux 10, the default value for the window overload, starting with kernel version 2.6.39. <br><br><h2>  Overload prevention </h2><br>  It is important to understand that TCP uses packet loss as a feedback mechanism that helps regulate performance.  A slow start creates a connection with a conservative overload window value and doubles the amount of data transferred at a time until it reaches the receiver's receive window, the sshtresh system threshold or until packets start to be lost, after which the overload prevention algorithm is enabled. <br><br>  Overload prevention is built on the assumption that packet loss is an indicator of network congestion.  Somewhere in the paths of packets on the link or on the router, packets have accumulated, and this means that you need to reduce the overload window in order to prevent further traffic from ‚Äúblocking‚Äù the network. <br><br>  After the overload window is reduced, a separate algorithm is applied to determine how the window should further grow.  Sooner or later, another packet loss will occur, and the process will be repeated.  If you have ever seen sawing traffic through a TCP connection, this is precisely because overload control and prevention algorithms adjust the overload window in accordance with the packet losses in the network. <br><br>  It is worth noting that the improvement of these algorithms is an active area of ‚Äã‚Äãboth scientific research and the development of commercial products.  There are options that work better on networks of a particular type or for transferring a particular type of file, and so on.  Depending on which platform you are running, you use one of many options: TCP Tahoe and Reno (original implementation), TCP Vegas, TCP New Reno, TCP BIC, TCP CUBIC (default on Linux) or Compound TCP (by default on windows) and many others.  Regardless of the specific implementation, the effects of these algorithms on the performance of web applications are similar. <br><br><h2>  Proportional speed reduction for TCP </h2><br>  Determining the best way to recover from packet loss is not a trivial task.  If you are too ‚Äúaggressive‚Äù in responding to this, the accidental loss of the packet will have an excessively negative effect on the connection speed.  If you do not respond quickly enough, then most likely it will cause further packet loss. <br><br>  Initially, TCP used the algorithm of multiple decrease and successive increase (Multiplicative Decrease and Additive Increase - AIMD): when a packet is lost, the overload window is halved and gradually increases by a specified amount with each round trip.  In many cases, AIMD proved to be an overly conservative algorithm, so new ones were developed. <br><br>  Proportional Rate Reduction (PRR) is a new algorithm described in RFC 6937, whose goal is faster recovery after packet loss.  According to Google‚Äôs measurements, where the algorithm was developed, it reduces the network delay by an average of 3-10% in packet loss connections.  PPR is enabled by default in Linux 3.2 and above. <br><br><h2>  The product of the channel width by delay (Bandwidth-Delay Product - BDP) </h2><br>  The built-in mechanisms for dealing with congestion in TCP have an important consequence: the optimal window values ‚Äã‚Äãfor the receiver and sender should vary according to the round-trip delay and the target data transfer rate.  Recall that the maximum number of unconfirmed packets "in transit" is defined as the smallest value from the receive and overload windows (rwnd and cwnd).  If the sender has exceeded the maximum number of unconfirmed packets, then it must stop the transmission and wait until the recipient confirms a certain number of packets so that the sender can restart the transmission.  How long should he wait?  This is determined by the circular delay. <br><br><h2>  BDP determines how much data can be ‚Äúon the go‚Äù </h2><br>  If the sender often has to stop and wait for the ACK-confirmation of previously sent packets, this will create a gap in the data stream, which will limit the maximum connection speed.  To avoid this problem, window sizes should be set large enough so that you can send data, awaiting receipt of ACK confirmations on previously sent packets.  Then the maximum transfer rate will be possible, no breaks.  Accordingly, the optimal window size depends on the speed of the circular delay. <br><br><img src="https://habrastorage.org/files/c3f/86a/9e2/c3f86a9e2d9648ca865c54a8da7a9bc2.png"><br>  <em>Fig.</em>  <em>5. The gap in the transmission due to the small values ‚Äã‚Äãof the windows.</em> <br><br>  How big should the receiving and overload windows be?  Let us examine by example: let cwnd and rwnd be 16 KB, and the round-trip delay is 100 ms.  Then: <br><br><img src="https://habrastorage.org/files/e1d/d03/f47/e1dd03f4759b4e2aae859d14df9ced8a.png"><br><br>  It turns out that whatever the channel width between the sender and the receiver, such a connection will never give a speed greater than 1.31 Mbit / s.  To achieve greater speed, you must either increase the value of the windows, or reduce the circular delay. <br><br>  Similarly, we can calculate the optimal value of the windows, knowing the circular delay and the required channel width.  We assume that the time remains the same (100 ms), and the sender's channel width is 10 Mbps, and the receiver is on a high-speed channel at 100 Mbps.  Assuming that the network between them has no problems at intermediate sites, we get for the sender: <br><br><img src="https://habrastorage.org/files/726/e15/3c3/726e153c3f63474ab99c3b5a1c1db89a.png"><br><br>  The window size should be at least 122.1 KB in order to fully occupy the channel at 10 Mbps.  Recall that the maximum receive window size in TCP is 64 KB, unless window scaling is enabled (RFC 1323).  Another reason to double check the settings! <br><br>  The good news is that window size matching is automatically done in the network stack.  The bad news is that this can sometimes be a limiting factor.  If you have ever wondered why your connection transmits at a rate that makes up only a small fraction of the available channel width, this is most likely due to the small size of the windows. <br><br><h2>  BDP in high-speed local networks </h2><br>  Circular delay can be a bottleneck in local networks.  To achieve 1 Gbit / s with a circular delay of 1 ms, you must have an overload window of not less than 122 KB.  The calculations are similar to those shown above. <br><br><h2>  Head-of-line blocking (HOL blocking) </h2><br>  Although TCP is a popular protocol, it is not the only one, and not always the most suitable for each particular case.  Its features such as delivery in order are not always necessary, and can sometimes increase the delay. <br><br>  Each TCP packet contains a unique sequence number, and the data must arrive in order.  If one of the packets has been lost, then all subsequent packets are stored in the receiver's TCP buffer until the lost packet is resubmitted and reaches the receiver.  Since this happens in the TCP layer, the application does not ‚Äúsee‚Äù these retransmissions or the queue of packets in the buffer, and simply waits until the data is available.  All that "sees" the application - this is the delay that occurs when reading data from the socket.  This effect is known as blocking the turn start. <br><br>  Locking the start of the queue frees applications from having to reorder the packets, which simplifies the code.  But on the other hand, there is an unpredictable delay in the arrival of packets, which negatively affects the performance of applications. <br><br><img src="https://habrastorage.org/files/105/a92/2de/105a922de7f94d45a4a82ff05f6f950c.png"><br>  <em>Fig.</em>  <em>6. Block the start of the queue.</em> <br><br>  Some applications may not require guaranteed delivery or order delivery.  If each package is a separate message, then delivery in order is not needed.  And if each new message overwrites the previous ones, then the guaranteed delivery is also not needed.  But in TCP there is no configuration for such cases.  All packages are delivered in turn, and if some is not delivered, it is sent again.  Applications for which latency is critical can use alternative transport, for example, UDP. <br><br><h2>  Packet loss is normal </h2><br>  Packet loss is even needed in order to provide better TCP performance.  The lost packet works as a feedback mechanism that allows the receiver and sender to change the sending rate to avoid network overload and minimize latency. <br><br>  Some applications can "cope" with the loss of the package: for example, to play audio, video or to transfer the status in the game, guaranteed delivery or delivery in order are not required.  Therefore, WebRTC uses UDP as the primary transport. <br><br>  If a packet loss occurred while playing audio, the audio codec can simply insert a small gap into the playback and continue processing incoming packets.  If the gap is small, the user may not notice it, and waiting for the delivery of a lost packet may result in a noticeable delay in playback, which will be much worse for the user. <br><br>  Similarly, if the game transfers its states, then there is no point in waiting for a packet describing the state at time T-1, if we already have information about the state at time T. <br><br><h2>  TCP optimization </h2><br>  TCP is an adaptive protocol designed to maximize network utilization.  Optimization for TCP requires an understanding of how TCP responds to network conditions.  Applications may need their own method of providing specified quality (QoS) to ensure stable operation for users. <br><br>  The requirements of applications and the numerous features of TCP algorithms make their interconnection and optimization in this area a huge field for study.  In this article, we just touched on some factors that affect TCP performance.  Additional mechanisms such as selective acknowledgment (SACK), deferred acknowledgment, fast retransmission and many others complicate the understanding and optimization of TCP sessions. <br><br>  Although the specific details of each algorithm and feedback mechanism will continue to change, the key principles and their consequences will remain: <br><ul><li>  The triple TCP handshake carries a serious delay; </li><li>  TCP slow start applies to each new connection; </li><li>  TCP flow and congestion control mechanisms regulate the throughput of all connections; </li><li>  TCP throughput is adjustable through the size of the congestion window. </li></ul><br>  As a result, the speed with which data can be transmitted in a TCP connection in modern high-speed networks is often limited by round-trip time.  While the channel width continues to grow, the delay is limited by the speed of light, and in many cases it is the delay, not the channel width, that is the bottleneck for TCP. <br><br><h2>  Server configuration setup </h2><br>  Instead of setting up each individual TCP parameter, it‚Äôs best to start by upgrading to the latest version of the operating system.  TCP best practices continue to evolve, and most of these changes are already available in recent versions of the OS. <br><br>  "Upgrading the OS on the server" seems like a trivial tip.  But in practice, many servers are configured for a specific version of the kernel, and system administrators can be against updates.  Yes, updating carries its own risks, but in terms of TCP performance, this is most likely to be the most effective action. <br><br>  After upgrading the OS, you need to configure the server in accordance with best practices: <br><br><ul><li>  <strong>Increase the initial value of the overload window:</strong> this will allow to transfer more data in the first exchange and significantly accelerates the growth of the overload window </li><li>  <strong>Disable Slow Start:</strong> Disabling Slow Start after a period of idle connection will improve the performance of long-lived TCP connections. </li><li>  <strong>Enable window scaling:</strong> this will increase the maximum value of the receive window and speed up connections where the delay is high. </li><li>  <strong>Enable TCP Fast Open:</strong> this will allow you to send data in the initial SYN packet.  This is a new algorithm, it must be supported by both the client and the server.  See if your application can benefit from it. </li></ul><br>  You may also need to configure other TCP parameters.  Refer to the <a href="http-tcp">‚ÄúTCP Tuning for HTTP‚Äù</a> material, which is regularly updated by the HTTP Working Group. <br><br>  For Linux users, ss will help check various open socket statistics.  At the command prompt, type <br><blockquote><pre>  ss --options --extended --memory --processes --info </pre></blockquote><br>  and you will see the current peers and their settings. <br><br><h2>  Application setup </h2><br>  How an application uses connections can have a huge impact on performance: <br><br><ul><li>  Any data transfer takes time&gt; 0.  Look for ways to reduce the amount of data sent. </li><li>  Zoom in to your customers geographically </li><li>  Reusing TCP connections can be a crucial point in improving performance. </li></ul><br>  Eliminating unnecessary data transfer is, of course, the most important type of optimization.  If you still need to transfer certain data, it is important to make sure that the appropriate compression algorithm is used for them. <br><br>  Moving data closer to clients by hosting servers around the world or using a CDN will help reduce round-trip time and greatly improve TCP performance. <br><br>  Finally, in all cases where this is possible, existing TCP connections should be re-used to avoid delays caused by the slow start algorithm and overload control. <br><br>  Finally, here is a checklist of what needs to be done to optimize TCP: <br><br><ul><li>  Update server OS </li><li>  Ensure cwnd is set to 10 </li><li>  Make sure window scaling is enabled. </li><li>  Disable slow start after idle connection </li><li>  Enable TCP Fast Open, if possible. </li><li>  Eliminate the transfer of unnecessary data </li><li>  Compress transmitted data </li><li>  Locate servers geographically closer to customers to reduce round-trip time. </li><li>  Reuse TCP connections where possible </li><li>  <a href="http-tcp">Review the recommendations of the HTTP Working Group.</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/327050/">https://habr.com/ru/post/327050/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327038/index.html">Gorilla: fast, scalable in-memory time-series database</a></li>
<li><a href="../327042/index.html">Videos: Moscow Zabbix Meetup in the office of Badoo</a></li>
<li><a href="../327044/index.html">Critical vulnerabilities are discovered in 25 Linksys Smart Wi-Fi devices.</a></li>
<li><a href="../327046/index.html">Performance comparison of the iron server and the Amazon cloud</a></li>
<li><a href="../327048/index.html">Analysis of communication from the Tor network to the infrastructure using the ELK stack</a></li>
<li><a href="../327052/index.html">Virtuality and overhead projector</a></li>
<li><a href="../327054/index.html">7Ps Framework: we structure meetings to make effective</a></li>
<li><a href="../327056/index.html">"The little things that we noticed": case IaaS-provider</a></li>
<li><a href="../327058/index.html">Difficult lessons: five years with Node.js</a></li>
<li><a href="../327060/index.html">Clarive 6.8 has been released.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>