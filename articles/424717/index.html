<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Backup a large number of heterogeneous web-projects</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="It would seem that the topic is beaten - much has been said and written about backup, so there is nothing to reinvent the wheel, just take it and do i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Backup a large number of heterogeneous web-projects</h1><div class="post__text post__text-html js-mediator-article"><p>  It would seem that the topic is beaten - much has been said and written about backup, so there is nothing to reinvent the wheel, just take it and do it.  However, every time when the system administrator of a web project faces the task of setting up backups, for many it hangs in the air with a big question mark.  How to collect backup data?  Where to store backups?  How to provide the necessary level of retrospective storage of copies?  How to unify the backup process for the whole zoo of different software? </p><br><p><img src="https://habrastorage.org/webt/xk/rn/7r/xkrn7rrnask1pgpv4uvrby6tnrc.jpeg"></p><a name="habracut"></a><br><p>  For ourselves, we first solved this problem in 2011. Then we sat down and wrote our backup scripts.  For many years, we have used only them, and they have successfully ensured a reliable process of collecting and synchronizing backups of our clients' web projects.  Backups were stored in our or some other external storage, with the possibility of tuning for a specific project. </p><br><p>  I must say, these scripts have worked their full.  But the further we grew, the more variegated projects we had with different software and external repositories that our scripts did not support.  For example, we did not have support for Redis and MySQL and PostgreSQL ‚Äúhot‚Äù backups, which appeared later.  The process of backups was not monitored, there were only email-alerts. </p><br><p>  Another problem was the support process.  For many years, our once compact scripts have grown and turned into a huge awkward monster.  And when we were going with the forces and released a new version, it was worth it to roll out an update for some of the customers who used the previous version with some kind of customization. </p><br><p>  As a result, at the beginning of this year we made a strong-willed decision: to replace our old backup scripts with something more modern.  Therefore, we first sat down and wrote out all the wishes for a new solution.  It turned out about the following: </p><br><ul><li>  Back up the most frequently used software: <br><ul><li>  Files (discrete and incremental backups) </li><li>  MySQL (cold / hot backups) </li><li>  PostgreSQL (cold / hot backups) </li><li>  MongoDB </li><li>  Redis </li></ul></li><li>  Store backups in popular repositories: <br><ul><li>  Local </li><li>  FTP </li><li>  Ssh </li><li>  SMB </li><li>  Nfs </li><li>  WebDAV </li><li>  S3 </li></ul></li><li>  Receive alerts in case of any problems during the backup process </li><li>  Have a single configuration file that allows you to manage backups centrally </li><li>  Add support for new software through the connection of external modules </li><li>  Specify extra options for collecting dumps </li><li>  Have the ability to restore backups using standard tools. </li><li>  Ease of initial configuration </li></ul><br><h1 id="analiziruem-imeyuschiesya-resheniya">  Analyzing existing solutions </h1><br><p>  We looked at open-source solutions that already exist: </p><br><ul><li>  Bacula and its fork, for example, Bareos </li><li>  Amanda </li><li>  Borg </li><li>  Duplicaty </li><li>  Duplicity </li><li>  Rsnapshot </li><li>  Rdiff-backup </li></ul><br><p>  But each of them had its flaws.  For example, Bacula is overloaded with unnecessary functions, the initial configuration is quite time-consuming because of the large amount of manual work (for example, for writing / searching database backup scripts), and for restoring copies you need to use special utilities, etc. </p><br><p>  In the end, we came to two important conclusions: </p><br><ol><li>  None of the existing solutions did not fully suit us; </li><li>  It seems that we ourselves had enough experience and madness to take up writing our decision. </li></ol><br><p>  So we did. </p><br><h1 id="rozhdenie-nxs-backup">  Birth nxs-backup </h1><br><p>  We chose Python as the language for implementation - it is easy to write and maintain, flexible and convenient.  The configuration files were made to be described in the yaml format. </p><br><p>  For the convenience of supporting and adding backups of new software, a modular architecture was chosen, where the process of collecting backups of each specific software (for example, MySQL) is described in a separate module. </p><br><h2 id="podderzhka-faylov-bd-i-udalyonnyh-hranilisch">  Support for files, databases and remote repositories </h2><br><p>  Currently, support is provided for the following types of file backups, databases, and remote repositories: </p><br><p>  DB: </p><br><ul><li>  MySQL (hot / cold backups) </li><li>  PostgreSQL (hot / cold backups) </li><li>  Redis </li><li>  MongoDB </li></ul><br><p>  Files: </p><br><ul><li>  Discrete copying </li><li>  Incremental backups </li></ul><br><p>  Remote repositories: </p><br><ul><li>  Local </li><li>  S3 </li><li>  SMB </li><li>  Nfs </li><li>  FTP </li><li>  Ssh </li><li>  WebDAV </li></ul><br><h2 id="diskretnoe-rezervnoe-kopirovanie">  Discrete backup </h2><br><p>  Either discrete or incremental backups are suitable for different tasks, so they implemented both types.  You can specify which method to use at the level of individual files and directories. </p><br><p>  For discrete copies (both files and databases), you can set a retrospective view in the format days / weeks / months. </p><br><h2 id="inkrementnoe-rezervnoe-kopirovanie">  Incremental backup </h2><br><p>  Incremental copies of files are made as follows: <br><img src="https://habrastorage.org/webt/c7/wk/ss/c7wksse4j_mxjkgdffptngpglkw.jpeg"></p><br><p>  At the beginning of the year is going to full backup.  Further, at the beginning of each month - an incremental monthly copy of a relatively annual.  Inside the monthly - incremental decadal relative to the monthly.  Inside each decade - incremental day relative to the decade. </p><br><p>  It is worth mentioning that while there are some problems when working with directories that contain a large number of subdirectories (tens of thousands).  In such cases, the collection of copies slows down significantly and can take more than a day.  We are actively engaged in the elimination of this defect. </p><br><h2 id="vosstanavlivaemsya-iz-inkrementnyh-bekapov">  Recovering from incremental backups </h2><br><p>  There is no problem with restoring from discrete backups - just take a copy of the desired date and deploy it with the usual console tar.  Incremental backups are a bit more complicated.  To recover, for example, on July 24, 2018, you need to do the following: </p><br><ol><li>  Expand a one-year backup, even if in our case it is counted from January 1, 2018 (in practice it can be any date, depending on when the decision was made to implement incremental backup) </li><li>  Roll on him a monthly backup for July </li><li>  Roll up the decade backup for July 21st </li><li>  Roll up a daily backup for July 24 </li></ol><br><p>  At the same time, to execute 2-4 points, it is necessary to add the -G switch to the tar command, thereby indicating that this is an incremental backup.  Of course, this is not the fastest process, but if you consider that recovering from backups is not so often economical and important, this scheme turns out to be quite effective. </p><br><h2 id="isklyucheniya">  Exceptions </h2><br><p>  Often you need to exclude individual files or directories from backups, for example, directories with a cache.  This can be done by specifying the appropriate exception rules: </p><br><div class="spoiler">  <b class="spoiler_title">sample configuration file</b> <div class="spoiler_text"><pre><code class="hljs ruby">- <span class="hljs-symbol"><span class="hljs-symbol">target:</span></span> - <span class="hljs-regexp"><span class="hljs-regexp">/var/www</span></span><span class="hljs-regexp"><span class="hljs-regexp">/*/data</span></span><span class="hljs-regexp"><span class="hljs-regexp">/ excludes: - exclude1/exclude</span></span>_file - exclude2 - <span class="hljs-regexp"><span class="hljs-regexp">/var/www</span></span><span class="hljs-regexp"><span class="hljs-regexp">/exclude_3</span></span></code> </pre> </div></div><br><h2 id="rotaciya-bekapov">  Backups rotation </h2><br><p>  In our old scripts, the rotation was implemented so that the old copy was deleted only after the new one was assembled successfully.  This led to problems on projects where, in principle, the space for backups was allocated to exactly one copy - a fresh copy could not be gathered there due to lack of space. </p><br><p>  In the new implementation, we decided to change this approach: first remove the old one and only then collect a new copy.  And the process of collecting backups put on monitoring to learn about the occurrence of any problems. </p><br><p>  In the case of a discrete backup, the old copy is considered to be an archive that goes beyond the specified storage scheme in the format days / weeks / months.  In the case of incremental backups, backups are stored by default for a year, and old copies are deleted at the beginning of each month, while archives for the same month of the previous year are considered old backups.  For example, before collecting a monthly backup on August 1, 2018, the system will check if there are any backups for August 2017, and if so, delete them.  This allows optimal use of disk space. </p><br><h2 id="logirovanie">  Logging </h2><br><p>  In any process, and especially in backups, it is important to keep your finger on the pulse and be able to find out if something went wrong.  The system keeps a log of its work and records the result of each step: start / stop of funds, the start / end of a specific task, the result of collecting a copy in the temporary directory, the result of copying / moving a copy from the temporary directory to a permanent location, the result of backups rotation, etc. .. </p><br><p>  Events are divided into 2 levels: </p><br><ul><li>  <em>Info</em> : information level - the flight is normal, the next stage is completed successfully, the corresponding information record is made in the log </li><li>  <em>Error</em> : error level - something went wrong, the next stage ended abnormally, the corresponding error record is made in the log </li></ul><br><h2 id="e-mail-notifikacii">  E-mail notifications </h2><br><p>  At the end of the backup collection, the system can send out email notifications. </p><br><p>  2 recipient lists are supported: </p><br><ul><li>  <em>Administrators</em> - those who serve the server.  They receive only error notifications; they are not interested in notifications of successful operations. </li><li>  <em>Business users</em> - in our case, these are customers who sometimes want to be notified to make sure that they are fine with backups.  Or, conversely, not very.  They can choose - to get the full log or only the log with errors. </li></ul><br><h2 id="struktura-konfiguracionnyh-faylov">  Configuration File Structure </h2><br><p>  The structure of the configuration files is as follows: </p><br><div class="spoiler">  <b class="spoiler_title">structure example</b> <div class="spoiler_text"><pre> <code class="bash hljs">/etc/nxs-backup ‚îú‚îÄ‚îÄ conf.d ‚îÇ ‚îú‚îÄ‚îÄ desc_files_local.conf ‚îÇ ‚îú‚îÄ‚îÄ external_clickhouse_local.conf ‚îÇ ‚îú‚îÄ‚îÄ inc_files_smb.conf ‚îÇ ‚îú‚îÄ‚îÄ mongodb_nfs.conf ‚îÇ ‚îú‚îÄ‚îÄ mysql_s3.conf ‚îÇ ‚îú‚îÄ‚îÄ mysql_xtradb_scp.conf ‚îÇ ‚îú‚îÄ‚îÄ postgresql_ftp.conf ‚îÇ ‚îú‚îÄ‚îÄ postgresql_hot_webdav.conf ‚îÇ ‚îî‚îÄ‚îÄ redis_local_ftp.conf ‚îî‚îÄ‚îÄ nxs-backup.conf</code> </pre> </div></div><br><p>  Here <em>/etc/nxs-backup/nxs-backup.conf</em> is the main configuration file, which specifies the global settings: </p><br><div class="spoiler">  <b class="spoiler_title">configuration file</b> <div class="spoiler_text"><pre> <code class="hljs sql">main: server_name: SERVER_NAME admin_mail: project-tech@nixys.ru client_mail: - '' mail_from: <span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>@domain.ru level_message: <span class="hljs-keyword"><span class="hljs-keyword">error</span></span> block_io_read: <span class="hljs-string"><span class="hljs-string">''</span></span> block_io_write: <span class="hljs-string"><span class="hljs-string">''</span></span> blkio_weight: <span class="hljs-string"><span class="hljs-string">''</span></span> general_path_to_all_tmp_dir: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span> cpu_shares: <span class="hljs-string"><span class="hljs-string">''</span></span> log_file_name: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">log</span></span>/nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>/nxs-backup.log jobs: !<span class="hljs-keyword"><span class="hljs-keyword">include</span></span> [conf.d<span class="hljs-comment"><span class="hljs-comment">/*.conf]</span></span></code> </pre> </div></div><br><p>  An array of jobs (jobs) contains a list of tasks (job), which are a description of what exactly to back up, where to store and in what quantity.  As a rule, they are placed in separate files (one file per job), which are connected via include in the main configuration file. </p><br><p>  They also took care of maximally optimizing the process of preparing these files and wrote a simple generator.  Therefore, the administrator does not need to spend time searching for the config template for some service, for example, MySQL, but rather simply run the command: </p><br><pre> <code class="bash hljs">nxs-backup generate --storage <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> scp --<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> mysql --path /etc/nxs-backup/conf.d/mysql_local_scp.conf</code> </pre> <br><p>  The output is the file <em>/etc/nxs-backup/conf.d/mysql_local_scp.conf</em> : </p><br><div class="spoiler">  <b class="spoiler_title">File contents</b> <div class="spoiler_text"><pre> <code class="hljs sql"> - job: PROJECT-mysql type: mysql tmp_dir: /var/nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">databases</span></span>/mysql/dump_tmp sources: - <span class="hljs-keyword"><span class="hljs-keyword">connect</span></span>: db_host: <span class="hljs-string"><span class="hljs-string">''</span></span> db_port: <span class="hljs-string"><span class="hljs-string">''</span></span> socket: <span class="hljs-string"><span class="hljs-string">''</span></span> db_user: <span class="hljs-string"><span class="hljs-string">''</span></span> db_password: <span class="hljs-string"><span class="hljs-string">''</span></span> auth_file: <span class="hljs-string"><span class="hljs-string">''</span></span> target: - all excludes: - information_schema - performance_schema - mysql - <span class="hljs-keyword"><span class="hljs-keyword">sys</span></span> gzip: <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> is_slave: <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> extra_keys: <span class="hljs-string"><span class="hljs-string">'--opt --add-drop-database --routines --comments --create-options --quote-names --order-by-primary --hex-blob'</span></span> storages: - <span class="hljs-keyword"><span class="hljs-keyword">storage</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span>: yes backup_dir: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">databases</span></span>/mysql/dump <span class="hljs-keyword"><span class="hljs-keyword">store</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">days</span></span>: <span class="hljs-string"><span class="hljs-string">''</span></span> weeks: <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">month</span></span>: <span class="hljs-string"><span class="hljs-string">''</span></span> - <span class="hljs-keyword"><span class="hljs-keyword">storage</span></span>: scp <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span>: yes backup_dir: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">databases</span></span>/mysql/dump <span class="hljs-keyword"><span class="hljs-keyword">user</span></span>: <span class="hljs-string"><span class="hljs-string">''</span></span> host: <span class="hljs-string"><span class="hljs-string">''</span></span> port: <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">password</span></span>: <span class="hljs-string"><span class="hljs-string">''</span></span> path_to_key: <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">store</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">days</span></span>: <span class="hljs-string"><span class="hljs-string">''</span></span> weeks: <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">month</span></span>: <span class="hljs-string"><span class="hljs-string">''</span></span></code> </pre> </div></div><br><p>  In which it remains only to substitute several necessary values. </p><br><p>  Let us consider an example.  Suppose we have on the server in the / var / www directory there are two platforms of an online store on 1C-Bitrix (bitrix-1.ru, bitrix-2.ru), each of which works from its database in different MySQL instances (port 3306 for bitrix_1_db and port 3307 for bitrix_2_db). </p><br><p>  The file structure of a typical Bitrix project is approximately as follows: </p><br><pre> <code class="bash hljs">‚îú‚îÄ‚îÄ ... ‚îú‚îÄ‚îÄ bitrix ‚îÇ ‚îú‚îÄ‚îÄ .. ‚îÇ ‚îú‚îÄ‚îÄ admin ‚îÇ ‚îú‚îÄ‚îÄ backup ‚îÇ ‚îú‚îÄ‚îÄ cache ‚îÇ ‚îú‚îÄ‚îÄ .. ‚îÇ ‚îú‚îÄ‚îÄ managed_cache ‚îÇ ‚îú‚îÄ‚îÄ .. ‚îÇ ‚îú‚îÄ‚îÄ stack_cache ‚îÇ ‚îî‚îÄ‚îÄ .. ‚îú‚îÄ‚îÄ upload ‚îî‚îÄ‚îÄ ...</code> </pre> <br><p>  As a rule, the <em>upload</em> directory weighs a lot, and only grows with time, so back it up incrementally.  All other directories are discrete, with the exception of directories with a cache and backups collected by Bitrix native tools.  Let the backup storage scheme for these two sites should be the same, while copies of files should be stored both locally and remotely in ftp storage, and the database should only be stored in remote smb storage. </p><br><p>  The final configuration files for this setup will look like this: </p><br><div class="spoiler">  <b class="spoiler_title">bitrix-desc-files.conf (configuration file with job description for discrete backup)</b> <div class="spoiler_text"><pre> <code class="hljs scala"> - job: <span class="hljs-type"><span class="hljs-type">Bitrix</span></span>-desc-files <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">type</span></span></span></span>: desc_files tmp_dir: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/nxs-backup/files/desc/dump_tmp sources: - target: - /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/www<span class="hljs-comment"><span class="hljs-comment">/*/ excludes: - bitrix/backup - bitrix/cache - bitrix/managed_cache - bitrix/stack_cache - upload gzip: yes storages: - storage: local enable: yes backup_dir: /var/nxs-backup/files/desc/dump store: days: 6 weeks: 4 month: 6 - storage: ftp enable: yes backup_dir: /nxs-backup/databases/mysql/dump host: ftp_host user: ftp_usr password: ftp_usr_pass store: days: 6 weeks: 4 month: 6</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">bitrix-inc-files.conf (configuration file with job description for incremental backups)</b> <div class="spoiler_text"><pre> <code class="hljs coffeescript"> - job: Bitrix-inc-files type: inc_files sources: - target: - <span class="hljs-regexp"><span class="hljs-regexp">/var/www/</span></span>*<span class="hljs-regexp"><span class="hljs-regexp">/upload/</span></span> gzip: <span class="hljs-literal"><span class="hljs-literal">yes</span></span> storages: - storage: ftp enable: <span class="hljs-literal"><span class="hljs-literal">yes</span></span> backup_dir: /nxs-backup/files/inc host: ftp_host user: ftp_usr password: ftp_usr_pass - storage: local enable: <span class="hljs-literal"><span class="hljs-literal">yes</span></span> backup_dir: /var/nxs-backup/files/inc</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">bitrix-mysql.conf (configuration file with job description for MySQL backups)</b> <div class="spoiler_text"><pre> <code class="hljs sql"> - job: Bitrix-mysql type: mysql tmp_dir: /var/nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">databases</span></span>/mysql/dump_tmp sources: - <span class="hljs-keyword"><span class="hljs-keyword">connect</span></span>: db_host: localhost db_port: <span class="hljs-number"><span class="hljs-number">3306</span></span> db_user: bitrux_usr_1 db_password: password_1 target: - bitrix_1_db excludes: - information_schema - performance_schema - mysql - <span class="hljs-keyword"><span class="hljs-keyword">sys</span></span> gzip: <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> is_slave: <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> extra_keys: <span class="hljs-string"><span class="hljs-string">'--opt --add-drop-database --routines --comments --create-options --quote-names --order-by-primary --hex-blob'</span></span> - <span class="hljs-keyword"><span class="hljs-keyword">connect</span></span>: db_host: localhost db_port: <span class="hljs-number"><span class="hljs-number">3307</span></span> db_user: bitrix_usr_2 db_password: password_2 target: - bitrix_2_db excludes: - information_schema - performance_schema - mysql - <span class="hljs-keyword"><span class="hljs-keyword">sys</span></span> gzip: yes is_slave: <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> extra_keys: <span class="hljs-string"><span class="hljs-string">'--opt --add-drop-database --routines --comments --create-options --quote-names --order-by-primary --hex-blob'</span></span> storages: - <span class="hljs-keyword"><span class="hljs-keyword">storage</span></span>: smb <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span>: yes backup_dir: /nxs-<span class="hljs-keyword"><span class="hljs-keyword">backup</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">databases</span></span>/mysql/dump host: smb_host port: smb_port <span class="hljs-keyword"><span class="hljs-keyword">share</span></span>: smb_share_name <span class="hljs-keyword"><span class="hljs-keyword">user</span></span>: smb_usr <span class="hljs-keyword"><span class="hljs-keyword">password</span></span>: smb_usr_pass <span class="hljs-keyword"><span class="hljs-keyword">store</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">days</span></span>: <span class="hljs-number"><span class="hljs-number">6</span></span> weeks: <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">month</span></span>: <span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre> </div></div><br><h2 id="parametry-dlya-zapuska-sbora-bekapov">  Parameters for running backup collection </h2><br><p>  In the previous example, we prepared job configuration files for collecting backups of all elements at once: files (discretely and incrementally), two databases and their storage in local and external (ftp, smb) storages. </p><br><p>  It remains to run the whole thing.  Start is made by command: </p><br><pre> <code class="bash hljs">nxs-backup start <span class="hljs-variable"><span class="hljs-variable">$JOB_NAME</span></span> -c <span class="hljs-variable"><span class="hljs-variable">$PATH_TO_MAIN_CONFIG</span></span></code> </pre> <br><p>  There are several reserved job names: </p><br><ul><li>  <strong>files</strong> - random execution of all <em>jobs</em> with <em>desc_files</em> , <em>inc_files types</em> (that is, in fact, back up files only) </li><li>  <strong>databases</strong> - random execution of all jobs with the types <em>mysql</em> , <em>mysql_xtradb</em> , <em>postgresql</em> , <em>postgresql_hot</em> , <em>mongodb</em> , <em>redis</em> (that is, <em>backing</em> up only the database) </li><li>  <strong>external</strong> - randomly execute all jobs with <em>external</em> type (running only additional user scripts, more on this below) </li><li>  <strong>all</strong> - imitation of running the command in turn with job <em>files</em> , <em>databases</em> , <em>external</em> (default value) </li></ul><br><p>  Since we need to get backups of data from both files and databases as of the same time (or with a minimum difference), it is recommended to run nxs-backup with job <strong>all</strong> , which will ensure consistent execution of the described job (Bitrix-desc- files, Bitrix-inc_files, Bitrix-mysql). </p><br><p>  That is, an important point - backups will not be collected in parallel, but sequentially, one after the other, with the minimum time difference.  Moreover, the software itself at the next launch checks for the presence of an already running process in the system and, if it is detected, will automatically finish its work with a corresponding note in the log.  This approach significantly reduces the load on the system.  Minus - backups of individual elements are not collected at once, but with some time difference.  But so far our practice shows that this is not critical. </p><br><h2 id="vneshnie-moduli">  External modules </h2><br><p>  As mentioned above, thanks to the modular architecture, the capabilities of the system can be expanded using additional user modules that interact with the system through a special interface.  The goal is to be able to add support for backups of new software in the future without having to rewrite nxs-backup. </p><br><div class="spoiler">  <b class="spoiler_title">sample configuration file</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"> - job: TEST-<span class="hljs-keyword"><span class="hljs-keyword">external</span></span> <span class="hljs-keyword"><span class="hljs-keyword">type</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">external</span></span> dump_cmd: <span class="hljs-string"><span class="hljs-string">''</span></span> storages: ‚Ä¶.</code> </pre> </div></div><br><p>  Particular attention should be paid to the key <strong>dump_cmd</strong> , where the full command for running the external script is specified as the value.  At the same time, upon completion of the execution of this command, it is expected that: </p><br><ul><li>  A complete software data archive will be compiled. </li><li>  Data will be sent to stdout in json format, like: <br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"full_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"ABS_PATH_TO_ARCHIVE"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"basename"</span></span>: <span class="hljs-string"><span class="hljs-string">"BASENAME_ARCHIVE"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"extension"</span></span>: <span class="hljs-string"><span class="hljs-string">"EXTERNSION_OF_ARCHIVE"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"gzip"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>/<span class="hljs-literal"><span class="hljs-literal">false</span></span> }</code> </pre> <br><ul><li>  In this case, the keys <em>basename</em> , <em>extension</em> , <em>gzip are</em> necessary exclusively for the formation of the final name of the backup. </li></ul></li><li>  In case of successful completion of the script, the return code should be 0 and any other in case of any problems. </li></ul><br><p>  For example, suppose we have a script for creating snapshot etcd <em>/etc/nxs-backup-ext/etcd.py</em> : </p><br><div class="spoiler">  <b class="spoiler_title">script code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#! /usr/bin/env python3 # -*- coding: utf-8 -*- import json import os import subprocess import sys import tarfile def archive(snapshot_path): abs_tmp_path = '%s.tar' %(snapshot_path) with tarfile.open(abs_tmp_path, 'w:') as tar: tar.add(snapshot_path) os.unlink(snapshot_path) return abs_tmp_path def exec_cmd(cmdline): data_dict = {} current_process = subprocess.Popen([cmdline], stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, executable='/bin/bash') data = current_process.communicate() data_dict['stdout'] = data[0][0:-1].decode('utf-8') data_dict['stderr'] = data[1][0:-1].decode('utf-8') data_dict['code'] = current_process.returncode return data_dict def main(): snapshot_path = "/var/backups/snapshot.db" dump_cmd = "ETCDCTL_API=3 etcdctl --cacert=/etc/ssl/etcd/ssl/ca.pem --cert=/etc/ssl/etcd/ssl/member-node1.pem"+\ " --key=/etc/ssl/etcd/ssl/member-node1-key.pem --endpoints 'https://127.0.0.1:2379' snapshot save %s" %snapshot_path command = exec_cmd(dump_cmd) result_code = command['code'] if result_code: sys.stderr.write(command['stderr']) else: try: new_path = archive(snapshot_path) except tarfile.TarError as e: sys.exit(1) else: result_dict = { "full_path": new_path, "basename": "etcd", "extension": "tar", "gzip": False } print(json.dumps(result_dict)) sys.exit(result_code) if __name__ == '__main__': main()</span></span></code> </pre> </div></div><br><p>  The config for running this script is as follows: </p><br><div class="spoiler">  <b class="spoiler_title">configuration file</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"> - job: etcd-<span class="hljs-keyword"><span class="hljs-keyword">external</span></span> <span class="hljs-keyword"><span class="hljs-keyword">type</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">external</span></span> dump_cmd: <span class="hljs-string"><span class="hljs-string">'/etc/nxs-backup-ext/etcd.py'</span></span> storages: - <span class="hljs-keyword"><span class="hljs-keyword">storage</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span>: yes backup_dir: /var/nxs-backup/<span class="hljs-keyword"><span class="hljs-keyword">external</span></span>/dump store: days: <span class="hljs-number"><span class="hljs-number">6</span></span> weeks: <span class="hljs-number"><span class="hljs-number">4</span></span> month: <span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre> </div></div><br><p>  At the same time, the program when running job <em>etcd-external</em> : </p><br><ul><li>  Run the <em>/etc/nxs-backup-ext/etcd.py</em> script <em>with</em> no parameters </li><li>  After completion of the script, check the completion code and the availability of the necessary data in stdout </li><li>  If all the checks were successful, the same mechanism will be further used as in the operation of already built-in modules, where the tmp_path is the value of the full_path key.  If not, complete the task with the corresponding mark in the log. </li></ul><br><h1 id="podderzhka-i-obnovlenie">  Support and update </h1><br><p>  The process of developing and maintaining a new backup system has been implemented for all CI / CD canons.  No more updates and script edits on the combat servers.  All changes pass through our central git-repository in Gitlab, where the pipeline contains the assembly of new versions of deb / rpm-packages, which are then uploaded to our deb / rpm repositories.  And after that through the package manager are delivered to the destination server clients. </p><br><h1 id="kak-skachat-nxs-backup">  How to download nxs-backup? </h1><br><p>  We did nxs-backup open-source project.  Anyone can download and use it to organize the backup process in their projects, as well as modify to fit their needs, write external modules. </p><br><p>  The source code for nxs-backup can be downloaded from the Github repository <a href="https://github.com/nixys/nxs-backup">via this link</a> .  There is also a guide for installation and configuration. </p><br><p>  We also prepared a Docker image and uploaded it to <a href="https://hub.docker.com/r/nixyslab/nxs-backup/">DockerHub</a> . </p><br><p>  If in the process of setting up or using any questions, please contact us.  We will help to understand and refine the instructions. </p><br><h1 id="zaklyuchenie">  Conclusion </h1><br><p>  In the near future we have to implement the following functionality: </p><br><ul><li>  Integration with monitoring </li><li>  Backup Encryption </li><li>  Web interface for managing backup settings </li><li>  Expanding backups using nxs-backup </li><li>  And much more </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/424717/">https://habr.com/ru/post/424717/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../424701/index.html">Non-fictional IT-stories about impostors and why these incomprehensible practices appeared during interviews</a></li>
<li><a href="../424703/index.html">And again about the depersonalization</a></li>
<li><a href="../424709/index.html">Masterpieces of the world column: 225 W RMS for 28 000 rubles</a></li>
<li><a href="../424711/index.html">From hydrogel to swine intestine: unusual materials in robotics</a></li>
<li><a href="../424713/index.html">The whole truth about the RTOS. Article # 12. Task Services</a></li>
<li><a href="../424723/index.html">Friday webinars from Skillbox: useful for beginners and not only</a></li>
<li><a href="../424725/index.html">Pro version of Oracle JDK 11+ (licensing and distribution)</a></li>
<li><a href="../424729/index.html">Why did the compiler turn my loop into an infinite condition?</a></li>
<li><a href="../424731/index.html">Hot tech support history, or Why does AutoCAD remove proxies?</a></li>
<li><a href="../424733/index.html">Blue pill (blue tablet) STM32F103 as a PLC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>