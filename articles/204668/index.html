<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Waited, waited and waited! OpenMP 4.0</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Each new OpenMP specification introduces very useful and necessary additions to the already existing functionality. For example, in version 3.0, so-ca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Waited, waited and waited! OpenMP 4.0</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b9a/ad1/20a/b9aad120abd39a8fd12e2b3965acf621.png"></div><br><br>  Each new OpenMP specification introduces very useful and necessary additions to the already existing functionality.  For example, in version 3.0, so-called tasks were added, which allowed solving an even wider range of tasks in parallelizing applications.  3.1, a number of improvements to work with tasks and reductions. <br><br>  But compared to what the standard 4.0 now gives us, the previous innovations seem to be small.  The latest version has expanded the types of supported parallelism, which has never been noticed before. <br><a name="habracut"></a><br>  We all know that parallelism is in fact very different.  It begins at the instruction level, when modern processor architectures provide us with the functionality of a pipeline and superscalarity.  Already at this level we can say that our application is parallel.  But this is something that is already embedded in the hardware today, and that is used implicitly for developers.  There are currently existing processors and other "sweets" - the number of cores and vector registers (SSE, AVX, etc.). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      They give us two more types of parallelism: <br><ul><li>  by tasks. <br>  In this case, all the cores of our processor are used.  The idea is to isolate independent tasks that can be simultaneously performed on several cores. </li><li>  according to (vectorization). <br>  Registers of increased length of each core are used.  In this case, processing of several elements (vectors) of data in one operation / instruction occurs, hence the name ‚Äúvectorization‚Äù. <br></li></ul><br><br>  Here, in fact, all types available on systems with shared memory.  It is worth noting that there are still distributed systems (hi to clusters and MPI), but this is not the focus of our conversation today.  We are talking about OpenMP, and it is classically ‚Äúsharpened‚Äù on systems with shared memory. <br><br>  Moreover, until the last moment, namely July 2013, it was always about concurrency in tasks.  Moreover, the use of OpenMP has become one of the most popular methods, universal in terms of language support (suitable for both C / C ++ and Fortran) and simple in terms of implementation (the idea of ‚Äã‚Äãadding parallelism step by step through directives). <br><br>  But data concurrency has a smaller role in terms of performance.  It is important to note that vectorization is one of the key points when using the Intel compiler if you are working on an application for which high performance is really important.  By the way, for any other compiler too.  Therefore, for a long time, there is a whole set of various directives that help vectorize the code ‚Äî that is, generate such instructions that will use the entire length of the registers, be it SSE, AVX or AVX2, or something more ‚Äúfresher‚Äù or ‚Äúlong‚Äù.  Do not forget that vectorization plays a key role in the new MIC architecture. <br><br>  They understood this in the committee working on the OpenMP specifications.  Therefore, by a willful decision, well-known to people working with the Intel compiler, directives for working with data parallelism, very similar to those of Intel Cilk Plus, were added to the last document. <br><br>  So, what appeared. <br>  Now we can not just ‚Äúscatter‚Äù our work in different streams through existing directives, but also to ensure the vectorization of the corresponding code.  And all this within the framework of OpenMP, that is, without reference to a specific compiler, since standards tend to support everything, sooner or later. <br><br>  I would like to first show how it was in Cilk Plus by a simple example. <br>  Suppose we have a certain cycle: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">add_floats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *a, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *b, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *c, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *d, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *e, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> n)</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;n; i++){ a[i] = a[i] + b[i] + c[i] + d[i] + e[i]; } }</code> </pre> <br>  So if we compile it with the vec-report key to find out if it was vectorized, we will see that it is not.  The reason is in the conservatism of the compiler - if it ‚Äúfeels‚Äù that vectorization is dangerous, it will prefer to ‚Äúplay it safe‚Äù and do nothing.  In our case, this is due to the large number of pointers passed to the function.  The compiler simply thinks that some of them may well have intersections in memory.  But if we, as developers, know that this is not the case and vectorize this cycle safely, we can use the pragma simd directive from Intel CilkPlus: <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> simd for (i=0; i&lt;n; i++){ a[i] = a[i] + b[i] + c[i] + d[i] + e[i];</span></span></code> </pre><br>  We reassemble and voila - the cycle is vectorized!  But once again - this is specific to the Intel compiler.  Now, this functionality also appeared in OpenMP, only the directive has become more ‚Äúfamiliar‚Äù form, namely: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp simd</span></span></code> </pre><br>  In addition, there is a mixed construction, for using two types of parallelism at the same time: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp parallel for simd</span></span></code> </pre><br>  It should be noted that the use of the construction in the ‚Äúbare‚Äù form is not very recommended, because compiler checks for this cycle are completely disabled.  Therefore, it is possible and necessary to set, as in other OMP directives, additional options that help the compiler (about the vector length, about memory alignment, access to it, etc.).  By the way, they are also very similar to those that were already in the Intel compiler, but with a few changes. <br><br>  Another very useful thing has also been added - the so-called elemental functions.  It is not a secret that if a certain function is called in a loop, then in the general case this loop is not vectorized.  In Cilk Plus, a magic <i>__declspec (vector) was used</i> , which allows us to make an elemental function from the most ordinary function - one that could ‚Äúproduce‚Äù a vector of results.  As a result, it could be called in a loop, with its subsequent successful vectorization.  In OpenMP, it now looks like this: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp declare simd</span></span></code> </pre><br>  And now developers on Fortran will also be happy, because there was no such support in it (Cilk Plus only for C / C ++) until the last days. <br>  Thus, in the hands of developers, a powerful tool has appeared in the use of all types of parallelism within one specification, which is good news.  But this is not all that has appeared.  Not paid attention to the now extremely popular programming model for "hybrid" systems with accelerators.  And no matter what type of accelerator ‚Äî whether it‚Äôs a GPU or what other unknown beast ‚Äî the model of its use from the developer‚Äôs point of view is now common, and it is also part of the new OpenMP.  With the help of the target directive, we can now perform calculations on accelerators and get results on the host: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp target map(to(b:count)) map(to(c,d)) map(from(a:count)) { #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp parallel for for (i=0; i&lt;count; i++) a[i] = b[i] * c + d; }</span></span></code> </pre><br>  But this is a separate big topic to talk about.  By the way, OpenMP is now increasingly beginning to compare with other standards, in particular OpenCL, OpenACC and others.  And an interesting comparison is obtained - with a lot of ‚Äúpluses‚Äù for OpenMP.  But back to the topic. <br>  In addition to all the above, other ‚Äúpleasures‚Äù also appeared, but I would filter them out as less significant, although very useful for solving various kinds of tasks.  I'm talking about new tools for error handling, binding threads to specific kernels, new tasking extensions, support for user-defined reductions and a number of other innovations. <br><br>  A full description can be classically found on <a href="http://openmp.org/wp/openmp-specifications/">the</a> OpenMP <a href="http://openmp.org/wp/openmp-specifications/">website</a> .  Well, one of the first compilers, which already partially supports a number of new functions, is <a href="http://software.intel.com/en-us/intel-composer-xe">here</a> .  As always, a trial 30-day version is available.  So welcome to try out the new features of OpenMP 4.0! </div><p>Source: <a href="https://habr.com/ru/post/204668/">https://habr.com/ru/post/204668/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../204656/index.html">"Anti-piracy" law is planned to expand on photos and software</a></li>
<li><a href="../204658/index.html">Recognition of guilloche elements on the example of the passport of the Russian Federation</a></li>
<li><a href="../204660/index.html">The mask Corvo, a character from the game Dishonored, is printed on a 3D printer and exhibited for the first time in crowdfunding. History of the project</a></li>
<li><a href="../204664/index.html">Where and how to train ‚Äúwalking on customers‚Äù? (training video)</a></li>
<li><a href="../204666/index.html">MPEG-DASH in nginx-rtmp-module: live video in a browser without flash</a></li>
<li><a href="../204670/index.html">Mail.Ru Group Technologies Forum in Nizhny Novgorod</a></li>
<li><a href="../204678/index.html">Clone VCL components</a></li>
<li><a href="../204680/index.html">Beeline and beta testers</a></li>
<li><a href="../204682/index.html">Optimize image processing in C ++ using SIMD. Median filter</a></li>
<li><a href="../204684/index.html">8 HTML elements that you do not use (and should)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>