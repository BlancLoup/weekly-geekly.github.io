<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A tool to help you choose the best product ideas.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Let's imagine that you manage a product that helps small businesses to provide technical support to their customers. You are looking for ways to incre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A tool to help you choose the best product ideas.</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/nh/qn/qd/nhqnqdnwisfmywptcpnep31hkke.png"></p><br><p>  Let's imagine that you manage a product that helps small businesses to provide technical support to their customers.  You are looking for ways to increase the level of engagement and retention of your customers.  You have two ideas: </p><br><ul><li>  A dashboard that will allow business owners to monitor engagement statistics. </li><li>  Chat bot that helps business owners automate communication with consumers. </li></ul><br><p>  Dashboard is a feature that has already been discussed several times with users and you feel that it has great potential, but also realize the risk that only one large user will use dashboards.  Chat bot is what everyone in your company likes and is squeezed by the management - it looks like a very necessary thing for customers, this is a cool project.  And yes, chat bots are in fashion now. </p><br><p>  What will you choose? </p><br><a name="habracut"></a><br><p><img src="https://habrastorage.org/webt/e_/m3/cc/e_m3ccz988civv6oe-xyhf0qucs.jpeg"></p><br><p>  Such prioritization issues are the heart of product management.  The cost of an error for the wrong choice can be quite high: the cost of development + the cost of deployment in production + the cost of support + costs of lost profits + all other costs. </p><br><p>  We often have temptations to make decisions on weak signals: majority votes, opinion of authoritative people ( <a href="http://alexkolokolov.com/hippo_anti_data_driven">HiPPO</a> ), industry trends, etc., but, as experience shows, this is a bad heuristic, this approach is no better than tossing a coin. </p><br><p>  In this article I will demonstrate that, in my opinion, is the best way to find successful ideas.  This approach includes three components: </p><br><ul><li>  ICE coefficient </li><li>  Confidence level </li><li>  Gradual incremental validation </li></ul><br><h2>  ICE coefficient </h2><br><p>  ICE calculation is a prioritization method invented by <a href="https://twitter.com/seanellis">Shaun Ellis, the man who helped grow companies like DropBox, Eventbrite and the term growth hacking</a> .  The calculation of the ICE coefficient was originally intended to prioritize growth experiments, but can also be applied to any other ideas. </p><br><p>  You calculate the coefficient for each idea using the following formula: </p><br><p><code><em> ICE = Impact () * Confidence () * Ease (),</em></code> </p> <br><p>  Where: </p><br><ul><li>  Influence is an assessment of how positively the idea will affect the key metric that you are trying to improve. </li><li>  Simplicity (implementation) is an assessment of how much effort and resources will be needed to implement an idea.  This is an inversion of the classic labor cost estimate (in person-weeks) - the less effort, the greater the Simplicity. </li><li>  Confidence - shows how much we are confident in what impact will be exerted, and also to some extent speaks about the simplicity of implementation.  I wrote a whole article <a href="https://medium.com/%40itamargilad/why-impact-effort-prioritization-doesnt-work-57d141fafc2c">explaining why prioritization by effort and value does not work</a> .  [ <a href="https://habr.com/company/kolesa/blog/419349/">translation of this article in Habr√©</a> ].  In short, the point is that we are all very bad in the estimates and naively do not suspect it.  The Confidence Index serves as an antidote, it helps us to be more accurate in our assumptions. </li></ul><br><p>  All three indicators are filled with values ‚Äã‚Äãon relative scales from 1 to 10, so none of them are overvalued.  Each team determines for itself what the indicators 1-10 correspond to, so that each equivalent is relevant.  Ultimately, the goal of the assessment is to get an ‚ÄúIdeas Bank‚Äù, which looks something like this: </p><br><table><tbody><tr><th>  The idea of ‚Äã‚Äãthe project </th><th>  Impact, I [0-10] </th><th>  Confidence, C [0-10] </th><th>  Simplicity, E [0-10] </th><th>  ICE [I x C x E] </th></tr><tr><td>  Community tab </td><td>  7 </td><td>  2 </td><td>  eight </td><td>  112 </td></tr><tr><td>  Update flow </td><td>  five </td><td>  five </td><td>  3 </td><td>  75 </td></tr><tr><td>  Adding PayPal Billing </td><td>  eight </td><td>  one </td><td>  five </td><td>  40 </td></tr><tr><td>  Fix bug with check </td><td>  one </td><td>  four </td><td>  3 </td><td>  12 </td></tr></tbody></table><br><p>  Let's look at an example to see how it works. </p><br><h2>  The first version of ICE </h2><br><p>  You decided to calculate ICE coefficients for two ideas - a dashboard and a chat bot.  At an early stage, you use gross values, based on your own intuition. </p><br><p>  Impact - you assume that dashboards will increase retention significantly, but only for some users, so set 5 out of 10. Chat bot, on the other hand, can affect a large number of users, therefore you put 8 out of 10. </p><br><p>  Simplicity - you think that dashboards will require 10 man-weeks of development, and chat bot - 20, based solely on data from similar previous projects.  You will get better estimates from the development team later, but for now use this simple table (compiled with the team) to convert the estimates into the value of the Simplicity parameter: </p><br><table><tbody><tr><th>  Man weeks </th><th>  Simplicity </th></tr><tr><td>  Less than 1 week </td><td>  ten </td></tr><tr><td>  1-2 weeks </td><td>  9 </td></tr><tr><td>  3-4 weeks </td><td>  eight </td></tr><tr><td>  5-6 weeks </td><td>  7 </td></tr><tr><td>  6-7 weeks </td><td>  6 </td></tr><tr><td>  8-9 weeks </td><td>  five </td></tr><tr><td>  10-12 weeks </td><td>  four </td></tr><tr><td>  13-16 weeks </td><td>  3 </td></tr><tr><td>  17-25 weeks </td><td>  2 </td></tr><tr><td>  26 weeks or more </td><td>  one </td></tr></tbody></table><br><p>  As a result, the dashboard gets the Simplicity value of 4 out of 10, and the chat bot - 2. </p><br><h2>  We count the confidence indicator </h2><br><p>  There is only one way to calculate the Confidence indicator - look at the supporting evidence.  To this end, I created a tool that describes the type tests and evidence that you may have, and the values ‚Äã‚Äãof the Assurance parameter that they have.  When you use this tool, consider what artifacts you already have, how many there are and what you need to do to get even more value. </p><br><img src="https://habrastorage.org/webt/nh/qn/qd/nhqnqdnwisfmywptcpnep31hkke.png"><br><p>  Text on the picture - Level of Confidence: </p><br><ul><li>  <i>About zero:</i> <br><ul><li>  <i>Own confidence.</i> </li><li>  <i>Presentation.</i> </li><li>  <i>Thematic support - consistent with the vision / strategy, current trends / buzzwords, external research, macro trends, product methodology.</i> </li></ul></li><li>  <i>Very low:</i> <br><ul><li>  <i>Someone's opinion - the team, management, external experts, investors, the media, someone else thinks that the idea is good.</i> </li><li>  <i>Estimates and plans - calculations on napkins, assessment of feasibility, timeline of the project, business model.</i> </li></ul></li><li>  <i>Low - unofficial evidence: based on several aspects of product data, frequent requests for sales, 1-3 interested customers, some of the competitors already have this ...</i> </li><li>  <i>Medium-low:</i> <br><ul><li>  <i>Market data is evidence based on surveys, smoke tests, all competitors already have this ...</i> </li><li>  <i>Evidence from users / clients - based on a large amount of product data, requests from top users, interviews with 20+ users, usability results, MVP launch results.</i> </li></ul></li><li>  <i>Medium - test results: based on long-term user research, results of launching a larger scale MVP, alpha, beta versions, A / B experiments.</i> </li><li>  <i>High - data after launch.</i> </li></ul><br><p>  <b><i>Note.</i></b>  If other evidence is used in your product or industry, you can create your own version of the Reliance Tool, just consider what is strong and what is weak evidence.  More information in <a href="https://medium.com/%40itamargilad/evidence-based-scoring-a-systematic-way-to-know-if-you-have-a-good-idea-44d39e166abf">an earlier post</a> (eng.). </p><br><p>  Let's go back to our example and look at the Confidence Tool in action. </p><br><ul><li>  Confirming evidence for a chat bot: your own confidence (you think this is a good idea), thematic support (the industry thinks it is a good idea) and the opinions of others (your leaders and colleagues think it is a good idea).  This gives you a confidence level of 0.1 out of 10, i.e.  about zero.  The tool clearly does not consider opinion as a reliable indicator.  Interesting. </li><li>  The following evidence is available for dashboards: self-confidence (you think this is a good idea), unofficial evidence (a handful of customers asked for it).  In fact, this increases the value of the Confidence parameter to a whopping 0.5 out of 10, which means a low level of confidence.  Unfortunately, users poorly predict their future behavior. </li></ul><br><p>  Calculation of ICE: </p><br><table><tbody><tr><th>  Idea </th><th>  Influence </th><th>  Simplicity </th><th>  Confidence </th><th>  Ice </th></tr><tr><td>  Dashboard </td><td>  four </td><td>  four </td><td>  0.5 </td><td>  eight </td></tr><tr><td>  Chat bot </td><td>  eight </td><td>  2 </td><td>  0.1 </td><td>  1.6 </td></tr></tbody></table><br><p><img src="https://habrastorage.org/webt/uc/yp/nv/ucypnvfuwymugvo4hngtuiwpbko.png"></p><br><p>  <i>The text in the picture: along the Y axis - the ICE score, along the X axis - the prioritization round.</i>  <i>The blue dot is a dashboard, the red dot is a chat bot.</i> </p><br><p>  At the moment, dashboards look like a more appropriate idea, but the Tool shows that the level of confidence is low.  So far, just not enough information to make a decision. </p><br><h2>  Estimates and Verification </h2><br><p>  Next, you meet with colleagues from the development and UX, and then discuss both ideas together.  Both projects at first glance seem to be quite feasible.  Development Timlid returns with approximate estimates of labor costs: dashboards take 12 man-weeks to run, and chat bot - 16. According to your scale of simplicity, this means indicators 4 and 3, respectively. </p><br><p>  In parallel with this, you make calculations on a napkin and update the ‚ÄúInfluence‚Äù column.  Upon closer inspection, the dashboard looks slightly less promising and gets 3. The chat bot still looks solid, at 8. </p><br><p>  Using the Confidence Tool shows that both ideas now pass the ‚ÄúEvaluations and Plans‚Äù test and get new indicators for the Confidence parameter.  Dashboard now has 0.8, chat bot - 0.4. </p><br><table><tbody><tr><th>  Idea </th><th>  Influence </th><th>  Simplicity </th><th>  Confidence </th><th>  Ice </th></tr><tr><td>  Dashboard </td><td>  3 </td><td>  four </td><td>  0.8 </td><td>  9.6 </td></tr><tr><td>  Chat bot </td><td>  eight </td><td>  3 </td><td>  0.4 </td><td>  9.6 </td></tr></tbody></table><br><p><img src="https://habrastorage.org/webt/tr/ve/vd/trvevd98nq2rxlnip7wwho_wcmw.png"></p><br><p>  Thus, the chat bot eliminated the gap.  However, the level of confidence is still low for a good reason - these are mainly figures obtained from the air, and you understand that you need to gather more evidence. </p><br><h2>  Market data </h2><br><p>  You send a survey to current users, asking them to choose one of 5 potential features, the list includes a chat bot and a dashboard.  You get hundreds of answers.  The results are very positive for chatbot - this is feature number 1, 38% of respondents chose it.  Dashboards ranked third with 17% of the vote. </p><br><p>  This gives both features a little bit of support from market data, but the chat bot is above 1.5.  Dashboards also get an increased value for the ‚ÄúConfidence‚Äù column, but so far only up to 1. </p><br><table><tbody><tr><th>  Idea </th><th>  Influence </th><th>  Simplicity </th><th>  Confidence </th><th>  Ice </th></tr><tr><td>  Dashboard </td><td>  3 </td><td>  four </td><td>  one </td><td>  12 </td></tr><tr><td>  Chat bot </td><td>  eight </td><td>  3 </td><td>  1.5 </td><td>  36 </td></tr></tbody></table><br><p><img src="https://habrastorage.org/webt/si/sc/iw/sisciwibjca5c_umalykjr4xwlg.png"></p><br><p>  Chat bot is becoming a strong leader.  It seems your colleagues and the industry were right.  Is it time to pull the trigger?  Probably not.  Projects are quite expensive and we still have only a little confidence in success.  Unfortunately, the survey results do not create a strong enough signal.  We continue to work! </p><br><h2>  Evidence from clients </h2><br><p>  To learn more, you do research with ten current users, showing them interactive prototypes of each of the features.  In parallel, you conduct a telephone interview and interview 20 respondents who must choose one of two candidate functions. </p><br><p>  The study shows a more detailed picture: </p><br><ul><li>  8 out of 10 customers found dashboards useful and said they would use it at least once a week.  Their understanding of the functionality coincides with what you wanted to convey and they had no difficulty in working with dashboards.  Telephone interviews confirmed understanding and desire to use on average once a week. </li><li>  9 out of 10 study participants said they would use a chat bot, their level of enthusiasm was very high.  Everyone immediately understood how a chat bot could help them and many asked to get access as soon as possible.  However, major usability issues were identified, plus some users voiced concern that their clients might be unhappy with the bot's unnatural responses. </li></ul><br><p>  This qualitative research gave food for thought.  Dashboards look more popular than previously thought.  A chat bot now looks like a project with higher risks and more potential.  Looking at the Reliance Tool, you set the dashboard and chat bot to the values ‚Äã‚Äã3 and 2.5, respectively.  You update Influence values ‚Äã‚Äãto 6 for dashboards and 9 for chat bot.  Also, from the results of usability research, you understand that the chat bot UI will require more work, so you reduce the Simplicity parameter to 2. </p><br><table><tbody><tr><th>  Idea </th><th>  Influence </th><th>  Simplicity </th><th>  Confidence </th><th>  Ice </th></tr><tr><td>  Dashboard </td><td>  6 </td><td>  four </td><td>  3 </td><td>  72 </td></tr><tr><td>  Chat bot </td><td>  9 </td><td>  2 </td><td>  2.5 </td><td>  45 </td></tr></tbody></table><br><p><img src="https://habrastorage.org/webt/f0/ee/dx/f0eedxxa7e-jyyxppzbaklhm3yq.png"></p><br><p>  The table has changed again and now the dashboard is in the lead.  You bring results to your team and management.  The forecast, based strictly on ICE, declares dashboards to be the winner, on the other hand, the level of Confidence is still far from high.  I do not want to let go of a potentially good feature, so the team decides to continue testing both. </p><br><h2>  Latest tests and winner! </h2><br><p>  You decided to start creating a chat bot MVP - development took six weeks and you launched it for the 200 respondents who participated in the previous survey, who voiced a desire to participate in beta testing.  167 included a feature, but the number of uses dropped dramatically from day to day, and by the end of the second week only 24 people were active users.  In subsequent surveys and calls, the picture became clearer.  The chat bot is more difficult to use and much less useful than the participants expected; worse, it is unfriendly to customers who seem to appreciate personal contact.  In fact, this feature makes business owners work harder. </p><br><p>  Analyzing the results, you and the team come to the conclusion that launching a convenient chat bot version that will meet customer expectations will require at least 40-50 additional person-weeks (Simplicity = 1) and this is very risky.  It is also clear that a much smaller number of users perceive a chat bot as convenient than originally expected.  Therefore, you have reduced the Impact to 2. This changes the original idea in a fundamental way, so that you can no longer trust the results of user research and accept them, so reduce the Confidence Index to 0.5. </p><br><p>  MVP Dashboard launched in five weeks for another 200 users.  The results are very good.  87% of participants use it, the majority daily, the outflow is small.  Feedback is extremely positive, most ask for access to full functionality.  You understand that the Impact is more than you expected - 8. The development team estimates that the revision of the full version will take 10 weeks, therefore Simplicity 4. According to the tool, you set Confidence to 6.5 out of 10. </p><br><table><tbody><tr><th>  Idea </th><th>  Influence </th><th>  Simplicity </th><th>  Confidence </th><th>  Ice </th></tr><tr><td>  Dashboard </td><td>  eight </td><td>  four </td><td>  6.5 </td><td>  208 </td></tr><tr><td>  Chat bot </td><td>  2 </td><td>  one </td><td>  0.5 </td><td>  one </td></tr></tbody></table><br><p><img src="https://habrastorage.org/webt/lq/i_/lg/lqi_lgrgp-nra5w7j_s1mcg_1he.png"></p><br><p>  Now prioritization is very simple.  Nobody argues that dashboard is the feature that should be dealt with.  You leave a chat bot in your Ideas Bank to record future finds, but it is naturally sorted to the very end because of the low ICE rate. </p><br><h2>  Total </h2><br><h3>  1. Stop investing in bad ideas. </h3><br><p>  This example illustrates how risky it is to bet on features that require a lot of effort and are based on flair, opinions, market trends, etc. Most of the ideas are more like a chat bot than a dashboard.  They bring less results and cost much more than you think.  The only way to find winning ideas is to test them and reduce the level of uncertainty. </p><br><h3>  2. Worry about results, not features. </h3><br><p>  It looks like a time consuming and slow way to create products, but in fact it is a more efficient way than alternatives.  Testing to determine the Confidence indicator not only reduces the amount of wasted effort to bad ideas, but also focuses teams on short and tangible <a href="https://blog.itnig.net/optimizing-your-project-for-learning-dfb60e86fd09">learning milestones</a> with quick measurable results, which improves focus and performance.  In the process, we learn a lot about our product, users, market and as a result we have the best final product, which has already been tested by customers.  For this reason, we are less often surprised by the results of the launch and corrections are required much less. </p><br><h3>  3. Let thousands of flowers bloom </h3><br><p>  In reality, we often have to make a choice not between two ideas, but between dozens.  By limiting the amount of effort to each, given the level of Confidence, we are able to test in parallel a multitude of ideas, avoiding the traps of the traditional approach to development.  You can read more about this <a href="https://habr.com/company/kolesa/blog/358672/">in the article ‚ÄúWhy you should stop using grocery roadmap and try GIST‚Äù</a> . </p><br><p><img src="https://habrastorage.org/webt/_y/nn/m1/_ynnm1shiwcm0o-pzb-ejjhdmdk.png"></p><br><p>  In this example, the team tests four ideas in parallel, launching several step-projects.  Each one improves the idea incrementally, as a result of testing, increasing the level of confidence in the results. </p><br><h3>  4. How to drag management and stakeholders to your side </h3><br><p>  What worries people most of all when I explain this topic is the question of how to ‚Äúsell‚Äù it to management and stakeholders.  Can we actually force them to limit their level of influence on the product?  Well, you will be surprised.  I heard from many executives that they would prefer not to make decisions on product issues, but if the team offers weak options, they feel the need to get involved.  That there are weak and strong options is, of course, a subjective opinion, as long as you show not just a polished presentation, but come with real, credible evidence.  You will be very surprised when you understand how much easier the discussion is.  On the other hand, the next time your CEO comes up with a regular batch of must-have ideas, try to show him how such ideas are evaluated: what indicators of Influence, Simplicity and Confidence do you indicate which ICE coefficient is finally obtained, how does the comparison with others ideas and how you can test them to increase your confidence. </p><br><p>  Most intelligent people will agree that this is a good way.  If they are still not convinced, throw off a link to this translation or the <a href="https://hackernoon.com/finding-winning-ideas-using-the-confidence-tool-d8f2d8cc2c15">original post Itamar</a> , where he is ready to defend this approach in the comments. </p><br><p>  <i>In the united company ‚ÄúWheels |</i>  <i>Roof |</i>  <i>Market ‚Äùwe are looking for product managers who are ready to experiment, quickly and inexpensively testing hypotheses.</i>  <i>You can apply for a job <a href="https://hh.kz/vacancy/22784549">on Headhunter</a> and the <a href="https://job.kolesa.kz/vacancy-product-manager-22784549">corporate website</a> .</i> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/425833/">https://habr.com/ru/post/425833/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../425823/index.html">IPO 2018 statistics: attracted $ 45 billion, Dropbox raised less money than pharmaceutical companies and real estate sellers</a></li>
<li><a href="../425825/index.html">How I created an online casino</a></li>
<li><a href="../425827/index.html">Google+ lesson: projects should be monitored so that the boundaries between the interests of users in real life are respected and online</a></li>
<li><a href="../425829/index.html">How we fought Roskomnadzor and what came of it</a></li>
<li><a href="../425831/index.html">RKN Alert - Roskomnadzor database in your browser</a></li>
<li><a href="../425835/index.html">"Breaking Bugs" in Sberbank: how to fix the seven-day rate of bugs per day</a></li>
<li><a href="../425837/index.html">Copy semantics and resource management in C ++</a></li>
<li><a href="../425839/index.html">Atlassian Conference Overview</a></li>
<li><a href="../425843/index.html">Python for the child: the choice of tutorial</a></li>
<li><a href="../425845/index.html">Auto-blocking apps on Google Play</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>