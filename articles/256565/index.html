<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Light streams in Embox</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Today, as promised, I will continue the theme of planning light entities, which I have already begun in my series of articles. In it, I talked about t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Light streams in Embox</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/334/427/c23/334427c23bd54f46ba40343bfe35bad9.png" align="right"><br>  Today, as promised, I will continue the theme of planning light entities, which I have already begun in my series of articles.  In it, I talked about the internal structure of the <a href="http://habrahabr.ru/company/embox/blog/244071/">tasklet</a> , <a href="http://habrahabr.ru/post/244155/">workqueue</a> and <a href="http://habrahabr.ru/post/244361/">protothread</a> .  Of course, the topic is not limited to these examples: there is also FreeRTOS with its <a href="http://www.freertos.org/croutine.html">coroutine</a> , or <a href="http://www.gnu.org/software/pth/">GNU Portable threads</a> ;  or you can move away from the structures and libraries used in the OS, and recall the various green threads, which are becoming more and more. <br><br>  This time I want to share how we implemented light streams in the <a href="https://github.com/embox/embox">Embox</a> project.  On the one hand, we tried to take into account the experience of previous developments, on the other - to bring something new. <br><a name="habracut"></a><br><h4>  How it all began </h4><br>  The problem came to us from different sides. <br><br>  Threads require their stack, consuming a relatively large amount of RAM.  Cooperative multitasking was carried out only by turning off the timer, which is responsible for calling the scheduler when the time slice expires.  What did it lead to?  On boards with limited resources, sometimes you have to completely abandon multitasking. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In addition, more and more tasks appeared for which it would be nice to have some kind of event handling mechanism.  It is desirable with priorities and synchronization primitives, and that all this is processed quickly and does not require extra memory. <br><br>  This made us think about lightweight, almost cooperative multitasking for some chainless entities.  But at the same time no one was going to give up full-fledged multitasking. <br><br>  Therefore, we decided not only to introduce lightweight planning units into the system, but also to entrust the work of dispatching these light streams to the main system scheduler on general rights with full flows.  Potentially, we have seen the following benefits: <br><ul><li>  You can get rid of the softirq layer and handle pending interrupts in high priority scheduler queues; </li><li>  In general, with proper prioritization, and some hardware interrupts can be handled in the same way; </li><li>  Flexible customization of priorities, including during execution.  For example, recently we had a task in which it was necessary to process interrupts from a timer earlier than from the network stack.  And some real-time tasks may require the processing of high-priority user flows ahead of some pending interrupts. </li></ul><br>  So, what we dreamed about: <br><ul><li>  A scheduler who can manage both regular and light streams; </li><li>  Efficient lightweight threads, sorts of scheduled features like event handlers with synchronization support. </li></ul><br><br>  To reduce the connectivity of the system, the scheduler will now manage the abstract planning units. <br><br><h4>  Schedee, or abstract planning unit </h4><br>  The idea is, in fact, quite simple, especially when viewed in terms of OOP.  Take a look at the chart: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/fc9/1f3/c9f/fc91f3c9f3fb402ca1a6fd4da7800c8d.png"></div><br>  Schedee is the parent abstract class of various types of threads.  Each stream type must provide some kind of interface for managing it.  The scheduler knows nothing about specific implementations, and in its function it only determines who will be executed next, does some preparation and delegates processing to a specific schedee, for example, by calling the special function doSomethng (). <br><br>  Next, I will talk about how we applied this idea in our planner. <br><br>  In the C language, inheritance, unfortunately, has to be realized by hands, namely, on the basis of structure as a member of another, more specific structure.  We will have an abstract schedee structure, from which the concrete thread and lthread structure types are inherited and provide the implementation of the necessary ‚Äúabstract‚Äù functions. <br><br>  We have already implemented the usual POSIX-compatible threads and the central scheduler that manages them.  Therefore, the expansion of the functionality of the scheduler occurred with an eye on the already existing implementation. <br><br>  The first thing we needed to do was to select from the structure of ordinary threads a part that the scheduler manages.  Based on this, we construct the abstract structure of schedee. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/25a/94f/1f8/25a94f1f8bcc4caaa7a5633746d28d5e.png"></div><br>  It turned out to be quite simple to select common fields from the structure.  But do you need something else?  To answer this question, it is necessary, first, to understand how the types of flows can differ fundamentally, and, second, to deal with the work of the scheduler. <br><br>  Flows can be: <br><ul><li>  Displaced or cooperative.  The former are pushed out by the threads with a higher priority or after the expiration of the time slice, while the latter transfer control to the scheduler themselves.  From the point of view of the scheduler function itself, there is no difference here, the only difference is when and by whom it will be called next time; </li><li>  With or without stack.  The presence of a stack on threads leads to additional memory consumption and the cost of context switching.  The lack of a stack makes it impossible to wait with a change of context and, as a result, crowding out (at least, full-fledged).  This difference is already a matter of principle for the scheduler, such streams should be processed differently; </li><li>  With one or more entry points.  With one entry point, everything is simple: the function runs from and to.  The presence of several entry points is typical for coroutines and iterators.  For such threads, it is necessary to store information about the current entry point; you can consider such information as an analogue of the thread context with the stack waiting for an event.  In any case, the scheduler should not be aware of this. </li></ul><br>  Let's see now how the planner was arranged.  The code is simplified for better understanding. <br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">schedule</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">thread</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">prev</span></span></span><span class="hljs-class">, *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">next</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ipl_t</span></span> ipl; prev = thread_self(); <span class="hljs-comment"><span class="hljs-comment">/*    */</span></span> ipl = ipl_save(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!prev-&gt;waiting) runq_enqueue(&amp;rq.<span class="hljs-built_in"><span class="hljs-built_in">queue</span></span>, prev); next = runq_extract(&amp;rq.<span class="hljs-built_in"><span class="hljs-built_in">queue</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (prev != next) <span class="hljs-comment"><span class="hljs-comment">//  ,  sched_switch(prev, next); //   . ipl_restore(ipl); }</span></span></code> </pre> <br>  The scheduler is arranged quite simply: it determines which thread will be executed next, and if the thread has changed, it switches the context.  After that, the new thread already naturally leaves the scheduler function and continues its work.  That is, the scheduler is sharpened to work only with stack threads. <br><br>  In order to abstract away from specific implementations of a schedee, specific processing needs to be put into a special function, let's call it process ().  A pointer to this function will be in the schedee. <br><br>  Now you need to understand how to handle threads without a stack.  What do we know about them? <br>  Such streams are not supplanted.  That is, there should be no implicit rescheduling calls; <br>  For chainless streams, there is no need to switch the context.  In fact, there are different approaches, in Linux, for example, a separate stack is allocated for the sequential processing of softirq.  We have so far stopped at the variant of processing such threads on the stack of the last executed full thread. <br><br>  Thus, if for regular flows it is necessary to leave the scheduler function, then it will be expedient to process loopless flows in a loop directly in the scheduler, which, by the way, is a fairly common approach.  The loop ends as soon as a thread arrives at the stack. <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">schedule</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> preempt)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">prev</span></span></span><span class="hljs-class">, *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">next</span></span></span><span class="hljs-class">, *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">last</span></span></span><span class="hljs-class">;</span></span> prev = schedee_get_current(); <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> ipl_save(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!prev-&gt;waiting) runq_enqueue(&amp;rq.<span class="hljs-built_in"><span class="hljs-built_in">queue</span></span>, prev); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>) { next = runq_extract(&amp;rq.<span class="hljs-built_in"><span class="hljs-built_in">queue</span></span>); <span class="hljs-comment"><span class="hljs-comment">/*     process() */</span></span> last = next-&gt;process(prev, next); <span class="hljs-comment"><span class="hljs-comment">/* process()  ,     . *    ,     , *  . */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (last) <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> ipl_save(); } }</code> </pre><br>  Encapsulation is a good principle, even if we are dealing with procedural programming.  So all the scheduler code should know only about the schedee, but not about the specific threads.  Here is the complete code for the schedee structure: <br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">runq_item_t</span></span> runq_link; <span class="hljs-comment"><span class="hljs-comment">/*    runq */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">spinlock_t</span></span> lock; <span class="hljs-comment"><span class="hljs-comment">/*     SMP */</span></span> <span class="hljs-comment"><span class="hljs-comment">/*  -,      *   schedee.    ,    *    ,    .. *   schedee,      * .  schedee ,    NULL. */</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> *(*</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">process</span></span></span><span class="hljs-class">)(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">prev</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">next</span></span></span><span class="hljs-class">);</span></span> <span class="hljs-comment"><span class="hljs-comment">/*          . */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> active; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ready; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> waiting; <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">affinity</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">affinity</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sched_timing</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sched_timing</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/*    runq */</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee_priority</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">priority</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/*    waitq.  ,   ,   . */</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">waitq_link</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">waitq_link</span></span></span><span class="hljs-class">;</span></span> };</code> </pre><br>  And finally, what the process () function of ordinary threads looks like: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">struct schedee *</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">thread_process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct schedee *prev, struct schedee *next)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">thread</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">next_t</span></span></span><span class="hljs-class">, *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">prev_t</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-keyword"><span class="hljs-keyword">next_t</span></span> = mcast_out(next, struct thread, schedee); <span class="hljs-keyword"><span class="hljs-keyword">prev_t</span></span> = mcast_out(prev, struct thread, schedee); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (prev != next) { thread_context_switch(<span class="hljs-keyword"><span class="hljs-keyword">prev_t</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">next_t</span></span>); } ipl_enable(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!<span class="hljs-keyword"><span class="hljs-keyword">prev_t</span></span>-&gt;siglock) { thread_signal_handle(); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> &amp;thread_self()-&gt;schedee; }</code> </pre><br><h4>  Light streams </h4><br>  Consider now the light streams of Embox, for which everything was started.  Our light streams are chainless, cooperative and support multiple entry points. <br><br>  In one of the tasks, it was necessary to process information constantly coming from an external source, moreover, with synchronization.  Therefore, the question was originally about adequate support for synchronization, which in fact rests on the skill: <br><ol><li>  first of all, for example, to capture a mutex;  in the general case, wait for any condition (analog of conditional variables) </li><li>  in case of failure, return control to the scheduler in the middle of the function </li><li>  start from the right place when the thread is awakened, for example, when releasing the necessary mutex. </li></ol><br>  In the case of normal flows, everything is simple: when you sleep, a call to the scheduler is requested and rescheduled.  The thread simply calls, for example, the sleep () function.  Items 1 and 3 are implemented by keeping the stack and context safe.  With chainless streams everything is more complicated: <br><ul><li>  You must exit the thread function explicitly in order for the stack to be in the same state as before the start of the light thread. </li><li>  The light stream function will start from the beginning.  When you call the local variables are no longer relevant. </li></ul><br><br>  To combat the last item, we decided to follow the path of coroutines, like Adam Dunkels in our <a href="http://dunkels.com/adam/pt/">protothread</a> library.  But, unlike Adam, we decided not to hide the logic behind cunning macros, but to make the interface as explicit as possible.  Our solution is based on the extension of GCC <a href="https://gcc.gnu.org/onlinedocs/gcc/Labels-as-Values.html">Labels as Values</a> .  This extension allows you to get links to tags, as well as calculate the indentation from a particular tag, using the usual manipulations with pointers. <br><h5>  Light streams and their structure </h5><br>  To understand everything in more detail, consider the details of the implementation.  First, the structure of lthread itself: <br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">lthread</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> (*run)(struct lthread *); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> label_offset; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">joining</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sched_wait_info</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">info</span></span></span><span class="hljs-class">;</span></span> };</code> </pre><br>  The first thing to clarify is the signature of the run function.  Since light streams do not have a stack, it is assumed that the structure of light streams will often be a member of another structure containing information that must be kept from the call to call.  Therefore, it is wise to use the reference to the lightweight itself as the main argument, and the rest of the information to be addressed using type conversion. <br><br>  The return value of the run function is the entry point information.  If the input point of the function is assumed to be one or when the restart is used, the initial input point should be used, then the return value will be 0. Otherwise, the return value is specified by the lthread_yield () macro.  I will describe this and other macros below. <br><br>  The label_offset field is indented from the initial function label.  This is a utility field for storing the input stream point.  Working with different input points is done using the lthread_resume () and lthread_yield () macros. <br><br>  The joining field is a reference to the schedee of a thread waiting for a light thread to complete, similar to normal threads.  More about this will be below. <br><br>  And finally, info is a service field with the necessary information for waiting by timeout. <br><br><h5>  Light Stream API </h5><br>  The basic light thread API is pretty simple.  The initialization and launch functions hardly require explanation: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lthread_init</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct lthread *lt, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> (*run)(struct lthread *))</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lthread_launch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct lthread *lt)</span></span></span></span>;</code> </pre><br>  When the application has completed, you need to make sure that the light flows are over and no one will wake them up.  If this is not the case, then it is not safe to terminate the application: the wake-up of a light stream can occur when its structure is irrelevant.  Therefore, you must first wait for the flow to be in the desired state.  This is similar to the thread_join () function.  We need its analogue for light streams: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">extern</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lthread_join</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct lthread *lt)</span></span></span></span>;</code> </pre><br>  Now this function has one drawback: it can only be called from a thread with a stack.  In fact, it can be expanded to the general case, if necessary. <br><br>  There is another important note regarding this feature.  In order to understand it, let's digress a little and pay attention to the life cycle of the light flow.  A light stream can only be in two states: ready and waiting.  Ready light threads are in the queue of the runq scheduler, and while it is in this state, you cannot add it to the queue a second time.  However, as soon as the ready flow comes from the queue, it enters a waiting state, and now it can be re-planned, including this it can do.  For example, tasklets in Linux behave in the same way.  If the light thread plans itself (in fact, never ends), then the thread that caused lthread_join () will simply hang.  The user himself is responsible for ensuring that the easy flow does not plan for himself in this case. <br><br>  Consider the part of the API that provides label management, that is, multiple entry points.  Important note: working with labels is performed only in the run () function itself, but not in the functions it calls.  Unfortunately, there is no way out of these limitations without a stack. <br><br>  Macro that returns a previously saved label: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/*  : goto lthread_resume(lt, start); */</span></span> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> lthread_resume(lt, initial_label) \ *((lt)-&gt;label_offset + (initial_label))</span></span></code> </pre><br>  A macro that returns the indentation relative to the initial label: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/*  : return lthread_yield(lt, start, resume_point); */</span></span> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> lthread_yield(initial_label, target_label) \ (target_label) - (initial_label);</span></span></code> </pre><br>  The lthread_resume () macro should always be paired with the goto statement, and lthread_yield () with the return statement. <br><br>  All wait and sync functions for light streams work on the same principle.  Consider the example of a simple wait timeout macro: <br><pre> <code class="cpp hljs">SCHED_WAIT_TIMEOUT_LTHREAD(self, cond_expr, timeout);</code> </pre><br>  This function returns one of three possible codes: <br><ul><li>  0 if the condition became true; </li><li>  ETIMEDOUT, if the condition is not fulfilled after the timeout expires; </li><li>  EAGAIN, if the condition is not yet true, the timer is started, you need to exit the easy flow function to return control to the scheduler. </li></ul><br><br>  Now consider the function of processing light threads, which is called from the scheduler: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/* :    */</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> struct schedee *</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lthread_process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct schedee *prev, struct schedee *next)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">lthread</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">lt</span></span></span><span class="hljs-class"> = </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mcast_out</span></span></span><span class="hljs-class">(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">next</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">lthread</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">schedee</span></span></span><span class="hljs-class">);</span></span> schedee_set_current(next); <span class="hljs-comment"><span class="hljs-comment">/*   ,         * . */</span></span> next-&gt;ready = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; next-&gt;waiting = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; <span class="hljs-comment"><span class="hljs-comment">/*   process()   . */</span></span> ipl_enable(); <span class="hljs-comment"><span class="hljs-comment">/*       .    * lthread_yield(). */</span></span> lt-&gt;label_offset =lt-&gt;run(lt); <span class="hljs-comment"><span class="hljs-comment">/*       ,  schedee,  *  . */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lt-&gt;joining &amp;&amp; __lthread_is_disabled(lt)) sched_wakeup(lt-&gt;joining); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>; }</code> </pre><br><h4>  Example </h4><br>  To demonstrate, consider a game Race, which works in two light streams: one is responsible for moving the road with obstacles, the other checks whether the control key is pressed. <br><br>  All the code of the game is <a href="">here</a> , here I will give only the main function of the light flow, responsible for moving the road. <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">move_road</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct lthread *self)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> to_wait; <span class="hljs-comment"><span class="hljs-comment">/*  lthread_resume()     . *    ,      , *    -   . */</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">goto</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lthread_resume</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, &amp;&amp;update)</span></span></span></span>; update: is_game_over |= is_obstacle(car_line_nr*RACE_ROAD_LEN + <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (is_game_over) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; race_update_road(); race_print_road(road); wait: to_wait = RACE_ROAD_UPD_MS - (step / RACE_LVL_STEP) * RACE_LVLUP_MS; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (SCHED_WAIT_TIMEOUT_LTHREAD(self, <span class="hljs-number"><span class="hljs-number">0</span></span>, to_wait) == -EAGAIN) { <span class="hljs-comment"><span class="hljs-comment">/*        0,   *   ,     * lthread_yield()  ,       *  . */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lthread_yield(&amp;&amp;update, &amp;&amp;wait); } <span class="hljs-keyword"><span class="hljs-keyword">goto</span></span> update; }</code> </pre><br>  This application was written to demonstrate the work of the scheduler and light streams on the STM32VLDISCOVERY board with an wh1602b LCD screen.  In fact, the characteristics of STM32VL allow you to run Embox with this game and with preemptive streams: 8kb RAM and 128kb flash.  Therefore, I will give a description of the Embox images for the board with the game on light streams and ordinary streams: <br><table><tbody><tr><th></th><th>  cooperative </th><th>  combined </th></tr><tr><td>  text Os / O2 </td><td>  28724/31504 </td><td>  30152/33116 </td></tr><tr><td>  data </td><td>  436 </td><td>  436 </td></tr><tr><td>  bss </td><td>  3168 </td><td>  3102 </td></tr><tr><td>  Main stack + thread stack </td><td>  1536 + 0 </td><td>  1078 + 1782 * 2 </td></tr></tbody></table><br>  Finally, a video with the process of the game. <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/vLe5T3gdfYI%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjsvoSd3JZYby2QXQrrvrNNlGhntg" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  Conclusion </h4><br>  All the code I gave in the article can be found in the github repository of our project: <br><ul><li>  <a href="https://github.com/embox/embox/tree/24f47ed68a75229b121b106caf38c07a80f5972a/src/kernel/lthread">Everything about light streams</a> </li><li>  <a href="">Scheduler Code</a> </li><li>  <a href="">Here the schedee structure is declared.</a> </li></ul><br>  We still have work to do.  Light flows are still young and, most likely, they will change and improve more than once.  Already there are ideas and challenges: <br><ul><li>  Perhaps it makes sense to divide light threads into two different types: using coroutines and simple atomic functions like a tasklet.  In addition, it is possible that you can achieve coroutine functionality without tags, simply by breaking the flow function into several and, with each call, replacing the function pointer.  It would have been a sort of state machine. </li><li>  Potentially, it is possible to realize the displacement of light flows by higher-priority light flows.  This is important for real-time, but difficult from the point of view that light flows will no longer be atomic, which means that different locks may be required. </li><li>  Of the synchronization mechanisms, only mutexes are implemented for light streams, since we most often use them.  Others are waiting in the wings. </li></ul><br>  Of course, there are a number of subsystems for which I want to introduce light flows.  For example, tty driver, pnet subsystem. <br><br>  Over time, all these problems will be solved.  You can do it too :) <br><br>  <i>PS In St. Petersburg, every last Wednesday of the month pass Linux.</i>  <i>I‚Äôll tell you about light streams, how the workqueue and taklet of the Linux kernel are arranged, and maybe something else :)</i> <i><br></i>  <i>There you can listen to other interesting performances.</i>  <i>For information, see the <a href="http://groups.google.com/group/spblinux/">SPbLUG</a> mailing <a href="http://groups.google.com/group/spblinux/">list</a> .</i>  <i>Meetings are like 19:00 at the address: 10th line of V.O.</i>  <i>33-35, Faculty of Geography, St. Petersburg State University.</i> </div><p>Source: <a href="https://habr.com/ru/post/256565/">https://habr.com/ru/post/256565/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../256551/index.html">Approaches and tools for working with BigData - everything is just beginning, it begins</a></li>
<li><a href="../256555/index.html">Do OS need short-term support clouds? (poll)</a></li>
<li><a href="../256559/index.html">PCB assembly: quick start from scratch</a></li>
<li><a href="../256561/index.html">IBM Research Center sets a new record for recording data on tape</a></li>
<li><a href="../256563/index.html">Weekly build Vivaldi 1.0.161.2</a></li>
<li><a href="../256567/index.html">DataTalks # 2: Data Visualization</a></li>
<li><a href="../256571/index.html">Programmer == creativity || programmer! = creativity</a></li>
<li><a href="../256573/index.html">CTB-Locker. We decided to pay</a></li>
<li><a href="../256575/index.html">Seven principles of the effectiveness of a data center from Microsoft</a></li>
<li><a href="../256577/index.html">We are switching from STM32 to the Russian K1986BE92QI microcontroller. Practical application: Generate and reproduce sound. Part three: generate a sine wave. A simple look at DMA + first acquaintance with timers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>