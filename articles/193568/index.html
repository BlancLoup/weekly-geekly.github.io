<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The case of Pixar or again about the importance of testing backups</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="1998, Pixar Studio. The creation of Toy Story 2 is in full swing. In the process involved more than 150 people. The size of the source materials of th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The case of Pixar or again about the importance of testing backups</h1><div class="post__text post__text-html js-mediator-article">  1998, Pixar Studio.  The creation of Toy Story 2 is in full swing.  In the process involved more than 150 people.  The size of the source materials of the animation is 10 GB (for those times it is a lot).  Every day a full backup is built to tape.  The cassette has a size of ... 4GB (data on tape is compressed, but, of course, not to that extent).  Each time an error is issued, but no one notices this, because the log file is located on the same tape and is written at the very end of the backup task, and since there is no longer any space on the tape, it is 0 bytes in size.  Every week a test data recovery is carried out, during which the first 2000 frames of animation are checked.  And, of course, every time the test passes successfully. <br><br>  ... And then suddenly the day came when one of the employees (mistakenly or intentionally) launched the command "/ bin / rm -r -f *" (or similar) on the server, which deleted 90% of the 100,000 animation source files.  One of the company's employees, Larry Cutler, was just looking through the files of the animation source folder, intending to correct something in Woody‚Äôs hat model, when he suddenly noticed that there were only 40 files left in the folder ... then 4 ... and after another second not left at all.  Larry called the IT service and said that " <i>there was a massive data loss,</i> " and that "the <i>recovery will require a full backup ...</i> " Which, as it turned out a little later, they did not have, despite the daily backup. <br><br><a name="habracut"></a><br>  What happened next?  The ‚Äúfull backup‚Äù, for obvious reasons, turned out to be not quite complete: it turned out that up to 30,000 files have not been on the tape lately.  The task was complicated by the fact that permanent files were created, deleted, and modified in the folder, so backups created at different times often contained different sets of files, so they had to be manually compared to detect what was deleted as planned, and that disappeared as a result of a failure.  It took many days of painstaking manual work to analyze all the missing files, the surviving versions of which were scattered in incremental and full backups over the past two months. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I would like to analyze: what actions need to be taken to minimize problems similar to those described above. <br><br>  First of all, we should distinguish between <b>testing the integrity of the backup</b> (media testing) and <b>testing of restoration from the backup</b> (data testing).  In the first case, you only check the integrity of the copy of the checksums of the data blocks.  In the second, you are testing to reflect a particular simulated scenario of a single failure or ‚Äúfull-blown catastrophe‚Äù of your productive network. <br><br><h5>  Backup recovery testing is recommended regularly. </h5><br>  As the productive system grows in size, the results of the recovery test may vary.  For example, a week ago everything was restored correctly, and then ‚Äúsuddenly‚Äù the backups ceased to fit in the repository, and the error message was not noticed.  Or installed a new network application, and its file location was not included in the backup.  Or, the system can be successfully replicated by a block method of direct mapping to a disk having a factory capacity of 2TB.  ‚ÄúDirect block mapping‚Äù means that a block of data on the target disk is mapped directly to a data block on the source disk (without using an intermediate redirect table).  But if at some point the system is upgraded, and the capacity of the source disk exceeds 2TB, and the backup disk is not updated (this often happens because the productive system infrastructure and backup infrastructure have different budgets, and in some cases, different administrators), this replication method will stop working. <br><br>  The recovery test should be carried out in sessions that allow the suspension or even a complete disconnection of the connection, followed by a recovery.  Ideally, recovery can be done from an administrator‚Äôs laptop, or from any computer on the network, including the administrator‚Äôs home computer.  Terminal connections allow this to be fully achieved, and the backup product must correctly work out this scenario.  The recovery process can take many hours, and flexibility in managing and monitoring this process is an important parameter. <br><br>  The recovery process may require additional steps that the backup product itself could not perform for some reason: for example, configuring the DNS, running the database script, etc.  When creating backup jobs, the administrator can easily forget about these steps due to the ‚Äúhuman factor‚Äù (after all, the described additional steps are needed during the system recovery phase, and not during the backup phase). <br><br>  If a backup scheme is used using offsite backup storage, then recovery testing should include a scenario when you need to request a copy from the external office and physically move it to the original office (for example, physically bring a cassette).  Remember that there are traffic jams on the roads when you check to see if you are in an SLA with an <a href="http://ashirmanov.blogspot.ru/2012/06/backup-20.html">RTO</a> . <br><br>  It must be said that the final SLA on the <a href="http://ashirmanov.blogspot.ru/2012/06/backup-20.html">RTO</a> is determined not only by you, but also by the SLA of the hardware and software manufacturers involved in the backup and recovery process.  For this reason, do not forget about your Backup-server.  If less reliable or less efficient hardware or software is installed on it than on the servers of the production network, the Backup server may let you down at the time of recovery, and you will not be able to perform a recovery SLA.  For example, if the productive network contains disks that the manufacturer changes in 1 day in the event of a failure under the premium guarantee, and the backup server has a disk with the usual warranty (repair within 45 days), then your final SLA on the productive network will be 45 days. <br><br><h5>  Modeling threats in terms of disruptions in the production network </h5><br>  It is extremely useful to simulate possible options for failure of the productive network.  The model should cover all scenarios of information recovery after failures.  For example, you cannot confine yourself to the scenario of the total disk's death, since when testing recovery, you will use recovery from a full backup plus recovery from an incremental chain each time.  But what if only one file on the disk is deleted, the latest version of which is in the last incremental copy?  In this case, the full copy is not used correctly, and you need to take only the last incremental one and extract the necessary file from it.  Such scenarios also need to be checked regularly.  Examples of threats to be modeled: <br><ul><li>  Physical full disk failure </li><li>  Deleting a single useful file </li><li>  Virus infection files </li><li>  Failure of an Active Directory domain controller, DNS server, VPN server, Exchange server, or other critical infrastructure simultaneously with a failure on the production server file </li><li>  Failure of a separate server in the main site / office and, at the same time, the disappearance of communication with the site / office backup </li><li>  Double failure - failure of the production server with subsequent failure of the backup server that performs recovery </li></ul><br>  For more information on threat modeling, you can read the post " <a href="http://ashirmanov.blogspot.ru/2013/09/Data-Protection-threat-model.html">Model of threats in data protection from failures</a> ." <br><br><h5>  How NOT to do productive network recovery testing </h5><br>  You should not perform recovery testing using intentional destruction of production network data.  For example, the head of one of the companies on Friday evening erased the contents of his hard disk of his computer and asked the IT service to restore everything by Monday morning.  There are several reasons for not doing this: <br><ul><li>  Recovery testing may fail and actual data will be irretrievably lost. </li><li>  Only one script is tested that assumes recovery from a full backup. </li><li>  Only recovery from one (last) time point is tested (that is, we know that everything works on Fridays, but we can‚Äôt say anything about the other days) </li><li>  Needless to say, there is also a human factor: IT staff will negatively perceive such a scenario of their work.  Since nobody likes to fix artificially created problems. </li></ul><br><br><h5>  Summarizing </h5><br>  It is necessary to regularly conduct data recovery testing, rather than simple backup integrity testing.  That is, to check the operability of the restored systems and the availability of data in them, in accordance with the <a href="http://ashirmanov.blogspot.ru/2012/06/backup-20.html">RPO</a> , and not just to check the checksums of the backup file data blocks.  In the case when the productive network is in a virtual environment, backup products created specifically for the virtual environment make the data verification process automated and transparent for the administrator, as they allow you to create virtual test sandbox laboratories isolated from the productive network.  An example of such a technology is <a href="http://habrahabr.ru/company/veeam/blog/162201/">Veeam SureBackup.</a> <br><br>  It is necessary to randomly select various objects for the scan, failure scenarios and time points: productive network computers, different recovery points, simulate different failures that require different types of recovery (from a full copy, from an incremental copy, recovery of a single file).  In the latter case, you need to randomly select files for testing recovery, rather than restoring the same file all the time. <br><br>  For the sake of data recovery testing, you should not unduly risk data from a productive network. <br><br><h5>  Additional materials </h5><br><ul><li>  <a href="http://habrahabr.ru/company/veeam/blog/162201/">SureBackup - automatic verification of the ability to restore data from backup</a> </li><li>  <a href="http://ashirmanov.blogspot.ru/2012/12/Backup-and-Recovery-Policy-Guidance.html">Backup and Recovery Policy Recommendations</a> </li><li>  <a href="http://ashirmanov.blogspot.ru/2013/04/veeam-vpower-virtual-lab-for-hyperv.html">Virtual Lab for Hyper-V as part of Veeam Backup &amp; Replication v7</a> </li><li>  <a href="http://go.veeam.com/wpg-backup-davis-five-fundamentals-of-modern-data-protection.html">5 fundamental principles of modern data protection from failures</a> (in English) </li><li>  <a href="http://www.quora.com/Pixar-Animation-Studios/Did-Pixar-accidentally-delete-Toy-Story-2-during-production">Pixar Animation Studios: Did Pixar accidentally delete Toy Story 2 during production?</a> </li><li>  <a href="http://thenextweb.com/media/2012/05/21/how-pixars-toy-story-2-was-deleted-twice-once-by-technology-and-again-for-its-own-good">Pixar's Toy Story 2 has been deleted</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/193568/">https://habr.com/ru/post/193568/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../193556/index.html">Comparison of the effectiveness of minimizers CSS- and JavaScript-code (September 2013)</a></li>
<li><a href="../193558/index.html">Sony SmartWatch 2 is available for pre-order.</a></li>
<li><a href="../193560/index.html">An update has been released that enhances the overall security of Windows 7</a></li>
<li><a href="../193562/index.html">Voyager 1 left the solar system (this time for sure)</a></li>
<li><a href="../193564/index.html">The first of the approved initiatives from the Russian Public Initiative website was rejected by the working group of the Russian government.</a></li>
<li><a href="../193570/index.html">We invite you to take part in a series of trainings and hackathon on Tizen!</a></li>
<li><a href="../193572/index.html">Manage any AV-technology from the phone. IR transceiver for Raspberry</a></li>
<li><a href="../193576/index.html">I want to congratulate all colleagues on the Day of the Programmer</a></li>
<li><a href="../193578/index.html">Private space is now in Russia</a></li>
<li><a href="../193580/index.html">2GIS - separately, spammers - separately</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>