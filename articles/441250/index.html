<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Quick start: Go + Apache Kafka + Redis</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, due to necessity, I looked through all the vacancy announcements of Go-developers, and half of them (at least) mention the platform for proc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Quick start: Go + Apache Kafka + Redis</h1><div class="post__text post__text-html js-mediator-article">  Recently, due to necessity, I looked through all the vacancy announcements of Go-developers, and half of them (at least) mention the platform for processing <a href="https://kafka.apache.org/intro">Apache Kafka</a> message flows and the NoSQL <a href="https://redis.io/">Redis</a> database.  Well, everyone, of course, wants the candidate to know Docker and his ilk.  All these requirements to us, who have seen the types of system engineers, seem to be somehow petty or something.  Well, in fact, how does one line differ from another?  With NoSQL databases, the situation is, of course, more diverse, but still they seem simpler than any MS SQL Server.  All this, of course, my personal, repeatedly mentioned on Habr√©, the <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D1%2584%25D1%2584%25D0%25B5%25D0%25BA%25D1%2582_%25D0%2594%25D0%25B0%25D0%25BD%25D0%25BD%25D0%25B8%25D0%25BD%25D0%25B3%25D0%25B0_%25E2%2580%2594_%25D0%259A%25D1%2580%25D1%258E%25D0%25B3%25D0%25B5%25D1%2580%25D0%25B0">Effect of Dunning - Kruger</a> . <br>  So, since all employers require, you need to study these technologies.  But starting with reading all the documentation from beginning to end is not very interesting.  In my opinion, it is more productive to read the introduction, make a working prototype, correct mistakes, run into problems, solve them.  And after all this, it is already with understanding to read the documentation, or even a separate book. <br><br><img src="https://habrastorage.org/webt/cn/q0/pd/cnq0pdshf1e8_dnfxpwrdkk46yc.jpeg"><br><br>  Those who are interested in a short time to get acquainted with the basic capabilities of these products, please read further. <br><a name="habracut"></a><br>  The training program will be engaged in the factorization of numbers.  It will consist of a generator of large numbers, a processor of numbers, a queue, column storage and a web server. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the course of development, the following design patterns will be applied: <br><br><ul><li>  Pipeline </li><li>  Spray ( <a href="">fan-out</a> ) </li><li>  Collector ( <a href="">fan-in</a> ) </li></ul><br>  The system architecture will look like this: <br><br><img src="https://habrastorage.org/webt/ns/sz/f2/nsszf2v5b5hozqdguchikxfugys.jpeg"><br><br>  In the picture, the conveyor design pattern is marked with an oval.  I will dwell on it in more detail. <br><br>  The "pipeline" template assumes that information comes in the form of a stream and is processed in stages.  Usually there is a generator (source of information) and one or several processors (information processors).  In this case, the generator will be a program on Go, placing random large numbers in a queue.  And the processor (the only one) will be the program that collects data from the queue and carries out factorization.  On pure Go, this pattern is quite easily implemented using channels (chan).  Above there is a link to my Github with an example.  Here, the role of channels will be performed by the message queue. <br><br>  Fan-In - Fan-Out templates are usually used together and in relation to Go, they mean paralleling computations with the help of Gorutin, followed by flattening the results and transferring them, for example, along the pipeline.  The link to the example is also given above.  Again, the channel is replaced by a queue, the gorutines remained in place. <br><br>  Now a few words about Apache Kafka.  Kafka is a message management system with excellent clustering tools, using transaction logs (exactly like in an RDBMS) for storing messages, and supporting both the queue model and the publisher / subscriber model.  The latter is achieved through groups of message recipients.  Each message gets only one member of the group (parallel processing), but the message will be delivered once to each group.  There can be many groups like recipients within each group. <br><br>  To work with Kafka, I will use the package "github.com/segmentio/kafka-go". <br>  Redis is a key-value column database in memory that supports the ability to permanently store data.  The main data type for keys and values ‚Äã‚Äãis strings, but there are some others.  Redis is considered one of the fastest (or most) databases in its class.  It is good to store all sorts of statistics, metrics, message flows, etc. in it. <br>  To work with Redis, I will use the "github.com/go-redis/redis" package. <br><br>  Since this article is a quick start, we will deploy both systems using Docker using ready-made images from DockerHub.  I use docker-compose on Windows 10 in container mode on a Linux VM (automatically created by the Docker VM program) with the following docker-compose.yml file: <br><br><pre><code class="xml hljs">version: '2' services: zookeeper: image: wurstmeister/zookeeper ports: - "2181:2181" kafka: image: wurstmeister/kafka:latest ports: - "9092:9092" environment: KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_CREATE_TOPICS: "Generated:1:1,Solved:1:1,Unsolved:1:1" KAFKA_DELETE_TOPIC_ENABLE: "true" volumes: - /var/run/docker.sock:/var/run/docker.sock redis: image: redis ports: - "6379:6379"</code> </pre> <br>  Save this file, go to the directory with it and execute: <br><br><pre> <code class="bash hljs">docker-compose up -d</code> </pre> <br>  Three containers should download and run: Kafka (queue), Zookeeper (configuration server for Kafka) and (Redis). <br><br>  You can make sure that the containers work with the help of the command: <br><br><pre> <code class="bash hljs">docker-compose ps</code> </pre> <br>  It must be something like: <br><br><pre> <code class="bash hljs">Name State Ports -------------------------------------------------------------------------------------- docker-compose_kafka_1 Up 0.0.0.0:9092-&gt;9092/tcp docker-compose_redis_1 Up 0.0.0.0:6379-&gt;6379/tcp docker-compose_zookeeper_1 Up 0.0.0.0:2181-&gt;2181/tcp, 22/tcp, 2888/tcp, 3888/tcp</code> </pre><br>  According to the yml file, three queues should be automatically created, you can see them with the command: <br><br><pre> <code class="bash hljs">docker <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> kafka-container_kafka_1 /opt/kafka_2.12-2.1.0/bin/kafka-topics.sh --list --zookeeper zookeeper:2181</code> </pre> <br>  There should be queues (topics in Kafka terms) generated, solved and unsolved. <br><br>  <a href="">The data generator</a> infinitely writes random numbers to the queue.  Its code is extremely simple.  You can verify that there are messages in the Generated queue using the command: <br><br><pre> <code class="bash hljs">docker <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> kafka-container_kafka_1 /opt/kafka_2.12-2.1.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic Generated --from-beginning</code> </pre><br>  Next, the <a href="">processor</a> - here you should pay attention to the parallelization of the processing of values ‚Äã‚Äãfrom the queue in the next block of code: <br><br><pre> <code class="go hljs"> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> wg sync.WaitGroup c := <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">//counter for { //       15     ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second) defer cancel() //      //    -     m, err := r.ReadMessage(ctx) if err != nil { fmt.Println("3") fmt.Println(err) break } wg.Add(1) //       10      goCtx, goCcancel := context.WithTimeout(context.Background(), 10*time.Millisecond) defer goCcancel() //     () go process(goCtx, c, &amp;wg, m) c++ } //     wg.Wait()</span></span></code> </pre> <br>  Since reading from the message queue blocks the program, I created a context.Context object with a timeout of 15 seconds.  This timeout will terminate the program if the queue is empty for a long time. <br><br>  Also, for each gorutina that factorizes the number, the maximum running time is also set.  I wanted the numbers that I managed to factor in to be written to one database.  And the numbers that could not be factorized in the allotted time - into another database. <br><br>  The benchmark was used to determine the approximate time: <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">BenchmarkFactorize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(b *testing.B)</span></span></span></span> { ch := <span class="hljs-built_in"><span class="hljs-built_in">make</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">chan</span></span> []<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> factors []<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i := <span class="hljs-number"><span class="hljs-number">1</span></span>; i &lt; bN; i++ { num := <span class="hljs-number"><span class="hljs-number">2345678901234</span></span> <span class="hljs-keyword"><span class="hljs-keyword">go</span></span> factorize(num, ch) factors = &lt;-ch b.Logf(<span class="hljs-string"><span class="hljs-string">"\n%d   %+v\n\n"</span></span>, num, factors) } }</code> </pre> <br>  Benchmarks in Go are varieties of tests and are placed in a file with tests.  Based on this measurement, the maximum number for a random number generator was selected.  On my computer, some of the numbers had time to decompose into factors, and some - not. <br><br>  Those numbers that could be decomposed were written in DB No. 0, non-decomposed numbers ‚Äî in DB No. 1. <br>  Here it must be said that in Redis there is no schema and tables in the classical sense.  By default, the DBMS contains 16 databases available to the programmer.  These bases are distinguished by their numbers - from 0 to 15. <br><br>  The time limit for gorutin in the processor was provided using the context and the select statement: <br><br><pre> <code class="go hljs"> <span class="hljs-comment"><span class="hljs-comment">//   go factorize(n, outChan) var item data select { case factors = &lt;-outChan: { fmt.Printf("\ngoroutine #%d, input: %d, factors: %+v\n", counter, n, factors) item.Number = n item.Factors = factors err = storeSolved(item) if err != nil { fmt.Println("6") log.Fatal(err) } } case &lt;-ctx.Done(): { fmt.Printf("\ngoroutine #%d, input: %d, exited on context timeout\n", counter, n) err = storeUnsolved(n) if err != nil { fmt.Println("7") log.Fatal(err) } return nil } }</span></span></code> </pre> <br>  This is another of the typical techniques of development on Go.  Its meaning is that the select statement goes through the channels and executes the code corresponding to the first active channel.  In this case, either the gorutin will produce the result in its channel, or the context channel with a timeout closes.  Instead of the context, you can use an arbitrary channel that will play the role of a manager and ensure the forced termination of the gorutin. <br><br>  The routines for writing to the database execute the command to select the desired database (0 or 1) and record pairs of the form (number - factors) for the parsed numbers or (number-number) for the non-resolved numbers. <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">storeSolved</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(item data)</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(err error)</span></span></span></span> { <span class="hljs-comment"><span class="hljs-comment">//    0 cmd := redis.NewStringCmd("select", 0) err = client.Process(cmd) b, err := json.Marshal(item.Factors) err = client.Set(strconv.Itoa(item.Number), string(b), 0).Err() return err }</span></span></code> </pre> <br>  The last part will be a <a href="">web server</a> , which will display a list of decomposed and non-decomposed numbers in the form of json.  It will have two endpoints: <br><br><pre> <code class="go hljs"> http.HandleFunc(<span class="hljs-string"><span class="hljs-string">"/solved"</span></span>, solvedHandler) http.HandleFunc(<span class="hljs-string"><span class="hljs-string">"/unsolved"</span></span>, unsolvedHandler)</code> </pre> <br>  The handler of the http request with receiving data from Redis and returning them in the form of json looks like this: <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">solvedHandler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span></span></span> { w.Header().Set(<span class="hljs-string"><span class="hljs-string">"Content-Type"</span></span>, <span class="hljs-string"><span class="hljs-string">"application/json"</span></span>) w.Header().Set(<span class="hljs-string"><span class="hljs-string">"Access-Control-Allow-Origin"</span></span>, <span class="hljs-string"><span class="hljs-string">"*"</span></span>) w.Header().Set(<span class="hljs-string"><span class="hljs-string">"Access-Control-Allow-Methods"</span></span>, <span class="hljs-string"><span class="hljs-string">"GET"</span></span>) w.Header().Set(<span class="hljs-string"><span class="hljs-string">"Access-Control-Allow-Headers"</span></span>, <span class="hljs-string"><span class="hljs-string">"Accept, Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization"</span></span>) <span class="hljs-comment"><span class="hljs-comment">//   ‚Ññ0 -   cmd := redis.NewStringCmd("select", 0) err := client.Process(cmd) if err != nil { w.WriteHeader(http.StatusInternalServerError) return } //      keys := client.Keys("*") var solved []data var item data //          for _, key := range keys.Val() { item.Key = key val, err := client.Get(key).Result() if err != nil { w.WriteHeader(http.StatusInternalServerError) return } item.Val = val solved = append(solved, item) } //    JSON err = json.NewEncoder(w).Encode(solved) if err != nil { w.WriteHeader(http.StatusInternalServerError) return } }</span></span></code> </pre> <br>  Result of the request at: <a href="http://localhost/solved">localhost / solved</a> <br><br><pre> <code class="json hljs">[{ <span class="hljs-attr"><span class="hljs-attr">"Key"</span></span>: <span class="hljs-string"><span class="hljs-string">"1604388558816"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"Val"</span></span>: <span class="hljs-string"><span class="hljs-string">"[1,2,3,227]"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"Key"</span></span>: <span class="hljs-string"><span class="hljs-string">"545232916387"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"Val"</span></span>: <span class="hljs-string"><span class="hljs-string">"[1,545232916387]"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"Key"</span></span>: <span class="hljs-string"><span class="hljs-string">"1786301239076"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"Val"</span></span>: <span class="hljs-string"><span class="hljs-string">"[1,2]"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"Key"</span></span>: <span class="hljs-string"><span class="hljs-string">"698495534061"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"Val"</span></span>: <span class="hljs-string"><span class="hljs-string">"[1,3,13,641,165331]"</span></span> }]</code> </pre> <br>  Now you can delve into the documentation and specialized literature.  Hope the article was helpful. <br><br>  I ask the experts not to be lazy and point out my mistakes. </div><p>Source: <a href="https://habr.com/ru/post/441250/">https://habr.com/ru/post/441250/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../441240/index.html">Has the evidence of the presence of new physics been lost at the Large Hadron Collider?</a></li>
<li><a href="../441242/index.html">Communication Network Monitoring Center: New State "Defender" of Runet</a></li>
<li><a href="../441244/index.html">WinRar vulnerability, unclosed for 19 years, allows to place the unpacked file in any place</a></li>
<li><a href="../441246/index.html">Qualcomm Introduces Snapdragon X55 Universal 5G Chip</a></li>
<li><a href="../441248/index.html">Russia ranked 9th in the global SSL rating, ahead of China, Denmark and Switzerland</a></li>
<li><a href="../441252/index.html">"Article about blowjob": scientists have processed 109 hours of oral sex to develop an AI that sucks dick</a></li>
<li><a href="../441254/index.html">Seminar ‚ÄúWhy we contacted Kubernetes and what we get from this,‚Äù February 28, Moscow</a></li>
<li><a href="../441258/index.html">Fully functional dynamic tracing in Linux using eBPF and bpftrace</a></li>
<li><a href="../441260/index.html">How Neural Networks Helped Graphics</a></li>
<li><a href="../441262/index.html">Simple and long tasks filter out candidates better than short and complex ones.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>