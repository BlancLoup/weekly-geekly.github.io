<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Quadcopter navigation using monocular vision</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Now for many, computer vision is not a secret behind seven locks. However, new algorithms and approaches do not cease to impress. One such area is mon...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Quadcopter navigation using monocular vision</h1><div class="post__text post__text-html js-mediator-article">  Now for many, computer vision is not a secret behind seven locks.  However, new algorithms and approaches do not cease to impress.  One such area is monocular vision, especially SLAM.  How we solved the task of navigating a quadrocopter equipped with a single camera will be discussed in this article. <br><br><img src="https://habrastorage.org/files/0c0/0b7/05f/0c00b705f38d4785962d44075c0214e2.jpg"><br><a name="habracut"></a><br>  <b>Task</b> <br><br>  The task is to move along a trajectory given by a sequence of positions in an initially unknown environment with possible obstacles.  To solve it you need to be able to: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  Build an obstacle map </li><li>  Determine the position of the quadrocopter relative to the trajectory and obstacles </li><li>  Adjust the trajectory taking into account the flyoff of obstacles </li><li>  Calculate control signals - implement the controller </li></ol><br><br>  The technical base is Parrot AR.Drone.  AR.Drone is equipped with the following devices of interest: <br><br><ol><li>  Front camera: 640x360, 30 fps, diagonal viewing angle 92 degrees </li><li>  Lower camera: used by the integrated autopilot to compensate for wind and drift in general </li><li>  Ultrasonic height sensor: operates within 0.25 - 3 m </li><li>  INS (accelerometer + gyroscope + magnetometer) + barometer: all sensors are integrated into a single system using (apparently) sensor fusion </li></ol><br><br><img src="https://habrastorage.org/files/928/d44/089/928d44089ec948b68901e77c78be68ab.png"><br><br>  In addition, a uniform odometry is formed based on the indications of the INS and the lower chamber. <br><br>  So, to build an environment map using standard AR.Drone tools, we can by and large only use the front camera.  This directly leads us to the task of monocular vision, namely the monocular SLAM. <br><br>  <b>Large Scale Direct SLAM</b> <br><br>  We can safely say that SLAM with the help of a single camera is a squeak of modern technology.  Such algorithms that have appeared in the last few years can be counted on the fingers of a careless milling operator - these are ORB SLAM, LSD (Large Scale Direct) SLAM (and its predecessor SVO (Semi-direct Visual Odometry)), PTAM (Parallel Tracking And Mapping).  Even fewer algorithms that build more or less dense (semi-dense) environment maps.  Of the most advanced algorithms, only LSD SLAM issues such cards: <br><br><img src="https://habrastorage.org/files/e0a/384/597/e0a384597fe34ce888833cb34c4c84e4.png"><br><br>  In a nutshell, LSD SLAM works as follows.  Three procedures work in parallel: tracking, mapping and map optimization.  The tracking component estimates the position of each new frame relative to the current keyframe.  The map building component processes frames with a known position, either clearing the frame map in a cunning way or creating a new keyframe.  The map optimization component searches for cycles in the keyframe graph and eliminates the effect of floating scale.  More information about the algorithm can be in the <a href="http://vision.in.tum.de/_media/spezial/bib/engel14eccv.pdf">article developers</a> . <br><br>  For stable and efficient operation of the algorithm (these requirements apply to any monocular SLAM algorithm) the following is necessary: <br><ol><li>  The most accurate calibration of the camera and the subsequent rectification of the image.  The accuracy of calibration and rectification, as well as the distortion model used, directly affects the quality of the resulting cards. </li><li>  Wide angle camera view.  For more or less reliable operation, cameras with an FOV of more than 80-90 degrees are needed. </li><li>  A sufficient number of frames per second.  With an FOV of 90 degrees, the number of frames per second should not be less than 30 (better - more). </li><li>  Camera movements should not contain turns without moving.  Such a movement breaks the algorithm. </li></ol><br>  Points 2 and 3 are related to each other with a simple consideration: to calculate the movement between two adjacent frames, the images on these frames must overlap to a sufficient degree.  Accordingly, the faster the camera moves, the greater must be the angle of view or frame rate so that the connection between frames is not lost. <br><br>  If you comply with these requirements, you can get very good quality cards, which can be seen by watching the video from the creators of LSD SLAM: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/GnuQzP3gty4%3Ffeature%3Doembed&amp;xid=17259,15700023,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhh4eVcaqDhnqRFuEDyPEqvLVk6jXQ" frameborder="0" allowfullscreen=""></iframe><br><br>  Impressive, isn't it?  However, even if you have reached such a quality of cards, another trouble awaits you: not a single monocular SLAM algorithm fundamentally can estimate the absolute scale of the maps obtained and, therefore, localization.  Therefore, it is necessary to resort to some tricks and find an external data source, either helping to determine the size of map objects, or evaluating the absolute values ‚Äã‚Äãof camera movements.  The first method is limited only by your imagination: you can put an object of a known size in the field of view of the camera and then compare it with the scales of similar parts of the map, you can initialize the algorithm in a previously known situation, and so on.  The second method is fairly easy to apply, using, for example, the altimeter data, which we have done. <br><br>  To estimate the scale, we used data on movements along the vertical axis, obtained from two sources: from the LSD SLAM algorithm and the AR.Drone altimeter.  The ratio of these values ‚Äã‚Äãis the scale of the map and the localization of the monocular system.  To eliminate random disturbances, we filtered the resulting scale value with a low-pass filter. <br><br>  <b>Obstacle avoidance and trajectory correction</b> <br><br>  LSD SLAM stores the environment map in the form of a graph of key frames with partial depth maps attached to them.  Combining all the nodes of the graph, we obtain a map of a known part of the environment in the form of a cloud of points.  However, this is not an obstacle map!  To get a dense (dense) obstacle map, we used the Octomap library, which builds an obstacle map in the form of an octree based on a point cloud. <br><br>  We used the FCL (Flexible Collision Library) + OMPL (Open Motion Planning Library) library stack to check collisions and adjust trajectories.  After the map is updated, the collision trajectory with obstacles test is started, in case of collisions, the trajectory segment is recalculated by the scheduler (we used BIT *, but there may be options). <br><br>  <b>Controller</b> <br><br>  The controller was in the end quite simple, based on the PID controller.  This was enough to follow the trajectory.  The only thing that had to be added was the speed limit of the camera rotation to maintain the stability of SLAM. <br><br><img src="https://habrastorage.org/files/b46/23e/31b/b4623e31ba3a4333b2d6008383a1a8ca.png"><br><br>  <b>Platform and general solution scheme</b> <br><br>  As a platform for the entire solution, we used ROS.  The platform offers all the necessary infrastructure for the rapid development of parallel components (nodes in ROS terminology), communications between them, monitoring, dynamic tuning, an excellent Gazebo simulator, and much more, facilitating the development of serious robotic solutions.  Although the stability of the individual components of the system still leaves much to be desired, and it‚Äôs not worthwhile to use it in the production of a responsible project. <br><br>  The general scheme of the solution was like this: <br><br><img src="https://habrastorage.org/files/53d/b9f/ff8/53db9fff8e264edab899c23755b778ef.png"><br><br>  <b>findings</b> <br><br>  Barrel of honey: <br><ul><li>  monocular SLAM is quite possible to try; </li><li>  ROS is a very convenient platform, at least for development and testing, implementation of cool robot projects becomes simpler and simpler. </li></ul><br>  A spoon of tar: <br><ul><li>  making monocular SLAM work is a very, very tricky business, especially regarding the task of calibrating the camera. </li></ul><br>  <b>References:</b> <br><br>  The LSD SLAM page on the developer's site: <a href="http://vision.in.tum.de/research/vslam/lsdslam">vision.in.tum.de/research/vslam/lsdslam</a> <br>  Open Motion Planning Library: <a href="http://ompl.kavrakilab.org/">ompl.kavrakilab.org</a> <br>  Flexible Collision Library: <a href="http://github.com/flexible-collision-library/fcl">github.com/flexible-collision-library/fcl</a> <br>  Octomap: <a href="http://octomap.github.io/">octomap.github.io</a> </div><p>Source: <a href="https://habr.com/ru/post/276595/">https://habr.com/ru/post/276595/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../276583/index.html">New leader in price-performance among storage systems?</a></li>
<li><a href="../276585/index.html">About using React with the canvas element</a></li>
<li><a href="../276587/index.html">Analysis of the current situation in the Russian BIM market in the field of civil engineering</a></li>
<li><a href="../276589/index.html">Introduction to IL2CPP</a></li>
<li><a href="../276593/index.html">Creating a program architecture or how to design a stool</a></li>
<li><a href="../276597/index.html">Binding Request Traker 4.x on Ubuntu to ldap using the example of ActiveDirectory</a></li>
<li><a href="../276599/index.html">What brings the idea (Objective-C) - target-action on the blocks and a lot of runtime</a></li>
<li><a href="../276603/index.html">Evgeny Kaspersky spoke about cybercrime at Innopolis University [video]</a></li>
<li><a href="../276607/index.html">Performance and memory profiling from multiple viewing angles</a></li>
<li><a href="../276609/index.html">Package Manager opkg. Offline installation of packages in the root file system image</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>