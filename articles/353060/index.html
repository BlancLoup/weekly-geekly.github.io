<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Application of convolutional neural networks for NLP problems</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When we hear about convolutional neural networks (CNN), we usually think about computer vision. CNN underlay the breakthroughs in image classification...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Application of convolutional neural networks for NLP problems</h1><div class="post__text post__text-html js-mediator-article">  When we hear about convolutional neural networks (CNN), we usually think about computer vision.  CNN underlay the breakthroughs in image classification - the famous AlexNet, the winner of the ImageNet competition in 2012, from which the boom of interest in this topic began.  Since then, convolutional networks have achieved great success in image recognition, due to the fact that they are designed like the visual cortex of the brain - that is, they can concentrate on a small area and highlight important features in it.  But as it turned out, CNN is good not only for this, but also for Natural Language Processing (NLP) tasks.  Moreover, in a recent article [1] from a team of authors from Intel and Carnegie-Mellon University, it is argued that they are suitable for this even better than the RNN, who have reigned supreme in the region in recent years. <br><br><h3>  Convolutional neural networks </h3><br>  First, a little theory.  What is convolution?  We will not dwell on this in detail, since a ton of materials has already been written about this, but still it‚Äôs worth a quick run.  There is a beautiful visualization from Stanford that allows you to grasp the essence: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/642/8cf/505/6428cf505ac1e9e1cf462e1ec8fe9a68.gif" alt="image"><br>  <a href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution"><i>A source</i></a> <br><a name="habracut"></a><br>  It is necessary to introduce basic concepts, so that later we understand each other.  A window that goes through a large matrix is ‚Äã‚Äãcalled a filter (in the English version of kernel, filter or feature detector, so you can find translations and tracing of these terms do not worry, it's all the same).  The filter is superimposed on a section of a large matrix and each value is multiplied with its corresponding filter value (the red numbers are lower and to the right of the black digits of the main matrix).  Then everything turned out is added up and the output (‚Äúfiltered‚Äù) value is obtained. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The window goes through a large matrix with some step, which in English is called stride.  This step is horizontal and vertical (although the latter will not be useful to us). <br><br>  It remains to introduce an important concept of the channel.  Channels in images are base colors known to many, for example, if we are talking about a simple and common RGB color coding scheme (Red - red, Green - green, Blue - blue), then it is assumed that of these three basic colors, by mixing them we can get any color.  The key word here is ‚Äúblending‚Äù, all three basic colors exist simultaneously, and can be obtained from, for example, the white light of the sun using a filter of the desired color (do you feel the terminology begins to make sense?). <br><br><img src="https://habrastorage.org/webt/hi/vq/0m/hivq0mqnx0cdnljwcndgxcia200.png" alt="image"><br><br>  And so it turns out that we have an image, it has channels and our filter walks along it with the necessary step.  It remains to understand - what to do with these channels?  With these channels we do the following - each filter (that is, a matrix of small size) is superimposed on the original matrix simultaneously on all three channels.  The results are simply summarized (which is logical, if you look at it, in the end, channels are our way of working with a continuous physical spectrum of light). <br><br>  It is necessary to mention one more detail, without which further understanding will be difficult: I will reveal to you a terrible secret, there are much more filters in convolution networks.  What does so much more mean?  This means that we have n filters that do the same job.  They walk with a window on the matrix and are considering something.  It would seem, why do one job twice?  One and more than one - due to the different initialization of the filter matrices, in the process of learning they begin to pay attention to different details.  For example, one filter looks at the line, and the other at a particular color. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c29/a52/fa1/c29a52fa109192d2f6df1869bd78f8b0.jpg" alt="image"><br>  <i>Source: cs231n</i> <br><br>  This is a visualization of different filters of the same layer of the same network.  See that they look at completely different features of the image? <br><br>  All we are armed with terminology in order to move on.  In parallel with the terminology, we figured out how the convolutional layer works.  It is the base for convolutional neural networks.  There is another base layer for CNN - this is the so-called pooling layer. <br><br>  The easiest way to explain it is by the example of max-pooling.  So, imagine that in a convolutional layer already known to you, the filter matrix is ‚Äã‚Äãfixed and is single (that is, multiplication by it does not affect the input data).  And instead of summing all the results of multiplication (input data according to our condition), we simply select the maximal element.  That is, we will select the pixel from the entire window with the highest intensity.  This is max-pooling.  Of course, instead of functions, the maximum may be another arithmetic (or even more complex) function. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e38/ee6/f95/e38ee6f954b7c7cea8f768c77eaff301.png" alt="image"><br>  <i>Source: cs231n</i> <br><br>  As a further reading on this subject, I recommend the <a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">post of</a> Chris Olah (Chris Olah). <br><br>  All of the above is good, but without nonlinearity, neural networks will not have the universal approximant property so necessary for us.  Accordingly, I must say a few words about them.  In recurrent and fully connected networks, balls are governed by such nonlinearities as sigmoid and hyperbolic tangent. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7de/85e/64f/7de85e64fdebcf9bdad105698bd0d536.png" alt="image"><br>  <a href="http://times.cs.uiuc.edu/course/510f17/ppt/deep-learning.pptx"><i>A source</i></a> <br><br>  These are good non-linear smooth functions, but they still require significant calculations compared to the one that rules the ball in the CNN: ReLU - Rectified Linear Unit.  In Russian, ReLU is called a linear filter (are you not tired of using the word filter?).  This is the simplest non-linear function, and is also not smooth.  But on the other hand, it is calculated for one elementary operation, for which developers of computing frameworks love it very much. <br>  All right, we have already discussed convolutional neural networks, how vision and all that is arranged.  But where about the lyrics, or have I shamelessly deceived you?  No, I did not deceive you. <br><br><h3>  Apply convolutions to texts </h3><br><img src="https://habrastorage.org/webt/sy/26/qz/sy26qzlrsztyhgpnv9fepwpna0k.png"><br><br>  This picture almost completely explains how we work with text using CNN.  Unclear?  Let's figure it out.  First of all, the question is - where do we get the matrix for work from?  CNN works with matrices, doesn't it?  Here we need to go back a little and remember what embedding is (there is a <a href="https://habrahabr.ru/company/ods/blog/329410/">separate article</a> on this subject). <br><br>  In short, embedding is the mapping of a point in some multidimensional space to an object, in our case, a word.  An example of perhaps the most famous such embedding is Word2Vec.  By the way, it has semantic properties, like <code>word2vec(‚Äúking‚Äù) - word2vec(‚Äúman‚Äù) + word2vec(‚Äúwoman‚Äù) ~= word2vec(‚Äúqueen‚Äù)</code> .  So, we take embedding for each word in our text and just put all the vectors in a row, getting the desired matrix. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b35/279/e2a/b35279e2ab1e2393963e6a434086eb2e.png" alt="image"><br><br>  Now the next step, the matrix is ‚Äã‚Äãgood, and it seems to even look like a picture - the same two dimensions.  Or not?  Wait, we have more channels in the picture.  It turns out that in the matrix of the picture we have three dimensions - width, height and channels.  And here?  And here we only have the width (the matrix for the convenience of displaying is transposed in the header section of the matrix section) is the sequence of tokens in the sentence.  And - no, not height, but channels.  Why channels?  Because embedding words only makes sense completely, every single measurement of it will not tell us anything. <br><br>  Well, we figured out the matrix, now more about convolutions.  It turns out that the convolution we can walk only on one axis - in width.  Therefore, in order to distinguish it from standard convolution, it is called one-dimensional (1D convolution). <br><br>  And now almost everything is clear, except for the mysterious Max Over Time Pooling.  What is this beast?  This is the max-pooling already discussed above, only applied to the entire sequence at once (that is, the width of its window is equal to the entire width of the matrix). <br><br><h3>  Examples of using convolutional neural networks for texts </h3><br><br><img src="https://habrastorage.org/webt/bx/yx/yt/bxyxytwaytk-pjk-1ogb9fkpjrc.png"><br>  <s>Picture to attract attention.</s>  In fact, an illustration from the work [4]. <br><br>  Convolutional neural networks are good where you need to see a piece or the entire sequence and draw some conclusion from this.  That is, these are tasks, for example, spam detection, tonality analysis, or extraction of named entities.  Parsing articles can be difficult for you, if you have just met neural networks, you can skip this section. <br><br>  In [2], Yun Kim (CNY) shows that CNN is good for classifying sentences on different datasets.  The picture used to illustrate the section above is just from his work.  It works with Word2Vec, but you can work directly with characters. <br><br>  In [3], the authors classify texts based directly on letters, learning to embedding them for them in the learning process.  On large datasets, they showed even better results than word networks. <br><br>  Convolutional neural networks have a significant drawback compared to RNN - they can only work with a fixed-size input (since the dimensions of the matrices in the network cannot change during operation).  But the authors of the above work [1] were able to solve this problem.  So now this restriction has been removed. <br><br>  In [4], authors classify texts based directly on symbols.  They used a set of 70 characters to represent each character as a one-hot vector and set the fixed text length to 1014 characters.  Thus, the text is represented by a 70x1014 binary matrix.  The network has no idea about the words and sees them as combinations of characters, and information about the semantic proximity of words is not provided to the network, as in the cases of pre-trained Word2Vec vectors.  The network consists of 1d conv, max-pooling layers and two fully-connected layers with dropout.  On large datasets, they showed even better results than word networks.  In addition, this approach significantly simplifies the preprocessing step that may contribute to its use on mobile devices. <br><br>  In another paper [5], the authors are trying to improve the use of CNN in NLP using developments from computer vision.  The main trends in computer vision recently is the increase in the depth of the network and the addition of so-called skip-links (eg, ResNet) that connect layers that are not adjacent to each other.  The authors showed that the same principles apply to NLP, they built CNN on the basis of symbols with 16-dimensional embedding, which they learned together with the network.  They trained the networks of different depths (9, 17, 29 and 49 conv layers) and experimented with skip-links to find out how they affect the result.  They concluded that increasing the depth of the network improves the results on selected data sets, but the performance of too deep networks (49 layers) is lower than moderately deep (29 layers).  The use of skip-links led to an improvement in the results of the network of 49 layers, but it still did not surpass the network indicator with 29 layers. <br><br>  Another important feature of CNN in computer vision is the possibility of using weights of a network trained on one large dataset (a typical example is ImageNet) in other tasks of computer vision.  In [6], the authors investigate the applicability of these principles in the problem of text classification using CNN with word embedding.  They study how the transfer of certain parts of the network (Embedding, conv layers and fully-connected layers) affects the classification results on selected datasets.  They come to the conclusion that in NLP tasks the semantic proximity of the source on which the network had previously been trained plays an important role, that is, the network trained on movie reviews will work well on another dataset with movie reviews.  In addition, they note that using the same embedding for words increases the success of the transfer and recommends not freezing the layers, but noting them on the target date. <br><br><h3>  Practical example </h3><br>  Let's take a practical look at how to do a sentiment analysis on CNN.  We analyzed a similar example in the <a href="https://habrahabr.ru/company/ods/blog/325432/">article about Keras</a> , so for all the details I refer you to her, and here only the key features for understanding will be considered. <br><br>  First of all, you need the concept of Sequence from Keras.  Actually, this is the sequence in the form convenient for Keras: <br><br><pre> <code class="python hljs">x_train = tokenizer.texts_to_sequences(df_train[<span class="hljs-string"><span class="hljs-string">"text"</span></span>]) x_test = tokenizer.texts_to_sequences(df_test[<span class="hljs-string"><span class="hljs-string">"text"</span></span>]) x_val = tokenizer.texts_to_sequences(df_val[<span class="hljs-string"><span class="hljs-string">"text"</span></span>])</code> </pre> <br>  Here, <code>text_to_sequences</code> is a function that translates text into a sequence of integers by a) tokenization, that is, splitting a string into tokens and b) replacing each token with its number in the dictionary.  (The dictionary in this example was compiled in advance. The code for its compilation is in a full notebook.) <br><br>  Further, the resulting sequences need to be aligned - as we remember, CNN does not know how to work with variable text lengths yet, this has not yet reached industrial application. <br><br><pre> <code class="python hljs">x_train = pad_sequences(x_train, maxlen=max_len) x_test = pad_sequences(x_test, maxlen=max_len) x_val = pad_sequences(x_val, maxlen=max_len)</code> </pre> <br>  After that, all sequences will either be truncated or padded with zeros to the length <code>max_len</code> . <br><br>  And now, actually the most important, the code of our model: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Embedding(input_dim=max_words, output_dim=<span class="hljs-number"><span class="hljs-number">128</span></span>, input_length=max_len)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">"relu"</span></span>)) model.add(GlobalMaxPool1D()) model.add(Dense(num_classes)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>))</code> </pre> <br>  The first layer is <code>Embedding</code> , which translates whole numbers (in fact, one-hot vectors, in which the unit space corresponds to the number of a word in the dictionary) into dense vectors.  In our example, the size of the embedding space (the length of the vector) is 128, the number of words in the <code>max_words</code> dictionary, and the number of words in the sequence are <code>max_len</code> , as we already know from the code above. <br><br>  After embedding, there is a one-dimensional convolutional <code>Conv1D</code> layer.  The number of filters in it is 128, and the width of the window for filters is 3. Activation must be clear - this is a favorite ReLU. <br><br>  After the ReLU comes the <code>GlobalMaxPool1D</code> layer.  ‚ÄúGlobal‚Äù in this case means that it is taken along the entire length of the incoming sequence, that is, it is nothing but the above-mentioned Max Over Time Pooling.  By the way, why is it called Over Time?  Because the sequence of words we have has a natural order, some words come to us earlier in the stream of speech / text, that is, earlier in time. <br><br>  Here is the model we got in the end: <br><br><img src="https://habrastorage.org/webt/ni/p7/bd/nip7bdqcgaua_un7udx5spmaipy.png"><br><br>  An interesting feature can be seen in the picture: after the convolutional layer, the sequence length was 38 instead of 40. Why is that?  Because you and I did not talk and did not use padding, a technique that allows you to virtually ‚Äúadd‚Äù data to the original matrix so that the light can go beyond it.  And without this, a convolution of length 3 with a step equal to 1 can make only 38 steps in a matrix 40 wide. <br><br>  Well, what did we get in the end?  In my tests, this classifier gave a quality of 0.57, which, of course, a little.  But you can easily improve my result if you make a little effort.  <a href="https://github.com/madrugado/keras-tutorial/blob/master/CNN_solution.ipynb">Go for it</a> . <br><br>  PS: Thanks for the help in writing this article to Evgeny Vasilyev <a href="https://habr.com/users/somesnm/" class="user_link">somesnm</a> and Bulat Suleimanov <a href="https://habr.com/users/khansuleyman/" class="user_link">khansuleyman</a> . <br><br><h4>  Literature </h4><br>  [1] Bai, S., Kolter, JZ, &amp; Koltun, V. (2018).  Generic Convolutional and Recurrent Networks for Sequence Modeling.  <a href="https://arxiv.org/abs/1803.01271">arxiv.org/abs/1803.01271</a> <br>  [2] Kim, Y. (2014).  Convolutional Neural Networks for Sentence Classification.  <a href="http://www.aclweb.org/anthology/D14-1181">Proceedings of the 2014 Conference on Empirical Methods of Natural Language Processing (EMNLP 2014), 1746‚Äì1751.</a> <br>  [3] Heigold, G., Neumann, G., &amp; van Genabith, J. (2016).  Neural morphological tagging from morphologically rich languages.  <a href="https://arxiv.org/abs/1606.06640">arxiv.org/abs/1606.06640</a> <br>  [4] Character-level Convolutional Networks for Text Classification.  Xiang Zhang, Junbo Zhao, Yann LeCun <a href="https://arxiv.org/abs/1509.01626">arxiv.org/abs/1509.01626</a> <br>  [5] Very Deep Convolutional Networks for Text Classification.  A Conneau, H Schwenk, L Barrault, Y Lecun <a href="https://arxiv.org/abs/1606.01781">arxiv.org/abs/1606.01781</a> <br>  [6] A Practitioners' Guide to Transfer Learning for Text Classification using Convolutional Neural Networks.  T Semwal, G Mathur, P Yenigalla, SB Nair <a href="https://arxiv.org/abs/1801.06480">arxiv.org/abs/1801.06480</a> </div><p>Source: <a href="https://habr.com/ru/post/353060/">https://habr.com/ru/post/353060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../353050/index.html">Data Analysis Using Python</a></li>
<li><a href="../353052/index.html">Android Lifecycle-aware Architecture Components</a></li>
<li><a href="../353054/index.html">Learn OpenGL. Lesson 5.1 - Advanced Lighting. Model Blinna-Fong</a></li>
<li><a href="../353056/index.html">PHP Digest 128 (March 25 - April 8, 2018)</a></li>
<li><a href="../353058/index.html">Is there any powder in the old dog? Hackathon Radio Canada 2018 (Part Three - Start! Attention! March!)</a></li>
<li><a href="../353064/index.html">Kubernetes 1.10: we stabilize data storage, security and networking</a></li>
<li><a href="../353066/index.html">ITSM literacy program: 7 ways to diagnose the causes of IT incidents and problems</a></li>
<li><a href="../353068/index.html">Sending mail from the Docker container (postfix and sasl dokerization)</a></li>
<li><a href="../353070/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ309 (April 2 - 8, 2018)</a></li>
<li><a href="../353072/index.html">Developing native extensions for Node.js</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>