<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Introduction to Neural Network Architectures</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Grigory Sapunov (Intento) 
 My name is Grigory Sapunov, I am a service company of Intento. I have been involved in neural networks for a long time and...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Introduction to Neural Network Architectures</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/3c1/8df/ad3/3c18dfad31738c1b68a9c612f338d468.png"><br><br><h2>  Grigory Sapunov (Intento) </h2><br>  My name is Grigory Sapunov, I am a service company of Intento.  I have been involved in neural networks for a long time and machine learning, in particular, has been building neural network recognizers of road signs and numbers.  I participate in the project on neural network stylization of images, I help many companies. <br><br>  Let's get straight to the point.  My goal is to give you a basic terminology and understanding of what is happening in this area, from which building blocks of neural networks, and how to use it. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The outline of the report is as follows.  First, a small introduction about what a <b>neuron is</b> , a <b>neural network</b> , a <b>deep neural network</b> , so that we can communicate in the same language. <br><br>  Then I will talk about important trends that are happening in this area.  Then we dive into the <b>architecture of neural networks</b> , consider the <b>three main classes</b> .  This will be the most informative part. <br><br>  After that, we will look at 2 relatively advanced topics and end with a small <b>overview of the frameworks and libraries</b> for working with neural networks. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/XY5AczPW7V4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  At the conference, Natalya Efremova from NTechLab spoke about practical cases.  I will tell you how neural networks are built inside, what kind of building blocks they consist of inside. <br><br><h3>  Summary </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/719/ef8/40a/719ef840a52f666efe25a773d487359e.png"><br><br><h3>  Recap: neuron, neural network, deep neural network </h3><br>  Brief reminder <br><br><img src="https://habrastorage.org/getpro/habr/post_images/355/148/987/355148987ed68fe7592f074b1e746625.png"><br><br>  An artificial neuron is a very distant resemblance of a biological neuron. <br><br>  What is an artificial neuron?  This is a simple feature actually.  She has entrances.  Each input is multiplied by some weights, then everything is summed up, driven through some non-linear function, the result is output - all, this is one neuron. <br><br>  If you are familiar with logistic regression, by which we mean the non-linear function SIGMOID, then one neuron is a complete analog of logistic regression, a simple linear classifier. <br><br>  In fact, there are many different activation functions, including the hyperbolic tangent (TANH), SIGMOID, and RELU shown in the figure. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8f8/5a4/771/8f85a4771f737614646b5bcd5aaf9ee6.png"><br><br>  In reality, everything is much more complicated.  This topic will not concern. <br><br>  I gave a very basic idea of ‚Äã‚Äãan artificial neuron, as a kind of biological neuron. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7d8/88d/66c/7d888d66cda6787af984befdc025ef78.png"><br><br>  An artificial neural network is a way to assemble neurons into a network so that it performs a specific task, for example, a classification task.  Neurons are collected in layers.  There is an input layer where the input signal is fed, there is an output layer, from where the result of the neural network is taken, and between them there are hidden layers.  There may be 1, 2, 3, a lot.  If the hidden layers are greater than 1, the neural network is considered deep, if 1, then shallow. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c1/8df/ad3/3c18dfad31738c1b68a9c612f338d468.png"><br><br>  There is a huge variety of different architectures, the main ones we will look at.  But keep in mind that a lot of them.  If interested, then follow the <a href="http://www.asimovinstitute.org/neural-network-zoo/">link</a> - look, read. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/596/9d4/395/5969d4395ea17419793401ec4183b4a6.png"><br><br>  Another useful thing to know when discussing neural networks.  I have already described how one neuron works: how each input multiplies by weights, by coefficients, sums up, multiplies by non-linearity.  This is, let's say, the production mode of the neuron, that is, inference, as it works in the already trained form. <br><br>  There is a completely different task - to train a neuron.  Training is to find these correct weights.  Training is built on the simple idea that if we at the output of a neuron know what the answer should be, and we know how it turned out, we become aware of this difference, an error.  This error can be sent back to all inputs of the neuron and understand which input influenced this error to a great extent, and accordingly, adjust the weight on this input so that the error is reduced. <br><br>  This is the main idea behind Backpropagation, an error back-propagation algorithm.  This process can be driven throughout the network and for each neuron to find how its weight can be modified.  For this you need to take derivatives, but in principle, this is not required lately.  All packages for working with neural networks are automatically differentiated.  If 2 years ago it was necessary to manually write complex derivatives for tricky layers, now the packages do it themselves. <br><br><h3>  Recap: important trends </h3><br>  What is happening with the quality and complexity of models <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f9d/5c2/aa8/f9d5c2aa8367586fc0c9ad1571a45473.png"><br><br>  First, the accuracy of neural networks is growing, and is growing very strongly.  There are already several examples when neural networks come to some area and force out the whole classical algorithm.  So it was in image processing and speech recognition, it will happen in different areas.  That is, there are neural networks that greatly reduce the error. <br><br>  Deep Learning is highlighted in purple in the diagram, the classic computer vision algorithm is highlighted in blue.  It is seen that Deep Learning has appeared, the error has decreased and continues to decrease further.  That is why Deep Learning completely supersedes all, conditionally, classical algorithms. <br><br>  Another important milestone is that we are beginning to overtake the quality of a person.  At the ImageNet competition, this happened for the first time in 2015.  But in fact, neural network systems that are superior to humans in quality have appeared earlier.  The first documented distinct case is 2011, when a system was built that recognized German road signs and did it 2 times better than a person. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9a4/44d/3cc/9a444d3ccb09d4a3cb088bfa74feda49.png"><br><br>  The second important trend - the complexity of neural networks is growing.  In terms of depth, depth increases.  If the winner of 2012 on ImageNet is the AlexNet network - there were less than 10 layers, then in 2014 there were already more than 20, in 2015 - under 150. This year, it seems, already beyond 200. What will happen next is unclear, perhaps will be even more. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86a/596/ec3/86a596ec3fa0b9da421e871813c44895.png"><br><br>  <a href="http://cs.unc.edu/~wliu/papers/GoogLeNet.pdf">http://cs.unc.edu/~wliu/papers/GoogLeNet.pdf</a> <br><br>  In addition to the growing depth, the architectural complexity grows as well.  Instead of simply joining the layers one by one, they begin to branch, blocks and structure appear.  In general, the architectural complexity is also growing. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dbe/445/439/dbe4454395cda02e033dba012a4d40be.png"><br><br>  <a href="https://culurciello.github.io/tech/2016/06/04/nets.html">https://culurciello.github.io/tech/2016/06/04/nets.html</a> <br><br>  This is a graph of the accuracy of various neural networks.  Here is the time it takes to execute, on the miscalculation of this network, that is, some computational load.  The size of the circle is the number of parameters that are described by the neural network.  It is interesting to compare the classic network AlexNet - the winner of 2012 and later networks.  They are better in accuracy, but usually contain fewer parameters.  This is also an important trend that neural networks complicate very cleverly.  That is, the architecture changes so that even though the number of layers is 150, the total number of parameters is less than in the 6-7-layer network, which was in 2012.  The architecture is somehow complicated in a very interesting way. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ced/7e7/e63/ced7e7e63e27edc26f9c98f2eb5cba55.png"><br><br>  Another trend is data growth.  In 1998 for training convolutional <br>  the neural network that recognized the handwritten checks was used 10 <sup>7</sup> pixels, in 2012 (IMAGENET) - 10 <sup>14</sup> . <br><br>  7 orders in 14 years is a crazy difference and a huge shift! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/396/a3b/7a6/396a3b7a6a528ef1ad74851257ff6663.png"><br><br>  At the same time, the number of transits on the processor is also growing, computing power is increasing - Moore's law is in effect.  Over these 14 years, processors have become conditionally 1000 times faster.  This is illustrated by the example of GPUs, which now dominate the area of ‚Äã‚ÄãDeep Learning.  Almost everything counts on graphics accelerators. <br><br>  NVIDIA has been redeployed from gaming to actually a company for artificial intelligence.  Its exhibitors left far behind Intel exhibitors, which do not look at all against this background. <br><br>  This is a picture of 2013, when the top-end video card was 4.5 TFLOPS.  Now the new TITAN X is already 11 TFLOPS.  In general, the exhibitor continues! <br><br>  In fact, we can expect that FPGAs will appear in the near future, which will partially press the GPU, and maybe even neuromorphic processors will appear over time.  Watch this - there is also a lot of interesting things happening. <br><br><h3>  Architecture neural networks.  Direct propagation neural networks </h3><br>  Fully Connected Feed-Forward Neural Networks, FNN <br><br>  The first classical architecture is fully connected direct propagation neural networks, or Fully Connected Feed-Forward Neural Network, FNN. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/442/b7c/bb2/442b7cbb29128bd5f02c8cdcc78eb655.png"><br><br>  Multi-layer Perceptron is generally a classic of neural networks.  That picture of neural networks that you saw, this is it - a multilayered fully connected network.  Fully connected - this means that each neuron is connected with all the neurons of the previous layer.  A good network works, it is suitable for classification, many classification problems are successfully solved. <br><br>  However, she has 2 problems: <br><br><ul><li>  <strong>Many parameters</strong> </li></ul><br>  For example, if you take a neural network of 3 hidden layers that needs to process 100 * 100 ps pictures, this means that there will be 10,000 ps at the input, and they are turned into 3 layers.  In general, to be honest with all the parameters, such a network will have about a million.  It really is a lot.  To train a neural network with a million parameters, you need a lot of training examples that are not always there.  In fact, there are examples now, but they didn‚Äôt exist before - therefore, in particular, the networks could not train properly. <br><br>  In addition, the network, which has many parameters, has an additional tendency to retrain.  It can be sharpened by something that in reality does not exist: some noise Data Set.  Even if, in the end, the network remembers examples, but on those that it did not see, then it will not be able to be used normally. <br><br>  Plus there is another problem called: <br><br><ul><li>  <strong>Fading gradients</strong> </li></ul><br>  Remember that story about Backpropagation, when an error from the outputs is sent to the input, distributed to all weights and sent further along the network?  Further, these derivatives - that is, the gradient (error derivative) - are run back through the neural network.  When there are many layers in a neural network, a very, very small part of this gradient can remain at the very end.  In this case, the input weight will be almost impossible to change because this gradient is practically ‚Äúdead‚Äù, it is not there. <br><br>  This is also a problem, due to which deep neural networks are also difficult to train.  We will return to this subject further, especially on recurrent networks. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c38/d28/cd6/c38d28cd634b4ad3e0bfb6935ab10a13.png"><br><br>  There are various variations of FNN networks.  For example, a very interesting variation of the Auto ENCODER.  This is a network of direct distribution with the so-called bottleneck in the middle.  This is a very small layer, say, of only 10 neurons. <br><br>  What are the advantages of such a neural network? <br><br>  The purpose of this neural network is to take some kind of input, drive it through itself and generate the same input at the output, that is, so that they match.  What's the point?  If we can train such a network that takes input, drives it through itself and generates exactly the same output, it means that these 10 neurons in the middle are enough to describe this input.  That is, you can greatly reduce the space, reduce the amount of data, economically encode any input data in the new terms of 10 vectors. <br><br>  It is convenient and it works.  Such networks can help you, for example, reduce the dimension of your task or find some interesting features that you can use. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed7/0c7/dec/ed70c7deca8bdee99ef2e4dfd29bfc0d.png"><br><br>  There is another interesting model of RBM.  I wrote it in the FNN variation, but in reality this is not true.  Firstly, it is not deep, and secondly, it is not Feed-Forward.  But it is often associated with FNN networks. <br><br>  What it is? <br><br>  This is a shallow model (on the slide it is drawn in a corner), which has an entrance and there is some hidden layer.  You give a signal to the input and try to train the hidden layer so that it generates this input. <br><br>  This is a generative model.  If you have trained it, then you can generate analogs of your input signals, but slightly different.  It is stochastic, that is, every time it will generate something slightly different.  If, for example, you have trained such a model to generate handwritten ones, then it will accumulate them a number of slightly different ones. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d5b/dba/f57/d5bdbaf5717f1b555ac248fbb5e606c1.png"><br><br>  What are good RBM - the fact that they can be used to train deep networks.  There is such a term - Deep Belief Networks (DBN) - in fact, this is a way to train deep networks, when 2 lower layers of a deep network are taken separately, input is given and RBM is trained on these first two layers.  After that, these weights are recorded.  Next, the second layer is taken, considered as a separate RBM and is also being trained.  And so throughout the network.  Then these RBMs are joined, combined into one neural network.  It turns out a deep neural network, which should be. <br><br>  But now there is a huge advantage - if you had previously taught it simply from some random (random) state, now it is not random ‚Äî the network is trained to restore or generate data from the previous layer.  That is, her weight is reasonable, and in practice this leads to the fact that such neural networks are already quite well-trained.  Then you can slightly train them with some examples, and the quality of such a network will be good. <br><br>  Plus there is an additional advantage.  When you use RBM, you essentially work on unallocated data, which is called Un supervised learning.  You have just pictures, you do not know their classes.  You drove millions, billions of pictures that you downloaded from Flickr or from somewhere else, and you have some kind of structure in the network itself that describes these pictures. <br><br>  You do not know what it is yet, but these are reasonable weights, which can then be taken and supplemented by a small number of different pictures, and this will be good.  This is a cool way to use a combination of 2 neural networks. <br><br>  Then you will see that this whole story is really about Lego.  That is, you have separate networks - recurrent neural networks, some other networks are all blocks that can be combined.  They are well combined on different tasks. <br><br>  These were the classic direct propagation neural networks.  Next, we turn to convolutional neural networks. <br><br><h3>  Neural Network Architecture: Convolutional Neural Networks </h3><br>  Convolutional Neural Networks, CNN <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7e1/1db/737/7e11db737d47a8add0827df12505469b.png"><br><br>  <a href="https://research.facebook.com/blog/learning-to-segment/">https://research.facebook.com/blog/learning-to-segment/</a> <br><br>  Convolutional neural networks solve 3 main tasks: <br><br><ol><li>  <strong>Classification.</strong>  You submit a picture, and the neural network just says - you have a picture about a dog, about a horse, about something else, and gives out a class. </li><li>  <strong>Detection</strong> is a more advanced task, when a neural network does not simply say that there is a dog or a horse in the picture, but also finds the Bounding box - where it is in the picture. </li><li>  <strong>Segmentation.</strong>  In my opinion, this is the coolest task.  In essence, this is a per-pixel classification.  Here we are talking about every pixel of the image: this pixel belongs to the dog, this one refers to the horse, and this one also relates to something.  In fact, if you know how to solve a segmentation problem, then the other 2 tasks are automatically given. </li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/473/0c4/7f8/4730c47f8ed2a86daa40356e88cc7dbd.png"><br><br>  What is a convolutional neural network?  In fact, the convolutional neural network is the usual feed-forward network, it‚Äôs just a little bit of a special kind.  Lego starts now. <br><br>  What is in the convolution network?  She has: <br><br><ul><li>  Convolutional layers - I will tell you further what it is; </li><li>  Subsampling, or Pooling-layers, which reduce the size of the image; </li><li>  Ordinary fully connected layers, the same multilayer perceptron, which is simply hung from above on these first 2 cunning layers. </li></ul><br>  A little more detail about all these layers. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/462/8dd/bde/4628ddbdea420895e5b0e426fae3c1b5.png"><br><br><ul><li>  <strong>Convolutional layers</strong> are usually drawn as a set of planes or volumes.  Each plane in such a picture or each slice in this volume is, in fact, one neuron that implements a convolution operation.  Again, then I will tell you what it is.  In essence, this is a matrix filter that transforms the original image into something else, and this can be done many times. </li><li>  <strong>Layers of subsampling</strong> (I will call Subsampling, it's easier) just reduce the size of the image: it was 200 * 200 ps, ‚Äã‚Äãafter Subsampling it became 100 * 100 ps.  In fact, averaging is a bit more cunning. </li><li>  <strong>Completely connected layers</strong> are usually used by the perceptron for classification.  There is nothing special about them. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/656/44e/038/65644e038835331869e3938fc8cde463.png"><br><br>  <a href="http://intellabs.github.io/RiverTrail/tutorial/">http://intellabs.github.io/RiverTrail/tutorial/</a> <br><br>  What is a convolution operation?  It scares everyone, but in reality it is a very simple thing.  If you worked in Photoshop and made Gaussian Blur, Emboss, Sharpen and a bunch of other filters, these are all matrix filters.  Matrix filters are in fact a convolution operation. <br><br>  How is it implemented?  There is a matrix, which is called the filter kernel (in the figure kernel).  For Blur it will be all units.  There is an image.  This matrix is ‚Äã‚Äãsuperimposed on a piece of the image, the corresponding elements are simply multiplied, the results are added and recorded at the center point. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/09e/08e/c54/09e08ec5407bec4e6b78e2b0303ce336.png"><br><br>  <a href="http://intellabs.github.io/RiverTrail/tutorial/">http://intellabs.github.io/RiverTrail/tutorial/</a> <br><br>  So it looks more clearly.  There is an image Input, there is a filter.  You run a filter over the entire image, honestly multiply the corresponding elements, add, write to the center.  Run, run - built a new image.  All this is a convolution operation. <br><br>  That is, in fact, convolution in convolutional neural networks is a cunning digital filter (Blur, Emboss, anything else), which itself is trained. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12a/61e/ad6/12a61ead639a0036f27b770925f3e653.png"><br><br>  <a href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a> <br><br>  In fact, convolutional layers all work on volumes.  That is, even if we take an ordinary RGB image, there are already 3 channels - this is, in fact, not a plane, but a volume of 3, conditionally, cubes. <br><br>  Convolution in this case is no longer a matrix, but a tensor - actually a cube. <br><br>  You have a filter, you run through the entire image, it immediately looks at all 3 color layers and generates one new point for one of this volume.  Run through the entire image - built one channel, one plane of the new image.  If you have 5 neurons, you have built 5 planes. <br><br>  This is how the convolutional layer works.  The task of learning the convolutional layer is the same as in ordinary neural networks - to find the weights, that is, to actually find the convolution matrix, which is completely equivalent to the weights in the neurons. <br><br>  What are these neurons doing?  They actually learn to look for some features, some local signs in the small part that they see - and that‚Äôs all.  Running one such filter is building some kind of map for finding these features in the image. <br><br>  Then you built many such planes, then use them as an image, feeding them on the following entrances. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/437/61c/a43/43761ca43da0f4f6e5920e56cf7185cf.png"><br><br>  <a href="http://vaaaaaanquish.hatenablog.com/entry/2015/01/26/060622">http://vaaaaaanquish.hatenablog.com/entry/2015/01/26/060622</a> <br><br>  The Pooling operation is an even simpler operation.  It is just averaging or taking a maximum.  It also works on some small squares, for example, 2 * 2.  You overlay an image and, for example, select the maximum element from this 2 * 2 box, send it to the output. <br><br>  Thus, you reduced the image, but not with a cunning Average, but with a slightly more advanced piece - you took the maximum.  This gives a small shift invariance.  That is, it does not matter to you whether some sign was found in this position or 2 ps to the right.  This thing allows the neural network to be slightly more resistant to image shifts. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/536/cce/ebb/536cceebbbfe79cc9ab897a713e04ee6.png"><br><br>  <a href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a> <br><br>  This is how the pooling layer works.  There is a cube of some size - 3 channels, 10, or 100 channels, which you counted by convolutions.  It simply reduces it in width and height, it does not touch other dimensions.  Everything is a primitive thing. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/57f/0ac/266/57f0ac26615a8c131d8dca161733ad63.png"><br><br>  What are good convolutional networks? <br><br>  They are good because they have much fewer parameters than the usual fully connected network.  Recall the example of a fully connected network, which we considered, where we got a million weights.  If we take a similar one, more precisely, a similar one ‚Äî it cannot be called a similar one, but a close convolutional neural network that has the same input, the same output will also have one fully connected output layer and 2 more convolutional layers with 100 neurons each, too. in the core network, it turns out that the number of parameters in such a neural network has decreased by more than an order of magnitude. <br><br>  It's great if the parameters are so much smaller - the network is easier to train.  We see it, it‚Äôs really easier to train. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/188/585/5e0/1885855e00c81842e46eab62013aa624.png"><br><br>  What does a convolutional neural network do? <br><br>  In fact, it automatically teaches some hierarchical features for images: first, basic detectors, lines of different inclination, gradients, etc.  Of these, she collects some more complex objects, then more complex ones. <br><br>  If you perceive a neuron as a simple logistic regression, a simple classifier, then a neural network is just a hierarchical classifier.  First, you single out simple signs, combine complex signs of them, even more complex ones, even more complex ones, and in the end you can combine some very complex sign - a specific person, a specific machine, an elephant, anything else. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/40e/d8d/18d/40ed8d18d16fce12d39945fae8c4cc80.png"><br><br>  Modern architectures of convolutional neural networks have become very complicated.  Those neural networks that won at the last competitions of ImageNet are no longer just some convolutional layers, Pooling layers.  These are directly finished blocks.  The figure shows examples from the network Inception (Google) and ResNet (Microsoft). <br><br>  In essence, the same basic components are inside: the same convolutions and pooling.  Just now there are more, they are somehow cleverly combined.  Plus, now there are direct links that allow you not to transform the image at all, but simply transfer it to the output.  It, by the way, helps that gradients do not fade.  This is an additional way to pass the gradient from the end of the neural network to the beginning.  It also helps to train such networks. <br><br>  It was quite classic convolutional neural networks.  Yes, there are different types of layers that can be used for classification.  But there are more interesting uses. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4ef/1a5/6d9/4ef1a56d92647176c1f03f93448b60f3.png"><br><br>  <a href="">https://arxiv.org/abs/1411.4038</a> <br><br>  For example, there is such a kind of convolutional neural networks called Fully-convolutional networks (FCN).  People rarely talk about them, but this is a cool thing.  You can take and tear the last multilayer perceptron, it is not needed - and throw it out.  And then the neural network can magically work on images of arbitrary size. <br><br>  That is, she learned, let's say, to determine 1000 classes in the images of cats, dogs, something else, and then we took the last layer and did not tear it off, but transformed it into a convolutional layer.  There are no problems - you can count the weights.  Then it turns out that this neural network seems to work with the same window for which it was trained, 100 * 100 ps, ‚Äã‚Äãbut now it can run through this window across the entire image and build a heat map on output - where in this particular image is specific class. <br><br>  You can build, for example, 1000 of these heatmap for all your classes and then use this to determine the location of the object in the picture. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is the first example where a convolutional neural network is not used for classification, but in fact for generating an image. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a61/bda/9d8/a61bda9d8388ed5e231da9b84d336c1c.png"><br><br> <a href="http://cvlab.postech.ac.kr/research/deconvnet/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://cvlab.postech.ac.kr/research/deconvnet/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A more advanced example is Deconvolution networks. About them, too, rarely speak, but it is even more cool thing. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In fact, Deconvolution is the wrong term. In digital signal processing, this word is taken by a completely different thing - a similar, but not such.</font></font><br><br>  What it is?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In essence, this is a trained upsling. That is, at some point you have reduced your image to some small size, maybe even 1 ps. Rather, not to a pixel, but to some small vector. Then you can take this vector and open. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Or, if at some point you get an image of 10 * 10 ps, ‚Äã‚Äãyou can now do Upsampling of this image, but in some tricky way in which Upsampling weights are also trained. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is not magic, it works, and in fact it allows us to train neural networks that receive some kind of output image from the input image. That is, you can submit entry / exit samples, and the one in the middle will learn by itself.</font></font> It is interesting. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In fact, many tasks can be reduced to the generation of images. The classification is a cool task, but it is still not comprehensive. There are many tasks where pictures need to be generated. Segmentation is basically a classic task, where you need to have a picture at the output. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Moreover, if you have learned to do so, then you can do it in a different way, more interesting. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/f6a/257/b28/f6a257b280d9a4c01fb71833c35fa929.png"><br><br> <a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/abs/1411.5928</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> It‚Äôs possible to tear off the first part, for example, and fasten some kind of fully connected network that we will teach - what goes to the entrance, for example, the class number: generate a chair for me that angle and in such a form. These layers generate some internal representation of this chair, and then it unfolds into a picture.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This example is taken from the work where the neural network really taught to generate different chairs and other objects. </font><font style="vertical-align: inherit;">It also works, and it's fun. </font><font style="vertical-align: inherit;">This is collected, in principle, from the same basic blocks, but they are wrapped differently. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/0fc/5f1/2af/0fc5f12af36fe13ed0b35a5cc017f2cf.png"><br><br> <a href="https://arxiv.org/abs/1508.06576"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/abs/1508.06576</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There are non-classical tasks, for example, transferring a style that we all hear about in the last year. </font><font style="vertical-align: inherit;">There are a bunch of applications that can do this. </font><font style="vertical-align: inherit;">They work on about the same technology. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/be1/896/4da/be18964da703d44c30825ae87f0c4502.png"><br><br> <a href="https://arxiv.org/abs/1508.06576"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/abs/1508.06576</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There is a ready trained network for classification. </font><font style="vertical-align: inherit;">It turned out that if we take a derived picture, load it into this neural network, then different convolutional layers will be responsible for different things. </font><font style="vertical-align: inherit;">That is, on the first convolutional layers will be the stylistic features of the image, on the latter - the content attributes of the image, and this can be used.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You can take a picture as a model of style, drive it through a ready-made neural network, which was not taught at all, remove stylistic signs, and remember. You can take any other picture, get rid of, take the content signs, remember. And then the random image (noise) can be driven away again through this neural network, to get the signs on the same layers, to compare with those that should have been received. And you have a task for Backpropagation. In fact, further gradient descent can be transformed random image to one for which these weights on the desired layers will be as necessary. And you got a stylized picture.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The only problem with this method is that it is long. This iterative run of the picture back and forth is a long time. Who played with this code in the style generation, knows that the classic code is long, and you have to suffer. All services like Prism and so on, which generate more or less quickly, work differently. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/872/1ad/439/8721ad43970ad085378350cfe9ddcaf6.png"><br><br> <a href="https://arxiv.org/abs/1603.03417"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/abs/1603.03417</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Since then, we have learned how to generate networks that just generate a picture in 1 pass. This is the same task of transforming an image that you have already seen: there is something at the entrance, there is something at the exit, you can train everything in the middle. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this case, the trick is that the loss function is the very function of the error you get on this neural network, and the error function is removed from the normal neural network that was trained for classification.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">These are hacker methods of using neural networks, but it turned out that they work, and this leads to great results. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Next, we turn to recurrent neural networks.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Neural Network Architecture: Recurrent Neural Networks </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recurrent Neural Networks, RNN </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/712/957/2b2/7129572b2675e11655d950078ce18493.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recurrent neural network is actually a very cool thing. At first glance, their main difference from conventional FNN networks is that some kind of cyclic connection just appears. That is, the hidden layer sends its own values ‚Äã‚Äãto itself in the next step. It would seem like a minor thing, but there is a fundamental difference. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/daa/035/983/daa0359837994cefd1c7f31025815be0.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">About the usual Feed-Forward neural network it is known that it is a universal approximator. They can approximate more or less any continuous function (there is such a Tsybenko theorem). It's great, but the recurrent neural networks are turing full. They can calculate any computable. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Essentially, recurrent neural networks are a regular computer. The task is to train him correctly. Potentially, it can read any algorithm. Another thing is that it is difficult to teach him.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In addition, conventional Feed-Forward neural networks have no opportunity to take into account the order in time - this is not in them, not presented. Recurrent networks do this explicitly, the concept of time is embedded in them. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Regular feed-forward networks do not have any memory, except for the one that was obtained at the training stage, and recurrent networks do. Due to the fact that the content of the layer is transferred back to the neural network, it is like its memory. It is stored while the neural network is running. This also adds a lot. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/b04/271/af2/b04271af2ae279f8db2ac11de666e50e.png"><br><br> <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> How are recurrent neural networks trained? In fact, almost the same. In addition to Backpropagation, of course, there are many other algorithms, but at the moment Backpropagation works best.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For recurrent neural networks, there is a variation of this algorithm - Backpropagation through time. </font><font style="vertical-align: inherit;">The idea is very simple - you take a recurrent neural network and the cycle simply expands on a few steps, for example, 10, 20 or 100, and you get a regular deep neural network, which you then teach with ordinary Backpropagation.</font></font><br><br>  But there is a problem.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As soon as we start talking about deep neural networks - where 10, 20, 100 layers - from gradients, which from the end should go to the very beginning, there is nothing left behind 100 layers. </font><font style="vertical-align: inherit;">With this we need to do something. </font><font style="vertical-align: inherit;">In this place, a certain hack was invented, a beautiful engineering solution called LSTM or GRU is a memory cell. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a4/517/731/8a4517731c88d9d177c1e1db00849c51.png"><br><br> <a href="https://deeplearning4j.org/lstm"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://deeplearning4j.org/lstm</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Their idea is that the visualization of a normal neuron is replaced with some kind of clever thing that has memory and there is a gate, which control when this memory needs to be reset, rewritten or saved, etc. These gates are also trained in the same way as everything else. In fact, this cell, when it has learned, can tell the neural network that we are now keeping this internal state for a long time, for example, 100 steps. Then, when the neural network used this state for something, it can be reset. It became unnecessary, we went to a new count. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On all more or less serious tests, these neural networks strongly do the usual classical recurrent ones, which are simply on neurons. Almost all recurrent networks are currently built on either LSTM or GRU.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e4e/604/956/e4e604956ad069370718269501d0ad83.png"><br><br> <a href="http://kvitajakub.github.io/2016/04/14/rnn-diagrams"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://kvitajakub.github.io/2016/04/14/rnn-diagrams</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I will not go into what it is inside, but these are such tricky blocks, much more complicated than ordinary neurons, but, in fact, they are similar. There are some gateways that control this very ‚Äúremember - not remember‚Äù, ‚Äúpass on - no pass on‚Äù. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">These were the classic recurrent neural networks. Then begins the topic, which is often silent, but it is also important.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c5/9c6/81a/1c59c681aa1521c9d317dc0f51027b83.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When we work with a sequence in a recurrent network, we usually feed one element, then the next, and set the previous state of the network to the input, this natural direction arises - from left to right. But it is not the only one! If we have, for example, a proposal, we begin to submit his words in the usual way to the neural network - yes, this is the normal way, but why not submit it from the end? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">That is, in many cases, the sequence has been given entirely from the very beginning. We have this proposal, and there is no point in highlighting one direction relative to another. We can run a neural network on the one hand, on the other hand, actually having 2 neural networks, and then combine their result.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is called Bidirectional - bidirectional recurrent neural network. Their quality is even higher than conventional recurrent networks, because there is more context: for each point there are now 2 contexts - what was before, and what will be after. For many tasks this adds quality, especially for language related tasks. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For example, there is German, where in the end something will definitely be hung up and the sentence will change - such a network will help. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/649/bc1/81a/649bc181a2a991d9d29daaf05978c293.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Moreover, we considered one-dimensional cases - for example, sentences. But there are multidimensional sequences - the same image can also be considered as a sequence. Then he generally has 4 directions that are reasonable in their own way. For an arbitrary point of the image there are, in fact, 4 contexts with such a detour.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are interesting multidimensional recurrent neural networks: they are both multidimensional and multidirectional. Now they are a little forgotten. This, by the way, is an old development, which is already 10 years old, probably, but now it is beginning to emerge. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6f6/61a/b28/6f661ab284d65ae6bbd5f35268521acf.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here are the latest works (2015). This neural network is analogous to the classic LeNet neural network, which classified handwritten numbers. But now it is never convolutional, but recurrent and multidirectional. There are arrows that are in different directions in the image. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The second example is the tricky neural network, which was used for segmentation of brain sections. She, too, is never convolutional, but recurrent, and she won in some regular competition.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In fact, this is a cool technology. I think that in the near future recurrent networks will very strongly press convolutional networks, because even for images they add a lot of things. This is a potentially more powerful class. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d9f/48b/196/d9f48b19620b7ed6bc94cda959866f25.png"><br><br> <a href="https://arxiv.org/abs/1507.01526"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/abs/1507.01526</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And there is also a very recent development of the Grid LSTM, which is still not very meaningful and conscious. In fact, the idea is simple - they took a recurrent network, at some point they replaced the neurons with some tricky cells, so that the state could be stored for a long time. If our network is deep in this direction, then there is no gate, gradients are also lost. What if in this direction is also something to add? Yes, added, it turned out cool!</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Just a problem - now there are almost no ready-made software libraries where this is implemented. </font><font style="vertical-align: inherit;">There are 1-2 pieces of code that you can try to use. </font><font style="vertical-align: inherit;">I hope that in the coming year these things will be publicly available, and it will be quite cool. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is a wonderful thing, see what happens to her, she is good. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now begin advanced topics.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Multimodal Learning </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mixing different modalities in one neural network, for example, image and text </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Multimodal training is also ideologically a simple thing when we take and we mix 2 modalities in a neural network, for example, pictures and text. Before that, we considered cases of work on 1 modality - only in pictures, only on sound, only on text. But you can mix! </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/b7a/b2e/31d/b7ab2e31d687023e4bbdbc1b85be2db9.png"><br><br> <a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://arxiv.org/abs/1411.4555</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> For example, there is a cool case - generating a description of pictures. You submit a picture to the neural network; it generates text at the output, say, in normal English, which describes what happens in this picture. A few years ago, this technology did not seem possible at all because it was not clear how to do this. But now it is implemented.</font></font><br><br><blockquote>  <font color="gray">By the way, we posted in open access the video of the last five years of the conference of developers of high-loaded systems <a href="http://www.highload.ru/">HighLoad ++</a> .</font>  <font color="gray">Watch, learn, share and subscribe to <a href="https://www.youtube.com/user/profyclub">the YouTube channel</a> .</font> </blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inside, everything is simple. </font><font style="vertical-align: inherit;">There is a convolutional neural network that processes the image, extracts some signs from it and writes it in some tricky state vector. </font><font style="vertical-align: inherit;">There is a recurrent network that is taught from this state to generate and expand text. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This combination of 2 modalities is very productive. </font><font style="vertical-align: inherit;">There are many such examples. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ae/979/67b/5ae97967bcea06068e96ef6bce7dc75a.png"><br><br> <a href="https://www.cs.utexas.edu/~vsub/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.cs.utexas.edu/~vsub/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There is, for example, an interesting task of annotating a video. </font><font style="vertical-align: inherit;">In fact, another dimension is simply added to the previous task - time.</font></font><br><br>  For example: <br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There is a football player who runs around the field; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There is a convolutional neural network that generates features; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There is a recurrent neural network that describes what happened in each frame or in a sequence of frames. </font></font></li></ul><br>  It is interesting! <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In a little more detail, how multimodal training looks inside. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/aca/900/47a/aca90047a21b145d67255472ef443a02.png"><br><br> <a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://arxiv.org/abs/1411.2539</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There is some tricky space that we can‚Äôt see, but it exists inside the neural network in the form of these weights, which it considers for itself. It turns out that in the process of learning we learn two different neural networks: convolutional and recurrent for the text that describes the picture and for the picture itself to generate vectors in this tricky space in one place. That is, to reduce 2 modalities into one. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If we have learned to do this, then further there it does not matter to some extent: submit a picture - generate text, submit text - find a picture. You can play with different things and build interesting things.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">By the way, there are already attempts to build networks that generate text in the text. </font><font style="vertical-align: inherit;">This is interesting, it also works. </font><font style="vertical-align: inherit;">Not very good yet, but the potential is huge.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sequence Learning and the seq2seq paradigm </font></font></h3><br>  When it is necessary to work with sequences of arbitrary length at the input and / or output <br><br>  The second interesting topic is Sequence Learning or the seq2seq paradigm.  I will not even translate it.  The idea is that a lot of your tasks come down to the fact that you have sequences.  That is, not just a picture that needs to be classified, to give out one number, but there is one sequence, and the output needs another sequence. <br><br>  For example, the translation is a classic task of Sequence 2 Sequence Learning: asked the text in English, want to receive in French. <br><br>  There are a lot of such tasks.  This is a picture description case. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b9/94d/471/4b994d4716cf12a206b73a235ddfe5a8.png"><br><br>  <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a> <br><br>  Ordinary neural networks, which we considered - drove something, drove through the network, removed at the output - not interesting. <br><br>  There is an option called One to many.  They drove the picture into the network, and then she went to work, work and generated a description of this picture.  Great. <br><br>  You can in the opposite direction.  For example, the classification of texts.  This is the favorite task of all marketers - to classify tweets - they are positive or negative in terms of emotional coloring.  You drove your proposal into a recurrent neural network, and then at the end it gave one number - yes, positively colored tweet, no, negatively colored tweet, or neutral, for example. <br><br>  There is a story about the translation.  You have long driven the sequence in the same language.  Then the network worked and started generating a sequence in another language.  This is generally the most common setting. <br><br>  There is another interesting setting when the inputs and outputs are synchronized.  For example, if you need to annotate each frame of the image, there is something on it or not. <br><br>  The figure shows all the variants of Sequence 2 Sequence Learning, and this is a very powerful paradigm.  It is powerful in that if everything inside the neural network is differentiable - and the neural networks that we discussed are all differentiable inside, it means that you can train the neural network, end-to-end, so to speak: some sequences have been fed to the input, others and what happens inside doesn‚Äôt matter to you.  The neural network itself will cope - at the entrance a bunch of examples in English, on the way out - a bunch of examples in French - great, she will learn the translation.  And really with good quality, if you have a large database and good computing power to drive it all away. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a08/07c/d43/a0807cd4331bb7c55f8d0cf87d59fb7d.png"><br><br>  Another insanely important thing, about which they almost never speak, but without which neither Google‚Äôs speech recognition nor Baidu, nor Microsoft - CTC works. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/029/395/6c0/0293956c06c58346ab69ef5c07938d42.png"><br><br>  <a href="https://github.com/baidu-research/warp-ctc">https://github.com/baidu-research/warp-ctc</a> <br><br>  CTC is such a tricky output layer.  What is he doing?  There are many tasks in which the alignment within this sequence is not really important.  There is a speech recognition task.  You took the sound, cut it into short frames of 50 ms, for example, and then you need to generate at the output what word it was, a sequence of phonemes.  By and large, you do not care where in the original signal was one or another phoneme.  What is important is only the order among themselves to get a word at the exit. <br><br>  The fact that you can throw out all the information about the exact position, in fact, a lot of what adds.  For example, you do not need to have accurate markup of phonemes across all frames of sound, because getting such markup is insanely expensive.  It is necessary to plant a person who will mark everything. <br><br>  You can just take everything and throw it away - there is input data, there is a way out - what should happen in terms of the output sequence is a word, there is this tricky CTC-layer that will do some kind of alignment inside itself, and this will allow, again, end- to-end to train such a tricky network, for which you did not mark anything at all. <br><br>  This is the most powerful thing, it is also not implemented in all modern packages.  But, for example, a year ago Baidu laid out its implementation of the CTC layer - this is great. <br><br>  Just a couple of words about different architectures. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/99a/d81/fb3/99ad81fb31bd10dfd2d8694435e99433.png"><br><br>  <a href="https://github.com/farizrahman4u/seq2seq">https://github.com/farizrahman4u/seq2seq</a> <br><br>  There is a classic architecture decoder-decoder.  The translation example, about which I spoke, is almost entirely reduced to this architecture. <br><br>  There is one input neural network, words are fed into it.  The output of this neural network is ignored, as it were, until the end of sentence character is given.  After that, the second network turns on and reads the state of the first network and starts generating the output words from it.  At the entrance are her results in the previous step. <br><br>  It works.  Many translation systems work this way. <br><br>  But this architecture has one problem - also a bottleneck.  The state vector (the size of the hidden layer) that is transmitted is limited and fixed.  That is, it turns out that it is the same for both the short sentence and the insanely long one ‚Äî this is not very good.  It may be that a long sentence does not fit into this volume. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5dc/f6d/117/5dcf6d117463596843dbe91e8ae5ffa8.png"><br><br>  <a href="https://research.googleblog.com/2016/09/a-neural-network-for-machine.html">https://research.googleblog.com/2016/09/a-neural-network-for-machine.html</a> <br><br>  Appeared architecture, as they say, with attention. <br><br>  Attention - this is such a tricky thing, which in fact is, in fact, very simple.  The idea is that now the decoder output to a neural network does not look at the output value of the previous neural network, but at all its intermediate states, but with some weights.  Weights are coefficients, how much you need to take each of those states into the final large amount that the decoder will work with. <br><br>  That is, attention is actually a simple linear combination of all previous states of an encoder, which is also being trained. <br><br>  Neural networks with attention in fact work very well.  On translation tasks and other complex tasks, they are very much superior in quality to neural networks without attention. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/461/496/38e/46149638e1e1775517c4107199d65f73.png"><br><br>  <a href="http://kelvinxu.github.io/projects/capgen.html">http://kelvinxu.github.io/projects/capgen.html</a> <br><br>  Extra bonus of such networks.  The figure shows the combination of 2 different neural networks: the convolutional neural network, from which we received some signs, further the recurrent neural network generates the text.  If we implemented the concept of attention, set off on some pictures, then we can look at generating a specific word, which weights were great.  This actually indicates which pixels of the image at a particular moment played a role in generating this particular word.  That is what the neural network seemed to pay attention to. <br><br>  By the way, the concept of attention is far from being implemented in every library, that is, there are no ready-made boxed solutions.  Sometimes you can find ready-made code that someone published as part of their work. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c1/5d5/1b6/3c15d51b6deb99e9105e8e3bcefd47da.png"><br><br>  <a href="http://kelvinxu.github.io/projects/capgen.html">http://kelvinxu.github.io/projects/capgen.html</a> <br><br>  CNN + RNN with attention = beautiful pictures. <br><br>  When the neural network generates a text about the STOP sign, it really looks at this sign - its weight, its contribution to the generation of a specific word STOP is very high, and all the other pixels play little role. <br><br>  This is an interesting concept, follow it too.  It will also be used in many places. <br><br><h3>  Frameworks and libraries for working with neural networks </h3><br>  Very brief overview <br><br>  In fact, you can talk about it for hours.  I have no purpose to tell you - yes, use this library here or this one - because all this is not so.  Libraries have a huge amount.  I will give a more or less relevant list of different libraries. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/935/f93/64a/935f9364adc17716c05593214e7bb8d9.png"><br><br>  Detailed list: <a href="http://deeplearning.net/software_links/">http://deeplearning.net/software_links/</a> <br><br>  Universal libraries and services: <br><br><ul><li>  <strong>Torch7</strong> ( <a href="http://torch.ch/">http://torch.ch/</a> ) [Lua] </li><li>  <strong>TensorFlow</strong> ( <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a> ) [Python, C ++] </li><li>  <strong>Theano</strong> ( <a href="http://deeplearning.net/software/theano/">http://deeplearning.net/software/theano/</a> ) [Python] <br><ul><li>  <strong>Keras</strong> ( <a href="http://keras.io/">http://keras.io/</a> ) </li><li>  <strong>Lasagne</strong> ( <a href="https://github.com/Lasagne/Lasagne">https://github.com/Lasagne/Lasagne</a> ) </li><li>  <strong>blocks</strong> ( <a href="https://github.com/mila-udem/blocks">https://github.com/mila-udem/blocks</a> ) </li><li>  <strong>pylearn2</strong> ( <a href="https://github.com/lisa-lab/pylearn2">https://github.com/lisa-lab/pylearn2</a> ) </li></ul><br></li></ul><br><ul><li>  <strong>Microsoft Cognitive Toolkit (CNTK)</strong> ( <a href="http://www.cntk.ai/">http://www.cntk.ai/</a> ) [Python, C ++, C #, BrainScript] </li><li>  <strong>Neon</strong> ( <a href="http://neon.nervanasys.com/">http://neon.nervanasys.com/</a> ) [Python] </li><li>  <strong>Deeplearning4j</strong> ( <a href="http://deeplearning4j.org/">http://deeplearning4j.org/</a> ) [Java] </li><li>  <strong>MXNet</strong> ( <a href="http://mxnet.io/">http://mxnet.io/</a> ) [C ++, Python, R, Scala, Julia, Matlab, Javascript] </li><li>  ... </li></ul><br>  First, there are universal libraries, about many of which you have heard. <br><br>  For example, TensorFlow (Google) is probably one of the most popular, although quite fresh.  It can be used in Python and C ++. <br><br>  There is a Torch library that actively supports Facebook at the moment.  This is the language of Lua.  But do not be afraid of him, in fact it is a cool language.  There is a lot of this library, which is implemented, there is a lot of fresh research right in the form of Lua code.  It's great. <br><br>  There is the Theano library - TensorFlow has now pressed it a little, but many different cool high-level wrappers have been built around Theano - you can write the neural network in several lines.  This is really very cool! <br><br>  Some of these wrappers, for example, Keras, can work with TensorFlow, as a backend, as they say.  That is, TensorFlow is a rather low-level code in terms of neural networks, Keras is a high-level code, or a single-line layer is convenient. <br><br>  Microsoft has published something, there is Neon, Deeplearning4j - a rare case - the Java library for Deeplearning.  They are few in Java.  A lot of Python and C ++.  In other languages, less. <br><br>  In addition, there are special tools for video processing. <br><br>  Image and video processing: <br><br><ul><li>  <strong>OpenCV</strong> ( <a href="http://opencv.org/">http://opencv.org/</a> ) [C, C ++, Python] </li><li>  <strong>Caffe</strong> ( <a href="http://caffe.berkeleyvision.org/">http://caffe.berkeleyvision.org/</a> ) [C ++, Python, Matlab] </li><li>  <strong>Torch7</strong> ( <a href="http://torch.ch/">http://torch.ch/</a> ) [Lua] </li><li>  <strong>clarifai</strong> ( <a href="https://www.clarifai.com/">https://www.clarifai.com/</a> ) </li><li>  <strong>Google Vision API</strong> ( <a href="https://cloud.google.com/vision/">https://cloud.google.com/vision/</a> ) </li><li>  ... </li></ul><br>  I included OpenCV here.  This is of course never a Deeplearning library, but it integrates well with other libraries. <br><br>  Caffe is an excellent library, we used it in Production.  This is a plus library, it is very fast, there is little faster than it is.  It is still cool, although those who are now developing neural networks for some reason think only of TensorFlow.  But keep in mind that there are a bunch of other great solutions, including the Caffe - a very cool thing. <br><br>  In addition, there are a number of different APIs that can be used in WEB. <br><br>  Speech recognition.  It's actually getting worse. <br><br>  Speech recognition: <br><br><ul><li>  <strong>Microsoft Cognitive Toolkit (CNTK)</strong> ( <a href="http://www.cntk.ai/">http://www.cntk.ai/</a> ) [Python, C ++, C #, BrainScript] </li><li>  <strong>KALDI</strong> ( <a href="http://kaldi-asr.org/">http://kaldi-asr.org/</a> ) [C ++] </li><li>  <strong>Google Speech API</strong> ( <a href="https://cloud.google.com/">https://cloud.google.com/</a> ) </li><li>  <strong>Yandex SpeechKit</strong> ( <a href="https://tech.yandex.ru/speechkit/">https://tech.yandex.ru/speechkit/</a> ) </li><li>  <strong>Baidu Speech API</strong> ( <a href="http://www.baidu.com/">http://www.baidu.com/</a> ) </li><li>  <strong>wit.ai</strong> ( <a href="https://wit.ai/">https://wit.ai/</a> ) </li><li>  ... </li></ul><br>  There is one cool KALDI library for speech recognition, it is positive.  But in general, speech recognition is more or less closed within large corporations because no one has a large Data Set about speech and sound.  But there is a large number of APIs from Yandex, Google, Baidu, Microsoft seems to have one too. <br><br>  Text processing: <br><br><ul><li>  <strong>Torch7</strong> ( <a href="http://torch.ch/">http://torch.ch/</a> ) [Lua] </li><li>  <strong>Theano / Keras / ...</strong> [Python] </li><li>  <strong>TensorFlow</strong> ( <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a> ) [C ++, Python] </li><li>  <strong>Google Translate API</strong> ( <a href="https://cloud.google.com/translate/">https://cloud.google.com/translate/</a> ) </li><li>  ... </li></ul><br>  For texts in general, there is nothing especially special, but all universal libraries are great.  Take Keras (or any other, not fundamentally), write something in a few lines - you have a neural network for working with text.  Or any other library is not important. <br><br>  That's all, thank you.  There is no universal answer to the question which universal library should be taken.  Look at your task.  There are many subtleties - and what kind of technology you have, what is embedded in it, and what code is already ready in nature - n <a href="http://github.com/">http://github.com/ there are</a> really a lot of codes that can be used.  This is an engineering challenge that needs to be approached thoughtfully.  One universal answer is not and can not be. <br><br><h3>  Questions and Answers </h3><br>  <strong><em>Question</em></strong> : Can you advise some literature for a beginner - what would be better to read, to look, to understand more deeply how to program neural networks? <br><br>  <strong><em>Answer</em></strong> : It depends a lot on your current level, on how deeply you want to get an understanding.  In fact, there are a huge number of blogs.  First, forget about the Russian language - there is practically nothing on it.  There are some transfers to Habr√©, but this is not serious against the background of the array that exists in nature. <br><br>  In English there are a huge number of cool blogs, where different examples are dealt with.  There are a lot of them, just google and find something on a specific topic.  There are different tutorials, again in English, more or less small.  There is a 800 page Deeplearning book, which is now on paper in AMT-Press, and it has been available in PDF for a long time. <br><br>  In general, there is literature.  There are some courses online, for example, on Coursera, there are attempts to run the course offline.  In particular, I will soon participate in one of these courses. <br><br>  In fact, there are quite a few different options.  Look on the Internet - true, there are many possibilities.  Most of them are still reading various foreign literature, but it is really good and comprehensive. <br><br>  But the code on GitHub is also good.  A lot of code is published, which you can at least see.  Often it can be read, it is not very scary.  And often with this code there are some intelligible comments about how it all works.  Just go to the Internet - there is a lot of everything there. <br><br>  <strong><em>Question</em></strong> : What, in general, are there approaches to learning neural networks?  Is it possible to just google a bunch of pictures from the Internet, or is it possible to take some neural networks that train other neural networks? <br><br>  <strong><em>Answer</em></strong> : Yes, this is a cool question.  In the training of neural networks, I think in the coming years there will also be a lot of progress.  There are different approaches.  First, yes - when you have scored a Data Set and are teaching it - this is a classic approach.  He is, from him there is no way to go, he is basic in many cases. <br><br>  But now, by the way, the base approach often becomes another approach called Transfer learning.  There are some already published neural networks that are trained on different tasks - on the same ImageNet.  You can take yourself a ready ImageNet neural network for 1000 classes and train it for some special classes.  This may be easier because you have, say, only 1000 pictures of your classes, and you do not train a good neural network from scratch on such a volume.  In order to train a deep neural network, you really need a lot of data.  We are talking about hundreds of thousands and millions of objects.  But then, if you have a ready-made grid, you took it, a little bit of additional training, and you already have a sane result.  Transfer learning is a good approach.  He works. <br><br>  The option when neural networks are taught by other neural networks is also such options.  They are more research than production.  This is a very cool topic, it's great to follow.  I don‚Äôt know very good production-solutions, but if you are interested in the scientific side, then yes, read, there are some really cool articles where a neural network teacher, which contains a model of some kind of world, teaches another neural network, and it works . <br><br>  <strong><em>Question</em></strong> : Are there any tools in which you can modify existing neural network architectures or create, for example, your own? <br><br>  <strong><em>Answer</em></strong> : See, if you want a visual tool, then rather no, than yes.  Although there are some plugins on TensorFlow that visualize something there.  But in general, this is actually not a very big problem because the neural network is often specified in the form of some kind of structure, text file or code, it is not very difficult to change, there you can add layers, reprogram it.  This is not even much programming, this is such a DSL special in fact.  You took and added a couple of layers. <br><br>  The most difficult thing in all these works is to observe the dimension between the layers.  If you do not really understand how the tensors are arranged there, these multidimensional arrays, there is a chance to get confused with the dimensions.  This is the hardest part of all this. <br><br>  <strong><em>Question</em></strong> : You told about quite a lot of different recurrent architectures <br>  neural networks.  And what exactly did you use and for what tasks? <br><br>  <strong><em>Answer</em></strong> : For most tasks, simple neural networks from the LSTM box work well, of sufficient depth and of sufficient size.  There are many tasks of classifying text, classifying anything in sequences.  If you start with one of the LSTM networks, this is, in principle, a normal start.  If you understand that bidirectionality is helpful in this place, you are doing Bidirectional LSTM. <br><br>  It would be great to start with all sorts of cool options with attention and so on, but it's just hard to start with them because they are difficult to program from scratch.  There is not trivial after all.  And there are not very many such good pieces of code that you took and use.  For me, the Base line for now is LSTM networks - unidirectional or bidirectional.  I used them to classify texts and images (recognition of numbers). <br><br>  <strong><em>Question</em></strong> : I know that neural networks are used to crack cryptographic algorithms, for example, the plaintext is input and the cipher text is output.  And then, in the opposite direction, the ciphertext is served, and the training simply gets open at the output.  The question is: what progress is now in this area, does it really work, and what architectures can you use for this? <br><br>  <strong><em>Answer</em></strong> : I cannot say much about this.  I am not enough in this area, so let's say competent.  I do not work at the interface with such security cryptography.  I saw some fresh work of Google, where one neural network was taught to generate a cipher, and another to crack.  But it seems to me these examples are far from good crypto-stable algorithms.  It seems to me that this is research at the level of the ‚ÄúIt is interesting to see what will come of it‚Äù series.  I have not heard about the cool work about breaking serious ciphers. <br><br><blockquote>  <font color="gray">This report is a transcript of one of the best speeches at the conference of developers of high-loaded <a href="http://highload.ru/%3Futm_source%3Dhabr%26utm_medium%3Dmedia%26utm_campaign%3Dpast.articles%26utm_content%3Dcommon">HighLoad ++</a> systems.</font>  <font color="gray">Less than a month is left before the HighLoad ++ 2017 conference.</font> <font color="gray"><br><br></font>  <font color="gray">We have already prepared <a href="http://www.highload.ru/2017/abstracts">the conference program</a> , now the schedule is being actively formed.</font> <font color="gray"><br><br></font>  <font color="gray">This year we continue to explore the topic of neural networks:</font> <font color="gray"><br><br></font> <ul><li>  <a href="http://www.highload.ru/2017/abstracts/3083.html">Identification of attributes and visual search in UGC-photos of clothes</a> / Dmitry Solovyov </li><li>  <a href="http://www.highload.ru/2017/abstracts/2987.html">Recognition of clouds and shadows on satellite images using deep learning</a> / Anatoly Filin </li><li>  <a href="http://www.highload.ru/2017/abstracts/2985.html">Neural networks: fast inference on the GPU using TensorRT (demo)</a> / Dmitry Korobchenko </li><li>  <a href="http://www.highload.ru/2017/abstracts/2938.html">Detection of anomalies in time series with the help of autoencoders</a> / Pavel Filonov </li><li>  <a href="http://www.highload.ru/2017/abstracts/3044.html">Face Recognition: From Scratch To Hatch</a> / Edward Tiantov </li></ul><br>  Also, some of these materials are used by us in an online training course on the development of high-load systems <a href="http://highload.guide/%3Futm_source%3Dhabr%26utm_medium%3Dmedia%26utm_campaign%3Dpast.articles%26utm_content%3Dcommon">HighLoad.Guide</a> is a chain of specially selected letters, articles, materials, videos.  Already, in our textbook more than 30 unique materials.  Get connected! <br></blockquote></div><p>Source: <a href="https://habr.com/ru/post/340184/">https://habr.com/ru/post/340184/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../340172/index.html">Analysis of the latest version of the Dridex malware for identity theft</a></li>
<li><a href="../340176/index.html">The whole web on 60+ FPS: how a new renderer in Firefox got rid of jerks and slowdowns</a></li>
<li><a href="../340178/index.html">Monoids, semigroups and all-all-all</a></li>
<li><a href="../340180/index.html">Wi-Fi security is compromised due to multiple vulnerabilities found in WPA2</a></li>
<li><a href="../340182/index.html">Critical vulnerabilities detected in WPA2 - Key Reinstallation Attacks (KRACK)</a></li>
<li><a href="../340186/index.html">How to create a competitive advantage and value of a technological product</a></li>
<li><a href="../340188/index.html">Our cloud-based JS is now ES2017, and this reduces the code by several times.</a></li>
<li><a href="../340190/index.html">Russian-speaking chat bot Boltoon: create a virtual companion</a></li>
<li><a href="../340192/index.html">Key QA Process Indicators</a></li>
<li><a href="../340194/index.html">A tricky javascript question asked at Google and Amazon interviews</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>