<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Administrator's summary: the difference between a microscope and a hammer when building a SAN (updated)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="One day, one of the clients of the integrator company where I worked asked to quickly draw a draft of a small storage system. As luck would have it, a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Administrator's summary: the difference between a microscope and a hammer when building a SAN (updated)</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/638/34e/d6a/63834ed6a2b14f7c89788e2f3b66954a.jpg" alt="image alt text"></p><br><p>  One day, one of the clients of the integrator company where I worked asked to quickly draw a draft of a small storage system.  As luck would have it, a special person on SAN was unavailable and the task was assigned to me.  At that time, my knowledge of storage was reduced to the impenetrable idea of ‚Äã‚Äã" <strong>Fiber Channel is cool and iSCSI is not very</strong> ." <a name="habracut"></a></p><br><p>  For all those who got into a similar situation or are slightly interested in the topic of SAN, we prepared a cycle of materials in the format <strong>"outline".</strong>  Today‚Äôs article focuses on storage technology for small and medium sized organizations.  I will try not to get bogged down with theory and use more examples. </p><br><h1 id="shd-razlichnye-i-v-meru-neobychnye">  Storage systems are different and moderately unusual </h1><br><p>  If the engineer is not particularly familiar with data storage networks (DSS), then choosing the right device often begins with studying the market in terms of its own stereotypes.  For example, I used to usually stop at simple DAS-systems, which surprisingly complemented with its illogical thesis about the ‚Äúcoolness‚Äù of the Fiber Channel.  On the other hand, DAS was understandable and did not require reading long administrator‚Äôs manuals and diving into the dark world of storage networks. </p><br><p>  If the organization simply runs out of space on a shared network drive, then <a href="https://servermall.ru/catalog/server-ibm-x3650-m3/">an inexpensive server</a> with a relatively high density of disks will suffice, as a reserve for the future.  Of the specialized systems, network file storage (NAS), such as <a href="http://www.synology.su/products/105">Synology DS414 SLim, is not bad</a> .  On it, it is convenient to create shared folders, and the rights are flexibly configured, and there is integration with Active Directory. </p><br><p><img src="https://habrastorage.org/files/0af/abf/b5b/0afabfb5b6ee4be883c093727208a997.jpg" alt="image alt text"></p><br><blockquote>  What I like about Synology's storage is a user-friendly interface with many plug-ins for any usage scenarios.  But their behavior is very strange.  For example, one customer had Synology DS411 + II.  It worked fine until the next reboot, after which it did not turn on.  Do not ask how I came to this, but the startup algorithm after a crash was as follows: <br><br>  1. Remove all disks, turn on the device, turn off the device; <br><br>  2. Insert one disk, turn on the device, turn off the device; 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      3. Insert the second disk, turn on the device, turn off the device; <br><br>  4. Repeat for the third and fourth disc.  After installing the fourth disk, the device turns on and works. <br><br>  The method was published on the Synology forum and it turned out that I am not the only one so lucky.  Since then I prefer small servers with GNU \ Linux on board, they have at least easier diagnostics. </blockquote><p>  From assemblies for NAS I can recommend <a href="http://www.openmediavault.org/">Openmediavault</a> . </p><br><p>  Everything becomes more complicated when you need to increase the disk capacity of existing servers, or there are thoughts about high availability.  This is where the temptation arises to build a full-fledged NAS or go to the other extreme, limiting itself to a simple DAS disk shelf. </p><br><div class="spoiler">  <b class="spoiler_title">A few words about what SAN and DAS are.</b>  <b class="spoiler_title">Just refresh your memory.</b> <div class="spoiler_text"><ul><li><p>  SAN, Storage Area Network is an architectural solution for connecting external storage devices across the network, such as disk arrays and tape libraries.  Moreover, connect at the block level so that the client works with them in the same way as with ordinary local disks.  In the Russian-language literature, the abbreviation SHD (Data Storage Network) is used - do not confuse it with the Data Storage System, which can be any disk shelf. </p><br></li><li>  Direct Attached Storage (DAS) - external disk or disk array connected directly to the server at the block level. </li></ul><br></div></div><br><p>  In this article, I will not touch on software implementations, such as Storage Spaces in a Windows environment, and I will limit myself to the iron and architectural nuances of storage. </p><br><h1 id="zachem-otdelnaya-set-hraneniya">  Why a separate storage network </h1><br><p>  Let's start with typical solutions for data storage, which involve the use of special networks and interfaces, as with them the most questions. </p><br><p>  The most inexpensive way to organize a SAN is the <strong><a href="https://en.wikipedia.org/wiki/Serial_Attached_SCSI">Serial Attached SCSI (SAS)</a></strong> interface.  The one with which the disks are connected in any modern server.  Use SAS and for direct connection of external disk array to the server. </p><br><p>  For a DAS array, it is possible to organize a fault-tolerant connection to several servers.  This is done using <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE%25D0%25BF%25D1%2583%25D1%2582%25D0%25B5%25D0%25B2%25D0%25BE%25D0%25B9_%25D0%25B2%25D0%25B2%25D0%25BE%25D0%25B4-%25D0%25B2%25D1%258B%25D0%25B2%25D0%25BE%25D0%25B4">Multipath</a> , client switching technology and data storage along several routes.  But the most popular is the partitioning of disks between servers, which already independently assemble RAID groups of them and divide them into volumes.  Such a scheme is called "Shared <a href="https://ru.wikipedia.org/wiki/JBOD">JBOD</a> ". </p><br><p>  To connect to the server, adapters (HBAs) for a specific interface are used, which simply allow the OS to see the finished disk volumes. <br><img src="https://habrastorage.org/files/2a7/727/c9d/2a7727c9df034e8d8bc1f0696d0d5556.jpg" alt="image alt text"></p><br><p>  It is worth noting that SAS supports three standards: </p><br><ul><li><p>  SAS-1, at a speed of 3 GB / s per device; </p><br></li><li><p>  SAS-2, at a speed of 6 Gb / s; </p><br></li><li>  SAS-3, providing already 12 Gb / s. </li></ul><br><p>  When planning your architecture, you should also keep in mind the <a href="https://en.wikipedia.org/wiki/Serial_Attached_SCSI">differences in SAS connectors</a> , which often leads to confusion when ordering cables.  The most popular when connecting external equipment are SFF-8088 (mini-SAS) and SFF-8644 (mini-SAS HD). </p><br><p>  As a SCSI part, SAS supports <a href="https://en.wikipedia.org/wiki/Serial_Attached_SCSI">expanders</a> , which allows you to connect up to 65,535 devices to a single controller and port.  Of course, the figure is rather theoretical and does not take into account the various overhead costs.  Most often, there are controllers with a real limitation of 128 disks, but it is not so convenient to scale such a SAN for two or more servers with simple expanders.  As a more adequate alternative, you can use SAS switches.  In fact, these are the same expanders, but with the support of resource allocation among servers, the so-called "zoning".  For example, for the SAS-2 standard, <a href="http://www.avagotech.com/products/server-storage/sas-6160-switch">LSI 6160 is the</a> most popular. </p><br><p><img src="https://habrastorage.org/files/f98/699/fa0/f98699fa01ac4636905d0a5aa7980f81.jpg" alt="image alt text"></p><br><p>  <em>Using SAS switches, it is possible to implement fault-tolerant schemes for multiple servers without a single point of failure.</em> </p><br><p><img src="https://habrastorage.org/files/7f6/1e1/f67/7f61e1f677964fd19865bd67fa1d7243.jpg" alt="image alt text"></p><br><p>  Of the benefits of using SAS include: </p><br><ul><li><p>  Low cost solution; </p><br></li><li><p>  High throughput - even with SAS-2, 24 Gb / s per port of the controller will be obtained; </p><br></li><li>  Low latency. </li></ul><br><p>  Not without drawbacks: </p><br><ul><li><p>  There are no mechanisms for replication by means of disk array; </p><br></li><li>  There is a limitation on the length of the cable segment: a normal copper SAS cable longer than 10 m is not found, an active one is no more than 25 m. There are also <a href="http://www.fci.com/en/products/optical-interconnect/active-optical-cables/minsashd-active-optical-cables.html">optical SAS cables</a> with a limitation of 100 meters, but they are significantly more expensive. </li></ul><br><p>  As a typical solution for small and medium-sized organizations, let's analyze the creation of a small failover cluster of virtual machines.  For the cluster, select two nodes with a single disk array.  As a conditional average volume of a disk volume we choose 1 TB. </p><br><blockquote>  I note that with software solutions like StarWind Native SAN, you can get the same cluster without a separate disk array, or with simple JBOD.  In addition, most hypervisors support NFS or SMB 3.0 network resources as storage.  But in software implementations, there are more nuances and "weak links" due to the greater complexity of the system.  Yes, and performance is usually lower. </blockquote><p>  To build such a system will need: </p><br><ul><li><p>  Two servers; </p><br></li><li><p>  Disk array; </p><br></li><li><p>  HBA for servers; </p><br></li><li>  Connecting cables. </li></ul><br><p>  For example, let's take a disk array as an HP MSA 2040 with twelve bays for HDD.  To connect we will use SAS 3.0 at a speed of 12 Gb / s.  We calculate <a href="http://www.stss.ru/products/hp_storage/HP_MSA_2040/C8R13A.html%3Fconfig%3D">the</a> total cost of the storage system as the first <a href="http://www.stss.ru/products/hp_storage/HP_MSA_2040/C8R13A.html%3Fconfig%3D">configurator</a> : </p><br><table><tbody><tr><td>  Disk shelf HP MSA 2040 </td><td>  360 250 ‚ÇΩ </td></tr><tr><td>  Dual Raid Controller 8x12 Gb SAS </td><td>  554 130 ‚ÇΩ </td></tr><tr><td>  HDD 600GB SAS 12G x4 </td><td>  230 560 ‚ÇΩ </td></tr><tr><td>  Cable mSAS external 2m x4 </td><td>  41 920 ‚ÇΩ </td></tr><tr><td>  HP SmartArray P441 8-external channel SAS 12G x2 </td><td>  189 950 ‚ÇΩ </td></tr><tr><td>  Total </td><td>  1 376 810 ‚ÇΩ </td></tr></tbody></table><br><p>  And here is the wiring diagram: </p><br><p><img src="https://habrastorage.org/files/a09/bd3/6cf/a09bd36cf1c84591873460b7fabc9905.jpg" alt="image alt text"></p><br><p>  <em>Each server will connect to each storage controller for multipathing.</em> </p><br><blockquote>  In my opinion, SAS 3.0 is optimal if you do not need distributed SAN networks and do not require detailed differentiation of access rights to the storage system.  For a small organization, you can achieve an excellent balance between price and performance. </blockquote><p>  After acquiring a second array in the future, it will be possible to connect each server to the controller of each disk shelf, but as the number of clients grows, this will seriously complicate the architecture.  For more clients, it is better to purchase one SAS switch.  Or two, to build a fault-tolerant solution. </p><br><p>  The traditional choice for building a SAN is <strong><a href="https://en.wikipedia.org/wiki/Fibre_Channel">Fiber Channel (FC)</a></strong> , an interface that connects network nodes over an optical fiber. </p><br><p>  FC supports several speeds: from 1 to 128 Gb / s (128GFC standard was released just in 2016).  Mostly used are 4GFC, 8GFC and 16GFC. </p><br><p>  Significant differences compared with SAS-systems are manifested in the design of large SAN: </p><br><ul><li><p>  Expansion is not done at the expense of expanders, but by the capabilities of <a href="https://en.wikipedia.org/wiki/Fibre_Channel">the network topology</a> </p><br></li><li>  The maximum cable length when using single-mode fiber can reach 50 km. </li></ul><br><p>  In small organizations, a single-switch structure is usually used when one server is connected to a disk array through one switch.  Such a scheme is the basis of other topologies: cascade (cascade), lattice (mesh) and ring (ring). </p><br><p>  The most scalable and fault-tolerant scheme is called ‚Äúcore-edge‚Äù (core-edge).  It resembles the well-known ‚Äústar‚Äù network topology, but only in the middle are <em>two</em> central switches that distribute traffic peripherally.  A special case of this scheme is the ‚Äúswitched fabric‚Äù (switched fabric), without peripheral switches. </p><br><p>  When designing you should pay attention to different types of transceivers.  These are special modules that convert a digital signal into an optical signal, for which LEDs or laser emitters are used.  Transceivers support different wavelengths and different optical cables, which affects the length of the segment. </p><br><p>  There are two types of transceivers: </p><br><ul><li><p>  Shortwave (Short Wave, SW, SX) - suitable only for multimode fibers; </p><br></li><li>  Longwave (Long Wave, LW, LX), compatible with multimode and single-mode fiber. </li></ul><br><p> The cable is connected to both types by the LC connector, but the SC connectors are quite rare. </p><br><p><img src="https://habrastorage.org/files/b21/1c2/8e0/b211c28e0b2b4e5db76460b8fb06358b.jpg" alt="image alt text"></p><br><p>  <em>Typical HBA with two FC ports</em> </p><br><blockquote>  When choosing equipment for a SAN, it is not superfluous to check all the components against the iron manufacturer‚Äôs compatibility tables.  Active network equipment is always better to choose a single brand to avoid compatibility problems even in theory - this is standard practice for such systems. </blockquote><p>  The advantages of solutions at FC include: </p><br><ul><li><p>  Ability to build a geographically distributed SAN; </p><br></li><li><p>  Minimum latency; </p><br></li><li><p>  High speed data transfer; </p><br></li><li>  The ability to replicate and create snapshots by disk array. </li></ul><br><p>  On the other side of the scale traditionally lies the cost. </p><br><p>  Storage systems from the SAS section can also be built on the 16GFC, replacing only the HBA and the disk shelf controller.  The cost at the same time will increase to 1 845 790 ‚ÇΩ. </p><br><blockquote>  In my practice, I met at the customer even an FC-based DAS array filled with disks less than half.  Why not use SAS?  The most original answer was: ‚Äúwhat could have been?‚Äù. </blockquote><br><div class="spoiler">  <b class="spoiler_title">A few words about logical ports.</b> <div class="spoiler_text"><p>  In a more complex infrastructure, FC becomes structurally more like TCP / IP.  The protocol also describes the layers, like the TCP \ IP stack, there are routers and switches, even ‚Äútagging‚Äù is described to isolate segments in the manner of a VLAN.  In addition, name resolution and device discovery services are running on FC switches. </p><br><p>  I will not delve into the subtleties, because quite a few <a href="https://habrahabr.ru/post/216369/">good articles</a> have already been written on the topic of FC.  I‚Äôll only pay attention to the fact that when choosing switches and routers for SAN, you need to pay attention to logical types of ports.  Different models support different combinations of basic types from the table: </p><br><table><tbody><tr><td>  Device Type </td><td>  Name </td><td>  Description </td></tr><tr><td>  Server </td><td>  N_Port (Node port) </td><td>  Used to connect to a switch or end device. </td></tr><tr><td></td><td>  NL_Port (Node Loop port) </td><td>  Port with loop topology support. </td></tr><tr><td>  Switch\ <br>  Router </td><td>  F_Port (Fabric port </td><td>  To connect N_Port, "loop" is not supported. </td></tr><tr><td></td><td>  FL_Port (Fabric Loop port), </td><td>  Port with "loop" support. </td></tr><tr><td></td><td>  E_Port (Expansion port </td><td>  Port for connecting switches. </td></tr><tr><td></td><td>  EX_port </td><td>  Port for connecting the switch and router. </td></tr><tr><td></td><td>  TE_port (Trunking Expansion port) </td><td>  E-port with VSAN support. </td></tr><tr><td>  Are common </td><td>  L_Port (Loop port) </td><td>  Any port with loop support (NL_port or FL_port). </td></tr><tr><td></td><td>  G_port (Generic port) </td><td>  Any unused device port with auto detection. </td></tr></tbody></table><br><p><img src="https://habrastorage.org/files/6ca/873/f0d/6ca873f0d90e46fcb2a82ecf54b30b4b.jpg" alt="image alt text"></p></div></div><br><p>  The article would be incomplete without mentioning the option of building a SAN on <strong><a href="https://en.wikipedia.org/wiki/InfiniBand">InfiniBand</a></strong> .  This protocol allows to achieve really high data transfer rates, but at a cost goes far beyond the scope of SMB. </p><br><h1 id="ispolzovanie-privychnogo-ethernet">  Using conventional Ethernet </h1><br><p>  You can do without learning new types of networks using good old Ethernet. </p><br><p>  A popular protocol for creating SANs on Ethernet networks is called the <strong><a href="https://en.wikipedia.org/wiki/Fibre_Channel_over_Ethernet">Internet Small Computer Systems Interface (iSCSI)</a></strong> .  It is built on top of TCP \ IP, and its main plus is in decent work on a regular gigabit network.  In everyday life, such solutions are often called "free SAN".  Of course, gigabit for serious tasks is not enough, and your service network of 10 Gb / s. </p><br><p>  The undoubted advantages include the low cost of basic equipment.  Since iSCSI is implemented by software, you can install the corresponding applications on regular servers.  Most SOHO NAS class supports this protocol initially. </p><br><blockquote>  The customer once sharply faced the question of moving Exchange 2003 from a dying server.  We decided to virtualize it with minimal downtime.  To do this, raised the iSCSI-target on the NAS Synology DS411 from the first part of the article and connected to the Exchange.  Then the database was transferred there and migrated to MS Virtual Server 2005 using disk2vhd.  After a successful migration, the database was moved back.  Later, such operations were carried out during the transition from MS Virtual Server to VMware. </blockquote><p>  Of course, to build a SAN on iSCSI, even if there is enough of a gigabit network for tasks, you should not ‚Äúrelease‚Äù it to a common LAN.  It will work, but broadcast requests and other service traffic will certainly affect the speed and will interfere with users.  It is better to build a separate isolated network with its own equipment.  Or, as a last resort, at least select the subnet with iSCSI in a separate VLAN.  It is worth noting that in order to achieve maximum performance of such systems it is necessary to include support for <strong>Jumbo Frames</strong> throughout the entire packet path. </p><br><p>  As a budget saving measure, the idea of ‚Äã‚Äãmerging gigabit ports using link aggregation ( <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25B3%25D1%2580%25D0%25B5%25D0%25B3%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25BA%25D0%25B0%25D0%25BD%25D0%25B0%25D0%25BB%25D0%25BE%25D0%25B2">LACP</a> ) may arise.  But, as <b>VitalKoshalew</b> correctly noted in the comments, the real balancing between a separate server and storage using LACP will not work.  A better budget solution would be to use Multipath technologies at the top levels of the OSI model. </p><br><p>  By the way, a completely correct iSCSI solution based on a 10 GB network, with hardware acceleration supported by iSCSI network cards and the corresponding switches comes close in cost to FC. </p><br><p><img src="https://habrastorage.org/files/468/2d9/06f/4682d906f04843ba9749c98b90681620.jpg" alt="image alt text"></p><br><p>  <em>Such a network scheme is possible due to the fact that iSCSI runs on top of TCP \ IP.</em> </p><br><p>  Among interesting solutions based on iSCSI, it is possible to note the operation of thin clients <a href="https://habrahabr.ru/post/144290">without a terminal server</a> ‚Äî an iSCSI volume is used instead of local disks.  A gigabit network is quite enough for such work, and it is not so easy to implement something similar by other means. </p><br><p>  Advantages of the solution: </p><br><ul><li><p>  Low cost; </p><br></li><li><p>  The possibility of building a geographically distributed network; </p><br></li><li>  Ease of design and maintenance. </li></ul><br><p>  Minuses: </p><br><ul><li><p>  Delays in accessing data can be significant, especially when working with a pool of virtual machines; </p><br></li><li>  Increased processor load if special HBAs with iSCSI hardware support are not used. </li></ul><br><p>  There is also a more "adult" alternative to iSCSI.  You can use the same Ethernet network, but wrap the storage protocol directly into Ethernet frames, bypassing TCP \ IP.  The protocol is called <strong><a href="https://en.wikipedia.org/wiki/Fibre_Channel_over_Ethernet">Fiber Channel over Ethernet (FCoE)</a></strong> and uses 10 GB Ethernet for operation.  In addition to traditional optics, you can use special copper cables or twisted pair category <strong>6a</strong> . </p><br><p>  An important difference from FC is that the Ethernet port can be used with TCP \ IP.  This requires special network adapters, the so-called Converged Network Adapter (CNA) with FC and FCoE support, although there are software solutions.  Since the protocol runs below the TCP \ IP level, a simple switch will not work.  In addition, there must be support for Jumbo Frames and Data Center Bridging (DCB, sometimes there is Data Center Ethernet).  Such solutions usually cost more (for example, Cisco Nexus series). </p><br><blockquote>  In theory, FCoE can be run in a gigabit network without using DCB, but this is a very extraordinary solution, for which I have not seen stories about successful launches. </blockquote><p>  If you go back to our small but proud virtualization cluster, then for it the 10 Gb / s iSCSI and FCoE solutions will be almost the same in cost, but in the case of iSCSI you can use cheap gigabit networks. </p><br><p>  Also worth mentioning is the rather exotic <strong><a href="https://en.wikipedia.org/wiki/ATA_over_Ethernet">ATA over Ethernet (AoE) protocol</a></strong> , which is similar in its work with FCoE.  Disk arrays with it are rare, software solutions are usually used. </p><br><h1 id="chto-v-itoge">  What is the result </h1><br><p>  The choice of a specific implementation of the storage system requires a thoughtful study of the specific situation.  You should not connect a disk array using FC simply because the "optics" sounds proudly.  A SAS solution will give similar or even greater performance where architecturally appropriate.  If you do not take into account the cost and complexity of the service, the distance between the connections will be a significant difference between all the storage connection technologies described.  This idea is well illustrated by one of the frames of the SNIA presentation: </p><br><p><img src="https://habrastorage.org/files/c4e/ae6/a8e/c4eae6a8ed93466e82ced1db3067e37c.jpg" alt="image alt text"></p><br><p>  If, after reading the article, you want to study the original SAN world in more detail, I can recommend the following bestsellers: </p><br><ul><li><p>  <a href="https://www.brocade.com/content/dam/common/documents/content-types-ru/whitepaper/brocade-san-design-wp-ru.pdf">Brocade - Basics of SAN Design</a> </p><br></li><li><p>  <a href="http://h10032.www1.hp.com/ctg/Manual/c00403562.pdf">HPE SAN Design Reference Guide</a> </p><br></li><li><p>  <a href="https://www.redbooks.ibm.com/redbooks/pdfs/sg245470.pdf">IBM - Introduction to Storage Area Networks</a> </p><br></li><li>  <a href="http://www.netwell.ru/download/documents/techlibrary/25%2520-%2520%25D0%259D%25D0%25B0%25D0%25B8%25D0%25BB%25D1%2583%25D1%2587%25D1%2588%25D0%25B8%25D0%25B5%2520%25D0%25BF%25D1%2580%25D0%25B0%25D0%25BA%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B8%2520%25D0%25BF%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25BE%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F%2520FC%2520SAN.pdf">Best practices for building FC SAN</a> </li></ul><br><p>  <strong>We are thinking over the publication of other articles on server technologies in the "educational program" format, so it would be great to receive feedback from you in the form of an assessment of this material.</strong>  If any topics are especially interesting to you - be sure to tell about them in the comments. </p></div><p>Source: <a href="https://habr.com/ru/post/312648/">https://habr.com/ru/post/312648/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312636/index.html">Any site can get information about which popular services you are authorized in</a></li>
<li><a href="../312638/index.html">Using ES6 generators using the example of koa.js</a></li>
<li><a href="../312640/index.html">How we filtered bots and lowered the bounce rate from 90% to 42%</a></li>
<li><a href="../312642/index.html">Unicode: the necessary practical minimum for each developer</a></li>
<li><a href="../312646/index.html">Anti-pager for paranoiac in Safari</a></li>
<li><a href="../312652/index.html">Creating shared storage based on CEPH RBD and GFS2</a></li>
<li><a href="../312654/index.html">Blockchain decomposition</a></li>
<li><a href="../312656/index.html">Two-factor authentication in Redmine</a></li>
<li><a href="../312658/index.html">Why is it important to check the values ‚Äã‚Äãreturned by the function?</a></li>
<li><a href="../312660/index.html">Free seminar "Operation of the data center: what you need to do yourself", October 27, Moscow</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>