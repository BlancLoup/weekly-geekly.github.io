<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We organize ML-project with the help of Ocean</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 


 Over the years of developing ML and DL projects, our studio has accumulated a large code base, a lot of experience, and interesting i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We organize ML-project with the help of Ocean</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/cz/_r/ya/cz_ryawz8unift6rexjknj69rvo.png" alt="image"></p><br><h2 id="vstuplenie">  Introduction </h2><br><p>  Over the years of developing ML and DL projects, our studio has accumulated a large code base, a lot of experience, and interesting insights and conclusions.  When you start a new project, this useful knowledge helps you more confidently start research, reuse useful methods and get first results faster. </p><br><p>  It is very important that all these materials are not only in the heads of the developers, but also in a readable form on the disk.  This will allow more effectively train new employees, bring them up to date and immerse them in the project. </p><br><p>  Of course, this was not always the case.  We faced a lot of problems in the early stages. </p><br><ul><li>  Each project was organized differently, especially if they were initiated by different people. </li><li>  It was not enough to track what the code is doing, how to run it, and who its author is. </li><li>  They did not use virtualization to the proper degree, often making it difficult for their colleagues to install existing libraries of another version. </li><li>  The conclusions drawn from the charts that had settled and died in the mountain jupyter notebooks were forgotten. </li><li>  Losing reports on the results and progress in the project. </li></ul><br><p>  In order to solve these problems once and for all, we decided that we need to work both on a single and correct project organization, and on virtualization, the abstraction of individual components and the re-use of useful code.  Gradually, all our progress in this area has become an independent framework - Ocean. </p><br><p>  The cherry on the cake is the project logs, which are aggregated and turned into a beautiful website, automatically assembled with the help of a single command. </p><br><p>  In the article we will tell on a small artificial example of what parts Ocean consists of and how to use it. </p><a name="habracut"></a><br><h2 id="pochemu-ocean">  Why Ocean </h2><br><p>  In the ML world there are other options that we considered.  First of all, we need to mention <a href="https://github.com/drivendata/cookiecutter-data-science">cookiecutter-data-science</a> (hereinafter CDS) as the ideological mastermind.  Let's start with a good one: CDS not only offers a convenient project structure, but also tells how to manage a project so that everything is good - so here we recommend digressing and see the main key ideas of this approach <a href="https://drivendata.github.io/cookiecutter-data-science/">in the original CDS article</a> . </p><br><p>  Armed with CDS in the working draft, we immediately introduced several improvements to it: we added a convenient file logger, a coordinating class responsible for project navigation and an automatic generator of Sphinx documentation.  In addition, they brought out several commands in the Makefile, so that even the uninitiated in the details of the project manager would be comfortable with them. </p><br><p>  However, in the process of work, the disadvantages of the CDS approach began to emerge: </p><br><ul><li>  The <strong>data</strong> folder can grow, but which of the scripts or notebooks gives rise to the next file is not completely clear.  A large number of files is easy to get confused.  It is not clear whether, within the framework of the implementation of the new functionality, it is necessary to use some of the existing files, since the description or documentation on their intended purpose is not stored anywhere. </li><li>  In <strong>data,</strong> there is a lack of a <strong>features</strong> subfolder into which attributes can be stored: counted statistics, vectors, and other characteristics from which different final representations of data would be collected.  This is already wonderfully written in a blog post. </li><li>  <strong>src</strong> is another problem folder.  It has functions that are relevant to the entire project, for example, the preparation and cleaning of the <strong>src.data</strong> module <strong>data</strong> .  But there is also the <strong>src.models</strong> module, which contains all the models from all experiments, and there may be dozens of them.  As a result, <strong>src</strong> is updated very often, expanding with very minor changes, and according to the CDS philosophy, after each update, you need to recompile the project, and this is also time ... - well, you understand. </li><li>  <strong>references</strong> is submitted, but there is still an open question: who, when and in what form should the materials be entered there.  And you can tell a lot in the course of the project: what work has been done, what is the result, what are the future plans. </li></ul><br><p>  To solve the above problems in the Ocean presents the following entity: an <em>experiment</em> .  The experiment is the repository of all the data that participated in the testing of some hypothesis.  This could include: what data was used, what data (artifacts) were obtained as a result, the version of the code, the start and end time of the experiment, the executable file, parameters, metrics and logs.  Some of this information can be tracked using special utilities, for example, MLFlow.  However, the structure of the experiments, which is presented in the Ocean, is richer and more flexible. </p><br><p>  The module of one experiment is as follows: </p><br><pre><code class="plaintext hljs">&lt;project_root&gt; ‚îî‚îÄ‚îÄ experiments ‚îú‚îÄ‚îÄ exp-001-Tree-models ‚îÇ ‚îú‚îÄ‚îÄ config &lt;- yaml-   ‚îÇ ‚îú‚îÄ‚îÄ models &lt;-   ‚îÇ ‚îú‚îÄ‚îÄ notebooks &lt;-    ‚îÇ ‚îú‚îÄ‚îÄ scripts &lt;- , , train.py  predict.py ‚îÇ ‚îú‚îÄ‚îÄ Makefile &lt;-      ‚îÇ ‚îú‚îÄ‚îÄ requirements.txt &lt;-    ‚îÇ ‚îî‚îÄ‚îÄ log.md &lt;-    ‚îÇ ‚îú‚îÄ‚îÄ exp-002-Gradient-boosting ...</code> </pre> <br><p>  We share the code base: reusable good code that is relevant to the entire project remains in the <b>src-</b> module of the project level.  It is rarely updated, so you rarely have to build a project.  And the <b>scripts</b> module of one experiment should contain code that is relevant only for the current experiment.  Thus, it can be changed often: it does not affect the work of colleagues in other experiments. </p><br><p>  Consider the possibilities of our framework for example of an abstract ML / DL-project. </p><br><h2 id="workflow-proekta">  Project workflow </h2><br><h3 id="inicializaciya">  Initialization </h3><br><p>  So, the client, the Chicago police, unloaded us with the <a href="https://www.kaggle.com/currie32/crimes-in-chicago/home">data</a> and the task: analyze the crimes committed in the city during 2011-2017 and draw conclusions. </p><br><p>  Getting started!  Go to the terminal and execute the command: </p><br><p> <code>ocean project new -n Crimes</code> </p> <br><p>  The framework has created the corresponding project folder.  We look at its structure: </p><br><pre> <code class="plaintext hljs">crimes ‚îú‚îÄ‚îÄ crimes &lt;- src-   ,    ‚îú‚îÄ‚îÄ config &lt;- ,     ‚îú‚îÄ‚îÄ data &lt;-  ‚îú‚îÄ‚îÄ demos &lt;-    ‚îú‚îÄ‚îÄ docs &lt;- Sphinx- ‚îú‚îÄ‚îÄ experiments &lt;-  ‚îú‚îÄ‚îÄ notebooks &lt;-   EDA ‚îú‚îÄ‚îÄ Makefile &lt;-       ‚îú‚îÄ‚îÄ log.md &lt;-   ‚îú‚îÄ‚îÄ README.md ‚îî‚îÄ‚îÄ setup.py</code> </pre> <br><p>  The <b>Coordinator</b> from the module of the same name, which is already written and ready, helps to navigate through all these folders.  To use it, you need to build a project: </p><br><p> <code>make package</code> </p> <br><blockquote>  <b>This is a bug</b> : if make commands do not want to be executed, then add the -B flag to them, for example, ‚Äúmake -B package‚Äù.  This also applies to all further examples. </blockquote><br><h3 id="logi-i-eksperimenty">  Logs and experiments </h3><br><p>  Getting started with the fact that the data of the client - in our case, the file of <b>crimes.csv</b> , - we put in the <b>data / raw</b> folder. </p><br><p>  The Chicago site has maps of city divisions into <a href="https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74">posts</a> (‚Äúbeats‚Äù - the smallest location, with one patrol vehicle assigned), sectors (‚Äúsectors‚Äù, consist of 3-5 posts), <a href="https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Districts-current-/fthy-xz3r">sections</a> (‚Äúdistricts‚Äù, consist of 3 sectors), <a href="https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Wards-2015-/sp34-6z76">administrative districts</a> (‚Äúwards‚Äù) and, finally, public areas (‚Äúcommunity area‚Äù).  This data can be used for visualization.  At the same time, json-files with coordinates of polygons-sections of each type are not data sent by the customer, so we put them in <b>data / external</b> . </p><br><p>  Next you need to enter the concept of the experiment.  It's simple: we consider a separate task as a separate experiment.  Need to parse / dump data and prepare it for future use?  It is worth putting into the experiment.  Prepare a lot of visualization and reports?  Separate experiment.  Test the hypothesis by preparing the model?  Well, you understand. </p><br><p>  To create our first experiment from the project folder, do the following: </p><br><p> <code>ocean exp new -n Parsing -a ivanov</code> </p> <br><p>  Now a new folder named <b>exp-001-Parsing has</b> appeared in the <b>crimes / experiments</b> folder, its structure is shown above. </p><br><p>  After that, you need to look at the data.  To do this, create a laptop in the appropriate folder <b>notebooks</b> .  In Surf, we stick to the name ‚Äúlaptop number - name‚Äù, and the created laptop will be called <b>001-Parse-data.ipynb</b> .  Inside, we will prepare the data for future work. </p><br><div class="spoiler">  <b class="spoiler_title">Data Preparation Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd pd.options.display.max_columns = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#       : from crimes.coordinator import Coordinator coord = Coordinator() coord.data_raw.contents() &gt; ['/opt/jupyterhub/notebooks/aolferuk/crimes/data/raw/crimes.csv'] #     : df = coord.data_raw.join('crimes.csv').load() df['Date'] = pd.to_datetime(df['Date']) df['Updated On'] = pd.to_datetime(df['Updated On']) df['Location X'] = np.nan df['Location Y'] = np.nan df.loc[df.Location.notnull(), 'Location X'] = df.loc[df.Location.notnull(), 'Location'].apply(lambda x: eval(x)[0]) df.loc[df.Location.notnull(), 'Location Y'] = df.loc[df.Location.notnull(), 'Location'].apply(lambda x: eval(x)[1]) df.drop('Location', axis=1, inplace=True) df['month'] = df.Date.apply(lambda x: x.month) df['day'] = df.Date.apply(lambda x: x.day) df['hour'] = df.Date.apply(lambda x: x.hour) #     : coord.data_interim.join('crimes.pkl').save(df)</span></span></code> </pre> </div></div><br><p>  In order for your colleagues to be aware of what you have done and whether your results can be used by them, you need to comment in the log: <b>log.md</b> file.  The log structure (which is essentially a familiar markdown file) looks like this: </p><br><p><img src="https://habrastorage.org/webt/4g/us/lz/4guslzybw2d55w0nvck2y_q1nyu.png" alt="log.md"></p><br><p>  Color highlighted parts that are filled by hand.  The main meta of the experiment (light plum color) is the author and the explanation of his task, the result to which the experiment goes.  References to data, both taken and generated in the process (green), help to monitor data files and to understand who uses what and why.  In the log itself (yellow color) the result of the work, conclusions and reasoning is described.  All this data will later become the content of the project log site. </p><br><p>  Next is the EDA ( <em>Exploratory Data Analysis</em> ) phase.  Perhaps it will be carried out by different people, and, of course, we will need the results in the form of reports and graphs in consequence.  These arguments are a reason to create a new experiment.  We carry out: </p><br><p> <code>ocean exp new -n Eda -a ivanov</code> </p> <br><p>  In the experiment <b>notebooks</b> folder, create notebook <b>001-EDA.ipynb</b> .  The full code does not make sense, but it is not needed, for example, by your colleagues.  But we need graphics and conclusions.  There is a lot of code in the notebook, and it is not in itself something that I want to show to the client.  Therefore, we will write our findings and insights into the <b>log.md</b> file, and save the graph images in the <b>references</b> . </p><br><p>  Here, for example, a map of the safe areas of Chicago, if fate brings you there: </p><br><p><img src="https://habrastorage.org/webt/0d/gc/yo/0dgcyoulqtdvmgoaclyjjdrd3t8.png" alt="chicagoMap"></p><br><p>  It was just received in a notebook and transferred to <b>references</b> . </p><br><p>  The following entry has been added to the log: </p><br><pre> <code class="plaintext hljs">19.02.2019, 18:15 EDA conclusion: * The most common and widely spread crimes are theft (including burglary), battery and criminal damage done with firearms. * In 1 case out of 4 the suspect will be set free after detention. [!Criminal activity in different beats of the city](references/beats_activity.jpg) Actual exploration you can check in [the notebook](notebooks/001-Eda.ipynb)</code> </pre> <br><p>  Please note: the graph is designed simply as inserting an image into an md file.  And if you leave a link to the notebook, then it will be converted into html-format and saved as a separate page of the site. </p><br><p>  To collect it from the logs of experiments, we execute the following command at the project level: </p><br><p> <code>ocean log new</code> </p> <br><p>  After that a folder of <b>crimes / project_log is created</b> , and <b>index.html</b> in it is the project log. </p><br><blockquote>  <b>This is a bug</b> : when displayed in Jupyter, the site is implemented as an iframe for greater security, and therefore the fonts are not displayed correctly.  Therefore, using Ocean, you can immediately make an archive with a copy of the site, so that it is convenient to download and open it on your local computer or send it by mail.  Like this: <br> <code>ocean log archive [-n NAME] [-p PASSWORD]</code> </blockquote> <br><h3 id="dokumentaciya">  Documentation </h3><br><p>  Let's look at the formation of documentation using Sphinx.  Create a function in the file <b>death / my_cool_module.py</b> and document it.  Please note that Sphinx uses the <a href="http://docutils.sourceforge.net/docs/user/rst/quickref.html">reStructured Text</a> Format (RST): </p><br><div class="spoiler">  <b class="spoiler_title">my_cool_module.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_super_cool_random</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(max_value)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Returns a random number from [0; max_value) interval. Considers the number to be taken from uniform distribution. :param max_value: Maximum value that defines range. :returns: Random number. '''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-comment"><span class="hljs-comment"># Good enough to begin with</span></span></code> </pre> </div></div><br><p>  And then everything is very simple: at the project level, we execute the documentation generation team, and it‚Äôs ready: </p><br><p> <code>ocean docs new</code> </p> <br><blockquote>  <strong>Question from the audience</strong> : Why, if we compiled a project through <code>make</code> , do you have to collect documentation through the <code>ocean</code> ? <br>  <strong>Answer</strong> : the process of generating documentation is not only the execution of a Sphinx command that can be placed in <code>make</code> .  Ocean takes on a scan of your source code directory, builds an index for Sphinx on them, and only then does Sphinx get to work. </blockquote><p>  Ready html documentation is waiting for you along the path of <b>death / docs / _build / html / index.html</b> .  And our module with comments already appeared there: </p><br><p><img src="https://habrastorage.org/webt/j0/fw/dp/j0fwdpya1gqoovqlstlvulpycgq.jpeg" alt="genDoc"></p><br><h3 id="modeli">  Models </h3><br><p>  The next step is to build a model.  We carry out: </p><br><p> <code>ocean exp new -n Model -a ivanov</code> </p> <br><p>  And this time, take a look at what is in the <b>scripts</b> folder inside the experiment.  The <b>train.py</b> file is a template for the future of the learning process.  The file already shows the boilerplate-code, which does several things at once. </p><br><ul><li>  The learning function accepts several file paths: <br><ul><li>  To the configuration file, in which it is reasonable to take out the model parameters, the learning parameters and other options that are conveniently controlled outside, without delving into the code. </li><li>  To the data file. </li><li>  Path to the directory in which you need to save the final dump of the model. </li></ul></li><li>  Tracks metrics obtained in the learning process in <b>mlflow</b> .  You can see everything that has been replayed via mlflow UI by executing the command <code>make dashboard</code> in the experiment folder. </li><li>  Sends an alert to your Telegram that the learning process has been completed.  To implement this mechanism, the <a href="https://alarmerbot.ru/">Alarmerbot</a> bot is <a href="https://alarmerbot.ru/">used</a> .  For this to work, you need to do quite a bit: send the / start command to the bot, and then transfer the token issued by the bot to the file <b>crimes / config / alarm_config.yml</b> .  The string can have the following form: <br> <code>ivanov: a5081d-1b6de6-5f2762</code> </li> <li>  Managed from the console. </li></ul><br><p>  Why manage our script from the console?  Everything is organized so that the process of learning or obtaining predictions of any model is easily organized by a third-party developer who is not familiar with the details of the implementation of your experiment.  In order for all the pieces of the puzzle to come together, after designing <b>train.py,</b> you need to issue a <b>Makefile</b> .  It contains the <b>train</b> command <b>stub</b> , and all you have to do is set the paths to the required configuration files listed above, and in the value of the username parameter, list everyone who wants to receive Telegram notifications.  In particular, the <code>all</code> alias works, which will send an alert to all team members. </p><br><p>  Once everything is ready, our experiment starts using the <code>make train</code> , simple and elegant. </p><br><p>  In case you want to use other people's neural networks, virtual environments ( <b>venv</b> ) will help.  Creating and deleting them as part of an experiment is very easy: </p><br><ul><li>  <code>ocean env new</code> will create a new environment.  It is not only active by default, but also creates an additional kernel (notebook) for notebooks and further research.  It will be called the same as the name of the experiment. </li><li>  <code>ocean env list</code> displays a list of cores. </li><li>  <code>ocean env delete</code> will <code>ocean env delete</code> environment created in the experiment. </li></ul><br><h2 id="chego-ne-hvataet">  What is missing? </h2><br><ul><li>  Ocean is not friendly with conda ( <del>  because we don't use it </del>  ). </li><li>  The project template is in English only. </li><li>  The problem of localization still applies to the site: building a project log assumes that all logs are in English. </li></ul><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  The source code of the project is <a href="https://github.com/surfstudio/ocean-demo">here</a> . </p><br><p>  If you are interested - great!  More information can be found in the README <a href="https://github.com/surfstudio/Ocean">in the Ocean repository</a> . </p><br><p>  And as they usually say in such cases, contributions are welcome, we will only be happy if you participate in improving the project. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/459340/">https://habr.com/ru/post/459340/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../45933/index.html">26.8 million unique internet users per week</a></li>
<li><a href="../459330/index.html">Bitrix for the programmer and manager: love and hate</a></li>
<li><a href="../459334/index.html">YouTrack 2019.2: system-wide banner, improvements to the page with a list of tasks, new search options and more</a></li>
<li><a href="../459336/index.html">Live and learn. Part 1. School and vocational guidance</a></li>
<li><a href="../459338/index.html">Using the verifier as a means of rapid simulation of RTL projects. Introduction to UVM</a></li>
<li><a href="../459342/index.html">Remote cache for iOS, feature toggles, dark themes and developer career - Avito iOS Meetup # 7 report</a></li>
<li><a href="../459344/index.html">DevOps metrics - where to get data for calculations</a></li>
<li><a href="../459346/index.html">Around the World with an e-book: a review of ONYX BOOX James Cook 2</a></li>
<li><a href="../459348/index.html">Another authorization bypass in public Wi-Fi networks</a></li>
<li><a href="../45935/index.html">Expanding a wide table in a column (EAV pattern)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>