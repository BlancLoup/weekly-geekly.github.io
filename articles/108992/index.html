<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>NLP: spell checker - an inside look (part 3)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="( Part 1 , Part 2 ) Last time I mentioned tokenization prematurely; Now you can talk about it, and at the same time about the marking of parts of spee...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>NLP: spell checker - an inside look (part 3)</h1><div class="post__text post__text-html js-mediator-article">  ( <a href="http://habrahabr.ru/blogs/artificial_intelligence/108831/">Part 1</a> , <a href="http://habrahabr.ru/blogs/artificial_intelligence/108923/">Part 2</a> ) Last time I mentioned tokenization prematurely;  Now you can talk about it, and at the same time about the marking of parts of speech (POS tagging). <br><br>  Suppose we have already caught all the errors (which we guessed to catch) at the level of text analysis with regular expressions.  So, it is time to move on to the next level, at which we will work with individual words of the sentence.  Tokenization module deals with words.  Even in such a simple task there are pitfalls.  I'm not even talking about languages ‚Äã‚Äãlike Chinese and Japanese, where even isolating individual words of a text is nontrivial (the hieroglyphs are written without spaces);  in English or in Russian, too, there is something to think about.  For example, is a dot in a shorthand or is it a separate token?  ("Other" - is it one token or two?) And the name of a person?  "JS Smith" - how many tokens are there?  Of course, a volitional decision can be made on each item, but in the future it can lead to various consequences, and this must be borne in mind. <br><br>  Something like this, I argued at the initial stages of our project, but now I tend to think that in word processing tasks I often have to obey the decisions of other people.  This will be clear on the example of marking parts of speech. <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  Marking of parts of speech </h1>  Knowing the division of sentences into words, you can already search through the text frequently encountered typos.  For example, to ship ‚Äúegg yoke‚Äù to ‚Äúegg yolk‚Äù (this typo seems to be so popular that <a href="http://en.wiktionary.org/wiki/egg_yoke">Wikipedia</a> even <a href="http://en.wiktionary.org/wiki/egg_yoke">mentions it</a> ).  But the real progress in comparison with regular expressions is provided by marking parts of speech, that is, by matching each word of the text of its part of speech: <br><br>  ‚ÄúI love big dogs.‚Äù -&gt; ‚ÄúI_PRP love_VBP big_JJ dogs_NNS ._.‚Äù <br><br>  In this example, the following markers are used: PRP - pronoun;  VBP is the verb of the present tense, the only person, not the third number;  JJ is an adjective;  NNS is a plural noun.  Well, the point - it's just a point. <br><br>  Knowing the parts of the speech of individual words, one can formulate more complex patterns of errors.  For example, ‚ÄúDT from‚Äù -&gt; ‚ÄúDT form‚Äù.  The token DT stands for ‚Äúdefining word‚Äù - an article or pointers like this / that.  If in the text there is a combination of ‚Äúthe from‚Äù or ‚Äúthis from‚Äù, most likely, this is a typo, and it meant not the preposition from, but ‚Äúform‚Äù - form.  It can be even trickier: ‚ÄúMD know VB‚Äù -&gt; ‚ÄúMD now VB‚Äù.  Here there is a catching typo ‚Äúknow instead of now‚Äù - the pattern ‚Äúmodal verb + know + verb‚Äù.  Under it falls, say, the phrase "I can know say something more." <br><br>  Of course, it is not difficult to implement simple operations such as ‚Äúor‚Äù (‚Äúif this or that has met‚Äù) and denial (‚Äúthis is not met‚Äù).  It is on such expressions that the already mentioned <a href="http://www.languagetool.org/">LanguageTool</a> system works.  Since it is distributed under the LGPL license, I decided to transfer all its rules to our system.  Why not?  People have done a great job, it would be foolish not to use the results, if allowed.  We will talk about the limitations of this approach, but for now let us return to the marking of parts of speech. <br><br>  The most popular method of POS-marking today is reduced to the same task of classification, this time in its full version.  We give the input to the learning algorithm a word and its context ‚Äî usually the initial and final characters of the word, as well as data about the previous words of the sentence ‚Äî these words themselves and their corresponding parts of speech.  We also report a part of the speech of the word in the current context, and the algorithm remembers this information.  If we now give the input a context, the algorithm will be able to make a reasonable guess about a part of speech. <br><br>  Here, too, often use the model of maximum entropy.  Although you could play with other algorithms.  For example, there is a development based on support vector machines ( <a href="http://www.lsi.upc.edu/~nlp/SVMTool/">SVMTool</a> ). <br><br><h1>  Annotated corpses, great and terrible </h1>  Last time I didn‚Äôt focus on this, but now it‚Äôs time to go.  In order for the POS tagger to work, it needs to be trained on a large collection of texts, where each word is assigned a tag of a part of speech.  Then a reasonable question arises: where is this collection to take? <br><br>  Such collections (‚Äúannotated corps‚Äù) exist, although there are not so many of them.  POS-marking is most common, less often - deep annotation, that is, marking of syntactic-semantic links between words in a sentence.  The largest deeply annotated corpus of English is called <a href="http://www.cis.upenn.edu/~treebank/">Penn Treebank</a> and contains almost three million words.  Good buildings also exist for German and Russian - this is one of those that I personally studied. <br><br>  Now think about this.  There are subtleties about which different linguists have different opinions.  For example, how many cases in Russian?  The student‚Äôs answer is six, but I can name at least eight or nine.  In English, what part of speech is the word book combined book market?  I would say that this is an adjective, but one can defend the interpretation as ‚Äúa noun in the role of an adjective.‚Äù <br><br>  Thus, it is possible to mark the text in different ways, based on any linguistic or practical considerations.  Unfortunately, our considerations are unlikely to be embodied in the final system, for using a ready-made corpus, we are forced to accept the rules of the game of its developers.  If I train the POS tagger on the Penn Treebank case, I have to accept that ‚Äúbook‚Äù is still treated as an adjective as a noun.  Who does not like - can create their own body and mark it at their discretion. <br><br>  Similarly, in Penn Treebank, the punctuation mark is always a separate token, so the entry ‚Äúetc.‚Äù is two tokens, and ‚ÄúJS Smith‚Äù is five tokens, even if this agreement is inconvenient for me.  No choice.  This is, by the way, on the issue of the presence of linguists in the project.  If I had unlimited budgets and a lot of time, I could try to make my own system, embodying our views on spelling.  However, in real conditions, the existing NLP tools and text boxes direct actions along a fairly clear route, leaving not too much room for imagination. <br><br>  Yes, another comment.  Naturally, ready-made collections contain correct texts, devoid of obvious grammatical errors.  What does this mean for us?  Well, take the same POS tagger.  First, we train him on correct texts (where he never sees combinations like ‚ÄúI has‚Äù), and then we use it to mark words in texts with errors.  Will he be as good in the new environment?  But who knows him;  but building a casing with typical mistakes for the sake of training a scriber is too much luxury for us. <br><br>  We continue in the next section. </div><p>Source: <a href="https://habr.com/ru/post/108992/">https://habr.com/ru/post/108992/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../108977/index.html">Potentially unsafe Dropbox behavior</a></li>
<li><a href="../108978/index.html">NAT on Cisco. Part 2</a></li>
<li><a href="../108984/index.html">"Black Friday" Kindle 2 for $ 89 broke up on Amazon in a few seconds</a></li>
<li><a href="../108985/index.html">Comments in the code - useful, senseless, harmful?</a></li>
<li><a href="../108990/index.html">Import views from module</a></li>
<li><a href="../108993/index.html">Important aspects of the RESTful API for your project</a></li>
<li><a href="../108997/index.html">VMware and Cisco - VDI-friends forever</a></li>
<li><a href="../108998/index.html">Citrix XenVault: corporate safe in user environment</a></li>
<li><a href="../109000/index.html">What to look for when buying a tablet</a></li>
<li><a href="../109004/index.html">Social startup ‚ÄúGrandma-Online‚Äù - results, thanks, and plans for the future</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>