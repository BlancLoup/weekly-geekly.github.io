<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep learning to determine the style and genre of paintings</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! 


 Today I want to talk about the second part of the service project for the identification and classification of works of art. Let me remi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep learning to determine the style and genre of paintings</h1><div class="post__text post__text-html js-mediator-article"><p>  Hi, Habr! </p><br><p>  Today I want to talk about the second part of the service project for the identification and classification of works of art.  Let me remind you that we solved two main tasks: </p><br><ol><li>  <a href="https://habr.com/company/singularis/blog/421187/">search for a picture in the database of a photo taken by a mobile phone;</a> </li><li>  definition of the style and genre of the picture, which is not in the database. </li></ol><br><p>  Today we will consider the use of a convolutional neural network to classify images by style and genre. </p><br><img src="https://habrastorage.org/webt/r3/ef/sj/r3efsjaeruoyzjzbsxzcprq7owk.jpeg"><br><p>  Let's help Dasha understand modern art? </p><a name="habracut"></a><br><h2>  Definition of the style of paintings </h2><br><p>  Of the nearly 250,000 paintings in the <a href="https://artchive.ru/">Arthive database,</a> less than 20% is assigned a genre, style or technique, often the classes exhibited in the database do not correspond to the true values, many classes contain too few images.  It seems there are even classes containing units of images.  Apparently, some authors consider it necessary to create a name for their own style. <br><br>  In total, about 75 styles were allocated in the database, however, for our work, the customer selected 27 mandatory styles (to which one more was later added), which the system must necessarily recognize. <br><br>  According to them, the distribution of filling was very uneven. </p><br><table><thead><tr><th>  Style </th><th>  qty </th><th>  Style </th><th>  qty </th></tr></thead><tbody><tr><td>  Realism </td><td>  19594 </td><td>  Primitivism </td><td>  1234 </td></tr><tr><td>  Impressionism </td><td>  15864 </td><td>  Art Deco </td><td>  1092 </td></tr><tr><td>  Romanticism </td><td>  8963 </td><td>  Northern Renaissance </td><td>  921 </td></tr><tr><td>  Baroque </td><td>  7726 </td><td>  Cubism </td><td>  902 </td></tr><tr><td>  Modern </td><td>  4882 </td><td>  Academism </td><td>  707 </td></tr><tr><td>  Surrealism </td><td>  4793 </td><td>  Gothic </td><td>  608 </td></tr><tr><td>  Revival </td><td>  4709 </td><td>  Modernism </td><td>  539 </td></tr><tr><td>  Expressionism </td><td>  4329 </td><td>  Social realism </td><td>  481 </td></tr><tr><td>  Symbolism </td><td>  4321 </td><td>  Pop Art </td><td>  475 </td></tr><tr><td>  Post-impressionism </td><td>  3951 </td><td>  Pointillism </td><td>  275 </td></tr><tr><td>  Abstractionism </td><td>  3664 </td><td>  Fauvism </td><td>  217 </td></tr><tr><td>  Ukie-e </td><td>  3136 </td><td>  Avant-garde </td><td>  174 </td></tr><tr><td>  Classicism </td><td>  1730 </td><td>  Hyperrealism </td><td>  13 </td></tr><tr><td>  Rococo </td><td>  1600 </td><td>  Fantasy </td><td>  eight </td></tr><tr><td></td><td></td><td>  <strong><em>Total</em></strong> </td><td>  96908 </td></tr></tbody></table><br><div class="spoiler">  <b class="spoiler_title">All styles</b> <div class="spoiler_text"><table><thead><tr><th>  Style </th><th>  qty </th><th>  Style </th><th>  qty </th><th>  Style </th><th>  qty </th></tr></thead><tbody><tr><td>  <strong>Realism</strong> </td><td>  19594 </td><td>  <strong>Pop Art</strong> </td><td>  475 </td><td>  Decorative art </td><td>  66 </td></tr><tr><td>  <strong>Impressionism</strong> </td><td>  15864 </td><td>  Biedermeier </td><td>  471 </td><td>  Minimalism </td><td>  66 </td></tr><tr><td>  <strong>Romanticism</strong> </td><td>  8963 </td><td>  Fantastic realism </td><td>  386 </td><td>  Sentimentalism </td><td>  66 </td></tr><tr><td>  <strong>Baroque</strong> </td><td>  7726 </td><td>  Abstract expressionism </td><td>  358 </td><td>  Cloisonianism </td><td>  60 </td></tr><tr><td>  <strong>Modern</strong> </td><td>  4882 </td><td>  Nabi </td><td>  339 </td><td>  Metaphysical painting </td><td>  56 </td></tr><tr><td>  <strong>Surrealism</strong> </td><td>  4793 </td><td>  <strong>Pointillism</strong> </td><td>  275 </td><td>  Mccchioli </td><td>  52 </td></tr><tr><td>  <strong>Revival</strong> </td><td>  4709 </td><td>  Suprematism </td><td>  273 </td><td>  Orphism </td><td>  51 </td></tr><tr><td>  <strong>Expressionism</strong> </td><td>  4329 </td><td>  Pre-Raphaelites </td><td>  252 </td><td>  Dadaism </td><td>  50 </td></tr><tr><td>  <strong>Symbolism</strong> </td><td>  4321 </td><td>  Magical realism </td><td>  248 </td><td>  Neoimpressionism </td><td>  49 </td></tr><tr><td>  <strong>Post-impressionism</strong> </td><td>  3951 </td><td>  Early Renaissance </td><td>  232 </td><td>  Luminism </td><td>  41 </td></tr><tr><td>  <strong>Abstractionism</strong> </td><td>  3664 </td><td>  Neo-expressionism </td><td>  230 </td><td>  Proto-renaissance </td><td>  39 </td></tr><tr><td>  The Golden Age of Holland </td><td>  3292 </td><td>  <strong>Fauvism</strong> </td><td>  217 </td><td>  Plentanism </td><td>  37 </td></tr><tr><td>  <strong>Ukie-e</strong> </td><td>  3136 </td><td>  Postmodernism </td><td>  192 </td><td>  Tenebrizm </td><td>  35 </td></tr><tr><td>  <strong>Classicism</strong> </td><td>  1730 </td><td>  <strong>Avant-garde</strong> </td><td>  174 </td><td>  Abstract impressionism </td><td>  34 </td></tr><tr><td>  <strong>Rococo</strong> </td><td>  1600 </td><td>  Modern Art </td><td>  149 </td><td>  Conceptualism </td><td>  29 </td></tr><tr><td>  <strong>Primitivism</strong> </td><td>  1234 </td><td>  Precisionism </td><td>  138 </td><td>  Japonism </td><td>  24 </td></tr><tr><td>  <strong>Art Deco</strong> </td><td>  1092 </td><td>  Cubofuturism </td><td>  108 </td><td>  Postmodern </td><td>  24 </td></tr><tr><td>  <strong>Northern Renaissance</strong> </td><td>  921 </td><td>  Constructivism </td><td>  104 </td><td>  Luchism </td><td>  24 </td></tr><tr><td>  <strong>Cubism</strong> </td><td>  902 </td><td>  Tonalism </td><td>  103 </td><td>  Byzantine </td><td>  20 </td></tr><tr><td>  <strong>Academism</strong> </td><td>  707 </td><td>  Orphism </td><td>  94 </td><td>  Romantic realism </td><td>  nineteen </td></tr><tr><td>  <strong>Gothic</strong> </td><td>  608 </td><td>  Regionalism </td><td>  93 </td><td>  <strong>Hyperrealism</strong> </td><td>  13 </td></tr><tr><td>  Neoclassicism </td><td>  601 </td><td>  Analytical realism </td><td>  89 </td><td>  Verism </td><td>  eleven </td></tr><tr><td>  Mannerism </td><td>  544 </td><td>  Naturalism </td><td>  73 </td><td>  Neo-primitivism </td><td>  ten </td></tr><tr><td>  <strong>Modernism</strong> </td><td>  539 </td><td>  Neo-modernism </td><td>  70 </td><td>  <strong>Fantasy</strong> </td><td>  eight </td></tr><tr><td>  <strong>Social realism</strong> </td><td>  481 </td><td>  Futurism </td><td>  67 </td><td>  Metarealism </td><td>  7 </td></tr><tr><td></td><td></td><td></td><td></td><td>  <strong><em>Total</em></strong> </td><td>  106284 </td></tr></tbody></table><br></div></div><br><p>  We are faced with the task of classifying images, but we cannot select some simple signs manually.  So, we will use deep machine learning, in which such complex features are automatically highlighted in the learning process. </p>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  Transfer learning </h1><br><p>  Consider the inception v3 network. </p><br><br><img src="https://habrastorage.org/webt/f3/pe/md/f3pemdvtfg6ryjjok5v1tr3ae6m.png" alt="General architecture with intermediate outputs"><br><br><p>  In its architecture (and in any other deep network) we can conditionally distinguish two main components - Feature Extractor and Predictor. <br><br>  Feature Extractor displays the input color images in a multi-dimensional feature space (multi-channel feature map).  The attribute map saves spatial information ‚Äî that is, it is a three-dimensional tensor with dimensions along the width, height, and number of feature channels; the final pooling has not yet been applied, which completely eliminates the information about the relative position of the features in the original image.  Feature Inventor v3 Network Extractor receives a 299 image as input <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.437ex" height="1.937ex" viewBox="0 -728.2 2771.5 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-69" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-6D" x="957" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-65" x="1835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-73" x="2302" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ times </script>  299 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.437ex" height="1.937ex" viewBox="0 -728.2 2771.5 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-69" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-6D" x="957" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-65" x="1835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-73" x="2302" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-2"> \ times </script>  3, and on output forms a feature map of size 17 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.437ex" height="1.937ex" viewBox="0 -728.2 2771.5 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-69" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-6D" x="957" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-65" x="1835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-73" x="2302" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ times </script>  17 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.437ex" height="1.937ex" viewBox="0 -728.2 2771.5 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-69" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-6D" x="957" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-65" x="1835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/singularis/blog/422357/&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhAe7Uyzd-2aphWb1_nbJnpZV8iGw#MJMATHI-73" x="2302" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ times </script>  2048. The size of the input can be varied, which will lead to changes in the size of the map of signs and can be useful to reduce the computational cost when working with a network. <br><br>  A Predictor is a network that generates output data based on a feature map formed by Feature Extractor.  As a rule, for the classification problem, the Predictor is a fully connected layer of neurons, the number of outputs of which coincides with the number of classes of the problem. <br><br>  Classical transfer learning assumes that we take a trained network, separate the Extract Extractor from it, and supplement it with a new predictor with the number of classes we need.  The resulting network is trained at low speed with partially or completely frozen scales of the Extract Extractor layers. </p><br><p>  Apply transfer learning to classify styles.  Take the Inception-v3 network trained on the imagenet dataset and replace the neuron output layer in it, which classifies the input images into the number of selected styles.  We trained the resulting network on images of different styles, freezing the training of all layers except the last. </p><br><p>  To analyze the data, we displayed the distribution of the validation set by classes. <br><br><img src="https://habrastorage.org/webt/dj/rq/-9/djrq-9odlvd6uudi_9eofw7ufl4.jpeg"><br><br>  Each line corresponds to a class from the validation set.  The brightness of the squares in the row is proportional to the number of pictures that fall into the class corresponding to the column. <br><br>  For better clarity, exclude the main diagonal and re-normalize the values ‚Äã‚Äãof each row. <br><br><img src="https://habrastorage.org/webt/tf/ch/oz/tfchozlbdfigafnapiq7dtbs53u.jpeg"><br><br>  In addition, we will try to map the distribution by style onto a two-dimensional space using TSNE. <br><br><img src="https://habrastorage.org/webt/v1/dq/bt/v1dqbtf7whkh1occcwdxp_cprcu.png"></p><br><p>  It can be seen that a lot of mistakes are observed, for example, when classifying paintings in the style of Fauvism - a significant part of them belong to expressionism as a network.  Northern Renaissance and Gothic often refer to Renaissance.  Many images of the Rococo style and classicism are related to realism.  Modernism and modern generally break up into many styles. </p><br><p>  Throwing a simple script that sorted out the training base by folders in accordance with the style defined by the network, we conducted a brief analysis of errors.  It turned out that the base markup at least raises questions. <br><br>  Many images in the style of modernism (which, although the customer noted as mandatory, but in general is not a style, but rather a direction in art as a whole) were actually duplicated in other styles, especially in modernity (and this is already a style). </p><br><p>  In the style of socialist realism there were abstract images, for example, works by Lissitzky.  Apparently, they got there thanks to the work of Lissitzky on the Soviet poster, which is very indirectly related to social realism. </p><br><p>  In many respects, these are really mistakes, but sometimes the reason is the debatable nature of highlighting some, especially modern styles.  It should be borne in mind that the base is filled with various users, and among them sometimes there is no consensus. <br><br>  Errors in the data lead to corresponding network image classification errors.  In the process of cleaning the base, both by us and by an expert art critic on the part of the customer, the marking for the training set has been significantly improved. </p><br><p>  However, the majority of network classification errors (by total) are related to more or less well-established styles, such as rococo, classicism, realism.  The attribution of works to these styles, as a rule, occurs on the basis of an epoch or authorship, and it seems that there is no doubt or controversy.  Why is the network unable to distinguish their style?  The main reason is the use of a pre-trained network to extract features. </p><br><p>  The point is that this network was trained to classify objects, determine what exactly is depicted, while discarding information that is not essential for the task about how it is depicted.  For example, from the point of view of the network, in all the images at the beginning of the article, in general, a person is depicted. </p><br><p>  To solve this problem, we made a network with intermediate outputs - it is believed that the signs become more and more difficult as they move along the network, and irrelevant information disappears gradually.  We will try to extract from the intermediate layers what was irrelevant for imagenet classification. </p><br><br><img src="https://habrastorage.org/webt/yl/iw/ut/yliwutsxjouveu2g4k8ojxk7qwg.png" alt="General architecture with intermediate outputs"><br><p>  There is another problem - graphics, prints, sketches.  In imagenet, on which the inception network was pre-trained, there is simply nothing of the kind, and, accordingly, the features distinguished by the network are not suitable for classifying such images. </p><br><br><table><tbody><tr><td align="center"> <a href="https://artchive.ru/artists/710~Kamil_Koro/works/5765~Agar_i_angel"><img src="https://habrastorage.org/webt/hk/5c/sf/hk5csf3ivfa2yc8cperdjnrk50u.jpeg"><br></a> <br></td><td align="center"><a href="https://artchive.ru/artists/256~Rembrandt_Kharmens_van_Rejn/works/18403~Agar_i_angel"><img src="https://habrastorage.org/webt/1u/4b/ng/1u4bngyrvbacxvb-ue-7shvhkky.jpeg"><br></a> <br></td></tr><tr><td align="center">  <a href="https://artchive.ru/artists/710~Kamil_Koro/works/5765~Agar_i_angel">Realism, Impressionism.</a> <a href="https://artchive.ru/artists/710~Kamil_Koro/works/5765~Agar_i_angel"><br><br></a>  <a href="https://artchive.ru/artists/710~Kamil_Koro/works/5765~Agar_i_angel">Camille Caro, Hagar and the Angel</a> <a href="https://artchive.ru/artists/710~Kamil_Koro/works/5765~Agar_i_angel"><br></a> <br></td><td align="center">  <a href="https://artchive.ru/artists/256~Rembrandt_Kharmens_van_Rejn/works/18403~Agar_i_angel">Baroque</a> <a href="https://artchive.ru/artists/256~Rembrandt_Kharmens_van_Rejn/works/18403~Agar_i_angel"><br></a>  <a href="https://artchive.ru/artists/256~Rembrandt_Kharmens_van_Rejn/works/18403~Agar_i_angel">Rembrandt Harmens van Rhine, Hagar and the Angel</a> <a href="https://artchive.ru/artists/256~Rembrandt_Kharmens_van_Rejn/works/18403~Agar_i_angel"><br></a> <br></td></tr></tbody></table><br><p>  On the other hand, beautifully hung as a separate cloud of the <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BA%25D0%25B8%25D1%2591-%25D1%258D">Ukye-e-</a> style <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BA%25D0%25B8%25D1%2591-%25D1%258D">painting</a> is a kind of engraving that has become widespread in Japan since the 17th century.  Although initially they were not on our mandatory list, we added them there. </p><br><br> <a href="https://artchive.ru/artists/2677~Utagava_Khirosige/works/326145~Risovye_polja_Asakusa_i_festival_Torinomachi_Serija_100_znamenitykh_vidov_Edo"><img src="https://habrastorage.org/webt/ub/xz/fq/ubxzfqqe_iut0ljlbu1uab_0mey.jpeg" alt="Asakus rice fields and the Torinomachi festival"><br></a> <br><br><p>  After working with data, it was possible to achieve a better distribution of classes. </p><br><h2>  We understand the genres </h2><br><p>  Of the total number of genres, 13 were selected (bold) </p><br><table><thead><tr><th>  Genre </th><th>  qty </th></tr></thead><tbody><tr><td>  Allegorical scene </td><td>  2500 </td></tr><tr><td>  <strong>Portrait</strong> </td><td>  2308 </td></tr><tr><td>  <strong>Landscape</strong> </td><td>  2213 </td></tr><tr><td>  Fantasy </td><td>  2191 </td></tr><tr><td>  Literary scene </td><td>  2096 </td></tr><tr><td>  <strong>Cityscape</strong> </td><td>  2048 </td></tr><tr><td>  <strong>Nu</strong> </td><td>  1981 </td></tr><tr><td>  <strong>Still life</strong> </td><td>  1932 </td></tr><tr><td>  <strong>Genre scene</strong> </td><td>  1736 </td></tr><tr><td>  <strong>Animalism</strong> </td><td>  1587 </td></tr><tr><td>  Religious scene </td><td>  1417 </td></tr><tr><td>  Mythological scene </td><td>  1368 </td></tr><tr><td>  <strong>Marina</strong> </td><td>  1210 </td></tr><tr><td>  Architecture </td><td>  958 </td></tr><tr><td>  <strong>Interior</strong> </td><td>  635 </td></tr><tr><td>  Historical scene </td><td>  534 </td></tr><tr><td>  <strong>Battle scene</strong> </td><td>  201 </td></tr><tr><td>  <strong>Zakli</strong> </td><td>  180 </td></tr><tr><td>  <strong>Lead</strong> </td><td>  124 </td></tr><tr><td>  Urban landscape </td><td>  sixteen </td></tr><tr><td>  <strong><em>Total</em></strong> </td><td>  27235 </td></tr></tbody></table><br><p>  Basically, the reduction in the number of genres has been achieved by reducing the genres of various scenes - "religious", "mythological", "allegorical", "literary" and combining them under the common name "genre scene".  We came to the conclusion that the separation of these genres can hardly be done with sufficient accuracy without significant cultural analysis. <br><br>  For example, for an allegorical scene, by definition, it is assumed that there is a hidden meaning in the image, the use of the figurative meaning of the objects depicted.  There is a difficulty with the "religious scene": it is very likely that the network trained to issue such a class will call them caricature images (for example, parodying the "Last Supper" da Vinci), and this may offend someone . </p><br><p>  The layout of data by genres initially seems to be quite good, except for several genres for which there are few images in the database.  Searching on the Internet, we were able to slightly expand the number of images in the genres (mainly the battle scene, twists and vedutas). <br>  After combining difficult genres into a common "genre scene", we immediately tried to educate the network head-on using the inception transfer learning network. </p><br><p><img src="https://habrastorage.org/webt/tk/af/n4/tkafn43bprvet-oqzwi-2sg4t60.jpeg" alt="Genres, result 1"></p><br><p>  It is seen that the points corresponding to images of different genres are mixed.  For these images, the network gives high values ‚Äã‚Äãof the probabilities of belonging to several genres at once, and the genre is most likely determined almost randomly.  The reason seems to be that genres, unlike styles, have a more pronounced hierarchy.  We tried to understand these links, we got such a map of genres: </p><br><p> <a href=""><br><img src="https://habrastorage.org/webt/wj/up/d4/wjupd4h-6mczoz_zo39rqscslpe.jpeg" alt="Hierarchy of genres"></a> </p><br><p>  Child and parental hierarchy genres often have common features from a network point of view (and from our point of view, too).  For example, a battle scene on land as a whole has the same characteristics as an ordinary landscape - an image of a large open area or city, and a battle scene at sea looks more like a marina genre.  Therefore, we have divided the battle scene genre into two - on land and at sea.  Another example: portraits, genre scenes and nudes from the point of view of the pre-trained network all have a common feature - the presence of people. </p><br><p>  In a database, pictures of similar content often refer either to a child or to a parent genre, depending on where it was determined by the expert who contributed the pictures to the database.  In this regard, a large-scale cleaning and redevelopment of the base was carried out taking into account the possible hierarchy of genres, which took a lot of effort (we managed to automate it, but not much). </p><br><p>  In order to transfer the hierarchy of genres to the network, we abandoned the one-hot presentation and set a unit for images not only in one genre, but also in its parent, if there is one, and also replaced the target function of the learning process and the output layer activation function .  Thus, the task became the Multilabel classification (the input image can belong to several classes). </p><br><p><img src="https://habrastorage.org/webt/0k/k9/fo/0kk9foqusebcdte0pcmm11nw0ya.jpeg"></p><br><p>  It seems to us that there is not enough of another genre here - abstraction.  Strictly speaking, it is not exactly a genre.  At least the experts insisted that there was no such genre.  In order for the network not to give random images to abstract images, another one was added to the general division of genres called ‚Äúfailed to identify‚Äù, including abstract and controversial images. </p><br><h2>  Instead of conclusion </h2><br><p>  In general, it was possible to achieve a satisfactory classification accuracy of styles and genres of images, but there is much to improve. </p><br><p>  Unfortunately, the classification of styles and techniques was not completed - the service support was not implemented. </p></div><p>Source: <a href="https://habr.com/ru/post/422357/">https://habr.com/ru/post/422357/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422345/index.html">Server in the clouds: the results of the project</a></li>
<li><a href="../422347/index.html">Migrating a real-world application from standalone MySQL to Percona XtraDB Cluster</a></li>
<li><a href="../422351/index.html">Remote code execution via uploading pictures on your server or local computer to ghostscript / imagick</a></li>
<li><a href="../422353/index.html">Instructions for working with TensorFlow Object Detection API</a></li>
<li><a href="../422355/index.html">Games with time: we accelerate the application at the level of perception</a></li>
<li><a href="../422359/index.html">The results of the quest that you have passed. Or not</a></li>
<li><a href="../422361/index.html">Corporate Syndrome</a></li>
<li><a href="../422363/index.html">Conference PyCon Russia 2018: video of all reports and presentations</a></li>
<li><a href="../422365/index.html">"Yandex" filed a complaint against the court decision to remove links to pirated content</a></li>
<li><a href="../422367/index.html">How to restore video for Full Throttle Remastered. Part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>