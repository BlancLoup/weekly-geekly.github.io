<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>I need to raise the Kubernetes cluster, but I'm just a code programmer. There is an exit</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day. Another note from my experience. This time, it‚Äôs superficially about the basic infrastructure that I use if I need to unload something, and ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>I need to raise the Kubernetes cluster, but I'm just a code programmer. There is an exit</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/j9/qc/fb/j9qcfbdq_raamw7rwyt02ci1an8.png"><br><br>  Good day.  Another note from my experience.  This time, it‚Äôs superficially about the basic infrastructure that I use if I need to unload something, and there are no <b>devOps around</b> .  But the current level of abstraction, in technology, has been allowing for about a year to live with this infrastructure, raised overnight, using the Internet and ready-made things. <br><br>  Keywords - <b>AWS</b> + <b>Terraform</b> + <b>kops</b> .  If it is useful to me, it may be useful to someone else.  Welcome to the comments. <br><a name="habracut"></a><br><h2>  -one.  What we're dealing with </h2><br>  The classic situation is that the project has been written to the stage when it is necessary to unload it somewhere and start using it.  And the project is more complicated than a simple html page.  I would like the possibility of horizontal scaling, the identity of the environment on the local, test, prod stands and a more or less normal deployment process. <br><blockquote>  It's about the app on <b>Laravel</b> , to show the whole process from beginning to end.  But in the same way, you can deploy a scattering of services on go, python applications, small sites on WP, html pages and much more.  This is enough to some level, and then a separate person appears in the team, who will improve and complement it. </blockquote>  Last time, I came to the <b>conclusion</b> that on local machines I install <b>GoLand, PhpStorm, Docker, Git</b> and are completely ready for work.  Yes, and manage from one machine, you can scatter clusters, so the whole process will be described without taking into account the OS on which you work, packing all things in a docker container. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  0. Getting ready for work. </h2><br>  Let's imagine that we have already registered an account on <b>AWS</b> , asked through technical support to increase the account limits for the number of simultaneously running servers, created the <b>IAM</b> user and now we have the <b>Access Key</b> + <b>Secret Key</b> .  The zone is <b>us-east-1</b> . <br><br>  What do we need on the local computer?  <b>AWS CLI</b> , <b>Terraform</b> for declarative management of <b>AWS</b> , <b>kubectl</b> , <b>kops</b> for setting up a cluster and <b>Helm</b> , for deploying some services.  We collect <b>Dockerfile</b> (which I have long found somewhere in the githabra, but I can not find where).  We write our <b>docker-compose.yml</b> for mount directories and a <b>Makefile</b> for aliases. <br><br><div class="spoiler">  <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre><code class="plaintext hljs">FROM ubuntu:16.04 ARG AWSCLI_VERSION=1.12.1 ARG HELM_VERSION=2.8.2 ARG ISTIO_VERSION=0.6.0 ARG KOPS_VERSION=1.9.0 ARG KUBECTL_VERSION=1.10.1 ARG TERRAFORM_VERSION=0.11.0 # Install generally useful things RUN apt-get update \ &amp;&amp; apt-get -y --force-yes install --no-install-recommends \ curl \ dnsutils \ git \ jq \ net-tools \ ssh \ telnet \ unzip \ vim \ wget \ &amp;&amp; apt-get clean \ &amp;&amp; apt-get autoclean \ &amp;&amp; apt-get autoremove \ &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* # Install AWS CLI RUN apt-get update \ &amp;&amp; apt-get -y --force-yes install \ python-pip \ &amp;&amp; pip install awscli==${AWSCLI_VERSION} \ &amp;&amp; apt-get clean \ &amp;&amp; apt-get autoclean \ &amp;&amp; apt-get autoremove \ &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* # Install Terraform RUN wget -O terraform.zip https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip \ &amp;&amp; unzip terraform.zip \ &amp;&amp; mv terraform /usr/local/bin/terraform \ &amp;&amp; chmod +x /usr/local/bin/terraform \ &amp;&amp; rm terraform.zip # Install kubectl ADD https://storage.googleapis.com/kubernetes-release/release/v${KUBECTL_VERSION}/bin/linux/amd64/kubectl /usr/local/bin/kubectl RUN chmod +x /usr/local/bin/kubectl # Install Kops ADD https://github.com/kubernetes/kops/releases/download/${KOPS_VERSION}/kops-linux-amd64 /usr/local/bin/kops RUN chmod +x /usr/local/bin/kops # Install Helm RUN wget -O helm.tar.gz https://storage.googleapis.com/kubernetes-helm/helm-v${HELM_VERSION}-linux-amd64.tar.gz \ &amp;&amp; tar xfz helm.tar.gz \ &amp;&amp; mv linux-amd64/helm /usr/local/bin/helm \ &amp;&amp; chmod +x /usr/local/bin/helm \ &amp;&amp; rm -Rf linux-amd64 \ &amp;&amp; rm helm.tar.gz # Create default user "kops" RUN useradd -ms /bin/bash kops WORKDIR /home/kops USER kops # Ensure the prompt doesn't break if we don't mount the ~/.kube directory RUN mkdir /home/kops/.kube \ &amp;&amp; touch /home/kops/.kube/config</code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">version: '2.1' services: cluster-main: container_name: cluster.com image: cluster.com user: root stdin_open: true volumes: - ./data:/data - ./.ssh:/root/.ssh - ./.kube:/root/.kube - ./.aws:/root/.aws cluster-proxy: container_name: cluster.com-kubectl-proxy image: cluster.com user: root entrypoint: kubectl proxy --address='0.0.0.0' --port=8001 --accept-hosts='.*' ports: - "8001:8001" stdin_open: true volumes: - ./data:/data - ./.ssh:/root/.ssh - ./.kube:/root/.kube - ./.aws:/root/.aws</code> </pre><br></div></div><div class="spoiler">  <b class="spoiler_title">Makefile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">docker.build: docker build -t cluster.com . docker.run: docker-compose up -d docker.bash: docker exec -it cluster.com bash</code> </pre> <br></div></div><br>  <b>Dockerfile</b> - we take a basic image of ubuntu and install all the software.  <b>Makefile</b> - just for convenience, you can use the usual alias mechanism.  <b>Docker-compose.yml</b> - we have added an additional container, which we will send to the <a href="https://github.com/kubernetes/dashboard">K8S Dashboard</a> browser if we need to visually see something. <br><br>  Create <b>data</b> , <b>.ssh</b> , <b>.kube</b> , <b>.aws folders</b> in the root and put our config for aws, ssh keys there and we can collect and run our container via <b>make docker.build &amp; make docker.run</b> . <br><br>  Well, in the <b>data</b> folder, create a folder in which we put the <b>k8s yaml</b> files, and next to the second, in which we will store the state of the cluster <b>terraform</b> .  The approximate result of this stage <a href="https://github.com/tw3eX/k8s-example-1"><b>put on githab</b></a> . <br><br><h2>  1. Raise our cluster. </h2><br><blockquote>  Further there will be a free translation of <a href="https://ryaneschinger.com/blog/kubernetes-aws-vpc-kops-terraform/">this</a> note.  I will omit many theoretical points, I will try to describe a brief squeeze.  All the same, the format of my notes - tldr. </blockquote><br>  In our <b>data / aws-cluster-init-kops-terraform folder, we</b> clone what lies in <a href="https://github.com/ryane/kubernetes-aws-vpc-kops-terraform">this</a> repository and go to the container console via <b>make docker.bash</b> .  A scattering of boring teams begins. <br><br><h4>  AWS CLI </h4><br>  Create a <b>kops</b> user, add permissions and reconfigure the <b>AWS CLI</b> on it, so as not to run commands from the superuser. <br><br><pre> <code class="bash hljs">aws iam create-group --group-name kops <span class="hljs-comment"><span class="hljs-comment">#   aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AWSCertificateManagerFullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops aws iam create-user --user-name kops aws iam add-user-to-group --user-name kops --group-name kops aws iam create-access-key --user-name kops</span></span></code> </pre><br><pre> <code class="bash hljs">aws configure</code> </pre><br><h4>  Initializing Terraform </h4><br>  <b>Change the</b> name of the cluster in the <b>data / aws-cluster-init-kops-terraform / variables.tf</b> file.  Do not forget to take our dns servers from the <b>update.json</b> file and update them where you bought your domain. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#    cd /data/aws-cluster-init-kops-terraform #    AWS CLI export AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id) export AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key) #  terraform terraform init terraform get terraform apply #  NS  cat update-zone.json \ | jq ".Changes[].ResourceRecordSet.Name=\"$(terraform output name).\"" \ | jq ".Changes[].ResourceRecordSet.ResourceRecords=$(terraform output -json name_servers | jq '.value|[{"Value": .[]}]')" \ &gt; update-zone.json</span></span></code> </pre><br><h4>  Kops </h4><br>  We create a cluster through <b>kops</b> , exporting a config to a <b>.tf</b> file. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> NAME=$(terraform output cluster_name) <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KOPS_STATE_STORE=$(terraform output state_store) <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> ZONES=$(terraform output -json availability_zones | jq -r <span class="hljs-string"><span class="hljs-string">'.value|join(",")'</span></span>) kops create cluster \ --master-zones <span class="hljs-variable"><span class="hljs-variable">$ZONES</span></span> \ --zones <span class="hljs-variable"><span class="hljs-variable">$ZONES</span></span> \ --topology private \ --dns-zone $(terraform output public_zone_id) \ --networking calico \ --vpc $(terraform output vpc_id) \ --target=terraform \ --out=. \ <span class="hljs-variable"><span class="hljs-variable">${NAME}</span></span></code> </pre><br><blockquote>  A small remark is needed here.  <b>Terraform</b> will create a <b>VPC</b> , and we will need to tweak a little the config that <b>kops</b> will give <b>us</b> .  This is done quite simply, through the auxiliary image <b>ryane / gensubnets: 0.1</b> <br></blockquote><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   terraform output -json &gt; subnets.json</span></span></code> </pre><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     echo subnets.json | docker run --rm -i ryane/gensubnets:0.1</span></span></code> </pre><br>  You can add policies for route53 right away. <br><br><pre> <code class="plaintext hljs">additionalPolicies: master: | [ { "Effect": "Allow", "Action": ["route53:ListHostedZonesByName"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["elasticloadbalancing:DescribeLoadBalancers"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["route53:ChangeResourceRecordSets"], "Resource": ["*"] } ] node: | [ { "Effect": "Allow", "Action": ["route53:ListHostedZonesByName"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["elasticloadbalancing:DescribeLoadBalancers"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["route53:ChangeResourceRecordSets"], "Resource": ["*"] } ]</code> </pre><br>  We edit through <b>kops edit cluster $ {NAME}</b> . <br><br><img src="https://habrastorage.org/webt/yw/wg/w4/ywwgw42_afdmr__elg0og_yjruk.png"><br><br>  Now we can raise the cluster itself. <br><br><pre> <code class="bash hljs">kops update cluster \ --out=. \ --target=terraform \ <span class="hljs-variable"><span class="hljs-variable">${NAME}</span></span> terraform apply</code> </pre><br>  Everything will go well, the context of <b>kubectl</b> will change.  In the <b>data / aws-cluster-init-kops-terraform folder</b> we will have the cluster state stored.  You can simply put everything in <b>git</b> and send it to a private bitbeta repository. <br><br><pre> <code class="bash hljs">$ kubectl get nodes NAME STATUS AGE ip-10-20-101-252.ec2.internal Ready,master 7m ip-10-20-103-232.ec2.internal Ready,master 7m ip-10-20-103-75.ec2.internal Ready 5m ip-10-20-104-127.ec2.internal Ready,master 6m ip-10-20-104-6.ec2.internal Ready 5m</code> </pre><br><h2>  2. Raise our application </h2><br>  Now that we have something, we can deploy our services in a cluster.  I will put approximate configs in <a href="https://github.com/tw3eX/k8s-example-1">the same repository</a> .  They can be put in <b>data / k8s</b> . <br><br><h4>  Service jokes </h4><br>  Let's start with the service stuff.  We need <b>helm</b> , <b>route53</b> , <b>storage-classes</b> and access to our private <b>registry</b> on <a href="https://hub.docker.com/">hub.docker.com</a> .  Well, or to any other, if there is such a desire. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Init helm kubectl create serviceaccount --namespace kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}' helm init</span></span></code> </pre><br><pre> <code class="bash hljs">kubectl apply -f default-namespace.yaml kubectl apply -f storage-classes.yaml kubectl apply -f route53.yaml kubectl apply -f docker-hub-secret.yml kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</code> </pre><br><h4>  PostgreSQL + Redis </h4><br>  I burned a lot of times, using the docker not for <b>stateless</b> containers, but the latter configuration has shown itself to be the most suitable.  I use <a href="https://github.com/sorintlab/stolon"><b>Stolon</b></a> to provide scalability.  About a year the flight is normal. <br><br>  Deploy <b>helm-charts</b> and a couple of quick <b>Redis</b> config files. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#  etcd  stolon cd etcd-chart helm install --name global-etcd . #   stolon cd stolon-chart helm dep build helm install --name global-postgres . #  redis kubectl apply -f redis</span></span></code> </pre><br><h4>  Nginx + PHP </h4><br>  Normal bunch.  <b>Nginx</b> and <b>php-fpm</b> .  I especially did not clean out the configs, but everyone can customize it for themselves.  Before applying, you must specify the image from which we will take the code + add a line of the certificate from the <b>AWS Certificate Manager</b> .  The php itself can be taken from dock-hab, but I collected my private one by adding some libraries. <br><br><pre> <code class="bash hljs">kubectl apply -f nginx kubectl apply -f php</code> </pre><br>  In our image with the code, we store it in the <b>/ crm-code</b> folder.  We substitute for our image and it will work correctly.  The file is <b>nginx / deployment.yml</b> . <br><br><img src="https://habrastorage.org/webt/xy/0k/0a/xy0k0axs4muxujs3b-dyp8ncske.png"><br><br>  We display the domain.  <b>Route53</b> service will pick it up, change / add DNS records, the certificate will be <b>uploaded</b> to the <b>ELB</b> from <b>AWS Certificate Manager</b> .  The file is <b>nginx / service.yml</b> . <br><br><img src="https://habrastorage.org/webt/aw/nl/ya/awnlyaieynoajtmb_feavw2_qke.png"><br><br>  We forward env variables in php to have them inside and connect to <b>PostgreSQL / Redis</b> .  The file is <b>php / deployment.yml</b> . <br><br><img src="https://habrastorage.org/webt/ry/n9/v4/ryn9v42o_jvzafh16vr3m2rcpo4.png"><br><br>  As a result, we have a <b>K8S</b> cluster, which at the basic level we can scale, add new services, new servers (nodes), change the number of <b>PostgreSQL, PHP, Nginx</b> instances and live before a separate person appears in the team to do it . <br><br>  As part of this small note, I will not touch upon the backups / monitoring of this whole good.  At the initial stage, <b>localhost: 8001 / ui</b> from the <a href="https://github.com/kubernetes/dashboard">K8S Dashboard</a> service will be enough.  Later it will be possible to screw <b>Prometheus</b> , <b>Grafana</b> , <b>Barman</b> , or any other similar solutions. <br><br>  Using the terminal or <b>Teamcity</b> , <b>Jenkins</b> code update will be done like this. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     -      Teamcity docker build -t GROUP/crm-code:latest . docker push GROUP/crm-code:latest #   (  ) kubectl set image deployment/php-fpm php-fpm=GROUP/php-fpm kubectl rollout status deployment/php-fpm kubectl set image deployment/php-fpm php-fpm=GROUP/php-fpm:latest kubectl set image deployment/nginx nginx=danday74/nginx-lua kubectl rollout status deployment/nginx kubectl set image deployment/nginx nginx=danday74/nginx-lua:latest kubectl rollout status deployment/php-fpm kubectl rollout status deployment/nginx</span></span></code> </pre><br>  I would be glad if it would be interesting to someone and doubly glad if it helps someone.  Thank you for your attention.  Once again I attach a link to the repository <a href="https://github.com/tw3eX/k8s-example-1">one</a> and <a href="https://github.com/ryane/kubernetes-aws-vpc-kops-terraform">two</a> . </div><p>Source: <a href="https://habr.com/ru/post/423481/">https://habr.com/ru/post/423481/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../423467/index.html">Russian developers will release a product compatibility catalog</a></li>
<li><a href="../423469/index.html">The fastest floating point numbers in the wild west</a></li>
<li><a href="../423475/index.html">Breaking the code of aging: the new science of aging and what it means to stay young</a></li>
<li><a href="../423477/index.html">Be a security ninja: start your way to the top of IB</a></li>
<li><a href="../423479/index.html">"First": whether to fly to Mars</a></li>
<li><a href="../423483/index.html">Finding the right way to split site content with a Webpack</a></li>
<li><a href="../423485/index.html">Lazy loading images using IntersectionObserver</a></li>
<li><a href="../423487/index.html">Node.js without node_modules</a></li>
<li><a href="../423489/index.html">I'm an emergency doctor, and I want to talk about the new Apple Watch electrocardiogram</a></li>
<li><a href="../423491/index.html">PHP Digest number 139 (September 3 - 17, 2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>