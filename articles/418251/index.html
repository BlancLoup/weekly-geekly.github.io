<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Computer vision: how AI is watching us</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, we talked about how we are analyzed in cinemas using computer vision technology: emotions, gestures, and that‚Äôs all. Today we are publishing...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Computer vision: how AI is watching us</h1><div class="post__text post__text-html js-mediator-article">  Recently, we <a href="https://habr.com/company/microsoft/blog/413015/">talked</a> about how we are analyzed in cinemas using computer vision technology: emotions, gestures, and that‚Äôs all.  Today we are publishing a conversation with our colleague from Microsoft Research.  He is creating the very same vision.  Under the cat, details about the development of technology, a little about the GDPR, as well as about the applications  Join now! <br><br><img src="https://habrastorage.org/webt/i_/zg/y5/i_zgy5xs27a3hquw1lamk3rlcws.jpeg"><a name="habracut"></a><br><br>  From a technical point of view, computer vision experts "create algorithms and systems for automatically analyzing images and extracting information from the visible world."  From the layman‚Äôs point of view, they create machines that they can see.  This is what the main research officer and head of the research department, Dr. Gang Hua, and a team of computer vision experts are doing.  For devices such as personal robots, unmanned vehicles and drones, which we encounter more and more often in everyday life, vision is very important. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Today, Dr. Hua will tell us how recent advances in AI and machine learning have helped to improve image recognition technology and ‚Äúunderstanding‚Äù video, as well as contributed to the development of art.  He will also explain the essence of the distributed ensemble approach to active learning, in which people and machines work together in the lab to create computer vision systems that can see and recognize an open world. <br><br><img src="https://habrastorage.org/webt/xf/xa/sf/xfxasftflwdrnlfndea5fgail34.jpeg"><br>  <i>Gan Hua, Principal Researcher and Head of Research and Development.</i>  <i>Photo courtesy of Maryatt Photography.</i> <br><br><h2>  Interview </h2><br>  If we look back ten or fifteen years ago, we will see that there was more diversity in the computer vision community.  In order to examine the problem from different sides and find its solution, various methods of machine learning and knowledge from various fields, such as physics and optics, were used.  We stress the importance of diversity in all areas of activity, so I think the scientific community will benefit if we have more different points of view. <br><br>  <b>We introduce you to advanced technology research and the scientists behind it.</b> <b><br><br></b>  <b>From a technical point of view, computer vision experts "create algorithms and systems for automatically analyzing images and extracting information from the visible world."</b>  <b>From the layman‚Äôs point of view, they create machines that they can see.</b>  <b>This is what the main research officer and head of the research department, Dr. Gan Hua, and a team of computer vision experts are doing.</b>  <b>For devices such as personal robots, unmanned vehicles and drones, which we encounter more and more often in everyday life, vision is very important.</b> <b><br><br></b>  <b>Today, Dr. Hua will tell us how recent advances in AI and machine learning have helped to improve image recognition technology and ‚Äúunderstanding‚Äù video, as well as contributed to the development of art.</b>  <b>He will also explain the essence of the distributed ensemble approach to active learning, in which people and machines work together in the lab to create computer vision systems that can see and recognize an open world.</b>  <b>This and much more is in the new release of the Microsoft Research podcast.</b> <b><br><br></b>  <b>You are the chief scientist and head of research at MSR (Microsoft Research), and your specialty is computer vision.</b> <br><br>  Yes. <br><br>  <b>If in general terms, why does a computer vision specialist get up in the morning?</b>  <b>What is its main goal?</b> <br><br>  Computer vision is a relatively young area of ‚Äã‚Äãresearch.  In short, we are trying to create such machines that will be able to see the world and perceive it just like a person.  Speaking more technical language, information that enters the computer in the form of simple images and video, can be represented as a sequence of numbers.  We want to extract from these numbers some structures that describe the world, some semantic information.  For example, I can say that some part of the image corresponds to a cat.  And the other part corresponds to the car, I mean the interpretation of this kind.  Here it is, the goal of computer vision.  It seems simple to people, but in order to teach computers this, we had to do a lot of work in the last 10 years.  However, computer vision as a field of research for 50 years.  Nevertheless, we still have many problems to solve. <br><br>  <b>Yes.</b>  <b>5 years ago you said the following: I paraphrase: ‚ÄúWhy, after 30 years of research, are we still working on the problem of facial recognition?‚Äù Tell us how you answered this question then and what has changed during that time.</b> <br><br>  If we answer from the perspective of five years ago, I would say that in the 30 years that have passed since the start of research in the field of computer vision and facial recognition, we have achieved a lot.  But for the most part we are talking about a controlled environment, where when capturing faces, you can adjust the lighting, camera, scenery, and the like.  Five years ago, when we began to work more in natural conditions, in an uncontrollable environment, it turned out that there is a huge gap in the accuracy of recognition.  However, over the past five years, our community has made great progress by using more advanced in-depth training methods.  Even in the field of face recognition in natural conditions, we have made progress and really came to the point where it became possible to use these technologies for various commercial purposes. <br><br>  <b>It turns out that deep learning has really allowed us to achieve great success in the areas of computer vision and image recognition over the past few years.</b> <br><br>  Right. <br><br>  <b>When we started talking about the difference in conditions in fully controlled and unpredictable environments, I remembered several scientists, guests of the podcast, who noted that computers fail when the data are not enough ... for example, the sequence ‚Äúdog, dog, dog, dog with three legs "- the computer begins to doubt whether the latter is also a dog?</b> <br><br>  Yes. <br><br>  <b>After all the truth?</b>  <b>So, what exactly is inaccessible earlier, deep learning methods allow you to do today in the field of recognition?</b> <br><br>  This is a great question.  From a research perspective, deep learning offers several possibilities.  First, it is possible to conduct comprehensive training in order to determine the correct representation of the semantic image.  For example, back to the dog.  Suppose we look at different photos of dogs, for example, images of 64 √ó 64 pixels, where each pixel can take about two hundred and fifty different values.  If you think about it, this is a huge number of combinations.  But if we speak of a dog as a pattern, where the pixels correlate with each other, then the number of combinations corresponding to the ‚Äúdog‚Äù will be much less. <br><br>  With the help of complex methods of deep learning, you can teach the system to determine the correct numerical representation of the ‚Äúdog‚Äù.  Due to the depth of the structures, we can create really complex models that can master a large amount of data for training.  Thus, if my training data covers all possible variants and representations of a template, then in the end I will be able to recognize it in a wider context, because I have considered almost all possible combinations.  This is the first. <br><br>  Another opportunity for deep learning is a kind of compositional behavior.  There is a structure layer and a presentation layer, therefore, when information or an image gets into deep networks and the extraction of low-level primitive images begins, the model can gradually collect semantic structures of higher and higher complexity from these primitive images.  In-depth learning algorithms identify smaller patterns that correspond to larger patterns and put them together to form the final pattern.  Therefore, it is a very powerful tool, especially for tasks of visual recognition. <br><br>  <b>So, this means that the main topic of the CVPR conference is the recognition of patterns by computer vision.</b> <br><br>  Yeah, right. <br><br>  <b>And pattern recognition is what technology really aspires to.</b> <br><br><img src="https://habrastorage.org/webt/ya/wl/re/yawlrerwyzbxcmkuxnwdoqgnqz4.jpeg"><br><br>  Yes of course.  In fact, the goal of computer vision is to grasp the meaning in pixels.  If we speak from a technical point of view, the computer needs to understand what the image is, and we get a certain numerical or symbolic result from it.  For example, a numerical result can be a three-dimensional cloud of points, which describes the structure of space or the shape of an object.  It can also be associated with some semantic labels, such as "dog" or "cat", as I said earlier. <br><br>  <b>Clear.</b>  <b>So let's talk a little about tags.</b>  <b>An interesting and important feature of the machine learning process is the fact that the computer needs to provide both pixels and tags.</b> <br><br>  Yes of course. <br><br>  <b>You talked about three things that are most interesting to you in the context of computer vision.</b>  <b>Videos, faces, as well as art and multimedia.</b>  <b>Let's talk about each of them separately, and let's start with your current research, with what you call ‚Äúunderstanding‚Äù the video.</b> <br><br>  Yes.  The expression "video understanding" speaks for itself.  We use video instead of images as input.  It is important not only to recognize the pixels, but also to consider how they move.  For computer vision, image recognition is a spatial problem.  In the case of video, it becomes a space-time, because the third, temporary, dimension appears.  And if you look at many real-world tasks related to streaming video, be it indoor surveillance cameras or road cameras on the highway, then the point is that the object moves within a constant flow of personnel.  And we need to extract information from this stream. <br><br>  <b>These cameras create a huge amount of video.</b>  <b>Security cameras, taking pictures around the clock in supermarkets and the like.</b>  <b>What benefits for people can you get from these records?</b> <br><br>  My team is working on one incubation project, under which we create a fundamental technology.  In this project we are trying to analyze traffic on the roads.  In cities, a huge number of road cameras have been installed, but most of the video they recorded is wasted.  However, these cameras can be helpful.  Let's look at one example: you want to control traffic lights more efficiently.  Usually, the change of red and green signals is determined by the established schedule.  However, if I saw that there are much fewer vehicles moving in one direction than in others, then in order to optimize the movement, I could keep the green color on in the overloaded directions longer.  This is just one of the applications. <br><br>  <b>Please embody this idea!</b> <br><br>  We will try! <br><br>  <b>Which of us did not stand at the red signal of the traffic light, although almost nobody went to the green in another direction?</b> <br><br>  That's it! <br><br>  <b>Just now, you ask yourself: why do I have to wait?</b> <br><br><img src="https://habrastorage.org/webt/01/qp/vl/01qpvlqyzjn4ere-vq9vxxy6jeq.jpeg"><br><br>  I agree.  This technology can also be applied in other cases, for example, when we have accumulated large archives of video.  Suppose citizens asked for additional bike lanes.  We could use video footage, analyze traffic data, and then decide whether to make a bike lane in this place.  By implementing this technology, we could significantly affect traffic flows and help cities make such decisions. <br><br>  <b>I think this is a great idea, because in most cases we make such decisions based on our own ideas, and not on data, looking at which we could say: "Hey, you know, here the bike lane would have by the way.</b>  <b>And here it will only complicate the movement. ‚Äù</b> <br><br>  Exactly.  Sometimes for this use other sensors.  They hire a company that installs special equipment on the roads.  But it is economically inefficient.  But the road cameras are already installed and just hang around.  Video streams are already available.  Right?  So why not take advantage of this? <br><br>  <b>Agree.</b>  <b>This is a great example of how machine learning and ‚Äúunderstanding‚Äù video can be applied.</b> <br><br>  Exactly. <br><br>  <b>So, another important application is face recognition.</b>  <b>We again return to the question "Why are we still working on the problem of facial recognition?".</b> <br><br>  Exactly. <br><br>  <b>By the way, such technologies in some cases can be applied in a very interesting way.</b>  <b>Tell us what is happening in the field of facial recognition.</b>  <b>Who does this and what's new?</b> <br><br>  Looking back, the facial recognition technology was studied by Microsoft when I was still working at Live Labs Research.  Then we created the first face recognition library that could be used by various product development teams.  For the first time, this technology began to be used in the Xbox.  Then the developers tried to use facial recognition to automatically log into the system.  I think it was the first time.  Over time, the center for the study of facial recognition shifted to Microsoft Research Asia, where we still have a group of researchers with whom I work. <br><br>  We are constantly trying to expand the boundaries of the possible.  Now we work together with technical services that help us collect more data.  Based on this data, we train more advanced models.  Recently, we have focused on the direction of research, which we call "the synthesis of persons with preservation of recognition."  The community of in-depth training experts has also achieved great success.  They use deep networks to train generative models that can model the distribution of images so that data can be extracted from it, that is, it can actually synthesize an image.  So you can create deep networks that create images. <br><br>  But we want to go one step further.  We want to synthesize faces.  At the same time, we want to preserve the recognition of these individuals.  Our algorithms should not just create an arbitrary set of faces without any semantic meaning.  Suppose we want to recreate the face of Brad Pitt.  You need to create a face that really looks like him.  If you need to recreate the face of a person I know, then the result must be accurate. <br><br>  <b>So you want to preserve the recognition of the face you are trying to recreate?</b> <br><br>  Right. <br><br>  <b>By the way, I wonder if this technology will work for a long time, as a person ages, or will you have to constantly update the database with people?</b> <br><br>  This is a very good question.  We are currently conducting research to solve this problem.  At the current level of technology, it is still necessary to update the database from time to time.  Especially if the face has changed a lot.  For example, if a plastic surgery was performed, the modern system will not be able to produce the correct result. <br><br>  <b>Wait, it's not you.</b> <br><br>  Yes, absolutely not like.  This issue can be approached from several sides.  Human faces do not really change very much between the ages of 17‚Äì18 and about 50. But what happens immediately after birth?  The faces of children vary greatly because bones grow and the shape of the face and skin change.  But as soon as a person grows up and goes into a stage of maturity, changes begin to occur very slowly.  Now we are conducting research in which we develop models of the aging process.  They will help create an improved face recognition system with age.  In fact, it is a very useful technology that can be applied in law enforcement, for example, in order to recognize children who were abducted many years ago, which ... <br><br>  <b>Look very different.</b> <br><br>  Yes, they look different.  If clever face recognition algorithms could look at the original photo ... <br><br>  <b>And to say what they would have looked like at the age of 14 if they had been abducted much earlier, or something like that?</b> <br><br>  Yes yes exactly. <br><br>  <b>This is a great use.</b>  <b>Let's talk about another area that you are actively exploring - multimedia and art.</b>  <b>Tell us how science intersects with art, and especially about your work in the field of deep transfer of artistic style.</b> <br><br>  Good.  Take a look at people's needs.  First of all, we need food, water and sleep, right?  After the basic needs are satisfied, the person manifests a strong desire for art ... <br><br>  <b>And the desire to create.</b> <br><br>  And create art objects.  In this area of ‚Äã‚Äãresearch, we want to link computer vision with artistic objects of multimedia and art.  We can use computer vision to bring people artistic enjoyment.  Within the framework of a separate research project on which we have been working for the last two years, we have created a sequence of algorithms with the help of which you can create an image in any artistic style if samples of this style are provided.  For example, we can create an image in the style of Van Gogh. <br><br>  <b>Van Gogh?</b> <br><br>  Yes, or any other artist ... <br><br>  <b>Renoir or Monet ... or Picasso.</b> <br><br>  Yes, any of them.  Anyone you can remember ... <br><br>  <b>Interesting.</b>  <b>Using pixels?</b> <br><br>  Yes, using pixels.  This is also created by deep networks using some of the deep learning technologies that we have developed. <br><br>  <b>It seems that this study requires knowledge from a variety of areas.</b>  <b>Where do you find professionals who can ...</b> <br><br>  I would say that in a sense, our goal is to ... You know, works of art are not always accessible to everyone.  Some of the artwork is really very expensive.  With the help of such digital technologies, we are trying to make such works accessible to ordinary people. <br><br>  <b>Democratize them.</b> <br><br>  Yes, democratize art, as you say. <br><br>  <b>It is impressive.</b> <br><br>  Our algorithm allows you to create a clear numerical model of each style.  And we can even mix them if we want to create new styles.  This is reminiscent of the creation of an artistic space where we can explore intermediate options and see how the techniques change when moving from one artist to another.  And we can even take a deeper look and try to understand what exactly determines the style of an artist. <br><br>  <b>I have a particular interest in the fact that, on the one hand, we are talking about working with numbers: computer science, algorithms, and mathematics.</b>  <b>On the other hand, speech about art is a much more metaphysical category.</b>  <b>And yet you have combined them, and this shows that the brain of a scientist can have an artistic side.</b> <br><br>  Exactly.  I think that the most important tool we use that helped put everything together is statistics. <br><br>  <b>Interesting.</b> <br><br>  All kinds of algorithms for machine learning actually only collect statistics on pixels. <br><br> <b>      ,        ‚Ä¶       ‚Äì       - MSR,      ‚Äì          .  ,          ?</b> <br><br>  .      ,     ,     -.       ‚Ä¶  .        ,    -   .       - , ,   .      .        . <br><br> , ,  Amazon Mechanical Turk.              .          ,     .      .    ,     . -,     ,         . -,      ,          . <br><br>     .      .         .         ,         .           ,   ,          .       . <br><br> <b>     ,          .      .  ,     ,            ?</b> <br><br>      ,     .   ,         ,   .         (       ),  ,         ,     -,      . <br><br> <b>  ,     .</b> <br><br>  Exactly.    ,     ,     ,   ,      ,          .     .       ,     NIH,    - (co-robots). <br><br> <b>- ?</b> <br><br> -.       .    ,       .     ,     .        ,      .     ,     . ,    .  ,  -      ,   ,  . <br><br> ,       ,      .       ,    ,  ? ,  ,   ?            .           . ,   ,       ,      . <br><br> <b>      Microsoft Research    ?</b> <br><br>    Microsoft  .   ,     2006-2009      Live Labs.     .       .       ,  .    Nokia Research, IBM Research            ‚Ä¶ <br><br> <b>  -, ?</b> <br><br> ,   -,   .    Microsoft Research  2015        .    ,   2017    . <br><br> <b>      .   ?</b> <br><br>      .  Microsoft Research   ‚Äî  .    .       ‚Äî    .        .        .   .      ,      ,  ,  Intelligent Group      ,    . <br><br> <b>     .</b> <br><br>  Yes. <br><br> <b>     ,    ,     .   -   ,     ?      -,      ?</b> <br><br>   ,      ,       .       .  :      .  ,     ,    ,    ,     ,    -    .     . ,   ,     , ,   .        ,   . <br><br> <b> ‚Ä¶    ,      : ,      ,    ? ,   ,   ,    ?</b> <br><br> Microsoft          (GDPR).   ,   ,       ,   ,  .   ,          .    - -,     .        .    ,    -  .         ,   ?   ,     ,       .    .      ,      ,            ,      ‚Ä¶ <br><br> <b>,      .     : ¬´   .      ¬ª.</b> <br><br>  Yeah, right. <br><br> <b>,           ,            .         ?       10 ?</b> <br><br>      .    ,    .               .     ,    .            .           ,    . <br><br>    , ,     ¬´¬ª .   ,       -     ,    .  - ,      ?          .    ‚Äî    .  ,    .      ,         ,     .    ,   .    ,     .     .     . ,        ‚Ä¶ <br><br> <b>   .</b> <br><br><img src="https://habrastorage.org/webt/gx/zq/56/gxzq56s3rjhnlshjilqoohazlmu.jpeg"><br><br>  That's it.     .       .     10-15  ,   ,          .          ,          ,     .        ,   ,    ,        . <br><br> <b>   .      , ,      ,        .</b> <br><br> ,  ! <br><br>       ,         ,   : Microsoft.com/research </div><p>Source: <a href="https://habr.com/ru/post/418251/">https://habr.com/ru/post/418251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../418241/index.html">Why gauss? (100 ways to solve an equation system)</a></li>
<li><a href="../418243/index.html">The popular history of astronomy is wrong</a></li>
<li><a href="../418245/index.html">How not to develop a project on Bitrix</a></li>
<li><a href="../418247/index.html">Accelerating the multiplication of float 4x4 matrices using SIMD</a></li>
<li><a href="../418249/index.html">New Google Compute Engine VM Images for Deep Learning</a></li>
<li><a href="../418253/index.html">There could be water, atmosphere and life on the early moon</a></li>
<li><a href="../418255/index.html">How traffic exchanges resell autosurfing and where from the network millions of bots</a></li>
<li><a href="../418257/index.html">Github.com refuses to use jQuery and switches to pure JavaScript</a></li>
<li><a href="../418261/index.html">The self-made glove stun gun is a weapon for the boom</a></li>
<li><a href="../418263/index.html">Russian scientists are developing a compact and cheap MEG system</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>