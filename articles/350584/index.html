<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>An overview of the new UMAP dimension reduction algorithm. Is it really better and faster than t-sne?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! The task of reducing the dimension is one of the most important in data analysis and may arise in the following two cases. First, for visual...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>An overview of the new UMAP dimension reduction algorithm. Is it really better and faster than t-sne?</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  The task of reducing the dimension is one of the most important in data analysis and may arise in the following two cases.  First, for visualization purposes: before working with multidimensional data, it may be useful for a researcher to look at their structure, reducing the dimension and projecting it onto a two-dimensional or three-dimensional plane.  Secondly, lowering the dimension is useful for preprocessing signs in machine learning models, since it is often inconvenient to train algorithms on a hundred signs, among which there may be a lot of noisy and / or linearly dependent ones, of course we would like to get rid of them.  Finally, reducing the dimension of space speeds up the training of models, and we all know that time is our most valuable resource. <br><br>  <a href="https://github.com/lmcinnes/umap">UMAP (Uniform Manifold Approximation and Projection)</a> is a new dimension reduction algorithm, the library with the implementation of which was released quite recently.  <a href="https://arxiv.org/abs/1802.03426">The authors of the algorithm believe</a> that UMAP is able to challenge modern models of reducing the dimension, in particular, t-SNE, which is by far the most popular.  According to the results of their research, UMAP has no restrictions on the dimension of the original feature space, which needs to be reduced, it is much faster and more computationally efficient than t-SNE, and it also copes better with the task of transferring the global data structure to a new, reduced space. <br><br>  In this article, we will try to make out what UMAP is, how to set up an algorithm, and finally, check whether it really has advantages over t-SNE. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/2i/ed/wy/2iedwyuaviygbldrtc2uytgkjvu.png"><br><a name="habracut"></a><br><h3>  Some theory </h3><br>  Algorithms for reducing the dimension can be divided into 2 main groups: they are trying to maintain either a global data structure or local distances between points.  The first includes such algorithms as the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">Principal Component Method (PCA)</a> and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html">MDS (Multidimensional Scaling)</a> , and the second <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">includes t-SNE</a> , <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html">ISOMAP</a> , <a href="https://github.com/lferry007/LargeVis">LargeVis,</a> and others.  UMAP refers to the latter and shows results similar to t-SNE. <br><br>  Since a deep mathematical preparation, knowledge of Riemannian geometry and topology is required for a deep understanding of the principles of the algorithm, we describe only the general idea of ‚Äã‚Äãthe UMAP model, which can be divided into two main steps.  At the first stage, we estimate the space in which, by our assumption, there are data.  It can be set a priori (how simple <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>R</mi><mi>n</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.982ex" height="2.057ex" viewBox="0 -780.1 1284.1 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/newprolab/blog/350584/&amp;xid=17259,1500004,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhgDc5RyGyfHL7lomJM2VRJFxUf4kw#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/newprolab/blog/350584/&amp;xid=17259,1500004,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhgDc5RyGyfHL7lomJM2VRJFxUf4kw#MJMATHI-6E" x="1074" y="513"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mi>n</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-1"> R ^ n </script>  ), or estimate based on data.  And in the second step we are trying to create a mapping from the estimated space at the first stage to a new, smaller dimension. <br><br><h3>  Application results </h3><br>  So, now we will try to apply UMAP to any data set and compare its visualization quality with t-SNE.  Our choice fell on dataset <a href="https://www.kaggle.com/zalando-research/fashionmnist">Fashion MNIST</a> , which includes 70,000 black and white images of various clothes in 10 classes: T-shirts, pants, sweaters, dresses, sneakers, etc.  Each picture has a size of 28x28 pixels or 784 pixels in total.  They will be features in our model. <br><br>  So, let's try to use the UMAP library in Python in order to present our garments on a two-dimensional plane.  Set the number of neighbors, equal to 5, and leave the remaining parameters by default.  We will discuss them later. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> umap fmnist = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'fashion-mnist.csv'</span></span>) <span class="hljs-comment"><span class="hljs-comment">#   embedding = umap.UMAP(n_neighbors=5).fit_transform(fmnist.drop('label', axis=1)) # </span></span></code> </pre> <br>  The result of the transformation was two vectors of the same length as the original dataset.  Visualize these vectors and see how well the algorithm was able to preserve the data structure: <br><br><img src="https://habrastorage.org/webt/dc/zy/zo/dczyzowgixjmrbuhszs-caztaj4.png"><br><br>  As you can see, the algorithm copes quite well and "has not lost" most of the valuable information that distinguishes one type of clothing from another.  Also, the fact that the UMAP has separated shoes, clothing for the body and pants from each other also speaks about the quality of the algorithm, understanding that these are completely different things.  Of course, there are mistakes.  For example, the model decided that a shirt and a sweater are one and the same. <br><br>  Now let's see how t-SNE is managed with the same data set.  To do this, we will use <a href="https://github.com/DmitryUlyanov/Multicore-TSNE">Multicore TSNE</a> ‚Äî the fastest (even in single-core mode) among all implementations of the algorithm: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> MulticoreTSNE <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MulticoreTSNE <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> TSNE tsne = TSNE() embedding_tsne = tsne.fit_transform(fmnist.drop(<span class="hljs-string"><span class="hljs-string">'label'</span></span>, axis = <span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br>  Result: <br><br><img src="https://habrastorage.org/webt/ly/sd/ha/lysdha9uryorh8v5_mqq5zlj5x8.png"><br><br>  T-SNE shows similar results with UMAP and makes the same mistakes.  However, unlike UMAP, t-SNE does not so clearly combine the types of clothing into separate groups: pants, things for the body and for legs are close to each other.  However, in general, it can be said that both algorithms have coped with the task equally well and the researcher is free to choose between one or the other.  It was possible, if not for one "but." <br><br>  This ‚Äúbut‚Äù is the speed of learning.  On a server with 4 Intel Xeon E5-2690v3 cores, 2.6 Hz and 16 GB of RAM on a 70000x784 data set, the UMAP learned in <b>4 minutes and 21 seconds</b> , while it took t-SNE almost 5 times longer : <b>20 minutes, 14 seconds</b> .  That is, UMAP is much more computationally efficient, which gives it a huge advantage over other algorithms, including t-SNE. <br><br><h3>  Algorithm parameters </h3><br>  <b>The number of neighbors is <i>n_neighbors</i> .</b>  Varying this parameter, you can choose what is more important to save in the new spatial representation of the data: global or local data structure.  Small parameter values ‚Äã‚Äãmean that, trying to estimate the space in which data is distributed, the algorithm is limited to a small neighborhood around each point, that is, it tries to catch a local data structure (possibly to the detriment of the overall picture).  On the other hand, the large values ‚Äã‚Äãof the <i>n_neighbors</i> force UMAP to take into account points in a larger neighborhood, keeping the global data structure, but missing details. <br><br>  Let's look at the example of our dataset, how the <i>n_neighbors</i> parameter affects the quality and speed of training: <br><br><img src="https://habrastorage.org/webt/q5/cw/si/q5cwsi6djed5_itnigbu85jqv3y.png"><br><br>  From this picture we can draw the following several conclusions: <br><br><ul><li>  With a number of neighbors equal to one, the algorithm works just awful, because it focuses too much on details and simply cannot catch the overall data structure. </li><li>  With the growing number of neighbors, the model pays less attention to the differences between different types of clothing, grouping similar ones and mixing them together.  At the same time, completely different wardrobe items are getting farther from each other.  As already mentioned, the overall picture becomes clearer, and the details are blurred. </li><li>  The <i>n_neighbors</i> parameter significantly affects the training time.  so you need to carefully approach his selection. </li></ul><br>  <b>The minimum distance is <i>min_dist</i> .</b>  This parameter should be understood literally: it determines the minimum distance at which points in the new space can be located.  Low values ‚Äã‚Äãshould be used if you are interested in which clusters your data is divided into, and high values ‚Äã‚Äãif it is more important for you to look at the data structure as a whole. <br><br>  Let's return to our dataset and estimate the effect of the <i>min_dist</i> parameter.  The value of <i>n_neighbors</i> will be fixed and equal to 5: <br><br><img src="https://habrastorage.org/webt/ju/_a/li/ju_alihzcmivbnpvp-ukjv_qhqg.png"><br><br>  As expected, increasing the value of the parameter leads to a lesser degree of clustering, data is collected in a heap and the differences between them are erased.  Interestingly, with the minimum value of <i>min_dist, the</i> algorithm tries to find differences within the clusters and divide them into even smaller groups. <br><br>  <b>Distance <i>metric</i> - <i>metric</i> .</b>  The <i>metric</i> parameter determines how distances in the source data space will be calculated.  By default, the UMAP supports all possible distances, from Minkowski to Hamming.  The choice of metric depends on how we interpret this data and its type.  For example, when working with textual information, it is preferable to use the cosine distance ( <i>metric = 'cosine'</i> ). <br><br>  Let's continue to play with our dataset and try various metrics: <br><br><img src="https://habrastorage.org/webt/4a/b7/-j/4ab7-jwiywyn7q-ae5q0j5pe4tq.png"><br><br>  According to the pictures, you can make sure that the choice of the distance measure greatly influences the final result, therefore, its choice should be approached responsibly.  If you are not sure which metric of the variety to choose, then the Euclidean distance is the safest option (the default is in UMAP). <br><br>  <b>The dimension of the finite space is <i>n_components</i> .</b>  Everything is obvious here: the parameter determines the dimension of the final space.  If you need to visualize data, then you should choose 2 or 3. If you use transformed vectors as features of machine learning models, then more is possible. <br><br><h3>  Conclusion </h3><br>  UMAP was developed quite recently and is constantly being improved, but now we can say that it is not inferior to other algorithms in terms of the quality of work and may finally solve the main problem of modern models of dimension reduction - slowness of learning. <br><br>  Finally, see how UMAP was able to visualize the <a href="https://cloud.google.com/bigquery/public-data/">Google News</a> data set, consisting of 3 million word vectors.  The training time was 200 minutes, while it took several days for t-SNE: <br><br><img src="https://habrastorage.org/webt/di/ja/2q/dija2qan8pnw6ur-enfdw-sr5y4.png"><br><br>  By the way, the drawing was built using the <i>datashader</i> library for visualizing big data, which we will tell you about in one of the following articles! <br><br><hr><br>  Among the algorithms for reducing the dimension is SVD, to which we pay attention in the context of building recommendations on our program <a href="https://goo.gl/ummktS">‚ÄúBig Data Specialist 8.0‚Äù</a> , which starts already on March 22. </div><p>Source: <a href="https://habr.com/ru/post/350584/">https://habr.com/ru/post/350584/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../350574/index.html">You can not just take and edit subtitles</a></li>
<li><a href="../350576/index.html">Background removal using deep learning</a></li>
<li><a href="../350578/index.html">UX-design in Russia and the CIS "under the microscope"</a></li>
<li><a href="../350580/index.html">Kali Linux is now available in the Microsoft Store</a></li>
<li><a href="../350582/index.html">Excel instead of PowerShell: queries to AD and system reports "on the knee"</a></li>
<li><a href="../350588/index.html">We wrote the code together for one computer for five months. This is what I learned</a></li>
<li><a href="../350590/index.html">FastTrack Training. "Network Basics". "The Value of Cisco Wireless Local Area Networks". Eddie Martin December 2012</a></li>
<li><a href="../350594/index.html">What is SaaS-business</a></li>
<li><a href="../350596/index.html">This SVG always shows today's date.</a></li>
<li><a href="../350598/index.html">Vue.js Moscow Meetup # 1 (03/22/2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>