<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Flying Pigs, or Optimizing Bytecode Interpreters</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content=""You can however, make a faster pig" (a comment in the Emaks source code) 

 Everyone knows the fact that pigs do not fly. No less popular is the opin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Flying Pigs, or Optimizing Bytecode Interpreters</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/bg/lp/cz/bglpczwnjg-u0usatiwfxggd-zi.jpeg"></p><br><blockquote>  "You can however, make a faster pig" (a comment in the Emaks source code) </blockquote><p>  Everyone knows the fact that pigs do not fly.  No less popular is the opinion that bytecode interpreters as a technique for executing high-level languages ‚Äã‚Äãcannot be accelerated without the use of time-consuming dynamic compilation. </p><br><p>  In the second part of a series of articles on bytecode interpreters, I will try to show by the example of a small PVM virtual machine (‚ÄúPig Virtual Machine‚Äù) that not everything is lost for hard-working piglets with ambitions and that it is possible to accelerate within the (mostly) standard C the work of such interpreters at least one and a half times. </p><a name="habracut"></a><br><h1 id="porosenokvm">  Pig VM </h1><br><p>  Let's get acquainted. </p><br><p>  <a href="">‚ÄúPiglet</a> VM <a href="">‚Äù</a> is an ordinary stack machine based on an <a href="">example</a> from the <a href="https://habr.com/company/badoo/blog/425325/">first part of a</a> series of articles.  Our piggy knows only one type of data - a 64-bit machine word, and all (integer) calculations are performed on a stack with a maximum depth of 256 machine words.  In addition to the stack, this pig has a working memory of 65,536 machine words.  The result of the program - one machine word - can either be placed in the register-result, or simply output to standard output (stdout). </p><br><p>  All state in the car "Pig VM" is stored in a single structure: </p><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-comment"><span class="hljs-comment">/* Current instruction pointer */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint8_t</span></span> *ip; <span class="hljs-comment"><span class="hljs-comment">/* Fixed-size stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> <span class="hljs-built_in"><span class="hljs-built_in">stack</span></span>[STACK_MAX]; <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> *stack_top; <span class="hljs-comment"><span class="hljs-comment">/* Operational memory */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> memory[MEMORY_SIZE]; <span class="hljs-comment"><span class="hljs-comment">/* A single register containing the result */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> result; } vm;</code> </pre> <br><p>  The above allows you to refer this machine to low-level virtual machines, almost all of the overhead in which falls on the maintenance of the main program cycle: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">interpret_result </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vm_interpret</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">uint8_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *bytecode)</span></span></span><span class="hljs-function"> </span></span>{ vm_reset(bytecode); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (;;) { <span class="hljs-keyword"><span class="hljs-keyword">uint8_t</span></span> instruction = NEXT_OP(); <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> (instruction) { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> OP_PUSHI: { <span class="hljs-comment"><span class="hljs-comment">/* get the argument, push it onto stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint16_t</span></span> arg = NEXT_ARG(); PUSH(arg); <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> OP_ADD: { <span class="hljs-comment"><span class="hljs-comment">/* Pop 2 values, add 'em, push the result back to the stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> arg_right = POP(); *TOS_PTR() += arg_right; <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-comment"><span class="hljs-comment">/* * ... * Lots of other instruction handlers here * ... */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> OP_DONE: { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> SUCCESS; } <span class="hljs-keyword"><span class="hljs-keyword">default</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ERROR_UNKNOWN_OPCODE; } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ERROR_END_OF_STREAM; }</code> </pre> <br><p>  From the code it is clear that for each opcode the piglet should: </p><br><ol><li>  Extract opcode from instruction stream. </li><li>  Make sure that the opcode is in the allowable range of opcode values ‚Äã‚Äã(the C compiler adds this logic when generating the switch code). </li><li>  Go to the body instructions. </li><li>  Extract instruction arguments from the stack or decode an instruction argument placed directly in bytecode. </li><li>  Perform an operation. </li><li>  If there is a result of the calculation, put it on the stack. </li><li>  Move the pointer from the current instruction to the next. </li></ol><br><p>  The payload here is only in the fifth paragraph, all the rest is overhead: decoding or retrieving instruction arguments from the stack (item 4), checking the opcode value (item 2), repeatedly returning to the beginning of the main loop and subsequent hardly predictable conditional jump (item 3). </p><br><p>  In short, the pig has clearly exceeded the recommended body mass index, and if we want to bring it into shape, we will have to deal with all these excesses. </p><br><h1 id="svinskiy-yazyk-assemblera-i-resheto-eratosfena">  Swine Assembly and Sieve of Eratosthenes </h1><br><p>  To begin, we define the rules of the game. </p><br><p>  Writing programs for a virtual machine right in C - moveton, but creating a programming language is a long time, so the pig and I decided to limit ourselves to the pig language of assembler. </p><br><p>  The program, which calculates the sum of numbers from 1 to 65 536, on this assembler looks like this: </p><br><pre> <code class="hljs pgsql"># sum numbers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">65535</span></span> # init the <span class="hljs-keyword"><span class="hljs-keyword">current</span></span> sum <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> the <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> PUSHI <span class="hljs-number"><span class="hljs-number">1</span></span> PUSHI <span class="hljs-number"><span class="hljs-number">1</span></span> # stack s=<span class="hljs-number"><span class="hljs-number">1</span></span>, i=<span class="hljs-number"><span class="hljs-number">1</span></span> STOREI <span class="hljs-number"><span class="hljs-number">0</span></span> # stack: s=<span class="hljs-number"><span class="hljs-number">1</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">routine</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">increment</span></span> the counter, add it to the current sum incrementandadd: # check if index is too big LOADI <span class="hljs-number"><span class="hljs-number">0</span></span> # stack: s, i ADDI <span class="hljs-number"><span class="hljs-number">1</span></span> # stack: s, i+<span class="hljs-number"><span class="hljs-number">1</span></span> DUP # stack: s, i+<span class="hljs-number"><span class="hljs-number">1</span></span>, i+<span class="hljs-number"><span class="hljs-number">1</span></span> GREATER_OR_EQUALI <span class="hljs-number"><span class="hljs-number">65535</span></span> # stack: s, i+<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> JUMP_IF_TRUE done # stack: s, i+<span class="hljs-number"><span class="hljs-number">1</span></span> DUP # stack: s, i+<span class="hljs-number"><span class="hljs-number">1</span></span>, i+<span class="hljs-number"><span class="hljs-number">1</span></span> STOREI <span class="hljs-number"><span class="hljs-number">0</span></span> # stack: s, i+<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ADD</span></span> # stack: s+i+<span class="hljs-number"><span class="hljs-number">1</span></span> JUMP incrementandadd done: <span class="hljs-keyword"><span class="hljs-keyword">DISCARD</span></span> PRINT DONE</code> </pre> <br><p>  Not Python, of course, but everything you need for pig happiness is here: comments, labels, conditional and unconditional jumps on them, mnemonics for instructions and the ability to specify the immediate arguments of instructions. </p><br><p>  Included with the machine "Piglet VM" are assembler and disassembler, which courageous in spirit and having a lot of free time, readers can independently try out in battle. </p><br><p>  The numbers add up very quickly, so to test the performance, I wrote another program - a naive implementation of the <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D1%2588%25D0%25B5%25D1%2582%25D0%25BE_%25D0%25AD%25D1%2580%25D0%25B0%25D1%2582%25D0%25BE%25D1%2581%25D1%2584%25D0%25B5%25D0%25BD%25D0%25B0">sieve of Eratosthenes</a> . </p><br><p>  In fact, the piglet and so runs pretty quickly (his instructions are close to the machine), so to get clear results, I‚Äôll make every measurement for a hundred program launches. </p><br><p>  The first version of our non-optimized pig runs like this: </p><br><pre> <code class="hljs javascript">&gt; ./pigletvm runtimes test/sieve-unoptimized.bin <span class="hljs-number"><span class="hljs-number">100</span></span> &gt; <span class="hljs-regexp"><span class="hljs-regexp">/dev/</span></span><span class="hljs-literal"><span class="hljs-literal">null</span></span> PROFILE: <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> code finished took <span class="hljs-number"><span class="hljs-number">545</span></span>ms</code> </pre> <br><p>  Half a second!  The comparison is definitely unfair, but the same Python algorithm makes a hundred runs a little slower: </p><br><pre> <code class="hljs javascript">&gt; python test/sieve.py &gt; <span class="hljs-regexp"><span class="hljs-regexp">/dev/</span></span><span class="hljs-literal"><span class="hljs-literal">null</span></span> <span class="hljs-number"><span class="hljs-number">4.66692185402</span></span></code> </pre> <br><p>  4.5 seconds, or nine times slower.  We must pay tribute to the pig - he has the ability!  Well, now let's see if our pig can pump a press. <br><img src="https://habrastorage.org/webt/ce/eq/ni/ceeqnik6-41cuvd3rwvkkuquoes.jpeg"></p><br><h1 id="uprazhnenie-pervoe-staticheskie-superinstrukcii">  Exercise One: Static Superinstructions </h1><br><p>  The first rule of fast code is not to do any extra work.  The second rule of fast code is to never do any extra work.  So what extra work does the "Pig VM"? </p><br><p>  Observation one: profiling our program shows that there are sequences of instructions that occur more often than others.  We will not torment our pig much and confine ourselves to pairs of instructions: </p><br><ol><li>  LOADI 0, ADD - put the number from the memory at address 0 and add it to the number on the top of the stack. </li><li>  PUSHI 65536, GREATER_OR_EQUAL ‚Äî put a number on the stack and compare it with the number that was previously at the top of the stack, putting the result of the comparison (0 or 1) back onto the stack. </li><li>  PUSHI 1, ADD - put a number on the stack, add it to the number that was previously at the top of the stack, and put the result of the addition back to the stack. </li></ol><br><p>  In the PorosenVM machine there are a little more than 20 instructions, and the whole byte is used for coding - 256 values.  Making new instructions is not a problem.  What we will do: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (;;) { <span class="hljs-keyword"><span class="hljs-keyword">uint8_t</span></span> instruction = NEXT_OP(); <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> (instruction) { <span class="hljs-comment"><span class="hljs-comment">/* * Other instructions here * */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> OP_LOADADDI: { <span class="hljs-comment"><span class="hljs-comment">/* get immediate argument as an memory address , add it to value from the address to the top * of the stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint16_t</span></span> addr = NEXT_ARG(); <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> val = vm.memory[addr]; *TOS_PTR() += val; <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> OP_GREATER_OR_EQUALI:{ <span class="hljs-comment"><span class="hljs-comment">/* get the immediate argument, compare it with the value from the address to the top of the stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> arg_right = NEXT_ARG(); *TOS_PTR() = PEEK() &gt;= arg_right; <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> OP_ADDI: { <span class="hljs-comment"><span class="hljs-comment">/* Add immediate value to the top of the stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint16_t</span></span> arg_right = NEXT_ARG(); *TOS_PTR() += arg_right; <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-comment"><span class="hljs-comment">/* * Other instructions here * */</span></span> }</code> </pre><br><p>  Nothing complicated.  Let's see what came of it: </p><br><pre> <code class="hljs javascript">&gt; ./pigletvm runtimes test/sieve.bin <span class="hljs-number"><span class="hljs-number">100</span></span> &gt; <span class="hljs-regexp"><span class="hljs-regexp">/dev/</span></span><span class="hljs-literal"><span class="hljs-literal">null</span></span> PROFILE: <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> code finished took <span class="hljs-number"><span class="hljs-number">410</span></span>ms</code> </pre> <br><p>  Wow!  Code for just three new instructions, and we won a hundred and fifty milliseconds! </p><br><p>  The win here is achieved due to the fact that our piglet doesn‚Äôt make unnecessary movements when executing such instructions: the execution stream does not fall out into the main loop, nothing is further decoded, and the arguments of the instructions don‚Äôt go through the stack once again. </p><br><p>  This is called static super instructions, since the additional instructions are determined statically, that is, by the programmer of the virtual machine at the design stage.  This is a simple and effective technique, which in one form or another is used by all virtual machines of programming languages. </p><br><p>  The main problem of static superinstructions is that without a specific program it is impossible to determine which particular instructions should be combined.  Different programs use different sequences of instructions, and these sequences can only be learned at the stage of launching a specific code. </p><br><p>  The next step could be a dynamic compilation of superinstructions in the context of a specific program, that is, dynamic superindications (in the 90s and in the early 2000s, this technique played the role of a primitive JIT compilation). </p><br><p>  It is impossible to create instructions on the fly in the framework of the usual C, and our little pig quite rightly does not consider this an honest competition.  Fortunately, I have a couple of better exercises for him. </p><br><h1 id="uprazhnenie-vtoroe-proverka-intervala-znacheniy-opkodov">  Exercise two: checking the range of values ‚Äã‚Äãopkodov </h1><br><p>  Following our rules of quick code, let us once again ask ourselves the eternal question: what can we not do? </p><br><p>  When we got acquainted with the device of the Pigment VM machine, I listed all the actions that the virtual machine performs for each opcode.  And point 2 (checking the value of the opcode for entering a valid interval of switch values) causes the most suspicion. </p><br><p>  Let's look at how GCC compiles the switch construct: </p><br><ol><li>  A transition table is built, that is, a table that displays the value of the opcode to the address of the code executing the instruction body. </li><li>  A code is inserted that checks whether the received opcode is in the interval of all possible switch values, and sends it to the default label if there is no handler for the opcode. </li><li>  Inserts the code that goes to the handler. </li></ol><br><p>  But why make a check of the interval of values ‚Äã‚Äãfor each instruction?  We believe that the opcode is either correct - the final execution of the instruction OP_DONE, or incorrect - went beyond the limits of the byte-code.  The tail of the opcode stream is marked by zero, and zero is the opcode of the OP_ABORT instruction, which completes the execution of the bytecode with an error. </p><br><p>  It turns out that this check is not needed at all!  And the pig should be able to convey this idea to the compiler.  Let's try to fix the main switch a bit: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">uint8_t</span></span> instruction = NEXT_OP(); <span class="hljs-comment"><span class="hljs-comment">/* Let the compiler know that opcodes are always between 0 and 31 */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> (instruction &amp; <span class="hljs-number"><span class="hljs-number">0x1f</span></span>) { <span class="hljs-comment"><span class="hljs-comment">/* All the instructions here */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">26</span></span> ... <span class="hljs-number"><span class="hljs-number">0x1f</span></span>: { <span class="hljs-comment"><span class="hljs-comment">/*Handle the remaining 5 non-existing opcodes*/</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ERROR_UNKNOWN_OPCODE; } }</code> </pre> <br><p>  Knowing that we have only 26 instructions, we impose a bit mask (the octal value 0x1f is a binary 0b11111 covering the interval from 0 to 31) on the opcode and add handlers to unused values ‚Äã‚Äãin the interval from 26 to 31. </p><br><p>  Bit instructions are one of the cheapest in the x86 architecture, and they are certainly cheaper than problematic conditional transitions like the one that uses the interval check.  Theoretically, we should win several cycles on each executable instruction, if the compiler takes our hint. </p><br><p>  By the way, the way of specifying the interval of values ‚Äã‚Äãin a case is not a standard C, but an extension of GCC.  But for our purposes, this code is suitable, especially since it is easy to remake it into several handlers for each of the unnecessary values. </p><br><p>  We try: </p><br><pre> <code class="hljs pgsql">&gt; ./pigletvm runtimes test/sieve.bin <span class="hljs-number"><span class="hljs-number">100</span></span> &gt; /dev/<span class="hljs-keyword"><span class="hljs-keyword">null</span></span> PROFILE: switch code finished took <span class="hljs-number"><span class="hljs-number">437</span></span>ms PROFILE: switch code (<span class="hljs-keyword"><span class="hljs-keyword">no</span></span> range <span class="hljs-keyword"><span class="hljs-keyword">check</span></span>) finished took <span class="hljs-number"><span class="hljs-number">383</span></span>ms</code> </pre> <br><p>  Another 50 milliseconds!  Piglet, you seemed to be heard on the shoulders! .. </p><br><h1 id="uprazhnenie-trete-trassy">  Exercise number three: trails </h1><br><p>  What other exercises can help our pig?  We received the biggest time savings due to super-instructions.  And they reduce the number of outputs in the main cycle and allow you to get rid of the corresponding overhead costs. </p><br><p>  The central switch is the main problem place for any processor with an extraordinary execution of instructions.  Modern branch predictors have learned to predict well even such complex indirect transitions, but smearing branch points along a code can help the processor to quickly move from instruction to instruction. </p><br><p>  Another problem is the byte read of the opcodes of instructions and immediate arguments from bytecode.  Physical machines operate with a 64-bit machine word and do not really like it when the code operates with smaller values. </p><br><p>  Compilers often operate with <a href="https://ru.wikipedia.org/wiki/%25D0%2591%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D1%258B%25D0%25B9_%25D0%25B1%25D0%25BB%25D0%25BE%25D0%25BA">base blocks</a> , that is, sequences of instructions without branches and labels inside.  The base unit starts either from the beginning of the program, or from the label, and ends with the end of the program, conditional branching, or a direct transition to the label that starts the next base unit. </p><br><p>  There are many advantages to working with base units, but our pig is interested in its key feature: the instructions within the base unit are executed sequentially.  It would be nice to somehow allocate these basic blocks and execute instructions in them without losing time to exit to the main loop. </p><br><p>  In our case, you can even expand the definition of the base unit to the track.  The track in terms of the machine "Pig VM" will include all consistently connected (that is, using unconditional jumps) basic blocks. </p><br><p>  In addition to the sequential execution of instructions, it would be nice to decode the immediate arguments of the instructions in advance. </p><br><p>  All this sounds pretty scary and resembles a dynamic compilation that we decided not to use.  Piglet even a little doubted his strength, but in practice everything was not so bad. </p><br><p>  Let's first think about how to present the instruction entering the track: </p><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">scode</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> arg; trace_op_handler *handler; };</code> </pre> <br><p>  Here arg is a pre-decoded instruction argument, and handler is a pointer to a function that executes the instruction logic. </p><br><p>  Now the view of each track looks like this: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> scode trace[MAX_TRACE_LEN];</code> </pre> <br><p>  That is, the track is a sequence of s-codes of limited length.  The trail cache itself inside the virtual machine looks like this: </p><br><pre> <code class="cpp hljs">trace trace_cache[MAX_CODE_LEN];</code> </pre> <br><p>  This is just an array of traces of length not exceeding the possible length of the bytecode.  The solution is lazy, practically to save memory, it makes sense to use a hash table. </p><br><p>  At the beginning of the interpreter, the first handler of each of the traces will compile itself: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> trace_i = <span class="hljs-number"><span class="hljs-number">0</span></span>; trace_i &lt; MAX_CODE_LEN; trace_i++ ) vm_trace.trace_cache[trace_i][<span class="hljs-number"><span class="hljs-number">0</span></span>].handler = trace_compile_handler;</code> </pre> <br><p>  The main interpreter loop now looks like this: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(vm_trace.is_running) { scode *code = &amp;vm_trace.trace_cache[vm_trace.pc][<span class="hljs-number"><span class="hljs-number">0</span></span>]; code-&gt;handler(code); }</code> </pre> <br><p>  The handler compiling the trace is a bit more complicated, and, in addition to building the trace starting from the current instruction, it does the following: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trace_compile_handler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(scode *trace_head)</span></span></span><span class="hljs-function"> </span></span>{ scode *trace_tail = trace_head; <span class="hljs-comment"><span class="hljs-comment">/* * Trace building here */</span></span> <span class="hljs-comment"><span class="hljs-comment">/* now, run the chain that has a trace_compile_handler replaced with proper instruction handler * function pointer */</span></span> trace_head-&gt;handler(trace_head); }</code> </pre><br><p>  Normal instruction handler: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">op_add_handler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(scode *code)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">uint64_t</span></span> arg_right = POP(); *TOS_PTR() += arg_right; <span class="hljs-comment"><span class="hljs-comment">/* * Call the next trace handler * */</span></span> <span class="hljs-comment"><span class="hljs-comment">/* scodes are located in an array so we can use pointer arithmetic to get the next handler */</span></span> code++; code-&gt;handler(code); }</code> </pre> <br><p>  Each handler terminates each trace, making no calls at the end of the function: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">op_done_handler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(scode *code)</span></span></span><span class="hljs-function"> </span></span>{ (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>) code; vm_trace.is_running = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; vm_trace.error = SUCCESS; }</code> </pre> <br><p>  All this, of course, is more complicated than adding superinstructions, but let's see if it gave us anything: </p><br><pre> <code class="hljs pgsql">&gt; ./pigletvm runtimes test/sieve.bin <span class="hljs-number"><span class="hljs-number">100</span></span> &gt; /dev/<span class="hljs-keyword"><span class="hljs-keyword">null</span></span> PROFILE: switch code finished took <span class="hljs-number"><span class="hljs-number">427</span></span>ms PROFILE: switch code (<span class="hljs-keyword"><span class="hljs-keyword">no</span></span> range <span class="hljs-keyword"><span class="hljs-keyword">check</span></span>) finished took <span class="hljs-number"><span class="hljs-number">395</span></span>ms PROFILE: trace code finished took <span class="hljs-number"><span class="hljs-number">367</span></span>ms</code> </pre> <br><p>  Hooray, another 30 milliseconds! </p><br><p>  How so?  Instead of simple tag transitions, we make chains of callbacks to instruction handlers, spend time on calls and passing arguments, but our little pig still runs along the tracks faster than a simple switch with its labels. </p><br><p>  Such a performance gain in runs is achieved due to three factors: </p><br><ol><li>  Predicting branches scattered in different places in the code is easy. </li><li>  The arguments of the handlers are always pre-decoded into a full machine word, and this is done only once - during the compilation of the trace. </li><li>  The compiler itself turns the chains of functions into a single call to the first handler function, which is possible due to optimization of the <a href="https://en.wikipedia.org/wiki/Tail_call">tail call</a> . </li></ol><br><p>  Before summing up our training sessions, the pig and I decided to try another ancient program interpretation technique - embroidered code. </p><br><h1 id="uprazhnenie-chetvertoe-shityy-kod">  Exercise Four: "sewn" code </h1><br><p>  Anyone interested in the history of interpreters, the pig heard about the <em>sewn code</em> (eng. Threaded code).  The options for this technique are many, but they all boil down to going through an array instead of an array of opcodes, for example, function pointers or labels, passing on them directly, without an intermediate opcode. </p><br><p>  Challenges to functions are expensive and have no special meaning these days;  Most of the other versions of the sewn code are not feasible in the framework of the standard C. Even the technique described below uses the widespread, but non-standard extension C - pointers to tags. </p><br><p>  In the version of the sewed code (eng. Token threaded code), which I chose to achieve our swine goals, we save the byte code, but before interpreting we create a table that displays opcodes of instructions to the addresses of instructions handler instructions: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> *labels[] = { [OP_PUSHI] = &amp;&amp;op_pushi, [OP_LOADI] = &amp;&amp;op_loadi, [OP_LOADADDI] = &amp;&amp;op_loadaddi, [OP_STORE] = &amp;&amp;op_store, [OP_STOREI] = &amp;&amp;op_storei, [OP_LOAD] = &amp;&amp;op_load, [OP_DUP] = &amp;&amp;op_dup, [OP_DISCARD] = &amp;&amp;op_discard, [OP_ADD] = &amp;&amp;op_add, [OP_ADDI] = &amp;&amp;op_addi, [OP_SUB] = &amp;&amp;op_sub, [OP_DIV] = &amp;&amp;op_div, [OP_MUL] = &amp;&amp;op_mul, [OP_JUMP] = &amp;&amp;op_jump, [OP_JUMP_IF_TRUE] = &amp;&amp;op_jump_if_true, [OP_JUMP_IF_FALSE] = &amp;&amp;op_jump_if_false, [OP_EQUAL] = &amp;&amp;op_equal, [OP_LESS] = &amp;&amp;op_less, [OP_LESS_OR_EQUAL] = &amp;&amp;op_less_or_equal, [OP_GREATER] = &amp;&amp;op_greater, [OP_GREATER_OR_EQUAL] = &amp;&amp;op_greater_or_equal, [OP_GREATER_OR_EQUALI] = &amp;&amp;op_greater_or_equali, [OP_POP_RES] = &amp;&amp;op_pop_res, [OP_DONE] = &amp;&amp;op_done, [OP_PRINT] = &amp;&amp;op_print, [OP_ABORT] = &amp;&amp;op_abort, };</code> </pre> <br><p>  Pay attention to the characters &amp;&amp; - these are pointers to labels with instruction bodies, this is a non-standard extension of GCC. </p><br><p>  To start the execution of the code, it is enough to jump on the pointer to the label corresponding to the first opcode of the program: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">goto</span></span> *labels[NEXT_OP()];</code> </pre> <br><p>  There is no loop here and there will not be; each of the instructions itself makes a jump to the next handler: </p><br><pre> <code class="cpp hljs">op_pushi: { <span class="hljs-comment"><span class="hljs-comment">/* get the argument, push it onto stack */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint16_t</span></span> arg = NEXT_ARG(); PUSH(arg); <span class="hljs-comment"><span class="hljs-comment">/* jump to the next instruction*/</span></span> <span class="hljs-keyword"><span class="hljs-keyword">goto</span></span> *labels[NEXT_OP()]; }</code> </pre> <br><p>  The absence of a switch ‚Äúsmears‚Äù the branch points along the instruction bodies, which in theory should help the branch predictor in the case of an extraordinary execution of instructions.  We as if built in switch directly into instructions and manually formed the transition table. </p><br><p>  That's the whole technique.  Piglet liked it for its simplicity.  Let's see what happens in practice: </p><br><pre> <code class="hljs pgsql">&gt; ./pigletvm runtimes test/sieve.bin <span class="hljs-number"><span class="hljs-number">100</span></span> &gt; /dev/<span class="hljs-keyword"><span class="hljs-keyword">null</span></span> PROFILE: switch code finished took <span class="hljs-number"><span class="hljs-number">443</span></span>ms PROFILE: switch code (<span class="hljs-keyword"><span class="hljs-keyword">no</span></span> range <span class="hljs-keyword"><span class="hljs-keyword">check</span></span>) finished took <span class="hljs-number"><span class="hljs-number">389</span></span>ms PROFILE: threaded code finished took <span class="hljs-number"><span class="hljs-number">477</span></span>ms PROFILE: trace code finished took <span class="hljs-number"><span class="hljs-number">364</span></span>ms</code> </pre> <br><p>  Oops!  This is the slowest of all our techniques!  What happened?  Perform the same tests by turning off all GCC optimizations: </p><br><pre> <code class="hljs pgsql">&gt; ./pigletvm runtimes test/sieve.bin <span class="hljs-number"><span class="hljs-number">100</span></span> &gt; /dev/<span class="hljs-keyword"><span class="hljs-keyword">null</span></span> PROFILE: switch code finished took <span class="hljs-number"><span class="hljs-number">969</span></span>ms PROFILE: switch code (<span class="hljs-keyword"><span class="hljs-keyword">no</span></span> range <span class="hljs-keyword"><span class="hljs-keyword">check</span></span>) finished took <span class="hljs-number"><span class="hljs-number">940</span></span>ms PROFILE: threaded code finished took <span class="hljs-number"><span class="hljs-number">824</span></span>ms PROFILE: trace code finished took <span class="hljs-number"><span class="hljs-number">1169</span></span>ms</code> </pre> <br><p>  Here the stitched code shows itself better. </p><br><p>  Three factors play a role here: </p><br><ol><li>  The optimizing compiler itself will build the transition table as well as our manual label table. </li><li>  Modern compilers remarkably get rid of unnecessary function calls. </li><li>  Approximately since the Intel generation of Haswell processors, branch predictors have learned to accurately predict transitions through a single branch point. </li></ol><br><p>  According to the old memory, this technique is still used in the code, for example, the Python VM interpreter, but, to be honest, these days it‚Äôs already archaism. </p><br><p>  Let's finally summarize and evaluate the success that our pig has achieved. </p><br><h1 id="razbor-porosyachih-poletov">  Parsing pig flights </h1><br><p><img src="https://habrastorage.org/webt/co/vy/6k/covy6k28ts8__ozuzuswtqpcora.jpeg"><br>  I'm not sure that this can be called a flight, but let's admit, our little pig has come a long way from 550 milliseconds for a hundred runs on the ‚Äúsieve‚Äù to the final 370 milliseconds.  We used different techniques: superinstructions, getting rid of checking intervals of values, complicated mechanics of tracks, and finally, even embroidered code.  At the same time, we, in general, acted within the framework of things implemented in all popular C compilers. Acceleration one and a half times, it seems to me, this is a good result, and the pig deserved an extra portion of bran in the trough. </p><br><p>  One of the implicit conditions that we set ourselves with the pig, is the preservation of the stack architecture of the PoroVM machine.  The transition to the register architecture, as a rule, reduces the number of instructions required for program logic and, accordingly, can help get rid of unnecessary exits to the instructions manager.  I think another 10-20% of the time on this could be cut. </p><br><p>  Our main condition - the lack of dynamic compilation - is also not a law of nature.  To pump up a pig with steroids in the form of a JIT compilation these days is very easy: in libraries like <a href="https://en.wikipedia.org/wiki/GNU_lightning">GNU Lightning</a> or <a href="https://www.gnu.org/software/libjit/">LibJIT,</a> all the dirty work has already been done.  But the time to develop and the total amount of code even with the use of libraries is greatly increased. </p><br><p>  There are, of course, other techniques to which our little pigs do not have hoofs.    ,     ‚Äî       - ‚Äî    - .         ,       . </p><br><p> <strong>PS</strong>    ,  ,   ,   ,   ( <a href="https://www.instagram.com/vovazomb/">https://www.instagram.com/vovazomb/</a> ),   . </p><br><p> <strong>PPS</strong>       ,     .  <a href="https://habr.com/users/true-grue/" class="user_link">true-grue</a> -           ‚Äî <a href="https://github.com/true-grue/PigletC">PigletC</a> .     ! </p><br><p> <strong>PPPS</strong>  <a href="https://habr.com/users/iliazeus/" class="user_link">iliazeus</a>    :      .            ;             .      <a href=""></a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/428878/">https://habr.com/ru/post/428878/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../428868/index.html">Multi-release JARs - Bad or Good?</a></li>
<li><a href="../428870/index.html">Mrr: Total FRP for React</a></li>
<li><a href="../428872/index.html">The story of one eye and 20 operations (not read impressionable), or he wanted to be a pilot, but he was not allowed into the sky</a></li>
<li><a href="../428874/index.html">The government has banned registration in messengers by someone else's numbers</a></li>
<li><a href="../428876/index.html">There is no way back: personal tester experience</a></li>
<li><a href="../428880/index.html">New authentication methods - a threat to privacy?</a></li>
<li><a href="../428882/index.html">Mobile Yandeks.Blitz: parse tasks</a></li>
<li><a href="../428884/index.html">Published DevOps service files from Sberbank employee</a></li>
<li><a href="../428888/index.html">qml: power and simplicity</a></li>
<li><a href="../428890/index.html">The whole truth about the RTOS. Article # 18. Event flag groups: helper services and data structures</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>