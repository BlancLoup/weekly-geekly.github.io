<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Machine hearing. SoundNet neural network trained to recognize objects by sound</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Left: an attempt to recognize the scene and objects only by sound. Right: real sound source 

 Recently, neural networks have made considerable progre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Machine hearing. SoundNet neural network trained to recognize objects by sound</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/ddf/3fb/5b2/ddf3fb5b2c1f4db590d386cf633c3503.jpg"><br>  <i>Left: an attempt to recognize the scene and objects only by sound.</i>  <i>Right: real sound source</i> <br><br>  Recently, neural networks have made considerable progress in the recognition of objects and scenes in the video.  Such achievements were made possible by training on massive datasets with labeled objects (for example, see the work <a href="http://places.csail.mit.edu/places_NIPS14.pdf">"Learning deep</a> areas for scenarios <a href="http://places.csail.mit.edu/places_NIPS14.pdf">using places database"</a> . NIPS, 2014).  Looking at photographs or video clips, a computer can almost accurately determine the scene of action by selecting one suitable description from <a href="http://places.csail.mit.edu/">401 scenes</a> , for example, ‚Äúcluttered kitchen‚Äù, ‚Äústylish kitchen‚Äù, ‚Äúteenager‚Äôs bedroom‚Äù, etc.  But in the field of understanding the sound neural networks have not yet demonstrated such progress.  Specialists from the Laboratory of Informatics and Artificial Intelligence (CSAIL) of the Massachusetts Institute of Technology have corrected this deficiency by developing the machine learning system <a href="http://projects.csail.mit.edu/soundnet/">SoundNet</a> . <br><a name="habracut"></a><br>  In fact, the ability to determine the scene from the sounds is just as important as determining the location from the video.  In the end, the picture from the camera can often be blurred or not provide enough information.  But if the microphone works - the robot will already be able to navigate where it is. <br><br>  From the point of view of science, learning the SoundNet neural network is quite a commonplace task.  Employees of CSAIL used the method of natural synchronization between machine vision and computer hearing, teaching the neural network to automatically extract the sound representation of the object from unallocated video material.  About 2 million Flickr videos (26 TB of data) were used for training, as well as an annotated sound database ‚Äî 50 categories and approximately 2000 samples. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/148/b51/575/148b5157503a4b499feabc69aa563d2a.png"><br>  <i>SoundNet Neural Network Architecture</i> <br><br>  Although the neural network was trained under visual observation, the system gives an excellent result offline by classifying at least three standard acoustic scenes for which the developers checked it.  Moreover, testing the neural network showed that it independently learned to recognize sounds characteristic for some scenes, and the developers did not provide its samples for recognizing these objects specifically.  According to the base of unmarked video materials, the neural network itself learned what scene corresponds to the sound of a jubilant crowd (this is a stadium) and bird chirping (this is a lawn or a park).  Simultaneously with the scene, the neural network recognizes the specific object that is the source of the sound. <br><br>  The video shows some examples of object recognition by sound.  Initially, the sound sounds and the recognition result is shown, and the picture itself is blurred - so you can try to check yourself.  Can you understand the location and the presence of certain objects only by sound as accurately as a neural network does.  For example, what does the song "Happy Birthday To You!" Most likely mean that a few people sing in chorus?  The correct answer is: the object is <font color="white">burning candles</font> , the scene is a <font color="white">restaurant, cafe, bar</font> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yJCjVvIY4dU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  "Machine vision has become so good that we can transfer this technology to other areas," <a href="http://news.mit.edu/2016/computer-learns-recognize-sounds-video-1202">said</a> Carl Vondrick, a student at the Massachusetts Institute of Technology in electrical engineering and computer science, one of the authors of the scientific work.  - We used the natural relationship between computer vision and sound.  It was possible to achieve a large scale due to a multitude of unpartitioned video materials so that the neural network learned to understand sound. ‚Äù <br><br>  SoundNet was tested on two standard sound recording bases, and it showed 13‚Äì15% higher accuracy of object recognition than the best of such programs.  On a data set with 10 different sound categories, SoundNet classifies sounds with 92% accuracy, and on a data set with 50 categories, it shows accuracy of 74%.  For comparison, on the same data sets, people show recognition accuracy, on average, 96% and 81%. <br><br><img src="https://habrastorage.org/files/b91/d3c/4fb/b91d3c4fb4f24d13b133a6706f528744.png"><br><br>  Even people sometimes can not exactly determine what exactly they hear.  Try this experiment on your own.  Let a colleague launch an arbitrary video from YouTube - and you try to say without looking at the monitor what is happening, where the sounds come from and what is shown on the screen.  Not always you can guess.  So the challenge for artificial intelligence is really not easy, but SoundNet managed quite well to cope with it. <br><br>  In the future, such computer programs may find practical practical value.  For example, your mobile phone will automatically recognize that you have come to a public place - a cinema or theater, and automatically muffle the volume of a call.  If the movie began and the audience subsided, the phone will automatically turn off the sound and turn on the vibrating alert. <br><br>  Orientation by terrain by sound will help in control programs for autonomous robots and other machines. <br><br>  In security systems and smart homes, the system can respond to specific sounds in a specific way.  For example, the sound of a broken window.  In the smart cities of the future, recognizing noise on the streets will help you understand its causes and deal with sound pollution. <br><br>  The scientific article was <a href="https://arxiv.org/abs/1610.09001">published</a> on October 27, 2016 in open access on the site arXiv.org (arXiv: 1610.09001, <a href="https://arxiv.org/pdf/1610.09001v1">pdf</a> ). </div><p>Source: <a href="https://habr.com/ru/post/399659/">https://habr.com/ru/post/399659/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../399649/index.html">A breakthrough in energy storage or another case when a scientist "abused" a journalist?</a></li>
<li><a href="../399651/index.html">Cold nuclear fusion: experiments create energy that should not be</a></li>
<li><a href="../399653/index.html">Megahertz is not caught, the kernels do not grow. What happened to the technical progress in the PC?</a></li>
<li><a href="../399655/index.html">Available 3D milling machines with CNC, from 250,000 to 1,000,000 rubles</a></li>
<li><a href="../399657/index.html">Kettle path to astrophoto. Part 3 - Orion Nebula (M42)</a></li>
<li><a href="../399663/index.html">Ask Ethan # 110: what did the sky look like when the Earth was still formed?</a></li>
<li><a href="../399665/index.html">If only not by bread alone</a></li>
<li><a href="../399669/index.html">Step aside: why the MacBook Pro touchbar does not help the development of touch interfaces</a></li>
<li><a href="../399671/index.html">Snake robot for laser cutting of nuclear waste</a></li>
<li><a href="../399673/index.html">Always in the lead: a consolidated review of Russian DVRs AdvoCam</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>