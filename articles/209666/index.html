<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Creating reliable iSCSI storage on Linux, part 2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Part one 

 We continue 
 We continue the creation of the cluster, begun by the first part . 
 This time I will talk about setting up the cluster. 

 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Creating reliable iSCSI storage on Linux, part 2</h1><div class="post__text post__text-html js-mediator-article">  <a href="https://habr.com/post/209460/">Part one</a> <br><br><h4>  We continue </h4><br>  We continue the creation of the cluster, begun by the <a href="http://habrahabr.ru/post/209460/">first part</a> . <br>  This time I will talk about setting up the cluster. <br><br>  Last time we ended up in what started the synchronization of DRBD. <br>  If we have chosen the same server as the Primary server for both resources, then after the synchronization is completed, we should see something like this in <b>/ proc / drbd</b> : <br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /proc/drbd version: 8.4.3 (api:1/proto:86-101) GIT-hash: 89a294209144b68adb3ee85a73221f964d3ee515 build by root@debian-service, 2013-04-30 07:43:49 0: cs:Connected ro:Secondary/Primary ds:UpToDate/UpToDate B r----- ns:0 nr:190397036 dw:190397036 dr:1400144904 al:0 bm:4942 lo:0 pe:0 ua:0 ap:0 ep:1 wo:d oos:0 1: cs:Connected ro:Secondary/Primary ds:UpToDate/UpToDate B r----- ns:0 nr:720487828 dw:720485956 dr:34275816 al:0 bm:3749 lo:468 pe:0 ua:0 ap:0 ep:1 wo:d oos:0</span></span></code> </pre> <br>  The most interesting field here is <b>ds: UpToDate / UpToDate</b> , meaning that both local and remote copies are relevant. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      After that, we will transfer resources to the secondary mode - then they will be managed by the cluster: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm secondary VM_STORAGE_1 # drbdadm secondary VM_STORAGE_2</span></span></code> </pre><br><h4>  Posemaker </h4><br>  So, the cluster manager. <br><a name="habracut"></a><br>  In short, it is the brain of the entire system that controls the abstractions called resources. <br>  A cluster resource can be, in principle, anything: IP addresses, file systems, DRBD devices, service programs, and so on.  It's pretty easy to create your own resource, which I had to do to manage iSCSI targets and LUNs, more on that later. <br><br>  Install: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># apt-get install pacemaker</span></span></code> </pre><br><h5>  Corosync </h5><br>  Pacemaker uses the Corosync infrastructure to communicate between the cluster nodes, so first you need to configure it. <br><br>  Corosync has a wide enough functionality and several modes to support communication between nodes (unicast, multicast, broadcast), has support for RRP (Redundant Ring Protocol), which allows you to use several different ways to communicate between the nodes of the cluster to minimize the risk of getting Split-brain, there are situations where the connection between the nodes is completely lost, and they both believe that the neighbor has died.  As a result, both nodes go into working mode and chaos begins :) <br><br>  Therefore, we will use both replication and external interfaces to ensure cluster connectivity. <br><br><h6>  Proceed to setup </h6><br>  First you need to generate an authorization key: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># corosync-keygen</span></span></code> </pre><br>  It must be placed under the name <b>/ etc / corosync / authkey</b> on both servers. <br><br>  Next, create a config, it should be identical on both nodes: <br><br>  <b>/etc/corosync/corosync.conf</b> <br><pre> <code class="bash hljs">compatibility: none totem { version: 2 secauth: on threads: 3 rrp_mode: active transport: udpu interface { member { memberaddr: 10.1.0.100 } member { memberaddr: 10.1.0.200 } ringnumber: 0 bindnetaddr: 10.1.0.0 mcastport: 5405 ttl: 1 } interface { member { memberaddr: 192.168.123.100 } member { memberaddr: 192.168.123.200 } ringnumber: 1 bindnetaddr: 192.168.123.0 mcastport: 5407 ttl: 1 } } amf { mode: disabled } service { ver: 1 name: pacemaker } aisexec { user: root group: root } logging { syslog_priority: warning fileline: off to_stderr: yes to_logfile: no to_syslog: yes syslog_facility: daemon debug: off timestamp: on logger_subsys { subsys: AMF debug: off tags: enter|leave|trace1|trace2|trace3|trace4|trace6 } }</code> </pre><br>  Here we describe two rings for communication - internal (via replication ports) and external (via switches), select the <b>udpu</b> protocol (UDP Unicast) and specify the IP addresses of the nodes in each ring.  I also had the idea to connect the nodes with a null modem cable, raise the PPP connection and put a third ring through it, but common sense suggested in time that it would come down. <br><br>  Everything, it is possible to start Pacemaker (it will start Corosync previously). <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># /etc/init.d/pacemaker start</span></span></code> </pre><br>  The entire configuration of Pacemaker is done via the <b>crm</b> utility, and it can be run on any server in the cluster ‚Äî it will automatically update the configuration on all the nodes after the change. <br><br>  Let's see the current status: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># crm status ============ Last updated: Mon Jan 20 15:33:29 2014 Last change: Fri Jan 17 18:30:48 2014 via cibadmin on server1 Stack: openais Current DC: server1 - partition WITHOUT quorum Version: 1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff 2 Nodes configured, 2 expected votes 0 Resources configured. ============ Online: [ server1 server2 ]</span></span></code> </pre><br>  If everything is approximately like this, then the connection is established and the nodes of each other see. <br><br>  Now we need resources to manage SCST. <br>  I once found them somewhere on the Internet, modified it to fit my needs and put it on <a href="https://github.com/blind-oracle/ocf-scst">Github</a> . <br><br>  From there we need two files: <br><ul><li>  <b>SCSTLun</b> - manages device creation </li><li>  <b>SCSTTarget</b> - manages the creation of iSCSI targets </li></ul><br>  These are, in fact, ordinary bash scripts that implement the simple Pacemaker API. <br>  Put them in <b>/usr/lib/ocf/resource.d/heartbeat</b> so that the cluster manager can see them. <br><br>  Next, run <b>crm</b> and enter configuration mode: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># crm crm(live)# configure crm(live)configure# edit</span></span></code> </pre><br>  A text editor opens (usually nano) and you can begin to describe the resources and their interactions. <br><br>  I will give an example configuration: <br><pre> <code class="bash hljs">node server1 node server2 primitive DRBD_VM_STORAGE_1 ocf:linbit:drbd \ params drbd_resource=<span class="hljs-string"><span class="hljs-string">"VM_STORAGE_1"</span></span> drbdconf=<span class="hljs-string"><span class="hljs-string">"/etc/drbd.conf"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"29"</span></span> role=<span class="hljs-string"><span class="hljs-string">"Master"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"31"</span></span> role=<span class="hljs-string"><span class="hljs-string">"Slave"</span></span> primitive DRBD_VM_STORAGE_2 ocf:linbit:drbd \ params drbd_resource=<span class="hljs-string"><span class="hljs-string">"VM_STORAGE_2"</span></span> drbdconf=<span class="hljs-string"><span class="hljs-string">"/etc/drbd.conf"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"29"</span></span> role=<span class="hljs-string"><span class="hljs-string">"Master"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"31"</span></span> role=<span class="hljs-string"><span class="hljs-string">"Slave"</span></span> primitive IP_iSCSI_1_1 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.24.10"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int1.24"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_1_2 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.25.10"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int2.25"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_1_3 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.26.10"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int3.26"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_1_4 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.27.10"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int4.27"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_1_5 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.28.10"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int5.28"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_1_6 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.29.10"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int6.29"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_2_1 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.24.20"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int1.24"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_2_2 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.25.20"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int2.25"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_2_3 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.26.20"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int3.26"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_2_4 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.27.20"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int4.27"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_2_5 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.28.20"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int5.28"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive IP_iSCSI_2_6 ocf:heartbeat:IPaddr2 \ params ip=<span class="hljs-string"><span class="hljs-string">"10.1.29.20"</span></span> cidr_netmask=<span class="hljs-string"><span class="hljs-string">"24"</span></span> nic=<span class="hljs-string"><span class="hljs-string">"int6.29"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> primitive ISCSI_LUN_VM_STORAGE_1 ocf:heartbeat:SCSTLun \ params iqn=<span class="hljs-string"><span class="hljs-string">"iqn.2011-04.ru.domain:VM_STORAGE_1"</span></span> device_name=<span class="hljs-string"><span class="hljs-string">"VM_STORAGE_1"</span></span> \ lun=<span class="hljs-string"><span class="hljs-string">"0"</span></span> path=<span class="hljs-string"><span class="hljs-string">"/dev/drbd0"</span></span> handler=<span class="hljs-string"><span class="hljs-string">"vdisk_fileio"</span></span> primitive ISCSI_LUN_VM_STORAGE_2 ocf:heartbeat:SCSTLun \ params iqn=<span class="hljs-string"><span class="hljs-string">"iqn.2011-04.ru.domain:VM_STORAGE_2"</span></span> device_name=<span class="hljs-string"><span class="hljs-string">"VM_STORAGE_2"</span></span> \ lun=<span class="hljs-string"><span class="hljs-string">"0"</span></span> path=<span class="hljs-string"><span class="hljs-string">"/dev/drbd1"</span></span> handler=<span class="hljs-string"><span class="hljs-string">"vdisk_fileio"</span></span> primitive ISCSI_TGT_VM_STORAGE_1 ocf:heartbeat:SCSTTarget \ params iqn=<span class="hljs-string"><span class="hljs-string">"iqn.2011-04.ru.domain:VM_STORAGE_1"</span></span> \ portals=<span class="hljs-string"><span class="hljs-string">"10.1.24.10 10.1.25.10 10.1.26.10 10.1.27.10 10.1.28.10 10.1.29.10"</span></span> \ tgtoptions=<span class="hljs-string"><span class="hljs-string">"InitialR2T=No ImmediateData=Yes MaxRecvDataSegmentLength=1048576 MaxXmitDataSegmentLength=1048576 MaxBurstLength=1048576 FirstBurstLength=524284 MaxOutstandingR2T=32 HeaderDigest=CRC32C DataDigest=CRC32C QueuedCommands=32 io_grouping_type=never"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> timeout=<span class="hljs-string"><span class="hljs-string">"60s"</span></span> primitive ISCSI_TGT_VM_STORAGE_2 ocf:heartbeat:SCSTTarget \ params iqn=<span class="hljs-string"><span class="hljs-string">"iqn.2011-04.ru.domain:VM_STORAGE_2"</span></span> \ portals=<span class="hljs-string"><span class="hljs-string">"10.1.24.20 10.1.25.20 10.1.26.20 10.1.27.20 10.1.28.20 10.1.29.20"</span></span> \ tgtoptions=<span class="hljs-string"><span class="hljs-string">"InitialR2T=No ImmediateData=Yes MaxRecvDataSegmentLength=1048576 MaxXmitDataSegmentLength=1048576 MaxBurstLength=1048576 FirstBurstLength=524284 MaxOutstandingR2T=32 HeaderDigest=CRC32C DataDigest=CRC32C QueuedCommands=32 io_grouping_type=never"</span></span> \ op monitor interval=<span class="hljs-string"><span class="hljs-string">"10s"</span></span> timeout=<span class="hljs-string"><span class="hljs-string">"60s"</span></span> group GROUP_ISCSI_1 IP_iSCSI_1_1 IP_iSCSI_1_2 IP_iSCSI_1_3 IP_iSCSI_1_4 \ IP_iSCSI_1_5 IP_iSCSI_1_6 ISCSI_TGT_VM_STORAGE_1 ISCSI_LUN_VM_STORAGE_1 group GROUP_ISCSI_2 IP_iSCSI_2_1 IP_iSCSI_2_2 IP_iSCSI_2_3 IP_iSCSI_2_4 \ IP_iSCSI_2_5 IP_iSCSI_2_6 ISCSI_TGT_VM_STORAGE_2 ISCSI_LUN_VM_STORAGE_2 ms MS_DRBD_VM_STORAGE_1 DRBD_VM_STORAGE_1 \ meta master-max=<span class="hljs-string"><span class="hljs-string">"1"</span></span> master-node-max=<span class="hljs-string"><span class="hljs-string">"1"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span>-max=<span class="hljs-string"><span class="hljs-string">"2"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span>-node-max=<span class="hljs-string"><span class="hljs-string">"1"</span></span> \ notify=<span class="hljs-string"><span class="hljs-string">"true"</span></span> target-role=<span class="hljs-string"><span class="hljs-string">"Master"</span></span> ms MS_DRBD_VM_STORAGE_2 DRBD_VM_STORAGE_2 \ meta master-max=<span class="hljs-string"><span class="hljs-string">"1"</span></span> master-node-max=<span class="hljs-string"><span class="hljs-string">"1"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span>-max=<span class="hljs-string"><span class="hljs-string">"2"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span>-node-max=<span class="hljs-string"><span class="hljs-string">"1"</span></span> \ notify=<span class="hljs-string"><span class="hljs-string">"true"</span></span> target-role=<span class="hljs-string"><span class="hljs-string">"Master"</span></span> location PREFER-1 MS_DRBD_VM_STORAGE_1 50: server1 location PREFER-2 MS_DRBD_VM_STORAGE_2 50: server2 colocation COLOC_ALL_1 inf: GROUP_ISCSI_1 MS_DRBD_VM_STORAGE_1:Master colocation COLOC_ALL_2 inf: GROUP_ISCSI_2 MS_DRBD_VM_STORAGE_2:Master order ORDER_ALL_1 inf: MS_DRBD_VM_STORAGE_1:promote GROUP_ISCSI_1:start order ORDER_ALL_2 inf: MS_DRBD_VM_STORAGE_2:promote GROUP_ISCSI_2:start property <span class="hljs-variable"><span class="hljs-variable">$id</span></span>=<span class="hljs-string"><span class="hljs-string">"cib-bootstrap-options"</span></span> \ dc-version=<span class="hljs-string"><span class="hljs-string">"1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff"</span></span> \ cluster-infrastructure=<span class="hljs-string"><span class="hljs-string">"openais"</span></span> \ expected-quorum-votes=<span class="hljs-string"><span class="hljs-string">"2"</span></span> \ stonith-enabled=<span class="hljs-string"><span class="hljs-string">"false"</span></span> \ no-quorum-policy=<span class="hljs-string"><span class="hljs-string">"ignore"</span></span> \ default-action-timeout=<span class="hljs-string"><span class="hljs-string">"240"</span></span> \ last-lrm-refresh=<span class="hljs-string"><span class="hljs-string">"1367942459"</span></span> rsc_defaults <span class="hljs-variable"><span class="hljs-variable">$id</span></span>=<span class="hljs-string"><span class="hljs-string">"rsc-options"</span></span> \ resource-stickiness=<span class="hljs-string"><span class="hljs-string">"100"</span></span></code> </pre><br><h6>  General Cluster Settings </h6><br>  They are at the bottom.  <b>No-quorum-policy = ‚Äúignore‚Äù</b> and <b>expected-quorum-votes = ‚Äú2‚Äù</b> are important here - we have a cluster of 2 servers and there can be no quorum here, so we ignore it. <br><br><h6>  Resources </h6><br>  Usually a resource can have two states - on or off, Started / Stopped. <br>  For example, <b>ocf: heartbeat: IPaddr2</b> picks up IP addresses on the interfaces and removes them, and also sends out gratious arp to update arp-tables.  This resource we specify the IP address, mask and interface. <br><br>  There are also special resources, for example DRBD ( <b>ocf: linbit: drbd</b> ), which have <b>Master / Slave</b> modes. <br>  When the node goes into active mode, the cluster manager will transfer the resource to master mode and vice versa.  DRBD will switch from Secondary to Primary.  For it, we specify the name of the resource and the path to the DRBD config (probably, it can be omitted, I don‚Äôt remember exactly). <br><br>  Next come our own handwritten resources. <br>  For <b>ocf: heartbeat: SCSTLun,</b> we specify the <b>IQN</b> target to which it will be added, <b>the device name</b> , the <b>LUN</b> number, and (the target must have a LUN 0, otherwise some initiators blow the roof), the <b>path to the exported device</b> and <b>the</b> handler . <br><br>  The handler needs to stop in more detail - this is the way SCST will work with our device. <br><br>  From interesting it: <br><ul><li>  <b>disk</b> - in fact, this is just a direct forwarding of SCSI commands from the initiator to the SCSI device, the simplest mode, but it works only with real SCSI devices, it does not suit us, since  export DRBD device </li><li>  <b>vdisk_blockio</b> - opens the device as a block, bypassing the operating system page-cache.  Used if you do not need to cache I / O. </li><li>  <b>vdisk_fileio</b> - opens the device as a file, allowing you to use the operating system page-cache, the most efficient mode, and choose it </li></ul><br>  The <b>vdisk_fileio</b> has an important parameter that affects the speed - <b>nv_cache = 1</b> , it is hardcoded in <b>SCSTLun</b> . <br>  This parameter tells SCST to ignore initiator commands to flush the cache to the device.  Potentially, this may lead to data loss in case of emergency shutdown of the storage because  the initiator will think that the data is on disk, and they are still in memory.  So use at your own risk. <br><br>  Next comes the <b>ocf: heartbeat: SCSTTarget resource</b> , to which we assign <b>IQN</b> , <b>portals</b> is a list of IP addresses through which this target will be available, <b>tgtoptions</b> are iSCSI options, you can read a lot about them. <br><br>  Directives responsible for the behavior of the cluster when starting and stopping resources: <br><ul><li>  <b>group</b> combines resources into a group to work with them as a whole.  Resources in the group are launched sequentially. </li><li>  <b>location</b> indicates on which node we want to see this resource by default. </li><li>  <b>colocation</b> sets what resources should be together on the same node </li><li>  <b>order</b> tells the cluster manager how to start up resources </li></ul><br>  After setting up the resources, exit the editor and apply the changes: <br><pre> <code class="bash hljs">crm(live)configure<span class="hljs-comment"><span class="hljs-comment"># commit crm(live)configure# exit</span></span></code> </pre><br>  After that you can see the current situation: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># crm status ============ Last updated: Mon Jan 20 17:04:04 2014 Last change: Thu Jul 25 13:59:27 2013 via crm_resource on server1 Stack: openais Current DC: server1 - partition with quorum Version: 1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff 2 Nodes configured, 2 expected votes 20 Resources configured. ============ Online: [ server1 server2 ] Resource Group: GROUP_ISCSI_1 IP_iSCSI_1_1 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_1_2 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_1_3 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_1_4 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_1_5 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_1_6 (ocf::heartbeat:IPaddr2): Stopped ISCSI_TGT_VM_STORAGE_1 (ocf::heartbeat:SCSTTarget): Stopped ISCSI_LUN_VM_STORAGE_1 (ocf::heartbeat:SCSTLun): Stopped Resource Group: GROUP_ISCSI_2 IP_iSCSI_2_1 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_2_2 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_2_3 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_2_4 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_2_5 (ocf::heartbeat:IPaddr2): Stopped IP_iSCSI_2_6 (ocf::heartbeat:IPaddr2): Stopped ISCSI_TGT_VM_STORAGE_2 (ocf::heartbeat:SCSTTarget): Stopped ISCSI_LUN_VM_STORAGE_2 (ocf::heartbeat:SCSTLun): Stopped Master/Slave Set: MS_DRBD_VM_STORAGE_1 [DRBD_VM_STORAGE_1] Slaves: [ server1 server2 ] Master/Slave Set: MS_DRBD_VM_STORAGE_2 [DRBD_VM_STORAGE_2] Slaves: [ server1 server2 ]</span></span></code> </pre><br>  We see that the resources are in an inactive state, DRBD in Slave mode (Secondary). <br><br>  Now you can try to activate them: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># crm resource start MS_DRBD_VM_STORAGE_1 # crm resource start MS_DRBD_VM_STORAGE_2</span></span></code> </pre><br>  Starting this resource, we call including the launch of other resources because  they are listed as dependent ( <b>colocation</b> ), and they will be launched in a strictly defined order ( <b>order</b> ): first, DRBD devices will switch to Primary mode, then IP addresses will rise, LUNs will be created and iSCSI targets will be created at the end. <br><br>  See the result: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># crm status ============ Last updated: Tue Jan 21 11:54:46 2014 Last change: Thu Jul 25 13:59:27 2013 via crm_resource on server1 Stack: openais Current DC: server1 - partition with quorum Version: 1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff 2 Nodes configured, 2 expected votes 20 Resources configured. ============ Online: [ server1 server2 ] Resource Group: GROUP_ISCSI_1 IP_iSCSI_1_1 (ocf::heartbeat:IPaddr2): Started server1 IP_iSCSI_1_2 (ocf::heartbeat:IPaddr2): Started server1 IP_iSCSI_1_3 (ocf::heartbeat:IPaddr2): Started server1 IP_iSCSI_1_4 (ocf::heartbeat:IPaddr2): Started server1 IP_iSCSI_1_5 (ocf::heartbeat:IPaddr2): Started server1 IP_iSCSI_1_6 (ocf::heartbeat:IPaddr2): Started server1 ISCSI_TGT_VM_STORAGE_1 (ocf::heartbeat:SCSTTarget): Started server1 ISCSI_LUN_VM_STORAGE_1 (ocf::heartbeat:SCSTLun): Started server1 Resource Group: GROUP_ISCSI_2 IP_iSCSI_2_1 (ocf::heartbeat:IPaddr2): Started server2 IP_iSCSI_2_2 (ocf::heartbeat:IPaddr2): Started server2 IP_iSCSI_2_3 (ocf::heartbeat:IPaddr2): Started server2 IP_iSCSI_2_4 (ocf::heartbeat:IPaddr2): Started server2 IP_iSCSI_2_5 (ocf::heartbeat:IPaddr2): Started server2 IP_iSCSI_2_6 (ocf::heartbeat:IPaddr2): Started server2 ISCSI_TGT_VM_STORAGE_2 (ocf::heartbeat:SCSTTarget): Started server2 ISCSI_LUN_VM_STORAGE_2 (ocf::heartbeat:SCSTLun): Started server2 Master/Slave Set: MS_DRBD_VM_STORAGE_1 [DRBD_VM_STORAGE_1] Masters: [ server1 ] Slaves: [ server2 ] Master/Slave Set: MS_DRBD_VM_STORAGE_2 [DRBD_VM_STORAGE_2] Masters: [ server2 ] Slaves: [ server1 ]</span></span></code> </pre><br>  If everything is so, then you can congratulate yourself - the cluster is running! <br>  Each resource group is running on its server, as indicated by the <b>location</b> directive in the config. <br><br>  For confirmation, you can see the kernel log - <b>dmesg</b> - there DRBD and SCST output their diagnostics. <br><br><h4>  The end of the second part </h4><br>  In the third and final part I will show how to configure the ESXi servers for optimal performance with this cluster. </div><p>Source: <a href="https://habr.com/ru/post/209666/">https://habr.com/ru/post/209666/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../209654/index.html">DipTrace. Innovations</a></li>
<li><a href="../209656/index.html">3D Scanner for iPad</a></li>
<li><a href="../209660/index.html">Romanian bitcoin millionaire paid OpenBSD debts</a></li>
<li><a href="../209662/index.html">Javascript promises</a></li>
<li><a href="../209664/index.html">How to increase the effectiveness of the development method of Kuklachev</a></li>
<li><a href="../209668/index.html">Career Architecture</a></li>
<li><a href="../209670/index.html">Sale of books!</a></li>
<li><a href="../209672/index.html">UpGrade gift - To beauty salon for BTC</a></li>
<li><a href="../209674/index.html">Compromising Target: Latest Data</a></li>
<li><a href="../209676/index.html">The release of FreeBSD10.0 has been released (the announcement is expected, FreeBSD 10.0-RELEASE iso files are available)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>