<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Classification of musical compositions by performers with the help of Hidden Markov Models</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hidden Markov models (Hidden Markov Models) have long been used in speech recognition. Thanks to the chalk-cepstral coefficients (MFCC), it became pos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Classification of musical compositions by performers with the help of Hidden Markov Models</h1><div class="post__text post__text-html js-mediator-article"><img src="https://pp.userapi.com/c844416/v844416390/787f/Ra3Iq_tHtCQ.jpg" alt="image"><br><br>  Hidden Markov models (Hidden Markov Models) have long been used in speech recognition.  Thanks to the chalk-cepstral coefficients (MFCC), it became possible to flip off the signal components that are not essential for recognition, significantly reducing the dimension of the features.  There are many simple examples on the Internet using HMM with MFCC to recognize simple words. <br><br>  After becoming acquainted with these possibilities, there appeared a desire to try out this recognition algorithm in music.  Thus was born the idea of ‚Äã‚Äãthe task of classifying musical compositions by performers.  About attempts, some magic and the results will be discussed in this post. <br><a name="habracut"></a><br><h2>  Motivation </h2><br>  The desire to get acquainted in practice with the hidden Markov models originated a long time ago, and last year I was able to link their practical use with the course project in the magistracy. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      During the pre-project googling, an interesting <a href="http://compbio.fmph.uniba.sk/vyuka/gm/old/2010-02/handouts/Chai2001.pdf">article</a> was found telling about using HMM to classify the folk music of Ireland, Germany and France.  Using a large archive of songs (thousands of songs), the authors of the article try to reveal the existence of a statistical difference between the compositions of different nations. <br><br>  While studying libraries with HMM I came across the code from the <a href="https://github.com/PacktPublishing/Python-Machine-Learning-Cookbook/blob/master/Chapter07/speech_recognizer.py">Python ML Cookbook</a> book, where, using the example of recognizing several simple words, the hmmlearn library was used, which was decided to be tested. <br><br><h2>  Formulation of the problem </h2><br>  In the presence of songs of several musical performers.  The task is to train the classifier based on the HMM to correctly recognize the authors of the songs entering it. <br><br>  Songs are presented in the format ".wav".  The number of songs for different groups is different.  The quality, duration of the compositions also vary. <br><br><h2>  Theory </h2><br>  To understand the operation of the algorithm (which parameters in which training are involved), it is necessary to at least superficially get acquainted with the theory of chalk-cepstral coefficients and hidden Markov models.  More detailed information is available in the <a href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">MFCC</a> and <a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf">HMM</a> articles. <br><br>  MFCC is a representation of a signal, roughly speaking, in the form of a special spectrum, from which components insignificant for human hearing are removed with the help of various filterings and transformations.  The spectrum is short-lived, that is, the signal is initially divided into intersecting segments of 20-40 ms.  It is assumed that on such segments of the signal frequency does not change too much.  And already on these segments and magic coefficients are considered. <br><br>  There is a signal <br><br><img src="https://pp.userapi.com/c840638/v840638035/6b64a/wXdQHQ0tbJ0.jpg" alt="image"><br><br>  25 ms segments are taken from it. <br><br><img src="https://pp.userapi.com/c840638/v840638035/6b630/Kjw1QDDIse0.jpg" alt="image"><br><br>  And for each of them are calculated chalk-cepstral coefficients <br><br><img src="https://pp.userapi.com/c840638/v840638035/6b638/-sOI6SCbu20.jpg" alt="image"><br><br>  The advantage of this view is that for speech recognition, it is enough to take about 16 coefficients for each frame instead of hundreds or thousands, in the case of the usual Fourier transform.  Experimentally, it has been found that in order to highlight these coefficients in songs it is better to take 30-40 components each. <br><br>  For a general understanding of the work of hidden Markov models, you can see the description on the <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BA%25D1%2580%25D1%258B%25D1%2582%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D1%2580%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C">wiki</a> . <br><br>  Their meaning is that there is an unknown set of hidden states <math> </math> $ inline $ x_1, x_2, x_3 $ inline $   whose manifestation is in some sequence determined by probabilities <math> </math> $ inline $ a_1, a_2, a_3 $ inline $   with some probabilities <math> </math> $ inline $ b_1, b_2, b_3 $ inline $   leads to a set of observed results <math> </math> $ inline $ y_1, y_2, y_3 $ inline $   . <br><br><img src="https://upload.wikimedia.org/wikipedia/commons/d/d5/Hmm.png" alt="image"><br><br>  In our case, the observed results are mfcc for each frame. <br>  <a href="https://habrahabr.ru/post/188244/">The Baum-Welch algorithm</a> (a special case of the more well-known EM algorithm) is used to find the unknown parameters of the HMM.  It is he who is engaged in training the model. <br><br><h2>  Implementation </h2><br>  Let's start, finally, to the code.  The full version is available <a href="https://github.com/Sklert/SongToBandClassifier">here</a> . <br><br>  The <a href="https://librosa.github.io/librosa/">librosa</a> library was chosen for the calculation of the MFCC.  You can also use the <a href="https://github.com/jameslyons/python_speech_features">python_speech_features</a> library, which, unlike librosa, implements only the functions necessary for calculating the chalk-core coefficients. <br><br>  We will take the songs in the format ".wav".  Below is the function for calculating the MFCC, which accepts the name of the ".wav" file as input. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getFeaturesFromWAV</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, filename)</span></span></span><span class="hljs-function">:</span></span> audio, sampling_freq = librosa.load( filename, sr=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, res_type=self._res_type) features = librosa.feature.mfcc( audio, sampling_freq, n_mfcc=self._nmfcc, n_fft=self._nfft, hop_length=self._hop_length) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> self._scale: features = sklearn.preprocessing.scale(features) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> features.T</code> </pre> <br>  On the first line, the usual download of the ".wav" file occurs.  The stereo file is converted to a single channel format.  librosa allows for different resampling, I stopped at <code>res_type='scipy'</code> . <br><br>  I considered it necessary to specify three basic parameters for the calculation of attributes: <code>n_mfcc</code> - the number of chalk-cepstral coefficients, <code>n_fft</code> - the number of points for the fast Fourier transform, <code>hop_length</code> - the number of samples for frames (for example, 512 samples for 22kG and will give about 23ms). <br><br>  Scaling is an optional step, but with it I managed to make the classifier more stable. <br><br>  Let us turn to the classifier.  hmmlearn turned out to be an unstable library, in which with each update something breaks.  However, its compatibility with scikit is good news.  At the moment (0.2.1), Hidden Markov Models with Gaussian emissions is the most working model. <br><br>  Separately, I want to note the following model parameters. <br><br><pre> <code class="python hljs">self._hmm = hmm.GaussianHMM(n_components=hmmParams.n_components, covariance_type=hmmParams.cov_type, n_iter=hmmParams.n_iter, tol=hmmParams.tol)</code> </pre><br>  Parameter <code>n_components</code> - determines the number of hidden states.  Relatively good models can be built using 6-8 hidden states.  They learn quite quickly: 10 songs take about 7 minutes on my Core i5-7300HQ 2.50GHz.  But for more interesting models, I preferred to use about 20 hidden states.  I tried more, but on my tests the results did not change much, and the training time increased to several days with the same number of songs. <br><br>  The remaining parameters are responsible for the convergence of the EM algorithm, limiting the number of iterations, accuracy, and determining the type of covariance parameters of states. <br><br>  hmmlearn is used for teaching without a teacher.  Therefore, the learning process is as follows.  Each class has its own model.  Next, the test signal is run through each model, where it calculates the logarithmic probability of the <code>score</code> each model.  The class that corresponds to the model that produced the highest probability, and is the owner of this test signal. <br><br>  Training in the code of one model looks like this: <br><br><pre> <code class="python hljs"> featureMatrix = np.array([]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(subfolder) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.endswith(<span class="hljs-string"><span class="hljs-string">'.wav'</span></span>)]: filepath = os.path.join(subfolder, filename) features = self.getFeaturesFromWAV(filepath) featureMatrix = np.append(featureMatrix, features, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len( featureMatrix) != <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> features hmm_trainer = HMMTrainer(hmmParams=self._hmmParams) hmm_trainer.train(featureMatrix)</code> </pre><br>  The code runs through the <code>subfolder</code> folder and finds all the ".wav" files, and for each of them it considers the MFCC, which later it simply adds to the matrix of attributes.  In the matrix of attributes, the row corresponds to the frame, the column corresponds to the coefficient number from the MFCC. <br><br>  After the matrix is ‚Äã‚Äãfilled, a hidden Markov model is created for this class, and the signs are transferred to the EM algorithm for training. <br><br>  The classification looks like this. <br><br><pre> <code class="python hljs"> features = self.getFeaturesFromWAV(filepath) <span class="hljs-comment"><span class="hljs-comment">#label is the name of class corresponding to model scores = {} for hmm_model, label in self._models: score = hmm_model.get_score(features) scores[label] = score similarity = sorted(scores.items(), key=lambda t: t[1], reverse=True)</span></span></code> </pre><br>  We wander through all the models and count logarithmic probabilities.  We get a set of classes sorted by probability.  The first element and show who the most likely performer of this song. <br><br><h2>  Results and Improvements </h2><br>  In the training sample were selected songs of seven performers: Anathema, Hollywood Undead, Metallica, Motorhead, Nirvana, Pink Floyd, The XX.  The number of songs for each of them, as well as the songs themselves, were chosen from considerations of which tests I would like to conduct. <br><br>  For example, the Anathema style of the band changed greatly during their career, starting with heavy doom metal and ending with calm progressive rock.  It was decided to send the songs from the first album to the test sample, and more to the training - softer songs. <br><br><div class="spoiler">  <b class="spoiler_title">List of compositions involved in the training</b> <div class="spoiler_text">  Anathema: <br>  Deep <br>  Pressure <br>  Untouchable Part 1 <br>  Lost control <br>  Underworld <br>  One last goodbye <br>  Panic <br>  A Fine Day To Exit <br>  Judgment <br><br>  Hollywood Undead: <br>  Been to hell <br>  SCAVA <br>  We are <br>  Undead <br>  Glory <br>  Young <br>  Coming back down <br><br>  Metallica: <br>  Enter sandman <br>  Nothing Else Matters <br>  Sad but true <br>  Of wolf and man <br>  The unforgiven <br>  The god that failed <br>  Wherever i may room <br>  My friend of misery <br>  Don't Tread On Me <br>  The struggle within <br>  Through the never <br><br>  Motorhead: <br>  Victory or die <br>  The Devil.mp3 <br>  Thunder &amp; lightning <br>  Electricity <br>  Fire storm hotel <br>  Evil eye <br>  Shoot Out All Of Your Lights <br><br>  Nirvana: <br>  Sappy <br>  About A Girl <br>  Something in the way <br>  Come as you are <br>  Endless nameless <br>  Heart Shaped Box <br>  Lithium <br><br>  Pink Floyd: <br>  Another Brick In The Wall pt 1 <br>  Comfortably Numb <br>  The dog of war <br>  Empty Spaces <br>  Time <br>  Wish you were here <br>  Money <br>  On The Turning Away <br><br>  The XX: <br>  Angels <br>  Fiction <br>  Basic space <br>  Crystalised <br>  Fantasy <br>  Unfold <br></div></div><br>  Tests produced a relatively good result (4 out of 16 tests, 4 errors).  Problems appeared while trying to recognize the artist by the cut part of the song. <br><br>  Suddenly it turned out that when the composition itself is classified correctly, a part of it can produce a diametrically opposite result.  Moreover, if this piece of composition contains the beginning of the song, then the model gives the correct result.  But if it still begins with another part of the composition, then the model is entirely sure that this song does not relate to the right performer. <br><br><div class="spoiler">  <b class="spoiler_title">Part of the tests</b> <div class="spoiler_text">  Master Of Puppets to Metallica (True) <br><br>  Master Of Puppets (Cut 00:00 - 00:35) to Metallica (True) <br><br>  Master Of Puppets (Cut 00:20 - 00:55) to Anathema (False, Metallica) <br><br>  The Unforgiven (Cut 01:10 - 01:35) to Anathema (False, Metallica) <br><br>  Heart Shaped Box to Nirvana (True) <br><br>  Heart Shaped Box (Cut 01:00 - 01:40) to Hollywood Undead (False, Nirvana) <br></div></div><br>  The solution was sought for a long time.  Attempts were made to train for 50 or more hidden states (almost three days of training), the number of MFCCs increased to hundreds.  But none of this solved the problem. <br><br>  The problem was solved very severe, but at some level of the subconscious mind a clear idea.  It consisted in randomly mixing (shuffle) rows in the matrix of features before learning.  The result justified itself by slightly increasing the learning time, but producing a more robust algorithm. <br><br><pre> <code class="python hljs"> featureMatrix = np.array([]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(subfolder) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.endswith(<span class="hljs-string"><span class="hljs-string">'.wav'</span></span>)]: filepath = os.path.join(subfolder, filename) features = self.getFeaturesFromWAV(filepath) featureMatrix = np.append(featureMatrix, features, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len( featureMatrix) != <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> features hmm_trainer = HMMTrainer(hmmParams=self._hmmParams) np.random.shuffle(featureMatrix) <span class="hljs-comment"><span class="hljs-comment">#shuffle it hmm_trainer.train(featureMatrix)</span></span></code> </pre><br>  Below are the results of the model test with parameters: 20 hidden states, 40 MFCC, with component scaling and shuffle. <br><br><div class="spoiler">  <b class="spoiler_title">Test results</b> <div class="spoiler_text">  The Man Who Sold The World to Anathema (False, Nirvana) <br><br>  We Are Mot√∂rhead to Motorhead (True) <br><br>  Master Of Puppets to Metallica (True) <br><br>  Empty to Anathema (True) <br><br>  Keep Talking to Pink Floyd (True) <br><br>  Tell Me Who Kill To Motorhead (True) <br><br>  Smells Like Teen Spirit to Nirvana (True) <br><br>  Orion (Instrumental) to Metallica (True) <br><br>  The Silent Enigma to Anathema (True) <br><br>  Nirvana - School to Nirvana (True) <br><br>  A Natural Disaster to Anathema (True) <br><br>  Islands to The XX (True) <br><br>  High Hopes to Pink Floyd (True) <br><br>  Have A Cigar to Pink Floyd (True) <br><br>  Lovelorn Rhapsody to Pink Floyd (False, Anathema) <br><br>  Holier Than Thou to Metallica (True) <br></div></div><br>  Result: 2 mistakes of 16 songs.  In general, not bad, although mistakes scare (Pink Floyd is clearly not so heavy). <br><br>  Tests with clippings of songs pass confidently. <br><br><div class="spoiler">  <b class="spoiler_title">Cuts from songs</b> <div class="spoiler_text">  Master Of Puppets to Metallica (True) <br><br>  Master Of Puppets (Cut 00:00 - 00:35) to Metallica (True) <br><br>  Master Of Puppets (Cut 00:20 - 00:55) to Metallica (True) <br><br>  The Unforgiven (Cut 01:10 - 01:35) to Metallica (True) <br><br>  Heart Shaped Box to Nirvana (True) <br><br>  Heart Shaped Box (Cut 01:00 - 01:40) to Nirvana (True) <br></div></div><br><h2>  Conclusion </h2><br>  The constructed classifier based on hidden Markov models shows satisfactory results, correctly identifying the performers for the majority of compositions. <br><br>  All code is available <a href="https://github.com/Sklert/SongToBandClassifier">here</a> .  To whom it is interesting, he can try to train models on his own compositions.  According to the results, you can also try to identify the common in the music of different groups. <br><br>  For a quick test on the trained compositions, you can look at the <a href="http://hmmtop.herokuapp.com/">site</a> spinning on Heroku (accepts small ".wav" files as input).  The list of compositions on which the model from the site was trained is presented above in the paragraph above under the spoiler. </div><p>Source: <a href="https://habr.com/ru/post/351462/">https://habr.com/ru/post/351462/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../351452/index.html">Why Photo Scarlett Johansson made PostgresSQL Mine Monero</a></li>
<li><a href="../351454/index.html">How to write a random number generator and is it possible to predict Math.random?</a></li>
<li><a href="../351456/index.html">Why let the characters down</a></li>
<li><a href="../351458/index.html">Unity: particle systems</a></li>
<li><a href="../351460/index.html">Computer vision and the Internet of things</a></li>
<li><a href="../351464/index.html">Integration of 3CX with its own CRM system: CRM template generator</a></li>
<li><a href="../351466/index.html">Annual Report on Cyber ‚Äã‚Äãand Info Security for 2017</a></li>
<li><a href="../351468/index.html">Our on Delex: how was the first DevOps and advanced Test Automation conference held in Minsk</a></li>
<li><a href="../351470/index.html">New 4G LTE vulnerabilities: mass mailing, impersonation of subscriber devices and others</a></li>
<li><a href="../351476/index.html">Protection against creative abuse of HSTS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>