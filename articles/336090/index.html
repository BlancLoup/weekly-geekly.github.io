<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why learn Spark?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Why do developers learn Spark? How to master the technology at home? What can, and what does Spark not, and what awaits it in the future? About this -...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why learn Spark?</h1><div class="post__text post__text-html js-mediator-article">  Why do developers learn Spark?  How to master the technology at home?  What can, and what does Spark not, and what awaits it in the future?  About this - in an interview with the trainer for Java and Big Data at EPAM <b>Alexey Zinoviev</b> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/a90/943/a91/a90943a91cec4884ae203b34caa02133.gif"></div><a name="habracut"></a><br><img src="https://habrastorage.org/web/0ec/c19/00d/0ecc1900d2904da48866574b36a8330a.png" alt="image" align="left">  <b>- You're a Java and Big Data trainer - what does this mean?</b>  <b>What do you do?</b> <br><br>  - In EPAM, I prepare and conduct trainings at the request of teams for senior and leading engineers (or, as we say in Aytishchine, signor and lead).  Digging all the themes with the letter J on a deep level is beyond the power of one person, so I specialize in the following: Java Concurrency, JVM Internals (those same guts), Spring Boot, Kafka, Spark, Lombok, the model of actors - in general, on that which allows both to increase the productivity of the developer himself, and to speed up the work of his application.  Of course, if necessary, I can prepare training on Java EE or patterns, but there are already enough such materials both in and outside EPAM. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>- You have listed quite a lot of different topics.</b> <br><br>  ‚ÄúEven in these topics there are always so many new questions and tasks that almost every morning I have to say to myself:‚Äú So, stop, I‚Äôm not doing this. ‚Äù  So, by the cut-off method, it turns out to highlight a number of areas with which I work.  One of them is Spark.  The Spark frameworks family is growing and expanding, so even here one has to choose one to become a real expert.  This year I chose Structured Streaming in order to understand what is going on at the level of its source code and promptly solve the emerging problems. <br><br>  <b>- Why does a developer learn to work with Spark?</b> <br><br>  - Three years ago, if you wanted to do Big Data, you had to be able to unscrew Hadoop, tune it, write bloody JoRa's MapReduce, etc.  Now knowledge of Apache Spark is just as important.  Although now at the interview, any Big Data engineer will still be driven by Hadoop.  But maybe not so carefully, and they will not demand experience of combat use. <br><br>  While under Hadoop, integration bridges with other data formats, platforms, and frameworks were long and painful, in the case of Spark we see a different situation.  The community that develops it competes to compete to connect the next NoSQL database by writing a connector for it. <br><br>  This leads to the fact that many large companies pay attention to Spark and migrate to it: most of their wishes are realized there.  Previously, they copied Hadoop in general detail, and at the same time they had their zest, associated with supporting additional operations, some kind of internal optimizer, etc. <br><br>  <b>- There is a Spark Zoo.</b>  <b>What can you do with it?</b> <br><br>  - First, Spark Zoo helps to quickly build reports, extract facts, aggregates from a large number of both static data and rapidly flowing into your Data Lake. <br><br>  Secondly, it solves the problem of integrating machine learning and distributed data, which are spread across the cluster and calculated in parallel.  This is done quite easily, and at the expense of R- and Python-connectors Spark's capabilities can be used by data scientists who are as far from the problems of building high-performance backends as possible. <br><br>  Thirdly, he copes with the problem of integrating everything with everything.  Everyone writes Spark connectors.  Spark can be used as a quick filter to reduce the dimension of the input data.  For example, distilling, filtering and aggregating a stream from Kafka, adding it to MySQL, why not? <br><br>  <b>- Are there problems that Spark can't handle?</b> <br><br>  - Of course there is, because we are still not at the framework fair, so that I can sell you the perfect hammer with which to paint the walls.  If we talk about the same machine learning, work on building an ideal framework is still underway.  Many copies of the final API design are broken, some of the algorithms are not parallelized (there are only articles and implementations of a single-threaded version). <br><br>  There is a certain problem that Spark Core has already changed three turns of the API: RDD, DataFrame, DataSet.  Many components are still built on RDD (I mean Streaming, most of the MLlib algorithms, processing large graphs). <br><br>  <b>- What about new Spark frameworks?</b> <br><br>  - All of them are not good enough to use in production.  The most ready now is Structured Streaming, which came out of the experimental underground.  But it is not yet possible in it, for example, to join the two threads.  You have to roll back and write on the DStreams / DataFrames mix.  But there are almost no problems with the fact that developers break API from version to version.  Everything is quite calm here, and the code written on Spark a couple of years ago will still work with minor changes. <br><br>  <b>- Where is Spark going?</b>  <b>What tasks will he be able to solve in the near future?</b> <br><br>  - Spark moves to a total square-nested perception of reality a la DataFrame everywhere, for all components.  This will allow you to safely remove RDD support in Spark 3.0 and fully concentrate on the engine to optimize the SparkAssembler that your top-level set of operations on labels turns into.  Spark follows the path of strong integration with DeepLearning, in particular, by the TensorFrames project. <br><br>  <b>- What to expect in a year, for example?</b> <br><br>  - I think in 2018 there will be more than now, monitoring tools, deployment and other services that will offer ‚ÄúSpark-cluster in one click with full integration with the whole row and visual designer‚Äù for reasonable money or even slightly free - only with server time billing. <br><br>  <b>- On Youtube there are a lot of videos, how to put Spark in two clicks, but few materials about what to do next.</b>  <b>What do you advise?</b> <br><br>  - I can recommend several resources: <br><br><ul><li>  <a href="https://databricks.com/blog/category/engineering/spark">Databricks blog</a> (eng) - the main source of information </li><li>  <a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/">Mastering Apache Spark 2</a> (eng) - the most complete GitBook on all aspects of Spark in the style of technical documentation </li><li>  <a href="https://zaleslaw.gitbooks.io/data-processing-book/content/">Data processing on Spark 2.2 and Kafka 0.10</a> (rus) - practical cases </li><li>  <a href="https://www.youtube.com/playlist%3Flist%3DPL972if8tX2vpdaa4OcZ76sZ1fBYqJbPcB">BigData / Hadoop / Spark video</a> (rus) - a set of my videos from various conferences </li><li>  <a href="https://www.youtube.com/user/TheApacheSpark">Spark Summit video</a> (eng) - festival of swimming pools from around the world. </li></ul><br>  <b>- What level developers should master Spark?</b> <br><br>  - It is possible, of course, to plant code writing on Spark and a person who has a couple of labs on Pascal or Python.  "Hello World" he can run without problems, but why is he? <br>  It seems to me that studying Spark will be useful for developers who have already worked in the ‚Äúbloody enterprise‚Äù, signed backends, stored procedures.  The same goes for those who have solid experience in setting up the DBMS and optimizing queries, who have not yet forgotten Computer Science, who like to think how to process data, lowering the constant in evaluating the complexity of an algorithm.  If you have been working together for several years now, and ‚Äúpoking around in the sources‚Äù is not yours, it is better to go past Spark. <br><br>  <b>- Is it possible to master Spark at home?</b> <br><br>  - You can start with a laptop, which is at least 8Gb RAM and a couple of cores.  Just put IDEA Community Edition + Scala Plugin + Sbt (you can also Maven), throw a couple of dependencies and go ahead.  This will work even under Windows, but, of course, it‚Äôs better to roll out everything at once under Ubuntu / CentOS. <br><br>  After that, you can deploy a small Spark cluster in the cloud for a project with data collection on the Web or to process any open dataset from <a href="https://github.com/caesar0301/awesome-public-datasets">github.com/caesar0301/awesome-public-datasets</a> .  Well, read my <a href="https://zaleslaw.gitbooks.io/data-processing-book/">GitBook</a> , of course. <br><br>  <b>- What difficulties do you usually encounter when working with Spark?</b> <br><br>  ‚ÄúWhat works on a small dataset (test methods and some JVM settings) often behaves differently on large hips in production. <br><br>  Another difficulty for a Java developer is to learn Scala.  Most of the code base and function signatures require reading Scala code with a dictionary.  However, this is a pleasant difficulty. <br><br>  And last but not least, complexity - even the Pet Project on a ‚Äúsmall cluster‚Äù and ‚Äúmedium hand dataset‚Äù is very expensive.  Accounts for Amazon are increasing in comparison with web-crafts to protect the next Java framework. <br><br>  On September 9, in Petersburg, I will conduct an Apache Spark <a href="https://events.epam.com/events/spark-ballet">training</a> for Java developers.  I will share my experience and tell you what Spark components should be used immediately, how to set up the environment, build your ETL process, how to work with the newest version of Spark and not only. </div><p>Source: <a href="https://habr.com/ru/post/336090/">https://habr.com/ru/post/336090/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../336080/index.html">Creating a programming language using LLVM. Part 6: Language Extension: User Defined Operators</a></li>
<li><a href="../336082/index.html">Angular - Implementing secure queries to the GraphQL API via JWT tokens</a></li>
<li><a href="../336084/index.html">Zabbix 3.4 released</a></li>
<li><a href="../336086/index.html">How to build a storage system with rocket on a standard hardware? SDS RAIDIX hardware platform architecture</a></li>
<li><a href="../336088/index.html">The future of web technologies: creating an intelligent chat bot that can hear and speak</a></li>
<li><a href="../336092/index.html">I'm not guilty. He came</a></li>
<li><a href="../336094/index.html">How Yandex taught artificial intelligence to understand the meaning of documents</a></li>
<li><a href="../336096/index.html">Declarative web programming</a></li>
<li><a href="../336098/index.html">Dive into BerkeleyDB JE. Introduction to DPL API</a></li>
<li><a href="../336100/index.html">Notation Oh-big and complexity of social interactions</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>