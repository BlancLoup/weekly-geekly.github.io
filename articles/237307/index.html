<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to deal with repost or a couple of words about perceptual hashes</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This publication focuses on perceptual image hashes and their use (for example, searching for duplicates). 

 Perceptual hash algorithms describe a cl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to deal with repost or a couple of words about perceptual hashes</h1><div class="post__text post__text-html js-mediator-article">  This publication focuses on perceptual image hashes and their use (for example, searching for duplicates). <br><br>  Perceptual hash algorithms describe a class of functions for generating comparable hashes.  They use various properties of the image to build an individual ‚Äúprint‚Äù.  In the future, these "prints" can be compared with each other. <br><br>  If the hashes are different, then the data is different.  If the hashes match, then the data is most likely the same (since there is a possibility of collisions, then the same hashes do not guarantee the coincidence of the data).  This article focuses on several popular methods for constructing perceptual image hashes, as well as a simple way to deal with collisions.  Anyone interested, please under the cat. <br><a name="habracut"></a><br><h4>  Overview </h4><br>  There are many different approaches to the formation of perceptual image hashes.  All of them are united by 3 main stages: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  Preliminary processing.  At this stage, the image is reduced to a form in which it is easier to process it to build a hash.  This may be the use of various filters (for example, Gauss), discoloration, image size reduction, etc. </li><li>  Basic calculations.  A matrix (or a vector) is constructed from the image obtained at stage 1.  The matrix (vector) can be a matrix of frequencies (for example, after a Fourier transform), a histogram of brightness, or an even simpler image. </li><li>  Build a hash.  From the matrix (vector) obtained in stage 2, some (possibly all) coefficients are taken and converted into a hash.  Usually the hash is obtained in size from 8 to ~ 100 bytes.  The calculated hash values ‚Äã‚Äãare then compared using functions that calculate the ‚Äúdistance‚Äù between two hashes. </li></ul><br><br>  In this publication, we will not deal with the implementation of the above algorithms.  It is an overview and tells about different approaches to the construction of hashes. <br><br><h4>  Perceptual Hash Algorithms </h4><br>  We will consider 4 different hash algorithms: Simple Hash [4], DCT Based Hash [1], [11], Radial Variance Based Hash [1], [5] and Marr-Hildreth Operator Based Hash [1], [6] . <br><br><h5>  Simple Hash (aka Average Hash) </h5><br>  The essence of this algorithm is to display the average value of low frequencies.  In images, high frequencies provide detail, while low ones show structure.  Therefore, to build such a hash function, which for similar images will produce a close hash, you need to get rid of high frequencies.  Principle of operation: <br><br><ul><li>  <b>Reduce the size.</b>  The fastest way to get rid of high frequencies is to reduce the image.  The image is reduced to a size in the range of 32x32 and 8x8. </li><li>  <b>Remove color.</b>  A small image is converted to grayscale, so the hash is reduced three times. </li><li>  <b>Calculate the average color value for all pixels.</b> </li><li>  <b>Build a chain of bits.</b>  For each pixel, a color replacement is made by 1 or 0, depending on whether it is larger or less than the average. </li><li>  <b>Build a hash.</b>  Translation of 1024 bits into one value.  The order does not matter, but usually the bits are written from left to right, top to bottom. </li></ul><br><br>  The resulting hash is resistant to scaling, compressing or stretching the image, changing the brightness, contrast, color manipulation.  But the main advantage of the algorithm is its speed.  To compare hashes of this type, the function of the normalized Hamming distance is used. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5af/ee0/c0b/5afee0c0b7f942ad0107c3fa20b99360.png" alt="image"><br>  Source image <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0c0/62e/5a2/0c062e5a22ba0a9fb55d1c70a689487b.png" alt="image"><br>  The resulting "imprint" <br><br><h5>  Discrete Cosine Transform Based Hash (aka pHash) </h5><br>  The discrete cosine transform (DCT, DCT) [7] is one of the orthogonal transforms, which is closely related to the discrete Fourier transform (DFT) and is a homomorphism of its vector space.  DCT, like any Fourier-oriented transform, expresses a function or signal (a sequence of a finite number of data points) as a sum of sinusoids with different frequencies and amplitudes.  DCT uses only cosine functions, in contrast to the DFT, which uses both cosine and sine functions.  There are 8 types of DCT [7].  The most common is the second type.  We will use it to build a hash function. <br>  Let's see what the second type of DCT is: <br><br>  Let x [m], where m = 0, ..., N - 1 is the sequence of the signal of length N. We define the second type of DCT as <br><br><img src="https://habrastorage.org/getpro/habr/post_images/409/761/8d3/4097618d3a5b30a357e2be38c7439281.png" alt="image"><br><br>  This expression can be rewritten as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/09b/011/113/09b0111130c267547ab2a8fcdbf4b24b.png" alt="image"><br><br>  where c [n, m] is an element of the DCT matrix at the intersection of row n and column m. <br>  DCT matrix is ‚Äã‚Äãdefined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4aa/8dd/4b6/4aa8dd4b64336ec9d406ef85bd8211bf.png" alt="image"><br><br>  This matrix is ‚Äã‚Äãvery convenient for calculating DCT.  DCT can be calculated in advance for any necessary length.  Thus, DCT can be represented as: <br>  DCT = M √ó I √ó M ' <br>  Where M is the DCT matrix, I is the image of a square size, M 'is the inverse matrix. <br><br>  Low-frequency DCT coefficients are most stable to image manipulation.  This is because most of the signal information is usually concentrated in several low frequency coefficients.  As a matrix I, an image is usually taken, compressed to a size of 32x32 and simplified using various filters, for example, bleaching.  The result is a DCT matrix (I), in the upper left corner of which the low-frequency coefficients are located.  To build a hash, the left upper block of frequencies 8x8 is taken.  Then a 8 byte hash is built from this block by finding the average and building a chain of bits (as in Simple Based Hash). <br>  Here are the steps to build a hash using this algorithm: <br><ul><li>  <b>Remove color.</b>  To suppress unnecessary treble; </li><li>  <b>Apply a median filter [8]</b> to reduce noise.  At the same time, the image is divided into so-called ‚Äúwindows‚Äù, then each window is replaced with a median [9] for adjacent windows; </li><li>  <b>Reduce image to size 32x32;</b> </li><li>  <b>Apply DCT to the image;</b> </li><li>  <b>Build a hash.</b> </li></ul><br>  The main advantages of such a hash: resistance to small rotations, blurring and image compression, as well as the speed of comparison of hashes, due to their small size.  To compare hashes of this type, the Hamming distance function is used. <br><br><h5>  Radial Variance Based Hash </h5><br>  The idea of ‚Äã‚Äãthe Radial Variance Based Hash algorithm is to build a ray dispersion vector (LVD) based on the Radon transform [5].  Then DCT is applied to the LVD and a hash is calculated.  The Radon transform is an integral transform of a multi-variable function along a straight line.  It is resistant to image processing through various manipulations (for example, compression) and geometric transformations (for example, rotations).  In the two-dimensional case, the Radon transform for the function f (x, y) looks like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75f/9fe/121/75f9fe121afa59ad6bb6d8e79752264f.png" alt="image"><br><br>  The Radon transform has a simple geometric meaning: it is an integral of the function along a straight line perpendicular to the vector n = (cos a, sin a) and passing at a distance s (measured along the vector n, with the corresponding sign) from the origin. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ef9/cb1/c9d/ef9cb1c9da0441f4edbc6536837f80e7.png" alt="image"><br><br>  To expand the Radon transform for discrete images, the linear integral along the straight line d = x ‚àô cos Œ± + y ‚àô sin Œ± can be approximated by summing the values ‚Äã‚Äãof all pixels lying in a line one pixel wide: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dfb/23b/a55/dfb23ba55426ef5b30ea657cf46e4524.png" alt="image"><br><br>  It was later found that it is better to use the variance instead of the sum of the pixel values ‚Äã‚Äãalong the projection line [6].  Dispersion handles brightness discontinuities along the projection line much better.  Such brightness discontinuities appear because of edges that are orthogonal to the projection line. <br>  Now we define the ray vector of dispersion.  Let Œì (Œ±) be the set of pixels on the projection line corresponding to a given angle.  Let (x ‚Ä≤, y ‚Ä≤) be the coordinates of the central pixel in the image.  x, y belong to Œì (Œ±) if and only if <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e4/552/4b4/3e45524b407dafa215f173f2369c9177.png" alt="image"><br><br>  Now we define the radial vector variance vector: <br>  Let I (x, y) denote the pixel brightness (x, y), #Œì (Œ±) is the power of the set, then the ray vector of dispersion R [Œ±], where Œ± = 0.1, ..., 179 is defined as <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d10/bb6/b90/d10bb6b9057193253faa8345228ee3b1.png" alt="image"><br><br>  It is enough to construct a vector with 180 angle values, since the Radon transform is symmetric.  The resulting vector can be used to build a hash, but this algorithm proposes some other improvement - to apply DCT to the received vector.  The result is a vector that inherits all the important properties of DCT.  The first 40 coefficients of the obtained vector, which correspond to low frequencies, are taken as a hash.  Thus, the size of the resulting hash is 40 bytes. <br>  So, we list the steps for constructing a hash using this algorithm: <br><ul><li>  <b>Remove color</b> to suppress unnecessary treble; </li><li>  <b>Blur an image</b> using a Gaussian blur [10].  The image is converted using the Gauss function to suppress some noise; </li><li>  <b>Apply gamma correction</b> to eliminate image fading. </li><li>  <b>Build the radial vector of the dispersion;</b> </li><li>  <b>Apply DCT to the dispersion vector;</b> </li><li>  <b>Build a hash.</b> </li></ul><br>  For comparison, hashes of this type are used to search for the peak of the mutual correlation function. <br><br><h5>  Marr-Hildreth Operator Based Hash </h5><br>  The operator Marra-Hildreta [16] allows you to define the edges on the image.  Generally speaking, the border in an image can be defined as an edge or contour that separates adjacent parts of the image, which have relatively different characteristics in accordance with certain features.  These features can be color or texture, but the most commonly used is a gray gradation of the image color (brightness).  The result of the definition of boundaries is a map of boundaries.  The border map describes the classification of borders for each image pixel.  If the boundaries are defined as an abrupt change in brightness, then derivatives can be used to find them or a gradient. <br>  Let function <img src="https://habrastorage.org/getpro/habr/post_images/aa3/e99/234/aa3e99234266cbd17069bdcd1fd61e7a.png" alt="image">  denotes the brightness level for the line (one-dimensional array of pixels).  The first approach to determining the boundaries is to find the local extrema of the function, that is, the first derivatives.  The second approach (the Laplace method) is to find the second derivatives <img src="https://habrastorage.org/getpro/habr/post_images/aa3/e99/234/aa3e99234266cbd17069bdcd1fd61e7a.png" alt="image">  [one]. <br>  Both approaches can be adapted for the case of two-dimensional discrete images, but with some problems.  To find derivatives in a discrete case, an approximation is required.  In addition, noise in the image can significantly impair the process of searching for boundaries.  Therefore, before determining the boundaries to the image, you must apply a filter that suppresses noise.  To build a hash, you can choose an algorithm that uses the Laplace operator (2 approach) and the Gauss filter. <br>  We define a continuous Laplacian (Laplace operator): <br>  Let be <img src="https://habrastorage.org/getpro/habr/post_images/4b8/d7e/970/4b8d7e97084d4f41cb7d700ab4670dc8.png" alt="image">  determines the brightness of the image.  Then continuous Laplacian is defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d1/21b/646/6d121b64657021710d14df9c099bbbfd.png" alt="image"><br><br>  Zeroing <img src="https://habrastorage.org/getpro/habr/post_images/20a/8c1/ee1/20a8c1ee1184a495def9f72ed78d7904.png" alt="image">  and there are points corresponding to the boundary of the function <img src="https://habrastorage.org/getpro/habr/post_images/4b8/d7e/970/4b8d7e97084d4f41cb7d700ab4670dc8.png" alt="image">  , since these are the points at which the second derivative vanishes.  Various filters (discrete Laplace operators) can be obtained from continuous Laplacian.  Such a filter <img src="https://habrastorage.org/getpro/habr/post_images/3bd/32a/fa5/3bd32afa5b520fcc4f67cd4cbf4cf55a.png" alt="image">  , can be applied to a discrete image by using the convolution of functions.  Laplace operator for image <img src="https://habrastorage.org/getpro/habr/post_images/564/bcb/120/564bcb120c0eda4e5fe93f6c6fa0c1e1.png" alt="image">  can be rewritten as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c5b/7b1/16f/c5b7b116f038b83f5e8edd06734bb467.png" alt="image"><br><br>  where * denotes the convolution of functions.  To build a boundary map, you need to find the treatment of zero discrete operator <img src="https://habrastorage.org/getpro/habr/post_images/d40/b59/d3a/d40b59d3a886229c847e08b763b235c2.png" alt="image">  . <br>  Now consider the Marra-Hildreth operator.  It is also called the Laplacian from the Gaussian filter (LoG) - this is a special type of discrete Laplace operator.  LoG is constructed by applying the Laplace operator to a Gauss filter (function).  The peculiarity of this operator is that it can select borders at a certain scale.  Scale variables can be varied in order to better define the boundaries. <br>  The Gauss filter is defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/33e/da8/35f/33eda835fc3cdec1e629484e3f37b396.png" alt="image"><br><br>  Convolution with Laplace operation can be swapped, because the derivative and convolution are linear operators: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b4a/879/6d8/b4a8796d8f75d85ec6be6fc9703699da.png" alt="image"><br><br>  This property allows you to pre-calculate the operator <img src="https://habrastorage.org/getpro/habr/post_images/0fe/8f9/178/0fe8f9178a556f37eb9700d22acf64c7.png" alt="image">  , because it does not depend on the image ( <img src="https://habrastorage.org/getpro/habr/post_images/4b8/d7e/970/4b8d7e97084d4f41cb7d700ab4670dc8.png" alt="image">  ). <br>  (operator Marra-Hildreta, Laplacian from the Gauss filter, LoG).  LoG hc (x, y) is defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a8c/8d3/8d8/a8c8d38d89b0839394d03ecfa6cf0e9d.png" alt="image"><br><br>  To use LoG in discrete form, we will make a discretization of this equation, substituting the desired scale variable.  By default, its value is taken as 1.0.  The filter can then be applied to the image using discrete convolution. <br>  Define the discrete convolution: <br>  Let x, y, z be the pixel width, length and depth of the image I. <br>  The result of the R convolution of the image I with the mask M is defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae2/b68/cab/ae2b68cabd5cfe92ca97902e42ddb72a.png" alt="image"><br><br>  Now we list the steps of the algorithm that uses the Marr-Hildret operator to build the hash: <br><ul><li>  <b>Remove color</b> to suppress unnecessary treble; </li><li>  <b>Convert image to size 128x128;</b> </li><li>  <b>Blur image (blurring).</b>  The image is converted using the Gauss function to suppress some noise [10]; </li><li>  <b>Build the operator Marra-Hildreta;</b> </li><li>  <b>Apply discrete convolution to LoG and image.</b>  Get <br>  an image with clearly visible brightness jumps; </li><li>  <b>Convert an image to a histogram.</b>  The image is divided into small blocks (5x5), in which the values ‚Äã‚Äãof brightness are summed. </li><li>  <b>Build a hash from the histogram.</b>  The histogram is divided into 3x3 blocks.  For these blocks, the average brightness value is assumed and the bit chaining method is used.  It turns out a binary hash of 64 bytes. </li></ul><br>  The size of the resulting hash is not small, however, the comparison of two hashes takes a rather short time compared with the Radial algorithm, since the function of the normalized Hamming distance is used.  Also, this algorithm is sensitive to image rotation, but is resistant to scaling, dimming, and compression. <br><br><h4>  Perceptual hash value comparison functions </h4><br><h5>  Hamming distance </h5><br>  Hamming distance determines the number of different positions between two binary sequences. <br>  Definition: <br>  Let A be an alphabet of finite length. <img src="https://habrastorage.org/getpro/habr/post_images/2fd/c57/c44/2fdc57c449396ddb255fe8e014285f11.png" alt="image">  - binary sequences (vectors).  Hamming distance Œî between x and y is defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/91c/cb7/2ab/91ccb72ab36d62b6a4f013ca092c717a.png" alt="image"><br><br>  This method of comparing hash values ‚Äã‚Äãis used in the DCT Based Hash method.  The hash is 8 bytes in size, so the Hamming distance lies in the [0, 64] segment.  The smaller the Œî value, the more similar the images. <br>  To facilitate comparison, the Hamming distance can be normalized using the length of the vectors: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/47f/358/5a7/47f3585a7d024c5fcd168c61642581c1.png" alt="image"><br><br>  The normalized Hamming distance is used in the Simple Hash and Marr-Hildreth Operator Based Hash algorithms.  Hamming distance lies in the interval [0,1] and the closer Œî to 0, the more similar the images. <br><br><h5>  Peak of the mutual correlation function </h5><br>  The correlation between the two signals is defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ace/2b9/556/ace2b95560b6ed21d6cb9631eabea822.png" alt="image"><br><br>  where x (t) and y (t) are two continuous functions of real numbers.  The function rxy (t) describes the displacement of these two signals relative to time T. The variable T determines how far the signal is shifted to the left.  If the signals x (t) and y (t) are different, the function rxy T is said to be mutually correlated. <br>  Define the Normalized Mutual Correlation Function: <br>  Let xi and yi, where i = 0, ... N - 1 are two sequences of real numbers, and N is the length of both sequences.  IAF with delay d will be defined as: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4a8/5f7/1dc/4a85f71dc2bb7aa0bca5853f95968294.png" alt="image"><br><br>  where mx and my denote the average value for the corresponding sequence. <br>  The peak of the mutual correlation function (PCC) is the maximum value of the function rd, which can be achieved on the interval d = 0, N. <br>  PCC is used to compare hash values ‚Äã‚Äãin the Radial Variance Based Hash algorithm.  PCC ‚àà [0,1], the greater its value, the more similar the images. <br><br><h4>  A few words about the practice </h4><br>  We considered 4 different approaches in the implementation of hash algorithms.  The perceptual hashes are wide in scope, from searching for similar images to detecting spam in pictures. <br><br>  In our project, we use a perceptual hash to identify duplicate images.  At the same time, it is often possible to successfully compare among themselves images containing watermarks (obtained from different sources) or images with cropped edges. <br>  Radial Variance Based Hash can be considered the best algorithm for finding duplicates, but it is extremely difficult to use it on large amounts of data, due to the very time-consuming comparison of hashes. <br><br>  For ourselves, we chose DCT based Hash.  We use 64-bit hash, this is quite enough to find duplicates, but such a small hash size inevitably leads to collisions.  With collisions, we struggle to construct a histogram (spectrum) for the image. <br>  Each component of the spectrum means the relative number of colors of one or another range in the image, in other words, it shows the distribution of colors in the image.  It looks like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/918/87a/1ff/91887a1ffe36f3ddc9db396f1931ae34.png" alt="image"><br><br>  Thus, we first look for images comparing the hash, and then compare the histograms, if the histograms are significantly different, then such an image is not considered to be similar.  The histograms themselves can be compared by counting the cross-correlation as well as by comparing Radial Variance Based Hash using the Pearson cross-correlation: <br><img src="https://habrastorage.org/getpro/habr/post_images/4a8/5f7/1dc/4a85f71dc2bb7aa0bca5853f95968294.png" alt="image"><br><br>  If this topic is interesting to the community, in the next article I will talk specifically about our implementation of DCT hash, as well as how to find the Hamming distance. <br><br><div class="spoiler">  <b class="spoiler_title">Bibliography</b> <div class="spoiler_text">  [1] Egmont-Petersen, M., de Ridder, D., Handels, H. ‚ÄúImage processing with <br>  neural networks - a review. ‚Äù  Pattern Recognition 35 (10), pp.  2279‚Äì2301 (2002) <br>  [2] Christoph Zauner.  Implementation and Benchmarking of Perceptual Image <br>  Hash Functions (2010) <br>  [3] Locality-sensitive hashing. <br>  <a href="http://en.wikipedia.org/wiki/Locality-sensitive_hashing">en.wikipedia.org/wiki/Locality-sensitive_hashing</a> <br>  [4] Simple and DCT perceptual hash-algorithms. <br>  <a href="http://www.hackerfactor.com/blog/index.php%3F/archives/432-Looks-Like-">www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-</a> <br>  It.html <br>  [5] Standaert, FX, Lefebvre, F., Rouvroy, G., Macq, BM, Quisquater, JJ, <br>  Legat, JD: Practical evaluation of a radial soft hash algorithm.  In <br>  Proceedings of the International Symposium on Information Technology: <br>  Coding and Computing (ITCC), vol.  2, pp.  89-94.  IEEE, Apr.  2005 <br>  [6] D. Marrand, E. Hildret.  Theory of edge detection, pp.  187-215 (1979) <br>  [7] <a href="http://en.wikipedia.org/wiki/Discrete_cosine_transform">en.wikipedia.org/wiki/Discrete_cosine_transform</a> <br>  [8] <a href="http://en.wikipedia.org/wiki/Median_filter">en.wikipedia.org/wiki/Median_filter</a> <br>  [9] <a href="http://en.wikipedia.org/wiki/Median">en.wikipedia.org/wiki/Median</a> <br>  [10] <a href="http://en.wikipedia.org/wiki/Gaussian_blur">en.wikipedia.org/wiki/Gaussian_blur</a> <br>  [11] Zeng Jie.  A Novel Block-DCT and PCA Based Image Perceptual Hashing <br>  Algorithm.  IJCSI International Journal of Computer Science Issues, Vol.  ten, <br>  Issue 1, No 3, January 2013 <br>  [12] <a href="http://de.wikipedia.org/wiki/Marr-Hildreth-Operator">de.wikipedia.org/wiki/Marr-Hildreth-Operator</a> <br><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/237307/">https://habr.com/ru/post/237307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../237295/index.html">Virtualization‚Å∞</a></li>
<li><a href="../237297/index.html">Emoji lisp</a></li>
<li><a href="../237301/index.html">Brain Target- a program for objectifying the evaluation of the results of neurosurgical treatment of brain tumors</a></li>
<li><a href="../237303/index.html">Cardiwear: Domestic Smart Electrocardiograph T-shirt</a></li>
<li><a href="../237305/index.html">Show Sound # 16 - Podcast about audio equipment, formats and technologies</a></li>
<li><a href="../237309/index.html">Paradise tax corners for data centers in the United States</a></li>
<li><a href="../237313/index.html">7 little tricks when working in Windows</a></li>
<li><a href="../237317/index.html">Flask Mega-Tutorial, Part 16: Debugging, Testing and Profiling</a></li>
<li><a href="../237323/index.html">Overload and specialization. Subtle moment</a></li>
<li><a href="../237331/index.html">3D displays for smartphones</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>