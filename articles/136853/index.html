<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Restore defocused and blurred images</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recovering distorted images is one of the most interesting and important problems in image processing tasks - both from theoretical and practical poin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Restore defocused and blurred images</h1><div class="post__text post__text-html js-mediator-article">  Recovering distorted images is one of the most interesting and important problems in image processing tasks - both from theoretical and practical points of view.  Special cases are blurring due to improper focus and blurring - these defects, with which each of you is well acquainted, are very difficult to correct - they were chosen as the topic of the article.  With the rest of the distortions (noise, irregular exposure, distortion), mankind has learned how to effectively deal, there are appropriate tools in every self-respecting photo editor. <br><br>  Why is there practically nothing to eliminate blurring and defocusing (unsharp mask doesn‚Äôt count) - can this be impossible in principle?  In fact, it is possible - the corresponding mathematical apparatus began to be developed about 70 years ago, but, like for many other image processing algorithms, all this has found wide application only in recent times.  Here, as a demonstration of the wow effect, a couple of pictures: <br><br><img src="https://habrastorage.org/storage2/73c/4ef/470/73c4ef470d38e37db24cf61230640dc1.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I did not use the tortured <a href="http://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B5%25D0%25BD%25D0%25B0_%2528%25D0%25B8%25D0%25B7%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5%2529">Lena</a> , but found my photo of Venice.  The right image is honestly obtained from the left, and without the use of tricks such as 48-bit format (in this case there will be a 100% recovery of the original image) - on the left is the most common PNG, blurred artificially.  The result is impressive ... but in practice, not everything is so simple.  Under the cat a detailed review of the theory and practical results. <br>  Be careful, lots of pictures in PNG format! <br><a name="habracut"></a><br><h1>  Introduction </h1><br>  Let's start from afar.  Many people think that blurring is an irreversible operation and information is irretrievably lost, because  each pixel turns into a spot, everything mixes, and with a large blur radius, we get a uniform color throughout the image.  This is not entirely true - all information is simply redistributed according to some law and can be unequivocally restored with some reservations.  The only exception is the edges of the image width to the blur radius - there is no full restoration. <br><br>  Let us demonstrate this ‚Äúon the fingers‚Äù using a small example for a one-dimensional case ‚Äî imagine that we have a row of pixels with values: <br>  x <sub>1</sub> |  x <sub>2</sub> |  x <sub>3</sub> |  x <sub>4</sub> ... - Original Image <br><br>  After distortion, the value of each pixel is summed with the value of the left one, i.e.  x ' <sub>i</sub> = x <sub>i</sub> + x <sub>i-1</sub> .  In theory, we must also divide by 2, but omit it for simplicity.  As a result, we have blurred images with pixel values: <br>  x <sub>1</sub> + x <sub>0</sub> |  x <sub>2</sub> + x <sub>1</sub> |  x <sub>3</sub> + x <sub>2</sub> |  x <sub>4</sub> + x <sub>3</sub> ... - Blurred Image <br><br>  Now we will try to restore, subtract sequentially the value chain by the scheme - from the second pixel the first, from the third result of the second, from the fourth result of the third and so on, we get: <br>  x <sub>1</sub> + x <sub>0</sub> |  x <sub>2</sub> - x <sub>0</sub> |  x <sub>3</sub> + x <sub>0</sub> |  x <sub>4</sub> - x <sub>0</sub> ... - Refurbished image <br><br>  As a result, instead of a blurred image, an original image was obtained, to the pixels of which an unknown constant x <sub>0</sub> with an alternating sign was added.  This is already much better - this constant can be chosen visually, it can be assumed that it is approximately equal to the value of x <sub>1</sub> , you can automatically choose with such a criterion that the values ‚Äã‚Äãof the neighboring pixels ‚Äújump‚Äù as little as possible, etc.  But everything changes as soon as we add noise (which is always present in real images).  With the scheme described at each step, the noise contribution to the common component will accumulate, which may ultimately give an absolutely unacceptable result, but, as we have seen, the recovery is quite realistic even in such a primitive way. <br><br><h1>  Distortion process model </h1><br>  We now turn to a more formal and scientific description of these processes of distortion and restoration.  We will consider only halftone black-and-white images under the assumption that to process a full-color image, it is enough to repeat all the necessary steps for each of the RGB color channels.  We introduce the following notation: <br>  <i>f (x, y)</i> - the original undistorted image <br>  <i>h (x, y)</i> is a distorting function <br>  <i>n (x, y)</i> - additive noise <br>  <i>g (x, y)</i> is the result of the distortion, i.e.  what we see as a result (blurred or defocused image) <br><br>  We formulate a distortion process model as follows: <br>  <i>g (x, y) = h (x, y) * f (x, y) + n (x, y)</i> (1) <br><br>  The task of recovering a distorted image is to find the best approximation <i>f '(x, y) of the</i> original image.  Consider each component in more detail.  With <i>f (x, y)</i> and <i>g (x, y),</i> everything is quite clear.  But about the function <i>h (x, y</i> ) you need to say a few words - what does it look like?  In the process of distortion, each pixel of the original image turns into a spot for the case of defocusing and a segment for the case of a simple blurring.  Or it can be said on the contrary that each pixel of a distorted image is ‚Äúassembled‚Äù from the pixels of some neighborhood of the original image.  All this is superimposed on each other and as a result we get a distorted image.  That, according to what law one pixel is smeared or assembled and is called the distortion function.  Other synonyms are PSF (Point spread function, i.e. point distribution function), the core of the distorting operator, kernel, and others.  The dimension of this function is usually less than the dimension of the image itself - for example, in the initial consideration of the example ‚Äúon fingers‚Äù, the dimension of the function was 2, since  each pixel consisted of two. <br><br><h1>  Distorting functions </h1><br>  Let's see how typical distorting functions look like.  Hereinafter we will use the tool that has already become standard for such purposes - Matlab, it contains everything necessary for a wide variety of experiments with image processing (and not only) and allows you to focus on the algorithms themselves, shifting all routine work to the library of functions.  However, for this you have to pay performance.  So back to the PSF, here are some examples of their type: <br><br><img src="https://habrastorage.org/storage2/9fc/2d7/eab/9fc2d7eab89010a65ef5f2979a6421fc.png"><br>  <b>PSF in the case of a Gaussian blur with the fspecial function ('gaussian', 30, 8);</b> <br><br><img src="https://habrastorage.org/storage2/5fe/116/30f/5fe11630f207472c4d2801e1d9c82483.png"><br>  <b>PSF in the case of smearing with fspecial ('motion', 40, 45);</b> <br><br>  The operation of applying a distorting function to another function (to the image, in this case) is called convolution, i.e.  A certain area of ‚Äã‚Äãthe original image is collapsed into one pixel of the distorted image.  It is denoted by the operator "*", not to be confused with ordinary multiplication!  Mathematically, for an image <i>f</i> with dimensions M x N and a distorting function <i>h</i> with dimensions mxn, this is written as: <br><br><img src="https://habrastorage.org/storage2/8a5/048/1d0/8a50481d0b3e240ad0c017f5bb65c518.png">  (2) <br><br>  Where <i>a = (m - 1) / 2, b = (n - 1) / 2</i> .  The operation inverse to convolution is called deconvolution, and the solution of such a problem is very nontrivial. <br><br><h1>  Noise model </h1><br>  It remains to consider the last term responsible for noise, <i>n (x, y)</i> in formula (1).  The causes of noise in digital sensors can be very different, but the main ones are thermal oscillations and dark currents.  The amount of noise is also influenced by a number of factors, such as ISO value, matrix type, pixel size, temperature, electromagnetic pickups, etc. In most cases, the noise is Gaussian (which is defined by two parameters ‚Äî average and dispersion), and is also additive, does not correlate with the image and does not depend on pixel coordinates.  The last three assumptions are very important for further work. <br><br><h1>  Convolution theorem </h1><br>  We now return to the original formulation of the restoration problem ‚Äî we need to somehow invert the convolution, while not forgetting the noise.  It is clear from formula (2) that getting <i>f (x, y)</i> from <i>g (x, y) is</i> not so easy - if you solve what is called head-on, you get a huge system of equations.  But the <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5">Fourier transform</a> comes to help us; we will not dwell on it in detail; quite a lot has already been said on this topic.  So, there is a convolution theorem, which states that the convolution operation in the spatial domain is equivalent to the usual multiplication in the frequency domain (and the multiplication is element-wise, not matrix).  Accordingly, the inverse convolution operation is equivalent to division in the frequency domain, i.e. this can be written as: <br><img src="https://habrastorage.org/storage2/51a/daf/5f6/51adaf5f6bd4a51c393e64446e01c45e.png">  (3) <br><br>  Where <i>H (u, v), F (u, v)</i> are the Fourier transforms of the corresponding functions.  So the process of distortion from the formula (1) can be rewritten in the frequency domain as: <br><img src="https://habrastorage.org/storage2/a67/78d/f30/a6778df306742b54222c62b97a73ba83.png">  (four) <br><br><h1>  Inverse filtering </h1><br>  Here it is suggested to divide this equality by <i>H (u, v)</i> and get the following estimate <i>F <sup>^</sup> (u, v) of the</i> original image: <br><img src="https://habrastorage.org/storage2/148/4ec/c4b/1484ecc4b429d399f1ba4471e1aafa38.png">  (five) <br>  This is called inverse filtering, but in practice it almost never works.  Why so?  To answer this question, we look at the last term in formula (5) - if the function <i>H (u, v)</i> takes a value close to zero or zero, then the contribution of this term will be dominant.  This is almost always found in real-world examples ‚Äî to explain this, let us recall how the spectrum looks after the Fourier transform. <br><br>  Take the original image <br><img src="https://habrastorage.org/storage2/d9e/e9b/89e/d9ee9b89eec2c4b25fadacd07e3c0438.png"><br><br>  transform it into a halftone and, using Matlab, we obtain the spectrum: <br><br><pre><code class="php hljs">% Load image I = imread(<span class="hljs-string"><span class="hljs-string">'image_src.png'</span></span>); figure(<span class="hljs-number"><span class="hljs-number">1</span></span>); imshow(I); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); % Convert image into grayscale I = rgb2gray(I); % Compute Fourier Transform <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> center it fftRes = fftshift(fft2(I)); % Show result figure(<span class="hljs-number"><span class="hljs-number">2</span></span>); imshow(mat2gray(log(<span class="hljs-number"><span class="hljs-number">1</span></span>+abs(fftRes)))); title(<span class="hljs-string"><span class="hljs-string">'FFT -   ( )'</span></span>); figure(<span class="hljs-number"><span class="hljs-number">3</span></span>); imshow(mat2gray(angle(fftRes))); title(<span class="hljs-string"><span class="hljs-string">'FFT -  '</span></span>);</code> </pre> <br><img src="https://habrastorage.org/storage2/672/2bb/a41/6722bba41ca16faaa8fa5f604dc18a4a.png"><br><br>  As a result, we obtain two components: amplitude and phase spectra.  By the way, many people forget about the phase.  Note that the amplitude spectrum is shown in a logarithmic scale, since  its values ‚Äã‚Äãvary very much - by several orders of magnitude; in the center, the maximum values ‚Äã‚Äã(of the order of millions) and rapidly decrease to almost zero as the distance from the center increases.  It is because of this that the inverse filtering will work only at zero or almost zero noise values.  Let's demonstrate this in practice using the following script: <br><pre> <code class="php hljs">% Load image I = im2double(imread(<span class="hljs-string"><span class="hljs-string">'image_src.png'</span></span>)); figure(<span class="hljs-number"><span class="hljs-number">1</span></span>); imshow(I); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); % Blur image Blurred = imfilter(I, PSF,<span class="hljs-string"><span class="hljs-string">'circular'</span></span>,<span class="hljs-string"><span class="hljs-string">'conv'</span></span> ); figure(<span class="hljs-number"><span class="hljs-number">2</span></span>); imshow(Blurred); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); % Add noise noise_mean = <span class="hljs-number"><span class="hljs-number">0</span></span>; noise_var = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; Blurred = imnoise(Blurred, <span class="hljs-string"><span class="hljs-string">'gaussian'</span></span>, noise_mean, noise_var); % Deconvolution figure(<span class="hljs-number"><span class="hljs-number">3</span></span>); imshow(deconvwnr(Blurred, PSF, <span class="hljs-number"><span class="hljs-number">0</span></span>)); title(<span class="hljs-string"><span class="hljs-string">''</span></span>);</code> </pre><br><img src="https://habrastorage.org/storage2/ddc/745/2c1/ddc7452c1d210ed41cd1737fd5704aa7.png"><br><pre>  noise_var = 0.0000001 noise_var = 0.000005 </pre><br>  It is clearly seen that the addition of even very small noise leads to significant interference, which greatly limits the practical application of the method. <br><br><h1>  Existing approaches for deconvolution </h1><br>  But there are approaches that take into account the presence of noise in the image - one of the most famous and the very first is the Wiener filter.  He considers the image and noise as random processes and finds such an estimate <i>f ‚Ä≤</i> for the undistorted image <i>f</i> , so that the standard deviation of these values ‚Äã‚Äãis minimal.  The minimum of this deviation is achieved on the function in the frequency domain: <br><img src="https://habrastorage.org/storage2/168/e0e/8d2/168e0e8d2e2755fd412bf5af8e51051a.png">  (6) <br>  This result was obtained by Wiener in 1942.  We will not give a detailed conclusion here, those who are interested can see it <a href="http://www.sernam.ru/tau_31.php">here</a> .  The function S here denotes the energy spectra of the noise and the original image, respectively - since these quantities are rarely known, the fraction S <sub>n</sub> / S <sub>f is</sub> replaced by some constant K, which can be approximately characterized as a signal-to-noise ratio. <br><br>  The next method is ‚Äúsmoothing least squares filtering with a connection‚Äù, other names: ‚ÄúTikhonov filtering‚Äù, ‚ÄúTikhonov regularization‚Äù.  His idea is to formulate the problem in a matrix form with further solution of the corresponding optimization problem.  This solution is written as: <br><img src="https://habrastorage.org/storage2/bbb/acf/473/bbbacf473cac4d25f7f1370a6180d7da.png">  (7) <br>  Where <i>y</i> is the regularization parameter, and <i>P (u, v)</i> is the Fourier transform of the Laplace operator (3 * 3 matrix). <br><br>  Another interesting approach was proposed independently by Richard [Richardson, 1972] and Lucy [Lucy, 1974].  The method is called the "Lucy-Richardson method."  Its distinguishing feature is that it is non-linear, unlike the first three - which can potentially give better results.  The second peculiarity - the method is iterative; accordingly, difficulties arise with the criterion for stopping iterations.  The basic idea is to use the maximum likelihood method for which it is assumed that the image obeys the Poisson distribution.  The formulas for the calculation are quite simple, without using the Fourier transform - everything is done in the spatial domain: <br><img src="https://habrastorage.org/storage2/54a/040/038/54a040038cf98a696f668f46bd49eeb9.png">  (eight) <br>  Here the symbol "*", as before, denotes the operation of convolution.  This method is widely used in programs for processing astronomical photographs - in them the use of deconvolution (instead of an unsharp mask, as in photo editors) is a de facto standard.  As an example, Astra Image, here are <a href="http://www.phasespace.com.au/decon_ex.htm">examples of deconvolution</a> .  The computational complexity of the method is very large - processing of a medium photo, depending on the number of iterations, can be known for many hours and even days. <br><br>  The last considered method, or rather, a whole family of methods that are now being actively developed and developed, is blind deconvolution.  In all previous methods it was assumed that the distorting function of the PSF is precisely known, in reality it is not so, usually the PSF is known only approximately by the nature of the visible distortion.  Blind deconvolution is an attempt to take this into account.  The principle is quite simple, if you don‚Äôt go into details - the first approximation of PSF is selected, then deconvolution is done using one of the methods, after which some criterion determines the degree of quality, based on it the PSF function is refined and the iteration is repeated until the desired result is achieved. <br><br><h1>  Practice </h1><br>  Now, with the theory of everything - let's move on to practice, let's start by comparing the listed methods on the image with artificial blurring and noise. <br><br><img src="https://habrastorage.org/storage2/152/5ee/fe4/1525eefe4cbeb0480e33bfcf1312b8f1.png"><br><pre> <code class="php hljs">% Load image I = im2double(imread(<span class="hljs-string"><span class="hljs-string">'image_src.png'</span></span>)); figure(<span class="hljs-number"><span class="hljs-number">1</span></span>); imshow(I); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); % Blur image PSF = fspecial(<span class="hljs-string"><span class="hljs-string">'disk'</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>); Blurred = imfilter(I, PSF,<span class="hljs-string"><span class="hljs-string">'circular'</span></span>,<span class="hljs-string"><span class="hljs-string">'conv'</span></span> ); % Add noise noise_mean = <span class="hljs-number"><span class="hljs-number">0</span></span>; noise_var = <span class="hljs-number"><span class="hljs-number">0.00001</span></span>; Blurred = imnoise(Blurred, <span class="hljs-string"><span class="hljs-string">'gaussian'</span></span>, noise_mean, noise_var); figure(<span class="hljs-number"><span class="hljs-number">2</span></span>); imshow(Blurred); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); estimated_nsr = noise_var / <span class="hljs-keyword"><span class="hljs-keyword">var</span></span>(Blurred(:)); % Restore image figure(<span class="hljs-number"><span class="hljs-number">3</span></span>), imshow(deconvwnr(Blurred, PSF, estimated_nsr)), title(<span class="hljs-string"><span class="hljs-string">'Wiener'</span></span>); figure(<span class="hljs-number"><span class="hljs-number">4</span></span>); imshow(deconvreg(Blurred, PSF)); title(<span class="hljs-string"><span class="hljs-string">'Regul'</span></span>); figure(<span class="hljs-number"><span class="hljs-number">5</span></span>); imshow(deconvblind(Blurred, PSF, <span class="hljs-number"><span class="hljs-number">100</span></span>)); title(<span class="hljs-string"><span class="hljs-string">'Blind'</span></span>); figure(<span class="hljs-number"><span class="hljs-number">6</span></span>); imshow(deconvlucy(Blurred, PSF, <span class="hljs-number"><span class="hljs-number">100</span></span>)); title(<span class="hljs-string"><span class="hljs-string">'Lucy'</span></span>);</code> </pre><br>  Results: <br><br><img src="https://habrastorage.org/storage2/4c7/f25/fa1/4c7f25fa14f588bbe1fcdc00d49d1eed.png"><br>  <b>Wiener Filter</b> <br><br><img src="https://habrastorage.org/storage2/cca/126/e0b/cca126e0b5371d9e1537d8b934ad7c36.png"><br>  <b>Regularization Tikhonov</b> <br><br><img src="https://habrastorage.org/storage2/e24/c7f/fde/e24c7ffdea7632da3118c94b1b557436.png"><br>  <b>Lucy-richardson filter</b> <br><br><img src="https://habrastorage.org/storage2/3e7/806/80f/3e780680fae858ff732ab86f03239cc0.png"><br>  <b>Blind deconvolution</b> <br><br><h1>  Conclusion </h1><br>  And at the end of the first part we will touch upon examples of real images.  Before that, all the distortions were artificial, which is certainly good for running in and studying, but it is very interesting to see how all this will work with real photos.  Here is one example of such an image taken with a Canon 500D DSLR camera with manual focus focus: <br><br><img src="https://habrastorage.org/storage2/26c/47f/599/26c47f5998a1dfbd0aa880a30a1c3a87.png"><br><br>  Next, run a simple script: <br><br><pre> <code class="php hljs">% Load image I = im2double(imread(<span class="hljs-string"><span class="hljs-string">'IMG_REAL.PNG'</span></span>)); figure(<span class="hljs-number"><span class="hljs-number">1</span></span>); imshow(I); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); %PSF PSF = fspecial(<span class="hljs-string"><span class="hljs-string">'disk'</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>); noise_mean = <span class="hljs-number"><span class="hljs-number">0</span></span>; noise_var = <span class="hljs-number"><span class="hljs-number">0.0001</span></span>; estimated_nsr = noise_var / <span class="hljs-keyword"><span class="hljs-keyword">var</span></span>(I(:)); I = edgetaper(I, PSF); figure(<span class="hljs-number"><span class="hljs-number">2</span></span>); imshow(deconvwnr(I, PSF, estimated_nsr)); title(<span class="hljs-string"><span class="hljs-string">''</span></span>);</code> </pre><br>  And we get the following result: <br><br><img src="https://habrastorage.org/storage2/9d8/554/c15/9d8554c156e63a213797502e4d5b9075.png"><br><br>  As you can see, new details have appeared on the image, clarity has become much higher, although noise also appeared in the form of ‚Äúringing‚Äù on contrasting borders. <br><br>  And an example with a real lubricant - for its implementation, the camera was mounted on a tripod, a relatively long exposure was set and a uniform motion was obtained at the moment of shutter release: <br><img src="https://habrastorage.org/storage2/15c/773/b99/15c773b99ae9b058e43548649946ce53.png"><br><br>  The script is about the same, only the type of PSF is now ‚Äúmotion‚Äù: <br><br><pre> <code class="php hljs">% Load image I = im2double(imread(<span class="hljs-string"><span class="hljs-string">'IMG_REAL_motion_blur.PNG'</span></span>)); figure(<span class="hljs-number"><span class="hljs-number">1</span></span>); imshow(I); title(<span class="hljs-string"><span class="hljs-string">' '</span></span>); %PSF PSF = fspecial(<span class="hljs-string"><span class="hljs-string">'motion'</span></span>, <span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); noise_mean = <span class="hljs-number"><span class="hljs-number">0</span></span>; noise_var = <span class="hljs-number"><span class="hljs-number">0.0001</span></span>; estimated_nsr = noise_var / <span class="hljs-keyword"><span class="hljs-keyword">var</span></span>(I(:)); I = edgetaper(I, PSF); figure(<span class="hljs-number"><span class="hljs-number">2</span></span>); imshow(deconvwnr(I, PSF, estimated_nsr)); title(<span class="hljs-string"><span class="hljs-string">''</span></span>);</code> </pre><br>  Result: <br><img src="https://habrastorage.org/storage2/e2e/12d/6be/e2e12d6be301a6dd467f365a236e46d2.png"><br><br>  The quality, again, has improved markedly - the frames on the windows and cars have become visible.  Artifacts are already different than in the previous defocusing example. <br><br>  At this interesting and finish the first part. <br>  In the second part, I will focus on the problems of processing real images - building PSF and evaluating them, consider more complex and advanced deconvolution techniques, methods for eliminating ring type defects, review and compare existing software, and so on. <br><br>  <b>PS</b> Not so long ago an article was published on the Habr√© about <a href="http://habrahabr.ru/blogs/image_processing/130198/">Fixing blurry photos in a new version of Photoshop</a> <br>  For those who want to play around with a similar technology to remove blurring (perhaps the one that will be used in Photoshop), you can download the demo version of the application, see recovery examples, and <a href="http://www.cse.cuhk.edu.hk/~leojia/projects/robust_deblur/robust_motion_deblurring.pdf">read about the principle of operation</a> . <br><br><h1>  Literature </h1><br>  Gonzalez R., Woods R. Digital Image Processing <br>  Gonzalez R., Woods R., Eddins S. Digital Image Processing in MATLAB <br><br>  <b>UPD:</b> <a href="http://habrahabr.ru/post/147828">Continuation Link</a> <br><br><pre>  - </pre>  Vladimir Yuzhikov </div><p>Source: <a href="https://habr.com/ru/post/136853/">https://habr.com/ru/post/136853/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../136848/index.html">Where Apple iCloud Stores Your Files</a></li>
<li><a href="../136849/index.html">Small life hacking with clipboard editing</a></li>
<li><a href="../136850/index.html">Welcome to our office</a></li>
<li><a href="../136851/index.html">Root on Lenovo ThinkPad Tablet</a></li>
<li><a href="../136852/index.html">PostgreSQL: Unique keys for a distributed database. Practice</a></li>
<li><a href="../136855/index.html">API maps from 2GIS: review</a></li>
<li><a href="../136858/index.html">Japanese operator shows ads in the alert zone on their Android phones</a></li>
<li><a href="../136859/index.html">Anonymous will launch their MegaUpload</a></li>
<li><a href="../136860/index.html">Open letter to JS leaders regarding semicolons</a></li>
<li><a href="../136861/index.html">28 years ago the first Mac was released</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>