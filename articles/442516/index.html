<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A guide to using pandas for analyzing large data sets.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When using the pandas library to analyze small data sets that do not exceed 100 megabytes, performance rarely becomes a problem. But when it comes to ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A guide to using pandas for analyzing large data sets.</h1><div class="post__text post__text-html js-mediator-article"> When using the pandas library to analyze small data sets that do not exceed 100 megabytes, performance rarely becomes a problem.  But when it comes to examining datasets that can reach several gigabytes in size, performance problems can lead to a significant increase in the duration of the data analysis and can even cause analysis to be impossible due to lack of memory. <br><br>  While tools like Spark can efficiently handle large data sets (from hundreds of gigabytes to several terabytes), in order to fully utilize their capabilities you usually need powerful and expensive hardware.  And, in comparison with pandas, they are not distinguished by a rich set of tools for quality cleaning, research and data analysis.  For medium-sized datasets, it is best to try to use pandas more effectively, rather than switching to other tools. <br><br> <a href="https://habr.com/ru/company/ruvds/blog/442516/"><img src="https://habrastorage.org/webt/gd/jg/60/gdjg60abxgti2otxocpd0ct2uci.jpeg"></a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the material we are publishing today, we will talk about the peculiarities of working with memory when using pandas, and how, simply selecting the appropriate types of data stored in the columns of the <code>DataFrame</code> tabular data <code>DataFrame</code> , to reduce memory consumption by almost 90%. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Work with data about baseball games</font> </h2><br>  We will work with Major League baseball data collected over 130 years and taken from <a href="http://www.retrosheet.org/gamelogs/index.html">Retrosheet</a> . <br><br>  Initially, this data was presented in the form of 127 CSV files, but we merged them into one data set using <a href="https://csvkit.readthedocs.io/en/1.0.2/">csvkit</a> and added, as the first row of the resulting table, a row with column names.  If you want, you can download <a href="https://data.world/dataquest/mlb-game-logs">our version of</a> this data and experiment with it by reading the article. <br><br>  We start by importing the dataset and take a look at its first five lines.  You can find them in <a href="https://docs.google.com/spreadsheets/d/1TbX9qG1Q8Jt1xXmQoWMWPJiyk9t0bkgQuEGuL8zfpLQ/edit%3Fusp%3Dsharing">this</a> table, on the <code>   </code> sheet. <br><br><pre> <code class="plaintext hljs">import pandas as pd gl = pd.read_csv('game_logs.csv') gl.head()</code> </pre> <br>  Below are information about the most important columns of the table with this data.  If you want to read the explanations for all columns - <a href="https://data.world/dataquest/mlb-game-logs/workspace/data-dictionary">here</a> you can find a dictionary of data for the entire data set. <br><br><ul><li>  <code>date</code> - The date of the game. </li><li>  <code>v_name</code> - Name of the guest team. </li><li>  <code>v_league</code> - guest team league. </li><li>  <code>h_name</code> - The name of the home team. </li><li>  <code>h_league</code> - home team league. </li><li>  <code>v_score</code> - Guest team points. </li><li>  <code>h_score</code> - <code>h_score</code> team points. </li><li>  <code>v_line_score</code> - Summary of guest team points, for example, <code>010000(10)00</code> . </li><li>  <code>h_line_score</code> - Summary by points of the home team, for example - <code>010000(10)0X</code> . </li><li>  <code>park_id</code> - ID of the field where the game was played. </li><li>  <code>attendance</code> - The number of viewers. </li></ul><br>  To find out general information about the <code>DataFrame</code> object, you can use the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html">DataFrame.info ()</a> method.  Through this method, you can learn about the size of the object, the types of data and memory usage. <br><br>  By default, pandas, for the sake of saving time, <code>DataFrame</code> rough information about the memory usage of a <code>DataFrame</code> object.  We are interested in accurate information, so we set the <code>memory_usage</code> parameter to <code>'deep'</code> . <br><br><pre> <code class="plaintext hljs">gl.info(memory_usage='deep')</code> </pre> <br>  Here is the information we managed to get: <br><br><pre> <code class="plaintext hljs">&lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 171907 entries, 0 to 171906 Columns: 161 entries, date to acquisition_info dtypes: float64(77), int64(6), object(78) memory usage: 861.6 MB</code> </pre> <br>  As it turned out, we have 171,907 rows and 161 columns.  The pandas library automatically figured out the data types.  There are 83 columns with numeric data and 78 columns with objects.  Object columns are used to store string data, and in cases where the column contains data of different types. <br><br>  Now, in order to better understand how you can optimize the memory usage of this <code>DataFrame</code> object, let's talk about how pandas stores data in memory. <br><br><h2>  <font color="#3AC1EF">Internal representation of the DataFrame object</font> </h2><br>  Inside pandas, data columns are grouped into blocks with values ‚Äã‚Äãof the same type.  Here is an example of how pandas stores the first 12 columns of a <code>DataFrame</code> object. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d35/c70/c63/d35c70c635289a5cecc520c58e662e9a.png"></div><br>  <i><font color="#999999">Internal representation of data of different types in pandas</font></i> <br><br>  You may notice that blocks do not store information about column names.  This happens because the blocks are optimized for storing values ‚Äã‚Äãthat are in the cells of the table of the <code>DataFrame</code> object.  For storing information about the correspondence between the row and column indexes of a dataset and what is stored in blocks of the same type of data, is responsible the class <code>BlockManager</code> .  It plays the role of an API that provides access to the underlying data.  When we read, edit, or delete values, the <code>DataFrame</code> class interacts with the <code>BlockManager</code> class to convert our requests to calls to functions and methods. <br><br>  Each data type has a specialized class in the <code>pandas.core.internals</code> module.  For example, pandas uses the <code>ObjectBlock</code> class to represent blocks containing string columns, and the <code>FloatBlock</code> class to represent blocks containing columns that <code>FloatBlock</code> floating-point numbers.  For blocks representing numeric values ‚Äã‚Äãthat look like integers or floating point numbers, pandas combines the columns and stores them as the <code>ndarray</code> data <code>ndarray</code> the NumPy library.  This data structure is based on the array C, the values ‚Äã‚Äãare stored in a continuous block of memory.  Thanks to this data storage scheme, access to data fragments is very fast. <br><br>  Since data of different types is stored separately, we investigate the use of memory by different types of data.  Let's start with the average memory usage for different types of data. <br><br><pre> <code class="plaintext hljs">for dtype in ['float','int','object']:   selected_dtype = gl.select_dtypes(include=[dtype])   mean_usage_b = selected_dtype.memory_usage(deep=True).mean()   mean_usage_mb = mean_usage_b / 1024 ** 2   print("Average memory usage for {} columns: {:03.2f} MB".format(dtype,mean_usage_mb))</code> </pre> <br>  As a result, it appears that the average indicators of memory usage for data of different types look like this: <br><br><pre> <code class="plaintext hljs">Average memory usage for float columns: 1.29 MB Average memory usage for int columns: 1.12 MB Average memory usage for object columns: 9.53 MB</code> </pre> <br>  This information gives us to understand that most of the memory goes to 78 columns that store object values.  We'll talk more about this later, but for now let's think about whether we can improve the use of memory by columns that store numeric data. <br><br><h2>  <font color="#3AC1EF">Subtypes</font> </h2><br>  As we have said, pandas presents numeric values ‚Äã‚Äãas <code>ndarray</code> NumPy data structures and stores them in continuous memory blocks.  This storage model allows you to save memory and quickly access values.  Since pandas represents each value of the same type using the same number of bytes, and <code>ndarray</code> structures store information about the number of values, pandas can quickly and accurately return information about the amount of memory consumed by columns storing numerical values. <br><br>  Many data types in pandas have many subtypes that can use fewer bytes to represent each value.  For example, the type <code>float</code> has subtypes <code>float16</code> , <code>float32</code> and <code>float64</code> .  The number in the type name indicates the number of bits that the subtype uses to represent values.  For example, in the subtypes just listed, 2, 4, 8, and 16 bytes are used for data storage, respectively.  The following table shows the subtypes most commonly used in pandas data types. <br><table><tbody><tr><td>  <sup>Memory usage, bytes</sup> <sup><br></sup> </td><td>  <sup>Floating point number</sup> <sup><br></sup> </td><td>  <sup>Integer</sup> <sup><br></sup> </td><td>  <sup>Unsigned integer</sup> <sup><br></sup> </td><td>  <sup>date and time</sup> <sup><br></sup> </td><td>  <sup>Boolean value</sup> <sup><br></sup> </td><td width="75">  <sup>An object</sup> <sup><br></sup> </td></tr><tr><td>  <sup>one</sup> <sup><br></sup> </td><td></td><td>  <sup>int8</sup> <sup><br></sup> </td><td>  <sup>uint8</sup> <sup><br></sup> </td><td></td><td>  <sup>bool</sup> <sup><br></sup> </td><td></td></tr><tr><td>  <sup>2</sup> <sup><br></sup> </td><td>  <sup>float16</sup> <sup><br></sup> </td><td>  <sup>int16</sup> <sup><br></sup> </td><td>  <sup>uint16</sup> <sup><br></sup> </td><td></td><td></td><td></td></tr><tr><td>  <sup>four</sup> <sup><br></sup> </td><td>  <sup>float32</sup> <sup><br></sup> </td><td>  <sup>int32</sup> <sup><br></sup> </td><td>  <sup>uint32</sup> <sup><br></sup> </td><td></td><td></td><td></td></tr><tr><td>  <sup>eight</sup> <sup><br></sup> </td><td>  <sup>float64</sup> <sup><br></sup> </td><td>  <sup>int64</sup> <sup><br></sup> </td><td>  <sup>uint64</sup> <sup><br></sup> </td><td>  <sup>datetime64</sup> <sup><br></sup> </td><td></td><td></td></tr><tr><td>  <sup>Variable memory</sup> <sup><br></sup> </td><td></td><td></td><td></td><td></td><td></td><td>  <sup>object</sup> <sup><br></sup> </td></tr></tbody></table><br>  A value of type <code>int8</code> uses 1 byte (8 bits) to store numbers and can represent 256 binary values ‚Äã‚Äã(2 to 8 degrees).  This means that this subtype can be used to store values ‚Äã‚Äãin the range from -128 to 127 (including 0). <br><br>  To check the minimum and maximum values ‚Äã‚Äãsuitable for storage using each integer subtype, you can use the <code>numpy.iinfo()</code> method.  Consider an example: <br><br><pre> <code class="plaintext hljs">import numpy as np int_types = ["uint8", "int8", "int16"] for it in int_types:   print(np.iinfo(it))</code> </pre> <br>  Having executed this code, we get the following data: <br><br><pre> <code class="plaintext hljs">Machine parameters for uint8 --------------------------------------------------------------- min = 0 max = 255 --------------------------------------------------------------- Machine parameters for int8 --------------------------------------------------------------- min = -128 max = 127 --------------------------------------------------------------- Machine parameters for int16 --------------------------------------------------------------- min = -32768 max = 32767 ---------------------------------------------------------------</code> </pre> <br>  Here you can pay attention to the difference between the types of <code>uint</code> (unsigned integer) and <code>int</code> (signed integer).  Both types have the same capacity, but, when storing only positive values ‚Äã‚Äãin columns, unsigned types allow for more efficient use of memory. <br><br><h2>  <font color="#3AC1EF">Optimize storage of numeric data using subtypes</font> </h2><br>  The <code>pd.to_numeric()</code> function can be used for downward conversion of numeric types.  To select integer columns, use the <code>DataFrame.select_dtypes()</code> method, then optimize them and compare the memory usage before and after optimization. <br><br><pre> <code class="plaintext hljs">#     ,   , #   ,      . def mem_usage(pandas_obj):   if isinstance(pandas_obj,pd.DataFrame):       usage_b = pandas_obj.memory_usage(deep=True).sum()   else: #     ,     DataFrame,   Series       usage_b = pandas_obj.memory_usage(deep=True)   usage_mb = usage_b / 1024 ** 2 #       return "{:03.2f} MB".format(usage_mb) gl_int = gl.select_dtypes(include=['int']) converted_int = gl_int.apply(pd.to_numeric,downcast='unsigned') print(mem_usage(gl_int)) print(mem_usage(converted_int)) compare_ints = pd.concat([gl_int.dtypes,converted_int.dtypes],axis=1) compare_ints.columns = ['before','after'] compare_ints.apply(pd.Series.value_counts)</code> </pre> <br>  Here is the result of a memory consumption study: <br><br> <code>7.87 MB <br> 1.48 MB</code> <br> <table><tbody><tr><td></td><td>  Before <br></td><td>  After <br></td></tr><tr><td>  uint8 <br></td><td>  NaN <br></td><td>  5.0 <br></td></tr><tr><td>  uint32 <br></td><td>  NaN <br></td><td>  1.0 <br></td></tr><tr><td>  int64 <br></td><td>  6.0 <br></td><td>  NaN <br></td></tr></tbody></table><br>  As a result, you can see a drop in memory usage from 7.9 to 1.5 megabytes, that is, we have reduced memory consumption by more than 80%.  The overall impact of this optimization on the original <code>DataFrame</code> object, however, is not particularly strong, since there are very few integer columns. <br><br>  Do the same with columns containing floating point numbers. <br><br><pre> <code class="plaintext hljs">gl_float = gl.select_dtypes(include=['float']) converted_float = gl_float.apply(pd.to_numeric,downcast='float') print(mem_usage(gl_float)) print(mem_usage(converted_float)) compare_floats = pd.concat([gl_float.dtypes,converted_float.dtypes],axis=1) compare_floats.columns = ['before','after'] compare_floats.apply(pd.Series.value_counts)</code> </pre> <br>  The result is the following: <br><br> <code>100.99 MB <br> 50.49 MB</code> <br> <table><tbody><tr><td></td><td>  Before <br></td><td>  After <br></td></tr><tr><td>  float32 <br></td><td>  NaN <br></td><td>  77.0 <br></td></tr><tr><td>  float64 <br></td><td>  77.0 <br></td><td>  NaN <br></td></tr></tbody></table><br>  As a result, all the columns that store floating-point numbers with the <code>float64</code> data type now store <code>float32</code> , which gave us a 50% reduction in memory usage. <br><br>  Create a copy of the original <code>DataFrame</code> object, use these optimized numeric columns instead of those that were originally present in it, and look at the overall memory utilization rate after optimization. <br><br><pre> <code class="plaintext hljs">optimized_gl = gl.copy() optimized_gl[converted_int.columns] = converted_int optimized_gl[converted_float.columns] = converted_float print(mem_usage(gl)) print(mem_usage(optimized_gl))</code> </pre> <br>  Here's what we got: <br><br> <code>861.57 MB <br> 804.69 MB</code> <br> <br>  Although we have significantly reduced memory consumption by columns storing numeric data, in general, for the entire <code>DataFrame</code> object, memory consumption has decreased by only 7%.  The source of a much more serious improvement in the situation may be the optimization of the storage of object types. <br><br>  Before we do this optimization, let's take a closer look at how strings are stored in pandas, and compare this with how numbers are stored here. <br><br><h2>  <font color="#3AC1EF">Comparison of number and string storage mechanisms</font> </h2><br>  The <code>object</code> type represents values ‚Äã‚Äãusing Python string objects.  This is partly due to the fact that NumPy does not support the representation of missing string values.  Since Python is a high-level interpreted language, it does not provide the programmer with the tools to fine-tune how data is stored in memory. <br><br>  This restriction leads to the fact that the lines are not stored in continuous fragments of memory, their representation in memory is fragmented.  This leads to an increase in memory consumption and slowing down the speed of working with string values.  Each element in the column storing an object data type is actually a pointer that contains an ‚Äúaddress‚Äù at which the present value is located in memory. <br><br>  Below is a diagram based on <a href="https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/">this</a> material, which compares the storage of numeric data using the NumPy data types and the storage of strings using the built-in Python data types. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d80/66f/54b/d8066f54b091531c120b94c90f698236.png"></div><br>  <i><font color="#999999">Storing numeric and string data</font></i> <br><br>  Here you can remember that above, in one of the tables, it was shown that variable memory is used to store object type data.  Although each pointer occupies 1 byte of memory, each specific string value occupies the same amount of memory that would be used to store a single string in Python.  To confirm this, we use the <code>sys.getsizeof()</code> method.  First, look at the individual lines, and then at the <code>Series</code> pandas object, which stores string data. <br><br>  So, first examine the usual lines: <br><br><pre> <code class="plaintext hljs">from sys import getsizeof s1 = 'working out' s2 = 'memory usage for' s3 = 'strings in python is fun!' s4 = 'strings in python is fun!' for s in [s1, s2, s3, s4]:   print(getsizeof(s))</code> </pre> <br>  Here the data on the use of memory look like this: <br><br> <code>60 <br> 65 <br> 74 <br> 74</code> <br> <br>  Now let's look at how the use of strings in the <code>Series</code> object looks like: <br><br><pre> <code class="plaintext hljs">obj_series = pd.Series(['working out',                         'memory usage for',                         'strings in python is fun!',                         'strings in python is fun!']) obj_series.apply(getsizeof)</code> </pre> <br>  Here we get the following: <br><br><pre> <code class="plaintext hljs">0    60 1    65 2    74 3    74 dtype: int64</code> </pre> <br>  You can see here that the sizes of strings stored in <code>Series</code> pandas objects are similar to their sizes when working with them in Python and when presented as independent entities. <br><br><h2>  <font color="#3AC1EF">Optimize data storage for object types using categorical variables</font> </h2><br>  <a href="http://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html">Categorical variables</a> appeared in pandas version 0.15.  The corresponding type, <code>category</code> , uses in its internal mechanisms, instead of the original values ‚Äã‚Äãstored in the columns of the table, integer values.  Pandas uses a separate dictionary that matches integer and source values.  This approach is useful in cases where the columns contain values ‚Äã‚Äãfrom a limited set.  When data stored in a column is converted into the <code>category</code> type, pandas uses the <code>int</code> subtype, which makes it possible to efficiently manage the memory and is able to represent all the unique values ‚Äã‚Äãfound in the column. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1f5/48d/59c/1f548d59c9b41fd906d038c19d3a2da2.png"></div><br>  <i><font color="#999999">Baseline and categorical data using the int8 subtype</font></i> <br><br>  In order to understand exactly where we can use categorical data to reduce memory consumption, find out the number of unique values ‚Äã‚Äãin the columns that store values ‚Äã‚Äãof object types: <br><br><pre> <code class="plaintext hljs">gl_obj = gl.select_dtypes(include=['object']).copy() gl_obj.describe()</code> </pre> <br>  What we have, you can find in <a href="https://docs.google.com/spreadsheets/d/1TbX9qG1Q8Jt1xXmQoWMWPJiyk9t0bkgQuEGuL8zfpLQ/edit%3Fusp%3Dsharing">this</a> table, on the sheet, the <code>    </code> . <br><br>  For example, in the <code>day_of_week</code> column, which is the day of the week on which the game was played, there are 171907 values.  Among them, only 7 unique.  In general, one glance at this report is enough to understand that in many columns for representing the data of approximately 172,000 games quite a few unique values ‚Äã‚Äãare used. <br><br>  Before we do full-scale optimization, let's select some single column that stores object data, at least <code>day_of_week</code> , and see what happens inside the program when it is converted to a categorical type. <br><br>  As already mentioned, this column contains only 7 unique values.  To convert it to a categorical type, we use the <code>.astype()</code> method. <br><br><pre> <code class="plaintext hljs">dow = gl_obj.day_of_week print(dow.head()) dow_cat = dow.astype('category') print(dow_cat.head())</code> </pre> <br>  Here's what we got: <br><br><pre> <code class="plaintext hljs">0    Thu 1    Fri 2    Sat 3    Mon 4    Tue Name: day_of_week, dtype: object 0    Thu 1    Fri 2    Sat 3    Mon 4    Tue Name: day_of_week, dtype: category Categories (7, object): [Fri, Mon, Sat, Sun, Thu, Tue, Wed]</code> </pre> <br>  As you can see, although the column type has changed, the data stored in it looks the same as before.  Let's look now at what is happening inside the program. <br><br>  In the following code, we use the <code>Series.cat.codes</code> attribute to find out which integer values ‚Äã‚Äãthe <code>category</code> type uses to represent each of the days of the week: <br><br><pre> <code class="plaintext hljs">dow_cat.head().cat.codes</code> </pre> <br>  We manage to figure out the following: <br><br><pre> <code class="plaintext hljs">0    4 1    0 2    2 3    1 4    5 dtype: int8</code> </pre> <br>  Here you can notice that each unique value is assigned an integer value, and that the column is now of type <code>int8</code> .  There are no missing values, but if that were the case, the number -1 would be used to indicate such values. <br><br>  Now let's compare the memory consumption before and after converting the <code>day_of_week</code> column to the <code>category</code> type. <br><br><pre> <code class="plaintext hljs">print(mem_usage(dow)) print(mem_usage(dow_cat))</code> </pre> <br>  This is what happens: <br><br> <code>9.84 MB <br> 0.16 MB</code> <br> <br>  As you can see, at first 9.84 megabytes of memory were consumed, and after optimization only 0.16 megabytes, which means 98% improvement of this indicator.  Note that working with this column probably demonstrates one of the most profitable optimization scenarios, when only 7 unique values ‚Äã‚Äãare used in a column containing approximately 172,000 items. <br><br>  Although the idea of ‚Äã‚Äãconverting all columns to this data type looks attractive, before you do this, you should consider the negative side effects of such a conversion.  So, the most serious disadvantage of this transformation is the impossibility of performing arithmetic operations on categorical data.  This also applies to conventional arithmetic operations, and using methods like <code>Series.min()</code> and <code>Series.max()</code> without first converting the data to a real numeric type. <br><br>  We should limit the use of the <code>category</code> type, mainly to columns that store <code>object</code> data, in which less than 50% of the values ‚Äã‚Äãare unique.  If all the values ‚Äã‚Äãin a column are unique, then the use of the <code>category</code> type will lead to an increase in memory usage.  This is due to the fact that in memory you have to store, in addition to the numeric category codes, the original string values ‚Äã‚Äãas well.  Details on <code>category</code> restrictions can be found in the pandas <a href="http://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html">documentation</a> . <br><br>  Create a loop that iterates through all the columns that store data of the <code>object</code> type, finds out if the number of unique values ‚Äã‚Äãin the columns does not exceed 50%, and if so, converts them into the <code>category</code> type. <br><br><pre> <code class="plaintext hljs">converted_obj = pd.DataFrame() for col in gl_obj.columns:   num_unique_values = len(gl_obj[col].unique())   num_total_values = len(gl_obj[col])   if num_unique_values / num_total_values &lt; 0.5:       converted_obj.loc[:,col] = gl_obj[col].astype('category')   else:       converted_obj.loc[:,col] = gl_obj[col]</code> </pre> <br>  Now let's compare what happened after optimization with what it was before: <br><br><pre> <code class="plaintext hljs">print(mem_usage(gl_obj)) print(mem_usage(converted_obj)) compare_obj = pd.concat([gl_obj.dtypes,converted_obj.dtypes],axis=1) compare_obj.columns = ['before','after'] compare_obj.apply(pd.Series.value_counts)</code> </pre> <br>  We get the following: <br><br> <code>752.72 MB <br> 51.67 MB</code> <br> <table><tbody><tr><td></td><td>  Before <br></td><td>  After <br></td></tr><tr><td>  object <br></td><td>  78.0 <br></td><td>  NaN <br></td></tr><tr><td>  category <br></td><td>  NaN <br></td><td>  78.0 <br></td></tr></tbody></table><br>           <code>category</code> ,     ,          , ,      ,     ,    ,  ,     . <br><br>  ,  ,     ,    <code>object</code> ,   752   52 ,    93%.     ,          .  ,       ,   ,  ,     891 . <br><br><pre> <code class="plaintext hljs">optimized_gl[converted_obj.columns] = converted_obj mem_usage(optimized_gl)</code> </pre> <br>     : <br><br> <code>'103.64 MB'</code> <br> <br>  .     - .    ,       <code>datetime</code> , ,  ,        . <br><br><pre> <code class="plaintext hljs">date = optimized_gl.date print(mem_usage(date)) date.head()</code> </pre> <br>       : <br><br> <code>0.66 MB</code> <br> <br>    : <br><br><pre> <code class="plaintext hljs">0    18710504 1    18710505 2    18710506 3    18710508 4    18710509 Name: date, dtype: uint32</code> </pre> <br>  ,               <code>uint32</code> . -       <code>datetime</code>     ,         64 .       <code>datetime</code> ,  ,  ,          . <br><br>      <code>to_datetime()</code> ,  <code>format</code>    ,      <code>YYYY-MM-DD</code> . <br><br><pre> <code class="plaintext hljs">optimized_gl['date'] = pd.to_datetime(date,format='%Y%m%d') print(mem_usage(optimized_gl)) optimized_gl.date.head()</code> </pre> <br>    : <br><br> <code>104.29 MB</code> <br> <br>    : <br><br><pre> <code class="plaintext hljs">0   1871-05-04 1   1871-05-05 2   1871-05-06 3   1871-05-08 4   1871-05-09 Name: date, dtype: datetime64[ns]</code> </pre> <br><h2> <font color="#3AC1EF">    </font> </h2><br>            <code>DataFrame</code> .        , , ,   ,  ,  ,  ,  .       ,        .    ,     ,     ,     .        ,        ,      <code>DataFrame</code> ,   . <br><br>  ,             .  <a href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html">pandas.read_csv()</a>   ,   . ,  <code>dtype</code>  ,   ,   ,   ,     ‚Äî  NumPy. <br><br>      ,          ,   .         ,      . <br><br><pre> <code class="plaintext hljs">dtypes = optimized_gl.drop('date',axis=1).dtypes dtypes_col = dtypes.index dtypes_type = [i.name for i in dtypes.values] column_types = dict(zip(dtypes_col, dtypes_type)) #    161 ,  #  10  /   #     preview = first2pairs = {key:value for key,value in list(column_types.items())[:10]} import pprint pp = pp = pprint.PrettyPrinter(indent=4) pp.pprint(preview)     : {   'acquisition_info': 'category',   'h_caught_stealing': 'float32',   'h_player_1_name': 'category',   'h_player_9_name': 'category',   'v_assists': 'float32',   'v_first_catcher_interference': 'float32',   'v_grounded_into_double': 'float32',   'v_player_1_id': 'category',   'v_player_3_id': 'category',   'v_player_5_id': 'category'}</code> </pre> <br>          ,      ,    . <br><br>    - : <br><br><pre> <code class="plaintext hljs">read_and_optimized = pd.read_csv('game_logs.csv',dtype=column_types,parse_dates=['date'],infer_datetime_format=True) print(mem_usage(read_and_optimized)) read_and_optimized.head()</code> </pre> <br>       : <br><br> <code>104.28 MB</code> <br> <br>    ,     <code>   </code>  <a href="https://docs.google.com/spreadsheets/d/1TbX9qG1Q8Jt1xXmQoWMWPJiyk9t0bkgQuEGuL8zfpLQ/edit%3Fusp%3Dsharing"></a> . <br><br>  ,    <code>   </code>  <code>   </code> ,     ,  ,       .      pandas       861.6   104.28 ,     88% . <br><br><h2> <font color="#3AC1EF">  </font> </h2><br> ,  ,    ,     .     . <br><br><pre> <code class="plaintext hljs">optimized_gl['year'] = optimized_gl.date.dt.year games_per_day = optimized_gl.pivot_table(index='year',columns='day_of_week',values='date',aggfunc=len) games_per_day = games_per_day.divide(games_per_day.sum(axis=1),axis=0) ax = games_per_day.plot(kind='area',stacked='true') ax.legend(loc='upper right') ax.set_ylim(0,1) plt.show()</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3b2/699/6a2/3b26996a26b73e9a3ce87f3ff22dcf34.png"></div><br> <i><font color="#999999">,    </font></i> <br><br>  ,  1920-      ,  ,    50 ,        . <br><br>  ,  ,    ,      50 ,   . <br><br>    ,      . <br><br><pre> <code class="plaintext hljs">game_lengths = optimized_gl.pivot_table(index='year', values='length_minutes') game_lengths.reset_index().plot.scatter('year','length_minutes') plt.show()</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a6d/6db/5d2/a6d6db5d2e6bdb7330ac8a0ff2a6febd.png"></div><br> <i><font color="#999999"> </font></i> <br><br>   ,   1940-         . <br><br><h2>  <font color="#3AC1EF">Results</font> </h2><br>            pandas,         ,     <code>DataFrame</code> ,   90%.       : <br><br><ul><li>       ,   ,   ,    , . </li><li>        . </li></ul><br>  ,            , ,         ,    ,  ,       pandas,    ,    . <br><br>  <b>Dear readers!</b>     <a href="https://habr.com/ru/company/ruvds/blog/441568/"></a>   <a href="https://habr.com/ru/users/eugene_bb/" class="user_link">eugene_bb</a> .    -  ,    ‚Äî    . <br><br> <a href="https://ruvds.com/ru-rub/"><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div><p>Source: <a href="https://habr.com/ru/post/442516/">https://habr.com/ru/post/442516/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../442500/index.html">Detekt Static Analyzer for Kotlin</a></li>
<li><a href="../442502/index.html">We transform the workplace in the recumbent for $ 200</a></li>
<li><a href="../442506/index.html">Is Russia being punished for illegal trade in personal data?</a></li>
<li><a href="../442508/index.html">How do udalenka accelerates innovation on gitlab</a></li>
<li><a href="../442514/index.html">Distributed systems. Design patterns. Book Review</a></li>
<li><a href="../442520/index.html">Case Saving 300,000 p. per month on contextual advertising</a></li>
<li><a href="../442522/index.html">Intuitive RL (Reinforcement Learning): An Introduction to Advantage-Actor-Critic (A2C)</a></li>
<li><a href="../442524/index.html">How to increase security in personal identification and access control systems</a></li>
<li><a href="../442526/index.html">The history of Soviet cassette players (part two): Walkman boom, gadget for the KGB and tape recorders</a></li>
<li><a href="../442528/index.html">How to make the game run at 60fps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>