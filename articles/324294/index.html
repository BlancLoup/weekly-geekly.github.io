<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Browser-based WebRTC broadcasts with low latency RTSP IP cameras</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="According to some data, today, hundreds of millions of IP cameras for video surveillance have been installed in the world. However, not all of them ha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Browser-based WebRTC broadcasts with low latency RTSP IP cameras</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/files/f7f/aff/610/f7faff6101c14442b381c8eb029098a0.jpg"></div><br>  According to some data, today, <b>hundreds of millions of</b> IP cameras for video surveillance have been installed in the world.  However, not all of them have a critical delay in video playback.  Video surveillance, as a rule, occurs ‚Äústatic‚Äù - the stream is recorded in the storage and can be analyzed for movement.  For video surveillance, many software and hardware solutions have been developed that do their job well. <br><br>  In this article, we will look at a slightly different application of the <b>IP camera</b> , namely the application in online broadcasts, where <b>low communication delay</b> is required <b>.</b> <br><a name="habracut"></a><br>  First of all, let's eliminate the possible misunderstanding in the terminology about webcams and IP cameras. <br><br>  <b>A webcam</b> is a video capture device that does not have its own processor and network interface.  A webcam requires a connection to a computer, smartphone, or other device that has a network card and processor. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/files/813/993/2ec/8139932ecf794e799477a5e2cd2068c7.jpg"></div><br>  <b>An IP camera</b> is a standalone device that has its own network card and processor for compressing captured video and sending it to the network.  Thus, the IP camera is a stand-alone mini-computer that fully connects to the network and does not require connection to another device, and can directly broadcast to the network. <br><br>  <b>Low</b> latency is quite a rare requirement for IP cameras and online broadcasts.  The need to work with low latency appears, for example, if the source of the video stream actively interacts with the viewers of this stream. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a5c/1f3/b93/a5c1f3b935fd4703beb9c082021e82fb.png"></div><br>  Most often, low latency is required in game use scenarios.  Examples include real-time video auction, live dealer video casino, interactive online TV show with presenter, quadcopter remote control, etc. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/dda/1cf/d2b/dda1cfd2b4864e049f2cdf678e6e1e0d.png"></div><br>  Dealer live online casinos at work. <br><br>  A regular RTSP IP camera, as a rule, shakes video in <b>H.264</b> codec and can work in two modes of data transport: <b>interleaved</b> and <b>non-interleaved</b> . <br><br>  <b>Interleaved</b> mode is the most popular and convenient, because  In this mode, video data is transmitted via TCP protocol within the network connection to the camera.  In order to distribute from an IP camera in interleaved, you just need to open / forward one RTSP port of the camera (for example, 554) to the outside.  The player can only connect to the camera via TCP and pick up the stream already inside this connection. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/52d/891/2aa/52d8912aa2b148a2b351df021f5b039f.jpg"></div><br>  The second mode of the camera is <b>non-interleaved</b> .  In this case, the connection is established using the <b>RTSP / TCP protocol</b> , and the traffic is already separate, using the <b>RTP / UDP protocol</b> outside the established TCP channel. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/d99/d11/133/d99d11133b4d4a8787e08cba79034709.jpg"></div><br>  <b>Non-interleaved</b> mode is more favorable for broadcasting videos with minimal latency, as it uses <b>RTP / UDP</b> , but at the same time is more problematic if the player is located behind <b>NAT</b> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/743/263/de9/743263de9f894921ba3c7e68640d5ee6.jpg"></div><br>  When you connect a player that is behind NAT to the IP camera, the player needs to know what external IP addresses and ports it can use to receive audio and video traffic.  These ports are specified in the SDP text config file, which is transmitted to the camera when an RTSP connection is established.  If the NAT was opened correctly and the correct IP addresses and ports are defined, then everything will work. <br><br>  So, in order to pick up video from a camera with a minimum delay, you need to use <b>non-interleave</b> mode and receive video traffic over UDP. <br><br>  Browsers do not support the RTSP / UDP protocol stack directly, but they support the protocol stack of the embedded <b>WebRTC</b> technology. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/1e5/263/637/1e526363741e4eb48ce70bf8c3baa659.jpg"></div><br>  Browser and camera technologies are very similar, in particular, <b>SRTP</b> is encrypted <b>RTP</b> .  But for the correct distribution to the browsers, the IP camera would need partial support for the WebRTC stack. <br><br>  To eliminate this incompatibility, an intermediate relay server is required, which will be a bridge between the IP camera protocols and browser protocols. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6f6/35b/f34/6f635bf34b084af6b1ff8c23a306cbe3.jpg"></div><br>  The server picks up the stream from the IP camera to itself via <b>RTP / UDP</b> and sends it to connected browsers via WebRTC. <br><br>  The WebRTC technology works over the <b>UDP protocol</b> and thus provides low latency in the direction <b>Server&gt; Browser</b> .  The IP camera also works under the <b>RTP / UDP protocol</b> and provides low latency in the direction <b>Camera&gt; Server</b> . <br><br>  The camera can give a limited number of streams, due to limited resources and bandwidth.  Using an intermediate server allows you to scale the broadcast from an IP camera to a large number of viewers. <br><br>  On the other hand, when using a server, two communication legs are included: <br>  1) Between viewers and server <br>  2) Between server and camera <br>  This topology has a number of "features" or "pitfalls."  We list them below. <br><br><h2>  Reef # 1 - Codecs </h2><br>  Obstacles to working with low latency and the causes of the deterioration of the overall system performance can be used codecs. <br><br>  For example, if the camera gives 720p video stream in H.264, and connects the Chrome-browser on an Android smartphone with support for only VP8. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ca0/76a/317/ca076a3173e14844bed0f337e70cff2c.jpg"></div><br>  When transcoding is turned on, a transcoding session must be created for each of the connected IP cameras, which decodes <b>H.264</b> and encodes in <b>VP8</b> .  In this case, the 16th nuclear dual-processor server will be able to serve only 10-15 IP cameras, from the approximate calculation 1 camera per physical core. <br><br>  Therefore, if the server capacity does not allow transcoding the planned number of cameras, then transcoding should be avoided.  For example, to serve only browsers with H.264 support, and the rest to suggest using a native mobile application for iOS or Android, where there is support for the H.264 codec. <br><br><img src="https://habrastorage.org/files/a72/4fa/5d2/a724fa5d209a4df7b575d3573a919f55.jpg"><br>  As an option to bypass transcoding in a mobile browser, you can use <b>HLS</b> .  But HTTP streaming doesn‚Äôt have a low latency at all and currently cannot be used for interactive broadcasts. <br><br><h2>  Reef # 2 - Camera Bitrate and Loss </h2><br>  UDP protocol helps to cope with the delay, but allows for loss of video packets.  Therefore, despite the low latency, with large losses in the network between the camera and the server, the picture can be spoiled. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6ed/8b0/c72/6ed8b0c72b484660b21e4cfbdb8a3f69.jpg"></div><br>  In order to eliminate losses, you need to make sure that the video stream generated by the camera has a bitrate that fits in the dedicated band between the camera and the server. <br><br><h2>  Reef # 3 - Viewers' Bitrate and Loss </h2><br>  Every broadcast viewer connected to the server also has a certain bandwidth on Download. <br><br>  If the IP camera sends a stream that exceeds the capabilities of the viewer's channel (for example, the camera sends <b>1 Mbps</b> , and the viewer can receive only <b>500 Kbps</b> ), then this channel will have large losses and, as a result, video friezes or strong artifacts. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/956/110/2b4/9561102b4b4a43f996a18d43b4081743.jpg"></div><br>  In this case, there are three options: <br><br><ol><li>  Transcode a video stream individually for each viewer under the required bitrate. </li><li>  Transcode streams are not for everyone connected, but for a group of spectators. </li><li>  Prepare camera streams in advance in several resolutions and bitrates. </li></ol><br>  <b>The first option</b> with transcoding for each viewer is not suitable, since it consumes CPU resources already with 10-15 connected viewers.  Although it should be noted that this option provides maximum flexibility with maximum CPU usage.  Those.  This is ideal, for example, if you are streaming only 10 geographically distributed people, each of them receives a dynamic bit rate and each of them needs a minimum delay. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/d9b/ec4/8fe/d9bec48fe9534f27889d950bdfc7e461.jpg"></div><br>  <b>The second option</b> is to reduce the load on the server's CPU using transcoding groups.  The server creates several bit rate groups, for example, two: <br><br><ul><li>  200 Kbps </li><li>  1 Mbps </li></ul><br>  If the viewer does not have enough bandwidth, he switches to the group in which he can comfortably receive the video stream.  Thus, the number of transcoding sessions is not equal to the number of viewers as in the first case, but is a fixed number, for example 2, if there are <b>two</b> transcoding groups. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/f70/0a0/b7f/f700a0b7f1ec4a03a9deaab6e5e52ceb.jpg"></div><br>  <b>The third option</b> involves the complete abandonment of transcoding on the server side and the use of already prepared video streams in various resolutions and bit rates.  In this case, the camera is configured to return two or three streams with different resolutions and bitrates, and viewers switch between these streams depending on their bandwidth. <br><br>  In this case, the transcoding load on the server goes and shifts to the camera itself, since  the camera is now forced to encode two or more streams instead of one. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/f15/e58/42a/f15e5842ad464ded8d2b7e659bd2fff7.jpg"></div><br>  As a result, we considered three options for adjusting the spectator bandwidth.  If we assume that one transcoding session takes 1 server core, we get the following CPU load table: <br><table><tbody><tr><td></td><td>  <strong>Adjustment method</strong> </td><td>  <strong>Number of cores on the server</strong> </td></tr><tr><td>  one </td><td>  Transcode a video stream for each viewer under the desired bitrate </td><td>  N - number of viewers </td></tr><tr><td>  2 </td><td>  Transcode video streams into groups of users </td><td>  G - the number of groups of spectators </td></tr><tr><td>  3 </td><td>  Prepare camera streams in advance in several resolutions and bitrates </td><td>  0 </td></tr></tbody></table><br>  From the table it can be seen that we can shift the transcoding load on the camera or transfer the transcoding to the server.  Options 2 and 3 at the same time look the most optimal. <br><br><h2>  RTSP testing as WebRTC </h2><br>  It is time to conduct several tests to identify the actual picture of what is happening.  Take a real IP camera and conduct a test to measure the delay in broadcasting. <br><br>  For testing, let's take the old <b>D-link DCS-2103</b> IP camera with <b>RTSP</b> support and <b>H.264 and G.711</b> codecs. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b9d/5b0/2a3/b9d5b02a3a0346888dce748f104ba5a7.jpg"></div><br>  Since the camera lay for a long time in the closet with other useful devices and wires, I had to send it to <b>Reset</b> by pressing and holding the button on the back of the camera for 10 seconds. <br><br>  After connecting to the network, a green light on the camera caught fire and the router saw another device on the local network with the IP address 192.168.1.37. <br><br>  Go to the web interface of the camera and set the codecs and resolution for testing: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/449/d38/1cc/449d381cc68b4728a59c04127aee557e.jpg"></div><br>  Next, go to the network settings and find out the RTSP address of the camera.  In this case, the RTSP address is <b>live1.sdp</b> , i.e.  The camera is available at <b>rtsp: //192.168.1.37/live1.sdp</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/814/0bd/3ba/8140bd3ba2e04478b3128bf90814e590.jpg"></div><br>  The availability of the camera is easy to check with the <b>VLC player</b> .  Media - Open Network Stream. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/77c/c5d/6f9/77cc5d6f9fe74479b432519fc89bfd16.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e7a/afd/097/e7aafd097de348e0aced98c09b804772.jpg"></div><br>  We made sure that the camera works and gives video via RTSP. <br><br>  As a server for testing we will use <a href="https://flashphoner.com/">Web Call Server 5</a> .  This streaming server supports <b>RTSP and WebRTC</b> protocols.  It will connect to the IP camera via <b>RTSP</b> and pick up the video stream.  Next, distribute the stream via <b>WebRTC</b> . <br><br>  You can <a href="https://flashphoner.com/download">install a Web Call Server</a> on your host or run a <a href="https://aws.amazon.com/marketplace/pp/B01D1L5EAK">ready-made Amazon EC2 instance</a> . <br><br>  After installation, you need to switch the server to RTSP <b>non-interleaved</b> mode, which we discussed above.  This can be done by adding settings. <br><br><pre><code class="hljs objectivec">rtsp_interleaved_mode=<span class="hljs-literal"><span class="hljs-literal">false</span></span></code> </pre> <br>  This setting is added to the flashphoner.properties config and requires a restart of the server: <br><br><pre> <code class="bash hljs">service webcallserver restart</code> </pre> <br>  Thus, we have a server that works according to the non-interleaved scheme, receives packets from an IP camera via UDP, and then distributes via WebRTC (UDP). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/5cf/47f/dae/5cf47fdaebb842929d3956a97115c884.jpg"></div><br>  The test server is located on a VPS server located in the data center of Frankfurt and has 2 cores and 2 gigabytes of RAM. <br><br>  The camera is located on the local network at 192.168.1.37. <br><br>  Therefore, the first thing we need to do is to forward port 554 to the address 192.168.1.37 for incoming <b>TCP / RTSP</b> connections, so that the server can establish a connection to our IP camera.  To do this, in the settings of the router, we add only one rule: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a5e/b94/c42/a5eb94c42e7943b88f9917b3e47382f4.jpg"></div><br>  The rule tells the router to redirect all incoming traffic on port 554, to 37 - the IP address. <br><br>  Then it remains to find out your external IP address.  This can be done in 5-15 seconds, googling by the word <b>whatismyip</b> <br><br>  If you have a friendly NAT and you know the external IP address, then you can start the tests with the server. <br><br>  The standard <a href="https://wcs5-eu.flashphoner.com/demo2/player">demo player</a> in Google Chrome browser looks like this: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/41f/dc5/9d4/41fdc59d44de472b9e753abfc2d513bc.jpg"></div><br>  To start playing an RTSP stream, you just need to enter its address in the <b>Stream</b> field. <br>  In this case, the stream address is: <b>rtsp: //ip-cam/live1.sdp</b> <br>  Here <b>ip-cam</b> is the external IP address of your camera.  The server will try to connect to this address. <br><br><h2>  Testing VLC Delays vs WebRTC </h2><br>  After we set up the IP camera and tested it in <b>VLC</b> , set up the server and tested the <b>RTSP</b> stream through the server with distribution via <b>WebRTC</b> , we can finally compare the delays. <br><br>  For this we will use a timer that will show on the monitor screen a split second.  We turn on the timer and play the video stream simultaneously on <b>VLC locally</b> and on the Firefox browser through a remote server. <br><br>  Ping to server <b>100 ms</b> . <br>  Ping locally <b>1 ms</b> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c41/556/1ee/c415561ee1fd4dc3917b27ec267b2dcf.png"></div><br>  The first test using the timer looks like this: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ab9/f1e/0b3/ab9f1e0b385f4bdaad4fa16dd143a5e6.png"></div><br>  On a black background is the original timer, which shows a zero delay.  On the left, <b>VLC</b> , on the right, <b>Firefox</b> , receiving a <b>WebRTC</b> stream from a remote server. <br><table><tbody><tr><td></td><td>  <strong>Zero</strong> </td><td>  <strong>VLC</strong> </td><td>  <strong>Firefox WCS</strong> </td></tr><tr><td>  Time </td><td>  50.559 </td><td>  49.791 </td><td>  50.238 </td></tr><tr><td>  <strong>Latency ms</strong> </td><td>  0 </td><td>  768 </td><td>  321 </td></tr></tbody></table>  In this test, we see a delay on <b>VLC</b> twice as much as a delay on <b>Firefox + Web Call Server</b> , despite the fact that the video in VLC is played on the local network, and the video that is displayed in Firefox passes through the server in the data center in Germany and returns back.  This discrepancy may be due to the fact that VLC works over TCP (interleaved mode) and includes some additional buffers for smooth video playback. <br><br>  We took a few snapshots to capture the delay values: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/4be/8d5/132/4be8d513247a4efebddc3c499bfd7b41.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c4c/dc4/498/c4cdc4498f0c4d5fa0692e2d1178e866.png"></div><br>  The measurement results look like this: <br><table><tbody><tr><td><strong>&nbsp;</strong></td><td>  <strong>Metric</strong> </td><td>  <strong>Zero</strong> </td><td>  <strong>VLC</strong> </td><td>  <strong>Firefox WCS</strong> </td></tr><tr><td rowspan="2">  <strong>Test1</strong> </td><td>  Time </td><td>  50.559 </td><td>  49.791 </td><td>  50.238 </td></tr><tr><td>  Latency </td><td>  0 </td><td>  <strong><font color="#CC0033">768</font></strong> </td><td>  <strong><font color="#006600">321</font></strong> </td></tr><tr><td rowspan="2">  <strong>Test2</strong> </td><td>  Time </td><td>  50.331 </td><td>  49.565 </td><td>  49.951 </td></tr><tr><td>  Latency </td><td>  0 </td><td>  <strong><font color="#CC0033">766</font></strong> </td><td>  <strong><font color="#006600">380</font></strong> </td></tr><tr><td rowspan="2">  <strong>Test3</strong> </td><td>  Time </td><td>  23.870 </td><td>  23.101 </td><td>  23.548 </td></tr><tr><td>  Latency </td><td>  0 </td><td>  <strong><font color="#CC0033">769</font></strong> </td><td>  <strong><font color="#006600">322</font></strong> </td></tr><tr><td colspan="3">  <strong>Average</strong> </td><td>  <strong><font color="#CC0033">768</font></strong> </td><td>  <strong><font color="#006600">341</font></strong> </td></tr></tbody></table>  Thus, the average delay in testing with <b>VLC on the local network</b> was <b>768 milliseconds</b> .  While the average delay in video passing through a remote server was <b>341 milliseconds</b> , i.e.  was <b>2 times lower</b> when using <b>UDP and WebRTC</b> . <br><br><h2>  Testing RTMP vs WebRTC delays </h2><br>  We will conduct similar tests with an RTMP player via a <b>Wowza server</b> and a simultaneous test with a WebRTC player via a <b>Web Call Server</b> . <br><br>  On the left we are picking up a video stream from Wowza in an RTMP connection.  On the right we collect the stream via WebRTC.  Above the absolute time (zero delay). <br><br>  Test - 1 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/0bf/84e/72a/0bf84e72aca84ade9eb430ee36e232ce.png"></div><br>  Test - 2 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ebc/aa5/2ef/ebcaa52efaa74c3399fcd725d840f9d6.png"></div><br>  Test - 3 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/61a/291/b58/61a291b5858548688a56a1bfb09bb168.png"></div><br>  Test - 4 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/029/d35/ae1/029d35ae1dd845ab8cf92d7413dda895.png"></div><br>  Test results can be displayed in a familiar table: <br><table width="624"><tbody><tr><td><strong>&nbsp;</strong></td><td>  <strong>Metric</strong> </td><td>  <strong>Zero</strong> </td><td>  <strong>RTMP</strong> </td><td>  <strong>Webrtc</strong> </td></tr><tr><td rowspan="2">  <strong>Test1</strong> </td><td>  Time </td><td>  37.277 </td><td>  35.288 </td><td>  36.836 </td></tr><tr><td>  Latency </td><td>  0 </td><td>  <strong><font color="#CC0033">1989</font></strong> </td><td>  <strong><font color="#006600">441</font></strong> </td></tr><tr><td rowspan="2">  <strong>Test2</strong> </td><td>  Time </td><td>  02.623 </td><td>  00.382 </td><td>  02.238 </td></tr><tr><td>  Latency </td><td>  0 </td><td>  <strong><font color="#CC0033">2241</font></strong> </td><td>  <strong><font color="#006600">385</font></strong> </td></tr><tr><td rowspan="2">  <strong>Test3</strong> </td><td>  Time </td><td>  29.119 </td><td>  27.966 </td><td>  28.796 </td></tr><tr><td>  Latency </td><td>  0 </td><td>  <strong><font color="#CC0033">1153</font></strong> </td><td>  <strong><font color="#006600">323</font></strong> </td></tr><tr><td rowspan="2">  <strong>Test4</strong> </td><td>  Time </td><td>  50.051 </td><td>  48.702 </td><td>  49.664 </td></tr><tr><td>  Latency </td><td></td><td>  <strong><font color="#CC0033">1349</font></strong> </td><td>  <strong><font color="#006600">387</font></strong> </td></tr><tr><td colspan="3">  <strong>Average</strong> </td><td>  <strong><font color="#CC0033">1683</font></strong> </td><td>  <strong><font color="#006600">384</font></strong> </td></tr></tbody></table><br>  Thus, the average delay when playing an <b>RTSP</b> stream in <b>Flash Player</b> via RTMP was <b>1683 milliseconds</b> .  Average WebRTC delay is <b>384 milliseconds</b> .  Those.  WebRTC was on average <b>4 times better</b> in latency. <br><br><h2>  Links </h2><br>  <a href="https://webrtc.org/">WebRTC technology</a> <br>  <a href="https://www.ietf.org/rfc/rfc2326.txt">RTSP</a> - RFC <br>  <a href="https://www.ietf.org/rfc/rfc2326.txt">RTSP interleaved</a> - RFC, 10.12 Embedded (Interleaved) Binary Data <br>  <a href="http://www.adobe.com/devnet/rtmp.html">RTMP</a> specification <br>  <a href="https://flashphoner.com/">Web Call Server</a> - WebRTC media server with RTSP support <br>  <a href="http://www.videolan.org/vlc/index.html">VLC</a> player for RTSP playback </div><p>Source: <a href="https://habr.com/ru/post/324294/">https://habr.com/ru/post/324294/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../324284/index.html">Resizing images based on content</a></li>
<li><a href="../324286/index.html">easymake - ‚Äúalmost‚Äù regular task-runner for building, testing and other tasks for node.js</a></li>
<li><a href="../324288/index.html">Development of space shooter for android using the Unity3D game engine</a></li>
<li><a href="../324290/index.html">Make your anonymizer in 10 minutes</a></li>
<li><a href="../324292/index.html">Design patterns, iOS view developer. Part 2. The Observer</a></li>
<li><a href="../324296/index.html">Again about Monty Hall or statistics as a collective intuition</a></li>
<li><a href="../324298/index.html">Experience passing certified Openstack Administrator (COA)</a></li>
<li><a href="../324300/index.html">Website creation on Yii 2 (blog, basic) - Part 1</a></li>
<li><a href="../324304/index.html">Deploying the symfony development environment for Windows</a></li>
<li><a href="../324306/index.html">The digest of interesting materials for the mobile # 195 developer (March 13-19)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>