<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hacker's guide to neural networks. Schemes of real values. Patterns in the "reverse" stream. Example "One neuron"</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content: 
 Chapter 1: Real Value Schemes  Part 1: 


 : ‚Ññ1:   
 Part 2: 


  ‚Ññ2:  
 Part 3: 


  ‚Ññ3:  
 Part 4: 


   
 Part 5: 


  ¬´¬ª " " 
 Part 6: ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hacker's guide to neural networks. Schemes of real values. Patterns in the "reverse" stream. Example "One neuron"</h1><div class="post__text post__text-html js-mediator-article">  Content: <br><div class="spoiler">  <b class="spoiler_title">Chapter 1: Real Value Schemes</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/paysto/blog/244723/">Part 1:</a> <br><pre><code class="html hljs xml">  :        ‚Ññ1:   </code> </pre> <br>  <a href="http://habrahabr.ru/company/paysto/blog/244935/">Part 2:</a> <br><pre> <code class="html hljs xml">  ‚Ññ2:  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/245051/">Part 3:</a> <br><pre> <code class="html hljs xml">  ‚Ññ3:  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/245403/">Part 4:</a> <br><pre> <code class="javascript hljs">        </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246093/">Part 5:</a> <br><pre> <code class="javascript hljs">   ¬´¬ª   <span class="hljs-string"><span class="hljs-string">" "</span></span></code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246397/">Part 6:</a> <br><pre> <code class="javascript hljs">     </code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Chapter 2: Machine Learning</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/paysto/blog/246523/">Part 7:</a> <br><pre> <code class="javascript hljs">  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246849/">Part 8:</a> <br><pre> <code class="javascript hljs">        (SVM)</code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246973/">Part 9:</a> <br><pre> <code class="javascript hljs">  SVM   </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/247033/">Part 10:</a> <br><pre> <code class="javascript hljs">   :  </code> </pre><br></div></div><br><br>  Let's look again at our example of a scheme with numbers entered.  The first diagram shows us the "raw" values, and the second - the gradients that return to their original values, as discussed earlier.  Note that the gradient always reduces to +1.  This is the standard push for the scheme in which the value should increase. <br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a0c/0d9/0b8/a0c0d90b8d9e453d9193dc60782dbb3d.PNG" alt="image"></div><br><br>  After a while, you will begin to notice patterns in how gradients are returned in a pattern.  For example, the logical element <b>+</b> always raises the gradient and simply passes it to all the original values ‚Äã‚Äã(note that in the example with -4 it was simply transferred to both the original values ‚Äã‚Äãof the logical element +).  This is because its own derivative for the original values ‚Äã‚Äãis +1, regardless of what the actual values ‚Äã‚Äãof the original data are equal to, so in the chain rule, the gradient from the top is simply multiplied by 1 and remains the same. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The same happens, for example, with the logical element max (x, y).  Since the gradient of the element max (x, y) with respect to its initial values ‚Äã‚Äãis +1 for that value of x or y, which is greater, and 0 for the second, this logical element in the process of inverse error distribution is effectively used only as a ‚Äúswitch‚Äù gradient: it takes the gradient from the top and ‚Äúdirects‚Äù it to its original value, which is higher when going back. <br><br>  <b>Numeric gradient check</b> <br><br>  Before we finish with this section, let's just make sure that the analytical gradient we calculated for the back propagation of error is correct.  Let's remember that we can do this by simply calculating a numerical gradient, and making sure we get [-4, -4, 3] for x, y, z.  Here is the code: <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   var x = -2, y = 5, z = -4; //    var h = 0.0001; var x_derivative = (forwardCircuit(x+h,y,z) - forwardCircuit(x,y,z)) / h; // -4 var y_derivative = (forwardCircuit(x,y+h,z) - forwardCircuit(x,y,z)) / h; // -4 var z_derivative = (forwardCircuit(x,y,z+h) - forwardCircuit(x,y,z)) / h; // 3</span></span></code> </pre><br><br>  <b>Example: One neuron</b> <br><br>  In the previous section, you finally understood the concept of back propagation of an error.  Let us now consider a more complex and practical example.  We consider a two-dimensional neuron that calculates the following function: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/652/d1f/efd/652d1fefdb6f4a27b98109d8859171ae.PNG" alt="image"></div><br><br>  In this expression, œÉ is a sigmoid function.  It can be described as a ‚Äúcompressing function‚Äù, since it takes the original value and compresses it so that it is between zero and one: Extremely negative values ‚Äã‚Äãare compressed towards zero, and positive values ‚Äã‚Äãare compressed towards one.  For example, we have the expression sig (-5) = 0.006, sig (0) = 0.5, sig (5) = 0.993.  Sigmoid function is defined as follows: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6b6/bec/798/6b6bec7986d04742999fdadd1d6a0df7.PNG" alt="image"></div><br><br>  The gradient with respect to its only initial value, as indicated in Wikipedia (or, if you know the calculation methods, you can calculate it yourself), looks like the following expression: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/757/9a4/1cb/7579a41cb60240d49e41a7e7b5750895.PNG" alt="image"></div><br><br>  For example, if the initial value of the sigmoid logic element is x = 3, the logical element will calculate the result of the equation f = 1.0 / (1.0 + Math.exp (-x)) = 0.95, after which the (local) gradient will have the following view: dx = (0.95) * (1 - 0.95) = 0.0475. <br><br>  That's all we need to use this logical element: we know how to take the original value and move it through the sigmoid logical element, and we also have an expression for the gradient relative to its original value, so we can also perform the inverse distribution mistakes with it.  Another point to which you should pay attention - technically, the sigmoid function consists of a whole set of logical elements arranged in a row that calculate additional atomic functions: the logical element of exponentiation, addition and division.  This attitude works fine, but for this example I decided to compress all these logical elements to one, which computes the sigmoid at a time, since the gradient expression turned out to be quite simple. <br><br>  Let's take this opportunity to carefully structure the associated code in a convenient, modular way.  To begin with, I would like to draw your attention to the fact that each line in our graphs has two numbers connected with it: <br><br>  1. The value that it has in the direct passage <br>  2. Gradient (i.e. push), which passes back along it while going back <br><br>  Let's create a simple segment structure (Unit) that will store these two values ‚Äã‚Äãalong each line.  Our logical elements will not work on top of segments: they will take them as initial values ‚Äã‚Äãand create them as output values. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//       var Unit = function(value, grad) { // ,     this.value = value; //        ,     this.grad = grad; }</span></span></code> </pre><br><br>  In addition to segments, we also need three logical elements: <b>+, * and sig</b> (sigmoid).  Let's start by applying the logical element of multiplication.  Here I use Javascript, which interestingly simulates classes using functions.  If you are not familiar with Javascript, what happens here is the definition of a class that has certain properties (accessed using the this keyword), and some methods (which are placed in the function prototype in Javascript).  Just remember them as class methods.  Also do not forget that the way we will use them is that we first send (forward) all the logical elements one by one, and then we return them back (backward) in the reverse order.  Here is the implementation of this: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> multiplyGate = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span>{ }; multiplyGate.prototype = { <span class="hljs-attr"><span class="hljs-attr">forward</span></span>: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">u0, u1</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//      u0  u1    utop this.u0 = u0; this.u1 = u1; this.utop = new Unit(u0.value * u1.value, 0.0); return this.utop; }, backward: function() { //          //  ,         //        . this.u0.grad += this.u1.value * this.utop.grad; this.u1.grad += this.u0.value * this.utop.grad; } }</span></span></code> </pre><br><br>  The multiplication logic element takes two segments, each of which contains a value, and creates a segment that stores its result.  Gradient is assigned zero as initial value.  Then note that when we call the backward function, we get the gradient from the result of the segment that we created during the front pass (which I hope will now have a filled gradient) and multiply it by the local gradient for this logical element (a chain rule! ).  This logical element performs multiplication (u0.value * u1.value) in the front pass, so we recall that the gradient with respect to u0 is equal to u1.value and with respect to u1 is equal to u0.value.  Also note that we use + = to add to the gradient with the backward function.  This may allow us to use the result of one logical element several times (imagine it as a branching line), since it turns out that the gradients along these branches are simply summed up when calculating the final gradient with respect to the result of the circuit.  The remaining two logical elements are defined in the same way: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> addGate = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span>{ }; addGate.prototype = { <span class="hljs-attr"><span class="hljs-attr">forward</span></span>: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">u0, u1</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.u0 = u0; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.u1 = u1; <span class="hljs-comment"><span class="hljs-comment">//      this.utop = new Unit(u0.value + u1.value, 0.0); return this.utop; }, backward: function() { //   .        1 this.u0.grad += 1 * this.utop.grad; this.u1.grad += 1 * this.utop.grad; } } var sigmoidGate = function() { //   this.sig = function(x) { return 1 / (1 + Math.exp(-x)); }; }; sigmoidGate.prototype = { forward: function(u0) { this.u0 = u0; this.utop = new Unit(this.sig(this.u0.value), 0.0); return this.utop; }, backward: function() { var s = this.sig(this.u0.value); this.u0.grad += (s * (1 - s)) * this.utop.grad; } }</span></span></code> </pre><br>  Note, again, that the backward function in all cases simply calculates the local derivative with respect to its initial value, after which it multiplies it by the gradient from the segment above (ie, the chain rule is valid).  To determine everything in full, let's finally write out the forward and reverse flows for our two-dimensional neuron with some approximate values: <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//    var a = new Unit(1.0, 0.0); var b = new Unit(2.0, 0.0); var c = new Unit(-3.0, 0.0); var x = new Unit(-1.0, 0.0); var y = new Unit(3.0, 0.0); //    var mulg0 = new multiplyGate(); var mulg1 = new multiplyGate(); var addg0 = new addGate(); var addg1 = new addGate(); var sg0 = new sigmoidGate(); //    var forwardNeuron = function() { ax = mulg0.forward(a, x); // a*x = -1 by = mulg1.forward(b, y); // b*y = 6 axpby = addg0.forward(ax, by); // a*x + b*y = 5 axpbypc = addg1.forward(axpby, c); // a*x + b*y + c = 2 s = sg0.forward(axpbypc); // sig(a*x + b*y + c) = 0.8808 }; forwardNeuron(); console.log('circuit output: ' + s.value); //   0.8808</span></span></code> </pre><br><br>  Now let's calculate the gradient: just repeat everything in the reverse order and call the backward function!  We recall that we saved the pointers to the segments when we were passing forward, so the logical element has access to its original values, as well as to the output segment that it had previously created. <br><br><pre> <code class="javascript hljs">s.grad = <span class="hljs-number"><span class="hljs-number">1.0</span></span>; sg0.backward(); <span class="hljs-comment"><span class="hljs-comment">//    axpbypc addg1.backward(); //    axpby  c addg0.backward(); //    ax  by mulg1.backward(); //    b  y mulg0.backward(); //    a  x</span></span></code> </pre><br><br>  Notice that the first line sets the output gradient (the most recent segment) to 1.0 to trigger the gradient chain.  This can be interpreted as a push on the last logical element with a force equal to +1.  In other words, we are pulling the whole circuit, forcing it to apply forces that will increase the output value.  If we did not set it to 1, all gradients would be calculated as zero due to multiplication according to the chain rule.  Finally, let's make the initial values ‚Äã‚Äãrespond to the calculated gradients and check that the function has increased: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> step_size = <span class="hljs-number"><span class="hljs-number">0.01</span></span>; a.value += step_size * a.grad; <span class="hljs-comment"><span class="hljs-comment">// a.grad  -0.105 b.value += step_size * b.grad; // b.grad  0.315 c.value += step_size * c.grad; // c.grad  0.105 x.value += step_size * x.grad; // x.grad  0.105 y.value += step_size * y.grad; // y.grad  0.210 forwardNeuron(); console.log('circuit output after one backprop: ' + s.value); //   0.8825</span></span></code> </pre><br><br>  Success!  0.8825 higher than the previous value, 0.8808.  Finally, let's check that we correctly did backward propagation of the error by checking the numerical gradient: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> forwardCircuitFast = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">a,b,c,x,y</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/(<span class="hljs-number"><span class="hljs-number">1</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.exp( - (a*x + b*y + c))); }; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> a = <span class="hljs-number"><span class="hljs-number">1</span></span>, b = <span class="hljs-number"><span class="hljs-number">2</span></span>, c = <span class="hljs-number"><span class="hljs-number">-3</span></span>, x = <span class="hljs-number"><span class="hljs-number">-1</span></span>, y = <span class="hljs-number"><span class="hljs-number">3</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> h = <span class="hljs-number"><span class="hljs-number">0.0001</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> a_grad = (forwardCircuitFast(a+h,b,c,x,y) - forwardCircuitFast(a,b,c,x,y))/h; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> b_grad = (forwardCircuitFast(a,b+h,c,x,y) - forwardCircuitFast(a,b,c,x,y))/h; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> c_grad = (forwardCircuitFast(a,b,c+h,x,y) - forwardCircuitFast(a,b,c,x,y))/h; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> x_grad = (forwardCircuitFast(a,b,c,x+h,y) - forwardCircuitFast(a,b,c,x,y))/h; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> y_grad = (forwardCircuitFast(a,b,c,x,y+h) - forwardCircuitFast(a,b,c,x,y))/h;</code> </pre><br><br>  Thus, all this gives the same values ‚Äã‚Äãas the gradients of the back propagation error [-0.105, 0.315, 0.105, 0.105, 0.210].  Fine! <br><br>  I hope you understand that even though we only looked at an example with one neuron, the code I gave above is a fairly simple way to calculate the gradients of arbitrary expressions (including very deep expressions).  All you need to do is write small logic elements that will calculate local simple derivatives with respect to their initial values, link them to a graph, run forward to calculate the output value, and then perform a reverse pass that will connect the gradient across path to the original value. </div><p>Source: <a href="https://habr.com/ru/post/246093/">https://habr.com/ru/post/246093/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../246077/index.html">Ruby and Postgis Time Zone Service</a></li>
<li><a href="../246081/index.html">About slow programming</a></li>
<li><a href="../246087/index.html">.NEXT in Moscow: how hardcore .NET-conference conquered the capital</a></li>
<li><a href="../246089/index.html">Creating Bluetooth profiles in the BLE TI stack</a></li>
<li><a href="../246091/index.html">Working groups in OpenCL 2.0. Heterogeneous working groups</a></li>
<li><a href="../246095/index.html">Monitoring Methods in DWDM Systems (Part 1)</a></li>
<li><a href="../246097/index.html">The problem of the "7th of January"</a></li>
<li><a href="../246099/index.html">OpenStack, Docker and Web Terminal, or how we do interactive exercises for learning Linux.</a></li>
<li><a href="../246105/index.html">Data structures: 2-3 heap (2-3 heap)</a></li>
<li><a href="../246111/index.html">Fight for ping in WoT tanks in Khabarovsk, Krasnoyarsk and Vladivostok</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>