<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Operating Systems: Three Easy Pieces. Part 5: Planning: Multi-Level Feedback Queue (translation)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction to operating systems 
 Hi, Habr! I want to bring to your attention a series of articles-translations of one interesting in my opinion lit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Operating Systems: Three Easy Pieces. Part 5: Planning: Multi-Level Feedback Queue (translation)</h1><div class="post__text post__text-html js-mediator-article"><h1>  Introduction to operating systems </h1><br>  Hi, Habr!  I want to bring to your attention a series of articles-translations of one interesting in my opinion literature - OSTEP.  This material takes a rather in-depth look at the work of unix-like operating systems, namely, working with processes, various schedulers, memory, and other similar components that make up a modern OS.  The original of all materials you can see <a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">here</a> .  Please note that the translation was made unprofessionally (fairly freely), but I hope I saved the general meaning. <br><br>  Laboratory work on this subject can be found here: <br><br><ul><li>  <a href="http://pages.cs.wisc.edu/~remzi/OSTEP/Homework/homework.html">original</a> </li><li>  <a href="https://github.com/remzi-arpacidusseau/ostep-code">original</a> </li><li>  <a href="https://github.com/bykvaadm/OS/tree/master/ostep">my personal adaptation</a> </li></ul><br>  Other parts: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  <a href="https://habr.com/en/post/446340/">Part 1: Intro</a> </li><li>  <a href="https://habr.com/en/post/446866/">Part 2: Abstraction: the process</a> </li><li>  <a href="https://habr.com/en/post/447182/">Part 3: Introduction to the Process API</a> </li><li>  <a href="https://habr.com/en/post/449026/">Part 4: Scheduler Introduction</a> </li><li>  <a href="https://habr.com/en/post/450116/">Part 5: MLFQ Scheduler</a> </li></ul><br>  And you can also look to me on the channel in the <a href="https://t.me/bykvaadm">telegram</a> =) <br><a name="habracut"></a><br><h2>  Planning: Multi-Level Feedback Queue </h2><br>  In this lecture we will talk about the problems of developing one of the most famous approaches to <br>  Planning, which is called <b>Multi-Level Feedback Queue</b> (MLFQ).  The MLFQ planner was first described in 1962 by Fernando J. Corbat√≥ in a system called the Compatible Time-Sharing System (CTSS).  These works (including later works on Multics) were subsequently presented to the Turing Award.  The planner was subsequently improved and acquired the look that can be found already in some modern systems. <br><br>  The MLFQ algorithm tries to solve 2 fundamental overlapping problems. <br>  <b>Firstly</b> , it tries to optimize the turnaround time, which, as we considered in the previous lecture, is optimized by launching the shortest tasks at the beginning of the queue.  However, the OS does not know how long this or that process will work, and this is the necessary knowledge for the operation of the SJF and STCF algorithms.  <b>Secondly</b> , MLFQ tries to make the system responsive to users (for example, for those who sit and stare at the screen while waiting for the task to complete) and thus minimize the response time.  Unfortunately, algorithms like RR reduce the response time, but extremely badly affect the turnover time metric.  Hence our problem: How to design a planner who will meet our requirements and at the same time be unaware of the nature of the process, in general?  How can the planner explore the characteristics of the tasks he runs and thus make better planning decisions? <br><br>  <u>The crux of the problem: How to plan a task without perfect knowledge?</u>  <u>How to develop a scheduler that simultaneously minimizes response time for interactive tasks and at the same time minimizes turnover time without knowing the time of task execution?</u> <br><br>  Note: we are learning from previous events <br><br>  The MLFQ lineup is an excellent example of a system that learns from past events to predict the future.  Similar approaches are often found in the OS (and many other branches in computer science, including hardware prediction branches and caching algorithms).  Such trips work when tasks have behavioral phases and are thus predictable. <br><br>  However, with such a technique one should be careful, because predictions can very easily turn out to be wrong and lead the system to making worse decisions than there would be without knowledge at all. <br><br><h3>  MLFQ: Basic Rules </h3><br>  Consider the basic rules of the MLFQ algorithm.  And although there are several implementations of this algorithm, the basic approaches are similar. <br><br>  In the implementation that we will consider, there will be several separate queues in MLFQ, each of which will have a different priority.  At any time, the task ready for execution is in the same queue.  MLFQ uses priorities to decide which task to run for execution, i.e.  the task with a higher priority (the task from the queue with the highest priority) will be launched first. <br><br>  Undoubtedly, there can be more than one task in a particular queue, so they will have the same priority.  In this case, the RR mechanism will be used to schedule the launch among these tasks. <br><br>  Thus, we arrive at two basic rules for MLFQ: <br><br><ul><li>  Rule1: If priority (A)&gt; Priority (B), task A will be launched (B will not) </li><li>  Rule2: If Priority (A) = Priority (B), A &amp; B are started using RR </li></ul><br>  Based on the above, the key elements to planning MLFQ are priorities.  Instead of assigning a fixed priority to each task, MLFQ changes its priority depending on the observed behavior. <br><br>  For example, if a task constantly quits working on the CPU while waiting for keyboard input, MLFQ will maintain the process priority at a high level, because this is how the interactive process should work.  If, on the contrary, the task is constantly and intensively using the CPU for a long period, MLFQ will lower its priority.  Thus, MLFQ will study the behavior of the processes at the time of their work and use the behavior. <br><br>  Let's draw an example of how the queues might look at some point in time and then you get something like this: <br><br><img src="https://habrastorage.org/webt/4x/ad/rr/4xadrrwfmrtn3mg-se6wgith9gm.png" alt="image"><br><br>  In this diagram, 2 processes A and B are in the queue with the highest priority.  Process C is somewhere in the middle, and process D is at the very end of the queue.  According to the MLFQ algorithm descriptions above, the scheduler will only perform tasks with the highest priority according to RR, and tasks C, D will be out of business. <br><br>  Naturally static snapshot will not give a complete picture of how MLFQ works. <br>  It is important to understand exactly how the picture changes over time. <br><br><h4>  Attempt 1: How to change priority </h4><br>  At this point, it is necessary to decide how MLFQ will change the priority level of the task (and thus the position of the task in the queue) in the course of its life cycle.  To do this, you need to keep in mind the workflow: a number of interactive tasks with a short working time (and thus frequent CPU release) and several long tasks that use the CPU all their working time, and the response time for such tasks is not important.  And so you can make the first attempt to implement the MLFQ algorithm with the following rules: <br><br><ul><li>  Rule3: When a task enters the system, it is placed in a queue with the highest </li><li>  priority. </li><li>  Rule4a: If a task uses the entire time window assigned to it, then its </li><li>  priority drops. </li><li>  Rule4b: If the Task frees the CPU before the expiration of its time window, then it </li><li>  stays with the same priority. </li></ul><br>  <b>Example 1: Single long-term task</b> <br><br>  As you can see in this example, the task for admission is set with the highest priority.  After a time window of 10ms, the process decreases in priority by the scheduler.  After the next time window, the task finally goes down to the lowest priority in the system, where it remains. <br><br><img src="https://habrastorage.org/webt/jl/wi/fg/jlwifg8osgxds9bpyftx2aoa9pa.png"><br><br>  <b>Example 2: They brought a short task</b> <br><br>  Now let's see an example of how MLFQ tries to get close to SJF.  In this example, there are two tasks: A, which is a long-playing task that constantly occupies the CPU and B, which is a short interactive task.  Suppose that A has been working for some time at the time when task B arrived. <br><br><img src="https://habrastorage.org/webt/hq/dp/ou/hqdpouigzrlqbjbhwnvgv9e8mxc.png"><br><br>  This graph shows the results of the script.  Task A, like any task using a CPU, is at the bottom.  Task B will arrive at time T = 100 and will be placed in the queue with the highest priority.  Since the time of her work is small, it will end before it reaches the last stage. <br><br>  From this example, one should understand the main goal of the algorithm: since the algorithm does not know a long task or a short one, first of all it assumes that the task is short and gives it the highest priority.  If this is a really short task, then it will be completed quickly, otherwise if it is a long task, then it will slowly move in priority down and will soon prove that it is a really long task that does not require a response. <br><br>  <b>Example 3: What about input and output?</b> <br><br>  Now let's take a look at an example with I / O.  As stated in rule 4b, if a process frees a processor without fully using its processor time, it remains at the same priority level.  The intentions of this rule are quite simple - if an interactive task performs many I / O operations, for example, expecting a user to press a key or mouse, such a task will release the processor before the allotted window.  We would not like to omit such a task by priority, and thus it will remain at the same level. <br><br><img src="https://habrastorage.org/webt/md/oa/f_/mdoaf_yf81n7xvy-j_bdo6hvbmm.png"><br><br>  This example shows how the algorithm will work with such processes ‚Äî Interactive Task B, which only needs a CPU for 1ms before executing the I / O process and Long Task A, which the CPU uses all its time. <br><br>  MLFQ keeps process B with the highest priority as it continues all the time <br>  release the CPU.  If B is an interactive task, then the algorithm in this case achieved its goal of launching interactive tasks quickly. <br><br>  <b>Problems with the current MLFQ algorithm</b> <br><br>  In the previous examples, we built the basic version of MLFQ.  And it seems that he does his job well and honestly, distributing processor time honestly between long tasks and allowing short tasks or tasks intensively addressing input and output to work quickly.  Unfortunately, this approach contains several serious problems. <br><br>  <b>First</b> , the hunger problem: if the system has a lot of interactive tasks, they will consume all the CPU time and thus no long task will be able to perform (they starve). <br><br>  <b>Secondly</b> , smart users could write their programs so that <br>  cheat the planner.  Cheating is to do something to make <br>  scheduler to issue process more CPU time.  Algorithm which <br>  described above is quite vulnerable to such attacks: before the time window is almost <br>  ran out need to perform an I / O operation (to some, no matter what file) <br>  and thus free up the CPU.  Such behavior will allow you to remain in the same <br>  queue itself and again get a larger percentage of CPU time.  If done <br>  this is correct (for example, running 99% of the window time before releasing the CPU), <br>  such a task can simply monopolize the processor. <br><br>  Finally, a program can change its behavior over time.  Those tasks <br>  who used the CPU, can become interactive.  In our example, similar <br>  tasks will not receive proper treatment from the scheduler, as others would receive <br>  (initial) interactive tasks. <br><br>  <u>Question to the audience: what attacks on the scheduler could have been made in the modern world?</u> <u><br></u> <br><h4>  Attempt 2: Raising Priority </h4><br><br>  Let's try to change the rules and see if we can avoid problems with <br>  fasting  What could we do to ensure that related <br>  CPU tasks will get their time (even if not for long). <br>  As a simple solution, you can suggest periodically <br>  increase the priority of all such tasks in the system.  There are many ways <br>  to achieve this, let's try to put something simple as an example: translate <br>  Immediately all tasks in the highest priority, hence the new rule: <br><ul><li>  <b>Rule5</b> : After a certain period S, transfer all tasks in the system to the highest queue. </li></ul><br>  Our new rule solves two problems at once.  First, the processes <br>  guaranteed not to starve: tasks in the highest queue will share <br>  CPU time according to the RR algorithm and so all processes will get <br>  CPU time  Secondly, if some process that previously used <br>  only the processor becomes interactive, then it will remain in line with the highest <br>  priority after once receiving a priority increase to the highest. <br>  Consider an example.  In this scenario, we consider one process using <br><img src="https://habrastorage.org/webt/cx/te/ll/cxtellydeep0hkgrqfiypt-zqq4.png"><br><br>  CPU and two interactive, short processes.  On the left in the figure, the figure shows behavior without increasing priority, and thus the long task begins to starve after arriving at the system of two interactive tasks.  In the figure on the right, every 50ms priority increase is performed and thus all processes are guaranteed to get CPU time and will be periodically started.  50ms in this case is taken as an example, actually this number is somewhat higher. <br>  Obviously, adding the time of a periodic increase in S leads to <br>  natural question: what value should be set?  One of the honored <br>  system engineers John Ousterhout called similar values ‚Äã‚Äãin systems like voo-doo <br>  constant as they in some way demanded black magic for the correct <br>  exhibiting.  And unfortunately S has that kind of flavor.  If you set the value too <br>  big - long tasks will starve.  And if you set the value too low, <br>  interactive tasks will not get the proper CPU time. <br><br><h4>  Attempt 3: Better Accounting </h4><br><br>  Now we have another problem that needs to be solved: how not <br>  let our planner fool?  The blame for this opportunity is <br>  rules 4a, 4b, which allow the task to maintain priority, freeing the processor <br>  before the expiration of the allotted time.  How to cope with it? <br>  The solution in this case can be considered the best accounting of CPU time on each <br>  MLFQ level.  Instead of forgetting the time the program used <br>  processor for the allotted period, should be considered and save it.  After <br>  the process has spent its allotted time should lower it to the next <br>  priority level.  Now it doesn't matter how the process will use its time - how <br>  constantly computing on the processor or as a multitude of calls.  In this way, <br>  Rule 4 should be rewritten as follows: <br><br><ul><li>  <b>Rule4</b> : After a task has spent its allotted time in the current queue (no matter how many times it has released the CPU), the priority of such a task decreases (it moves down the queue). </li></ul><br>  Let's look at an example: <br><img src="https://habrastorage.org/webt/je/rs/kw/jerskwy36cewrg6auapm-dal7iu.png">  " <br><br>  The figure shows what happens if you try to trick the scheduler as <br>  if it were with the previous rules 4a, 4b, the result will be left.  With new <br>  the rule is the result on the right.  Prior to protection, any process could cause I / O to complete and <br>  thus dominate the CPU, after enabling protection, regardless of the behavior <br>  I / O, it will still go down in the queue anyway and thus can not unfairly <br>  take possession of CPU resources. <br><br><h4>  Improving MLFQ and other problems </h4><br>  With the above improvements, new problems arise: one of the main <br>  questions - how to parameterize a similar scheduler?  Those.  How much should be <br>  queues?  What should be the window size of the program within the queue?  how <br>  program priority should often be increased in order to avoid starvation and <br>  take into account the change in the behavior of the program?  To these questions, there is no simple <br>  response and only experiments with loads and subsequent configuration <br>  a planner can lead to some kind of satisfactory balance. <br><br>  For example, most MLFQ implementations allow you to assign different <br>  time intervals to different queues.  High priority queues usually <br>  assigned short intervals.  These queues consist of interactive tasks, <br>  switching between them is quite sensitive and should take 10 or less <br>  ms  In contrast, low-priority queues consist of long tasks that use <br>  CPU.  And in this case, long time intervals fit very well (100ms). <br><img src="https://habrastorage.org/webt/p4/1j/-d/p41j-d9spzwfok9w7xmkcewqgrq.png"><br><br>  In this example, there are 2 tasks that have worked in the high-priority queue 20 <br>  ms, broken into windows for 10ms.  40ms in the middle queue (window in 20ms) and in the low-priority <br>  The queue time window has become 40ms, where the tasks have completed their work. <br><br>  Implementing MLFQ in the Solaris OS is a class of time-sharing planners. <br>  The scheduler provides a set of tables that define exactly how it should <br>  change the priority of the process over the course of its life, what should be the size <br>  allocated window and how often you need to raise the priorities of the task.  Administrator <br>  systems can interact with this table and force the scheduler to behave <br>  differently.  The default for this table is 60 queues with a gradual increase <br>  window size from 20ms (high priority) to several hundred ms (lowest priority), and <br>  also with a boost of all tasks once a second. <br><br>  Other MLFQ planners do not use a table or any specific <br>  the rules that are described in this lecture, on the contrary, they calculate priorities using <br>  mathematical formulas.  For example, the scheduler in FreeBSD uses the formula to <br>  calculating the current priority of the task, based on how much process <br>  used the CPU.  In addition, CPU utilization decays over time, and so <br>  This way, the priority is raised somewhat differently than described above.  This is true <br>  called decay algorithms.  Since version 7.1, FreeBSD uses the ULE scheduler. <br><br>  Finally, many planners have other features.  For example, some <br>  planners reserve higher levels for the operating system and such <br>  Thus, no user process will be able to get the highest priority in <br>  the system.  Some systems allow you to give advice to help. <br>  Scheduler correctly set priorities.  So for example, using the <b>nice</b> command <br>  You can increase or decrease the priority of the task and thus increase or decrease <br>  reduce the chances of the program for processor time. <br><h3>  MLFQ: Results </h3><br>  We have described a planning approach called MLFQ.  His name <br>  concluded in the principle of operation - it has several queues and uses feedback <br>  to prioritize the task. <br>  The final rules will be as follows: <br><ul><li>  <b>Rule1</b> : If priority (A)&gt; Priority (B), task A will be launched (B will not) </li><li>  <b>Rule2</b> : If Priority (A) = Priority (B), A &amp; B are started using RR </li><li>  <b>Rule3</b> : When a task enters the system, it is placed in the queue with the highest priority. </li><li>  <b>Rule4</b> : After a task has spent its allotted time in the current queue (no matter how many times it has released the CPU), the priority of such a task decreases (it moves down the queue). </li><li>  <b>Rule5</b> : After a certain period S, transfer all tasks in the system to the highest queue. </li></ul><br>  MLFQ is interesting for the following reason - instead of requiring knowledge of <br>  the nature of the problem in advance; the algorithm studies the past behavior of the task and exposes <br>  priorities are appropriate.  Thus, he tries to sit at once on two chairs - to achieve performance for small tasks (SJF, STCF) and honestly run long, <br>  CPU-loading jobs.  Therefore, many systems, including BSD and their derivatives, <br>  Solaris, Windows, Mac use some form of algorithm as a scheduler. <br>  MLFQ as a base. <br><h4>  Additional materials: </h4><br><ol><li>  <a href="https://manpages.debian.org/stretch/manpages/sched.7.en.html">manpages.debian.org/stretch/manpages/sched.7.en.html</a> </li><li>  <a href="https://en.wikipedia.org/wiki/Scheduling_">en.wikipedia.org/wiki/Scheduling_</a> (computing) </li><li>  <a href="https://pages.lip6.fr/Julia.Lawall/atc18-bouron.pdf">pages.lip6.fr/Julia.Lawall/atc18-bouron.pdf</a> </li><li>  <a href="https://www.usenix.org/legacy/event/bsdcon03/tech/full_papers/roberson/roberson.pdf">www.usenix.org/legacy/event/bsdcon03/tech/full_papers/roberson/roberson.pdf</a> </li><li>  <a href="https://chebykin.org/freebsd-process-scheduling">chebykin.org/freebsd-process-scheduling</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/450116/">https://habr.com/ru/post/450116/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../450104/index.html">Very difficult and very interesting: IT-communities on TechTrain</a></li>
<li><a href="../450106/index.html">The project of the organization of construction and reconstruction in cramped conditions in SPDS Construction site</a></li>
<li><a href="../450110/index.html">Design patents: part two (examples from Microsoft, Snapchat, Samsung, Netflix, Airbnb, Tinder)</a></li>
<li><a href="../450112/index.html">Eh, what happened to the suitcases? On the example of a children's suitcase-scooter ZINC</a></li>
<li><a href="../450114/index.html">That we implemented in EWM thanks to your advice</a></li>
<li><a href="../450118/index.html">Stream the screen to multiple devices over the network</a></li>
<li><a href="../450122/index.html">Startup Digest: Genetics (January - March 2019)</a></li>
<li><a href="../450124/index.html">Set up the Strava heatmap layer in OsmAnd</a></li>
<li><a href="../450126/index.html">Backdoor and Buhtrap encoder distributed using Yandex.Direct</a></li>
<li><a href="../450128/index.html">Using Minolta AF optics (Sony A-mount) on modern mirrorless Sony cameras</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>