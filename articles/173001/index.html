<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Does every kernel really have its ‚Äúown‚Äù cache of the first and second levels?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Modern Core i7 processors have an obvious, documented, but for some reason not very well-known, even among many specialists, scenario priority inversi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Does every kernel really have its ‚Äúown‚Äù cache of the first and second levels?</h1><div class="post__text post__text-html js-mediator-article">  Modern Core i7 processors have an obvious, documented, but for some reason not very well-known, even among many specialists, scenario priority inversion.  I will describe it in this post.  It has C code, three diagrams, and some details of how caches work in Core i7 processors.  No cover is not broken, all information has long been publicly available. <br><br>  <a href="http://en.wikipedia.org/wiki/Priority_inversion">Priority inversion</a> is a situation where a low priority process can block or slow down a high priority.  Usually we mean the sequence of access to execution on the core for a high-priority code with respect to a low-priority one.  The core of the OS should do quite well with this.  However, in addition to computational cores, which are easy to distribute through affinity and MSI-X, there are resources in the processor that are common to all tasks - a memory controller, QPI, a shared third-level cache, and a PCIe device.  I will not go into PCIe issues, since  I am not an expert in this topic.  Priority inversion on the basis of memory access and QPI I have not seen for a long time - the bandwidth of a modern multi-channel controller is usually enough for both high-priority and low-priority tasks.  I will stop on caches. <br><a name="habracut"></a><br>  Consider a diagram with caches in the processors of the Core i7 architecture of the third generation.  However, it does not even matter which generation. <br><img src="https://habrastorage.org/getpro/habr/post_images/a2d/59b/365/a2d59b3659a83a3b377f92cb27091e9e.jpg" alt="image"><br>  At this rather high level of abstraction, the difference between Nehalem, Westmere, Sandy Bridge, Ivy Bridge and Haswell is not noticeable.  By the way, the most detailed description of how everything is arranged inside Sandy Bridge can be found in the <a href="http://www.edn.com/design/systems-design/4399725/1/Memory-Hierarchy-Design---Part-6--The-Intel-Core-i7">article by</a> Hennessey (yes, that one). <br><br>  We see that the third-level cache (LLC), the largest, simultaneously serves all cores ‚Äî both those that ‚Äúmold‚Äù are low-priority processes, and those that receive external device interrupts or a local APIC timer, which should be process and produce results faster.  Eviction policy cache last level - some approximation to the <a href="http://en.wikipedia.org/wiki/Cache_algorithms">LRU</a> .  Consequently, the more and the more often a certain kernel uses the cache, the more LLC will get it.  Priorities?  What are the priorities ??  By the way, not very important tasks are very often not programmed as carefully as high-priority ones, and therefore require a lot of memory and cache.  A high-priority task often waits for an external event, while its data and code are pushed out of the LLC.  I have already <a href="http://habrahabr.ru/company/intel/blog/117760/">written</a> about this once, but in the comments to that post I incorrectly answered the question about the exclusivity of the L1 / L2 cache. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      If you look at the diagram above, it seems that each kernel has its ‚Äúown‚Äù cache, at least 256 kilobytes in size.  More than enough for many realtime .text and .data tasks.  Well, at least you can always count on the storage of 32kb data + 32kb code in the cache with a response time of several cycles?  It is easy to check. <br><br>  Disable hypertreaming and power management.  I run the following microbenchmark: <br><br>  <b>Helper functions</b> <pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> POOL_SIZE_L1D_LINES 512 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> POOL_SIZE_L2_LINES 8192 </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// This can differ on your CPU. Check with CPUID or some system diagnostics tool #define POOL_SIZE_LLC_LINES 6*1024*1024/64 // Yes, I waste 3/4 of space for the sake of test simplicity // 1 cache line == 1 linked list item. // Pointer length is hard coded to 8 bytes (Intel 64) struct list_item { unsigned long long int tick; list_item *next; unsigned char padding[48]; }; // Build a linked list of size N with pseudo-random pattern void build_list(list_item *head, int N, int A, int B) { int C = B; list_item *current = head; for (int i = 0; i &lt; N - 1; i++) { current-&gt;tick = 0; C = (A*C + B) % N; current-&gt;next = (list_item*)&amp;(head[C]); current = current-&gt;next; } } // Touch first N elements in a linked list void warmup_list(list_item* current, int N) { bool write = (N &gt; POOL_SIZE_L2_LINES) ? true : false; for(int i = 0; i &lt; N - 1; i++) { current = current-&gt;next; //No write is needed to keep a line in L1,but looks like it is needed to keep it in L2! if (write) current-&gt;tick++; // FIXME AK: to check on HSW } }</span></span></span></span></code> </pre> <br>  The build_list initializes the list so that the prefetcher cannot find the regular access pattern.  At the same time, the entire list is in the cache, in that level where it fits. <br><br>  Now on kernel number 2, we run a list traversal, and measure how much time it takes on average for each iteration. <br><br>  <b>Linked list traversal speed measurements</b> <pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">measure</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(list_item* head, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> N)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> __int64 i1, i2, avg = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; <span class="hljs-number"><span class="hljs-number">50</span></span>; j++) { list_item* current = head; <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> WARMUP_ON while(in_copy) warmup_list(head, N); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> while(in_copy) spin_sleep(1); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span><span class="hljs-meta"> i1 = __rdtsc(); for(int i = 0; i </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt; N; i++) { current-&gt;tick++; current = current-&gt;next; } i2 = __rdtsc(); avg += (i2-i1)/50; in_copy = true; } printf("%i\n", avg/N); }</span></span></span></span></code> </pre><br><br>  The code of the flow measuring the passage time through lists of various sizes will be like this: <br><br>  <b>Measurements for different linked list sizes</b> <pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// We initialize the linked list only once, and make it big enough to make sure // we do not observe effects of spatial locality but only effects of temporal locality // Magic numbers 509, 509 &lt;= Hull-Dobell Theorem criteria build_list(head, POOL_SIZE_LLC_LINES*2, 509, 509); for (int i = 10; i &lt; POOL_SIZE_L1D_LINES; i+=5) { warmup(head, i); measure(head, i); }; for (int i = POOL_SIZE_L1D_LINES; i &lt; POOL_SIZE_L2_LINES; i+=50) { warmup(head, i); measure(head, i); }; for (int i = POOL_SIZE_L2_LINES; i &lt; POOL_SIZE_LLC_LINES*2; i+=1000) { warmup(head, i); measure(head, i); };</span></span></code> </pre><br><br>  Add a second thread, clogging the third level cache: let it spin on the core number 3, and copy 18MB of data back and forth.  18 MB - for sure to score LLC.  Let it be synchronized with the first thread so that almost at any moment in time only one of them is actively working with the cache.  (I am aware that the implementation of the spinlock is wrong and inefficient, and everything works only due to suitable timing.) <br><br>  <b>A thread that runs on another core and consumes LLC</b> <pre> <code class="cpp hljs">list_item *area1 = (list_item *)<span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(POOL_SIZE_LLC_LINES*<span class="hljs-number"><span class="hljs-number">64</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>); list_item *area2 = (list_item *)<span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(POOL_SIZE_LLC_LINES*<span class="hljs-number"><span class="hljs-number">64</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(!in_copy) spin_sleep(<span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> DISRUPT_ON memcpy(area1, area2, POOL_SIZE_LLC_LINES*64*3); memcpy(area2, area1, POOL_SIZE_LLC_LINES*64*3); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> spin_sleep(10); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span><span class="hljs-meta"> in_copy = false; };</span></span></code> </pre><br><br>  We will conduct three types of measurements: <br><img src="https://habrastorage.org/getpro/habr/post_images/668/b91/c1d/668b91c1d8db35565c16116aad95f719.jpg" alt="image"><br><ul><li>  Baseline, the "red" test, shows the speed of traversing the list in favorable conditions - the second thread does not use the cache. </li><li>  The bad option, the ‚Äúblue‚Äù test, shows what happens if the second stream has time to pick up the entire LLC volume, while the first stream is hanging in the spinlock. </li><li>  Finally, the ‚Äúgreen‚Äù test shows what happens if the first stream, while waiting, periodically reads its data. </li></ul><br>  For control, I also ran a test in which the data of the pest stream fit into its ‚Äúown‚Äù L2.  As expected, in this case there was no effect on the speed of traversing the list by the first thread.  (The conflict missies could theoretically be seen, but I did not observe them) <br><br>  Here are the measurement results: <br><img src="https://habrastorage.org/getpro/habr/post_images/39a/1d6/fd1/39a1d6fd15e201c8ffb968c6bb3b1240.jpg" alt="image"><br>  Horizontal - the number of items in the list.  Vertically - CPU cycles spent on traversing a single element.  Interestingly, to get the ‚Äústeps‚Äù (a graph that shows the boundaries of the caches) you only need to slightly change the benchmark, adding a bit of spatial locality. <br><br>  For comparison, on the computer on which I drove this test, the access times to the elements of the memory hierarchy are as follows: <br><ul><li>  L1D hit = 4 cycles </li><li>  L2 hit = 11 cycles </li><li>  LLC hit = 31 cycle </li><li>  DRAM hit = ~ 100 cycles </li></ul><br>  The time spent on one move through the list is proportional to <br>  L1D_hit * P (L1D_hit) + L2_hit * P (L2_hit) + LLC_hit * P (LLC_hit) + DRAM_hit * P (DRAM_hit), where P is the probability of finding the next element of the list at a given cache level.  Those. <br>  P (L1D_hit) + P (L2_hit) + P (LLC_hit) + P (DRAM_hit) = 1 <br>  The specific probability distribution depends on the size of the list relative to the caches, and can be measured using Vtune, oprofile or Linux perf.  For example, here is the measurement of probabilities with Vtune for a fixed list length of 16384 items (512 kilobytes). <br><table border="1" cellpadding="3" cellspacing="3"><tbody><tr><td></td><td>  <font color="red">undisturbed</font> </td><td>  <font color="blue">disturbed</font> </td><td>  <font color="green">warmup</font> </td></tr><tr><td>  L1 hit% </td><td>  0.08 </td><td>  0 </td><td>  63 </td></tr><tr><td>  L2 hit% </td><td>  72 </td><td>  0.07 </td><td>  0.1 </td></tr><tr><td>  LLC hit% </td><td>  25 </td><td>  2.6 </td><td>  22 </td></tr><tr><td>  DRAM hit% </td><td>  3 </td><td>  97 </td><td>  15 </td></tr><tr><td>  DTLB miss% </td><td>  21 </td><td>  66 </td><td>  37 </td></tr></tbody></table>  Vtune confirms that the difference in performance between the "blue" and "green" options lies in the proportion of misses on the caches of different levels caused by the transition to the next item in the list.  It can be seen that <b>if the data of the high-priority flow were pushed out of the third-level cache, they are automatically invalidated in the first and second level caches of the corresponding core</b> .  However, the figures of the measured probabilities themselves were unexpected for me.  There are no surprises in the ‚Äúblue‚Äù column, and in the red one I expected more hits in L1, and in the ‚Äúgreen‚Äù one - much more hits in L2.  However, the latter partly explains the incomprehensible peak on the green graph in the region of 16k list elements. <br><br>  If the first thread woke up via an interrupt, in the ‚Äúblue‚Äù version even the IDT and the ISR code would have to be dragged out of memory for it, since it would have already been pushed out of L1I, L2, and LLC.  To my great regret, modern processors of the Core i7 architecture do not have the ability to ‚Äúlock‚Äù a part of LLC for exclusive use by a specific core.  Therefore, the only way to avoid deleting important data from LLC, and, as a result, from L2 and L1, is to update them periodically, even if they are not needed at the moment. <br><br>  In this post I don‚Äôt want to say at all that I have found some problem in the architecture of the Core i7.  Such an organization of the work of the cache (more resources are received by the one who needs more) in the general case (desktop, most server loads) improves performance.  The priority inversion case described above may occur in a narrow class of tasks, usually associated with real-time systems.  Also, prefetcher usually should help.  They do not cope with this test just because I located pointers at pseudo-random addresses. <br><br>  Whew!  It seems that I just wrote a large text, the essence of which could be posted in tweet: ‚ÄúWhen I download it, I‚Äôm not sure what I‚Äôm looking for.  So warm up  " </div><p>Source: <a href="https://habr.com/ru/post/173001/">https://habr.com/ru/post/173001/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../172993/index.html">Jobs movie release postponed indefinitely</a></li>
<li><a href="../172999/index.html">What can threaten the dot at the end of the domain name</a></li>
<li><a href="../173/index.html">Friedman will manage Reiman's money ??</a></li>
<li><a href="../1730/index.html">Koreans accuse Google of patent infringement</a></li>
<li><a href="../17300/index.html">JavaScript: creating DOM fragments</a></li>
<li><a href="../173003/index.html">Each of us is a little auto mechanic. Or about handbooks</a></li>
<li><a href="../173007/index.html">Smart home: protection against water leaks, the system Aquastorozh</a></li>
<li><a href="../173009/index.html">Geoportal "Voice of the People"</a></li>
<li><a href="../17301/index.html">Sharkoon HDD Docking Station</a></li>
<li><a href="../173011/index.html">The answer service for Formspring closes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>