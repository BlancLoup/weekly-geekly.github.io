<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we repaired compaction in Cassandra for a week</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The main repository of metrics in our country is cassandra, we have been using it for more than three years. For all previous problems, we successfull...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we repaired compaction in Cassandra for a week</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/e81/f9e/22e/e81f9e22e7094c13add85d41f8c3c6cc.jpg" align="left" width="350">  The main repository of metrics in our country is cassandra, we have been using it for more than three years.  For all previous problems, we successfully found a solution using the built-in diagnostic tools for Cassandra. </p><br><p>  The cassandra has quite informative logging (especially at the level of DEBUG, which can be enabled on the fly), detailed metrics available via JMX and a rich set of utilities (nodetool, sstable *). </p><br><p>  But recently we ran into one rather interesting problem, and we had to seriously think and read the source code of Cassandra to figure out what was going on. </p><a name="habracut"></a><br><p>  It all started with the fact that the response time of Cassandra to reading on one of the tables began to grow: <br><br><img src="https://habrastorage.org/files/6dc/49c/e9d/6dc49ce9d34b4eb18b50441c39329a2a.png" width="600"><br></p><br><p>  In this case, the logs were empty, there were no background processes (compactions).  We quickly noticed that the number of <a href="https://docs.datastax.com/en/glossary/doc/glossary/gloss_sstable.html">SSTables</a> in the <strong>bunches</strong> table is <strong>growing</strong> (there we store the values ‚Äã‚Äãof our clients' metrics): <br><br><img src="https://habrastorage.org/files/56e/917/d1d/56e917d1da6e45b88dcb7c1a6128460c.png" width="600"><br></p><br><p>  Moreover, this happens only on three servers out of 9: </p><br><p><img src="https://habrastorage.org/files/68b/0e9/205/68b0e920572d456e87088e45a350d8ad.png" width="600"><br></p><br><p>  Then we stupid for a long time, googled and read <a href="https://issues.apache.org/jira/browse/CASSANDRA/%3FselectedTab%3Dcom.atlassian.jira.jira-projects-plugin:summary-panel">JIRA</a> , but there were no similar bugs.  But as time went on, it was necessary to find at least a temporary solution, since the response time grew almost linearly.  It was decided to force the compaction of the bunches table, but since it is not obvious from the documentation, on one or all of the nodes, compaction will start at <strong>nodetool compact</strong> , we initiated this process via JMX. </p><br><p> <em>The fact is that we have already learned from bitter experience that changing the compaction strategy through the <code>ALTER TABLE</code> fraught with launching a full compactiton simultaneously on all the nodes of the cluster.</em>  <em>Then there was a <a href="https://blog.alteroot.org/articles/2015-04-20/change-cassandra-compaction-strategy-on-production-cluster.html">way</a> to make it more manageable.</em> </p><br><p>  This time it turned out that <strong>nodetool compact</strong> starts compaction only on the node with which we work. </p><br><p>  After compaction has ended, the number of sstable has decreased, but immediately began to grow again: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/ed0/b3a/054/ed0b3a054b004992929ce240ab1bc072.png" width="600"><br></p><br><p>  Thus, we have a crutch that allows us to keep the performance of cassandra at an acceptable level in manual mode.  We set compaction to cron on problem nodes, and the response time for reading began to look like this: </p><br><p><br><img src="https://habrastorage.org/files/aee/d4b/baf/aeed4bbafc004191a237c01a1fdf1384.png" width="600"><br></p><br><p>  At the moment we are using cassandra 2.1.15, but JIRA found several similar bugs fixed in version 2.2+. </p><br><p>  Since there were no good ideas at that time, we decided to upgrade one of the problematic nodes to 2.2 (the more so we were going to do it anyway and our application was already tested with 2.2).  The update went smoothly, but it did not solve our problem. </p><br><p>  In order not to introduce additional entropy into the current situation, we decided not to update the entire cluster and return to 2.1 (this is done by removing the node from the cluster and returning it with the old version). </p><br><p>  It became clear that with a swoop this problem can not be solved and it's time to go read the code of Cassandra.  Since we ultimately store timeseries in this table, we use <a href="http://www.datastax.com/dev/blog/datetieredcompactionstrategy">DateTieredCompactionStrategy</a> with the following settings: </p><br><pre> <code class="hljs 1c">{ 'class': 'org.apache.cassandra.db.compaction.DateTieredCompactionStrategy', 'base_time_seconds': '<span class="hljs-number"><span class="hljs-number">1440</span></span>0', 'max_sstable_age_days': '90' }</code> </pre> <br><p>  This allows for our case to ensure that data for the same time interval lies side by side and does not mix with the old data.  At the same time, data older than 90 days should not be compacted at all, this will eliminate unnecessary load on the disks, since these data will not exactly change. </p><br><p>  There is a hypothesis: what if our sstable is not compact, because Cassandra thinks that they are older than 90 days? </p><br><p>  The time on which Cassandra relies is an internal timestamp that every column must have.  Cassandra either puts down the current timestamp when writing data, or it can be set by the client: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">table</span></span> (fld1, fld2) <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (val1, val2) <span class="hljs-keyword"><span class="hljs-keyword">USING</span></span> <span class="hljs-built_in"><span class="hljs-built_in">TIMESTAMP</span></span> <span class="hljs-number"><span class="hljs-number">123456789</span></span>;</code> </pre> <br><p>  (we do not use this feature). </p><br><p>  When checking the metadata of all sstable with the sstablemetadata utility, we found the anomalous timestamp value: </p><br><pre> <code class="hljs erlang-repl">$ sstablemetadata /mnt/ssd1/cassandra/okmeter/bunches-<span class="hljs-number"><span class="hljs-number">3</span></span>f892060ef5811e5950a476750300bfc/okmeter-bunches-ka-<span class="hljs-number"><span class="hljs-number">377</span></span>-Data.db |head SSTable: /mnt/ssd1/cassandra/okmeter/bunches-<span class="hljs-number"><span class="hljs-number">3</span></span>f892060ef5811e5950a476750300bfc/okmeter-bunches-ka-<span class="hljs-number"><span class="hljs-number">377</span></span> Partitioner: org.apache.cassandra.dht.RandomPartitioner Bloom Filter FP chance: <span class="hljs-number"><span class="hljs-number">0.010000</span></span> Minimum timestamp: <span class="hljs-number"><span class="hljs-number">1458916698801023</span></span> Maximum timestamp: <span class="hljs-number"><span class="hljs-number">5760529710388872447</span></span></code> </pre> <br><p>  But the newly created sstable had absolutely normal timestamps, why aren't they compact?  The <a href="">code</a> found this: </p><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">/** * Gets the timestamp that DateTieredCompactionStrategy considers to be the "current time". * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> the maximum timestamp across all SSTables. * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@throws</span></span></span><span class="hljs-comment"> java.util.NoSuchElementException if there are no SSTables. */</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">long</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getNow</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Collections.max(cfs.getSSTables(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Comparator&lt;SSTableReader&gt;() { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compare</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SSTableReader o1, SSTableReader o2)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Long.compare(o1.getMaxTimestamp(), o2.getMaxTimestamp()); } }).getMaxTimestamp(); }</code> </pre> <br><p>  Now in our case: </p><br><pre> <code class="hljs pgsql">$ <span class="hljs-type"><span class="hljs-type">date</span></span> -d @<span class="hljs-number"><span class="hljs-number">5760529710388</span></span> Sat <span class="hljs-type"><span class="hljs-type">Dec</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">46</span></span>:<span class="hljs-number"><span class="hljs-number">28</span></span> MSK <span class="hljs-number"><span class="hljs-number">184513</span></span></code> </pre> <br><p>  That is, another 182 thousand years, you can not even hope for compaction :) </p><br><p>  On each of the three problem servers there was one ‚Äúbroken‚Äù sstable of sufficiently large size (60Gb, 160Gb and 180Gb).  The most "small" of them was moved to the side, then through <strong>sstable2json</strong> they got a human-readable file of 125Gb in size and began to grep it.  It turned out that there is one broken column (a secondary metric of one test project) that can be safely removed. </p><br><p>  There was no standard way to remove data from sstable from cassandra, but the <a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsSSTableScrub_t.html">sstablescrub</a> utility is very close in meaning.  Looking at <a href="">Scrubber.java</a> , it became clear that he does not read the timestamp and it is quite difficult to make a beautiful patch, we made it ugly: </p><br><pre> <code class="diff hljs"><span class="hljs-comment"><span class="hljs-comment">--- a/src/java/org/apache/cassandra/db/compaction/Scrubber.java +++ b/src/java/org/apache/cassandra/db/compaction/Scrubber.java @@ -225,6 +225,11 @@ public class Scrubber implements Closeable if (indexFile != null &amp;&amp; dataSize != dataSizeFromIndex) outputHandler.warn(String.format("Data file row size %d different from index file row size %d", dataSize, dataSizeFromIndex)); + if (sstable.metadata.getKeyValidator().getString(key.getKey()).equals("226;4;eJlZUXr078;1472083200")) { + outputHandler.warn(String.format("key: %s", sstable.metadata.getKeyValidator().getString(key.getKey()))); + throw new IOError(new IOException("Broken column timestamp")); + } + if (tryAppend(prevKey, key, dataSize, writer)) prevKey = key; }</span></span></code> </pre> <br><p>  where <strong>226; 4; eJlZUXr078; 1472083200 is the</strong> key of the bat record, which we know as a result of the exercises with sstable2json. </p><br><p>  And it worked! <br>  Separately pleased that <strong>sstablescrub</strong> works very quickly, almost at the speed of writing to disk.  Since sstable is an immutable structure, any modifications create a new sstable, that is, for scrub, you need to provide enough free space on the disks.  For us, this turned out to be a problem, we had to do scrub on another server and copy the cleaned sstable back to the right server. </p><br><p>  After stripping the broken record, our table began to compact itself. </p><br><p>  But on one node we noticed that one fairly weighty sstable (with itself) with a size larger than 100Gb is constantly compacted: </p><br><pre> <code class="hljs pgsql">CompactionTask.java:<span class="hljs-number"><span class="hljs-number">274</span></span> - Compacted <span class="hljs-number"><span class="hljs-number">1</span></span> sstables <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> [/mnt/ssd1/cassandra/okmeter/bunches<span class="hljs-number"><span class="hljs-number">-3</span></span>f892060ef5811e5950a476750300bfc/okmeter-bunches-ka<span class="hljs-number"><span class="hljs-number">-5322</span></span>,]. <span class="hljs-number"><span class="hljs-number">116</span></span>,<span class="hljs-number"><span class="hljs-number">660</span></span>,<span class="hljs-number"><span class="hljs-number">699</span></span>,<span class="hljs-number"><span class="hljs-number">171</span></span> bytes <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">116</span></span>,<span class="hljs-number"><span class="hljs-number">660</span></span>,<span class="hljs-number"><span class="hljs-number">699</span></span>,<span class="hljs-number"><span class="hljs-number">171</span></span> (~<span class="hljs-number"><span class="hljs-number">100</span></span>% <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> original) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">653</span></span>,<span class="hljs-number"><span class="hljs-number">864</span></span>ms = <span class="hljs-number"><span class="hljs-number">30.448947</span></span>MB/s. <span class="hljs-number"><span class="hljs-number">287</span></span>,<span class="hljs-number"><span class="hljs-number">450</span></span> total partitions merged <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">287</span></span>,<span class="hljs-number"><span class="hljs-number">450.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Partition</span></span> merge counts were {<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">287450</span></span>, }</code> </pre> <br><p>  As soon as the process ended, she began to compact herself again, for example, the graph of reading operations on disks looked like this: <br><br><img src="https://habrastorage.org/files/624/26c/274/62426c274b0c4a108f05ecad3da7e9c7.png" width="600"><br></p><br><p>  Here you can see how this file migrated from ssd1 to ssd2 and back. </p><br><p>  There was also a mistake in the log about the lack of space: </p><br><pre> <code class="hljs 1c">CompactionTask.java:<span class="hljs-number"><span class="hljs-number">87</span></span> - insufficient space to compact all requested files SSTableReader(path='/mnt/ssd2/cassandra/okmeter/bunches-3f<span class="hljs-number"><span class="hljs-number">892060</span></span>ef<span class="hljs-number"><span class="hljs-number">5811</span></span>e<span class="hljs-number"><span class="hljs-number">5950</span></span>a<span class="hljs-number"><span class="hljs-number">47675030</span></span>0bfc/okmeter-bunches-ka-<span class="hljs-number"><span class="hljs-number">2135</span></span>-Data.db'), STableReader(path='/mnt/ssd1/cassandra/okmeter/bunches-3f<span class="hljs-number"><span class="hljs-number">892060</span></span>ef<span class="hljs-number"><span class="hljs-number">5811</span></span>e<span class="hljs-number"><span class="hljs-number">5950</span></span>a<span class="hljs-number"><span class="hljs-number">47675030</span></span>0bfc/okmeter-bunches-ka-<span class="hljs-number"><span class="hljs-number">5322</span></span>-Data.db')</code> </pre> <br><p>  But why even compact 1 sstable?  I had to figure out how sstable is generally selected for compaction in the DateTieredCompactionStrategy: </p><br><ul><li>  It takes a list of all sstable for the current table; </li><li>  Sstable participating in compaction right now are excluded; </li><li>  Sstables that have a maximum timestamp older than max_sstable_age_days are excluded; </li><li>  The rest are grouped by minimum timestamp, starting with the freshest.  In each of these groups, candidates are selected according to <a href="https://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html">SizeTieredCompactionStrategy</a> , and for the first interval (base_time_seconds) a minimum of <strong>min_threshold</strong> (in our case, 4) files is required, and for older ones, two are sufficient.  If there are no candidates within the group, the group is skipped.  For one pass, one of the ‚Äúyoungest‚Äù groups is selected for compaction; </li><li>  For the selected sstable group for compaction, the size of the resulting file is predicted (just the sum of all source files), if there is no free space in any <a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html">data_file_directories</a> , the largest file is excluded from the group; </li><li>  If at least 1 file is left in the group, compaction is started; </li></ul><br><p>  At the log level of DEBUG, it became clear that in our case: </p><br><ul><li>  The group on compaction from 3 files turned out </li><li>  SizeTieredCompactionStrategy has chosen to merge 2 files out of 3 </li><li>  Because of the lack of space, there was 1 candidate left, he was compacting around </li></ul><br><p>  I do not venture to judge this bug or feature (maybe when using TTL there is a need to compact 1 file), but we needed to fix it somehow.  We decided that we just need to find a way to let cassandra zakompakti. </p><br><p>  We use servers in which 2 sata disks and 2 ssd.  We have problems with space on ssd, we decided that we copy the candidates for this problematic compaction to disk, put links on ssd, thereby freeing up space on ssd for the resulting sstable.  It worked and compaction on this machine began to work as usual. </p><br><p><br><img src="https://habrastorage.org/files/815/deb/c90/815debc90fdd4107bd9eabc91b9272aa.png" width="600"><br></p><br><p>  This graph shows how hdd2 participated in the process. </p><br><h2>  Total </h2><br><ul><li>  We didn‚Äôt figure out just how a record with a crooked timestamp got into sstable (let's postpone it until the repetition, if it is of course) </li><li>  It is necessary to tweak the settings of the DateTieredCompactionStrategy: reduce the <strong>max_sstable_age_days</strong> to 10-30 days so that the sstable does not grow to gigantic sizes (it will be easier to provide a buffer when manipulating them) </li><li>  Cassandra source code is fairly clear and documented. </li><li>  This problem has almost no effect on the availability of our service (it slowed down several times for 2-3 minutes) </li></ul></div><p>Source: <a href="https://habr.com/ru/post/310000/">https://habr.com/ru/post/310000/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../309988/index.html">Keen observer</a></li>
<li><a href="../309990/index.html">The architecture of the network core in the iOS application on Swift 3. Part 1</a></li>
<li><a href="../309992/index.html">Webinar: Tools for Data Scientist</a></li>
<li><a href="../309994/index.html">Remote annunciator of critical temperature and humidity based on AVR MK and DHT22 sensor</a></li>
<li><a href="../309996/index.html">How the Dolphin Emulator defeated the latest unplayed GameCube game</a></li>
<li><a href="../310002/index.html">Hypervisor wars: To be continued</a></li>
<li><a href="../310006/index.html">AdBlock Plus has made a new milestone in the history of "acceptable advertising"</a></li>
<li><a href="../310008/index.html">The Myth of the Immaturity of Mobile NFC Technologies</a></li>
<li><a href="../310014/index.html">OpenJDK: Project Panama</a></li>
<li><a href="../310016/index.html">Analytical calculation of derivatives on C ++ templates</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>