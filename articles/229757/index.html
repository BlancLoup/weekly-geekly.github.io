<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content: 
 1. Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images 
 2. Determinatio...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images</h1><div class="post__text post__text-html js-mediator-article"><h4>  Content: </h4><br>  1. <a href="http://habrahabr.ru/post/229757/">Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images</a> <br>  2. <a href="http://habrahabr.ru/post/229817/">Determination of the dominant signs of classification and the development of a mathematical model of facial expressions "</a> <br>  3. <a href="http://habrahabr.ru/post/229895/">Synthesis of optimal facial recognition algorithm</a> <br>  4. <a href="http://habrahabr.ru/post/229949/">Implementation and testing of facial recognition algorithm</a> <br>  5. <a href="http://habrahabr.ru/post/230053/">Creating a test database of images of users' lips in various states to increase the accuracy of the system</a> <br>  6. <a href="http://habrahabr.ru/post/230133">Search for the best open source audio speech recognition system</a> <br>  7. <a href="http://habrahabr.ru/post/231629/">Search for the optimal audio system of speech recognition with closed source code, but having open API, for the possibility of integration</a> <br>  8. <a href="http://habrahabr.ru/post/231821/">Experiment for integrating video extensions into audio speech recognition system with test report</a> <br><br>  Auto face detection and recognition technologies are used in a number of computer vision systems: biometric identification, human-machine interface, robot vision, computer animation, identification and detection systems in photo-video cameras, and so on.  The main difference between these applications among themselves is the target classes, which are objects of recognition.  The target classes in the recognition tasks can be: a person with elements of overlap, an image of a person‚Äôs face, a living person‚Äôs face, facial expression, facial features, gender, race, age, person‚Äôs personality and other characteristics.  For convenience, we will separate the target classes into separate groups, which, when attempting to build an automatic face detection system, form difficulties: <br><br>  - Strongly varying appearance of the face in different people; <br>  - Even a relatively small change in the orientation of the face relative to the camera entails a serious change in the image of the face; <br>  - The possible presence of individual characteristics (mustache, beard, glasses, wrinkles, and so on), which significantly complicate automatic recognition; <br>  - A change in facial expression can greatly affect how the face looks on the image; <br>  - Shooting conditions (lighting, color balance of the camera, image distortions introduced by the optics of the system, image quality) greatly influence the resulting face image [1]. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The task of detection on the image is the first step, preprocessing in the process of solving the problem of "higher level" (for example, face recognition, facial expression recognition, and so on).  Existing face detection algorithms can be divided into two categories: empirical recognition methods and face image modeling methods.  The first category includes methods that are repelled from human experience in recognizing faces and attempting to formalize and algorithmize this experience.  The second category focuses on pattern recognition tools, considering the problem of face detection as a special case of the general recognition problem.  For a set of training images, a face image model is built, and the detection task is reduced to checking the input image for the satisfaction of the resulting model. <br><br><a name="habracut"></a><br><br>  Among the methods of empirical face detection, a family of methods using skin color as a sign of the presence of a face is distinguished.  In general, color is a combination of different light waves with a predominance of certain frequencies.  In order to describe the color information it is necessary, first of all, to get rid of the color, that is, to convert it into a form that allows direct measurement, namely the form of brightness characteristics.  Each of the filters used creates a uniform color stream after itself, that is, in essence, a tone image that is easy enough to record and encode ‚Äî convert to color form.  Filters are needed in order to be able to capture the receiving tone. <br><br>  To solve this problem, it is necessary to find out how many and which filters are enough to analyze color information.  As practice shows, all three filters are enough to solve this problem (red ‚Äî red, green ‚Äî green, and blue ‚Äî blue colors). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4d1/7cf/9af/4d17cf9af4a4737d280e46fde8361417.png"><br>  Fig.  1 Example of using color filters: red, green and blue <br><br>  The methods associated with the analysis of color space are widespread, since they combine several important advantages: low computational complexity;  high processing speed;  ease of implementation;  resistance to changes in the orientation and scale of the face;  resistance to changes in lighting (with the exception of color);  resistance to changes in facial expression and partial overlapping of the face by another object of the scene. [1] <br><br>  Since the selection of the color of human skin and lips is quite stable, their color characteristics are almost independent of sanctification.  Therefore, the color space in which the search will be carried out should not take into account the lighting.  This condition is satisfied by the RGB color space (red, green, blue), which is used in the construction of color classes. <br><br>  When detecting areas with skin color, along with the usual RGB color representation, that is, the intensities of the red, green and blue color components, an additional color-based representation is used - the HSL representation (hue - color or hue, saturation - saturation, luminosity - brightness): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c41/2e5/718/c412e571832655114e67f8e1c37f3900.png"><br>  Figure 2. HSL view <br><br>  H = arctg (y‚ÅÑk) / 2k; <br>  S = ‚àö (k ^ 2 + y ^ 2); <br>  L = (R + G + B) / 3; <br>  Where: <br>  k = R-0.5- (G + B) <br>  y = ‚àö3‚ÅÑ2 (GB) <br>  [2] <br><br>  The RGB color space has the advantage that its components are primary to the computer, and their use will ensure the highest processing speed.  Components are usually rated for their sum [3,4].  Of the components of this space the most popular: red and green color schemes.  Sometimes, instead of the components themselves, the color difference is used [4]. <br><br>  Using the HSL color space is more suitable for color analysis, since its components are directly related to color.  However, its use limits the need to perform arctangent and square root calculations, which requires some time. <br><br>  Recently, due to the increase in the speed of computers, this color space (HSL) is used more often [5], but its use to solve our problem: creating a mobile mimicking application is not entirely reasonable.  Since the system requirements of mobile devices: performance, multitasking, picture quality of VGA cameras and so on - does not fully satisfy our requirements for implementing a mobile application based on HSL color space. <br><br>  The implementation of facial recognition technology, using RGB space as a basis, is also not the optimal solution.  Since this space has drawbacks related to the limited color gamut. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/63c/b11/02f/63cb1102ff81ee9b43f8fdfd6e702c7f.png"><br>  Fig.  3 Example of color limitation of RGB space <br><br>  Therefore, taking into account the specifics and shortcomings of RGB color spaces (limited in color gamut) and HSL (excessive system requirements for data processing), it is proposed to take as a basis the ‚Äúcompromise‚Äù solution - the YCbCr (or YUV) color model, which, in essence, is encoding RGB information.  In the YCbCr model, color consists of 3 components: brightness (Y) and two color difference (U and V). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd6/c21/d35/cd6c21d35040257d3cbf8a02d18d43ba.png"><br>  Fig.  4 Example of a color model YCbCr, where Y = 0.5 <br><br>  Thus, as the color space in the system under consideration, the following was chosen: {R, G, Cb, Cr}, where: <br>  R = r / (r + g + b); <br>  G = g / (r + g + b); <br>  but: <br>  Cb and Cr are the corresponding components of the YCbCr color space. <br>  As mentioned earlier, the red and green (G) components of the RGB space are the most popular solutions, and their interaction, together with the color difference indicators (Cb) and (Cr), makes it possible to avoid as much as possible - the influence of light intensity, which will allow us to carry out clear separation of the skin area of ‚Äã‚Äãthe face and the skin of the lips.  Among the advantages of the YCbCr color model, it is also necessary to single out a quick transition and transformation of this color model from the RGB format to the new color space {R, G, Cb, Cr}. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f78/0f3/b4d/f780f3b4d83ee8b4a6c1c5b61044a8b8.png"><br>  Fig.  5 Example of changing the color space of the analyzed image <br><br><h4>  Conclusion: </h4><br><br>  Since we are faced with the task of developing a method for identifying potential areas of persons with the following properties: resistance to inevitable inaccuracies in color segmentation, accuracy in identifying areas, high speed of work.  An important requirement is to maintain the high speed of the methods, along with an increase in resilience, in order to retain the most important advantage of using skin color for face detection - speed.  That is why, based on the goal, traditionally priority is given to the RGB color space, since it has the following number of advantages: <br>  - Low computational complexity; <br>  - High processing speed; <br>  - Ease of implementation; <br>  - Resistance to changes in the orientation and scale of the face; <br>  - Resistance to changes in lighting; <br>  - Resistance to changes in facial expression and partial overlapping of the face with another object of the scene. <br>  However, among the disadvantages of this color space, you must select: <br>  - Not high resistance to the inevitable inaccuracies of color segmentation (the fusion of objects of uniform color with the color of human skin into a single background). <br>  To solve this drawback, it is supposed to transform and transfer to the YCbCr color model from the RGB color space, to implement the new space {R, G, Cb, Cr}.  The color space {R, G, Cb, Cr} more reliably and clearly separates the area of ‚Äã‚Äãthe skin of the face and lips, avoiding the effect of sanctification as much as possible;  Binarization in this color format does not present much difficulty for the system, compared to the HSL model.  The latter condition is fundamental, since we are faced with the task of implementing facial recognition technology for mobile devices. <br><br><h4>  Bibliographic list: </h4><br><br>  1. Vezhnevets V., Dyagtereva A. Detection and localization of the face in the image.  CGM Journal, 2003 <br>  2. Gupta D. Computer Gesture Recognition: Using the Constellation method. Caltech undergraduate Research Journal, 2001, vol.1, # 1.  - pp.  26-31. <br>  3. Graf HP, Cosatto E., Gibbon D., Kosheisen M., Patajan E. Multi-modal system.  - AT &amp; T lab technical report 95.5.1, 1996 <br>  4. Vezhnevets V. Human-Computer Interface. GraphiCon - 2002. <br>  5. Vizilter Yu.V., Zheltov S.Yu., Ososkov M.V.  The system of recognition and visualization of the characteristic features of a human face in real time on personal computers using a web-camera. // GraphiCon - 2002. <br><br>  <i>To be continued</i> </div><p>Source: <a href="https://habr.com/ru/post/229757/">https://habr.com/ru/post/229757/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../229741/index.html">Improving performance: boxing in .NET that can be avoided</a></li>
<li><a href="../229743/index.html">Node.js + jQuery Ajax. Upload files to server</a></li>
<li><a href="../229747/index.html">A simple way to connect an arbitrary video source in Qml</a></li>
<li><a href="../229749/index.html">Raspberry Developers Release Raspberry Pi Model B +</a></li>
<li><a href="../229755/index.html">Meet Avaya ERS 4000</a></li>
<li><a href="../229761/index.html">Fail story of SaaS Helpdesk for small business</a></li>
<li><a href="../229763/index.html">YaLinqo (LINQ to Objects for PHP) - version 2.0</a></li>
<li><a href="../229765/index.html">Juniper SRX Series Basic Setup</a></li>
<li><a href="../229767/index.html">Efficient multithreading in Python</a></li>
<li><a href="../229773/index.html">Android "Evolution": how it was</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>