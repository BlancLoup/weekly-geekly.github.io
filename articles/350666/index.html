<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>MathOps or math in monitoring</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="What I want to talk about began on December 30, 2010, when Etsy posted the first commit of its StatsD system on GitHub. This, now, super popular syste...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>MathOps or math in monitoring</h1><div class="post__text post__text-html js-mediator-article">  What I want to talk about began on December 30, 2010, when Etsy posted the first commit of its StatsD system on GitHub.  This, now, super popular system written in <em>JavaScript (hipsters rejoice),</em> to which you can send metrics, measurements of the performance of pieces of your code, and it aggregates them and sends them already aggregated to the time-series storage system. <br><br><img src="https://habrastorage.org/webt/sm/pq/6m/smpq6mh_ds_lx4b3wj05a7hq3yk.png"><br><br>  Against the background of the popularity of StatsD and other time-series systems, the idea of ‚Äã‚Äã‚Äú <em>Monitor Everything</em> ‚Äù emerged: the more different things in the system are measured, the better, because in case of an unexpected situation it will be possible to find the necessary, already collected metric, which will allow to understand everything. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <blockquote>  <strong>Let's do everything that you can monitor - and it will be cool!</strong> <br></blockquote><br>  But as often happens with any fashionable technology, which was originally made with some restrictions, when people start using it, they don‚Äôt really think about these restrictions, but do as it‚Äôs written, as it‚Äôs necessary. <br><br>  And it so happened that there are a lot of problems with all this, about which, in fact, Pavel Trukhanov ( <a href="https://habrahabr.ru/users/tru_pablo/" class="user_link">tru_pablo</a> ) will tell us. <br><a name="habracut"></a><br><blockquote>  Regardless of what software we are developing, mobile game or banking software, we want the system to process incoming events quickly, without glitches, nothing breaks and users are happy. <br><br>  To do this, you need to constantly monitor that the process goes as it should.  <a href="https://habrahabr.ru/company/okmeter/"><strong>Okmeter</strong></a> does a service designed to allow thousands of engineers not to repeat the same thing from time to time in their monitoring services. <br><br>  Not surprisingly, the company's director <strong>Pavel Trukhanov</strong> ( <a href="https://habrahabr.ru/users/tru_pablo/">@tru_pablo</a> ) has to read a lot about monitoring, about metrics, about mathematics, thinking, then reading a lot more and thinking a lot.  This topic he became ill, and he decided to speak.  This article is a transcript of his report on RHS ++ 2017 </blockquote><br><br><h2>  Queuing systems </h2><br>  We are talking about queuing systems, where independent requests come.  SMOs include: <br><br><ul><li>  <strong>the service</strong> that serves them; </li><li>  <strong>timings</strong> , including <em>service time</em> - <em>service time</em> and response time - waiting time in the queue; </li><li>  result of service. </li></ul><br>  If we talk about the web, then there is access logs, in which the response time and the http-status of the response are recorded, from which it is possible to understand whether there are errors or brakes.  We want the system to process incoming events quickly, without glitches, nothing ‚Äúfeil‚Äù and the users were happy.  To do this, you need to constantly monitor that the process is proceeding as we expect.  At the same time, there is our notion that everything is good, but there is a reality, and we constantly compare them. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/7yYR1dgSfyU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Charts </h2><br>  If the process does not meet our expectations, then how we set / determined for ourselves a kind of ‚Äúnormal‚Äù situation, we need to further understand.  For this, it is very convenient to use <strong><em>time series</em> charts</strong> , in which time is plotted on a horizontal scale, and the desired parameter is plotted on a vertical scale. <br><br><img src="https://habrastorage.org/webt/vb/sb/zy/vbsbzyz0hrq8ywm0epfrfrblpji.png"><br><br>  I find such graphics most useful in situations where something goes wrong, as we expect, because they clearly show: <br><br><ul><li>  <strong>impact</strong> <em>,</em> that is how bad everything is; </li><li>  <strong>history</strong> - what the typical behavior of the indicator looks like; </li><li>  <strong>process dynamics</strong> , i.e.  you can see whether the situation is getting worse or better. </li></ul><br>  Everyone knows that the graphics are different, for example, <em>bar</em> , <em>scatter</em> (point), <em>heatmap</em> and others.  But I like the <em>time line</em> exactly, and I recommend them, because our brain is able to coolly determine which of the <em>segments is</em> longer =) This is our evolutionary property that such a graph allows us to use directly. <br><br><img src="https://habrastorage.org/webt/cd/hh/1o/cdhh1ofpzl1uyzis8effuzlntom.png"><br><br><h3>  How to make such a schedule? </h3><br>  Time is plotted on a horizontal scale, and a vertical scale is used for other parameters.  Those.  for each point in time there is one vertical strip of pixels that can be filled with information.  In it, say, 800 or even 1600 points, depending on the size of your monitor. <br><br>  Per unit of time a <strong>different number of events</strong> can occur in the system, 10, 100, 1000 or more, if the system is super large.  No matter how many on your system, it is important that this is not one event.  In addition, events can have different types, timings or results. <br><br>  Despite the fact that you can make as many graphs as you like and look at different aspects on individual graphs, all the same, in the end, for a specific graph, you need to build one number from several events with numerous parameters. <br><br><h3>  1000 timings - what to do with them? </h3><br>  The timings can be visualized as a distribution density: the current timing value is plotted horizontally, and the number of timings with this value is plotted vertically. <br><br>  The graph of the <strong>density of distribution</strong> shows that there are timings with a certain average value, there are fast, there are slow ones. <br><br><img src="https://habrastorage.org/webt/db/c9/cx/dbc9cxquy4746ebz0z-krtnuuxw.png"><br><br>  In addition to the distribution density, it is convenient to look at <strong>the distribution function</strong> , which is simply an integral of the distribution density.  It is good because its range of values ‚Äã‚Äãis limited to a segment from 0 to 1, therefore it allows you to compare completely different parameters with each other without normalization.  But the distribution density is more familiar and physical. <br><br>  In reality, for those systems we are talking about, the distribution density graph does not look like the well-known Gaussian bell of the normal distribution.  Since, at a minimum, <strong>timings are not negative</strong> (unless you have gone back time on your server, which happens of course, but rarely).  Therefore, in most real cases, the graph will look something like the following figure. <br><br><img src="https://habrastorage.org/webt/-h/42/yi/-h42yib2b-kv1063vsa15htf2xy.png"><br><br>  This is also a kind of model, an approximation.  It is called the log-normal distribution, and is an exponent of the normal distribution function. <br><br>  But the reality, of course, is not even that.  All systems look a bit different.  For example, a person screwed <em>Memcached</em> to his <em>php</em> , half of the requests went to <em>Memcached</em> , and half <em>did</em> not.  Accordingly, a bimodal (two-vertex) distribution was obtained. <br><br><img src="https://habrastorage.org/webt/xh/i2/87/xhi287hwkalb2qyeokiprrncspi.png"><br><br>  To be honest, the actual distribution functions look like anything (figure below).  The more complex the system, the more diverse they will be.  On the other hand, when the system becomes too complex, simply out of a million parts, it converses back to the normal distribution on average. <br><br><img src="https://habrastorage.org/webt/2l/mp/-6/2lmp-6oc3uvpiqlfihcclgtusfc.png"><br><br>  It is important to remember that these 1000 timings are calculated continuously, at each interval of time, for example, every minute.  That is, for each interval we have some kind of distribution density. <br><br><img src="https://habrastorage.org/webt/b7/0y/1k/b70y1kxqzfd0q0nzb2nioa8v28e.png"><br><br>  1000 timings - what to do with them? <br><br>  To put one number on the graph, instead of 1000, you need to take some statistics from the measurements - this means, in fact, to compress a thousand number to one.  That is, with the loss of data - this is important. <br><br><img src="https://habrastorage.org/webt/xm/ac/p1/xmacp1jejkq10ofxwdbr8nws_lw.png"><br><br>  Statistics that are known (and distributed): <br><br><ol><li>  <strong>The arithmetic average</strong> is the center of mass of the density graph. </li><li>  <strong>The mode</strong> for the density function is argmax of the distribution density, i.e.  the position of the maximum along the X axis. Here the question arises: what to do when there are several peaks. </li><li>  <strong>Median</strong> - the value of X, in which the area of ‚Äã‚Äãthe figure is divided in half. </li></ol><br>  In addition to the median, there are <strong>percentiles</strong> and other statistics, but I want to emphasize that <strong>whatever statistics we take, it will still be one number</strong> that will not fully describe a thousand observations. <br><br>  Suppose we took some statistics and (hooray, finally) we have a schedule: <br><br><img src="https://habrastorage.org/webt/8q/5g/aw/8q5gawvjqihwu4cnlcnbpcy4hpi.png"><br><br>  In this case, this is a graph of the arithmetic average.  Something is already clear about it.  It is clear that the average has small fluctuations, but there is no scatter of values ‚Äã‚Äãby orders of magnitude. <br><br><img src="https://habrastorage.org/webt/cv/aw/sj/cvawsjge5zpznzsam0a9efh6ckk.jpeg"><br><br>  Here is an example: this distribution density is taken from a specific service.  Guess the statistics - select one of the options, and then I will hold a session of black magic with exposure. <br><br><div class="spoiler">  <b class="spoiler_title">Answer</b> <div class="spoiler_text">  It seems you can easily imagine where the center of mass of the figure is located, but try to guess exactly, I'm sure that you are fooled!  Let's get a look: <br><br><img src="https://habrastorage.org/webt/9c/xf/x7/9cxfx7zzf2vsncj712unhvkxzd0.jpeg"><br></div></div><br>  Well, this may not have been difficult to guess, but here is another example: <br><br><img src="https://habrastorage.org/webt/tq/lp/5p/tqlp5pbtcwqyo_dem7vqoj0yb9u.png"><br><br><div class="spoiler">  <b class="spoiler_title">Answer</b> <div class="spoiler_text"> Here the average is 500. When I myself answered this question for myself, it seemed to me that 2 healthy peaks should be balanced somewhere in the region of 300. <br><br><img src="https://habrastorage.org/webt/6c/gq/uw/6cgquw07sbrzgs6tsvu-x7edeik.jpeg"><br><br>  The fact is that if we otzumim this schedule, it turns out that he also has observations on the far tail, which are simply not visible in the scale in which we look. <br><br><img src="https://habrastorage.org/webt/xr/iy/j0/xriyj0s8pun7gyf_f27x9dsoglm.png"><br></div></div><br>  Real complex systems usually behave this way.  They always have a competition for resources, because sometimes there are many requests at the same time, and there are situations when for a specific request the stars are badly converged and the processing time is long.  If we recall that the physical meaning of the expectation is the center of gravity of the distribution density, it is clear that even a few measurements on the far tail outweigh the lever rule.  Therefore, the average is not located where there is a ‚Äútypical average‚Äù. <br><br>  My point is that the distributions may be completely different in different systems and in different parts of your system.  And as long as you haven‚Äôt really calculated the average, having previously collected a bunch of observations, having built a graph on the basis of the statistics collected, in fact you can hardly guess the result correctly.  Since even with the statistics collected, the average is not easy to guess. <br><br><h3>  Disputes about arithmetic mean </h3><br>  It is believed that mean / average metric is very bad to use for monitoring.  Percentile fans shout from any angle: ‚ÄúI saw in your monitoring an average - you are a bad person!  Take and use better percentile! " <br><br>  It should be noted, they say it is not from scratch and there is a certain reason in it: <br><br>  <strong>1. Physical meaning.</strong> <br><br>  Besides the fact that the average is the center of mass, one can describe the physical sense this way: you bet on a certain number, and the results of the bet (won or lost) accumulate.  That amount, which was won by putting everything in one bag of money, is the essence of the expectation, which is equal to the arithmetic average. <br><br>  But an online system, such as, for example, an online store, in which users expect to open a product card very quickly and rather buy it, cannot be compared with the concept of expectation and what it was designed for. <br><br>  <strong>2. Robust emissions</strong> <br><br>  The second argument of the percentile fans is that the ‚Äúaverage is not robust to emissions‚Äù.  Indeed, we have seen that even one observation on the far tail outweighs the numerous observations located closer to the beginning of the axis (in our case, with large and small timings, respectively). <br><br>  But what I want to explain to you here is counterintuitive: in fact, monitoring doesn‚Äôt need robustness!  On the contrary, <strong>we need non-safety</strong> to emissions - that is, a system that will clearly notice and show them.  For example, if you have never had such a thing so that the average goes beyond a certain limit.  And suddenly, from nowhere, there was some unprecedented distant ejection, then you, of course, want to know about it.  After all, the system began to behave like never before - this is a sure sign that something is wrong.  You do not want to close your eyes and say: ‚ÄúNo, I need a robustness to emissions!  This is a blowout, I don‚Äôt want to know about it. ‚Äù <br><br>  Where did the demand / desire for robustness to emissions come from?  When your task is not monitoring, but research of some system, for example, when you inherited a certain IT system, and you want to study some of its properties, select some basic pattern of behavior under load.  We do this in some controlled environment / conditions and measure the behavior.  Then it would be good if the statistics, which we are trying to characterize this behavior, have a robustness to emissions.  Because we would like to discard and ignore the possible influence of some events that are completely unrelated to our research setup and with the characteristic behavior of the system.  (For example, like a laboratory assistant Vasya, who recorded the observations and fell asleep or recorded incorrectly). <br><br>  When you monitor and control, on the contrary you need to know about all these emissions - which ones are typical and which are out of the ordinary. <br><br><img src="https://habrastorage.org/webt/dh/dg/5v/dhdg5v2h5jsk_tjjqeb6vj6ewxa.png"><br><br>  In the figure above, the Gaussian bell is "cut" into pieces. <br><br><blockquote>  Many people know the ‚Äúrule of 3 <strong><em>œÉ</em></strong> (sigma)‚Äù: if you ‚Äúretreat 3 <strong><em>œÉ</em></strong> ‚Äù from the mean, then the probability of getting observation outside this interval is very small. </blockquote><br>  From here comes a hasty sentence: ‚Äúthen let‚Äôs hang up on our (any or favorite) metrics a check that will follow when the value has come out of 3 <strong><em>œÉ</em></strong> from the average and warn us.‚Äù  They say, "since these are rare events, then if this has already happened, then most likely something is wrong and you need to wake everyone up and do something." <br><br>  In the figure, as you can see, a 3 <strong><em>œÉ</em></strong> departure gives approximately 0.1% probability, and it seems that these are really terribly rare events.  but not really!  1 time in 700 observations you will have something to fall out there. <br><br>  I want to show that even with a normal distribution of events that go beyond these notorious 3 <strong><em>œÉ</em></strong> , occur more often than you expect, than the general understanding of the "rare" and "abnormal".  And, if it is monitoring, they will send you spam, and not benefit. <br><br>  These two tasks are related: <br><br><ol><li>  We first want to understand how our <strong>system behaves in the ‚Äúnorm‚Äù</strong> , and this is very important, because our a priori view may not correspond to reality in any way. </li><li>  Then, when we built the distributions, <strong>select the threshold values</strong> (focusing on the distribution or not too much), get alerts on them and monitor. </li></ol><br><h3>  What is the "norm"? </h3><br>  In my opinion, the value of 300 in our first example does not describe the "average" or typical behavior of the system.  The median (the 50th percentile), in my personal sense, is closer to what I would call ‚Äútypical‚Äù for this distribution. <br><br>  Percentile P90 is at around 550. And the more percentiles taken, the more detailed the description of the distribution will be. <br><br><img src="https://habrastorage.org/webt/8s/nq/f2/8snqf2krtrt7dkmqdxtjdmd1tia.png"><br><br>  Of course, you can build and look at the distribution itself, its density, but in control / monitoring or optimization tasks, you still need to <strong>operate with a limited number of parameters</strong> so that different distributions can be compared. <br><br>  Let's look at one more example, one more distribution of service response times.  It looks, in a sense, like: <br><br><img src="https://habrastorage.org/webt/om/jm/ti/omjmti6lrvdrx5zh5y5ulzkwsqk.png"><br><br><img src="https://habrastorage.org/webt/18/cn/g1/18cng1nqpdf_r95t60_gngha6eo.jpeg"><br><br>  My expectations tell me: ‚ÄúDude, wait, you have almost all the observations here, up to 15 milliseconds, and 95th, why is there somewhere?‚Äù <br><br>  Paradox. <br><br>  Well, the 95th is a cool percentile, the fans convinced us that it is important to look not only at the middle and not at the median, but also at the higher percentiles.  Let's start monitoring on the P95, since it obviously covers all the previous ones. <br><br><h3>  Monitoring </h3><br>  We set ourselves a Service Level Objective - or in Russian, a goal.  For example, to P95 &lt;55 ms and start to follow this. <br><br>  Actually, there are a lot of points <strong>why this SLO is bad</strong> . <br><br>  <strong>Subtle degradation</strong> <br><br><img src="https://habrastorage.org/webt/jh/yf/4j/jhyf4jtbcp7c52eg4hld7ffdeie.png"><br><br>  And you, for certain, would like to know that such changes occurred in the system.  Therefore, the ‚Äúlet's only look at the X-percentile‚Äù approach does not work again.  ¬Ø \ _ („ÉÑ) _ / ¬Ø <br><br>  The solution suggests itself: <br><br><blockquote>  - Well, let's follow a large number of percentiles!  One 9x-th is not enough, let's set the condition P75 &lt;15 ms for the 75th one.  And on some! </blockquote><br>  Let's see what happens. <br><br><img src="https://habrastorage.org/webt/tm/e_/ax/tme_axwhhcvwgx0dowddil0ovu4.png"><br><br>  Such our current requirements for the behavior of the system is the yellow border on the graph.  And the blue curve is what the latency system looks like in reality.  What you need to see is that to the right of p95 (the scale is non-linear), latency immediately begins to grow.  In the sense that when we clamp our system on the thresholds, then where we stop controlling it, it immediately tries to jump out from under these thresholds as soon as it can faster.  That is, if we have all optimized at the level of p95, then timings grow significantly on p96. <br><br>  <strong>Second moment</strong> <br><br>  Since we are a monitoring company, we are constantly asked: ‚ÄúCan you track the percentages?  Do you draw the 95th percentile? " <br><br>  We reluctantly answer: "Yes, you can ...".  In our monitoring there are percentiles, but we hide them and try not to show them because they are misleading users. <br><br>  Suppose there is a distribution density. <br><br><img src="https://habrastorage.org/webt/rz/x7/kb/rzx7kbn0rmwglrkljaj6kzyyy78.png"><br><br>  We see 3 percentiles and an average.  But what is wrong here?  It‚Äôs not so that 95 is not just "95".  This is 95 out of 100. So, somewhere there are 5 more?  Where are these 5%? <br><br>  On the right tail the schedule is already low, and it feels that there are only very rare events to the right.  And although they are, but you can not look at them. <br><br>  But in the figure I collected the 5% and put a column.  And a lot of them!  <strong>5% is every 20th</strong> .  It's a lot!  And it is immediately clear that it is <strong>wrong to ignore them</strong> . <br><br><img src="https://habrastorage.org/webt/ga/_o/n6/ga_on6etydxt5gtcqmmxlpt9pnc.png"><br><br>  When you look at the 95th percentile of your service, and it‚Äôs cool (let's say about 100 milliseconds), you think that everything is great!  In fact, you just deliberately closed your eyes by 5%: ‚ÄúI will not look at that horror in the far tail of the distribution, because it‚Äôs scary and unpleasant ‚Äî I don‚Äôt want to look there!‚Äù This is, of course, <strong>irresponsible</strong> . <br><br>  It is clear that here too the solution suggests itself: ‚ÄúOk, ok, 95 is not enough, let's take 99!  We are cool guys, let's even take three nines - 99.9%! ‚Äù <br><br>  Already, it would seem, at 99.9%, one thousandth is not really included, which, probably, is costly to optimize and you can score on such a rarity. <br><br>  Yes? <br><br>  But I will try to convince you that <strong>99.9% is still not enough.</strong> <br><br>  This is again a counterintuitive (and bold) statement.  Before proving it, I would like to talk about these "senior" percentiles. <br><br>  As in life, percentiles are often measured. <br><br>  Now there are a lot of tools, starting with <em>StatsD</em> , ending with the whole variety of modern utilities that allow us to easily get different measurements. <br><br><blockquote>  - Let's measure how our service behaves! <br><br>  - Come on! <br><br>  - Let's stick the monitoring - I read on <em>one thematic resource</em> , how it is done - set - and that's it!  There are charts! </blockquote><br>  And here we have already received response timelines.  Let‚Äôs look at (our favorite) percentiles. <br><br><img src="https://habrastorage.org/webt/yu/xi/wl/yuxiwlhukixugkui6n10_9muz48.png"><br><br>  Here, the median (p50) is cool, I personally like super!  Such a superstable - always ~ 2 milliseconds.  It begs to rather hang the trigger with a threshold with a small margin of 2.2-3.5 ms and receive notifications when something goes wrong. <br><br>  Let's look at the 90th percentile, and it behaves not so stable anymore <br><br><img src="https://habrastorage.org/webt/fn/k8/3s/fnk83s2ww2ywaom2cizwfglpjm4.png"><br><br>  95th - at all, like a comb. <br><br><img src="https://habrastorage.org/webt/zc/4h/8j/zc4h8j12nal9po6jh5yr5hphy70.png"><br><br>  It would seem, where is the promised, praised robustness to emissions ?!  This is how intuition deceives us again, prompting that ‚Äúrobust‚Äù means ‚Äúsmooth‚Äù, stable.  Although in reality it is not so. <br><br>  Continuing to talk about (counter) intuitive sensations of percentiles, we will look at another chart. <br><br><img src="https://habrastorage.org/webt/ws/gk/0d/wsgk0dk5jswfm9ctz236i-lmm1g.png"><br><br>  It seems that on this graph, p99 ranges from 1 second to ~ 2-3 seconds.  And his "real value" should be somewhere around 1.1s <br><br>  But if we calculate p99 for all the data accumulated during this period, it turns out that p99 is ‚Äúreal‚Äù in a completely different place - the difference is 10 times.  How so? <br><br>  First, we measure the percentile per interval - in this case per minute.  For the day runs 1440 every minute measurements.  We drew this graph, and our brain automatically calculates a horizontal trend for it, if we see that it does not float.  Even if we guessed it: ‚ÄúSo, this is a percentile - you probably need to take a maximum from it, it turns out to be about 5s‚Äù - anyway, it‚Äôs actually not there. <br><br>  If we take this distribution and try to collect statistics, when the percentile that we calculate stops changing (or almost stops) from adding measurements over time, it turns out that it is still not where we expect it, but twice as high. <br><br>  Our head calculates a certain horizontal level, and the percentile behaves differently. <br><br><img src="https://habrastorage.org/webt/gx/l4/t_/gxl4t_mrqdstt4vn2bkhsah_4qg.png"><br><br>  For example, we look at the schedule for 8 hours and nothing much happens, and there were emissions at night.  You can often see (and in this particular case) fewer requests at night.  And it seems everything should work faster.  And from the point of view of percentiles, everything works not necessarily faster, but somehow.  Because it can be really faster, and there can be, for example, cold caches, because of which slow return. <br><br>  Let's go back to the number of nines. <br><br><h3>  What have we forgotten, or what about the users? </h3><br>  While we were discussing queuing systems, requests, services, perceptions, we lost real users.  Users are not requests, but people.  They roam the site (or in a mobile application) and want to accomplish something there through intermediate steps, which are often more than 1. And we measure statistics by individual requests. <br><br><ul><li>  Sessions last a long time; </li><li>  The general impression of the responsiveness of the service; </li><li>  One bad response time is strongly affected; </li><li>  Important Ajax and other resources. </li></ul><br>  Each user in the session has its own viewing depth.  But: <br><br><ul><li>  The probability of one page being better than p99 is 99%; </li><li>  The probability of N pages being no worse than p99 is (0.99N) * 100%; </li><li>  The number of users who stumble on something worse p99 is (1 - (0.99N)) * 100% </li><li>  For p99 and N = 10, this is 10%; </li><li>  For p99.9 and N = 20, this is 2% </li></ul><br>  We believe that only 1% of users remain on whom we are hammering if we monitor the 99th percentile.  But again, this is not the case <strong>and it is as much as 10%!</strong> <br><br>  And when we talk about the latency of individual subqueries that already go directly to the database, or to some web service, or <em>application</em> server, the ratio is even greater. <br><br>  Therefore, 99.9% is often not enough ‚Äúhigh‚Äù percentile, which you need to focus on. <br><br><h2>  Conclusion </h2><br>  Any statistician will say: "Do not trust your intuition in statistics!" <br><br>  I am telling you: <strong>‚ÄúDo not trust your intuition in monitoring!‚Äù</strong> <br><br><img src="https://habrastorage.org/webt/ob/ne/mk/obnemktor5wmsxnyqhpdg5khr1u.jpeg"><br><br><h3>  Contacts </h3><br>  Pavel Trukhanov <strong>on Habrahabr</strong> - <a href="https://habrahabr.ru/users/tru_pablo/">@tru_pablo</a> <br><br>  <a href="https://habrahabr.ru/company/okmeter/">The company's blog</a> and the <a href="https://okmeter.io/">okmeter.io</a> service <a href="https://okmeter.io/">itself</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Questions and answers</b> <div class="spoiler_text">  <strong>- We have about the same problem.</strong>  <strong>The question is how to choose thresholds for monitoring?</strong>  <strong>If we look at the graph of the 95th, 99th percentiles, we see peaks there.</strong>  <strong>Suppose <em>I have a Product Owner</em> asking: ‚ÄúHow long can we promise almost always the answer time?‚Äù, I say: ‚ÄúIf you look at the 95th percentile, 300 milliseconds‚Äù - ‚ÄúYes, okay, great!</strong>  <strong>And what about the 99th? ‚Äù-‚Äú 40 seconds ‚Äù-‚Äú What ?! ‚Äù</strong> <br><br>  <strong>It‚Äôs impossible to live with it at all.</strong>  <strong>That is, if you put 40 seconds, it is not monitoring, but garbage;</strong>  <strong>if you put 300 milliseconds, it turns out to be 100 alerts per hour.</strong> <br><br>  <strong>The question is - how to live?</strong> <br><br>  First, cheers to your <em>Product Owner</em> , that he understands what percentile is, because my <em>Product owners,</em> when I say to them: ‚ÄúSuch and such percentile, such and such time‚Äù, one number can understand, two numbers - already finish! <br><br>  Back to the question.  The answer is honest and very simple - it was not necessary to spend so much time on it.  You dug a hole for yourself, your <em>Product Owner</em> has the opportunity to see the percentile graphs (or ask you this question).  You fall into it and ask me how you will not fall into it.  Do not dig a hole for yourself - you will not fall into it. <br><br>  No need to keep track of percentiles - this is wrong.  We in <strong>Okmeter</strong> recommend choosing thresholds not on the behavior of percentiles, but on what you see fit.  For example, to make the user feel good when the site is quickly opened (or slowly). <br><br>  It depends on a million parameters, starting, of course, from the service itself.  But at the same time, there are guidelines from industry leaders.  <em>Google</em> says 400 milliseconds <em>server time</em> is fine.  Amazon explains that a delay of an additional 100 milliseconds over 400 causes the <em>conversion rate</em> to drop by 9%, according to other estimates by 16%.  But in my opinion, you, as the owner of this system, must decide that in such situations the user should see the page in such time, it should be worked out. <br><br>  Further you do not draw pertsenti.  Percentiles in monitoring - this is evil! <br><br>  Drawing them, instead of using your internal consideration (or external Google) and saying that it should work up to such a threshold, you start looking at the graph: <br><br>  - Look, we have 50 milliseconds, there are pages of this type here! <br><br>  - Very good!  Let's set such a threshold! <br><br>  No, don't do that!  You decide that the server should be responsible for 400 milliseconds.  Then you draw - he was responsible for 400 milliseconds in such a percentage.  Worse, but still tolerable, up to the second we have so many percent.  And the fact that higher than a second - it's all no longer good! <br><br>  Then you can track it, then there is no such problem that they ask you about guaranteed time. <br><br>  Yes, it happens that the IT system behaves like a lognormal - a long-tail blingo.  In fact, I see (we have a lot of statistics from clients) that this tail is often thicker than usual, and goes further than that of the lognormal distribution. <br><br>  This is a typical real situation - not at all, but at many. <br><br>  When you are asked a question: ‚ÄúHave you stopped drinking brandy in the morning long ago?‚Äù - no need to answer it.  When you are asked: ‚ÄúWhat is our guaranteed server response time?‚Äù - there is no such guaranteed time.  The server fell, the data center burned down, the meteorite fell off - and the server response time is two days while it is being repaired. <br><br>  The answer is - <em>out of the box</em> .  In the framework of percentiles honestly can not answer. <br><br>  <strong>- A question again about monitoring.</strong>  <strong>There are different analyzes to understand what is happening.</strong>  <strong>The classic model - you can build the 50th, 90th, 99th percentile, and so on.</strong>  <strong>The question is which visualization tool do you recommend - <em>open source</em> , not open source?</strong>  <strong>How to do an analysis of temporal trends, namely to find matches, something else?</strong> <br><br>  If I understand the question correctly.  Suppose if we are really talking about <em>post mortem</em> , at this point no graphics are needed.  Monitoring is monitoring, <em>post mortem</em> is <em>post mortem</em> .  These are different things. <br><br>  It would be desirable, of course, as always, to have a <em>silver bullet</em> from some system in which everything is there, it shows everything, also keeps it - you can look at it all after the fact.  But this is unreal - it is just a completely different system.  Such an answer, if for garlic. <br><br>  <strong>- Besides percentiles and medium, what other interesting mathematical metrics and graphs can you offer?</strong> <strong>, ,        .</strong> <br><br>     ‚Äî .      ,  . <br><br>    ,   .  ,  3    ,   0,1,       .    , ,    .      -    . <br><br>     , ,   ‚Äî    ,       25-  75- . <br><br>    ‚Äî   .      ,    .   ‚Äî   .  It all depends on the task.       . <br><br>    ‚Äî   <em>Product Owner'</em> ,       ?    ,  <em>Amazon</em> .  ,    100 ,      ,   .       . <br><br>   ,       : <br><br> ‚Äî     ,   -  StatsD   ,   - .   ! <br><br> ‚Äî ,    ‚Äî  ,   ! <br><br> ,         . <br><br>      ,   .    ,   : LD50 ( <em>lethal dose</em> ) ‚Äî         ,     . <br><br>          ‚Äî      ,    .   ,       ,    .   ,    . <br><br> <strong>‚Äî   ,      ,  ,  .    :  ‚Äî ,  ‚Äî  .</strong> <br><br> <strong> ,     -   ‚Äî , ?    ? ,    ‚Äî     ,       ?</strong> <br><br> , okmeter   ,  real-time  .      . <br><br> <strong>‚Äî  ,     ,   ,     ‚Äî     ,   ,   .</strong> <br><br> <strong> ,    .      99,9% ,   -    - ,    .</strong> <br><br> <strong>   ,      ,   .      -    (99,9  99,999),         .</strong> <br><br>  ,     ! <br><br>    2 : <br><br><ol><li>      ‚Äî 99-  ‚Äî 40 .   ! ,   ! ( sarcasm) </li><li>   point  ,   ‚Äî  ,    . </li></ol><br>     - . ,   ‚Äî  ‚Äú  , ,  ,  !        ‚Äù. <br><br>  -     ‚Äî   ‚Äî  ,      ‚Äî   99,9-!    ‚Äî   ! <br><br> <strong>‚Äî  -  ‚Äî      .   -    ,   ,         ,        .  ?      ,   ,  .</strong> <br><br>    ‚Äî     ‚Äî -      ,    ? <br><br>      <em>Apdex score</em> ,   ‚Äî   ,  4     ,     . <br><br>  ,   ?      ?    ,  ,     ,    ? <br><br> <strong>‚Äî , ,    ,        ,     .</strong> <br><br>       ,       . <br><br> <strong>‚Äî -   ‚Äî  300-400 ,    .       ?</strong> <br><br> ‚Äî   ,   .       . <br></div></div><br><blockquote>    ,     DevOps,    <a href="http://ritfest.ru/">++</a>    <a href="http://rootconf.ru/">RootConf</a> .          <a href="http://speakers.ritfest.ru/"></a> .     ,    ‚Äî  . </blockquote></div><p>Source: <a href="https://habr.com/ru/post/350666/">https://habr.com/ru/post/350666/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../350656/index.html">ASC scenario as the basis of timeliness and harmony in business</a></li>
<li><a href="../350658/index.html">CSS weirdness to know about</a></li>
<li><a href="../350660/index.html">GitLab 10.5 released: integration with Let's Encrypt, Gemnasium dependency checks and external CI / CD files</a></li>
<li><a href="../350662/index.html">Creating animation transitions between Activity in Android</a></li>
<li><a href="../350664/index.html">About the book "Ensuring the safety of automated process control systems in accordance with modern standards"</a></li>
<li><a href="../350668/index.html">R means regression</a></li>
<li><a href="../350670/index.html">The second wave: who will have to go to the online box office this summer</a></li>
<li><a href="../350672/index.html">9 best books about IT and programming that you might have missed</a></li>
<li><a href="../350674/index.html">What we read in February: Angular sources, results of the year in numbers, frame recognition and other useful links</a></li>
<li><a href="../350676/index.html">Everything simple became complicated again</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>