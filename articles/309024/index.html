<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep learning: opportunities, perspectives and a bit of history</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="For the past few years, the phrase ‚Äúdeep learning‚Äù has been appearing too often in the media. Various magazines like KDnuggets and DigitalTrends try n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep learning: opportunities, perspectives and a bit of history</h1><div class="post__text post__text-html js-mediator-article">  For the past few years, the phrase ‚Äúdeep learning‚Äù has been appearing too often in the media.  Various magazines like <a href="http://www.kdnuggets.com/2015/12/deep-learning-tools.html">KDnuggets</a> and <a href="http://www.digitaltrends.com/cool-tech/mit-audio-turing-test-algorithm/">DigitalTrends</a> try not to miss the news from this sphere and talk about popular frameworks and libraries. <br><br>  Even popular publications like <a href="http://www.nytimes.com/2016/03/16/opinion/where-computers-defeat-humans-and-where-they-cant.html">The NY Times</a> and <a href="http://www.forbes.com/sites/kevinmurnane/2016/04/01/what-is-deep-learning-and-how-is-it-useful/">Forbes</a> tend to write regularly about what scientists and developers from the field of deep learning are doing.  And interest in depth learning is still not fading.  Today we will talk about what deep learning is capable of now, and what scenario it will develop in the future. <br><br> <a href="https://habrahabr.ru/company/it-grad/blog/309024/"><img src="https://habrastorage.org/files/c71/c0b/68a/c71c0b68abdc4caca2950900a0e47d98.jpg"></a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>/ photo <a href="https://www.flickr.com/photos/xdxd_vs_xdxd/6830603137/in/photolist-bpACkB-ifV2aH-eqxQSg-p1Pahi-bpAv1a-7mAUtN-bpuk9B-4pxGrk-d5YG7y-bpAuZk-bpuk96-bpuGMx-bpACkV-r36XMp-bpuk9n-bpuGMn-bpAuZT-bpuk9i-k5tN2x-d3CMFu-d3CMku-4pByNJ-bpuk92-bpACmi-bpyKLB-opgTge-djmMCC-bpyKJT-bpz1VT-bpAv1n-bA3Ysu-bpuk9g-bpuGMi-eky9rU-vkpmwx-bpyKLZ-bpuGMt-bpz1VF-d7FkjN-bpysBa-diZVu6-bpAuZx-bwCxyV-d85yzQ-d6TpUN-4vawEV-4uUXwN-whHfNv-bpyKHD-bpyKJk">xdxd_vs_xdxd</a> <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC</a></i> <br><a name="habracut"></a><br><h3>  A few words about deep learning, neural networks and AI </h3><br>  What is the difference between the depth learning algorithm and the usual neural network?  According to <a href="https://www.quora.com/How-does-deep-learning-work-and-how-is-it-different-from-normal-neural-networks-applied-with-SVM">Patrick Hall</a> , lead data researcher at SAS, the most obvious difference is that there are more hidden layers in the neural network used in depth learning.  These layers are between the first, or input, and the last, output, layer of neurons.  At the same time, it is not at all necessary <a href="http://www.kdnuggets.com/2015/01/deep-learning-explanation-what-how-why.html">to connect</a> all neurons at different levels to each other. <br><br>  The distinction between deep learning and artificial intelligence is not so straightforward.  For example, <a href="https://homes.cs.washington.edu/~pedrod/">Pedro Domingos</a> , a professor at the University of Washington, agrees with the opinion that in-depth training acts as a hyponym for the term ‚Äúmachine learning,‚Äù which in turn is a hyponym for artificial intelligence.  Domingos says that in practice their areas of application intersect quite rarely. <br><br>  However, there is another opinion.  <a href="http://www.dmi.usherb.ca/~larocheh/index_en.html">Hugo Larochelle</a> , a professor at the University of Sherbrooke, is confident that these concepts are almost unrelated.  Hugo remarks that AI focuses on the goal, and in-depth training focuses on a <a href="http://www.kdnuggets.com/2016/08/artificial-intelligence-dead-long-live-deep-learning.html">specific technology</a> or methodology necessary for machine learning.  Therefore, hereinafter, speaking of achievements in the field of AI (such as AlphaGo, for example), we will keep in mind that such developments use depth learning algorithms - but along with other developments from the field of AI in general and machine learning in particular [as rightly <a href="http://www.kdnuggets.com/2016/08/artificial-intelligence-dead-long-live-deep-learning.html">notes</a> Pedro Domingos]. <br><br><h3>  From the ‚Äúdeep neural network‚Äù to deep learning </h3><br>  Deep neural networks appeared quite a long time ago, back in the <a href="https://en.wikipedia.org/wiki/Deep_learning">1980s</a> .  So why deep learning began to actively develop only in the 21st century?  Representations in the neural network are created in layers, so it was logical to assume that more layers would allow the network to learn better.  But a big role is played by the network training method.  Previously, for depth learning <a href="https://www.datarobot.com/blog/a-primer-on-deep-learning/">the same algorithms</a> were used as for learning artificial neural networks - the reverse encryption method.  Such a method could effectively train only the last layers of the network, as a result of which the process was extremely long and the hidden layers of the deep neural network did not actually ‚Äúwork‚Äù. <br><br>  Only in 2006, <a href="https://www.datarobot.com/blog/a-primer-on-deep-learning/">three independent groups of</a> scientists were able to develop ways to overcome difficulties.  Jeffrey Hinton was able to pre-train the network using <a href="https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf">the Boltzmann machine</a> , teaching each layer separately.  To solve image recognition problems, Jan LeCan suggested using a <a href="http://yann.lecun.com/exdb/lenet/">convolutional neural network</a> consisting of convolutional layers and subsample layers.  <a href="https://www.iro.umontreal.ca/~bengioy/yoshua_en/research.html">The cascade</a> auto-encoder, developed by Yoshua Bengio, also enabled all layers to be used in a deep neural network. <br><br><h3>  Projects that "see" and "hear" </h3><br>  Today, in-depth training is used in completely different fields, but perhaps most of the <a href="https://github.com/aymericdamien/TopDeepLearning">examples of use</a> lie in the field of image processing.  The face recognition function has been around for a long time, but as they say, there is no limit to perfection.  <a href="http://cmusatyalab.github.io/openface/">The developers of the OpenFace service are</a> confident that the problem has not yet been solved, because the recognition accuracy can be improved.  And these are not just words, OpenFace is able to distinguish even similar people.  Details about the work of the program have already been written in <a href="https://habrahabr.ru/post/306568/">this</a> article.  In-depth training will also help when working with black and white files, which <a href="https://github.com/pavelgonchar/colornet">Colornet uses to</a> automatically colorize. <br><br>  In addition, deep networks are now able to recognize human emotions.  And along with the ability to track the use of the company's logo in the photos and analysis of the accompanying text, we get a <a href="https://www.technologyreview.com/s/602037/google-and-microsoft-want-every-company-to-scrutinize-you-with-ai/">powerful marketing tool</a> .  Similar services are developing, for example, IBM.  The tool allows you to evaluate the authors of texts when searching for bloggers for cooperation and advertising. <br><br>  <a href="https://github.com/karpathy/neuraltalk">NeuralTalk</a> can describe images with a few sentences.  The base of the program loads a set of images and 5 sentences describing each of them.  At the learning stage, the algorithm learns to predict bids based on a keyword using the previous context.  And at the stage of prediction, Jordan‚Äôs neural network is already creating sentences describing pictures. <br><br>  Today there are many applications that can solve different problems in working with audio.  For example, the <a href="https://github.com/tensorflow/magenta">Magenta</a> application developed by the Google team can create music.  But most applications focus on speech recognition.  The <a href="https://research.googleblog.com/2015/08/the-neural-networks-behind-google-voice.html">Google Voice</a> Internet service is able to transcribe voice mail and has SMS management functions, while researchers used existing voice messages to train deep networks. <br><br><h3>  Projects in the "conversational genre" </h3><br>  According to such scholars as <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">Noam Chomsky</a> , it is impossible to teach a computer to fully understand speech and to conduct a conscious dialogue, because even the mechanism of human speech is not fully understood.  Attempts to teach cars to speak began in 1968, when Terry Vinograd created the <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">SHRDLU</a> program.  She knew how to recognize parts of speech, describe objects, answer questions, even had a small memory.  But attempts to expand the vocabulary of the machine led to the fact that it became impossible to control the application of the rules. <br><br>  But today, with the help of Google‚Äôs in-depth training in the face of developer <a href="https://scholar.google.ru/citations%3Fuser%3DvfT6-XIAAAAJ%26hl%3Dru">Kuok Le, he has</a> stepped far forward.  His designs are able to respond to emails in Gmail and even help Google technical support specialists.  And the <a href="http://www.cnet.com/news/the-meaning-of-life-according-to-google-chatbot-ai/">Cleverbot</a> program studied dialogues from 18,900 films.  Therefore, she can even answer questions about the meaning of life.  So, the bot believes that the meaning of life is to serve the good.  However, scientists are once again faced with the fact that artificial intelligence only mimics understanding and <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">has no idea about reality</a> .  The program perceives speech only as a combination of certain characters. <br><br>  Language learning can help in translation.  Google has long been engaged in improving the quality of translation in its service.  But how much can machine translation be closer to the ideal, if a person cannot always correctly understand the meaning of a statement?  Ray Kurzweil proposes to graphically represent the semantic meaning of words in a language to solve this problem.  The process is quite time-consuming: in a special directory of <a href="https://www.technologyreview.com/s/513696/deep-learning/">Knowledge Graph</a> , created at Google, scientists have downloaded data on almost 700 million topics, places, people, between which almost a billion different connections were made.  All this is aimed at improving the quality of translation and the perception of the language by artificial intelligence. <br><br>  The idea of ‚Äã‚Äãrepresenting the language by graphic and / or mathematical methods is not new.  Back in the 80s, scientists had the task to present a language in a format with which a neural network could work.  As a result, a variant was proposed to represent words in the form of mathematical vectors, which made it possible to accurately determine the semantic proximity of different words (for example, the words ‚Äúboat‚Äù and ‚Äúwater‚Äù should be close to each other in vector space).  Today‚Äôs Google research, which modern researchers call not ‚Äúvectors of individual words‚Äù, but ‚Äúvectors of ideas‚Äù, is based on these studies. <br><br><h3>  Deep learning and health care </h3><br>  Today, in-depth training penetrates even into the sphere of public health and helps to monitor the condition of patients not worse than doctors.  For example, the <a href="https://www.technologyreview.com/s/602037/google-and-microsoft-want-every-company-to-scrutinize-you-with-ai/">Darmut-Hitchcock</a> Medical Center in the United States uses the specialized Microsoft <a href="http://blogs.microsoft.com/transform/2015/07/13/dartmouth-hitchcock-ushers-in-a-new-age-of-proactive-personalized-healthcare-using-cortana-analytics-suite/">ImagineCare</a> service, which allows physicians to detect subtle changes in the patients' condition.  Algorithms obtain data on weight changes, monitor patient pressure, and can even recognize an emotional state based on an analysis of telephone conversations. <br><br>  Deep learning is also used in pharmaceuticals.  Today, molecular therapy is used to treat various types of cancer.  But in order to create an effective and safe medicine, it is necessary to identify active molecules that would act only on a given target, thus avoiding side effects.  The search for such molecules can be performed using in-depth training (a description of the project conducted jointly by scientists from universities in Austria, Belgium and the R &amp; D department of Johnson &amp; Johnson is in <a href="http://www.bioinf.jku.at/publications/2014/NIPS2014c.pdf">this</a> scientific material). <br><br><h3>  Does the algorithm have intuition? </h3><br>  How deep is deep learning really?  <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">AlphaGo</a> developers can answer this question.  This algorithm is not able to speak, can not recognize emotions.  But he is able to beat anyone in a board game.  At first glance, there is nothing special.  Almost 20 years ago, a computer developed by IBM, for the first time <a href="https://habrahabr.ru/company/ibm/blog/143676/">beat</a> a man in chess.  But AlphaGo is another matter.  Board game Go appeared in ancient China.  The beginning is something like chess - opponents play a checkered board, black pieces against whites.  But this is where the similarities end, because the figures are small pebbles, and the goal of the game is to surround the opponent's pebbles with their own. <br><br>  But the main difference is that there are no known winning combinations in advance, it is impossible to think a few moves ahead.  The car can not be programmed to win, because it is impossible to build a winning strategy in advance.  This is where deep learning comes into play.  Instead of programming certain moves, AlphaGo <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">analyzed</a> hundreds of thousands of games and played a million games with itself.  Artificial intelligence can be trained in practice and perform complex tasks, acquiring what a person would call "an intuitive understanding of a winning strategy." <br><br><h3>  Cars won't take over the world </h3><br>  Despite the staggering successes of AlphaGo, artificial intelligence is far from enslaving the human race.  Machines have learned a kind of "intuitive thinking", processing a huge array of data, but, according <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">to</a> Fey-Fey Lee, head of the Stanford laboratory of artificial intelligence, abstract and creative thinking is not available to them. <br><br>  Despite some progress in image recognition, a computer may confuse a traffic sign with a refrigerator.  Together with his colleagues, Lee makes a database of images with their detailed description and a large number of tags that will allow the computer to get more information about real objects. <br><br>  According to Lee, this approach ‚Äî learning based on a photo and describing it in detail ‚Äî is similar to how children learn, associating words with objects, relationships, and actions.  Of course, this analogy is rather rough - for a child to understand the interconnections of objects in the real world, it is not necessary to describe each object and its environment in detail. <br><br>  Professor <a href="http://cocosci.mit.edu/josh">Josh Tenenbaum</a> , a student of cognitive science at MIT, notes that the algorithm of knowledge of the world and learning from a computer is very different from the process of knowledge in humans;  despite its size, artificial neural networks can not be compared with the device of biological networks.  Thus, the ability to speak is formed in a person very early and is based on the visual perception of the world, the possession of the musculoskeletal system.  Tenenbaum is <a href="https://www.technologyreview.com/s/602094/ais-language-problem/">sure</a> that it is not possible to teach machines to complete thinking without imitating human speech and the psychological component. <br><br>  Fei-Fei Lee agrees with this opinion.  According to the scientist, the current level of work with artificial intelligence will not allow bringing it closer to human intelligence - at least due to the fact that people have emotional and social intelligence.  Therefore, the seizure of the world by cars should be postponed for at least another couple of decades. <br><br>  <i>PS Additional reading: Our <b><a href="https://habrahabr.ru/company/it-grad/blog/309022/">IaaS digest</a></b> - 30 materials on the applicability of cloud technologies.</i> </div><p>Source: <a href="https://habr.com/ru/post/309024/">https://habr.com/ru/post/309024/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../309012/index.html">DevCon School schools and other good news for the day of knowledge</a></li>
<li><a href="../309014/index.html">The first mobile browser with support for Chromium extensions. New alpha Yandex Browser</a></li>
<li><a href="../309016/index.html">Graduates of the online program share their impressions</a></li>
<li><a href="../309018/index.html">How it works: A few words about DNS</a></li>
<li><a href="../309022/index.html">IaaS Digest: 30 Materials on Cloud Applicability</a></li>
<li><a href="../309026/index.html">‚ÄúApplication Architectures‚Äù: a little about serverless architectures</a></li>
<li><a href="../309028/index.html">Says statistics: present and future of IaaS</a></li>
<li><a href="../309030/index.html">‚ÄúThe Evolution of Music‚Äù: A couple of words about recommender algorithms for streaming services</a></li>
<li><a href="../309032/index.html">Interview with the designer: Mikhail Ozornin</a></li>
<li><a href="../309036/index.html">Model of the interaction of ships with water in video games: part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>