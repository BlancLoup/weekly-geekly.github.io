<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Learning and testing neural networks on PyTorch using Ignite</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr, in this article I will talk about the ignite library, with which you can easily train and test neural networks using the PyTorch framework. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Learning and testing neural networks on PyTorch using Ignite</h1><div class="post__text post__text-html js-mediator-article"><p>  <em>Hi, Habr, in this article I will talk about the <a href="https://pytorch.org/ignite">ignite</a> library, with which you can easily train and test neural networks using the PyTorch framework.</em> </p><br><p>  With <a href="https://pytorch.org/ignite">ignite,</a> you can write cycles for learning the network literally in a few lines, add standard metrics from the box, save the model, etc.  Well, for those who moved from TF to PyTorch, we can say that the <em>ignite</em> library is Keras for PyTorch. </p><br><p>  The article will detail the example of training a neural network for a classification task using <em>ignite</em> </p><br><p><img src="https://habrastorage.org/webt/35/ar/af/35arafc8y9aicrbpz5unazs-y-a.png"></p><a name="habracut"></a><br><h2 id="dobavim-esche-bolshe-ognya-v-pytorch">  Add more fire to PyTorch </h2><br><p>  I will not waste time talking about how <em>cool the</em> PyTorch framework is.  The one who has already used it, understands what I am writing about.  But, with all its merits, it is still low-level in terms of writing cycles for learning, testing, testing neural networks. </p><br><p>  If we look at the <a href="https://github.com/pytorch/examples">official examples of</a> using the PyTorch framework, we will see in the training code of the grid at least two cycles of iterations per epoch and training sample batch: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, epochs + <span class="hljs-number"><span class="hljs-number">1</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(train_loader): <span class="hljs-comment"><span class="hljs-comment"># ...</span></span></code> </pre> <br><p>  The main idea of ‚Äã‚Äãthe <a href="https://pytorch.org/ignite">ignite</a> library is to factor these cycles into a single class, while allowing the user to interact with these cycles using event handlers. </p><br><p>  As a result, in the case of standard deep learning tasks, we can pretty well save on the number of lines of code.  Less lines - less mistakes! </p><br><p>  For example, for comparison, on the left is the code for learning and validating the model using <em>ignite</em> , and on the right - on pure PyTorch: <br><img src="https://habrastorage.org/getpro/habr/post_images/914/408/b07/914408b07fa093c696e66cb15ae36bfc.png" alt="image"></p><br><p>  So again, what good is <a href="https://pytorch.org/ignite">ignite</a> ? </p><br><ul><li>  for each task, there is no need to write <code>for epoch in range(n_epochs)</code> and <code>for batch in data_loader</code> cycles <code>for epoch in range(n_epochs)</code> each task. </li><li>  allows for better factorization of the code </li><li>  allows you to calculate base metrics out of the box </li><li>  provides ‚Äúbuns‚Äù of type <br><ul><li>  saving the latest and best models (also the optimizer and learning rate scheduler) during training, </li><li>  early learning stop </li><li>  etc </li></ul></li><li>  integrates easily with visualization tools: tensorboardX, visdom, ... </li></ul><br><p>  In a sense, as already mentioned, the <a href="https://pytorch.org/ignite">ignite</a> library can be compared to all known <a href="https://keras.io/">Keras</a> and its API for learning and testing networks.  Also, the <a href="https://pytorch.org/ignite">ignite</a> library at first glance is very similar to the <a href="https://github.com/pytorch/tnt/">tnt</a> library, since initially both libraries pursued the same goals and have similar ideas for their implementation. </p><br><p>  So, we light: </p><br><pre> <code class="hljs sql">pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> pytorch-ignite</code> </pre> <br><p>  or </p><br><pre> <code class="hljs swift">conda install ignite -<span class="hljs-built_in"><span class="hljs-built_in">c</span></span> pytorch</code> </pre> <br><p>  Further on a concrete example we will look at the API library <a href="https://pytorch.org/ignite">ignite</a> . </p><br><h2 id="zadacha-klassifikacii-s-ignitehttpspytorchorgignite">  Classification task with <a href="https://pytorch.org/ignite">ignite</a> </h2><br><p>  In this part of the article, we will consider a <em>school</em> example of learning a neural network for a classification task using the <a href="https://pytorch.org/ignite">ignite</a> library. </p><br><p>  So, let's take a simple dataset with pictures of fruit with <a href="https://www.kaggle.com/moltean/fruits">kaggle</a> .  The task is to compare each class with fruit to the corresponding class. </p><br><p>  Before using <a href="https://pytorch.org/ignite">ignite</a> , let's define the main components: </p><br><p>  Data flow (dataflow): </p><br><ul><li>  trainer batch bootloader, <code>train_loader</code> </li><li>  check sample fetch batch loader, <code>val_loader</code> </li></ul><br><p>  Model: </p><br><ul><li>  take a small squeezeNet grid from <code>torchvision</code> </li></ul><br><p>  Optimization Algorithm: </p><br><ul><li>  take SGD </li></ul><br><p>  Loss function: </p><br><ul><li>  Cross-entropy </li></ul><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dataset, DataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data.dataset <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Subset <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageFolder <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ColorJitter, ToTensor, Normalize FRUIT360_PATH = Path(<span class="hljs-string"><span class="hljs-string">"."</span></span>).resolve().parent / <span class="hljs-string"><span class="hljs-string">"input"</span></span> / <span class="hljs-string"><span class="hljs-string">"fruits-360_dataset"</span></span> / <span class="hljs-string"><span class="hljs-string">"fruits-360"</span></span> device = <span class="hljs-string"><span class="hljs-string">"cuda"</span></span> train_transform = Compose([ RandomHorizontalFlip(), RandomResizedCrop(size=<span class="hljs-number"><span class="hljs-number">32</span></span>), ColorJitter(brightness=<span class="hljs-number"><span class="hljs-number">0.12</span></span>), ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>]) ]) val_transform = Compose([ RandomResizedCrop(size=<span class="hljs-number"><span class="hljs-number">32</span></span>), ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>]) ]) batch_size = <span class="hljs-number"><span class="hljs-number">128</span></span> num_workers = <span class="hljs-number"><span class="hljs-number">8</span></span> train_dataset = ImageFolder((FRUIT360_PATH /<span class="hljs-string"><span class="hljs-string">"Training"</span></span>).as_posix(), transform=train_transform, target_transform=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) val_dataset = ImageFolder((FRUIT360_PATH /<span class="hljs-string"><span class="hljs-string">"Test"</span></span>).as_posix(), transform=val_transform, target_transform=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.models.squeezenet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> squeezenet1_1 model = squeezenet1_1(pretrained=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">81</span></span>) model.classifier[<span class="hljs-number"><span class="hljs-number">-1</span></span>] = nn.AdaptiveAvgPool2d(<span class="hljs-number"><span class="hljs-number">1</span></span>) model = model.to(device)</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.optim <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGD optimizer = SGD(model.parameters(), lr=<span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) criterion = nn.CrossEntropyLoss()</code> </pre> </div></div><br><p>  So now it's time to start <a href="https://pytorch.org/ignite">ignite</a> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Engine, _prepare_batch <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.train() optimizer.zero_grad() x, y = _prepare_batch(batch, device=device) y_pred = model(x) loss = criterion(y_pred, y) loss.backward() optimizer.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loss.item() trainer = Engine(process_function)</code> </pre> <br><p>  Let's see what this code means. </p><br><h3 id="dvizhok-engine">  Engine <code>Engine</code> </h3><br><p>  The class <code>ignite.engine.Engine</code> is the framework of the library, and the object of this class is <code>trainer</code> : </p><br><pre> <code class="python hljs">trainer = Engine(process_function)</code> </pre> <br><p>  It is defined with the <code>process_function</code> input function for processing a single batch and serves to implement passes through the training set.  Inside the <code>ignite.engine.Engine</code> class, the following happens: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> epoch &lt; max_epochs: <span class="hljs-comment"><span class="hljs-comment"># run once on data for batch in data: output = process_function(batch)</span></span></code> </pre> <br><p>  Let's return to the <code>process_function</code> function: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.train() optimizer.zero_grad() x, y = _prepare_batch(batch, device=device) y_pred = model(x) loss = criterion(y_pred, y) loss.backward() optimizer.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loss.item()</code> </pre> <br><p>  We see that inside the function we, as usual in the case of learning the model, calculate the predictions <code>y_pred</code> , calculate the loss function <code>loss</code> and gradients.  The latter allow updating model weights: <code>optimizer.step()</code> . </p><br><p>  In general, there are no restrictions on the <code>process_function</code> function code.  We only note that it takes two arguments as input: an <code>Engine</code> object ( <code>trainer</code> in our case) and a batch from the data loader.  Therefore, for example, to test a neural network, we can define another object of the <code>ignite.engine.Engine</code> class, in which the input function simply calculates the predictions, and implement a pass through the test sample one single time.  Read about it below. </p><br><p>  So, the above code only defines the necessary objects without running the training.  In principle, in the minimal example, you can call the method: </p><br><pre> <code class="python hljs">trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> <br><p>  and this code is enough to "quietly" (without any output of intermediate results) train the model. </p><br><div class="spoiler">  <b class="spoiler_title">The note</b> <div class="spoiler_text"><p>  Note also that for tasks of this type the library has a convenient method for creating a <code>trainer</code> object: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_supervised_trainer trainer = create_supervised_trainer(model, optimizer, criterion, device)</code> </pre> </div></div><br><p>  Of course, in practice, the above example is of little interest, so let's add the following options for the ‚Äútrainer‚Äù: </p><br><ul><li>  display of the loss function value every 50 iterations </li><li>  running the calculation of metrics on the training set with a fixed model </li><li>  running the calculation of metrics on the test sample after each epoch </li><li>  saving model parameters after each epoch </li><li>  keeping the top three models </li><li>  change in learning rate depending on the era (learning rate scheduling) </li><li>  early-stopping </li></ul><br><h3 id="sobytiya-i-obrabotchiki-sobytiy">  Events and Event Handlers </h3><br><p>  To add the above options for the trainer, the <a href="https://pytorch.org/ignite">ignite</a> library provides an event system and the launch of custom event handlers.  Thus, the user can control an <code>Engine</code> class object at each stage: </p><br><ul><li>  engine started / completed launch </li><li>  era began / ended </li><li>  batch iteration started / ended </li></ul><br><p>  and run your code on every event. </p><br><h4 id="vyvod-na-ekran-znacheniya-funkcii-poter">  Display of loss function values </h4><br><p>  To do this, simply define the function in which the output will be displayed on the screen, and add it to the "trainer": </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Events log_interval = <span class="hljs-number"><span class="hljs-number">50</span></span> @trainer.on(Events.ITERATION_COMPLETED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_training_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> iteration = (engine.state.iteration - <span class="hljs-number"><span class="hljs-number">1</span></span>) % len(train_loader) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> iteration % log_interval == <span class="hljs-number"><span class="hljs-number">0</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}"</span></span> .format(engine.state.epoch, iteration, len(train_loader), engine.state.output))</code> </pre> <br><p>  Actually there are two ways to add an event handler: via <code>add_event_handler</code> , or through the <code>on</code> decorator.  The same as above can be done like this: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Events log_interval = <span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_training_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># ... trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)</span></span></code> </pre> <br><p>  Note that any arguments can be passed to the event handling function.  In general, this function will look like this: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_handler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">pass</span></span> trainer.add_event_handler(Events.ITERATION_COMPLETED, custom_handler, *args, **kwargs) <span class="hljs-comment"><span class="hljs-comment">#  @trainer.on(Events.ITERATION_COMPLETED, *args, **kwargs) def custom_handler(engine, *args, **kwargs): pass</span></span></code> </pre> <br><p>  So, let's start training on one epoch and see what happens: </p><br><pre> <code class="python hljs">output = trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[50/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.3459</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[100/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.2801</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[150/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.2294</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[200/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.1467</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[250/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 3<span class="hljs-selector-class"><span class="hljs-selector-class">.8607</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[300/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 3<span class="hljs-selector-class"><span class="hljs-selector-class">.6688</span></span></code> </pre> <br><p>  Not bad!  Come on. </p><br><h4 id="zapusk-rascheta-metrik-na-obuchayuschey-i-testovoy-vyborkah">  Running the calculation of metrics on the training and test samples </h4><br><p>  Let's calculate the following metrics: average accuracy, average completeness after each epoch on the part of the training and the entire test sample.  Note that we will calculate the metrics on the part of the training sample after each training epoch, and not during the training.  Thus, the measurement of efficiency will be more accurate, since the model does not change during the calculation. </p><br><p>  So, we define the metrics: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Loss, CategoricalAccuracy, Precision, Recall metrics = { <span class="hljs-string"><span class="hljs-string">'avg_loss'</span></span>: Loss(criterion), <span class="hljs-string"><span class="hljs-string">'avg_accuracy'</span></span>: CategoricalAccuracy(), <span class="hljs-string"><span class="hljs-string">'avg_precision'</span></span>: Precision(average=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), <span class="hljs-string"><span class="hljs-string">'avg_recall'</span></span>: Recall(average=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) }</code> </pre> <br><p>  Next, we will create two engines for evaluating the model using <code>ignite.engine.create_supervised_evaluator</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_supervised_evaluator <span class="hljs-comment"><span class="hljs-comment"># ,  device = ‚Äúcuda‚Äù    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device) val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)</span></span></code> </pre> <br><p>  We create two engines so that we can attach additional event handlers to one of them ( <code>val_evaluator</code> ) to save the model and stop learning early (more on this later). </p><br><p>  Let's also take a closer look at how the engine for model evaluation is defined, namely, how the <code>process_function</code> input function is defined for processing a single batch: </p><br><pre> <code class="hljs python"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_supervised_evaluator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, metrics={}, device=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> device: model.to(device) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_inference</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.eval() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): x, y = _prepare_batch(batch, device=device) y_pred = model(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y_pred, y engine = Engine(_inference) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> name, metric <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> metrics.items(): metric.attach(engine, name) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> engine</code> </pre> <br><p>  We continue further.  Let us randomly select a part of the training sample on which we will calculate the metrics: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data.dataset <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Subset indices = np.arange(len(train_dataset)) random_indices = np.random.permutation(indices)[:len(val_dataset)] train_subset = Subset(train_dataset, indices=random_indices) train_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre> <br><p>  Next, let's determine at what point in the training we will start the calculation of metrics and will produce output to the screen: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@trainer.on(Events.EPOCH_COMPLETED) def compute_and_display_offline_train_metrics(engine): epoch = engine.state.epoch print("Compute train metrics...") metrics = train_evaluator.run(train_eval_loader).metrics print("Training Results - Epoch: {} Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}" .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall'])) @trainer.on(Events.EPOCH_COMPLETED) def compute_and_display_val_metrics(engine): epoch = engine.state.epoch print("Compute validation metrics...") metrics = val_evaluator.run(val_loader).metrics print("Validation Results - Epoch: {} Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}" .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))</span></span></code> </pre><br><p>  You can run! </p><br><pre> <code class="python hljs">output = trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p>  We get on the screen </p><br><pre> <code class="hljs ruby">Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">3.5112</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.9840</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.8807</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.9285</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.5026</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.1944</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.1018</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.3699 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3981</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.3686 Compute validation metrics... Validation Results - Epoch: 1 Average Loss: 2.0519 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3850</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.3578 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3845</span></span></code> </pre><br><p>  Already better! </p><br><p>  <strong>Few details</strong> <br>  Let's take a little look at the previous code.  The reader may have noticed the following line of code: </p><br><pre> <code class="python hljs">metrics = train_evaluator.run(train_eval_loader).metrics</code> </pre> <br><p>  and, probably, there was a question about the type of the object obtained from the function <code>train_evaluator.run(train_eval_loader)</code> , which has the <code>metrics</code> attribute. </p><br><p>  In fact, the <code>Engine</code> class has a structure called <code>state</code> (of type <code>State</code> ) in order to be able to pass data between event handlers.  This <code>state</code> attribute contains basic information about the current epoch, iteration, number of epochs, etc.  It can also be used to transfer any user data, including the results of calculating metrics. </p><br><pre> <code class="python hljs">state = train_evaluator.run(train_eval_loader) metrics = state.metrics <span class="hljs-comment"><span class="hljs-comment">#   train_evaluator.run(train_eval_loader) metrics = train_evaluator.state.metrics</span></span></code> </pre> <br><h5 id="raschet-metrik-vo-vremya-obucheniya">  Calculation of metrics during training </h5><br><p>  If the task is a huge learning sample and the calculation of metrics after each training epoch is expensive, and yet I would like to see some metrics change during training, then the following <code>RunningAverage</code> event handler can be used out of the box.  For example, we want to calculate and display the accuracy of the classifier: </p><br><pre> <code class="python hljs">acc_metric = RunningAverage(CategoryAccuracy(...), alpha=<span class="hljs-number"><span class="hljs-number">0.98</span></span>) acc_metric.attach(trainer, <span class="hljs-string"><span class="hljs-string">'running_avg_accuracy'</span></span>) @trainer.on(Events.ITERATION_COMPLETED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_running_avg_metrics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"running avg accuracy:"</span></span>, engine.state.metrics[<span class="hljs-string"><span class="hljs-string">'running_avg_accuracy'</span></span>])</code> </pre> <br><p>  To use the <code>RunningAverage</code> functionality, you need to install <em>ignite</em> from sources: </p><br><pre> <code class="hljs objectivec">pip install git+https:<span class="hljs-comment"><span class="hljs-comment">//github.com/pytorch/ignite</span></span></code> </pre> <br><h4 id="izmenenie-skorosti-obuchenie-learning-rate-scheduling">  Change learning speed (scheduling) </h4><br><p>  There are several ways to change the speed of learning with <em>ignite</em> .  Next, we consider the simplest method by calling the <code>lr_scheduler.step()</code> function at the beginning of each epoch. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.optim.lr_scheduler <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ExponentialLR lr_scheduler = ExponentialLR(optimizer, gamma=<span class="hljs-number"><span class="hljs-number">0.8</span></span>) @trainer.on(Events.EPOCH_STARTED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">update_lr_scheduler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> lr_scheduler.step() <span class="hljs-comment"><span class="hljs-comment">#    : if len(optimizer.param_groups) == 1: lr = float(optimizer.param_groups[0]['lr']) print("Learning rate: {}".format(lr)) else: for i, param_group in enumerate(optimizer.param_groups): lr = float(param_group['lr']) print("Learning rate (group {}): {}".format(i, lr))</span></span></code> </pre> <br><h4 id="sohranenie-luchshih-modeley-i-drugih-parametrov-vo-vremya-obucheniya">  Saving the best models and other parameters during training </h4><br><p>  During training, it would be great to record the weights of the best model on the disk, as well as periodically save the model weights, optimizer parameters, and learning speed change parameters.  The latter can be useful in order to resume learning from the last saved state. </p><br><p>  <em>Ignite</em> has a special <code>ModelCheckpoint</code> class for this.  So let's create a <code>ModelCheckpoint</code> event <code>ModelCheckpoint</code> and store the best model by the precision value on the test set.  In this case, we define the <code>score_function</code> function, which <code>score_function</code> the value of accuracy in the event handler and it decides whether to save the model or not: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.handlers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> val_avg_accuracy = engine.state.metrics[<span class="hljs-string"><span class="hljs-string">'avg_accuracy'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> val_avg_accuracy best_model_saver = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"best_models"</span></span>, filename_prefix=<span class="hljs-string"><span class="hljs-string">"model"</span></span>, score_name=<span class="hljs-string"><span class="hljs-string">"val_accuracy"</span></span>, score_function=score_function, n_saved=<span class="hljs-number"><span class="hljs-number">3</span></span>, save_as_state_dict=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, create_dir=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment"># "best_models" -    1     #   -&gt; {filename_prefix}_{name}_{step_number}_{score_name}={abs(score_function_result)}.pth # save_as_state_dict=True, #   `state_dict` val_evaluator.add_event_handler(Events.COMPLETED, best_model_saver, {"best_model": model})</span></span></code> </pre> <br><p>  Now we will create another <code>ModelCheckpoint</code> event <code>ModelCheckpoint</code> in order to save the learning state every 1000 iterations: </p><br><pre> <code class="python hljs">training_saver = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"checkpoint"</span></span>, filename_prefix=<span class="hljs-string"><span class="hljs-string">"checkpoint"</span></span>, save_interval=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_saved=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_as_state_dict=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, create_dir=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) to_save = {<span class="hljs-string"><span class="hljs-string">"model"</span></span>: model, <span class="hljs-string"><span class="hljs-string">"optimizer"</span></span>: optimizer, <span class="hljs-string"><span class="hljs-string">"lr_scheduler"</span></span>: lr_scheduler} trainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)</code> </pre> <br><p>  So, almost everything is ready, add the last element: </p><br><h4 id="rannyaya-ostanovka-obucheniya-early-stopping">  Early-stopping </h4><br><p>  Let's add another event handler that will stop learning if there is no improvement in the quality of the model over 10 epochs.  The quality of the model will again be evaluated using the score_function <code>score_function</code> . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.handlers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EarlyStopping early_stopping = EarlyStopping(patience=<span class="hljs-number"><span class="hljs-number">10</span></span>, score_function=score_function, trainer=trainer) val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)</code> </pre> <br><h3 id="zapusk-obucheniya">  Start learning </h3><br><p>  In order to run the training we just need to call the <code>run()</code> method.  We will train the model for 10 epochs: </p><br><pre> <code class="python hljs">max_epochs = <span class="hljs-number"><span class="hljs-number">10</span></span> output = trainer.run(train_loader, max_epochs=max_epochs)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Output on display</b> <div class="spoiler_text"><pre> <code class="hljs ruby">Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">01</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.7984</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.9736</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">4.3419</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.0261</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.1724</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">2.1599</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.5363</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.5177 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5477</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.5178 Compute validation metrics... Validation Results - Epoch: 1 Average Loss: 1.5116 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5139</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.5400 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5140</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span>8 Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.4076</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.4892</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.2485</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.6511</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">3.3376</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.3299</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">3.2686</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.1977 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">1792</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.1942 Compute validation metrics... Validation Results - Epoch: 2 Average Loss: 3.2772 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">1962</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.1628 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">1918</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">006400000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">9016</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.2006</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8892</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8141</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">1.4005</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8888</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7368</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.7554 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7818</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.7554 Compute validation metrics... Validation Results - Epoch: 3 Average Loss: 0.7177 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7623</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.7863 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7611</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">005120000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8490</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8493</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8100</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">9165</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">9370</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">6548</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7047</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.7713 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8040</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.7728 Compute validation metrics... Validation Results - Epoch: 4 Average Loss: 0.6737 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7778</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.7955 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7806</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">0040</span></span>96000000000001 Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">6965</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">6196</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">6194</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3986</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">6032</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">7152</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5049</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.8282 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8393</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.8314 Compute validation metrics... Validation Results - Epoch: 5 Average Loss: 0.5084 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8304</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.8386 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8328</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">003276</span></span>8000000000007 Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4433</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4764</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5578</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3684</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4847</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3811</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4383</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.8474 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8618</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.8495 Compute validation metrics... Validation Results - Epoch: 6 Average Loss: 0.4419 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8446</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.8532 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8442</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">002621440000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4447</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4602</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5345</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3973</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5023</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">5303</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4305</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.8579 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8691</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.8596 Compute validation metrics... Validation Results - Epoch: 7 Average Loss: 0.4262 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8590</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.8685 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8606</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">0020</span></span>97152000000001 Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4867</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3090</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3721</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4559</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3958</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4222</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3432</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.8818 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8895</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.8817 Compute validation metrics... Validation Results - Epoch: 8 Average Loss: 0.3644 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8713</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.8784 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8707</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">001677721600000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3557</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3692</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3510</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3446</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3966</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3451</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">9</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3315</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.8954 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">9001</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.8982 Compute validation metrics... Validation Results - Epoch: 9 Average Loss: 0.3559 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8818</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.8876 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8847</span></span> Learning <span class="hljs-symbol"><span class="hljs-symbol">rate:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">0013421772</span></span>800000006 Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3340</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3370</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3694</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3409</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">4420</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">2770</span></span> Compute train metrics... Training Results - <span class="hljs-symbol"><span class="hljs-symbol">Epoch:</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> Average <span class="hljs-symbol"><span class="hljs-symbol">Loss:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">3246</span></span> <span class="hljs-params"><span class="hljs-params">| Accuracy: 0.8921 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Precision:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8988</span></span> <span class="hljs-params"><span class="hljs-params">| Recall: 0.8925 Compute validation metrics... Validation Results - Epoch: 10 Average Loss: 0.3536 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Accuracy:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8731</span></span> <span class="hljs-params"><span class="hljs-params">| Precision: 0.8785 |</span></span> <span class="hljs-symbol"><span class="hljs-symbol">Recall:</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">8722</span></span></code> </pre> </div></div><br><p>  Now check the models and parameters saved to disk: </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">ls</span></span> best_models/ model_best_model_10_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8730994</span></span>.pth model_best_model_8_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8712978</span></span>.pth model_best_model_9_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8818188</span></span>.pth</code> </pre> <br><p>  and </p><br><pre> <code class="hljs pgsql">ls <span class="hljs-keyword"><span class="hljs-keyword">checkpoint</span></span>/ checkpoint_lr_scheduler_3000.pth checkpoint_optimizer_3000.pth checkpoint_model_3000.pth</code> </pre> <br><h3 id="predskazaniya-obuchennoy-modelyu">  Predictions by a trained model </h3><br><p>  To begin with, we will create a test data loader (for example, let's take a validation sample) so that the data batch consists of images and their indices: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Dataset)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, ds)</span></span></span><span class="hljs-function">:</span></span> self.ds = ds <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__len__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(self.ds) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__getitem__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, index)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.ds[index][<span class="hljs-number"><span class="hljs-number">0</span></span>], index test_dataset = TestDataset(val_dataset) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre> <br><p>  Using <em>ignite,</em> we will create a new prediction engine for test data.  To do this, we define the <code>inference_update</code> function, which gives the result of the prediction and the image index.  To improve accuracy, we will also use the well-known ‚Äútest time augmentation‚Äù (TTA) trick. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn.functional <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> F <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite._utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> convert_tensor <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_prepare_batch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(batch)</span></span></span><span class="hljs-function">:</span></span> x, index = batch x = convert_tensor(x, device=device) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x, index <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">inference_update</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> x, indices = _prepare_batch(batch) y_pred = model(x) y_pred = F.softmax(y_pred, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">"y_pred"</span></span>: convert_tensor(y_pred, device=<span class="hljs-string"><span class="hljs-string">'cpu'</span></span>), <span class="hljs-string"><span class="hljs-string">"indices"</span></span>: indices} model.eval() inferencer = Engine(inference_update)</code> </pre> <br><p>  Next, create event handlers that will notify about the prediction stage and save the predictions to the selected array: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inferencer.on(Events.EPOCH_COMPLETED) def log_tta(engine): print("TTA {} / {}".format(engine.state.epoch, n_tta)) n_tta = 3 num_classes = 81 n_samples = len(val_dataset) #     y_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32) @inferencer.on(Events.ITERATION_COMPLETED) def save_results(engine): output = engine.state.output tta_index = engine.state.epoch - 1 start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size end_index = min(start_index + batch_size, n_samples) batch_y_probas = output['y_pred'].detach().numpy() y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas</span></span></code> </pre> <br><p>  Before starting the process, let's load the best model: </p><br><pre> <code class="python hljs">model = squeezenet1_1(pretrained=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">64</span></span>) model.classifier[<span class="hljs-number"><span class="hljs-number">-1</span></span>] = nn.AdaptiveAvgPool2d(<span class="hljs-number"><span class="hljs-number">1</span></span>) model = model.to(device) model_state_dict = torch.load(<span class="hljs-string"><span class="hljs-string">"best_models/model_best_model_10_val_accuracy=0.8730994.pth"</span></span>) model.load_state_dict(model_state_dict)</code> </pre> <br><p>  Run: </p><br><pre> <code class="python hljs">inferencer.run(test_loader, max_epochs=n_tta) &gt; TTA <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; TTA <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; TTA <span class="hljs-number"><span class="hljs-number">3</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><p>  Next, in a standard way, we take the average of the predictions of TTA and calculate the index of the class with the highest probability: </p><br><pre> <code class="python hljs">y_probas = np.mean(y_probas_tta, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>) y_preds = np.argmax(y_probas, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)</code> </pre> <br><p>  And now we can calculate once again the accuracy of the model according to the obtained predictions: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score y_test_true = [y <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _, y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> val_dataset] accuracy_score(y_test_true, y_preds) &gt; <span class="hljs-number"><span class="hljs-number">0.9310369676443035</span></span></code> </pre> <br><p> ,     ,          .   ,   ,      ,    <em>ignite</em>      . </p><br><h2 id="drugie-primery-s-ignitehttpspytorchorgignite">    <a href="https://pytorch.org/ignite">ignite</a> </h2><br><p>       <a href="https://www.kaggle.com/vfdev5/pytorch-and-ignite-on-fruits-360"></a> . </p><br><p>  github      <a href="https://github.com/pytorch/ignite/tree/master/examples"> </a>       </p><br><ul><li> fast neural transfer </li><li> reinforcement learning </li><li> dcgan </li></ul><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>    ,   <a href="https://pytorch.org/ignite">ignite</a>      Facebook           (.   ).        0.1.0,   API (Engine, State, Events, Metric, ...)           .       ,      ,     ,     pull request-  <a href="https://github.com/pytorch/ignite"> github</a> . </p><br><p>  Thanks for attention! </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/424781/">https://habr.com/ru/post/424781/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../424767/index.html">We make from Habr cake. Again</a></li>
<li><a href="../424771/index.html">Personal experience: from the idea and a clean slate to a draft version of the site</a></li>
<li><a href="../424773/index.html">Biopharma and numerical modeling: Amgen's experience and practice</a></li>
<li><a href="../424777/index.html">Using Consul to scale stateful services</a></li>
<li><a href="../424779/index.html">Multi-page SPA on Python</a></li>
<li><a href="../424787/index.html">Interview with Aaron Patterson, speaker of the RubyRussia 2018 conference</a></li>
<li><a href="../424789/index.html">How to deploy a Ruby on Rails application with HAProxy Ingress, unicorn / puma, and web sockets</a></li>
<li><a href="../424791/index.html">Expansion of network capabilities of a programmable relay using WI-FI</a></li>
<li><a href="../424793/index.html">How to print an electric motor</a></li>
<li><a href="../424795/index.html">How big can a solar-powered drone be?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>