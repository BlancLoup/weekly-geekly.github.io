<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>High Performance Computing: Problems and Solutions</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Computers, even personal, are becoming increasingly difficult. Not so long ago, in the box buzzing on the table, everything was simple - the higher th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>High Performance Computing: Problems and Solutions</h1><div class="post__text post__text-html js-mediator-article">  Computers, even personal, are becoming increasingly difficult.  Not so long ago, in the box buzzing on the table, everything was simple - the higher the frequency, the greater the performance.  Now the systems have become multi-core, multi-processor, specialized accelerators have appeared in them, computers are increasingly being combined into clusters. <br>  What for?  How to understand all this diversity? <br>  What does SIMD, SMP, GPGPU and other scary words mean more and more often? <br>  What are the limits of applicability of existing productivity technologies? <br><br><h4>  Introduction </h4><br><h5>  Where are the difficulties? </h5><br>  Computer power is growing rapidly and all the time it seems that everything is enough for the existing speed. <br>  But no - growing productivity allows you to solve problems that previously could not be risen.  Even at the household level, there are tasks that will load your computer for a long time, for example, home video encoding.  In industry and science, such tasks are even greater: huge databases, molecular dynamics calculations, modeling of complex mechanisms ‚Äî automobiles, jet engines ‚Äî all of this requires increasing computing power. <br>  In previous years, the main productivity growth was provided fairly simply by reducing the size of microprocessor elements.  At the same time, power consumption fell and work frequencies grew, computers became faster and faster, retaining, in general terms, their architecture.  The microchip manufacturing process changed and megahertz grew into gigahertz, delighting users with increased productivity, because if ‚Äúmega‚Äù is a million, then ‚Äúgig‚Äù is already a billion operations per second. <br>  But, as you know, paradise is either not forever, or not for everyone, and not so long ago it has ended in the computer world.  It turned out that the frequency cannot be increased further - leakage currents grow, processors overheat and it does not work around it.  You can, of course, develop cooling systems, use water radiators, or cool with liquid nitrogen ‚Äî but this is not available to every user, only for supercomputers or technomaniacs.  Yes, and with any cooling, the possibility of growth was small, about two times maximum, which was unacceptable for users accustomed to a geometric progression. <br>  It seemed that Moore's law, according to which the number of transistors and the associated computer performance doubled every one and a half to two years, would cease to operate. <br>  It's time to think and experiment, remembering all the possible ways to increase the speed of calculations. <br><a name="habracut"></a><br><h5>  Performance formula </h5><br>  Take the most general performance formula: <br><br><img src="https://habrastorage.org/storage/f8f4efeb/d3e86848/815f4ba6/28480d14.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We see that performance can be measured in the number of executable instructions per second. <br>  Let us write the process in more detail, we introduce a clock frequency there: <br><br><img src="https://habrastorage.org/storage/3fdcc1e3/6a276d86/e890e894/e4298c4b.png"><br><br>  The first part of the resulting work is the number of instructions executed per clock (IPC, Instruction Per Clock), the second is the number of processor cycles per unit of time, the clock frequency. <br>  Thus, to increase performance, you must either raise the clock frequency or increase the number of instructions executed per clock cycle. <br>  Because  the increase in frequency has stopped, it is necessary to increase the number of instructions executed ‚Äúat a time‚Äù. <br><br><h4>  Enable parallelism </h4><br>  How to increase the number of instructions executed per cycle? <br>  Obviously, performing several instructions at a time, in parallel.  But how to do that? <br>  It all depends on the program being executed. <br>  If the program is written by the programmer as single-threaded, where all instructions are executed sequentially, one after another, the processor (or compiler) will have to ‚Äúthink for a man‚Äù and look for parts of the program that can be executed simultaneously, parallelized. <br><br><h4>  Instruction level parallelism </h4><br>  Take a simple program: <br> <code>a = 1 <br> b = 2 <br> c = a + b <br></code> <br>  The first two instructions can be carried out in parallel, only the third depends on them.  So, the whole program can be completed in two steps, not three. <br>  <i><b>A processor that is able to determine independent and non-contradictory instructions and execute them in parallel is called a superscalar processor</b></i> . <br>  Many modern processors, including the latest x86 - superscalar processors, but there is another way: to simplify the processor and to assign the search for parallelism to the compiler.  At the same time, the processor executes commands in ‚Äúbundles‚Äù that the compiler has prepared for the program, in each such ‚Äúbundle‚Äù - a set of instructions that are independent of each other and can be executed in parallel.  Such an architecture is called <b>VLIW (very long instruction word - ‚Äúvery long machine command‚Äù),</b> its further development was called <b>EPIC (explicitly parallel instruction computing) - microprocessor architecture with explicit command parallelism)</b> <br>  The most famous processors with this architecture are Intel Itanium. <br>  There is a third way to increase the number of instructions executed per cycle, this is <b>Hyper Threading Technology.</b> In this technology, the superscalar processor independently parallelizes not commands of one thread, but commands of several (in modern processors ‚Äî two) parallel launched threads. <br>  Those.  physically, the processor core is one, but idle when performing one task, processor power can be used to perform another.  The operating system sees one processor (or one processor core) with Hyper Threading as two independent processors.  But in fact, of course, Hyper Threading works worse than real two independent processors.  tasks on it will compete for computing power among themselves. <br><br>  Concurrency technologies at the instruction level were actively developed in the 90s and the first half of the 2000s, but at present their potential is almost exhausted.  You can rearrange commands, rename registers and use other optimizations, extracting parallel-running sections from sequential code, but dependencies and branches will not allow you to fully parallelize the code.  Parallelism at the level of instructions is good because it does not require human intervention - but this is not good: while a person is smarter than a microprocessor, he will have to write a truly parallel code. <br><br><h4>  Data Level Concurrency </h4><br><h5>  Vector processors </h5><br>  We have already mentioned scalarity, but besides a scalar there is a vector, and besides superscalar processors there are vector ones. <br>  Vector processors perform some kind of operation on whole data arrays, vectors.  In a ‚Äúpure‚Äù form, vector processors were used in supercomputers for scientific computing in the 1980s. <br>  According <a href="http://parallel.ru/computers/taxonomy/flynn.html">to Flynn‚Äôs classification</a> , vector processors are <b>SIMD - (single instruction, multiple data - a single command stream, a multiple data stream)</b> . <br>  Currently, x86 processors implement many vector extensions - these are MMX, 3DNow !, SSE, SSE2, etc. <br>  Here is how, for example, multiplication of four pairs of numbers with one command using SSE looks like: <br><br> <code>float a[4] = { 300.0, 4.0, 4.0, 12.0 }; <br> float b[4] = { 1.5, 2.5, 3.5, 4.5 }; <br> __asm { <br> movups xmm0, a ; //  4      a   xmm0 <br> movups xmm1, b ; //  4      b   xmm1 <br> mulps xmm1, xmm0 ; //    : xmm1=xmm1*xmm0 <br> movups a, xmm1 ; //     xmm1   a <br> }; <br></code> <br><br>  Thus, instead of four consecutive scalar multiplications, we made only one - vector. <br>  Vector processors can significantly speed up computations on large amounts of data, but their scope is limited, typical operations on fixed arrays are far from being applicable everywhere. <br>  However, the race of vectorization of calculations is far from over - so in the latest Intel processors a new vector extension AVX (Advanced Vector Extension) appeared <br>  But much more interesting now look <br><br><h5>  GPUs </h5><br>  The theoretical computing power of processors in modern video cards is growing much faster than in conventional processors (see the famous NVIDIA image) <br><img src="https://habrastorage.org/storage/4b9ceddf/f65cbd20/35f6e5fc/173b0ebe.png"><br>  Not so long ago, this power was adapted for universal high-performance computing using CUDA / OpenCL. <br>  The architecture of graphic processors (GPGPU, General Purpose computation on GPU - universal calculations by means of a video card), is close to the already considered SIMD. <br>  It is called <b>SIMT - (single instruction, multiple threads, one instruction - multiple threads)</b> .  Just as in SIMD, operations are performed with data arrays, but there are much more degrees of freedom ‚Äî for each cell of the data being processed, there is a separate command string. <br>  As a result <br>  1) In parallel, hundreds of operations can be performed on hundreds of data cells. <br>  2) In each stream, an arbitrary sequence of commands is executed; it can access different cells. <br>  3) Branching is possible.  However, in parallel, only threads with the same sequence of operations can be executed in parallel. <br><br>  GPGPUs allow you to achieve impressive results on some tasks.  but there are fundamental limitations that do not allow this technology to become a universal magic wand, namely <br>  1) It is possible to accelerate on a GPU only by a code that is well parallelized by data. <br>  2) GPU uses its own memory.  Transferring data between GPU memory and computer memory is quite expensive. <br>  3) Algorithms with a large number of branches work on the GPU inefficiently <br><br><h4>  Multiarchitecture- </h4><br>  So, we have reached completely parallel architectures - independently parallel, both by commands and by data. <br>  In Flynn's classification, this is <b>MIMD (Multiple Instruction stream, Multiple Data stream - Multiple Command stream, Multiple Data stream).</b> <br>  To use all the power of such systems, multi-threaded programs are needed, their execution can be ‚Äúscattered‚Äù into several microprocessors and thereby achieve an increase in productivity without an increase in frequency.  Various technologies of multithreading have long been used in supercomputers, they are now ‚Äúdescended from heaven‚Äù to ordinary users, and a multi-core processor is more a rule than an exception.  But multi-core is not a panacea. <br><br><h5>  Severe law, but it is the law </h5><br>  Parallelism is a good way to get around the limitation of clock speed growth, but it has its own limitations. <br>  First of all, this is the <b>law of Amdal</b> , which states <br>  <b>Acceleration of the program execution due to parallelization of its instructions on the set of calculators is limited by the time required to execute its sequential instructions.</b> <br><br>  The acceleration of the code depends on the number of processors and the parallelism of the code according to the formula <br><br><img src="https://habrastorage.org/storage/075bb631/b4d3edcf/452b58ba/e1c5db51.png"><br><br>  Indeed, using parallel execution, we can speed up the execution time of only parallel code. <br>  In any program except parallel code, there are also consecutive sections and it will not be possible to speed them up by increasing the number of processors, only one processor will work on them. <br><br>  <i>For example, if the execution of sequential code takes only 25% of the execution time of the entire program, then it will not be possible to speed up this program more than 4 times.</i> <br>  Let's build a graph of the dependence of the acceleration of our program on the number of parallel computing computers-processors.  Substituting in the formula 1/4 of the sequential code and 3/4 of the parallel code, we get <br><img src="https://habrastorage.org/storage/ea2b93b2/7cb22489/c7464de1/2621dc66.png"><br><br>  Is it sad  And how. <br>  The world's fastest supercomputer with thousands of processors and terabytes of memory on our, it seems, even a good (75%!) Parallel task, less than twice as fast as a regular desktop quad core. <br>  And still worse than in this ideal case.  In the real world, the costs of ensuring parallelism are never equal to zero, and therefore when adding more and more new processors, performance will start to fall from a certain point. <br>  But how, then, is the power of modern very, very multi-core supercomputers used? <br>  In many algorithms, the execution time of a parallel code strongly depends on the amount of data processed, and the execution time of a sequential code is not.  The more data you need to process, the greater the gain from parallel processing.  Therefore, by ‚Äúdriving‚Äù large amounts of data to the supercomputer, we get good acceleration. <br>  For example, multiplying 3 * 3 matrices on a supercomputer, we hardly notice the difference with the usual single-processor version, but multiplying matrices with a size of 1000 * 1000 will already be fully justified on a multi-core machine. <br>  There is such a simple example: 9 women in 1 month cannot give birth to one child.  Parallelism does not work here.  But the same 81 women in 9 months can give birth (take maximum efficiency!) 81 children, that is, we get the maximum theoretical performance from increased parallelism, 9 children per month or, on average, the same one child per month for 9 women . <br>  Big computers - big tasks! <br><br><h5>  Multiprocessor </h5><br>  <b>A multiprocessor</b> is a computer system that contains several processors and one that is visible to all processors.  address space. <br>  Multiprocessors differ in the organization of work with memory. <br><br><h6>  Shared memory systems </h6><br>  In such systems, multiple processors (and processor caches) have access to the same physical RAM.  Such a model is often called symmetric multiprocessing (SMP).  Access to memory in such a system is called UMA (uniform memory access, uniform access) because  Any processor can access any memory location and the speed of this access is independent of the memory address.  However, each microprocessor can use its own cache. <br><img src="https://habrastorage.org/storage/d62ed8a1/c508a0a6/2b56a234/7d77bbab.png"><br>  Several processor cache subsystems are usually connected to shared memory via the bus. <br><br>  Let's look at the picture. <br>  What is good with us? <br>  Any processor accesses all memory and it all works the same.  Programming for such systems is easier than for any other multiarchitecture.  The bad thing is that all processors access memory through the bus, and as the number of processing cores grows, the capacity of this bus quickly becomes a bottleneck. <br>  Adds headaches and the problem of ensuring the coherence of caches. <br><br><h6>  Cache coherence </h6><br>  Suppose we have a multiprocessor computer.  Each processor has its own cache, well, as in the figure above.  Let several processors read a memory cell, and it got into their caches.  It's okay, as long as this cell is unchanged - it is read from fast caches and is somehow used in calculations. <br>  If, as a result of the program, one of the processors changes this memory cell so that there is no mismatch, so that all other processors ‚Äúsee‚Äù this update will have to change the contents of the cache of <b>all</b> processors and somehow slow them down for the duration of this update. <br>  It is good if the number of cores / processors is 2, like in a desktop computer, and if 8 or 16?  And if they all exchange data through a single bus? <br>  Performance losses can be very significant. <br><br><h6>  Multi-core processors </h6><br>  How to reduce the load on the tire? <br>  First of all, you can stop using it to ensure coherence.  What is the easiest way to do this? <br>  Yes, yes, use shared cache.  This is how most modern multi-core processors work. <br><img src="https://habrastorage.org/storage/cd41222b/2da69b2f/95f90d8a/89358443.png"><br>  Let's look at the picture, find two differences from the previous one. <br>  Yes, the cache is now one for all, respectively, the problem of coherence is not worth it.  And the circles turned into rectangles, it symbolizes the fact that all the cores and caches are on the same chip.  In reality, the picture is somewhat more complicated, the caches are multilevel, some are common, some are not, a special bus can be used for communication between them, but all <b>true</b> multi-core processors do not use an external bus to ensure cache coherence, which means they reduce the load on it. <br>  Multi-core processors - one of the main ways to improve the performance of modern computers. <br>  Six nuclear processors are already being produced, in the future there will be even more cores ... where are the limits? <br>  First of all, the ‚Äúnuclearity‚Äù of processors is limited by heat generation, the more transistors simultaneously working in one chip, the more this crystal heats, the harder it is to cool it. <br>  And the second big limitation is, again, the throughput of the external bus.  Many cores require a lot of data to grind them, the bus speed is no longer enough, you have to give up SMP in favor <br><br><h6>  NUMA </h6><br>  <b>NUMA (Non-Uniform Memory Access - ‚ÄúNon-uniform Memory Access‚Äù or Non-Uniform Memory Architecture - ‚ÄúNon-Uniform Memory Architecture‚Äù) is an architecture in which, with a common address space, the speed of memory access depends on its location</b> . there is ‚Äúown‚Äù memory, access to which is faster and ‚Äúalien‚Äù, access to which is slower. <br>  In modern systems, it looks like this <br><br><img src="https://habrastorage.org/storage/7076d50c/c202edbe/d4498bb4/9d8331bf.png"><br><br>  The processors are connected to memory and to each other using a fast bus, in the case of AMD this is <i>Hyper Transport,</i> in the case of the latest Intel processors it is <i>QuickPath Interconnect</i> <br>  Because  There is no common for all tires, when working with "its" memory, it ceases to be a bottleneck of the system. <br>  NUMA architecture allows you to create quite productive multiprocessor systems, and given the multi-core modern processors, we‚Äôll get a very serious computing power ‚Äúin one package‚Äù, limited mainly by the complexity of ensuring the cache coherence of this processor and memory confusion. <br>  But if we need more power, we will have to combine several multiprocessors into <br><br><h5>  Multicomputer </h5><br><br>  A multicomputer is a computer system without shared memory, consisting of a large number of interconnected computers (nodes), each of which has its own memory.  When working on a common task, multicomputer nodes interact by sending messages to each other. <br>  Modern multicomputers built from a variety of typical parts are called computational clusters. <br>  Most modern supercomputers are built on a cluster architecture, they combine many computing nodes using a fast network (Gigabit Ethernet or InfiniBand) and allow you to achieve the maximum possible with modern development of science computing power. <br>  The problems limiting their power are also rather big <br>  It: <br>  1) System programming with thousands of computing processors operating in parallel <br>  2) Giant power consumption <br>  3) Difficulty leading to fundamental unreliability <br><br><h4>  Putting it all together </h4><br>  Well, in short, we ran through almost all the technologies and principles of building powerful computing systems. <br>  Now there is an opportunity to imagine the structure of a modern supercomputer. <br>  This is a multicomputer cluster, each node of which is a NUMA or SMP system with several processors, each of the processors with several cores, each core with the possibility of superscalar internal parallelism and vector extensions.  On top of all this, GPGPU accelerators are installed in many supercomputers. <br>  All these technologies have advantages and limitations, there are subtleties in the application. <br>  And now try to efficiently download and program all this magnificence! <br>  The task is not trivial ... but very interesting. <br>  What will happen next? <br><br><h5>  Information sources </h5><br>  The course <a href="http://hpcu.ru/courses/29">"Basics of parallel computing"</a> Internet University supercomputer technology <br>  <a href="http://parallel.ru/computers/taxonomy/flynn.html">Flynn's classification</a> on parallels.ru <br>  <a href="http://ece.uic.edu/~wenjing/courses/fa08ECE569/ECE569/w21.pdf">MultiProcessors, their Memory Organizations and Implementations by Intel &amp; AMD</a> <br>  <a href="http://www.ict.edu.ru/ft/005646/62323e1-st10.pdf">Multi-core as a way to increase computing system performance</a> <br>  Wikipedia and the Internet <br><br>  PS The text was born as an attempt to sort out and organize in my head information about technologies in the field of high-performance computing.  Inaccuracies and errors are possible, I will be very grateful for comments and comments. </div><p>Source: <a href="https://habr.com/ru/post/117021/">https://habr.com/ru/post/117021/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../117014/index.html">Almaty GTUG - first meeting</a></li>
<li><a href="../117015/index.html">Idea. Free public hosting</a></li>
<li><a href="../117017/index.html">Happy Birthday, Runet!</a></li>
<li><a href="../117018/index.html">JetBrains RubyMine 3.1.1 Released</a></li>
<li><a href="../117019/index.html">Using Flash Player Debugger in Google Chrome</a></li>
<li><a href="../117022/index.html">Happy Birthday Runet! 99 .RU domains from REG.RU as a gift!</a></li>
<li><a href="../117024/index.html">Testing a new VPS platform from Majordomo</a></li>
<li><a href="../117025/index.html">WordPress search plugin. More than search with Sphinx Search</a></li>
<li><a href="../117027/index.html">ADCSpb # 4. Memory management</a></li>
<li><a href="../117028/index.html">Update BIOS on Eee PC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>