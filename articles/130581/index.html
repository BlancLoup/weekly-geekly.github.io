<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Recirculating Neural Networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recirculating neural networks are multilayered neural networks with inverse propagation of information. In this case, the reverse distribution of info...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Recirculating Neural Networks</h1><div class="post__text post__text-html js-mediator-article">  Recirculating neural networks are multilayered neural networks with inverse propagation of information.  In this case, the reverse distribution of information occurs through bidirectional links, which have different weights in different directions.  During the back propagation of signals, in such networks they are transformed in order to restore the input image.  In the case of direct signal propagation, the input data is compressed.  Recycling networks are trained without a teacher. <br><a name="habracut"></a><br>  Recirculation networks are characterized by both direct Y = f (X) and inverse X = f (Y) information conversion.  The task of such a transformation is to achieve the best auto-prediction or self-reproducibility of the vector X. Recirculating neural networks are used to compress (direct transform) and restore the original (inverse transform) information.  Such networks are self-organizing in the process of work.  They were offered in 1988.  The theoretical basis of recirculation neural networks is the analysis of the main components. <br><br><h4>  Principal component method </h4><br>  The principal component method is used in statistics to compress information without significant loss of information content.  It consists in a linear orthogonal transformation of the input vector X of dimension n to the output vector Y of dimension p, where p &lt;n.  In this case, the components of the vector Y are uncorrelated and the total dispersion after transformation remains unchanged.  The set of input patterns will be represented in the form of a matrix: <br><br><img src="http://habrastorage.org/storage1/b9c202ce/5e175db9/ed340889/e9f44496.png"><br>  Where <br><img src="https://habrastorage.org/storage1/31bc67c2/39437d92/2fd51850/72518c4c.png"><br>  corresponds to the k-th input image, L is the total number of images. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We assume that the matrix X is centered, that is, the expectation vector Œº = 0.  This is achieved through the following transformations: <br><img src="https://habrastorage.org/storage1/09342053/45896e2e/fa975892/7cb8f07b.png"><br><br>  The covariance matrix of input data X is defined as <br><img src="https://habrastorage.org/storage1/b2f7cb96/97b74749/bbba9e62/dca48b0f.png"><br>  where œÉij is the covariance between the i-th and j-th component of the input images. <br><br>  The elements of the covariance matrix can be calculated as follows: <br><img src="https://habrastorage.org/storage1/96fed7cb/031e2a67/ddb65e88/c84950f0.png"><br>  where i, j = 1, ..., n. <br><br>  The principal component method is to find such linear combinations of source variables. <br><img src="https://habrastorage.org/storage1/4535845b/31a99abe/8d63f352/7aa0e4b2.png"><br>  what <br><img src="https://habrastorage.org/storage1/25edb2ac/19cfa326/810ae63f/b1875a2a.png"><br><br>  From the last expressions, it follows that the variables i are uncorrelated, ordered by the increase in the variance, and the sum of the variances of the input images remains unchanged.  Then the subset of the first p variables y characterizes most of the total variance.  The result is a representation of the input information. <br><br>  The variables y, i = 1, ..., p are called the main components.  In matrix form, the transformation of the principal components can be represented as <br><img src="https://habrastorage.org/storage1/e4d46a68/8dee5653/cd3dbc8c/05e46e32.png"><br>  where the rows of the WT matrix must satisfy the orthogonality condition, i.e. <br><img src="https://habrastorage.org/storage1/1e2feafa/57009c0e/d52ae0f4/ccb1287a.png"><br>  the vector Wi is defined as <br><img src="https://habrastorage.org/storage1/117494fb/1086431e/6f898cfc/920610e0.png"><br><br>  To determine the principal components, it is necessary to determine the weight coefficients Wi, j = 1, ..., p. <br><br><h4>  Recycle Neural Network Architecture </h4><br>  A recirculating neural network is a combination of two layers of neural elements that are interconnected by bidirectional connections. <br><img src="https://habrastorage.org/storage1/df589684/38a75e4b/38a9485a/230d3daf.png"><br><br>  Each of the layers of neural elements can be used as input or output.  If the layer of neural elements serves as an input, then it performs distribution functions. <br><br>  Otherwise, the neural elements of the layer are processing.  The weighting coefficients corresponding to direct and feedback are characterized by a matrix of weighting factors W and W '.  For clarity, the recirculation network can be presented in expanded form. <br><br>  Such a network representation is equivalent and characterizes the complete information conversion cycle.  In this case, the intermediate layer of neural elements encodes (compressed) the input data X, and the last layer recovers the compressed information Y. Call the neural network layer corresponding to the connection matrix W direct, and the corresponding connection matrix W 'reverse. <br><br>  The recirculation network is designed for both data compression and recovery of compressed information.  Data compression is carried out by direct conversion of information into accordance with the expression: <br><img src="https://habrastorage.org/storage1/a0557df7/fd475816/99815b06/3f4bea59.png"><br>  Data recovery or reconstruction occurs during the inverse transformation of information: <br><img src="https://habrastorage.org/storage1/4e2bb501/ed40a10d/799ceae1/8049357c.png"><br><br>  As an activation function of neural elements F, both linear and nonlinear functions can be used.  When using the linear activation function: <br><img src="https://habrastorage.org/storage1/d3a794bd/15e845bd/ba141507/e26de55f.png"><br><br>  Linear recirculation networks in which weighting factors are determined in accordance with the method of principal components are called PCA networks. <br><br><h4>  Image processing </h4><br>  Recycle neural networks can be used to compress and repair images.  The image is divided into blocks.  The block is called a window, which is assigned a recycle neural network.  The number of neurons in the first layer of the network corresponds to the dimension of the window (the number of pixels; sometimes each color is separate).  By scanning the image using the window and feeding it to the neural network, you can compress the input image.  A compressed image can be restored using reverse propagation of information. <br><br>  An example of a neural network can be seen below: <br><img src="https://habrastorage.org/storage1/6cdf29c7/083f11e7/140d578b/6715227f.png"><br><br>  On the left, the original image, on the right, the restored image after compression.  A 3 by 3 pixel window was used, the number of neurons on the second layer was 21, the maximum allowable error was 50. The compression ratio was 0.77.  It took 129 iterations to train the neural network. <br><br>  Source codes can be found <a href="https://github.com/kondratovich/jimmy-neutron-one">here</a> (or <a href="https://github.com/kondratovich/jimmy-neutron-one-java">here</a> is a faster version). </div><p>Source: <a href="https://habr.com/ru/post/130581/">https://habr.com/ru/post/130581/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../130574/index.html">TDD on the example of UrlBuilder</a></li>
<li><a href="../130577/index.html">CAP-theorem simple, accessible language</a></li>
<li><a href="../130578/index.html">FPGA. The first steps</a></li>
<li><a href="../130579/index.html">5th meeting of the DEFCON-Russia group</a></li>
<li><a href="../130580/index.html">Bare Metal Deployment - how to look at one of the most interesting innovations of System Center Virtual Machine Manager 2012 RC closer</a></li>
<li><a href="../130582/index.html">We write our bot for Google AI Challenge. Fast start</a></li>
<li><a href="../130585/index.html">And talk? Interactive development webinar for Windows Phone</a></li>
<li><a href="../130587/index.html">New tzdata time zone database address</a></li>
<li><a href="../130588/index.html">"Weakly load 40 cores?" Or a simple parallel programming contest Acceler8 2011</a></li>
<li><a href="../130589/index.html">Why I do not believe in Dart</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>