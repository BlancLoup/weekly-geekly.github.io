<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Testing and debugging MapReduce</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At Rostelecom, we use Hadoop to store and process data downloaded from multiple sources using java applications. Now we have moved to the new version ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Testing and debugging MapReduce</h1><div class="post__text post__text-html js-mediator-article"> At Rostelecom, we use Hadoop to store and process data downloaded from multiple sources using java applications.  Now we have moved to the new version of hadoop with Kerberos Authentication.  When moving, we encountered a number of problems, including the use of the YARN API.  Using Hadoop with Kerberos Authentication deserves a separate article, and in this one we‚Äôll talk about debugging Hadoop MapReduce. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/517/ccf/f7f/517ccff7f9688538cbffdd7ab838470e.png"><br><a name="habracut"></a><br>  When performing tasks in a cluster, launching a debugger is complicated by the fact that we do not know which node will process one or another part of the input data, and we cannot configure our debugger in advance. <br><br>  You can use the time-tested <code>System.out.println("message")</code> .  But how to analyze the output of <code>System.out.println("message")</code> scattered around these nodes? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We can output messages to standard error.  Everything written in stdout or stderr, <br>  sent to the appropriate log file, which can be found on the web page of the extended information about the task or in the log files. <br><br>  We can also include debugging tools in the code, update task status messages, and use custom counters to help us understand the scale of the disaster. <br><br>  The Hadoop MapReduce application can be debugged in all three modes in which Hadoop can work: <br><br><ul><li>  standalone <br></li><li>  pseudo-distributed mode <br></li><li>  fully distributed <br></li></ul><br>  In more detail we will focus on the first two. <br><br><h3>  Pseudo-distributed mode (pseudo-distributed mode) </h3><br>  Pseudo-distributed mode is used to simulate a real cluster.  And it can be used for testing in an environment as close to productive as possible.  In this mode, all Hadoop daemons will run on the same node! <br><br>  If you have a dev server or another sandbox (for example, a Virtual Machine with a customized development environment, such as Hortonworks Sanbox with HDP), you can debug the control program using remote debugging tools. <br><br>  To start debugging you need to set the value of the environment variable: <code>YARN_OPTS</code> .  Below is an example.  For convenience, you can create a startWordCount.sh file and add the necessary parameters to it to start the application. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash source /etc/hadoop/conf/yarn-env.sh export YARN_OPTS='-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=6000 ${YARN_OPTS}' yarn jar wordcount-0.0.1.jar ru.rtc.example.WordCount /input /output</span></span></code> </pre><br>  Now, running the <code>`./startWordCount.sh`</code> , we will see the message <br><br><pre> <code class="plaintext hljs">Listening for transport dt_socket at address: 6000</code> </pre><br>  It remains to configure the IDE for remote debugging (remote debugging).  I am using intellij IDEA.  Go to the menu Run -&gt; Edit Configurations ... Add a new configuration <code>Remote</code> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/344/574/fe7/344574fe735f992742437f5ba3660c31.png"><br><br>  Put a breakpoint in main and run. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e8a/cc9/8f5/e8acc98f5739b25b54630170fcd3c057.png"><br><br>  That's it, now we can debug the program as usual. <br><blockquote>  ATTENTION.  You must make sure that you are working with the latest version of the source code  If not, you may have differences in the lines in which the debugger stops. <br></blockquote><br>  In earlier versions of Hadoop, a special class was supplied that allowed you to rerun the failed task - isolationRunner.  The data that caused the crash was saved to disk at the address specified in the Hadoop environment variable mapred.local.dir.  Unfortunately, in the latest versions of Hadoop, this class is no longer available. <br><br><h3>  Standalone (local launch) </h3><br>  Standalone is the standard mode in which Hadoop operates.  It is suitable for debugging where HDFS is not used.  With this debugging, you can use input and output through the local file system.  Standalone mode is usually the fastest Hadoop mode, as it uses the local file system for all input and output data. <br><br>  As mentioned earlier, you can embed debugging tools in your code, for example, counters.  Counters are defined by <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B5%25D1%2580%25D0%25B5%25D1%2587%25D0%25B8%25D1%2581%25D0%25BB%25D1%258F%25D0%25B5%25D0%25BC%25D1%258B%25D0%25B9_%25D1%2582%25D0%25B8%25D0%25BF">enum</a> Java.  The enumeration name defines the name of the group, and the enumeration fields define the names of the counters.  The counter can be useful for assessing the problem, <br>  and can be used as an addition to debug output. <br><br>  Ad and use counter: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> ru.rt.example; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.IntWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.LongWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.Text; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.mapreduce.Mapper; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Map</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Mapper</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LongWritable</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">IntWritable</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Text word = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(); <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> Word {   TOTAL_WORD_COUNT, } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">map</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(LongWritable key, Text value, Context context)</span></span></span><span class="hljs-function"> </span></span>{   String[] stringArr = value.toString().split(<span class="hljs-string"><span class="hljs-string">"\\s+"</span></span>);   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (String str : stringArr) {     word.set(str);     context.getCounter(Word.TOTAL_WORD_COUNT).increment(<span class="hljs-number"><span class="hljs-number">1</span></span>);   } } } }</code> </pre><br>  For incrementing the counter, use the <code>increment(1)</code> method. <br><br><pre> <code class="java hljs">... context.getCounter(Word.TOTAL_WORD_COUNT).increment(<span class="hljs-number"><span class="hljs-number">1</span></span>); ...</code> </pre><br>  After successful completion of the MapReduce task at the end displays the values ‚Äã‚Äãof the counters. <br><br><pre> <code class="plaintext hljs">    Shuffle Errors           BAD_ID=0           CONNECTION=0           IO_ERROR=0           WRONG_LENGTH=0           WRONG_MAP=0           WRONG_REDUCE=0   ru.rt.example.Map$Word           TOTAL_WORD_COUNT=655</code> </pre><br>  Erroneous data can be output to stderr or to stdout, or write output to hdfs using the <code>MultipleOutputs</code> class for further analysis.  The obtained data can be transferred to the application in standalone mode or when writing unit tests. <br><br>  Hadoop has the MRUnit library, which is used in conjunction with testing frameworks (for example, JUnit).  When writing unit tests, we check that the output function produces the expected result.  We use the MapDriver class from the MRUnit package, in whose properties we install the class under test.  To do this, use the <code>withMapper()</code> method, the input values <code>withInputValue()</code> and the expected result <code>withOutput()</code> or <code>withMultiOutput()</code> if multiple output is used. <br><br>  Here is our test. <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> ru.rt.example; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.IntWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.LongWritable; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.Text; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.mrunit.mapreduce.MapDriver; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.mrunit.types.Pair; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.junit.Before; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.junit.Test; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.IOException; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestWordCount</span></span></span><span class="hljs-class"> </span></span>{   <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> MapDriver&lt;Object, Text, Text, IntWritable&gt; mapDriver;   <span class="hljs-meta"><span class="hljs-meta">@Before</span></span>  <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setUp</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{     Map mapper = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Map();     mapDriver.setMapper(mapper)  }   <span class="hljs-meta"><span class="hljs-meta">@Test</span></span>  <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mapperTest</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException </span></span>{     mapDriver.withInput(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> LongWritable(<span class="hljs-number"><span class="hljs-number">0</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(<span class="hljs-string"><span class="hljs-string">"msg1"</span></span>));     mapDriver.withOutput(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Pair&lt;Text, IntWritable&gt;(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(<span class="hljs-string"><span class="hljs-string">"msg1"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> IntWritable(<span class="hljs-number"><span class="hljs-number">1</span></span>)));     mapDriver.runTest();  } }</code> </pre><br><h3>  Fully distributed mode (fully distributed mode) </h3><br>  As the name suggests, this is a mode in which all the power of Hadoop is used.  The launched program MapReduce can run on 1000 servers.  It's always hard to debug MapReduce, since you have Mappers running on different machines with different inputs. <br><br><h2>  Conclusion </h2><br>  As it turned out, testing MapReduce is not as simple as it seems at first glance. <br>  To save time searching for errors in MapReduce, I used all of these methods and advise everyone to use them too.  This is especially useful in the case of large installations, such as those that work at Rostelecom. </div><p>Source: <a href="https://habr.com/ru/post/432828/">https://habr.com/ru/post/432828/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../432818/index.html">Homemade plotter: tips for beginners, working with grbl-firmware</a></li>
<li><a href="../432820/index.html">Dynamic testing of Android applications</a></li>
<li><a href="../432822/index.html">I spoil the development of my life with my code review and I don‚Äôt want to</a></li>
<li><a href="../432824/index.html">Accelerating the creation of ConcurrentReferenceHashMap</a></li>
<li><a href="../432826/index.html">Modern Android development on Kotlin. Part 2</a></li>
<li><a href="../432830/index.html">Automated imposition of fines for abandoned garbage</a></li>
<li><a href="../432832/index.html">How to "glue" Intel-based server and overcome the scale-up ceiling in 8 processors</a></li>
<li><a href="../432834/index.html">Internal and external linking in C ++</a></li>
<li><a href="../432836/index.html">The first good light with Aliexpress</a></li>
<li><a href="../432838/index.html">Software development through the prism of Milgram's experiment ‚ÄúSubmission to authority‚Äù</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>