<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Efficient Backup in Amazon Web Services - Recipes</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! 
 Today we will talk about techniques for setting up backup files and MySQL / InnoDB / XtraDB in applications deployed in the cloud, for exampl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Efficient Backup in Amazon Web Services - Recipes</h1><div class="post__text post__text-html js-mediator-article">  Hello! <br>  Today we will talk about techniques for setting up backup files and MySQL / InnoDB / XtraDB in applications deployed in the cloud, for example, Amazon Web Services. <br><img src="https://habrastorage.org/storage2/ad5/59e/06c/ad559e06cfc47ff7bb68958b641087d2.jpg"><br>  During the development of the <a href="http://www.bitrix24.ru/">Bitrix24</a> cloud service, we tried several backup schemes, stumbled upon some of the hidden issues of the Amazon architecture and software limitations - however, everything gradually decomposed and buzzed :-) <br>  We will also carefully consider the issue of incremental backup of sufficiently large amounts of data (hundreds of gigabytes and more), raids and configurations with InnoDB / XtraDB. <br>  But first of all, let's take a closer look at the data storage technologies offered by Amazon. <br><a name="habracut"></a><br><br><h4>  Where do the virtual machine data live? </h4><br>  So, let's start with the fact that Amazon offers us data storage of virtual machines - <a href="http://aws.amazon.com/ebs/">EBS</a> virtual block devices.  Such a disk is easily created and connected to the server in 2 clicks.  The maximum disk size is 1TB.  By default, there is a limit on 5000 disks and 20TB, but it is increased <a href="http://aws.amazon.com/contact-us/ebs_volume_limit_request/">upon the first request</a> . <br>  The technology of local block devices is also proposed, the data on which ... disappears along with the server (and this can easily happen when the machine crashes) - but I will not write about it, because  we have not experimented with it. <br><br><h4>  EBS Performance </h4><br>  It is quite immediately obvious that they are slower than the "iron" ones.  The saturation of the device (% util, iostat command) with a random read volume of a dozen or so MB / s (even less by record) quickly approaches 100%.  Slowdown is clearly visible on popular operations such as copying folders from disk to disk, unpacking archives, etc. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Raid? </h4><br>  In order to adequately start working with Amazon disks, the easiest way is to ‚Äúshove‚Äù them into a software raid.  For databases, we use raid-10 on 8 EBS disks on both ext4 and xfs.  Software raid <a href="https://raid.wiki.kernel.org/index.php/Linux_Raid">is</a> done <a href="https://raid.wiki.kernel.org/index.php/Linux_Raid">quite simply</a> , it works for a long time and practically does not break. <br>  A raid can be especially useful if an EBS disk suddenly ‚Äúcrashes‚Äù. <br>  However, for a number of tasks we do not use raids - for example, to store the binary MySQL log, for backups, etc. And for storing the nginx cache, raid0 on EBS disks, which has been running steadily for about a year, is well suited. <br><br><h4>  EBS Disk Reliability </h4><br>  To be honest, for one and a half years of working with Amazon EBS disks, they have never failed us (no nonsense like ‚Äúbedov‚Äù, reading errors, etc.) ... except when lightning struck the Irish data center of Amazon - then several disks immediately flew out from raid-10 :-) <br>  However, if you carefully read what Amazon writes about the reliability of its disks, then you realize that you need to do a raid and, of course, regular backups: <br>  <i>It can be used to ensure that all data is replicated.</i>  <i>It‚Äôs been your last snapshot.</i>  <i>As a rule, it‚Äôs possible to make it true that it‚Äôs the most recent Amazon of of 0.1% - 0.5%, where it refers to the complete loss of volume.</i>  <i>AFR of around 4%, which makes it possible to compare 10 times more reliable than conventional commodity disk drives.</i> <br>  On the other hand, we have more than a hundred loaded EBS disks in production and in a year and a half software raids have never knocked out disks due to IO errors.  On the "iron" disks, I am sure, we would have already changed more than one device, so draw conclusions. <br><br><h4>  Available backup technologies </h4><br>  When the data is relatively small and it does not change often, you can play with tar.  But imagine a large online store that stores business information both in the database and in the files on the disk: new files appear every minute, and the total size of the content is hundreds of gigabytes. <br>  DRBD?  Yes, but did not try this technology in the Amazon and often hear from colleagues about her incredible braking when errors occur. <br>  <a href="http://ru.wikipedia.org/wiki/LVM">LVM</a> and snapshots in copy-on-write mode are similar to this technology, only with additional buns and Amazon offers us.  <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateSnapshot.html">Nesting of the</a> block device can be done as many times as necessary.  Wherein: <br><ol><li>  In the next snepshot disc EBS get ONLY CHANGES.  And it is completely transparent and it becomes obvious when you look at the monthly bill for the use of disk space.  Even if you have 100 snapshots from a 500GB disk, but the data did not change often - you pay for about 500-500GB, which of course plays in favor of the client. </li><li>  It is possible and necessary to remove snapshots - to preserve the balance between the size of the backup window and the cost of storing data.  At the same time, that causes delight, you can delete ANY snepshot - Amazon automatically consolidates the data as needed.  And the head on the topic doesn't hurt at all - where the basic snapshot is, and where the incremental is, it doesn't matter if you remove the excess from any position (those who worked with Acronis will appreciate the convenience). </li><li>  Disk drives are saved in <a href="http://aws.amazon.com/s3/">S3</a> .  S3 - as everyone probably already knows, this is a repository of objects of any format that replicates data at least in 2 more datacenters.  Those.  The snapshot of the disk becomes practically ‚Äúunkillable‚Äù and is saved more reliably than the screw tester in the locked nightstand under the desktop :-). </li><li>  The ripping of the disk is done almost instantly - then the background data is transferred to S3 for a certain time (sometimes tens of minutes - if the Amazon is loaded). </li></ol><br>  All this means that we can make snapshots of a huge folder of frequently changing content on the disk at least once every 5 minutes - they will be stored securely in S3 and if you need to roll back 1TB of changeable data 5 minutes ago - we easily do this: <br><ol><li>  <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateVolume.html">Create a disc</a> from a saved snapshot. </li><li>  We connect the disk to the server. </li></ol><br>  Of course, it is technically impossible to instantly transfer 1TB of data from S3 to a SAN where EBS drives live, so although the block device becomes available to the operating system, the data on it will be flooded in the background for some time - therefore, the speed of working with the disk may not be very high at first.  But, nevertheless, you will agree how conveniently you can make an incremental backup of a large amount of data and roll it back to any location, for example, a week ago in 5-minute increments?  :-) <br>  In addition to the possibility of creating snapshots from EBS disks, you can send files to S3 directly.  The <a href="http://s3tools.org/s3cmd">s3cmd</a> utility is convenient to use - you can synchronize the file system trees with the cloud in both directions (only changes based on the calculation of md5 on the local disk and storing the md5 object inside s3 in ‚ÄúETag‚Äù are transmitted).  We tried solutions based on <a href="http://ru.wikipedia.org/wiki/Filesystem_in_Userspace">FUSE</a> technology - <a href="http://code.google.com/p/s3fs/wiki/FuseOverAmazon">s3fs</a> , but noticed slowdowns and long-term freezes with the growth of LA with its intensive use. <br><img src="https://habrastorage.org/storage2/5ad/ce5/6bf/5adce56bf18eb1dea076b7782b5b9c81.jpg"><br><br><h4>  Snephot raid </h4><br>  As I wrote above, EBS disks show adequate performance if they are combined into raid0, raid10.  And how to backup raid?  Take a snapshot of each disk in turn?  :-) We understand that it is impossible and the Amazon does not offer us anything here. <br>  Good people wrote a convenient utility - <a href="https://launchpad.net/ec2-consistent-snapshot">ec2-consistent-snapshot</a> .  You can use it, or you can repeat its logic in scripts. <br><ol><li>  We use a file system that supports "freezing" - i.e.  it understands that snapshots are being made from it at the block device level and it is necessary to reset the buffers, commit transactions and temporarily stop block changes.  Until recently, XFS understood such a command ( <a href="http://linux.die.net/man/8/xfs_freeze">xfs_freeze</a> ), but in the <a href="http://kernelnewbies.org/Linux_2_6_29">‚Äúlatest‚Äù linux distributions</a> it was <a href="http://linux.die.net/man/8/fsfreeze">possible to</a> ‚Äúfreeze‚Äù and other common file systems: ext3 / ext4, xfs, jfs, reiserfs. </li><li>  We reset changes and briefly prohibit writing to FS: ‚Äúfsfreeze -f mountpoint‚Äù </li><li>  Make snapshots of each raid drive: AWS API call <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateSnapshot.html">CreateSnapshot</a> . </li><li>  Allow write to FS: ‚Äúfsfreeze -u mountpoint‚Äù </li></ol><br>  If you have xfs, you can use the <a href="http://linux.die.net/man/8/xfs_freeze">xfs_freeze</a> command. <br>  To connect a saved raid, it is better to write a script that <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-AttachVolume.html">connects the</a> disks to the machine and starts a software raid from them.  The raid saved to the snapshots by the above method perfectly rises without losing the file system log - we use it in different places in production. <br>  So, we learned how to make snapshots of raids in s3 with any amount of data with a frequency of at least once in 5 minutes and recover data from them.  Such things, I am sure, will be useful to many people on various projects in the cloud. <br><br><h4>  Nesneshot machine entirely </h4><br>  Sometimes it is more convenient not to bathe separately with each raid, but to make a snapshot of all the disks of a machine with <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateImage.html">one team</a> .  You can snapshot in 2 modes: with and without stopping the machine.  In the latter case, we are logically warned about the possible ‚Äúcorruption‚Äù of data on disks / raids: <br>  <i>When taking a snapshot of a file system, we recommend unmounting it first.</i>  <i>It is a state of the peace of mind.</i>  <i>It can be made without unmounting.</i> <br>  After creating the snapshot of the machine, an AMI (Amazon Machine Image) object appears, with links to the saved snapshots of each of its disks.  It is possible to start a server with all disks / raids from this object in one command - AWS API call <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-RunInstances.html">RunInstances</a> .  Feel the power of technology?  Working servers can not only be backed up as a whole, but also be lifted from the whole CALEC with all the raids by one team!  This technology saved us dozens of hours of system administration in an Amazon accident last August - we raised the machines from snapshots and deployed the configuration in another data center. <br>  However, there is a serious pitfall - the CreateImage command is completely opaque and it is unclear how long it takes snapshots from all server disks - a second or 10 seconds?  The interval of 5 seconds was selected by the method of scientific spear, which allows you to shoot complete images of the car with raids.  I warn you - test the script carefully before launching into production - however, you see, it‚Äôs hard to resist the ‚Äúgoodness‚Äù of creating a full machine backup :-) <br><br><h4>  MySQL incremental backup </h4><br>  Let me remind you of our task - to back up a project with attendance of millions of hits per day and hundreds of gigabytes of frequently changing content (the heaviest content is rendered in s3 and downloaded separately).  I repeat the well-known reasonable approaches to the MySQL backup: <br><ol><li>  Logical backup with slave.  In this case, we do not slow down the operation of the main server, however ... we are at risk of backing up ‚Äúrandomly‚Äù unsynchronized data (therefore, we need to monitor synchronism, for example, using <a href="http://www.percona.com/doc/percona-toolkit/2.1/pt-table-checksum.html">pt-table-checksum</a> ). </li><li>  Binary snapshot with the help of LVM from a combat server / slave, or copy the blocks to a DRBD disk on a backup machine. </li><li>  Incremental binary backup from a combat server or a slave using <a href="http://www.percona.com/software/percona-xtrabackup/">xtrabackup</a> or similar <a href="http://www.mysql.com/products/enterprise/backup.html">paid tool</a> . </li></ol><br>  To be able to quickly roll back a large online store 5-10 minutes ago in the event of a catastrophic deletion of data in the database (an erroneous query that kills data in several tables of orders ‚Äî who hasn‚Äôt yet been with? :-)) - it seems that only option 3 will do .  However, as it turned out, the binary incremental backup when creating puts a considerable load on the already weak EBS disks, but also to impose increments on the basic binary backup when recovering can take ... a few hours! <br>  I do not consider recovery scenarios from a logical backup with preliminary editing of the MySQL binary log here - this is still not done quickly. <br>  And here again the Amazon helps us.  MySQL incremental backup is done like this: <br><ol><li>  We reset MySQL / InnoDB / XtraDB buffers to disk: ‚ÄúFLUSH TABLES WITH READ LOCK‚Äù </li><li>  We reset changes and briefly prohibit writing to FS: ‚Äúfsfreeze -f mountpoint‚Äù </li><li>  Make a snapshot of all machine disks: <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateImage.html">CreateImage</a> .  See above about pitfalls.  If there are concerns, we make snapshots of each raid disk from the database: AWS API call <a href="http://docs.amazonwebservices.com/AWSEC2/latest/APIReference/ApiReference-query-CreateSnapshot.html">CreateSnapshot</a> . </li><li>  Allow write to FS: ‚Äúfsfreeze -u mountpoint‚Äù </li><li>  We remove the global locking of all tables in all databases: ‚ÄúUNLOCK TABLES‚Äù. </li></ol><br>  Now we have an AMI object with a hot MySQL backup and we did the maximum possible so that it starts up from the backup as quickly as possible. <br>  Thus, it turned out to be content to simply make an incremental backup of the MySQL server in S3 with a frequency of at least once every 5 minutes and the possibility of its quick input into production.  If the server is used in replication, then it will usually restore it without any problems, if you did not forget to set conservative replication settings in the settings (well, or you can quickly return it to work manually): <br>  <a href="http://dev.mysql.com/doc/refman/5.5/en/replication-options-binary-log.html">sync_binlog</a> = 1 <br>  <a href="http://dev.mysql.com/doc/refman/5.5/en/innodb-parameters.html">innodb_flush_log_at_trx_commit</a> = 1 <br>  <a href="http://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html">sync_master_info</a> = 1 <br>  <a href="http://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html">sync_relay_log</a> = 1 <br>  <a href="http://dev.mysql.com/doc/refman/5.5/en/replication-options-slave.html">sync_relay_log_info</a> = 1 <br><br><h4>  How to scripted actions with Amazon? </h4><br>  For the system administrator there are <a href="http://docs.amazonwebservices.com/AWSEC2/latest/CommandLineReference/Welcome.html%3Fr%3D6724">convenient utilities</a> pulling the REST-methods of the API of Amazon.  Several utilities are downloaded, for each web service used, and calls to utilities are scripted in bash.  Here is an example of a script changing the server hardware: <br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash #Change cluster node hw type #Which node to change hardware? NODE_INSTANCE_ID=$1 #To which hw-type to change? #Some 64-bit hw types: t1.micro (1 core, 613M), m1.large (2 cores, 7.5G), m1.xlarge (4 cores, 15G), #m2.xlarge (2 cores, 17G), c1.xlarge (8 cores, 7G) NODE_TARGET_TYPE='c1.xlarge' #To which reserved elastic ip to bind node? NODE_ELASTIC_IP=$2 ec2-stop-instances $NODE_INSTANCE_ID while ec2-describe-instances $NODE_INSTANCE_ID | grep -q stopping do sleep 5 echo 'Waiting' done ec2-modify-instance-attribute --instance-type $NODE_TARGET_TYPE $NODE_INSTANCE_ID ec2-start-instances $NODE_INSTANCE_ID ec2-associate-address $NODE_ELASTIC_IP -i $NODE_INSTANCE_ID</span></span></code> </pre> <br>  For developers there are libraries in different languages ‚Äã‚Äãto work with the Amazon API.  Here is a library for working from PHP - <a href="http://aws.amazon.com/sdkforphp/">AWS SDK for PHP</a> . <br>  As you can see, scripting work with Amazon objects is easy. <br><img src="https://habrastorage.org/storage2/5c8/926/aa1/5c8926aa1ef06fe2c74e857308812830.jpg"><br><br><h4>  Results </h4><br>  With specific examples, diluted with the theoretical base of popular practices and salted with effective tools of the Amazon API, we learned: <br><ul><li>  incrementally back up and restore large amounts of data from EBS disks and Amazon raids to S3 and back </li><li>  back up and restore the whole Amazon machine </li><li>  incrementally back up and quickly put into operation a MySQL server with data stored on raids of EBS disks </li><li>  discussed several pitfalls </li><li>  We looked at how simple scripting basic actions </li></ul><br>  In one of the following articles I will tell you how to efficiently manage traffic and balance the load between clusters and Amazon data centers. <br>  In practice, we actively use the technologies listed in the article, experiment, open and ready to share experiences and look for simple and effective solutions to emerging problems using the tools of the open source world. <br>  I invite everyone to register on our cloud service <a href="http://www.bitrix24.ru/">Bitrix24</a> and see what we have done.  I also invite those who wish to attend a <a href="http://habrahabr.ru/company/bitrix/blog/143702/">FREE seminar</a> on web clusters and high loads, which will be held in the 1C conference hall on May 22. <br>  Good luck to everyone in building scalable and fault-tolerant systems! </div><p>Source: <a href="https://habr.com/ru/post/143820/">https://habr.com/ru/post/143820/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../143814/index.html">Encrypt messages for a specified time</a></li>
<li><a href="../143815/index.html">‚ÄúRunet today‚Äù, May 14, 2012. Experts of the issue: Andrei Chechin, Dmitry Danilenko</a></li>
<li><a href="../143816/index.html">Do I need posts on Habrahabr?</a></li>
<li><a href="../143817/index.html">Connection Raspberry Pi and Arduino</a></li>
<li><a href="../143818/index.html">Typeless lambda calculus, combinators, Unlambda and Fibonacci numbers</a></li>
<li><a href="../143821/index.html">davfs2 and encfs on box.com</a></li>
<li><a href="../143823/index.html">Number 8-800, or how to splurge in one day</a></li>
<li><a href="../143824/index.html">In Diablo III you can play for free!</a></li>
<li><a href="../143825/index.html">Color Kindle. Soon</a></li>
<li><a href="../143826/index.html">Wireless Internet (4G + 3G) vs wired. Who will win?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>