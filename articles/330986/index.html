<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apache Spark as the core of the project. Part 2. Streaming, and what we ran into</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello colleagues. Yes, less than three years from the first article , but the project abyss released only now. I want to share with you my thoughts an...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apache Spark as the core of the project. Part 2. Streaming, and what we ran into</h1><div class="post__text post__text-html js-mediator-article">  Hello colleagues.  Yes, less than three years from the <a href="https://habrahabr.ru/post/271375/">first article</a> , but the project abyss released only now.  I want to share with you my thoughts and problems regarding Spark streaming in conjunction with Kafka.  Perhaps there are people among you with successful experience, so I will be glad to talk in the comments. <br><br><a name="habracut"></a>  So, in our project there is a need to make decisions in real time.  We successfully use Spark for batch processing, and therefore decided to use it for realtime.  This gives us a single technology platform and a single code base. <br><br>  Workflow looks like this: All events are queued (Apache Kafka), and then read and processed by Spark streaming consumers.  Consumers must solve two problems: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  Data routing (redirect data streams to different storage) </li><li>  Making decisions in real time. </li></ul><br>  The data that comes to Kafka should ultimately get into HDFS in the form of ‚Äúraw‚Äù log files converted to parquet, and in HBase, in the form of attributes of user profiles.  At one time, for similar routing, we quite successfully used Apache Flume, but this time we decided to delegate this business to Spark streaming.  Spark out of the box can work with HDFS and HBase, in addition, the developers guarantee ‚Äúexactly once‚Äù semantics.  And now let's take a little closer look at the semantics of data delivery (Message Delivery Semantics). <br>  There are three types of them: <br><br><ul><li>  <i>At most once</i> - The message may be lost, but never delivered more than once. </li><li>  <i>At least once</i> - The message can never be lost, but can be delivered more than once. </li><li>  <i>Exactly once</i> - This is what people want.  A message can only be delivered once, and cannot be lost. <br></li></ul><br>  And here lies the biggest misunderstanding.  When Spark developers talk about exactly once semantics, they mean only Spark.  That is, if the data got into the Spark process, then they will be delivered once to all user functions involved in processing, including those located on other hosts. <br><br>  But as you understand full workflow does not consist of only one spark.  Three sides are involved in our process, and semantics should be considered for the whole bundle. <br><br>  As a result, we have two problems - the delivery of data from Kafka to Spark, and the delivery of data from Spark to storage (HDFS, HBase). <br><br><h3>  From Kafka to Spark </h3><br>  Theoretically, the problem of delivering data from Kafka to Spark has been solved in two ways. <br><br><h4>  Method one, old (Receiver-based Approach) </h4><br>  The driver has a driver that uses the Kafka consumer API to track the read data (offsets).  These offsets in the classics of the genre are stored in the Zookeeper.  And everything would be fine, but there is a non-zero probability of delivering the message more than once, at the moments of failure, and this is At least once. <br><br><h4>  Method Two, New (Direct Approach (No Receivers)) </h4><br>  The developers have implemented a new Sparkovsky driver, which itself deals with tracking of offsets.  It stores information about the read data in HDFS, in the so-called checkpoints.  This approach guarantees semantics exactly once, and that is what we use. <br><br><h4>  Problem #number </h4><br>  Spark sometimes spoils the checkpoints, so much so that it cannot work with them later, and goes into a state of severe drug intoxication.  He stops reading the data, but at the same time he continues to hang in his memory and tell everyone that everything is all right with him.  What is the cause of this problem is not at all clear.  Accordingly, we kill the process, remove the checkpoints, start and read everything from the beginning, or from the end.  And this is also not exactly once)) For historical reasons, we are using version 1.6.0 on Cloudera.  Perhaps it is worth updating, and everything will pass. <br><br><h4>  Problem number two </h4><br>  Kafka - beats rarely but aptly.  There are such situations that any broker falls.  To understand why the fall occurred is simply impossible, because of absolutely non-informative logs.  The fall of any broker is not scary, Kafka is designed for that.  But if you missed, and the broker did not restart in time, the entire cluster would be inoperable.  This certainly does not happen in one hour, but nonetheless. <br><br><h3>  From Spark to external storage </h3><br>  Here things are not so good.  The developer himself must take care of guarantees for the delivery of data from Spark to external storage, which introduces a weak overhead into development and architecture.  If at this level exactly once semantics is needed, then it is necessary not to be bothered.  By the way, we have not solved the problem in this part of the system, and we are content with At most once semantics. <br><br><h3>  Results: </h3><br>  I feel you can use Spark streaming, but only if your data does not have a special financial value and you are not afraid to lose it.  The ideal case is when the data is guaranteed to get into the storage using some other, more reliable subsystem, and Spark streaming is used as a rough tool that helps generate some kind of rough conclusions or not accurate statistics, but in real time, followed by refining batch processing mode. <cut></cut></div><p>Source: <a href="https://habr.com/ru/post/330986/">https://habr.com/ru/post/330986/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../330976/index.html">Career in Digital: what is it, who needs it, where to start</a></li>
<li><a href="../330978/index.html">You have the right to anonymity. Part 3. Law enforcement struggle with anonymity tools</a></li>
<li><a href="../330980/index.html">Energy accounting as part of the shopping center SCADA system</a></li>
<li><a href="../330982/index.html">Analytics in recruitment: it is not your bigdata</a></li>
<li><a href="../330984/index.html">How I passed the CISSP certificate exam</a></li>
<li><a href="../330988/index.html">Architecture and indexing algorithms audio records VKontakte</a></li>
<li><a href="../330990/index.html">Simulation of transients during electrical circuit switching by means of Python</a></li>
<li><a href="../330992/index.html">Without getting out of the chat: the stages of the development of Unified Communications</a></li>
<li><a href="../330994/index.html">Verizon completed Yahoo takeover</a></li>
<li><a href="../330996/index.html">NTT Com announced the creation of the world's first fully software-defined network</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>