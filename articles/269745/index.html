<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Learning machine learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I am not a real bigdot, I just found xgboost on github'e. 

 The pursuit of 500kr from Beeline forced me to plunge into the world of machine learning,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Learning machine learning</h1><div class="post__text post__text-html js-mediator-article"><img align="left" src="https://habrastorage.org/files/5d4/b3d/e80/5d4b3de8065f4b1bacbfed086f96e053.png" alt="beeline 100% match" width="55%" height="55%"><br>  <i>I am not a real bigdot, I just found xgboost on github'e.</i> <br><br>  The pursuit of <a href="http://special.habrahabr.ru/beeline/">500kr from Beeline</a> forced <a href="http://special.habrahabr.ru/beeline/">me</a> to plunge into the world of machine learning, to which I showed interest before, but did not show confidence and, accordingly, did not dive.  A quick search revealed that in this regard, <a href="https://github.com/dmlc/xgboost">xgboost</a> now <a href="https://github.com/dmlc/xgboost">steers</a> from Chinese comrades from the University of Washington.  As I understand it, this is something like Apple in the field of machine learning: I pressed one button and got what I wanted quickly and beautifully. <br><a name="habracut"></a><br>  Upon closer examination, the settings came to light; by twisting them, you can speed up or slow down learning, refine or coarsen the predictions given by this program.  The input to the program is most conveniently served in the libsvm format.  Surely there are a lot of libraries with which you can transfer anything (from csv to avi) to libsvm, but in this case I managed to use my ‚Äúbicycle‚Äù in JavaScript. <br><br>  So, already on September 30, with xgboost help, 76.58% of hits were received according to preliminary estimates.  Mature bigdatschiki meanwhile fell by 77% +!  After reading about the benefits of ensembles (this is a combination of several predictions on the basis of a majority of votes), I began to look for other methods in order to get uncorrelated with the existing predictions.  As if to make an ensemble of predictions of approximately the same origin, their accuracy is averaged, and if from completely different ones, then accuracy increases. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I tried the method of support vectors (SVM), the method of the nearest neighbors with the weighting by distance of the neighbor and "random-forest".  These methods have already required some data preparation: somewhere to normalize, somewhere to weigh the significance of the factors, I had to understand a little, because I know the python at the level ‚ÄúI read / write with a dictionary‚Äù, with the Python sklearn (Sci-Kit Learn), since there the documentation and examples are clear and the cat.  The results are much worse: from 57 to 73% of hits, due to the inability to prepare data for which these methods are critical.  Although it seems to do as they say in the books, the categories are in dummy variables, the numbers are in the range [0; 1], they are discarded by insignificant ones. <br><br>  To diversify the model began to get rid of significant and insignificant factors.  The variable x8 contains more than 90% of the information available in all variables about the age group (only one can get 72% + hits).  Xgboost without this information, something began to miss a lot - within 55% of hits, but surprisingly, 73% of the nearest neighbors remained.  Creating several dozens of options with various circumcisions of information available for learning, gathered them into an ensemble and ... 77.05%.  It is sad‚Ä¶ <br><br>  Some useful method of processing input data or method, therefore, did not apply, but knowledgeable people used.  Well, it has become annoying.  Somewhat cheered up is that, as it turned out, Beeline‚Äôs checking for a preliminary rating is always done on the first 15 thousand test lines, and not on the random 15 thousand, as I had originally intended.  This means that you can pull out some more lines of data for training and cross-validation.  Suddenly something unknown and useful in them ?! <br><br>  It is not clear whether this was provided by the organizers of the competition, but on October 27, over several hours and approximately 23 thousand attempts received 15 thousand first lines of the test sample with the correct answers (there were no caps, no restrictions on the frequency of sending options for solutions, so all passed quickly and cheaply even in 1-2 streams).  But these additional 15k didn‚Äôt bring much benefit, besides the fun of ƒåSV: according to my estimates, the leaders did not manage to bypass 70% of the test data, as the methods I used could not be found. <br><br><h3>  The practical results of the lesson ML from Beeline </h3><br><ul><li>  xgboost is optimal when searching for dependencies in data; it allows you to get 95% of the best possible result at the cost of 5% of effort; it suits the consumer approach to the task of lazing at zero level. </li><li>  For the advanced level will go python-sklearn.  If you constantly work with him, then it is also not difficult, the classes in the library are comfortable, they implement almost all fantasies. </li><li>  Combining the uncorrelated results of even poor quality, one can improve the accuracy to a level above the best available source options (ensemble utility). </li></ul><br>  And how did you participate in the contest from Beeline and what did you get out of it? </div><p>Source: <a href="https://habr.com/ru/post/269745/">https://habr.com/ru/post/269745/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../269735/index.html">How lighthouses work: iBeacon Physics Technology</a></li>
<li><a href="../269737/index.html">Secure crypto programming. Part 2, final</a></li>
<li><a href="../269739/index.html">Conference on web analytics and internet marketing CONVERT.2015 will be held in Yekaterinburg on December 7</a></li>
<li><a href="../269741/index.html">Swift + VK.API, or the story of SwiftyVK</a></li>
<li><a href="../269743/index.html">We continue to fight the frontend-routine</a></li>
<li><a href="../269747/index.html">Why google voice neural nets search?</a></li>
<li><a href="../269751/index.html">Attackers exploit a vulnerability in the Ksoft Uploader software! for installing Gh0st RAT</a></li>
<li><a href="../269753/index.html">Testing the functionality of Symantec Backup Hot-Add. Increased speed of copying and restoring data</a></li>
<li><a href="../269755/index.html">Control modes using the mouse and the touch screen in Windows 10 and Windows 8</a></li>
<li><a href="../269757/index.html">The book "Minecraft. Program your world "</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>