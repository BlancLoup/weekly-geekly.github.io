<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI: imitation of intelligence, deception and real achievements</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Since when did programs learn to impersonate people? How to understand if we are adept at us snag or really strong AI? When will the program cope with...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AI: imitation of intelligence, deception and real achievements</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/fa8/e6d/ad1/fa8e6dad12df4b4eb6dca1a78ea3facb.png"><br><br>  Since when did programs learn to impersonate people?  How to understand if we are adept at us snag or really strong AI?  When will the program cope with machine translation or write its first novel?  Sergei <a href="https://geektimes.ru/users/oulenspiegel/" class="user_link">oulenspiegel</a> Markov, author of the <a href="https://geektimes.ru/users/oulenspiegel/" class="user_link">game</a> ‚Äú <a href="https://geektimes.ru/company/mailru/blog/277064/">Play at God‚Äôs Level: How AI Learned to Win a Man,</a> ‚Äù returns to the topic of smart machines in our new neural article. <br><a name="habracut"></a><br><h1>  Do programs know how to pretend to be people? </h1><br>  In the late 30s of the last century, when the first electronic computers had not yet been created, computer science experts began asking themselves about the "rationality" of machines.  If something looks like a cat, meows like a cat, behaves like a cat, in any experiment it manifests itself like a cat, then probably this is a cat.  This idea was formulated by Alfred Ayer - an English neo-positivist philosopher, a representative of analytical philosophy. <br><br>  All of us beloved Alan Turing was more socialized than Iyer.  Turing liked to go to parties, and at that time an interesting game was spread among the intellectual public - ‚ÄúImitation game‚Äù.  The game consisted in the fact that the girl and the guy were locked in two different rooms, leaving a wide gap under the door into which the participants of the game could send notes with questions.  The person who was in the room wrote some answers to the questions.  The task of the game was to guess which room the guy is in, and which one the girl is in.  Turing suggested the following: "And let us use a similar procedure in order to understand whether we created the same universal AI." 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/a81/a85/c6f/a81a85c6f34a424f8b0531bd25c594f9.gif"><br><br>  The first program that could communicate with a person through a certain correspondence is <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BB%25D0%25B8%25D0%25B7%25D0%25B0_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B0)">ELIZA</a> , created in 1966.  The program tried to impersonate itself in an experiment not just for a person, but for a psychiatrist.  Her style of communication is parody.  That is, she speaks in a specific psychiatric jargon, asks the appropriate model questions.  In principle, this program is a large set of rules according to which it found certain patterns in a person‚Äôs speech.  In response to the presence of the corresponding input information pattern, ELIZA transformed it in a certain way and provided information on the output. <br><br>  The program could fool people in some situations.  The AOLiza experiment was conducted, when the program communicated through the America Online network with randomly selected users, and many of them did not realize that in this case the machine communicated with them.  It is clear that this experiment cannot be considered as at least some serious approximation to the passing of the Turing test. <br><br>  The name of the program ELIZA came from the name of the heroine Bernard Shaw from the play ‚ÄúPygmalion‚Äù, which tells how London phonetics professor Henry Higgins tries to make a real lady from the public lower classes, teaching her the rules of behavior and the language of high society. <br><br><img src="https://habrastorage.org/files/a33/aca/b1e/a33acab1ed9f45ab86b24c9a7d7b8530.png"><br><br>  Interestingly, the second program of this kind (chat bot), created in 1972 by Kenneth Kolbay of Stanford University, was a kind of comic discussion with the authors of the ELIZA program.  She was called PARRY.  If ELIZA tried to pretend to be a doctor, then PARRY tried to impersonate a patient.  PARRY considered herself a paranoid schizophrenic. <br><br>  Interestingly, the program is well deceived professional psychiatrists.  In the experiments, it turned out that 48% of psychiatrists are unable to understand whether they are dealing with a person or a program.  But here, again, there was no purity of the experiment.  If a person has certain dysfunctions, then his behavior can be quite automatic in some situations. <br><br><img src="https://habrastorage.org/files/370/7a4/1af/3707a41affbf491086b2bf51c0318e04.png"><br><br>  An interesting development of those times that made a very big impression is the SHRDLU program.  The name SHRDLU is derived from ETAOIN SHRDLU - this is how the alphabetical keys on the linotypes are located (in accordance with the decrease in the frequency of occurrence of letters in English).  As, for example, now YTSUKEN and FYVAPROLDZH. <br><br>  SHRDLU had a small world in which a limited number of objects were represented.  These were pyramids, various cubes, a box.  And SHRDLU was able to communicate in a natural language with a person, discussing what is happening in this world, and knew how to execute commands that were given in a natural language by a person.  At the same time, the vocabulary was not limited at all, that is, a person could say anything, and the program could respond fairly freely.  Here is an example of how SHRDLU works: <br><br>  <b>Man</b> : What is in the box? <br>  <b>Computer</b> : Blue pyramid and blue block. <br>  <b>Man</b> : What is the pyramid on? <br>  <b>Computer</b> : On the box. <br>  <b>Man</b> : How many blocks are there in the box? <br>  <b>Computer</b> : Four. <br>  <b>Man</b> : At least one of them is thinner than the one I told you about?  Is it worth something? <br>  <b>Computer</b> : Yes, it is on the table. <br>  <b>Man</b> : Can the table collect blocks? <br>  <b>Computer</b> : No <br>  <b>Man</b> : Can a pyramid stand on a block? <br>  <b>Computer</b> : Yes. <br>  <b>Man</b> : Can a pyramid stand on a pyramid? <br>  <b>Computer</b> : I don't know. <br>  <b>Man</b> : Good.  Put the pyramid one on another. <br>  <b>Computer</b> : It does not work. <br>  <b>Man</b> : Please put two red blocks on top of each other.  Either a green cube or a pyramid.  Can you? ‚ÄùAnd SHRDLU takes these blocks, starts to operate with them. <br><br>  Even now, this kind of demonstration looks impressive.  Interestingly, the <a href="http://hci.stanford.edu/~winograd/shrdlu/">SHRDLU source can be downloaded</a> , the program is written in LISP, there is even some modern visualizer for Windows.  If you open its source code, you will see that the program consists of a huge number of ingenious rules. <br><br>  When you read these rules, you understand how sophisticated logic is incorporated into the program.  Terry Grape, apparently, conducted many experiments, allowing different people to communicate with this system.  The SHRDLU world is very small: it can be described in about 50 different words.  And within such a small space, you can create an impression of intellectual behavior in the system. <br><br><h1>  What programs can now </h1><br>  Once Turing was cornered to the wall and directly asked: "When will the programs pass the tests?"  Turing suggested that in 2000 there will appear machines using 10 <sup>9</sup> bits of memory, capable of deceiving a person in 30% of cases. <br><br><img src="https://habrastorage.org/files/4a8/e2c/c10/4a8e2cc104ab47e0bd0ad34bf1e7825e.jpg"><br><br>  It is interesting to check whether the Turing forecast in 2016 came true.  The program ‚Äú <a href="https://ru.wikipedia.org/wiki/%25D0%2596%25D0%25B5%25D0%25BD%25D1%258F_%25D0%2593%25D1%2583%25D1%2581%25D1%2582%25D0%25BC%25D0%25B0%25D0%25BD">Eugene Goostman</a> ‚Äù is a boy from Odessa.  In the first test, held in 2012, the program was able to deceive the judges in 20.2% of cases.  In 2014, in the test, the same program, already modernized, in tests organized by the University of Reading, was able to deceive the judges in 33% of cases.  Roughly speaking, with an error of plus or minus 10 years, Turing approximately fell into the forecast. <br><br>  Then came the <a href="http://www.ifmo.ru/ru/viewnews/4916/chatbot_vypusknika_universiteta_itmo_obmanul_polovinu_sudey_v_russkoyazychnom_teste_tyuringa.htm">Sonya Guseva</a> program, and in 2015 she was able to deceive the judges in 47% of cases.  It is worth noting that the testing procedure involves limiting the time for experts to communicate with the program (usually about 5 minutes), and in the light of this limitation, the results no longer look so clear.  However, to solve many practical problems, for example, in the field of SMM automation, this is more than enough.  Most likely, users of social networks will not be able to distinguish an advanced advertising bot from a person in practice. <br><br>  Perhaps the most famous and serious objection to these successes is the response of the philosopher John Searle, who proposed a mental experiment called the <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B8%25D1%2582%25D0%25B0%25D0%25B9%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BD%25D0%25B0%25D1%2582%25D0%25B0">Chinese Room</a> .  Imagine that there is a closed room, a person is sitting in it.  We know that a person does not understand Chinese, cannot read what is written in Chinese characters on paper.  But our experimental has a book with rules, in which the following is written: ‚ÄúIf you have such hieroglyphs at the entrance, then you should take these hieroglyphs, and make them in that order.‚Äù  He opens this book, it is written in English, looks at what they gave him at the entrance, and then, in accordance with these rules, forms the answer, and throws it at the exit.  In a certain situation, it may seem that there is a person inside the room, actually understanding Chinese.  But after all, the individual inside the room does not know the Chinese language on the formulation of the problem.  It turns out that when the experiment was set up according to the Turing canons, it actually does not indicate that someone who understands Chinese is sitting inside.  A great controversy has developed around this argument.  There are typical objections to it.  For example, the argument that if John himself does not understand Chinese, then the whole system, composed of John and a set of rules, already has this very understanding.  Till now articles in a scientific press on this subject are written.  However, most computer science experts believe that the Turing experiment is sufficient to draw certain conclusions. <br><br><h1>  Machine translate </h1><br><img src="https://habrastorage.org/files/59e/251/c50/59e251c502b04fb6b1a4b14af89b88fe.jpg"><br><br>  From the machines that only pretend to be AI, let's move on to programs that really exceed human capabilities.  One of the tasks directly related to the creation of AI is the task of automated translation.  In principle, automated translation appeared long before the appearance of the first electronic machines.  Already in the 1920s, the first mechanical machines were built, based on photographic equipment and fancy electrical mechanics, which were designed to speed up the search for words in dictionaries. <br><br>  The idea to use a computer for translation was expressed in 1946, immediately after the appearance of the first such machines.  The first public demonstration of machine translation (the so-called Georgetown experiment) took place in 1954.  The first serious entry with serious money for the solution of this problem was carried out in the early 1960s, when systems were created in the United States for translation from Russian to English.  These were the MARK and GAT programs.  And in 1966 an interesting document was published on the evaluation of existing machine translation technologies and prospects.  The content of this document can be summarized as follows: everything is very, very, very bad.  But, nevertheless, no need to throw, we must continue to gnaw granite. <br><br>  In the Soviet Union there were also such studies, for example, the group ‚ÄúSpeech statistics‚Äù, headed by <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B8%25D0%25BE%25D1%2582%25D1%2580%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9,_%25D0%25A0%25D0%25B0%25D0%25B9%25D0%25BC%25D1%2583%25D0%25BD%25D0%25B4_%25D0%2593%25D0%25B5%25D0%25BD%25D1%2580%25D0%25B8%25D1%2585%25D0%25BE%25D0%25B2%25D0%25B8%25D1%2587">Raimund Piotrovsky</a> .  The employees of his laboratory founded the well-known company PROMT, which developed the first domestic commercial machine translation program based, among other things, on the ideas of Piotrovsky.  Somewhere else by 1989, it was estimated that the automated translation system would speed up the translator‚Äôs work about 8 times.  Now these figures are probably still a little improved.  Of course, no system can match the translator, but it can speed up his work many times over.  And every year the indicator of influence on the work of translators is growing. <br><br>  The most important milestone in recent decades has been the arrival of systems on the stage, which emphasize purely statistical methods.  As early as 1960-1970, it was clear that approaches based on the compilation of manual semantic maps of the language and syntactic structures appear to lead to a dead end, since the scale of the work is incredibly large.  As it was believed, it is impossible in principle to keep up with the changing living language. <br><br>  Forty years ago, linguists dealt with rather small language corpuses.  Linguists could either manually process the data ‚Äî take and count the number of such-and-such words in War and Peace, compile frequency tables, and do a primary statistical analysis, but the labor costs for performing such operations were tremendous.  And here the situation drastically changed exactly when the Internet appeared, because along with the Internet a huge number of buildings in natural languages ‚Äã‚Äãappeared.  The question arose of how to make a system, which ideally would not know anything or almost nothing about the language, but at the same time receive giant corps at the entrance.  Analyzing these shells, the system will automatically translate texts from one language to another quite well.  This approach is implemented, for example, in Google Translate, that is, it is a system, behind the work of which there is very little work of linguists.  So far, the translation quality of the previous generation systems - LEC, Babylon, PROMT - is higher than that of Google Translate. <br><br>  Here, the problem rests on what kind of preprocessing we need for natural language, so that the results can be pushed into good predictive models such as convolutional neural networks, and the output will be what we need.  How should preprocessing be constructed, what specific knowledge about natural language should it have in order to solve the further task of learning the system? <br><br><img src="https://habrastorage.org/files/72c/c40/81a/72cc4081a9c94e0796f34f613e2b405b.jpg"><br><br>  Recall the story of sausage in the dough (sausage in the father-in-law).  That is, there is a sausage in the dough, but ‚Äúin the dough‚Äù means not the dough, but the test.  AI must understand a range of human cultural characteristics.  He should understand that, most likely, in this context, the practice of wrapping dough in the preparation of sausages is supposed, and not the practice of putting sausages in the test.  This does not mean that the second practice does not exist.  Perhaps, in some context, an adequate translation would be to insert a sausage in the test.  And here, only by understanding these most cultural references, which are present in natural language at every step, can one achieve a successful translation.  Or maybe this is some kind of statistics related to the fact that, based on a statistical analysis of the shells, we simply see that in the texts of such subjects the most often used translation is about ‚Äúsausage placed in dough‚Äù. <br><br>  Another example is related to a cat that gave birth to three kittens: two whites, one African American.  Again, what a huge cultural stratum floats here under the translation.  In fact, the fact that an African American got here is a kind of approach towards understanding the cultural characteristics of modern society.  While these problems are solved by different crutches such as setting the subject of the text.  That is, we can say that we translate text in algebra.  And then the program should understand that ‚ÄúLie algebra‚Äù is ‚ÄúLie algebra‚Äù and not ‚ÄúLie algebra‚Äù.  One way or another, this may work, but in universal terms we are still very far from a system that is truly comparable in quality to a human translator. <br><br>  In recent years, neural network technologies have actively come into the field of machine translation.  The specific topology of recurrent neural networks - the so-called Long-term-short-term memory (LSTM) architecture used for analyzing statements, turned out to be well applicable for solving translation problems.  Modern <a href="https://arxiv.org/pdf/1409.3215.pdf">tests</a> show that the use of LSTM networks makes it possible to achieve a translation quality comparable to the level of quality of conventional technologies with a little effort. <br><br>  Another fun task is writing poems.  If you look at the purely technical side of the question, how to rhyme the words and put them in a certain poetic size, then this task was very simple as early as the 1970s, when Piotrovsky began to deal with it.  We have a dictionary of words with accents, there are rhythmic maps of poetic sizes ‚Äî we took and put words into this size.  But here I would like to write something meaningful.  As the first flies-Drosophila was taken the poetry of the skalds, because there is a very simple and clearly formulated canon. <br><br>  <i>Gudrun from revenge</i> <i><br></i>  <i>Gore maiden together</i> <i><br></i>  <i>Khar was skilled</i> <i><br></i>  <i>Hamdir was brave</i> <i><br></i>  <i>Sons killed.</i> <i><br></i>  <i>Nierdom is not nice.</i> <i><br></i>  <i>Conciliator.</i> <i><br></i>  <i>Spear destructor.</i> <br>  - Tord son of Sjarek, translated by S.V.  Petrova <br><br>  A skald poem consists of so-called kennings, and each kenning is just a combination of several words that has an absolutely clear emotional and semantic coloring.  The whole poem is made up of a sequence of Kenning.  The task for a poetry writing program can be worded as follows: write an abusive poem about a crow.  Accordingly, according to these criteria, the program selects suitable ones from its library of Kenning, and then adds a poem from them.  This experiment is similar to the experiment of Terry Winograd with SHRDLU, because here is also a very simple model space, and in it primitive approaches can work, helping to get good results. <br><br><h1>  Machine translation for scientific articles </h1><br><img src="https://habrastorage.org/files/0b2/f76/b14/0b2f76b1400d4fdbb42b89a6c816dcce.jpg"><br><br>  This is a machine uplift.  Now we will explain why he is needed here.  <a href="https://ru.wikipedia.org/wiki/SCIgen">SCIgen</a> program generates science-like nonsense.  In general, she does it in English, but here you can make a combo - take the program-translator and science-like nonsense with the correct dictionaries translate into Russian.  The result is a second order nonsense. <br><br>  What do we lead to?  There is such a problem: a mandatory requirement for a person who is going to defend a dissertation, to have several publications on the topics of his dissertation in journals from the list of the Higher Attestation Commission (HAC).  Accordingly, a certain streaming business has developed around this requirement, namely, magazines have appeared that accept anything for publication.  Formally, there should be a reviewer in the WAK journal who should read your text and say ‚Äúyes, we accept this article for publication‚Äù or ‚Äúno, we do not accept‚Äù.    ¬´ ¬ª,     ¬´    X,     ¬ª.      ,        . <br><br>       SCIgen   ,        ,        ,   ¬´:       ¬ª. ,     , - ,     ,  ,         ,      . <br><br><h1>      </h1><br><img src="https://habrastorage.org/files/570/035/d34/570035d343dd4c91a101838e44ac033f.jpg"><br><br>  2013      ¬´   ¬ª,      .     -,        ,   .  2016        ,    ¬´,    ¬ª.          1450  ,  .    ,      2865           .  ,   2016     -     .   ,    . <br><br>    . ,   ,        .  ,  -       ,   ,  .      .   ,     ,    (  <a href="https://glvrd.ru/">.</a> ,     ,    ). <br><br><img src="https://habrastorage.org/files/db9/a39/c7f/db9a39c7fbe1410e8cd1b3d5bc202ec3.jpg"><br><br>  ,     .   , ,  ,     .   ,      ,     ,    ,     . <br><br><img src="https://habrastorage.org/files/7e3/dfd/bc4/7e3dfdbc431b400c8e72d93867a8586e.png"><br><br>    Summly,         . Summly    ,    ,     summary,   400 ,     ¬´¬ª.   ,     ,     ¬´¬ª. ,       ,      30   Yahoo. <br><br><h1>   </h1><br><img src="https://habrastorage.org/files/e97/d6c/55d/e97d6c55db084917baf33a300d8f1a21.jpg"><br><br>      Civil Science,     ,   ,         .         . <br><br> -  . ,    , ,  ,    ,       ,      .     ,    ,     ,        ,      200 .         .   -,         ,         .     ,        .     ,     ,     ,   .          .   ,   ,   . <br><br>     ‚Äî   .   ,     ,        ,   ,   ,     ,  ,  ,     . <br><br>       .     ,       ,   Prisma,       . <br><br><h1>  :    </h1><br><img src="https://habrastorage.org/files/530/337/284/5303372845c84781b58b374b72bd2cbe.jpg"><br><br>      ,        2045 ,       2029 . <br><br>       .           .        Blue Brain ,    ,    ,    .      2022      .  ,    ‚Äî    1000  . ,             ‚Äî         () ,        .       .   <a href="http://biorxiv.org/content/early/2016/07/07/062745"></a>     BioRXiv. <br><br> ,     ,         .          ,        .   .     ,   ,      ,   ,         ( ),   - ,       . , Microsoft    <a href="https://www.microsoft.com/en-us/research/publication/accelerating-deep-convolutional-neural-networks-using-specialized-hardware/"></a> ,   FPGA      .   ,  CNTK, TensorFlow, Caffe,       . <br><br>    TrueNorth,  IBM     DARPA SyNapse,           .   IBM   ,        .       ,  ,    N .    TrueNorth    ,  -   community   . <br><br>       . ,    .  ,   ,     ,      .  ,       .    ,          ,     . <br><br>        ,  :    ,         ?      ,     :         .        . -,     ,  20%   ,      2%   .  ,   ,     . ,        .  ,      ,         .       ÃÅ  ,   ÃÅ  .             .    ,        ,        .              . <br><br>     ¬´  ¬ª     ¬´¬ª        .    ,     .       ,  ,   -  XX .     ,   ,      .      ,   -  ,  : ¬´, ,  ,  .    ,  ,    .  ¬ª.    - , - , - .    ?    ,    -    ,       ,    ,    ,      .        , ,      . <br><br><h1>     </h1><br>           .          .    , ,   computer science          .  ,              ¬´¬ª,   ¬´¬ª ,     ,    ¬´ ¬ª      .    ,       . ,        reverse engineering   .   ,   ,    ,   ,  opensource-.         .     ! </div><p>Source: <a href="https://habr.com/ru/post/396671/">https://habr.com/ru/post/396671/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../396661/index.html">Overview of the USB-Lightning Transcend JetDrive Go 300K flash drive</a></li>
<li><a href="../396663/index.html">LED lamps Feron</a></li>
<li><a href="../396665/index.html">Rosatom entered the US market with fuel for Western-style reactors</a></li>
<li><a href="../396667/index.html">Ask Ethan # 81: Can you crawl out of a black hole?</a></li>
<li><a href="../396669/index.html">Someone else's space: the hard way of the Brazilian space program</a></li>
<li><a href="../396673/index.html">Wings, legs and tails</a></li>
<li><a href="../396677/index.html">Omega2: the world's smallest microcomputer with Linux and Wi-Fi</a></li>
<li><a href="../396679/index.html">Xiaomi Mi Drone - the first real tests of the new quadcopter</a></li>
<li><a href="../396681/index.html">In Europe, the number of honeybee colonies fell by 12%</a></li>
<li><a href="../396685/index.html">Liquid metal forced to move</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>