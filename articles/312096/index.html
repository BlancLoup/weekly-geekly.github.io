<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>"Spherical trader in a vacuum": instructions for use</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="If you analyze  forums on markets (including Forex), we can distinguish two fairly stable opinions, let's call them pessimistic and optimistic: 

 Pes...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>"Spherical trader in a vacuum": instructions for use</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/64c/774/9d1/64c7749d11394bc68dbff0090f1ccc4a.jpg"><br><br>  If you analyze <img src="https://tex.s2cms.ru/svg/N">  forums on markets (including Forex), we can distinguish two fairly stable opinions, let's call them pessimistic and optimistic: <br><br>  Pessimists say: the <i>market is <b>random</b> "because I built a random process chart and my friend (professional trader) could not distinguish it from the EURUSD chart", which means it is impossible to have a stable income on the market (Forex)!</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Optimists object to them: <i>if the market were random, the quotes would not have walked around 1, but went to infinity.</i>  <i>So the market is not accidental and you can earn on it.</i>  <i>I saw a really <b>stable</b> earning strategy with a large profit factor (more than that)!</i> <br><br>  Let's try to remain realistic and benefit from both opinions: <b>suppose</b> that the market is random, and based on this assumption, we construct a methodology for checking the profitability of the trading system for <b>non-randomness</b> . <br><br><hr>  <b>The techniques considered in the article are universal for any markets, be it a fund, forex, or any other!</b> <br><hr><br><a name="habracut"></a><br><h1>  Formulation of the problem </h1><br>  Thanks to the well-known joke about a spherical horse in vacuum, a wonderful allegory was born, meaning an ideal, but completely inapplicable in practice model. <br><br>  However, with the correct formulation of the problem, it is possible to extract quite tangible practical benefits by applying a "spherical model in vacuum."  For example, through the denial of "sphericity" of the real object of study. <br><br>  Suppose we have a trading system used in a certain market.  Also suppose that the market is not accidental and the system uses something that is not a random number generator disguised as indicators for making trading decisions.  To assess the stability of income, we use the profit factor: <img src="https://tex.s2cms.ru/svg/PF%3D%7BP%20%5Cover%20L%7D" alt="PF = {P \ over L}">  where <img src="https://tex.s2cms.ru/svg/P">  - the amount of income, and <img src="https://tex.s2cms.ru/svg/L">  - amount of loss (positive number). <br><br>  What should be the profit factor so that you can talk about the stability of this system?  Obviously, the higher the profit factor, the more reasons to trust the system.  But the lower limit is estimated by different experts in different ways.  The most popular options are:&gt; 2 (so-so),&gt; 5 (good system),&gt; 10 (great system).  There is also such a variation: <img src="https://tex.s2cms.ru/svg/PF_m%3D%7BP-p_m%20%5Cover%20L%7D" alt="PF_m = {P-p_m \ over L}">  where <img src="https://tex.s2cms.ru/svg/p_m">  - The maximum value of the income on the transaction, this value is called a reliable profit factor.  It is believed that the minimum acceptable value for a reliable profit factor of 1.6. <br><br>  What always confused me in the profit factor was the fact that the market dynamics and the intensity of trade are not taken into account.  Therefore, I propose a different approach to assessing the significance of the profit factor, rather than a comparison with some a priori given value: the profit factor should be as high as possible, but <b>not lower than the profit factor of a random system in a random market</b> with similar trading intensity and volatility accordingly (in fact, not lower than that of the ‚Äúspherical trader‚Äù in the ‚Äúideal gas‚Äù or in the ‚Äúvacuum‚Äù). <br><br>  It remains only to build an ideal model for comparison. <br><a name="spherical"></a><br><h1>  "Spherical trader ..." </h1><br>  Suppose we are considering some random trading system (‚Äúspherical trader‚Äù).  Since the model is random, trading events occur at random points in time, regardless of the decisions made earlier.  The direction of transactions is also random (with a probability of 0.5 sale or purchase).  The volume of transactions is assumed constant, and without loss of generality, we estimate the profit and loss in points. <br><br>  Let the average duration of the transaction is <img src="https://tex.s2cms.ru/svg/t_0">  , and the average time between closing two subsequent transactions <img src="https://tex.s2cms.ru/svg/%5Ctau_0">  (we will not impose any restrictions on the number of simultaneously open transactions). <br><br>  Also assume that we will deal with Poisson flows of events: <br><br>  Transaction duration <img src="https://tex.s2cms.ru/svg/t">  will be a random variable with an <a href="https://habrahabr.ru/post/311092/">exponential</a> distribution: <br><a name="1_1"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f(t)%3D%5Clambda_te%5E%7B-%5Clambda_tt%7D%5C%20%5C%20%5C%20(1.1)" alt="f (t) = \ lambda_te ^ {- \ lambda_tt} \ \ \ (1.1)"></div><br>  Where <img src="https://tex.s2cms.ru/svg/%5Clambda_t%3D%7B1%20%5Cover%20t_0%7D">  . <br><br>  Amount of deals <img src="https://tex.s2cms.ru/svg/k">  committed over a period of time <img src="https://tex.s2cms.ru/svg/T">  will be described by the <a href="https://habrahabr.ru/post/311092/">Poisson</a> distribution: <br><a name="1_1"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/P_T(k)%3D%7B%7B%5Cleft(%5Clambda_%5Ctau%20T%20%5Cright)%7D%5Ek%20%5Cover%20k!%7De%5E%7B-%5Clambda_%5Ctau%20T%7D%5C%20%5C%20%5C%20(1.2)" alt="P_T (k) = {{\ left (\ lambda_ \ tau T \ right)} ^ k \ over k!} E ^ {- \ lambda_ \ tau T} \ \ \ (1.2)"></div><br>  Where <img src="https://tex.s2cms.ru/svg/%5Clambda_%5Ctau%3D%7B1%5Cover%20%5Ctau_0%7D">  . <br><a name="vacuum"></a><br><h1>  "... in a vacuum" </h1><br>  Now consider the ideal habitat of the ‚Äúspherical trader‚Äù - ‚Äúvacuum‚Äù, that is, a completely random market. <br><br>  Suppose that the market is described by the <a href="https://habrahabr.ru/post/311092/">normal</a> distribution of changes in the values ‚Äã‚Äãof quotes <img src="https://tex.s2cms.ru/svg/%5CDelta">  over a period of time <img src="https://tex.s2cms.ru/svg/T">  : <br><a name="2_1"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f(%5CDelta)%3D%7B1%20%5Cover%20%5Csigma_T%20%5Csqrt%7B2%20%5Cpi%7D%7De%5E%7B%5CDelta%5E2%20%5Cover%20%7B2%20%5Csigma_T%5E2%7D%7D%5C%20%5C%20%5C%20(2.1)" alt="f (\ Delta) = {1 \ over \ sigma_T \ sqrt {2 \ pi}} e ^ {\ Delta ^ 2 \ over {2 \ sigma_T ^ 2}} \ \ \ (2.1)"></div><br>  Where <img src="https://tex.s2cms.ru/svg/%5Csigma_T">  is determined as follows: let the quotes change for a unit time by a <a href="https://habrahabr.ru/post/311092/">normally</a> distributed random variable with variance <img src="https://tex.s2cms.ru/svg/%5Csigma_1%5E2">  then, if we consider the time intervals <img src="https://tex.s2cms.ru/svg/T">  by changing the quotes will have a variance: <br><a name="2_2"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Csigma_T%5E2%3D%5Csigma_1%5E2%20T%5C%20%5C%20%5C%20(2.2)" alt="\ sigma_T ^ 2 = \ sigma_1 ^ 2 T \\\ (2.2)"></div><br><br>  This is a known correlation for the Brownian process. <br><br>  Taking into account formulas <a href="https://habr.com/ru/post/312096/">(2.1)</a> and <a href="https://habr.com/ru/post/312096/">(1.1), the</a> result of the transaction, considered as a change in quotations over the period from the beginning to the end of the transaction, will be described as the integral of conditional probability <img src="https://tex.s2cms.ru/svg/f(%5CDelta_t%7Ct)">  by <img src="https://tex.s2cms.ru/svg/t">  : <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7B%5Csigma_1%2C%5Clambda_t%7D(%5CDelta)%3D%5Cint%5Climits_%7B0%7D%5E%7B%5Cinfty%7D%20%7B%5Clambda_t%20%5Cover%20%7B%5Csigma_1%20%5Csqrt%7B2%20%5Cpi%20t%7D%7D%7De%5E%7B-%7B%5CDelta%5E2%20%5Cover%20%7B2%20%5Csigma_1%5E2%20t%7D%7D%7De%5E%7B-%5Clambda_tt%7Ddt" alt="f _ {\ sigma_1, \ lambda_t} (\ Delta) = \ int \ limits_ {0} ^ {\ infty} {\ lambda_t \ over {\ sigma_1 \ sqrt {2 \ pi t}}} e ^ {- {\ Delta ^ 2 \ over {2 \ sigma_1 ^ 2 t}}} e ^ {- \ lambda_tt} dt"></div><br><br>  or <br><a name="2_3"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7B%5Csigma_1%2C%5Clambda_t%7D(%5CDelta)%3D%7B%5Clambda_t%20%5Cover%20%7B%5Csigma_1%20%5Csqrt%7B2%20%5Cpi%7D%7D%7D%5Cint%5Climits_%7B0%7D%5E%7B%5Cinfty%7D%20t%5E%7B-%7B1%20%5Cover%202%7D%7De%5E%7B-%7B%5CDelta%5E2%20%5Cover%20%7B2%20%5Csigma_1%5E2%20t%7D%7D%7De%5E%7B-%5Clambda_tt%7Ddt%5C%20%5C%20%5C%20(2.3)" alt="f _ {\ sigma_1, \ lambda_t} (\ Delta) = {\ lambda_t \ over {\ sigma_1 \ sqrt {2 \ pi}}} \ int \ limits_ {0} ^ {\ infty} t ^ {- {1 \ over 2}} e ^ {- {\ Delta ^ 2 \ over {2 \ sigma_1 ^ 2 t}}} e ^ {- \ lambda_tt} dt \ \ \ (2.3)"></div><br><br>  Solving this integral using Wolfram Mathematica gives the following result: <br><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7B%5Csigma_1%2C%5Clambda_t%7D(%5CDelta)%3D%7B1%20%5Cover%20%5Csqrt%7B2%7D%7D%7B%5Csqrt%7B%5Clambda_t%7D%20%5Cover%20%5Csigma_1%7De%5E%7B-%5Csqrt%7B2%7D%20%7B%5Csqrt%7B%5Clambda_t%7D%20%5Cover%20%5Csigma_1%7D%7C%5CDelta%7C%7D" alt="f _ {\ sigma_1, \ lambda_t} (\ Delta) = {1 \ over \ sqrt {2}} {\ sqrt {\ lambda_t} \ over \ sigma_1} e ^ {- \ sqrt {2} {\ sqrt {\ lambda_t } \ over \ sigma_1} | \ Delta |}"></div><br><br>  or <br><a name="2_4"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7B%5Csigma_1%2C%5Clambda_t%7D(%5CDelta)%3D%7B%5Calpha%20%5Cover%202%7De%5E%7B-%5Calpha%7C%5CDelta%7C%7D%5C%20%5C%20%5C%20(2.4)" alt="f _ {\ sigma_1, \ lambda_t} (\ Delta) = {\ alpha \ over 2} e ^ {- \ alpha | \ Delta |} \ \ \ (2.4)"></div><br><br>  Where <img src="https://tex.s2cms.ru/svg/%5Calpha%3D%7B%5Csqrt%7B2%20%5Clambda_t%7D%20%5Cover%20%5Csigma_1%7D" alt="\ alpha = {\ sqrt {2 \ lambda_t} \ over \ sigma_1}">  . <br><br>  The resulting pattern is the distribution of <a href="https://habrahabr.ru/post/311092/">Laplace</a> . <br><br>  Thus, the income or loss on a single transaction of a random system in a random market is described by the <a href="https://habrahabr.ru/post/311092/">Laplace</a> distribution, and the absolute value of the result <img src="https://tex.s2cms.ru/svg/R">  The transaction has an <a href="https://habrahabr.ru/post/311092/">exponential</a> distribution: <br><a name="2_5"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%5Calpha(R)%3D%5Calpha%20e%5E%7B-%5Calpha%20R%7D%5C%20%5C%20%5C%20(2.5)" alt="f_ \ alpha (R) = \ alpha e ^ {- \ alpha R} \ \ \ (2.5)"></div><br>  Where <img src="https://tex.s2cms.ru/svg/%5Calpha%3D%7B%5Csqrt%7B2%20%5Clambda_t%7D%20%5Cover%20%5Csigma_1%7D" alt="\ alpha = {\ sqrt {2 \ lambda_t} \ over \ sigma_1}">  . <br><br>  It is known that the <a href="https://habrahabr.ru/post/311092/">exponential</a> distribution is a special case of the <a href="https://habrahabr.ru/post/311092/">chi-square distribution</a> ( <img src="https://tex.s2cms.ru/svg/k%3D2">  at <img src="https://tex.s2cms.ru/svg/%5Calpha%3D0.5">  ).  This means that total income and total losses can be described as sums of random variables with a <a href="https://habrahabr.ru/post/311092/">chi-squared distribution</a> , which means that they themselves are <a href="https://habrahabr.ru/post/311092/">chi-squared</a> quantities. <br><br>  Let it be done <img src="https://tex.s2cms.ru/svg/k_p">  profitable trades with results <img src="https://tex.s2cms.ru/svg/R_i%5E%2B">  and <img src="https://tex.s2cms.ru/svg/k_l">  unprofitable with absolute losses <img src="https://tex.s2cms.ru/svg/R_i%5E-">  .  Then total income <img src="https://tex.s2cms.ru/svg/P_%5Calpha">  (normalized to <img src="https://tex.s2cms.ru/svg/2%20%5Calpha">  ) and total losses <img src="https://tex.s2cms.ru/svg/L_%5Calpha">  (also normalized to <img src="https://tex.s2cms.ru/svg/2%20%5Calpha">  ) will be described by <a href="https://habrahabr.ru/post/311092/">chi-square distributions</a> with degrees of freedom <img src="https://tex.s2cms.ru/svg/2k_p">  and <img src="https://tex.s2cms.ru/svg/2k_l">  respectively: <br><a name="2_6"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f%5Cleft(P_%5Calpha%20%5Cright)%3D%5Cchi_%7Bk_p%7D%5E2%5Cleft(%7BP_%5Calpha%5Cright)%5C%20%5C%20%5C%20(2.6)" alt="f \ left (P_ \ alpha \ right) = \ chi_ {k_p} ^ 2 \ left ({P_ \ alpha \ right) \ \ \ (2.6)"></div><br><a name="2_7"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f%5Cleft(L_%5Calpha%20%5Cright)%3D%5Cchi_%7Bk_l%7D%5E2%5Cleft(%7BL_%5Calpha%5Cright)%5C%20%5C%20%5C%20(2.7)" alt="f \ left (L_ \ alpha \ right) = \ chi_ {k_l} ^ 2 \ left ({L_ \ alpha \ right) \ \ \ (2.7)"></div><br><br>  Where <img src="https://tex.s2cms.ru/svg/P_%5Calpha%3D%7B1%20%5Cover%20%7B2%5Calpha%7D%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_p%7DR_i%5E%2B" alt="P_ \ alpha = {1 \ over {2 \ alpha}} \ sum \ limits_ {i = 1} ^ {k_p} R_i ^ +">  and <img src="https://tex.s2cms.ru/svg/L_%5Calpha%3D%7B1%20%5Cover%20%7B2%5Calpha%7D%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_l%7DR_i%5E-" alt="L_ \ alpha = {1 \ over {2 \ alpha}} \ sum \ limits_ {i = 1} ^ {k_l} R_i ^ -">  . <br><br>  the ratio of these values ‚Äã‚Äãwill be as follows: <br><a name="2_8"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%7BP_%5Calpha%20%5Cover%20%7BL_%5Calpha%7D%7D%3D%7B%7B%7B1%20%5Cover%20%7B2%5Calpha%7D%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_p%7DR_i%5E%2B%7D%5Cover%20%7B%7B1%20%5Cover%20%7B2%5Calpha%7D%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_l%7DR_i%5E-%7D%7D%3D%7B%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_p%7DR_i%5E%2B%7D%20%5Cover%20%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_l%7DR_i%5E-%7D%7D%3D%7BP%20%5Cover%20L%7D%3DPF%5C%20%5C%20%5C%20(2.8)" alt="{P_ \ alpha \ over {L_ \ alpha}} = {{{1 \ over {2 \ alpha}} \ sum \ limits_ {i = 1} ^ {k_p} R_i ^ +} \ over {{1 \ over { 2 \ alpha}} \ sum \ limits_ {i = 1} ^ {k_l} R_i ^ -}} = {{\ sum \ limits_ {i = 1} ^ {k_p} R_i ^ +} \ over {\ sum \ limits_ {i = 1} ^ {k_l} R_i ^ -}} = {P \ over L} = PF \ \ \ (2.8)"></div><br><br>  Where <img src="https://tex.s2cms.ru/svg/P%3D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_p%7DR_i%5E%2B" alt="P = \ sum \ limits_ {i = 1} ^ {k_p} R_i ^ +">  total income as well <img src="https://tex.s2cms.ru/svg/L%3D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bk_l%7DR_i%5E-" alt="L = \ sum \ limits_ {i = 1} ^ {k_l} R_i ^ -">  total losses.  Their attitude <img src="https://tex.s2cms.ru/svg/PF%3D%7BP%20%5Cover%20L%7D">  - profit factor. <br><br>  Now consider the following value: <br><a name="2_9"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/PF_k%3DPF%5Ctimes%7Bk_l%5Cover%20%7Bk_p%7D%7D%5C%20%5C%20%5C%20(2.9)" alt="PF_k = PF \ times {k_l \ over {k_p}} \ \ \ (2.9)"></div><br><br>  This value can be interpreted as a ‚Äúnormalized profit factor‚Äù: the ratio of the average income to the average loss per transaction.  Let's see what distribution this quantity has: <br><a name="2_10"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/PF_k%3DPF%5Ctimes%7Bk_l%5Cover%20%7Bk_p%7D%7D%3D%7BP%20%5Cover%20L%7D%5Ctimes%7Bk_l%5Cover%20%7Bk_p%7D%7D%3D%7B%7BP_%5Calpha%7D%20%5Cover%20%7BL_%5Calpha%7D%7D%5Ctimes%7Bk_l%5Cover%20%7Bk_p%7D%7D%3D%7B%7B%7BP_%5Calpha%7D%20%5Cover%20%7B2k_p%7D%7D%5Cover%7B%7BL_%5Calpha%7D%20%5Cover%20%7B2k_l%7D%7D%7D%5C%20%5C%20%5C%20(2.10)" alt="PF_k = PF \ times {k_l \ over {k_p}} = {P \ over L} \ times {k_l \ over {k_p}} = {{P_ \ alpha} \ over {L_ \ alpha}} \ times {k_l \ over {k_p}} = {{{P_ \ alpha} \ over {2k_p}} \ over {{L_ \ alpha} \ over {2k_l}}} \ \ \ (2.10)"></div><br><br>  The resulting quantity, the <a href="https://habrahabr.ru/post/311092/">chi-squared</a> ratio of the quantities normalized to the number of their degrees of freedom, has a <a href="https://habrahabr.ru/post/311092/">Fisher</a> distribution. <br><br>  So we found the distribution of the magnitude, the statistics <img src="https://tex.s2cms.ru/svg/PF_k">  for the profit factor "spherical trader in a vacuum" with a known amount of profitable <img src="https://tex.s2cms.ru/svg/k_p">  and unprofitable <img src="https://tex.s2cms.ru/svg/k_l">  deals. <br><br>  Before proceeding to the generalization to the case of unknowns <img src="https://tex.s2cms.ru/svg/k_p">  and <img src="https://tex.s2cms.ru/svg/k_l">  Let us consider the behavior of the ‚Äúspherical trader‚Äù in the ‚Äúnot entirely random‚Äù market (let's call this environment a joke ‚Äúthe ideal gas‚Äù). <br><br><h1>  "... in perfect gas" </h1><br>  Now consider a slightly more complicated situation: when the market is a generalized Brownian motion.  That is, unlike the random, has a memory.  In this case, formula <a href="https://habr.com/ru/post/312096/">(2.2)</a> will take the following form: <br><a name="3_1"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Csigma_T%5E2%3D%5Csigma_1%5E2%20T%5E%7B2H%7D%5C%20%5C%20%5C%20(3.1)" alt="\ sigma_T ^ 2 = \ sigma_1 ^ 2 T ^ {2H} \ \ \ (3.1)"></div><br><br>  Where <img src="https://tex.s2cms.ru/svg/H">  - Hurst index, a quantity characterizing the fractal properties of the time series and related to the fractal dimension of Hausdorff-Besicovitch <img src="https://tex.s2cms.ru/svg/D">  in the following way: <img src="https://tex.s2cms.ru/svg/D=2-H">  .  Hurst's indicator can take values <img src="https://tex.s2cms.ru/svg/0%3CH%3C1">  . <br><br>  With <img src="https://tex.s2cms.ru/svg/H%3D0.5">  the time series degenerates into a random, non-memory, corresponding to the case considered above.  With <img src="https://tex.s2cms.ru/svg/H%3C0.5">  the series is constantly striving to change the direction of the existing trend, and therefore has a memory, such a series is called antipersistent, chaotic.  With <img src="https://tex.s2cms.ru/svg/H%3E0.5">  the series also has a memory, but seeks to preserve the existing trend, such a series is called persistent, deterministic.  The stronger the Hurst index is different from 0.5, the more clearly the chaotic or deterministic properties are expressed in the series. <br><br>  Different markets are characterized by different values ‚Äã‚Äãof the Hurst index, in addition, they may change from time to time.  Hurst index can be calculated by the values ‚Äã‚Äãof the time series.  So, when evaluating the profit factor, you can take into account the value <img src="https://tex.s2cms.ru/svg/H">  calculated by a number of quotes in the same period when transactions of the analyzed strategy were made.  There are several standard procedures for estimating the Hurst index, for example RS-statistics or wavelet-based methods. <br><br>  Suppose that a random trading strategy works on the market with the Hurst index H, then, taking into account <a href="https://habr.com/ru/post/312096/">(3.1)</a> , the formula <a href="https://habr.com/ru/post/312096/">(2.3)</a> takes the form: <br><a name="3_2"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7B%5Csigma_1%2C%5Clambda_t%2CH%7D(%5CDelta)%3D%7B%5Clambda_t%20%5Cover%20%7B%5Csigma_1%20%5Csqrt%7B2%20%5Cpi%7D%7D%7D%5Cint%5Climits_%7B0%7D%5E%7B%5Cinfty%7D%20t%5E%7B-H%7De%5E%7B-%7B%5CDelta%5E2%20%5Cover%20%7B2%20%5Csigma_1%5E2%20t%5E%7B2H%7D%7D%7D%7De%5E%7B-%5Clambda_tt%7Ddt%5C%20%5C%20%5C%20(3.2)" alt="f _ {\ sigma_1, \ lambda_t, H} (\ Delta) = {\ lambda_t \ over {\ sigma_1 \ sqrt {2 \ pi}}} \ int \ limits_ {0} ^ {\ infty} t ^ {- H} e ^ {- {\ Delta ^ 2 \ over {2 \ sigma_1 ^ 2 t ^ {2H}}}} e ^ {- \ lambda_tt} dt \ \ \ (3.2)"></div><br><br>  Obviously, when <img src="https://tex.s2cms.ru/svg/H%3D0.5">  This expression is equivalent to <a href="https://habr.com/ru/post/312096/">(2.3)</a> . <br><br>  Unfortunately, expression <a href="https://habr.com/ru/post/312096/">(3.2)</a> is not integrated analytically.  Therefore, to find the distribution of the absolute values ‚Äã‚Äãof the difference in quotations between the moments of the beginning and end of the transaction (absolute transactions) for random trading in the market with the Hurst index <img src="https://tex.s2cms.ru/svg/H">  we use numerical simulation. <br><br>  I conducted simulations using Python. <br><br>  The simulation is as follows. <br><br>  1) Set the simulation parameters: <br><img src="https://tex.s2cms.ru/svg/N%3D1000000">  - the volume of the experimental sample; <br><img src="https://tex.s2cms.ru/svg/M%3D100">  - the number of ranges to build a histogram <br><br>  2) Generate a sample distE of an <a href="https://habrahabr.ru/post/311092/">exponentially</a> distributed random variable and a sample distN of a <a href="https://habrahabr.ru/post/311092/">normally</a> distributed variable of volume N each. <br><br>  3) Given the relation <a href="https://habr.com/ru/post/312096/">(3.1)</a> , we create a test sample distT, each value of which is calculated from the corresponding distN and distE values: <img src="https://tex.s2cms.ru/svg/distT%5Bi%5D%3D%5Cleft%7CdistN%5Bi%5D%20%5Ctimes%20distE%5Bi%5D%5EH%5Cright%7C"><br><br>  4) For the distribution obtained, a histogram of M ranges is constructed (the number of hits in the ranges).  From the obtained histogram, K first ranges are selected, the number of hits in which is different from zero.  Also rationing is performed on the number of hits in the first range. <br><br>  5) Based on the obtained histogram, the type of distribution is approximated. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> stats <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">testH</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(N, M, H, p)</span></span></span><span class="hljs-function">:</span></span> distE = np.random.exponential(<span class="hljs-number"><span class="hljs-number">1</span></span>, N) distN = np.random.normal(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, N) distT = abs(distN * distE**H) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p == <span class="hljs-number"><span class="hljs-number">1</span></span>: plt.figure(<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.hist(distT, M) plt.title(<span class="hljs-string"><span class="hljs-string">'H='</span></span>+str(H)) [y, x] = np.histogram(distT, M) K = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(M): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> y[i] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: K = i <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> y = y * <span class="hljs-number"><span class="hljs-number">1.0</span></span> / y[<span class="hljs-number"><span class="hljs-number">0</span></span>] x = x[<span class="hljs-number"><span class="hljs-number">1</span></span>:K] y = y[<span class="hljs-number"><span class="hljs-number">1</span></span>:K] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> getCoeff(x, y, p, <span class="hljs-string"><span class="hljs-string">'H='</span></span>+str(H))</code> </pre> <br>  Examples of histograms of the obtained distributions for the values ‚Äã‚Äãof the Hurst index 0.1, 0.3, 0.5, 0.7 and 0.9 are given below. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6c3/fb4/f9e/6c3fb4f9eedc4e02922e7fb6a5829d0c.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a8d/f86/cd4/a8df86cd4804447ea743b0acde2ba7c8.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9f5/b5c/5ae/9f5b5c5ae1c746dfbb9132ef7cd1725a.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b03/624/1f3/b036241f38f143e6a96a6bcf77a46029.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/860/384/e7c/860384e7c38541969dba360f920f0a49.png"></div><br>  The general view of the histograms suggests that the obtained distributions, up to a constant, can be described by a function of the form: <br><a name="3_3"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7B%5Csigma_1%2C%5Clambda_t%2CH%7D(%5CDelta)%3DCe%5E%7B-%5CDelta%5E%7BK_%7B%5Csigma_1%2C%5Clambda_t%2CH%7D%7D%7D%5C%20%5C%20%5C%20(3.3)" alt="f _ {\ sigma_1, \ lambda_t, H} (\ Delta) = Ce ^ {- \ Delta ^ {K _ {\ sigma_1, \ lambda_t, H}}} \ \ \ (3.3)"></div><br><br>  To search for the distribution parameter, we use the following algorithm: <br><br>  1) Let us be given <img src="https://tex.s2cms.ru/svg/X">  - centroids of histogram ranges and <img src="https://tex.s2cms.ru/svg/Y">  - the number of hits in the ranges normalized to the number hit in the first range. <br><br>  2) Then, ignoring the first range, perform the conversion: <img src="https://tex.s2cms.ru/svg/X'%3Dln(X)">  and <img src="https://tex.s2cms.ru/svg/Y'%3Dln(-ln(Y))"><br><br>  3) Using the method of least squares, we find the parameters of linear regression <img src="https://tex.s2cms.ru/svg/K">  and <img src="https://tex.s2cms.ru/svg/B">  such that <img src="https://tex.s2cms.ru/svg/Y'%5Capprox%20KX'%2BB"><br><br>  4) Based on received <img src="https://tex.s2cms.ru/svg/K">  accept: <br><br><img src="https://tex.s2cms.ru/svg/K_%7B%5Csigma_1%2C%5Clambda_t%2CH%7D%3DK">  . <br><br>  Parameter <img src="https://tex.s2cms.ru/svg/B">  compensates for the error of normalization. <br><br>  The listing of the procedure for calculating the coefficients is given below: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getCoeff</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, p, S)</span></span></span><span class="hljs-function">:</span></span> X = np.log(x) Y = np.log(-np.log(y)) n = len(X) k = (sum(X) * sum(Y) - n * sum(X * Y)) / (sum(X) ** <span class="hljs-number"><span class="hljs-number">2</span></span> - n * sum(X ** <span class="hljs-number"><span class="hljs-number">2</span></span>)) b = (sum(Y) - k * sum(X)) / n <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p == <span class="hljs-number"><span class="hljs-number">1</span></span>: plt.figure(<span class="hljs-number"><span class="hljs-number">2</span></span>) plt.plot(np.exp(X), np.exp(-np.exp(Y)), <span class="hljs-string"><span class="hljs-string">'b'</span></span>, np.exp(X), np.exp(-np.exp(k * X + b)), <span class="hljs-string"><span class="hljs-string">'r'</span></span>) plt.title(S) plt.show() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> k</code> </pre><br>  The following are examples for envelopes of histograms for the Hurst values ‚Äã‚Äãof 0.1, 0.3, 0.5, 0.7 and 0.9 (blue line) and their models (red line): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/08d/3b3/863/08d3b3863f954a8eab762e16cce0014d.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/39e/5c2/a0a/39e5c2a0a89649609a92e0ee1094109f.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/974/94e/ee0/97494eee06fb47e09b8407c77245a481.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/f1f/6ef/19d/f1f6ef19d043437e974834c6bcaf945d.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e39/7aa/d53/e397aad53a3c46bdbd5375e9ce341573.png"></div><br>  With the values ‚Äã‚Äãof the Hurst index above 0.5, the simulation accuracy is higher. <br><br>  Now we find the dependence <img src="https://tex.s2cms.ru/svg/K">  from <img src="https://tex.s2cms.ru/svg/H">  .  To do this, we simulate a series of values <img src="https://tex.s2cms.ru/svg/K">  for various <img src="https://tex.s2cms.ru/svg/H">  and try to establish a functional dependency. <br><br>  I used to simulate the values <img src="https://tex.s2cms.ru/svg/H">  from 0.01 to 0.99 in increments of 0.01.  In addition, for each value <img src="https://tex.s2cms.ru/svg/H">  values <img src="https://tex.s2cms.ru/svg/K">  calculated 20 times and averaged: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: N = <span class="hljs-number"><span class="hljs-number">1000000</span></span>; M = <span class="hljs-number"><span class="hljs-number">100</span></span>; Z = np.zeros((<span class="hljs-number"><span class="hljs-number">99</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">99</span></span>): Z[i, <span class="hljs-number"><span class="hljs-number">0</span></span>] = (i + <span class="hljs-number"><span class="hljs-number">1</span></span>) * <span class="hljs-number"><span class="hljs-number">0.01</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">20</span></span>): W = float(<span class="hljs-string"><span class="hljs-string">'nan'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> np.isnan(W): W = testH(N, M, (i + <span class="hljs-number"><span class="hljs-number">1</span></span>) * <span class="hljs-number"><span class="hljs-number">0.01</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>) Z[i, <span class="hljs-number"><span class="hljs-number">1</span></span>] += W Z[i, <span class="hljs-number"><span class="hljs-number">1</span></span>] *= <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> Z[i, :] X = Z[:, <span class="hljs-number"><span class="hljs-number">0</span></span>].T Y = Z[:, <span class="hljs-number"><span class="hljs-number">1</span></span>].T plt.figure(<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(X, Y) plt.show()</code> </pre><br>  The resulting dependence is as follows: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9bb/e5e/366/9bbe5e366cbd4dd7a7cede394c5df015.png"></div><br>  The graph looks like a distorted sigmoid, so we will look for the pattern as a sigmoid: <br><a name="3_4"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/K(H)%3Dd%20-%20%7Bc%20%5Cover%20b%20%2B%20e%5E%7Ba_3%20H%5E3%20%2B%20a_2%20H%5E2%20%2B%20a_1%20H%20%2B%20a_0%7D%7D%5C%20%5C%20%5C%20(3.4)" alt="K (H) = d - {c \ over b + e ^ {a_3 H ^ 3 + a_2 H ^ 2 + a_1 H + a_0}} \ \ \ (3.4)"></div><br>  A numerical minimization procedure using the least squares method gives the following results: <br><br><img src="https://tex.s2cms.ru/svg/a_0%20%3D%205.8857559002%5C%5C%0Aa_1%20%3D%20-18.9879949799%5C%5C%0Aa_2%20%3D%2022.9482650626%5C%5C%0Aa_3%20%3D%20-12.2596355071688%5C%5C%0Ab%20%20%3D%204.0311294847%5C%5C%0Ac%20%20%3D%205.2838274853%5C%5C%0Ad%20%20%3D%201.9023437995"><br><br>  The total quadratic error is about 0.005. <br><br>  Below are graphs of experimental dependence <img src="https://tex.s2cms.ru/svg/K(H)">  (blue line) and model line according to formula <a href="https://habr.com/ru/post/312096/">(3.4)</a> (red line): <br><div style="text-align:center;"><img src="https://habrastorage.org/files/568/83e/667/56883e6674c64944a50be69c6e9de871.png"></div><br>  It should be noted that the obtained pattern is valid only for the case when <img src="https://tex.s2cms.ru/svg/%5Csigma_1%3D1">  and <img src="https://tex.s2cms.ru/svg/%5Clambda_t%3D1">  .  Therefore, in the future, we will assume that these conditions are fulfilled (we will ensure their fulfillment) and omit the corresponding indices. <br><br>  Now, considering <a href="https://habr.com/ru/post/312096/">(3.3)</a> and <a href="https://habr.com/ru/post/312096/">(3.4)</a> for the estimated value <img src="https://tex.s2cms.ru/svg/H">  we know the distribution of the absolute value of transactions.  Using the <a href="https://habrahabr.ru/post/311092/">distribution property of the transformation of a random variable</a> , we make the replacement of the variable in <a href="https://habr.com/ru/post/312096/">(3.4)</a> : <br><a name="3_5"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Cdelta%3D%5CDelta%5E%7BK(H)%7D%5C%20%5C%20%5C%20(3.6)"></div><br><br>  Then: <br><a name="3_6"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f_%7BH%7D(%5CDelta)%3DCe%5E%7B-%5CDelta%5E%7BK(H)%7D%7D%20%3E%3E%3E%20f'_%7BH%7D(%5Cdelta)%3D%7BC%20%5Cover%20K%7D%5Cdelta%5E%7B%7B1%20%5Cover%20%7BK(H)%7D%7D-1%7De%5E%7B-%5Cdelta%7D%5C%20%5C%20%5C%20(3.6)" alt="f_ {H} (\ Delta) = Ce ^ {- \ Delta ^ {K (H)}} >>> f '_ {H} (\ delta) = {C \ over K} \ delta ^ {{1 \ over {K (H)}} - 1} e ^ {- \ delta} \ \ \ (3.6)"></div><br><br>  This is a probability density function of a quantity having a <a href="https://habrahabr.ru/post/311092/">gamma distribution</a> with a number of degrees of freedom. <img src="https://tex.s2cms.ru/svg/k%3D%7B1%20%5Cover%20%7BK(H)%7D%7D">  and a single scale parameter.  Given this, formula <a href="https://habr.com/ru/post/312096/">(3.6)</a> .  Must be rewritten as: <br><a name="3_7"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/f'_%7BH%7D(%5Cdelta)%3D%7B1%20%5Cover%20%7B%5CGamma%5Cleft(%7B1%20%5Cover%20%7BK(H)%7D%7D%5Cright)%7D%7D%5Cdelta%5E%7B%7B1%20%5Cover%20%7BK(H)%7D%7D-1%7De%5E%7B-%5Cdelta%7D%5C%20%5C%20%20(3.7)" alt="f '_ {H} (\ delta) = {1 \ over {\ Gamma \ left ({1 \ over {K (H)}} \ right)}} \ delta ^ {{1 \ over {K (H) }} - 1} e ^ {- \ delta} \ \ (3.7)"></div><br><br>  Let's summarize: <br><br>  Having information about the Hearst Market Indicator <img src="https://tex.s2cms.ru/svg/H">  calculated for the same period of history on which we test the system, we can find the value <img src="https://tex.s2cms.ru/svg/K">  using formula <a href="https://habr.com/ru/post/312096/">(3.4)</a> .  We can also find the average trade intensity <img src="https://tex.s2cms.ru/svg/%5Clambda_t">  and parameter <img src="https://tex.s2cms.ru/svg/%5Csigma_1">  for transaction results.  In order for the formulas proposed above to be valid, it is necessary to give the values <img src="https://tex.s2cms.ru/svg/%5Clambda_t">  and <img src="https://tex.s2cms.ru/svg/%5Csigma_1">  to unit.  To do this, perform the normalization: <img src="https://tex.s2cms.ru/svg/R'_i%3D%7B%7BR_i%20%5Clambda_t%5EH%7D%20%5Cover%20%5Csigma_1%7D">  where <img src="https://tex.s2cms.ru/svg/R_i">  - result <img src="https://tex.s2cms.ru/svg/i">  transactions (regardless of the sign of the result).  This transformation follows from <a href="https://habr.com/ru/post/312096/">(3.1)</a> . <br><br>  According to <a href="https://habr.com/ru/post/312096/">(3.7)</a> , the values <img src="https://tex.s2cms.ru/svg/%5Cdelta_i%3D%7CR_i%7C%5EK">  will have <a href="https://habrahabr.ru/post/311092/">gamma distributions</a> with parameters <img src="https://tex.s2cms.ru/svg/(K%2C%201)">  .  Therefore, the values <img src="https://tex.s2cms.ru/svg/2%5Cdelta_i">  will have a <a href="https://habrahabr.ru/post/311092/">chi-square distribution</a> c <img src="https://tex.s2cms.ru/svg/2K">  degrees of freedom. <br><br>  Let it be done <img src="https://tex.s2cms.ru/svg/k_p">  profitable transactions with income values <img src="https://tex.s2cms.ru/svg/R%5E%2B_i">  and <img src="https://tex.s2cms.ru/svg/k_l">  with loss values <img src="https://tex.s2cms.ru/svg/R%5E-_i">  (positive values).  Then, taking into account <a href="https://habr.com/ru/post/312096/"><img src="https://tex.s2cms.ru/svg/K(H)"></a>  and <a href="https://habr.com/ru/post/312096/">(3.7)</a> values <br><br><img src="https://tex.s2cms.ru/svg/P_H%3D2%5Csum%20%5Climits_%7Bi%3D1%7D%5E%7Bk_P%7D%7B(R_i%5E%2B)%7D%5E%7BK(H)%7D" alt="P_H = 2 \ sum \ limits_ {i = 1} ^ {k_P} {(R_i ^ +)} ^ {K (H)}"><br><br>  and <br><br><img src="https://tex.s2cms.ru/svg/L_H%3D2%5Csum%20%5Climits_%7Bi%3D1%7D%5E%7Bk_L%7D%7B(R_i%5E-)%7D%5E%7BK(H)%7D" alt="L_H = 2 \ sum \ limits_ {i = 1} ^ {k_L} {(R_i ^ -)} ^ {K (H)}"><br><br>  will have a <a href="https://habrahabr.ru/post/311092/">chi-square</a> distribution with quantities of degrees of freedom <img src="https://tex.s2cms.ru/svg/2k_PK(H)">  and <img src="https://tex.s2cms.ru/svg/2k_LK(H)">  respectively. <br><br>  Therefore, the value: <br><a name="3_8"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/PF_H%3D%7BP_H%5Cover%7BL_H%7D%7D%5Ctimes%7Bk_L%5Cover%20%7Bk_P%7D%7D%3D%7B%7B%5Csum%20%5Climits_%7Bi%3D1%7D%5E%7Bk_P%7D%7B(R_i%5E%2B)%7D%5E%7BK(H)%7D%7D%5Cover%7B%5Csum%20%5Climits_%7Bi%3D1%7D%5E%7Bk_L%7D%7B(R_i%5E-)%7D%5E%7BK(H)%7D%7D%7D%5Ctimes%7Bk_L%5Cover%20%7Bk_P%7D%7D%5C%20%5C%20%5C%20(3.8)" alt="PF_H = {P_H \ over {L_H}} \ times {k_L \ over {k_P}} = {{\ sum \ limits_ {i = 1} ^ {k_P} {(R_i ^ +)} ^ {K (H)} } \ over {\ sum \ limits_ {i = 1} ^ {k_L} {(R_i ^ -)} ^ {K (H)}}} \ times {k_L \ over {k_P}} \ \ \ (3.8)"></div><br><br>  will have a <a href="https://habrahabr.ru/post/311092/">Fisher</a> distribution c <img src="https://tex.s2cms.ru/svg/%5Cleft%5B2k_PK(H)%2C%202k_LK(H)%5Cright%5D">  degrees of freedom (the number of degrees of freedom, in general, will be non-integer, thus the fractal properties of the market are manifested). <br><br>  Let's call the value <img src="https://tex.s2cms.ru/svg/PF_H">  generalized normalized profit factor.  With <img src="https://tex.s2cms.ru/svg/H%3D0.5">  the generalized profit factor degenerates into the normalized normal profit factor <a href="https://habr.com/ru/post/312096/">(2.9)</a> . <br><br><h1>  Final summary </h1><br>  So, we investigated the ‚Äúspherical trader‚Äù in a random market and found the distribution of the normalized profit factor.  Then we summarized the results for the case of a market with an arbitrary fractal dimension, represented by a measurable quantity - the Hurst index. <br><br>  Now we have a value that we call the generalized normalized profit factor, which is calculated using information on the results of transactions (by the way, let's not forget to correct them taking into account the spread: take it away from losses and add to income).  For greater universality of the methodology, the volume of transactions is considered constant, or we measure everything in points.  Do not forget also to carry out the normalization of the average duration of the transaction and the standard deviation of the distribution of the results of transactions: <img src="https://tex.s2cms.ru/svg/R'_i%3D%7B%7BR_i%20%5Clambda_t%5EH%7D%20%5Cover%5Csigma_1%7D">  where <img src="https://tex.s2cms.ru/svg/R_i">  - result <img src="https://tex.s2cms.ru/svg/i">  deal. <br><br>  All the results obtained so far are tied to a known number of profitable and unprofitable transactions, which is a random variable with a <a href="https://habrahabr.ru/post/311092/">binomial</a> distribution for a known total number of transactions, which, in turn, is also a random variable distributed across <a href="https://habrahabr.ru/post/311092/">Poisson</a> . <br><br>  We introduce a new designation.  Let the generalized normalized profit factor <a href="https://habr.com/ru/post/312096/">(3.8)</a> for a given amount of profitable <img src="https://tex.s2cms.ru/svg/k_P">  and the amount of unprofitable <img src="https://tex.s2cms.ru/svg/k_L">  transactions (with a known indicator of Hirst <img src="https://tex.s2cms.ru/svg/H">  ) is denoted by <img src="https://tex.s2cms.ru/svg/PF_%7BH%2C%20k_P%2Ck_L%7D">  and has a <a href="https://habrahabr.ru/post/311092/">Fisher</a> distribution with degrees of freedom <img src="https://tex.s2cms.ru/svg/%5Cleft%5B2k_PK(H)%2C%202k_LK(H)%5Cright%5D">  . <br><br>  Then, taking into account the <a href="https://habrahabr.ru/post/311092/">binomial</a> distribution of the number of profitable and unprofitable transactions, as well as the equal probability of receiving income or loss on each transaction, we introduce the value <img src="https://tex.s2cms.ru/svg/PF_%7BH%2C%20N%7D">  - generalized normalized profit factor, taking into account only the total number of transactions.  This value will have the following distribution: <br><a name="4_1"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/F_N(PF_%7BH%2C%20N%7D)%3D%5Cleft(%7B1%20%5Cover%202%7D%5Cright)%5EN%5Csum%5Climits_%7Bk%3D0%7D%5E%7BN%7D%7B%5Cleft%5B%7BN!%5Cover%7Bk!(N-k)!%7D%7D%20F_%7B2kK(H)%2C2(N-k)K(H)%7D(PF_%7BH%2C%20N%7D)%5Cright%5D%7D%5C%20%5C%20%5C%20(4.1)" alt="F_N (PF_ {H, N}) = \ left ({1 \ over 2} \ right) ^ N \ sum \ limits_ {k = 0} ^ {N} {\ left [{N! \ Over {k! ( Nk)!}} F_ {2kK (H), 2 (Nk) K (H)} (PF_ {H, N}) \ right]} \ \ \ (4.1)"></div><br><br>  Where <img src="https://tex.s2cms.ru/svg/F_%7Bk_1%2Ck_2%7D(x)">  - <a href="https://habrahabr.ru/post/311092/">Fisher</a> distribution density with degrees of freedom <img src="https://tex.s2cms.ru/svg/k_1">  and <img src="https://tex.s2cms.ru/svg/k_2">  and value <img src="https://tex.s2cms.ru/svg/K(H)">  described by formula <a href="https://habr.com/ru/post/312096/">(3.4)</a> , where <img src="https://tex.s2cms.ru/svg/H">  - Hurst figure. <br><br>  In practice, with sufficiently large <img src="https://tex.s2cms.ru/svg/N">  expression <a href="https://habr.com/ru/post/312096/">(4.1)</a> can be approximated by an incomplete sum: <br><a name="4_1_"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/F_N(PF_%7BH%2C%20N%7D)%3D%7B%5Csum%5Climits_%7Bk%3Da%7D%5E%7Bb%7D%7B%5Cleft%5B%7BN!%5Cover%7Bk!(N-k)!%7D%7D%20F_%7B2kK(H)%2C2(N-k)K(H)%7D(PF_%7BH%2C%20N%7D)%5Cright%5D%7D%20%5Cover%20%7B%5Csum%5Climits_%7Bk%3Da%7D%5E%7Bb%7D%7BN!%5Cover%7Bk!(N-k)!%7D%7D%7D%7D%5C%20%5C%20%5C%20(4.1*)" alt="F_N (PF_ {H, N}) = {\ sum \ limits_ {k = a} ^ {b} {\ left [{N! \ Over {k! (Nk)!}} F_ {2kK (H), 2 (Nk) K (H)} (PF_ {H, N}) \ right]} \ over {\ sum \ limits_ {k = a} ^ {b} {N! \ Over {k! (Nk)!}} }} \ \ \ (4.1 *)"></div><br><br>  Where <img src="https://tex.s2cms.ru/svg/a">  and <img src="https://tex.s2cms.ru/svg/b">  ( <img src="https://tex.s2cms.ru/svg/a%3Cb">  ) limit a subset of the possible values ‚Äã‚Äãof the number of profitable transactions. <br><br>  Now we will consider the generalized normalized profit factor without reference to any number of transactions, but only taking into account the average trade intensity <img src="https://tex.s2cms.ru/svg/%5Clambda_%5Ctau">  and the testing period of the strategy <img src="https://tex.s2cms.ru/svg/T">  : <img src="https://tex.s2cms.ru/svg/PF_%7B%5Clambda_%5Ctau%2CT%2CH%7D">  .  Given that the total number of transactions is distributed by <a href="https://habrahabr.ru/post/311092/">Poisson</a> , <img src="https://tex.s2cms.ru/svg/PF_%7B%5Clambda_%5Ctau%2CT%2CH%7D">  will have the following distribution: <br><a name="4_2"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/PF_%7B%5Clambda_%5Ctau%2CT%2CH%7D%3D%5Csum%5Climits_%7Bk%3D0%7D%5E%5Cinfty%20%7B%7B%5Cleft(%5Clambda_%5Ctau%20T%5Cright)%5Ek%5Cover%7Bk!%7D%7DF_k(PF_%7BH%2CN%7D)%7D%5C%20%5C%20%5C%20(4.2)" alt="PF _ {\ lambda_ \ tau, T, H} = \ sum \ limits_ {k = 0} ^ \ infty {{\ left (\ lambda_ \ tau T \ right) ^ k \ over {k!}} F_k (PF_ { H, N})} \ \ \ (4.2)"></div><br><br>  Or, for the considered number of transactions in the range <img src="https://tex.s2cms.ru/svg/%5Ba%2Cb%5D">  : <br><a name="4_2_"></a><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/PF_%7B%5Clambda_%5Ctau%2CT%2CH%7D%3D%7B%5Csum%5Climits_%7Bk%3Da%7D%5Eb%20%7B%7B%5Cleft(%5Clambda_%5Ctau%20T%5Cright)%5Ek%5Cover%7Bk!%7D%7DF_k(PF_%7BH%2CN%7D)%7D%20%5Cover%20%7B%5Csum%20%5Climits%20_%7Bk%3Da%7D%5Eb%7B%5Cleft(%5Clambda_%5Ctau%20T%5Cright)%5Ek%5Cover%7Bk!%7D%7D%7D%7D%5C%20%5C%20%5C%20(4.2*)" alt="PF _ {\ lambda_ \ tau, T, H} = {\ sum \ limits_ {k = a} ^ b {{left (\ lambda_ \ tau T \ right) ^ k \ over {k!}} F_k (PF_ { H, N})} \ over {\ sum \ limits _ {k = a} ^ b {\ left (\ lambda_ \ tau T \ right) ^ k \ over {k!}}}} \ \ \ (4.2 * )"></div><br><br>  The obtained distribution can be used to test the significance of the generalized normalized profit factor calculated by <a href="https://habr.com/ru/post/312096/">(3.8)</a> for a trading system with a known average transaction duration and trading intensity for a certain amount of time in the market with known volatility and Hurst index.  The method of application of the test is absolutely similar to that for the <a href="https://habrahabr.ru/post/311092/">Fisher</a> test.  To carry it out, it suffices to replace in <a href="https://habr.com/ru/post/312096/">(4.1)</a> (or <a href="https://habr.com/ru/post/312096/">(4.1 *)</a> ) the density function with the Fisher distribution function and substitute the value of the calculated generalized profit factor as an argument.  The resulting probability value must be compared with the value <img src="https://tex.s2cms.ru/svg/1-%5Calpha">  where <img src="https://tex.s2cms.ru/svg/%5Calpha">  - required level of significance.  If this level is exceeded for the calculated statistics, one can reject the hypothesis about the randomness of the trading system (about the ‚Äúsphericity of the trader in a vacuum‚Äù). <br><br><h1>  Conclusion </h1><br>  The proposed approach based on the construction of a generalized normalized profit factor, taking into account the volatility and fractal properties of the market, as well as the intensity of trade and the average duration of transactions, allows us to construct a statistical test of the significance of the results achieved in terms of the likelihood of similar results being obtained randomly.  Using the test, it is possible with a given level of significance to talk about the fulfillment of the <b>necessary</b> condition for ascertaining the reliability of the system.  But the results will not be a <b>sufficient</b> condition ... <br><br>  Unfortunately, I do not know the test, the results of which will be sufficient for the unequivocal adoption of a strategy as unconditionally reliable. </div><p>Source: <a href="https://habr.com/ru/post/312096/">https://habr.com/ru/post/312096/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312084/index.html">DIY Password Manager</a></li>
<li><a href="../312086/index.html">Easy way to lose customers or why not use Google CDN</a></li>
<li><a href="../312088/index.html">ES6 const is not about immunity</a></li>
<li><a href="../312090/index.html">PostgreSQL integration with MS SQL Server for those who want quicker and deeper</a></li>
<li><a href="../312092/index.html">We consider porn sites, we evaluate the effectiveness of Roskomnadzor</a></li>
<li><a href="../312098/index.html">Y Combinator recommends reading in 2016</a></li>
<li><a href="../312110/index.html">"Flaskr" - introduction to Flask, development through testing (TDD) and jQuery</a></li>
<li><a href="../312112/index.html">Free backup utility with free ESXI</a></li>
<li><a href="../312114/index.html">Dribbble: review of the most interesting interface designs for the past week</a></li>
<li><a href="../312118/index.html">‚ÄúFaster, higher, stronger‚Äù: New data-cent technologies</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>