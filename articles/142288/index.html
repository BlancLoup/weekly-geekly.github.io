<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What is Grab: Spider?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I can‚Äôt add Grab documentation in any way: Spider is part of the Grab library for writing asynchronous spiders. Thought to lay out pieces of documenta...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What is Grab: Spider?</h1><div class="post__text post__text-html js-mediator-article">  I can‚Äôt add Grab documentation in any way: Spider is part of the <a href="http://grablib.org/">Grab</a> library for writing asynchronous spiders.  Thought to lay out pieces of documentation on habrakhabr.  I think with some feedback the matter will go faster.  At the moment in the documentation there is only an introduction, describing in general terms, what kind of beast is this Grab: Spider.  I spread it. <a name="habracut"></a><br><br>  The Spider module is a framework that allows you to describe a site parser as a set of handler functions, where each handler is responsible for a specific type of request.  For example, when parsing a forum, you will have handlers for the main page, sub-forum page, topic page, member profile page.  Initially, such a structure of the parser was developed due to the limitations of the asynchronous mode, but it later turned out that it was very convenient to write parsers in such a structured form (one request - one function). <br><br>  The Spider module works asynchronously.  This means that there is always only one workflow program.  For multiple queries, neither threads nor processes are created.  All created requests are processed by the multicurl library.  The essence of the asynchronous approach is that the program creates network requests and waits for signals about the readiness to respond to these requests.  As soon as the answer is ready, the handler function is called, which we tied to a specific request.  The asynchronous approach allows processing more simultaneous connections than the approach associated with creating threads or processes since  memory is occupied by only one process and the processor does not need to constantly switch between multiple processes. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      There is one nuance that will be very unusual for those who are used to working in synchronous style.  Asynchronous approach allows calling handler functions when the network response is ready.  If the parsing algorithm consists of several consecutive network requests, then you need to store information somewhere about what we created the network request for and what to do with it.  Spider allows you to quite conveniently solve this problem. <br><br>  Each handler function takes two input arguments.  The first argument is the Grab object, which stores information about the network response.  The beauty of the Spider module is that it has saved the familiar interface for working with synchronous requests.  The second argument of the handler function is the Task object.  Task objects are created in Spideer in order to add a new task to the network request queue.  Using the Task object, you can save intermediate data between multiple requests. <br><br>  Consider the example of a simple parser.  Suppose we want to go to the site habrahabr.ru, read the latest news headlines, then for each header find the image using images.yandex.ru and save the data to a file: <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># coding: utf-8 import urllib import csv import logging from grab.spider import Spider, Task class ExampleSpider(Spider): #  ,   Spider   #         #    initial initial_urls = ['http://habrahabr.ru/'] def prepare(self): #      #  prepare      #   self.result_file = csv.writer(open('result.txt', 'w')) #       #  ,      . self.result_counter = 0 def task_initial(self, grab, task): print 'Habrahabr home page' #        initial # ..   ,     #    self.initial_urls #         #     Grab for elem in grab.xpath_list('//h1[@class="title"]/a[@class="post_title"]'): #   -    #   habrapost #  ,       #  yield -      # -    : # self.add_task(Task('habrapost', url=...)) yield Task('habrapost', url=elem.get('href')) def task_habrapost(self, grab, task): print 'Habrahabr topic: %s' % task.url #  ,     #    ,  #     ,   #    #          post = { 'url': task.url, 'title': grab.xpath_text('//h1/span[@class="post_title"]'), } #       ,  , #     Task   .   #        ,    #      .   ,   #    Task     #         query = urllib.quote_plus(post['title'].encode('utf-8')) search_url = 'http://images.yandex.ru/yandsearch?text=%s&amp;rpt=image' % query yield Task('image_search', url=search_url, post=post) def task_image_search(self, grab, task): print 'Images search result for %s' % task.post['title'] #         ,  #     !     , #           # .      ,   #   ,     `task.post`. image_url = grab.xpath_text('//div[@class="b-image"]/a/img/@src') yield Task('image', url=image_url, post=task.post) def task_image(self, grab, task): print 'Image downloaded for %s' % task.post['title'] #      . #  ,   . path = 'images/%s.jpg' % self.result_counter grab.response.save(path) self.result_file.writerow([ task.post['url'].encode('utf-8'), task.post['title'].encode('utf-8'), path ]) #     ,  #       self.result_counter += 1 if __name__ == '__main__': logging.basicConfig(level=logging.DEBUG) #      -   #  ,     #        ,      bot = ExampleSpider(thread_number=2) bot.run()</span></span></code> </pre> <br><br>  In the example, the simplest parsers are considered and not a lot of possibilities that Spider can do are affected.  Read about them in the detailed documentation.  Please note that some of the handler functions will work with an error, for example, because Yandex will not find anything by a given request. <br><br>  Next, I plan to describe various ways of creating Task-objects, processing network errors, and the functionality of repeating tasks that were stopped by mistake. <br><br>  In writing, questions about Grab are best asked in the <a href="http://groups.google.com/group/python-grab">mailing</a> list: <a href="http://groups.google.com/group/python-grab">groups.google.com/group/python-grab</a> <br><br>  Order a revision of Grab, as well as a parser based on Grab and Grab :: Spider here: <a href="https://grablab.org/">grablab.org</a> </div><p>Source: <a href="https://habr.com/ru/post/142288/">https://habr.com/ru/post/142288/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../142280/index.html">In Krasnodar, Yota pre-turns off WiMAX base stations</a></li>
<li><a href="../142281/index.html">TEST-Camp Petersburg: a workshop of applications for society</a></li>
<li><a href="../142284/index.html">Photo from the exhibition Consumer Electronics & Photo Expo 12</a></li>
<li><a href="../142285/index.html">Unity - choose which array to use</a></li>
<li><a href="../142287/index.html">Goblog: Homemade static blog engine for Go</a></li>
<li><a href="../142289/index.html">Review of fresh materials, March 2012</a></li>
<li><a href="../142290/index.html">Update 2.0.1 for PlayBook released</a></li>
<li><a href="../142293/index.html">Spam via RSS</a></li>
<li><a href="../142295/index.html">Beeline protects SMS fraudsters?</a></li>
<li><a href="../142296/index.html">Appcelerator / IDC: Mobile Development: 1Q 2012</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>