<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>OpenMP application performance profiling</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="OpenMP is perhaps the most common parallel programming model on threads, on shared memory systems. Appreciate it for high-level parallel constructions...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>OpenMP application performance profiling</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/ffa/884/47f/ffa88447f4d8d5ad394d15af55f5014f.png"><br><br>  OpenMP is perhaps the most common parallel programming model on threads, on shared memory systems.  Appreciate it for high-level parallel constructions (in comparison with programming system streams) and support by different manufacturers of compilers.  But this post is not about the OpenMP standard itself, there are a lot of materials about it on the net. <br><br>  Parallelize computations on OpenMP for the sake of performance, which is what the article is about.  More precisely, performance measurement using Intel VTune Amplifier XE.  Namely, how to get information about: <br><ul><li>  Retrieving the profile of the entire OpenMP application </li><li>  Profile of individual OpenMP parallel regions (CPU time, hot functions, etc.) </li><li>  Work balance within a separate OpenMP parallel region </li><li>  Parallel / Serial Code Balance </li><li>  The granularity level of parallel tasks </li><li>  Synchronization objects, latency and inter-thread control transfers </li></ul><a name="habracut"></a><br><h4>  Run OpenMP profiling application </h4><br>  To profile an OpenMP program, you will need VTune Amplifier XE 2013 Update 4 or later.  The application is better to build Composer XE 2013 Update 2 or newer.  Analysis of older OpenMP implementations from Intel or from other manufacturers (GCC and Microsoft OpenMP) is also possible, but less useful information will be collected.  VTune Amplifier XE cannot recognize their parallel regions. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      All steps described in the article are valid for Windows and Linux.  The examples given were tested on Linux. <br><br>  If your compiler is older than Intel Composer XE 2013 SP1, set the KMP_FORKJOIN_FRAMES environment variable to 1. You can do this in the VTune Amplifier itself in the ‚ÄúUser-defined Environment Variable‚Äù dialog in the project properties, well or manually: <br><br>  # <code>export KMP_FORKJOIN_FRAMES=1</code> <br><br>  To get complete information about source files with parallel regions, compile with the option -parallel-source-info = 2.  For my examples, I used the following compilation line: <br><br>  # <code>icc -openmp -O3 -g -parallel-source-info=2 omptest.cpp work.cpp -o omptest</code> <br><br>  Everything else is no different from the analysis of a regular application: we launch the VTune Amplifier, create a project, specify our application, and start profiling: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c9/ea1/7d0/1c9ea17d09df0d3c9aeb83e96e226df6.png"><br><br><h4>  View OpenMP parallel regions </h4><br>  OpenMP parallel regions are represented in VTune Amplifier XE as frame domains.  Frames are a sequence of non-overlapping intervals of application execution time.  Those.  You can break the program all the time at the stage: for example, stage 1 (initialization), stage 2 (work), stage 3 (completion).  These stages can be represented by three frames.  Frames are often mentioned in graphics applications - the idea is the same, but the concept of a frame in VTune Amplifier is broader.  Frames are global and not tied to specific threads. <br><br>  Each parallel OpenMP region is shown as a separate frame domain.  It is identified by the source file and line numbers.  The frame domain denotes a region in the source code.  Each challenge to this region is a frame.  Frame - the period from the point of separation (or launch) of threads (fork) to the point of their reunion (join)  The number of frames is not related to the number of threads and the size of the tasks. <br><br>  The pseudo code below contains two parallel OpenMP constructs, two regions.  Each of them will be recognized as a domain frame in the VTune Amplifier XE profile, so there will be two domain frames: <br><br><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">int</span></span> main() { #pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> // frame <span class="hljs-keyword"><span class="hljs-keyword">domain</span></span> #<span class="hljs-number"><span class="hljs-number">1</span></span>, frame count: <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; NUM_ITERATIONS; i++) { do_work(); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> j=<span class="hljs-number"><span class="hljs-number">0</span></span>; j&lt;<span class="hljs-number"><span class="hljs-number">4</span></span>; j++) { #pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> // frame <span class="hljs-keyword"><span class="hljs-keyword">domain</span></span> #<span class="hljs-number"><span class="hljs-number">2</span></span>, frame count: <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; NUM_ITERATIONS; i++) { do_work(); } } }</code> </pre> <br>  The first frame domain is called only once.  Therefore, frame domain # 1 will have only 1 frame, even if the body of a parallel loop is executed immediately by 16 threads.  The second parallel region (frame domain # 2) is launched from the loop sequentially 4 times.  For each iteration, a parallel construction is invoked, with the corresponding starts and terminations of the threads.  Therefore, frame domain # 2 will have 4 frames in the VTune Amplifier XE profile. <br><br>  Parallel regions are recognized if the program uses Intel OpenMP runtime.  To see them, as a result of VTune Amplifier XE, switch to the Bottom-up tab and select the grouping by "Frame Domain / Frame Type ...": <br><br><img src="http://habrastorage.org/getpro/habr/post_images/4f2/73d/333/4f273d333e8a227b12bc4e1933fcdce5.png"><br><br>  Parallel OpenMP regions and their corresponding thread activity can also be seen in the Tasks and Frames tab: <br><br><img src="http://habrastorage.org/getpro/habr/post_images/c5c/1c3/1ad/c5c1c31adbf76df5ba7236d2fe4e39c6.png"><br><br><h4>  Sequential region </h4><br>  All the CPU time spent outside the parallel regions is going to the frame domain called ‚Äú[No frame domain - Outside any frame]‚Äù.  This allows you to evaluate the sequential part of your code: <br><br><img src="http://habrastorage.org/storage3/8bc/3ec/4fc/8bc3ec4fc24c13b181e6e28159b064d0.png"><br><br><h4>  Overhead and active wait (overhead and spin time) </h4><br>  Overhead time in OpenMP is the time spent executing internal runtime procedures related to flow control, work distribution, scheduling, synchronization, etc.  This is the time spent not on useful calculations, but on the internal functions of the library.  Spin time is the time during which the CPU is running.  This can occur, for example, if the synchronization object makes a call to the poll, instead of going into the waiting state ‚Äî spinning (spinning) while waiting.  OpenMP threads can also ‚Äúspin‚Äù like this, for example, on the synchronization barrier. <br><br>  Overhead and active wait are tracked by known function names and call sequences that waste CPU time.  Some internal OpenMP functions manage threads, tasks, and so on, so the time spent in them is related to overhead.  The time of active waiting is also determined by the functions that implement the ‚Äútorsion‚Äù. <br><br>  Overhead costs and active waiting are defined for Intel OpenMP runtimes, GCC and Microsoft OpenMP, Intel Threading Building Blocks and Intel Cilk Plus. <br><br><img src="http://habrastorage.org/storage3/1bc/c82/4bb/1bcc824bbfbb8b13f2447f275a3a5b84.png"><br><br><h4>  Scenario 1: Ideally balanced parallel region </h4><br>  In my simple example, a parallel region in the omptest.cpp file on line 54 is a good case.  Look at the Bottom-up tab, grouped by ‚ÄúFrame Domain / Frame Type / Frame / Thread / Function / Call Stack‚Äù: <br><br><img src="http://habrastorage.org/storage3/a24/3a2/013/a243a2013f2aa9d10c59388728ab0e84.png"><br><br>  The domain frame contains only one frame, which means that the parallel region was called only once.  Expanding the details in the table shows 8 threads.  This is good for a 4 core machine with Hyper Threading that was tested.  The CPU is well loaded (green color of the CPU time bar), all 8 threads are busy in this region and do almost the same amount of work.  This parallel region is marked on the timeline, where a high processor load is also visible for all eight threads.  This does not mean that everything is perfect - for example, there may be cache misses or insufficient use of SIMD instructions.  But no problems with the OpenMP threads and the balance of work were found. <br><br>  The code from the example on line 54: <br><br><pre> <code class="hljs swift">#pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> schedule(<span class="hljs-keyword"><span class="hljs-keyword">static</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment">// line 54 for (int index = 0 ; index &lt; oloops ; index++) { double *a, *b, *c, *at ; int ick ; a = ga + index*84 ; c = gc + index*84 ; fillmat (a) ; ick = work (a, c,gmask) ; if (ick &gt; 0) { printf("error ick failed\n") ; exit(1) ; } }</span></span></code> </pre> <br><h4>  Scenario 2: Unbalanced parallel region </h4><br>  The region on line 82 is not so balanced.  It uses only 4 streams from 8 available, the remaining 4 are waiting.  This is reflected in the level of CPU usage (red color): <br><br><img src="http://habrastorage.org/storage3/be8/194/00c/be819400ccf062bd97bf1ef8127f6e07.png"><br><br>  The code on line 82 (just turned off every second iteration): <br><br><pre> <code class="hljs swift">#pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> schedule(<span class="hljs-keyword"><span class="hljs-keyword">static</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment">// line 82 for (int index = 0 ; index &lt; oloops ; index++) { double *a, *b, *c, *at ; int ick ; if (index%2 == 0) { a = ga + index*84 ; c = gc + index*84 ; fillmat (a) ; ick = work (a, c, gmask) ; if (ick &gt; 0) { printf("error ick failed\n") ; exit(1) ; } } }</span></span></code> </pre> <br><br><h4>  Scenario 3: Problems with granularity </h4><br>  The previous examples had one domain frame and one frame.  The region on line 147 contains a number of frames: <br><br><img src="http://habrastorage.org/storage3/960/64f/d8a/96064fd8a061e6d37d1e2a6343598cb7.png"><br><br>  This means that a parallel region has been called multiple times.  The CPU time of each frame is very small - this can be seen in the pop-up window when you hover the frame with the mouse in the timeline.  This suggests that granularity is too high, in the sense that we too often run very short parallel OpenMP regions.  From this we get high overhead and low CPU. <br><br>  The code on line 147: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (q = <span class="hljs-number"><span class="hljs-number">0</span></span> ; q &lt; LOOPS ; q++) { #pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> schedule(static,<span class="hljs-number"><span class="hljs-number">1</span></span>) firstprivate(tcorrect) lastprivate(tcorrect) // <span class="hljs-type"><span class="hljs-type">line</span></span> <span class="hljs-number"><span class="hljs-number">147</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span> ; <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> &lt; oloops ; <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>++) { <span class="hljs-type"><span class="hljs-type">double</span></span> *la, *lc; <span class="hljs-type"><span class="hljs-type">int</span></span> lq,lmask ; la = ga + <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>*<span class="hljs-number"><span class="hljs-number">84</span></span> ; lc = gc + <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>*<span class="hljs-number"><span class="hljs-number">84</span></span> ; lq = q ; lmask = gmask ; ick = work1(ga, gc, lq,lmask) ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (ick == VLEN) tcorrect++ ; } }</code> </pre> <br><h4>  Scenario 4: Sync Objects and Wait Time </h4><br>  Waiting on the synchronization object can be a serious bottleneck for performance.  For a complete picture of the synchronizations and expectations in your application, collect the ‚ÄúLocks and Waits‚Äù analysis.  Before launch, enable the ‚ÄúAnalyze user tasks‚Äù and ‚ÄúAnalyze Intel runtimes and user synchronization‚Äù checkboxes in the new analysis settings. <br><br>  The Bottom-up panel shows you a list of synchronization objects, sorted by timeout: <br><br><img src="http://habrastorage.org/storage3/a25/514/a1d/a25514a1dff2a880667455c7735de2d3.png"><br><br>  VTune Amplifier XE can recognize OpenMP synchronization primitives, such as the omp critical construction or synchronization barriers used inside OpenMP runtime.  You can see how much time is spent waiting and how it is distributed: many expectations of short duration, or several long expectations.  VTune Amplifier XE shows if the thread waited actively (spin waiting), or really went into a wait state.  The timeline gives a picture of transitions of management (transitions) - vertical yellow lines.  From them you can understand which threads intercepted the synchronization object, how often, what kind of object it was, how long they waited, and so on. <br><br>  The code on line 118: <br><br><pre> <code class="hljs delphi">#pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> schedule(<span class="hljs-keyword"><span class="hljs-keyword">static</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (int <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span> ; <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> &lt; oloops ; <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>++) <span class="hljs-comment"><span class="hljs-comment">{ #pragma omp critical (my_sync) // line 118 { double *a, *b, *c, *at ; int ick ; a = ga + index*84 ; c = gc + index*84 ; fillmat (a) ; ick = work (a, c,gmask) ; if (ick &gt; 0) { printf("error ick failed\n") ; exit(1) ; }</span></span> } }</code> </pre> <br><h4>  Summary </h4><br>  Intel VTune Amplifier XE gives you the opportunity to look deep inside the OpenMP application.  You can evaluate the balance of sequential and parallel code, and how the program behaves in each parallel region.  Intel VTune Amplifier XE can help you find problems with load balancing between OpenMP threads, problems with granularity, estimate overhead, and understand the timing pattern.  Linking detailed CPU usage statistics to a specific OpenMP region will allow you to better understand the behavior of your application.  You can get the most detailed information using Intel OpenMP runtime, but profiling of other implementations is also possible (GCC and Microsoft OpenMP). </div><p>Source: <a href="https://habr.com/ru/post/204058/">https://habr.com/ru/post/204058/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../204046/index.html">Pleasant 3D portraits at the Olympics</a></li>
<li><a href="../204048/index.html">Asterisk. We unload the secretary / dispatcher / first line of those. support</a></li>
<li><a href="../204050/index.html">Generating duplicate blocks of code using a plugin for Sublime Text 2</a></li>
<li><a href="../204052/index.html">XCP for those who want but fear 2</a></li>
<li><a href="../204054/index.html">Jet man: rocket man</a></li>
<li><a href="../204064/index.html">Database Support Plugin in JetBrains IDE</a></li>
<li><a href="../204066/index.html">How i was kul hacker</a></li>
<li><a href="../204068/index.html">Configuring WebRTC + Eclipse 4.3 + ubuntu 13.10</a></li>
<li><a href="../204070/index.html">Perfect posture with LUMOback</a></li>
<li><a href="../204074/index.html">The deflationary nature of BTC - is it bad?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>