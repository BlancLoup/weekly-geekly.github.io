<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Splunk - Installing agents to collect Windows and Linux logs</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We are often asked questions about how to load various data into Splunk . One of the most common sources of interest turned out to be the Windows and ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Splunk - Installing agents to collect Windows and Linux logs</h1><div class="post__text post__text-html js-mediator-article">  We are often asked questions about how to load various data into <b>Splunk</b> .  One of the most common sources of interest turned out to be the <b>Windows</b> and <b>Linux</b> logs, which allow you to track and manage operating system problems.  By uploading data to Splunk, you can analyze the performance of all systems in one place, even when you have dozens or hundreds of different sources. <br><br> <a href="https://habrahabr.ru/company/tssolution/blog/352944/"><img src="https://habrastorage.org/webt/ro/t-/2m/rot-2mpdxpqwqlnexobpvsqofaq.png"></a> <br><br>  In this article we will explain step by step how to load data from Windows and Linux into Splunk for further processing and analysis. <br><a name="habracut"></a><br><h2>  <font color="#0075a9">Setting up basic infrastructure</font> </h2><br>  In order to start collecting data we need the following system elements: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  Splunk - Indexer </li><li>  Windows server </li><li>  Linux server </li></ul><br><img src="https://habrastorage.org/webt/_k/99/tl/_k99tlc1emqli985bqa5wibuq00.png"><br><br>  In order to upload logs to Splunk, you must first configure the indexer, this will require: <br><br><div class="spoiler">  <b class="spoiler_title">‚Ä¢ Install and configure Splunk-indexer to receive data;</b> <div class="spoiler_text">  First of all, you'll need Splunk on a machine that is our indexer.  If you do not have Splunk installed, you can read more about how and what systems you can install it <a href="https://habrahabr.ru/company/tssolution/blog/323814/">here</a> . <br><br>  After installation, you must configure the indexer to receive data: <br>  <i><b>Settings-Forwarding and Receiving</b></i> , then in the <i><b>Receive data</b></i> section add a new configuration: <i><b>Configure receiving</b></i> . <br><br><img src="https://habrastorage.org/webt/2d/ih/rx/2dihrxobycwsxzrz0q7om30lnt8.png"><br><img src="https://habrastorage.org/webt/rk/22/rr/rk22rrnplb3tsuqdtfxuxtyhiac.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">‚Ä¢ Create an application ‚ÄúSend to indexer‚Äù, which will configure the transfer to all sources that send data to the indexer;</b> <div class="spoiler_text">  This application is necessary in order to simplify the management of data sources when there are many of these sources or access to them for making changes is difficult.  Also, the application will allow you not to make potentially erroneous configuration changes on many hosts, limiting it to changing only in one place. <br><br>  Create an application: <i><b>Apps - Manage Apps - Add New</b></i> <br><br><img src="https://habrastorage.org/webt/6q/oc/kg/6qockggoel5cmvqnsodguryo8qe.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">‚Ä¢ Generate the configuration file outputs.conf</b> <div class="spoiler_text">  After creating the application, it is necessary to generate the configuration file outputs.conf (You can read more about that file <a href="">on the official Splunk website</a> ) <br><br>  In the text editor, enter the following text, replacing <i>indexer_hostname_or_ip_address</i> with the host name or indexer IP address and the receiving port set in the previous step: <br><pre><code class="hljs axapta">[tcpout] defaultGroup = <span class="hljs-keyword"><span class="hljs-keyword">default</span></span>-autolb-<span class="hljs-keyword"><span class="hljs-keyword">group</span></span> [tcpout:<span class="hljs-keyword"><span class="hljs-keyword">default</span></span>-autolb-<span class="hljs-keyword"><span class="hljs-keyword">group</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> = &lt;indexer_hostname_or_ip_address&gt;:<span class="hljs-number"><span class="hljs-number">9997</span></span> [tcpout-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>:<span class="hljs-comment"><span class="hljs-comment">//&lt;indexer_hostname_or_ip_address&gt;:9997]</span></span></code> </pre> <br>  Save as <i><b>outputs.conf</b></i> and add to the <i>\ etc \ apps \ sendtoindexer \ local</i> folder (you must create the local folder). <br></div></div><br><div class="spoiler">  <b class="spoiler_title">‚Ä¢ Configure the Deployment Server to manage the Send to indexer application and other applications;</b> <div class="spoiler_text">  Deployment Server is required in order to distribute applications and configurations to all related Splunk instances on other hosts.  To activate the Deployment Server, you must place at least one application in the <i>% SPLUNK_HOME% \ etc \ deployment-apps</i> folder <i>.</i>  In our case, we moved the <b>Send to indexer</b> application there.  (It was moved, not copied, as we will do next with other applications.) <br></div></div><br>  At this stage, we finish the preliminary adjustment of the indexer and proceed to installing the agents on Windows and Linux machines. <br><br><h2>  <font color="#0075a9">WINDOWS</font> </h2><br>  A universal tool for uploading logs is a special agent - <b>Splunk Universal Forwarder</b> .  Universal Forwarder is a version of Splunk Enterprise with significantly limited functionality, the only task of which is to collect data from the host and send it. <br><br>  Download it at this <a href="https://www.splunk.com/ru_ru/download/universal-forwarder.html">link</a> . <br><br><img src="https://habrastorage.org/webt/xr/ur/ip/xrurip3jkcsfft3_fbeuaome8hc.png"><br><br>  The picture above shows that Universal Forwarder can be installed on both Windows and Linux, Solaris and other operating systems. <br><br>  1. <b>Install Universal Forwarder</b> <br><img src="https://habrastorage.org/webt/er/y2/bc/ery2bcagjl54r8zfq_ihsomeirk.png"><br><br>  We specify the IP address or the name of the Splunk indexer as the <b>Deployment Server</b> , where we created the application ‚ÄúSend to indexer‚Äù.  The default port is <i>8089</i> .  Leave the Receiving Indexer section empty, since these functions will be performed by ‚ÄúSend to indexer‚Äù. <br><br>  2. The next step we need to go back to Splunk and define the server class for the application "Send to indexer". <br><br>  The server class is something like a rule in which we specify which applications we will distribute between which target client machines.  The criteria for the formation of different server classes can be the type of machine, operating system, geographical area or type of application, and the classes can overlap with each other.  (You can read more <a href="http://docs.splunk.com/Documentation/Splunk/7.0.3/Updating/Definedeploymentclasses">on the official website</a> ) <br><br>  <i><b>Settings - Forwarder Management - edit action - add new classes.</b></i> <br><br><img src="https://habrastorage.org/webt/hq/p6/9z/hqp69zpyfc6jhezkyx4a9cthdtg.png"><br><br>  3. After saving, you will be prompted to add applications that we will send and target systems, the so-called clients, to whom we will send them. <br><br><img src="https://habrastorage.org/webt/5-/fv/y2/5-fvy24sugus773hjawfruwuqgc.png"><br><br>  Add " <b>Send to indexer</b> " in the application section. <br><br><img src="https://habrastorage.org/webt/n5/kc/cf/n5kccfzzyql78kklyqf_zohj1ju.png"><br><br>  4. Then add the client.  The client will be our Windows machine on which we installed Universal Forwarder.  If Universal Forwarder was installed correctly, then the machine should appear in the list of clients connected to the <b>Deployment Server</b> .  We put it in <b><i>Include (whitelist)</i></b> . <br><br><img src="https://habrastorage.org/webt/yf/dg/mo/yfdgmobajzkemnycynj_0nv4jn4.png"><br><br>  5. Check whether everything works correctly, looking at the contents of the index <i>_internal</i> .  After adding ‚ÄúSend to indexer‚Äù to the Universal Forwarder server class, it starts sending its internal logs there.  Also in this index, we can further monitor whether our agents are working properly. <br><br>  6. Next, download a special Add-on from <a href="https://splunkbase.splunk.com/app/742/">SplunkBase</a> , which allows you to collect data on the work of Windows. <br><br>  7. Install the application on Splunk-Indexer ( <i><b>Apps - Manage Apps - Install app from file</b></i> ) <br>  By default, it is installed in the directory <i>... \ Splunk \ etc \ apps \ Splunk_TA_windows</i> , but we need to copy it to the deployment-apps folder so that this application is available to the deployment server, so that later we can send it to other machines as well and "Send to indexer".  ( <b>Important</b> : in the apps folder it should also remain so that the indices we need for the data are formed on the indexer). <br><br>  8. Then you need to pre-configure the application. <br>  Go to the directory <i>... \ Splunk \ etc \ deployment-apps \ Splunk_TA_windows</i> <br>  Create a sub-directory ‚Äúlocal‚Äù in it ( <b>Important</b> : Always make changes to the configuration files in the local directory). <br><br>  Copy the inputs.conf file from.  <i>.. \ Splunk \ etc \ deployment-apps \ Splunk_TA_windows \ default \ inputs.conf</i> to the <i>local</i> directory. <br><br>  Enable indexing of required data.  To do this, we make some changes in the <b>inputs.conf</b> file from the <b>local</b> directory via a text editor.  Replace the values ‚Äã‚Äãof disabled = 1 to disabled = 0 in the required blocks of the file.  Let's add system logs by Application, Security, System. <br><br><img src="https://habrastorage.org/webt/5d/cc/z0/5dccz00pypnbami_5etzas5wlmm.png"><br><br>  9. Next, on Splunk-indexer, we add the previously created server-class to the application.  ( <i><b>Settings - Forwarder Management - Apps - Splunk_TA_Windows - ‚Äú+‚Äù - Windows Forwarder</b></i> ) <br><br><img src="https://habrastorage.org/webt/kq/ms/2e/kqms2egfpd8ttkwx7le1_9m9cba.png"><br><br>  10. Restart the <b>deployment server</b> , this can be done via the command line from the directory <i>... / splunk / bin</i> : <br><br><pre> <code class="hljs pgsql">./splunk reload deploy-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span></code> </pre> <br>  Check if data is being loaded.  ( <i><b>Settings - Indexes</b></i> ) They should fall into the wineventlog index.  As you can see in our picture, the latest data that was currently loaded has a timestamp 3 minutes ago. <br><br><img src="https://habrastorage.org/webt/xs/sc/te/xsscte7unl_gqodunk_qblccxv8.png"><br><br><h2>  <font color="#0075a9">LINUX</font> </h2><br>  One of the tools to improve security in Linux is the <b>auditd</b> audit <b>subsystem</b> .  With its help you can get detailed information about all system events.  It is the data generated by this system that we will index in Splunk. <br><br>  (Code will be submitted for Linux CentOS) <br><br>  1. Check if there is a pre-installed audit system on the machine, if not install it. <br><br><pre> <code class="hljs sql">sudo yum list audit audit-libs sudo yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> <span class="hljs-keyword"><span class="hljs-keyword">audit</span></span> <span class="hljs-keyword"><span class="hljs-keyword">audit</span></span>-libs</code> </pre> <br>  Add a new rule that we will track. <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">sudo</span></span> auditctl -w /etc/ -p wa -k test_audit</code> </pre> <br>  You can check its availability using the function. <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">auditctl</span></span> -l</code> </pre> <br>  The logs generated by auditd fall into the file: <br><br><pre> <code class="hljs pgsql">cd /var/<span class="hljs-keyword"><span class="hljs-keyword">log</span></span>/audit/audit.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span> cat audit.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span></code> </pre> <br>  2. Next, install the <b>Universal Forwarder</b> .  Find the distribution can be on the <a href="https://www.splunk.com/en_us/download/universal-forwarder.html">link.</a> <br><br>  It is necessary to download a file of the .rpm format, after which downloading it will be possible to get a wget link. <br><br><pre> <code class="hljs vhdl">yum install wget cd /tmp/ wget -O splunkforwarder-<span class="hljs-number"><span class="hljs-number">7.0</span></span>.<span class="hljs-number"><span class="hljs-number">3</span></span>-fa31da744b51-linux-<span class="hljs-number"><span class="hljs-number">2.6</span></span>-x86_64.rpm <span class="hljs-symbol"><span class="hljs-symbol">'https</span></span>://www.splunk.com/bin/splunk/DownloadActivityServlet?<span class="hljs-keyword"><span class="hljs-keyword">architecture</span></span>=x86_64&amp;platform=linux&amp;version=<span class="hljs-number"><span class="hljs-number">7.0</span></span>.<span class="hljs-number"><span class="hljs-number">3</span></span>&amp;product=universalforwarder&amp;filename=splunkforwarder-<span class="hljs-number"><span class="hljs-number">7.0</span></span>.<span class="hljs-number"><span class="hljs-number">3</span></span>-fa31da744b51-linux-<span class="hljs-number"><span class="hljs-number">2.6</span></span>-x86_64.rpm&amp;wget=<span class="hljs-literal"><span class="hljs-literal">true</span></span>' rpm -i splunkforwarder-<span class="hljs-number"><span class="hljs-number">7.0</span></span>.<span class="hljs-number"><span class="hljs-number">3</span></span>-fa31da744b51-linux-<span class="hljs-number"><span class="hljs-number">2.6</span></span>-x86_64.rpm</code> </pre> <br>  3. Next, create a new user who will be responsible for working with splunk. <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">adduser</span></span> splunk</code> </pre> <br>  4. Give permissions to the user we just created and run UniversalForwarder on his behalf. <br><br><pre> <code class="hljs pgsql">chown -R splunk:splunk /opt/splunkforwarder/ /opt/splunkforwarder/bin/splunk <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> boot-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span> -<span class="hljs-keyword"><span class="hljs-keyword">user</span></span> splunk</code> </pre> <br>  5. We will configure the forwarder and specify the <b>Deployment Server</b> , as well as in the part with Windows, this is the IP address or the name Splunk-indexer / <br><br><pre> <code class="hljs sql">/opt/splunkforwarder/bin/splunk <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> deploy-poll &lt;IP- Splunk Indexer&gt; :<span class="hljs-number"><span class="hljs-number">8089</span></span> -auth <span class="hljs-keyword"><span class="hljs-keyword">admin</span></span>:changeme /opt/splunkforwarder/<span class="hljs-keyword"><span class="hljs-keyword">bin</span></span>/splunk edit <span class="hljs-keyword"><span class="hljs-keyword">user</span></span> <span class="hljs-keyword"><span class="hljs-keyword">admin</span></span> -<span class="hljs-keyword"><span class="hljs-keyword">password</span></span> &lt;  &gt; -auth <span class="hljs-keyword"><span class="hljs-keyword">admin</span></span>:changeme /opt/splunkforwarder/<span class="hljs-keyword"><span class="hljs-keyword">bin</span></span>/splunk restart</code> </pre> <br>  6. You can check if the forwarder is working as follows: <br><br><pre> <code class="hljs dos"> <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/splunkforwarder/bin/ ./splunk status</code> </pre> <br>  7. Next, go to Splunk-indexer and install a special Add-on on it, which allows you to transfer logs from Linux.  Download the distribution can be on the <a href="https://splunkbase.splunk.com/app/833/">link</a> . <br><br>  8. After installation, we find the folder with the application at the following address <i>../splunk/etc/apps/Splunk_TA_nix</i> .  Copy the <b>Splunk_TA_nix</b> folder from the apps to the <b>deployment-apps</b> .  To make this application appear as available to the deployment server. <br><br>  In the ... / deployment-apps / Splunk_TA_nix directory, create the local folder and copy the input.conf file from the ../Splunk_TA_nix/default folder into it. <br><br>  In the file ... / deployment-apps / Splunk_TA_nix / local / input.conf through a text editor make changes that show the data from which folders we want to collect.  In our case, this is / var / log / audit. <br><br>  In input.conf there is a [monitor: /// var / log] section in which you need to change disabled = 1 to disabled = 0 (Important: make sure that the necessary folder is in whitelist if it doesn‚Äôt exist, but you need to add it) <br><br>  9. Next, check if the Deployment server saw a new client, our Linux machine.  ( <i><b>Settings - Forwarder Management - Clients</b></i> ). <br><br>  If it is not there, then it is necessary to check the name (Host name) of the machine, if it matches the name of the indexer machine, then it is necessary to change it, otherwise an error occurs. <br><br><pre> <code class="hljs dos"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /etc/hosts cat hosts hostname test.testdomain.com</code> </pre> <br>  10. Then create a new server class related to Linux. <br>  <i><b>Settings - Forwarder Management - Server Classes - New Server Class</b></i> <br><br><img src="https://habrastorage.org/webt/uo/dk/ji/uodkjiwnvjpxjffrsrkutbcow6q.png"><br><br>  11. Add the ‚ÄúSend to indexer‚Äù and ‚ÄúSplunk_TA_nix‚Äù applications to this class, and add a Linux machine as a client. <br><br><img src="https://habrastorage.org/webt/xc/ey/s1/xceys19rxaw7q34jpcv7-ptq6wk.png"><br><br>  Please note that files will not load if Universal Forwarder (the user under which we use Universal Forwarder) does not have access to the folders that need to be monitored.  So you need to take into account this moment and allow access. <br><br>  12. At the end, you need to restart the <b>deployment serve</b> r, this can be done via the command line from the <i>... / splunk / bin directory</i> : <br><br><pre> <code class="hljs pgsql">./splunk reload deploy-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span></code> </pre> <br>  After performing the above operations, you will receive Linux logs that will be loaded into the OS index. <br><br><h2>  <font color="#0075a9">Conclusion</font> </h2><br>  Thus, we showed you how to upload your logs from Windows and Linux to Splunk for further analysis and processing.  We hope that this information will be useful for you. <br><br>  We are happy to answer all your questions and comments on this topic.  Also, if you are interested in something specifically in this area, or in the field of machine data analysis in general, we are ready to refine the existing solutions for you, for your specific task.  To do this, you can write about it in the comments or simply send us a request through the form on our <a href="https://tssolution.ru/splunk/">website</a> . <br><br>  We are the official <a href="https://partners.splunk.com/locator/partner/333601/ts-solution">Premier Splunk Partner</a> . <br><br><img src="https://habrastorage.org/webt/ey/yy/9n/eyyy9nzwq4rf9kolg17ihjq5bik.png"><br><br><h2>  PS </h2><br>  <b>On June 28, 2018,</b> ‚Äú <a href="http://tssolution.tilda.ws/study-splunk">Splunk Getting Started</a> ‚Äù will be taught <b>in Moscow</b> , where in 6 hours the participants will receive a theoretical base and practical skills for working in Splunk.  Learn more about learning and register at this <a href="http://tssolution.tilda.ws/study-splunk">link</a> . </div><p>Source: <a href="https://habr.com/ru/post/352944/">https://habr.com/ru/post/352944/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../352930/index.html">What will happen if you combine ArrayList and LinkedList?</a></li>
<li><a href="../352932/index.html">Tooltips in Power BI - a new feature for Desktop</a></li>
<li><a href="../352934/index.html">[Ekaterinburg, announcement] java.ural.Meetup @ 2 - the announcement of the second Java-mitap + video reports from java.ural.Meetup @ 1</a></li>
<li><a href="../352938/index.html">Reusable UI components in Ruby on Rails applications</a></li>
<li><a href="../352942/index.html">Conference DEFCON 23. "How I knocked down the annoying drone of a neighbor's child." Michael robinson</a></li>
<li><a href="../352948/index.html">Macro for Autodesk Revit that trim walls</a></li>
<li><a href="../352950/index.html">Be careful with copy-paste: fingerprinting text with unprintable characters</a></li>
<li><a href="../352952/index.html">System Shock source code is publicly available under the GPL</a></li>
<li><a href="../352954/index.html">Spring Boot. Background tasks and not only</a></li>
<li><a href="../352958/index.html">MBO, OKR, PPR: mix but not shake</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>