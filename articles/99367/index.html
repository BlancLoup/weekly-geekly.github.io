<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using Intel AVX: writing the program of tomorrow</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 A new set of SIMD instructions for x86 Intel AVX processors was presented to the public in March 2008. And although the implementation ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using Intel AVX: writing the program of tomorrow</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  A new set of SIMD instructions for x86 Intel AVX processors was presented to the public in March 2008.  And although the implementation of these instructions in hardware will wait another six months, the AVX specification can already be considered established, and support for the AVX instruction set has been added to new versions of compilers and assemblers.  This article discusses practical optimization issues for Intel AVX routines in C / C ++ and assembler languages. <br><a name="habracut"></a><br><h4>  AVX command set </h4><br>  All AVX commands, as well as some other commands, are described in a <a href="http://software.intel.com/file/28986">reference book</a> that can be found on <a href="http://software.intel.com/en-us/avx/">the Intel AVX website</a> .  In a sense, the AVX instruction set is an extension of the SSE instruction set, which is already supported by all modern processors.  In particular, AVX initially extends 128-bit SSE registers to 256 bits.  The new 256-bit registers are denoted as ymm0-ymm15 (for the 32-bit program, only ymm0-ymm7 is available);  while the 128-bit SSE registers xmm0-xmm15 refer to the lower 128 bits of the corresponding AVX register. <br><img src="https://habrastorage.org/storage/habraeffect/63/23/6323d67a17f2817de50b19e4e0717040.png" alt="AVX &amp; amp; SSE registers"><br>  To work effectively with the new 256-bit registers, a myriad of instructions have been added to AVX.  However, most of them are only slightly modified versions of the already familiar SSE instructions. <br>  So, each instruction from SSE (as well as SSE2, SSE3, SSSE3, SSE4.1, SSE4.2 and AES-NI) has its analogue in AVX with the prefix v.  In addition to the prefix, such AVX instructions differ from their SSE counterparts in that they can have three operands: the first operand indicates where to write the result, and the remaining two tell where to get the data.  Three-instruction instructions are good because firstly they get rid of redundant register-copying operations in the code, and secondly they simplify writing good optimizing compilers.  SSE2 code <br> <code>movdqa xmm2, xmm0 <br> punpcklbw xmm0, xmm1 <br> punpckhbw xmm2, xmm1</code> <br>  can be rewritten from avx as <br> <code>vpunpckhbw xmm2, xmm0, xmm1 <br> vpunpcklbw xmm0, xmm0, xmm1</code>  <code>vpunpckhbw xmm2, xmm0, xmm1 <br> vpunpcklbw xmm0, xmm0, xmm1</code> . <br>  At the same time, the commands with the prefix v zero the highest 128 bits of the AVX register into which they write.  For example, the instruction <b>vpaddw xmm0, xmm1, xmm2 will</b> zero the upper 128-bit register ymm0. <br>  In addition, some SSE instructions were extended to AVX to work with 256-bit registers.  These instructions include all commands working with floating-point numbers (both single and double precision).  For example, the following AVX code <br> <code>vmovapd ymm0, [esi] <br> vmulpd ymm0, ymm0, [edx] <br> vmovapd [edi], ymm0</code> <br>  processes 4 double at once. <br>  In addition, AVX includes some new instructions. <br><ul><li>  vbroadcastss / vbroadcastsd / vbroadcastf128 - filling the entire AVX register with the same loaded value </li><li>  vmaskmovps / vmaskmovpd - conditional loading / saving of float / double numbers in AVX register depending on the sign of numbers in another AVX register </li><li>  vzeroupper - reset the older 128 bits of all AVX registers </li><li>  vzeroall - full resetting of all AVX registers </li><li>  vinsertf128 / vextractf128 - insert / receive any 128-bit part of the 256-bit AVX register </li><li>  vperm2f128 - swapping the 128-bit parts of the 256-bit AVX register.  The permutation parameter is set statically. </li><li>  vpermilps / vpermilpd - permutation of float / double numbers inside 128-bit parts of the 256-bit AVX register.  The parameters of the permutation are taken from another AVX register. </li><li>  vldmxcsr / vstmxcsr - load / save AVX control parameters (where to go without it!) </li><li>  xsaveopt - getting hints about which AVX registers contain data.  This command is made for OS developers and helps them speed up the context switch. </li></ul><br><h4>  Using AVX in assembly code </h4><br>  Today AVX is supported by all popular x86 assemblers: <br><ul><li>  <a href="http://en.wikipedia.org/wiki/GNU_Assembler" title="Wikipedia about GAS">GAS (GNU Assembler)</a> - from binutils version 2.19.50.0.1, but it is better to use 2.19.51.0.1, which supports the later AVX specification </li><li>  <a href="http://en.wikipedia.org/wiki/Microsoft_Macro_Assembler" title="Microsoft Macro Assembler Wikipedia">MASM</a> - starting from version 10 (included in Visual Studio 2010) </li><li>  <a href="http://www.nasm.us/" title="The Netwide Assembler: NASM">NASM</a> - starting from version 2.03, but it is better to use the latest version </li><li>  <a href="http://www.tortall.net/projects/yasm/" title="The Yasm Modular Assembler Project">YASM</a> - starting with version 0.70, but it is better to use the latest version </li></ul><br><h5>  Definition of AVX support system </h5><br>  The first thing to do before using AVX is to make sure the system supports it.  Unlike different versions of SSE, AVX requires its support not only by the processor, but also by the operating system (after all, it must now save the top 128-bit AVX registers when switching context).  Fortunately, the AVX developers have provided a way to learn about the support of this set of instructions by the operating system.  The OS saves / restores the AVX context using special XSAVE / XRSTOR instructions, and these commands are configured using the extended control register (extended control register).  Today there is only one such register - XCR0, aka XFEATURE_ENABLED_MASK.  You can get its value by writing the register number to ecx (for XCR0 it is, of course, 0) and calling the <b>XGETBV</b> command.  The 64-bit register value will be stored in the edx pair of registers: eax.  The zero bit of the register XFEATURE_ENABLED_MASK means that the XSAVE command saves the state of the FPU registers (however, this bit is always set), the first bit is set to save SSE registers (the lower 128 bits of the AVX register), and the second bit is set to save the high 128 bits of AVX register.  So  to be sure that the system maintains the state of AVX registers when switching contexts, you need to make sure that bits 1 and 2 are set in the XFEATURE_ENABLED_MASK register. However, this is not all: before calling the XGETBV command, you need to make sure that the OS really uses XSAVE instructions / XRSTOR for context management.  This is done by calling the CPUID instruction with the eax = 1 parameter: if the OS has enabled context saving / recovery management with the XSAVE / XRSTOR instructions, then after performing the CPUID, in the 27th bit of the ecx register there will be one.  In addition, it would be nice to check that the processor itself supports the AVX instruction set.  This is done in the same way: call the CPUID with eax = 1 and make sure that after that in the 28th bit of the ecx register there is one.  All of the above can be expressed in the following code (copied, with minor modifications, from the Intel AVX Reference): <br> <code>; extern "C" int isAvxSupported() <br> _isAvxSupported: <br> xor eax, eax <br> cpuid <br> cmp eax, 1 ;   CPUID  eax = 1? <br> jb not_supported <br> mov eax, 1 <br> cpuid <br> and ecx, 018000000h ; ,    27 (  XSAVE/XRSTOR) <br> cmp ecx, 018000000h ;  28 ( AVX ) <br> jne not_supported <br> xor ecx, ecx ;   XFEATURE_ENABLED_MASK/XCR0  0 <br> xgetbv ;  XFEATURE_ENABLED_MASK   edx:eax <br> and eax, 110b <br> cmp eax, 110b ; ,    AVX     <br> jne not_supported <br> mov eax, 1 <br> ret <br> not_supported: <br> xor eax, eax <br> ret <br></code> <br><h5>  Using AVX instructions </h5><br>  Now that you know when to use AVX instructions, it's time to switch to using them.  Programming under AVX differs little from programming under other instruction sets, but the following features should be taken into account: <br><ul><li>  It is extremely undesirable to mix SSE- and AVX-instructions (including AVX-analogs of SSE-instructions).  To move from executing AVX instructions to SSE instructions, the processor stores the top 128 bits of the AVX registers in a special cache, which can take fifty clock cycles.  When, after an SSE instruction, the processor returns to the execution of AVX instructions, it will restore the top 128 bits of the AVX registers, which will take another fifty cycles.  Therefore, mixing the SSE and AVX instructions will result in a noticeable decrease in performance.  If you need some command from the SSE in the AVX-code, use its AVX-analogue with the prefix v. </li><li>  Saving the upper part of the AVX registers during the transition to the SSE code can be avoided if you reset the top 128 bits of the AVX registers with the vzeroupper or vzeroall commands.  Although these commands nullify all AVX registers, they work very quickly.  The pitch rule will use one of these commands before exiting a subroutine using AVX. </li><li>  The load / save commands for aligned data vmovaps / vmovapd / vmovdqa require that data be aligned by 16 bytes, even if the command itself loads 32 bytes. </li><li>  On Windows x64, the subroutine should not change the xmm6-xmm15 registers.  Thus, if you use these registers (or their corresponding registers ymm6-ymm15), you must save them on the stack at the beginning of the subroutine and recover from the stack before exiting the subroutine. </li><li>  The Sandy Bridge core will be able to run two 256-bit AVX floating-point commands for each cycle (one multiplication and one addition) due to the expansion of execution units to 256 bits.  The Bulldozer core will have two 128-bit universal floating point execution units that allow it to execute one 256-bit AVX command per cycle (multiply, add, or combined multiplied-add and fused multiply-add); you can hope for the same performance as the Sandy Bridge). </li></ul><br>  Now you know everything to write code using AVX.  For example, such: <br> <code>; extern "C" double _vec4_dot_avx( double a[4], double b[4] ) <br> _vec4_dot_avx: <br> %ifdef X86 <br> mov eax, [esp + 8 + 0] ; eax = a <br> mov edx, [esp + 8 + 8] ; edx = b <br> vmovupd ymm0, [eax] ; ymm0 = *a <br> vmovupd ymm1, [edx] ; ymm1 = *b <br> %else <br> vmovupd ymm0, [rcx] ; ymm0 = *a <br> vmovupd ymm1, [rdx] ; ymm1 = *b <br> %endif <br> vmulpd ymm0, ymm0, ymm1 ; ymm0 = ( a3 * b3, a2 * b2, a1 * b1, a0 * b0 ) <br> vperm2f128 ymm1, ymm0, ymm0, 010000001b ; ymm1 = ( +0.0, +0.0, a3 * b3, a2 * b2 ) <br> vaddpd xmm0, xmm0, xmm1 ; ymm0 = ( +0.0, +0.0, a1 * b1 + a3 * b3, a0 * b0 + a2 * b2 ) <br> vxorpd xmm1, xmm1, xmm1 ; ymm1 = ( +0.0, +0.0, +0.0, +0.0 ) <br> vhaddpd xmm0, xmm0, xmm1 ; ymm0 = ( +0.0, +0.0, +0.0, a0 * b0 + a1 * b1 + a2 * b2 + a3 * b3 ) <br> %ifdef X86 ;  32-          st(0) <br> sub esp, 8 <br> vmovsd [esp], xmm0 <br> vzeroall ;  SSE-  :   <br> fld qword [esp] <br> add esp, 8 <br> %else <br> vzeroupper ;  xmm0   ,     128  <br> %endif <br> ret <br></code> <br><h5>  Testing AVX code </h5><br>  To make sure that the AVX code works, it is better to write Unit tests for it.  However, the question arises: how to run these Unit tests if none of the currently sold processor supports AVX?  This will help you a special utility from Intel - <a href="http://software.intel.com/en-us/articles/intel-software-development-emulator/">Software Development Emulator (SDE)</a> .  All that SDE can do is launch programs by emulating new instruction sets on the fly.  Of course, the performance will be far from that on real hardware, but you can check the correctness of the program in this way.  Using SDE is easy: if you have a unit test for AVX code in the avx-unit-test.exe file and need to run it with the ‚ÄúHello, AVX!‚Äù Parameter, then you just need to run SDE with the parameters <br> <code>sde -- avx-unit-test.exe "Hello, AVX!"</code> <br>  When you launch the SDE program, it emulates not only the AVX instructions, but also the XGETBV and CPUID instructions, so if you use the previously proposed method for detecting AVX support, the program running under SDE will decide that AVX is indeed supported.  In addition to AVX, SDE (or rather, the JIT pin compiler on which SDE is built) can emulate SSE3, SSSE3, SSE4.1, SSE4.2, SSE4a, AES-NI, XSAVE, POPCNT and PCLMULQDQ instructions, so even a very old processor will not prevent you from developing software for new instruction sets. <br><br><h5>  AVX code performance evaluation </h5><br>  Some understanding of AVX code performance can be obtained using another utility from Intel - <a href="http://software.intel.com/en-us/articles/intel-architecture-code-analyzer/">Intel Architecture Code Analyzer (IACA)</a> .  IACA allows you to estimate the execution time of the linear code segment (if conditional branching commands are encountered, the IACA considers that the transition does not occur).  To use IACA, you must first mark with special markers the code points that you want to analyze.  Markers look like this: <br> <code>;   ,    <br> %macro IACA_START 0 <br> mov ebx, 111 <br> db 0x64, 0x67, 0x90 <br> %endmacro <br> <br> ;   ,    <br> %macro IACA_END 0 <br> mov ebx, 222 <br> db 0x64, 0x67, 0x90 <br> %endmacro</code> <br>  Now you should surround these macros with the code you want to analyze. <br> <code>IACA_START <br> vmovups ymm0, [ecx] <br> vbroadcastss ymm1, [edx] <br> vmulps ymm0, ymm0, ymm1 <br> vmovups [ecx], ymm0 <br> vzeroupper <br> IACA_END</code> <br>  The object file compiled with these macros needs to be fed to the IACA: <br> <code>iaca -32 -arch AVX -cp DATA_DEPENDENCY -mark 0 -o avx-sample.txt avx-sample.obj</code> <br>  Parameters for IACA need to be understood as <br><ul><li>  <i>-32</i> - means that the input object file (MS COFF) contains a 32-bit code.  For 64-bit code, you need to specify <i>-64</i> .  If the input file IACA is not an object file (.obj), but an executable module (.exe or .dll), then this argument can be omitted. </li><li>  <i>-arch AVX</i> - shows IACA that you need to analyze the performance of this code on a future Intel processor with AVX support (i.e. Sandy Bridge).  Other possible values: <i>-arch nehalem</i> and <i>-arch westmere</i> . </li><li>  <i>-cp DATA_DEPENDENCY</i> asks IACA to show which instructions are on the critical path for the data (that is, which instructions need to be optimized so that the result of this code is calculated faster).  Other possible meaning: <i>-cp PERFORMANCE</i> asks IACA to show which instructions plug the processor pipeline. </li><li>  <i>-mark 0</i> tells IACA to analyze all the tagged parts of the code.  If you specify <i>-mark n</i> , IACA will only analyze the nth tagged code. </li><li>  <i>-o avx-sample</i> specifies the name of the file to which the analysis results will be written.  You can omit this parameter, then the results of the analysis will be displayed in the console. </li></ul><br>  The result of starting IACA is shown below: <br> <code>Intel(R) Architecture Code Analyzer Version - 1.1.3 <br> Analyzed File - avx-sample.obj <br> Binary Format - 32Bit <br> Architecture  - Intel(R) AVX <br> <br> ******************************************************************* <br> Intel(R) Architecture Code Analyzer Mark Number 1 <br> ******************************************************************* <br> <br> Analysis Report <br> --------------- <br> Total Throughput: 2 Cycles;             Throughput Bottleneck: FrontEnd, Port2_ALU, Port2_DATA, Port4 <br> Total number of Uops bound to ports:  6 <br> Data Dependency Latency:    14 Cycles;  Performance Latency:    15 Cycles <br> <br> Port Binding in cycles: <br> ------------------------------------------------------- <br> |  Port  |  0 - DV |  1 |  2 -  D |  3 -  D |  4 |  5 | <br> ------------------------------------------------------- <br> | Cycles |  1 |  0 |  0 |  2 |  2 |  1 |  1 |  2 |  1 | <br> ------------------------------------------------------- <br> <br> N  - port number, DV - Divider pipe (on port 0), D - Data fetch pipe (on ports 2 and 3) <br> CP - on a critical Data Dependency Path <br> N  - number of cycles port was bound <br> X  - other ports that can be used by this instructions <br> F  - Macro Fusion with the previous instruction occurred <br> ^  - Micro Fusion happened <br> *  - instruction micro-ops not bound to a port <br> @  - Intel(R) AVX to Intel(R) SSE code switch, dozens of cycles penalty is expected <br> !  - instruction not supported, was not accounted in Analysis <br> <br> | Num of |          Ports pressure in cycles          |    | <br> |  Uops  |  0 - DV |  1 |  2 -  D |  3 -  D |  4 |  5 |    | <br> ------------------------------------------------------------ <br> |   1    |    |    |    |  1 |  2 |  X |  X |    |    | CP | vmovups ymm0, ymmword ptr [ecx] <br> |   2^   |    |    |    |  X |  X |  1 |  1 |    |  1 |    | vbroadcastss ymm1, dword ptr [edx] <br> |   1    |  1 |    |    |    |    |    |    |    |    | CP | vmulps ymm0, ymm0, ymm1 <br> |   2^   |    |    |    |  1 |    |  X |    |  2 |    | CP | vmovups ymmword ptr [ecx], ymm0 <br> |   0*   |    |    |    |    |    |    |    |    |    |    | vzeroupper <br></code> <br>  The most important metrics here are Total Throughput and Data Dependency Latency.  If the code you are optimizing is a small subroutine, and the program has a data dependency on its result, then you should try to make Data Dependency Latency as little as possible.  As an example, the above listing of the vec4_dot_avx subroutine.  If the code being optimized is part of a loop that processes a large array of elements, then your task is to reduce Total Throughput (in general, this metric would be called Reciprocal Throughput, but oh well). <br><br><h4>  Using AVX in C / C ++ Code </h4><br>  AVX support is implemented in the following popular compilers: <br><ul><li>  Microsoft C / C ++ Compiler from version 16 (included in Visual Studio 2010) </li><li>  Intel C ++ Compiler from version 11.1 </li><li>  GCC since version 4.4 </li></ul><br>  To use the 256-bit AVX instructions, the distribution of these compilers includes a new header file <i>immintrin.h</i> with a description of the corresponding intrinsic functions.  The inclusion of this header file automatically entails the inclusion of header files of all SSE-intrinsic.  As for the 128-bit AVX instructions, for them there are not only separate headers, but also separate intrinsics functions.  Instead, they use intrinsic functions for SSEx instructions, and the type of instructions (SSE or AVX) into which calls to these intrinsic functions will be compiled is specified in the compiler settings.  This means that mixing SSE and AVX forms of 128-bit instructions in one compiled file will not work, and if you want to have both SSE and AVX versions of functions, then you will have to write them in different compiled files (and compile these files with different parameters ).  Compilation options that include compiling SSEx intrinsic functions in AVX instructions are as follows: <br><ul><li>  / arch: AVX - for Microsoft C / C ++ Compiler and Intel C ++ Compiler for Windows </li><li>  -mavx - for GCC and Intel C ++ Compiler for Linux </li><li>  / QxAVX - for Intel C ++ Compiler </li><li>  / QaxAVX - for Intel C ++ Compiler </li></ul><br>  It should be borne in mind that these commands not only change the behavior of SSEx intrinsic functions, but also allow the compiler to generate AVX instructions when compiling normal C / C ++ code (/ QaxAVX tells the Intel compiler to generate two versions of code - with AVX instructions and basic x86 instructions ). <br>  To make it easier to deal with all these intrinsics, Intel made an online reference guide - the Intel Intrinsic Guide, which includes descriptions of all the intrinsic functions supported by Intel processors.  For those instructions that are already implemented in the hardware, latency and throughput are also indicated.  You can download this reference book from the <a href="http://software.intel.com/en-us/avx/">Intel AVX</a> website (there are versions for Windows, Linux and Mac OS X). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  Definition of AVX support system </h5><br>  In principle, to recognize the support of the AVX system, you can use the previously assembled code, rewriting it in an inline-assembler, or simply linking the assembled object file.  However, if inline assembly is not possible (for example, because of coding guidelines, or because the compiler does not support it, as is the case with Microsoft C / C ++ Compiler for Windows x64), then you are in deep shit.  The problem is that the intrinsic functions for the xgetbv instruction do not exist!  Thus, the task is divided into two parts: check that the processor supports AVX (this can be done cross-platform) and check that the OS supports AVX (here you have to write your own code for each OS). <br>  You can verify that the processor supports AVX using the same CPUID instruction for which there is an intrinsic-function void <a href="http://msdn.microsoft.com/en-us/library/hskdteyh.aspx">__cpuid</a> (int cpuInfo [4], int infoType).  The infoType parameter sets the value of the eax register before the CPUID call, and after executing the function, cpuInfo will contain the eax, ebx, ecx, edx registers (in that order).  So  we get the following code: <br> <code>int isAvxSupportedByCpu() { <br> int cpuInfo[4]; <br> __cpuid( cpuInfo, 0 ); <br> if( cpuInfo[0] != 0 ) { <br> __cpuid( cpuInfo, 1 ); <br> return cpuInfo[3] &amp; 0x10000000; //  ,  28-   ecx  <br> } else { <br> return 0; //          <br> } <br> }</code> <br>  With support from the OS more difficult.  AVX is currently supported by the following OS: <br><ul><li>  Windows 7 </li><li>  Windows Server 2008 R2 </li><li>  Linux with kernel 2.6.30 and higher </li></ul><br>  Windows has added the ability to learn about OS support for new instruction sets in the form of the GetEnabledExtendedFeatures function from kernel32.dll.  Unfortunately, this function is <a href="http://msdn.microsoft.com/en-us/library/dd405466.aspx">documented a little less than nothing</a> .  But you can still get some information about her.  This feature is described in the WinBase.h file from the Platform SDK: <br> <code>WINBASEAPI <br> DWORD64 <br> WINAPI <br> GetEnabledExtendedFeatures( <br> __in DWORD64 FeatureMask <br> );</code> <br>  The values ‚Äã‚Äãfor the FeatureMask parameter can be found in the WinNT.h header: <br> <code>// <br> // Known extended CPU state feature IDs <br> // <br> <br> #define XSTATE_LEGACY_FLOATING_POINT        0 <br> #define XSTATE_LEGACY_SSE                   1 <br> #define XSTATE_GSSE                         2 <br> <br> #define XSTATE_MASK_LEGACY_FLOATING_POINT   (1i64 &lt;&lt; (XSTATE_LEGACY_FLOATING_POINT)) <br> #define XSTATE_MASK_LEGACY_SSE              (1i64 &lt;&lt; (XSTATE_LEGACY_SSE)) <br> #define XSTATE_MASK_LEGACY                  (XSTATE_MASK_LEGACY_FLOATING_POINT | XSTATE_MASK_LEGACY_SSE) <br> #define XSTATE_MASK_GSSE                    (1i64 &lt;&lt; (XSTATE_GSSE)) <br> <br> #define MAXIMUM_XSTATE_FEATURES             64</code> <br> <br>  It is easy to see that the XSTATE_MASK_ * masks correspond to the same bits in the XFEATURE_ENABLED_MASK register. <br>  In addition to this, in the Windows DDK there is a description of the <a href="http://msdn.microsoft.com/en-us/library/ff561905.aspx">RtlGetEnabledExtendedFeatures</a> function and <a href="http://msdn.microsoft.com/en-us/library/ff561905.aspx">XSTATE_MASK_XXX</a> constants, like two drops of water similar to GetEnabledExtendedFeatures and XSTATE_MASK_ from WinNT.h.  So  To determine if Windows supports AVX, you can use the following code: <br> <code>int isAvxSupportedByWindows() { <br> const DWORD64 avxFeatureMask = XSTATE_MASK_LEGACY_SSE | XSTATE_MASK_GSSE; <br> return GetEnabledExtendedFeatures( avxFeatureMask ) == avxFeatureMask; <br> }</code> <br>  If your program should work not only in Windows 7 and Windows 2008 R2, then the GetEnabledExtendedFeatures function needs to be loaded dynamically from kernel32.dll, since  Other versions of Windows do not have this feature. <br><br>  In Linux, as far as I know, there is no separate function to learn about OS support from AVX.  But you can take advantage of the fact that AVX support was added to 2.6.30 kernel.  Then it remains only to verify that the kernel version is not less than this value.  You can check the kernel version using the <a href="http://www.kernel.org/doc/man-pages/online/pages/man2/uname.2.html">uname</a> function. <br><br><h5>  Using AVX instructions </h5><br>  Writing AVX code using intrinsic functions will not cause you any difficulty if you have ever used MMX or SSE using intrinsic.  The only thing that needs to be taken care of is to call the _mm256_zeroupper () function at the end of the subroutine (as you might guess, this intrinsic-function generates a vzeroupper instruction).  For example, the above assembler subroutine vec4_dot_avx can be rewritten in intrinsic like this: <br> <code>double vec4_dot_avx( double a[4], double b[4] ) { <br> // mmA = a <br> const __m256d mmA = _mm256_loadu_pd( a ); <br> // mmB = b <br> const __m256d mmB = _mm256_loadu_pd( b ); <br> // mmAB = ( a3 * b3, a2 * b2, a1 * b1, a0 * b0 ) <br> const __m256d mmAB = _mm256_mul_pd( mmA, mmB ); <br> // mmABHigh = ( +0.0, +0.0, a3 * b3, a2 * b2 ) <br> const __m256d mmABHigh = _mm256_permute2f128_pd( mmAB, mmAB, 0x81 ); <br> // mmSubSum = ( +0.0, +0.0, a1 * b1 + a3 * b3, a0 * b0 + a2 * b2 ) <br> const __m128d mmSubSum = _mm_add_pd( <br> _mm256_castpd256_pd128( mmAB ), <br> _mm256_castpd256_pd128( mmABHigh ) <br> ); <br> // mmSum = ( +0.0, +0.0, +0.0, a0 * b0 + a1 * b1 + a2 * b2 + a3 * b3 ) <br> const __m128d mmSum = _mm_hadd_pd( mmSubSum, _mm_setzero_pd() ); <br> const double result = _mm_cvtsd_f64( mmSum ); <br> _mm256_zeroupper(); <br> return result; <br> }</code> <br> <br><h5>  Testing AVX code </h5><br>  If you use the AVX instruction set via intrinsic-functions, then, in addition to running this code under the SDE emulator, you have another opportunity - to use a <a href="http://software.intel.com/en-us/articles/avx-emulation-header-file/">special header file</a> that emulates 256-bit AVX intrinsic-functions via the SSE1.2 intrinsic-functions .  In this case, you will have an executable file that can be run on Nehalem and Westmere processors, which, of course, is faster than an emulator.  However, keep in mind that this method does not succeed in detecting errors generated by the AVX code by the compiler (and they may well be). <br><br><h5>  AVX code performance evaluation </h5><br>  Using IACA to analyze the performance of AVX code created by a C / C ++ compiler from intrinsic functions is almost the same as analyzing assembler code.  In the IACA distribution you can find the header file iacaMarks.h, which describes the macros markers IACA_START and IACA_END.  They need to mark the analyzed code sections.  In the code of the subroutine, the IACA_END token must appear before the return statement, otherwise the compiler will "optimize" by throwing out the marker code.  The IACA_START / IACA_END macros use an inline-assembler that is not supported by Microsoft C / C ++ Compiler for Windows x64, so if you need to use special macros for it - IACA_VC64_START and IACA_VC64_END. <br><br><h4>  Conclusion </h4><br>  This article has demonstrated how to develop programs using the AVX instruction set.  I hope that this knowledge will help you to please your users with programs that use the capabilities of a computer for one hundred percent! <br><br><h4>  Exercise </h4><br>  The code for the vec4_dot_avx subroutine is not optimal in terms of performance.     .     Data Dependency Latency? </div><p>Source: <a href="https://habr.com/ru/post/99367/">https://habr.com/ru/post/99367/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../99362/index.html">Will the Russian market be closed for devices without a GLONASS chip?</a></li>
<li><a href="../99363/index.html">Announced Facebook C # SDK</a></li>
<li><a href="../99364/index.html">Habrafutbol-4: the beginning</a></li>
<li><a href="../99365/index.html">New version of IronRuby 1.1 released</a></li>
<li><a href="../99366/index.html">Compilation. 3: bison</a></li>
<li><a href="../99368/index.html">On Monday, Valve released a new free (!) Game Alien Swarm</a></li>
<li><a href="../99369/index.html">Overview of the Chinese UMPC Gome FlyTouch</a></li>
<li><a href="../99371/index.html">We create PivotViewer site content in 10 minutes using the example of Habrahabr</a></li>
<li><a href="../99373/index.html">Making lines of multiple parts</a></li>
<li><a href="../99375/index.html">Facts and Errors of Professional Programming</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>