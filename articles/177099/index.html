<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Methods for assessing the subjective quality of speech</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anyway, the most important resource in data transmission networks is the bandwidth of communication channels. In addition to increasing the maximum ba...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Methods for assessing the subjective quality of speech</h1><div class="post__text post__text-html js-mediator-article">  Anyway, the most important resource in data transmission networks is the bandwidth of communication channels.  In addition to increasing the maximum bandwidth of communication channels and their number, it is obvious that it makes sense to optimize the use of existing ones.  For example, using compression algorithms.  For each case, the most optimal algorithm (in terms of computational complexity, compression ratio, etc.) can be its own. <br>  A feature of sound compression is the subjectivity of its perception by man.  This at the same time makes it possible to exclude insignificant information from the signal, but also complicates the compression algorithm. <br>  In order to achieve the highest compression ratio with minimal loss of subjective quality, it is necessary to know the laws of its perception.  This deals with <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D1%2581%25D0%25B8%25D1%2585%25D0%25BE%25D0%25B0%25D0%25BA%25D1%2583%25D1%2581%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0">psychoacoustics</a> . <br>  When using psychoacoustic properties, traditional methods of quality assessment are no longer suitable for compression.  For example, the signal-to-noise ratio becomes almost useless, because  compression occurs without taking into account those parts that a person does not perceive.  Thus, the quality assessment should also take into account the properties of the human hearing system. <br><br>  Under the cat will be considered some properties of speech signals and features of their perception by man, objective and subjective ways of assessing the quality of these signals. <br><br>  PS This article used my thesis, defended in 2011 at the Moscow Aviation Institute at the Faculty of Radio Electronics Flying Devices of the Department.  402. Previously, the work has not been published anywhere. <br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Speech signal and its basic properties </h4><br>  In the general case, a speech signal in telecommunications systems means a process that performs the function of transmitting a voice message.  It can be acoustic, mechanical, electrical and other processes.  A speech message is usually created in the human brain.  Then it turns into signals of the nervous system that control the articulation movements of the speech organ.  In turn, these movements control the formation of speech signals in the speech-forming path.  The speech-forming tract consists of laryngeal, pharyngeal, oral and nasal cavities, the volume and elasticity of the walls of which vary with time.  Changes in the configuration of the speech-forming path in the process of making speech sounds affect the acoustic wave passing through the path.  The received signals are emitted into the surrounding space as an acoustic signal.  Next, the acoustic signal in the transmission path of the telecommunications system is converted into an electrical signal. <br>  In the future, the signal can undergo various transformations, remaining electric.  In some cases, after amplification, the electrical signal directly enters the electroacoustic transducer, in other cases, after a series of transformations in form (modulation and demodulation, quantization, coding, companding, etc.) eventually also turns into an acoustic signal, however, the signal may remain digital, for example, in speech recognition tasks.  Acoustic signal, acting on the eardrum, turns into a mechanical signal, and in the inner ear - a signal of the nervous system.  This signal in the central nervous system is, as it were, decoded, as a result of which the original message is recreated.  In some cases, this message may differ from the original one, which is associated with distortions in communication systems. <br>  The frequency of the sound wave can vary greatly, but a person perceives frequencies from 20 to 22 000 Hz (wavelength from 1.56 cm to 17.19 m).  The dynamic range of the volume levels perceived by a person is very large. <br><div class="spoiler">  <b class="spoiler_title">Therefore, when measuring the sound volume using a logarithmic scale</b> <div class="spoiler_text">  Level = 10 * lg (P1 / P2) [dB] </div></div><br>  It was established experimentally that the power of the weakest audible sound is 1 ¬µW.  There is also a volume scale in units of sound pressure, where the pressure of 10 ^ ‚Äì5 N / cm2 is taken as the zero level.  For this scale, dB SPL (Sound Pressure Level - SPL) is used. <br>  Practically, the transmission of a voice message via electrical communication is solved by means of a digital representation, processing, and transmission of a speech signal through a communication channel ‚Äî an acoustic wave represented in the form of electrical oscillation.  In such a case, speech represents the vibrations of a complex form, depending on the words being spoken, the timbre of the voice, intonation, gender and age of the speaker.  Under the frequency range of speech understand the bandwidth occupied by the speech signal.  It lies in the frequency range from 100 to 8000 Hz.  However, in accordance with the recommendations of the CCITT (International Advisory Committee on Telephony and Telegraphy), during signal conversion and processing, they are limited to the frequency range from 300 to 3400 Hz. <br><br><h4>  Subjective perception of sound </h4><br>  As already noted, the human hearing aid perceives sounds whose frequency is in the range from 20 to 22,000 Hz.  but <br>  The sensitivity of the human ear is not the same throughout the perceived range. <br>  The figure shows areas of the auditory perception, including the corresponding speech and music: <br><img src="https://habrastorage.org/storage2/429/ffc/024/429ffc0247379de74f6c3cb889274380.png" alt="Areas of hearing"><br>  The frequency range of human speech is approximately in the range from 100 to 8000 Hz. <br>  The existence of a hearing threshold is the basis for the construction of lossy sound compression algorithms. <br><br><h5>  Frequency masking </h5><br>  In addition, for effective compression, two more properties of human hearing organs are used: frequency masking and time masking. <br>  Frequency (auditory) masking occurs when a normally audible sound is covered by another loud sound with a close frequency.  The figure schematically depicts the masking and masked sounds: <br><img src="https://habrastorage.org/storage2/693/408/5ee/6934085ee4ae1b459c4e37dfebee4c8b.png" alt="Frequency masking"><br>  The audible (masking) sound raises the threshold of hearing in its surroundings (threshold of hearing during masking).  As a result, the sound <br>  shown by the dotted line is no longer heard, since it is masked by a louder sound.  This property is used in compression.  Signals corresponding to such sounds are simply removed from the data set, since they will not be heard anyway.  Frequency masking depends on the frequency of the signal.  It ranges from 100 Hz at low audible frequencies to 4,000 Hz at high frequencies.  Consequently, the range of audible frequencies can be divided into several critical bands, within which the ear sensitivity falls. <br><br><h5>  Critical stripes </h5><br>  Critical bars are another sound characteristic along with frequency.  In contrast to frequency, the critical bands are determined in accordance with the auditory perception. <div class="spoiler">  <b class="spoiler_title">25 approximate areas of critical bands are given in the table.</b> <div class="spoiler_text"><table><tbody><tr><th>  No </th><td>  Region </td><th>  No </th><td>  Region </td><th>  No </th><td>  Region </td><th>  No </th><td>  Region </td><th>  No </th><td>  Region </td></tr><tr><th>  one </th><td>  0-100 </td><th>  6 </th><td>  510-630 </td><th>  eleven </th><td>  1270-1480 </td><th>  sixteen </th><td>  2700-3150 </td><th>  21 </th><td>  6400-7700 </td></tr><tr><th>  2 </th><td>  100-200 </td><th>  7 </th><td>  630-770 </td><th>  12 </th><td>  1480-1720 </td><th>  17 </th><td>  3150-3700 </td><th>  22 </th><td>  7700-9500 </td></tr><tr><th>  3 </th><td>  200-300 </td><th>  eight </th><td>  770-920 </td><th>  13 </th><td>  1720-2000 </td><th>  18 </th><td>  3700-4400 </td><th>  23 </th><td>  9500-12000 </td></tr><tr><th>  four </th><td>  300-400 </td><th>  9 </th><td>  920-1080 </td><th>  14 </th><td>  2000-2320 </td><th>  nineteen </th><td>  4400-5300 </td><th>  24 </th><td>  12000-15500 </td></tr><tr><th>  five </th><td>  400-510 </td><th>  ten </th><td>  1080-1270 </td><th>  15 </th><td>  2320-2700 </td><th>  20 </th><td>  5300-6400 </td><th>  25 </th><td>  15500-23500 </td></tr></tbody></table><br></div></div><br>  The critical bands can be described as follows: due to the limited hearing of sound frequencies, the threshold of hearing <br>  the frequency f is raised by the adjacent sound, if the sound is in the critical band f.  The width of the critical band is called its size. <br><br><h5>  Temporary masking </h5><br><img src="https://habrastorage.org/storage2/da5/df3/378/da5df3378878010f95cfa1c52884d32d.png" alt="Temporary masking"><br>  Temporal masking is observed when a loud sound of frequency f in time is preceded or followed by a less loud sound of close frequency (and also with a simultaneous sound of close frequency).  The masking of the preceding sound manifests itself in an interval of not more than 10 ms, whereas the subsequent sound can be masked in an interval from 100 to 200 ms. <br><br><h4>  Converting speech signals to digital form </h4><br>  Given the audience of the portal, there is no special reason to consider the processes of discretization and quantization. <br><br><h4>  Methods for assessing speech quality </h4><br>  Methods of assessing the quality of the audio signal transmission system are mainly determined by the purpose of this system (speech, music, etc.).  A common feature for these systems is that they all eventually come to the human hearing system.  When transmitting via communication channels, speech is considered as a random process, the characteristics of which determine the parameters of the transmitted signal (dynamic range, band, signal-to-noise ratio).  All these parameters are measurable and can be accurately determined.  However, considering that, on the other hand, the speech signal is perceived by a person, it should be noted that, from the person‚Äôs point of view, the speech signal is evaluated subjectively, obeying the laws of the psychophysiology of hearing.  Thus, we get the following picture: the quality of the speech signal is objectively evaluated by a number of indicators that can never fully replace the system of perception of sound by man.  Disregarding the nuances of directly transmitting a speech signal, one can say that an objective assessment of speech quality should correlate with a subjective assessment. <br>  The quality of a codec can be evaluated by two criteria: <br><ol><li>  Objective quality preservation <br>  Distortion detection using hardware. <br></li><li>  Preservation of subjective quality <br>  Determination of the visibility of distortion by subjective statistical <br>  tests. <br></li></ol><br>  Since rigorous mathematical relationships that establish a connection between the objective parameters of the sound path and perception have not yet been obtained, none of the existing methods can provide an accurate assessment of the sound quality.  Currently, there are three types of methods for assessing the quality of sound signals: subjective, objective, and psychoacoustic. <br><br><h5>  Subjective methods </h5><br>  To assess the signal distortion, subjective statistical tests (FID) are performed with the help of a group of experts. <br>  Subjective quality assessments are based on the statistical processing of subjective quality assessments of a fairly large number of expert listeners.  These assessments significantly depend on the age and gender of the speaker, the speed of pronunciation of phrases and other circumstances.  Tests for obtaining subjective assessments are carried out with imitation of real conditions, for example, ambient noise, background speech of other people, etc. The quantitative results of these tests reflect the average quality, level of effort of the listener, intelligibility, and natural sound. <br>  Each separate outcome of the FID is a random event, and the apparatus of probability theory and mathematical statistics is used to analyze the results.  However, even taking into account these measures, it is impossible to repeat the test results exactly. <br>  MOS (Mean Opinion Score) expert assessment is a subjective measurement defined in ITU-T Recommendation P.800 for assessing the quality of transmission in telephone networks. <br>  For different tasks, different 5-point category rating scales can be used.  The three most used scales of opinion in ITU-T studies are: <br><br><div class="spoiler">  <b class="spoiler_title">Quality scale when listening</b> <div class="spoiler_text"><table><tbody><tr><th>  Speech quality </th><th>  Evaluation </th></tr><tr><td>  Great </td><td>  five </td></tr><tr><td>  Good </td><td>  four </td></tr><tr><td>  Satisfactory </td><td>  3 </td></tr><tr><td>  Mediocre </td><td>  2 </td></tr><tr><td>  The bad </td><td>  one </td></tr></tbody></table><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Effort when listening</b> <div class="spoiler_text"><table><tbody><tr><th>  The effort required to understand the meaning of phrases </th><th>  Evaluation </th></tr><tr><td>  Perhaps complete relaxation, no effort required. </td><td>  five </td></tr><tr><td>  Attention needed, does not require noticeable effort </td><td>  four </td></tr><tr><td>  Requires moderate effort </td><td>  3 </td></tr><tr><td>  Significant effort required </td><td>  2 </td></tr><tr><td>  The meaning is not clear under any conditions. </td><td>  one </td></tr></tbody></table><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Preference scale by volume</b> <div class="spoiler_text"><table><tbody><tr><th>  Volume Preference </th><th>  Evaluation </th></tr><tr><td>  Much louder than preferred level </td><td>  five </td></tr><tr><td>  Louder than preferred </td><td>  four </td></tr><tr><td>  Preferred level </td><td>  3 </td></tr><tr><td>  Quiet preferred level </td><td>  2 </td></tr><tr><td>  Significantly quieter preferred level </td><td>  one </td></tr></tbody></table><br></div></div><br><br>  The estimated value (average score of opinions) is indicated by <br>  MOS characters.  MOS estimates are given in the table: <br><table><tbody><tr><th>  Subjective quality assessment <br>  speech sound </th><th>  The level of perception of speech information </th><th>  Evaluation </th></tr><tr><td>  Fine </td><td>  Speech is perceived completely and effortlessly. </td><td>  five </td></tr><tr><td>  Good </td><td>  Speech is perceived freely, without appreciable effort. </td><td>  four </td></tr><tr><td>  Satisfactorily </td><td>  Speech is perceived with moderate effort, the presence of defects is indisputable </td><td>  3 </td></tr><tr><td>  poorly </td><td>  Speech is perceived attention </td><td>  2 </td></tr><tr><td>  Very bad </td><td>  Speech is not perceived in whole or in part. </td><td>  one </td></tr></tbody></table><br><br>  The absolute values ‚Äã‚Äãof MOS depend on the context of the tests, they are influenced by differences in the level of knowledge of the language, etc. <br><br><h5>  Objective methods </h5><br>  Objective methods offer less time-consuming methods compared to subjective ones.  Objective methods are based on an assessment of the degree of difference between the encoded and original signals. <br>  The parameters are diverse and for different types of coding may differ fundamentally.  Despite the fact that there is some correlation between objective indicators and subjective quality, it is impossible to clearly judge subjective quality, which, in fact, explains the quality assessment method for each of the codecs.  Thus, it is obvious that at the moment there is no universal objective method for assessing subjective quality. <br><br><h6>  Signal to noise ratio (SNR) </h6><br>  The most common estimate is the signal to noise ratio.  This method is also called the general signal-to-noise ratio.  It takes into account the overall ratio of signal power and noise throughout the duration of the signal.  However, at a low intensity of the useful signal, at some segment it may be masked by another part of the signal with a higher intensity of the useful signal, which ultimately distorts the estimate. <br><br><h6>  Segment signal / noise ratio (segSNR) </h6><br>  It is a development of the signal-to-noise ratio method.  In this case, the signal-to-noise ratio is estimated at intervals of 15 to 20 ms, which makes it possible to obtain a more accurate estimate as a whole, since the uneven signal intensity will not distort the whole picture. <br><br><h5>  Psychoacoustic methods </h5><br>  Psychoacoustic quality assessment methods take into account the peculiarities of human perception of sound in general and speech in particular.  The peculiarity of these methods is that only the subjective quality of the signal is assessed using hardware and software.  Thus, strictly speaking, they relate to objective methods, but are built on the basis of the peculiarities of the subjective perception of sound by man. <br>  With the development of ways to eliminate redundancy of audio signals, it became impossible to evaluate the quality by objective parameters, and the subjective statistical tests remained (and remain) very laborious.  The elimination of redundancy was based on the features of the perception of sound and speech by man, which led to the application of knowledge about these features in the methods of quality assessment. <br>  The task of any method of assessing the quality of a speech signal is to achieve a high degree of correlation with the subjective statistical tests, which still remains the most accurate assessment of speech quality. <br>  Most of the methods are based on a comparison of the original and coded signals using some psychoacoustic model.  The degree of noticeable distortion in the coded signal for a person is evaluated.  A psychoacoustic model is a model that converts a sound signal into its internal representation from the point of view of the human hearing aid, which is compared with the internal representation of the original signal. <br>  The most common is weighted spectrum distortion (WSS) and the PESQ estimate, as defined in <a href="http://www.itu.int/rec/T-REC-P.862-200102-I/en">ITU-T Rec</a> . <a href="http://www.itu.int/rec/T-REC-P.862-200102-I/en">P.862</a> . <br><br><h6>  Weighted Spectral Distortion (WSS) </h6><br>  The WSS method estimates spectrum distortion in 25 critical hearing bands between the original and distorted signal segments. <br>  First, the signal energy is determined in each of the 25 critical bands and the peak critical band is determined, the energy of which is greater than the others.  After that, taking into account the information about the peak, the weight coefficient of each critical band is determined.  Further, the assessment is formed taking into account the weight and energy of each critical band. <br><br><h6>  PESQ Evaluation </h6><br>  This algorithm is an objective method for determining the quality of voice communication in telephone systems, which predicts the results of a subjective assessment of the quality of this type of communication by expert listeners.  To determine the quality of voice transmission, PESQ provides for a comparison of the input, or reference, signal with its distorted version at the output of the communication system.  This process is shown schematically in the figure: <br><br><img src="https://habrastorage.org/storage2/86c/226/b52/86c226b521b4b479a242d21c608ba18a.png" alt="Generalized PESQ algorithm scheme"><br><br>  The result of comparing the input and output signals is a communication quality assessment, which is similar to the average subjective MOS score (Mean Opinion Score), determined by a group of expert listeners according to ITU-T P.800 specification.  PESQ scores are calibrated using a huge MOS rating database. <br>  PESQ incorporates many new developments, which favorably distinguishes its previous speech codec performance evaluation algorithms, for example, PSQM and MNB [ITU-T P.861].  These innovations make it possible to confidently use PESQ both to determine the quality of end-to-end speech transmission, and to assess the impact on the communication quality of individual elements of network equipment, including codecs. <br>  In the process of developing the PESQ standard, ITU-T specialists selected the best methods for determining the quality of voice communication from the point of view of the correlation of their results with the MOS estimates under various communication conditions, which is a guarantee of good performance of the standardized algorithm when testing conventional (fixed and mobile) networks and transmission systems packet data. <br>  The PESQ algorithm takes into account the following causes of signal quality degradation: coding distortion, transmission errors, packet loss, packet transfer delay time and fluctuation of this time, signal filtering in analog network components. <br><br>  <strong>Signal processing in PESQ:</strong> <br><br><img src="https://habrastorage.org/storage2/c6b/de5/e51/c6bde5e51a59832f71d7f1baa26dd398.png" alt="Detailed scheme of the PESQ algorithm"><br><ol><li>  <b>Leveling</b> <br>  To correctly compare input and output speech signals, their power level must be equalized.  This is necessary because the input signal cannot be of any particular level, and the gain of the system under test is unknown before testing. <br>  In PESQ, it is assumed that the level of the signal being heard is constant and equal to 79 dB of sound pressure at the ERP point (Ear Reference Point) [ITU-T P.830 Section 8.1.2].  To bring to the specified level, both signals are amplified - input and output. </li><li>  <b>Input filtering</b> <br>  Analog connections often filter the signals transmitted through them to one degree or another.  For example, the transmitting part of the handset usually filters the speech signal, having an amplitude-frequency characteristic (AFC), which is similar to the standard Modified IRS (Intermediate Reference System) send [ITU-T P.830].  As a rule, this is permissible, since this kind of signal processing has a smaller impact on the quality of communication than the signal distortions that occur during its coding. </li><li>  <b>Time alignment</b> <br>  A variable signal transmission delay may occur in a communication system.  To correctly compare the input and output signals, they must be aligned relative to each other in time.  In PESQ, the signal is listened on, but there is no information about the latency of the latter on the network.  A voice is detected in the PESQ to identify the speech parts of the signal and discard the noise. <br>  Time alignment is performed in three stages: <br><ul><li>  In the first stage, PESQ aligns large portions of active speech identified by a voice detector.  These fragments may contain pauses, the duration of which does not exceed a predetermined threshold value (200 ms).  In this process, a delay is detected in the transmission of large fragments of the output signal compared to the input signal. </li><li>  In the second stage, PESQ evens out partially coinciding small sections of speech (frames).  This process reveals a delay, which is not constant during the transmission of a large fragment of active speech; in packet networks, such a delay can be quite significant. </li><li>  The third stage is carried out after the operation of the auditory transformation.  At this stage, the so-called ‚Äúbad intervals‚Äù (fragments of speech with very large distortions) are re-aligned.  This step improves the accuracy of the algorithm when using a small number of files, the transfer of which incorrectly determines the delay variation during the initial time alignment process. </li></ul></li><li>  <b>Auditory conversion</b> <br>  Comparison of the input and output signals is preceded by their auditory transformation, which mimics certain features of human hearing.  This gives information about the perceived loudness of the signal depending on time and frequency, represented as a sensation surface.  Determination of the distortion parameters. The difference between the perceptual surfaces of the input and output files is called the error surface;  it indicates all audible differences in the sound of these files appearing in the system under test.  The error surface is analyzed taking into account the effect on the communication quality of those small signal distortions that are not audible against the background of high-volume signals (masking effect).  Based on information about positive and negative errors, two distortion parameters are calculated as nonlinear means over specific areas of the error surface.  These parameters are: <br><ul><li>  Absolute (symmetric) distortion absolute audible error </li><li>  Additional (asymmetric) distortion - characterize audible errors that are significantly louder than the input signal </li></ul></li></ol><br>  Thus, the algorithm gives two distortion parameters in which the error values ‚Äã‚Äãof each type are summed up.  At the final stage of the algorithm, these distortion parameters are converted into an estimate of the quality of communication, which is a linear combination of the average values ‚Äã‚Äãof symmetric and asymmetric distortions. <br>  The PESQ algorithm evaluates speech quality on a five-point scale standardized in the telecommunications industry - from 1 to 5 [ITU-T P.800].  However, the PESQ score does not exceed 4.5, since it is usually the maximum value obtained by subjective testing of MOS. <br>  PESQ assessment characterizes the perception of the quality of communication by users.  A higher score of 4.5 means that the algorithm did not reveal any distortions. <br><br><h4>  Used sources </h4><br><ol><li>  Sergeenko V.S., Barinov V.V., Data compression, speech, sound and images in telecommunication systems, 2009, IP "Radiosoft" </li><li>  Richter SG, Coding and voice transmission in digital mobile communication systems, 2009, Hotline - Telecom </li><li>  <a href="http://www.itu.int/rec/dologin_pub.asp%3Flang%3De%26id%3DT-REC-P.862-200102-I!!SOFT-ZST-E%26type%3Ditems">ITU-T P.800</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/177099/">https://habr.com/ru/post/177099/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../177083/index.html">JQuery plugin for translating pages using html5 data- * attributes</a></li>
<li><a href="../177085/index.html">Creating and storing backup copies of databases in MS SQL. Practical advice</a></li>
<li><a href="../177089/index.html">Understanding the construction of multi-regional sites</a></li>
<li><a href="../177095/index.html">Impressions of the Hannover Messe</a></li>
<li><a href="../177097/index.html">How does LTE cope with inter-cell interference</a></li>
<li><a href="../177105/index.html">Pichmongi and maglutes</a></li>
<li><a href="../177109/index.html">Formal languages ‚Äã‚Äãand grammar</a></li>
<li><a href="../177111/index.html">Marathon puzzles in C ++</a></li>
<li><a href="../177113/index.html">Hormonal holywar Admin and Development PHP or REMOTE_ADDR vs HTTP_X_FORWARDED_FOR</a></li>
<li><a href="../177115/index.html">Comparing Angular, Backbone, CanJS and Ember</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>