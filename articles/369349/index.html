<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Artificial neural networks in simple words</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When, over a bottle of beer, I started a conversation about neural networks - people usually started to look at me fearfully, were sad, sometimes thei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">🔎</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">📜</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">⬆️</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">⬇️</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Artificial neural networks in simple words</h1><div class="post__text post__text-html js-mediator-article"><img width="500" src="https://habrastorage.org/files/8b7/670/081/8b767008109149b9b48ee3058e62e028.png" alt="image" align="left"><br><p>  When, over a bottle of beer, I started a conversation about neural networks - people usually started to look at me fearfully, were sad, sometimes their eyes started to twitch, and in extreme cases they climbed under the table.  But, in fact, these networks are simple and intuitive.  Yes Yes exactly!  And let me, I will prove it to you! <br><br clear="left">  Suppose I know two things about a girl — whether she is cute to me or not, and whether there is anything to talk to her about.  If there is, then we will consider it a unit, if not, then - zero.  A similar principle we take for the exterior.  Question: “What girl will I fall in love with and why?” </p><br><p>  You can think simply and uncompromisingly: <em>“If you are cute and have something to talk about, then you will fall in love.</em>  <em>If neither one nor the other, then dismiss. ”</em> </p><br><a name="habracut"></a><br><p>  <strong>But what if the lady is cute to me, but she has nothing to talk about?</strong>  <strong>Or vice versa?</strong> </p><br><p>  It is clear that for each of us one thing will be more important.  More precisely, each parameter has its level of importance, or rather, weight.  If we multiply a parameter by its weight, then we get, respectively, “the influence of appearance” and “influence <del>  talkativeness </del>  conversation. ” </p><br><p>  And now I can answer my question with a clear conscience: </p><br><p>  <em>“If the influence of charisma and the influence of talkativeness in the sum is more than the value of“ falling in love ”, then I will fall in love ...”</em> </p><br><p><img src="https://habrastorage.org/files/ead/ac7/0bd/eadac70bd4984a9a83630b4d8b8ebf89.png" alt="image"></p><br><p>  That is, if I put a lot of weight on the boltology of the ladies and a small appearance weight, then in a controversial situation I will fall in love with a person with whom it is pleasant to chat.  And vice versa. </p><br><p><img src="https://habrastorage.org/files/bfe/d13/e50/bfed13e5071e427e934455c535f39487.png" alt="image"></p><br><p>  Actually, this rule is the neuron. </p><br><p>  <strong>An artificial neuron is a function that converts several input facts into one output.</strong>  By adjusting the weights of these facts, as well as the excitation threshold, we adjust the adequacy of the neuron.  In principle, for many the science of life ends at this level, but this story is not about us, right? </p><br><p>  Let's make some more conclusions: </p><br><ul><li>  If both weights are small, then it will be difficult for me to fall in love with anyone. </li><li>  If both weights are too large, then I will fall in love with even a pole. </li><li>  You can also make me fall in love with a pillar by lowering the amorousness threshold, but please - don't do this to me!  Better let's forget about him for now, ok? </li></ul><br><div class="spoiler">  <b class="spoiler_title">Speaking of the threshold</b> <div class="spoiler_text"><p>  It is ridiculous, but the parameter “amorousness” is called “threshold of arousal”.  But, so that this article did not receive a rating of “18+”, let's agree to say simply “threshold”, ok? </p></div></div><br><h2>  Neural network </h2><br><p>  There are no definitely nice and sociable ladies.  And falling in love with love is different, no matter what anyone says.  Therefore, instead of brutal and uncompromising “0” and “1”, let's use percentages.  Then you can say - “I'm very in love (80%), or“ this lady is not very talkative (20%) ”. </p><br><p>  Our primitive “maximalist neuron” from the first part does not suit us.  It is replaced by a “sage neuron”, the result of which will be a number from 0 to 1, depending on the input data. </p><br><p><img src="https://habrastorage.org/files/1c9/39c/bab/1c939cbab74b4a49b02e7f893da97b3f.png" alt="image"></p><br><p>  “The neuron-sage” can tell us: “this lady is beautiful enough, but I don’t know what to say to her, so I’m not really excited about her” </p><br><p><img src="https://habrastorage.org/files/5e4/251/6cf/5e42516cfd0f45da9fbdb39a35b05994.png" alt="image"></p><br><div class="spoiler">  <b class="spoiler_title">A bit of terminology</b> <div class="spoiler_text"><p>  By the way, the input facts of the neuron are called synapses, and the output judgment is called an axon.  Connections with a positive weight are called excitatory, and those with a negative weight are called inhibitory.  If the weight is zero, then it is considered that there is no connection (dead connection). </p></div></div><br><p>  Let's go further.  Let's make a different assessment on these two facts: how good is it to work with (cooperate) with such a girl?  We will act in exactly the same way - add a wise neuron and adjust the weights in a comfortable way for us. </p><br><p>  But, judging a girl by two characteristics is very rude.  Let's judge her by three!  Add one more fact - money.  Which will vary from zero (absolutely poor) to one (Rockefeller's daughter).  Let's see how our opinions will change with the arrival of money ... </p><br><p>  For myself, I decided that, in terms of charm, money is not very important, but a smart look can still affect me, because I will make the weight of money small, but positive. </p><br><p>  In my work, I don't really care how much money a girl has, so I’ll make the weight zero. </p><br><p><img src="https://habrastorage.org/files/7bf/11a/b7b/7bf11ab7b53d4b67b0eb2e1f09f0f25f.png" alt="image"></p><br><p>  To evaluate a girl only for work and love is very stupid.  Let's add how pleasant it will be to travel with her: </p><br><ul><li>  Charisma in this problem is neutral (zero or low weight). </li><li>  Talk will help us (positive weight). </li><li>  When money ends up in real travels, the drive itself begins, so I’ll make the weight of the money slightly negative. </li></ul><br><p>  We combine all these three schemes into one and find that we have moved to a deeper level of judgment, namely, from charisma, money and talkativeness - to the admiration, cooperation and comfort of traveling together.  And note - these are also signals from zero to one.  So, now I can add the final “maximalist neuron”, and let it unambiguously answer the question “marry or not”? </p><br><p><img src="https://habrastorage.org/files/b64/d4c/138/b64d4c138872468bb77eb5b1d9badc1b.png" alt="image"></p><br><p>  Well, of course, not everything is so simple (in terms of women).  Bring some drama and reality into our simple and rainbow world.  First, let's make the neuron "marry - not marry" - wise.  Doubts are inherent in all, one way or another.  And yet - let's add a neuron “I want children from it” and, in order to be completely truthful, the neuron “stay away from it”. </p><br><p>  I do not understand anything in women, and therefore my primitive network now looks like a picture at the beginning of the article. </p><br><p>  Input judgments are called "input layer", the final - "output layer", and the one that is hidden in the middle, is called "hidden".  The hidden layer is my judgments, semi-finished products, thoughts that no one knows about.  There may be several hidden layers, and maybe none. </p><br><h2>  Down with maximalism. </h2><br><p>  Remember, I talked about the negative impact of money on my desire to travel with a person?  So - I was a goof.  For travel is best suited person, whose money is not small, and not much.  It's more interesting for me and I won't explain why. </p><br><p>  But here I am faced with a problem: </p><br><p>  If I put the weight of money negative, then the less money - the better for traveling. <br>  If positive, the richer the better <br>  If zero - then the money “poboku”. </p><br><p> It does not work out for me like this, with one weight, to make the neuron recognize the situation “not a lot — not a little”! </p><br><p>  To get around this, I will make two neurons - “a lot of money” and “little money”, and give them the input cash flow from our lady. </p><br><p>  Now I have two judgments: “many” and “little”.  If both conclusions are insignificant, then literally “neither more nor less” will turn out.  That is, add one more neuron to the output, with negative weights: </p><br><p><img src="https://habrastorage.org/files/2a9/053/272/2a9053272a4f493393213005bbca8892.png" alt="image"></p><br><p>  <em>"Naming".</em>  <em>Red arrows - positive connections, blue - negative</em> </p><br><p>  In general, this means that neurons are similar to the elements of the constructor.  Just as a processor is made from transistors, we can assemble a brain from neurons.  For example, the judgment “Either rich or smart” can be done like this: </p><br><p><img src="https://habrastorage.org/files/79a/e9b/426/79ae9b426f1c4fe2ac693ed90950556a.png" alt="image"></p><br><p>  <em>Or or.</em>  <em>Red arrows - positive connections, blue - negative</em> </p><br><p>  Or so: </p><br><p><img src="https://habrastorage.org/files/3f8/5d0/11a/3f85d011a0d94290b7ec8ad06a233df7.png" alt="image"></p><br><p>  <em>you can replace the “wise” neurons with “maximalists” and then we get the logical operator XOR.</em>  <em>The main thing - do not forget to set the thresholds of excitement.</em> </p><br><p>  Unlike transistors and the uncompromising logic of a typical “if-that” programmer, a neural network can make informed decisions.  Their results will smoothly change, with a smooth change in input parameters.  Here it is wisdom! </p><br><p>  I would like to draw your attention to the fact that adding a layer of two neurons allowed the neuron to “do nothing more or less” to make a more complex and balanced judgment, to move to a new level of logic.  From “many” or “little” - to a compromise solution, to a deeper, from a philosophical point of view, judgment.  And what if you add hidden layers yet?  We are able to reach that simple network with our minds, but what about a network that has 7 layers?  Are we able to understand the depth of its judgments?  And if in each of them, including the input, there are about a thousand neurons?  What do you think she is capable of? </p><br><p>  Imagine that I continued to complicate my example of marriage and falling in love, and came to such a network.  Somewhere in it all our nine neurons are hidden, and this is more like the truth.  With all the desire, to understand all the dependencies and the depth of judgments of such a network is simply impossible.  For me, the transition from the 3x3 network to 7x1000 is comparable to the realization of the scale, if not of the universe, then of the galaxy, relative to my height.  Simply put, I will not succeed.  The solution of such a network, the fire output of one of its neurons - will be inexplicable logic.  This is what in everyday life we ​​can call “intuition” (at least - “one of ..”).  Incomprehensible desire of the system or its hint. </p><br><p>  But, unlike our synthetic example 3x3, where each neuron of the hidden layer is quite clearly formalized, this is not necessarily the case in this network.  In a well-tuned network, whose size is not redundant to solve the problem, each neuron will detect some sign, but this absolutely does not mean that there will be a word or sentence in our language that can describe it.  If you project on a person, then this is some characteristic of him that you feel, but you cannot explain with words. </p><br><h2>  Training. </h2><br><p>  A few lines earlier, I mentioned a well-tuned network, which probably provoked the dumb question: “How can we set up a network consisting of several thousand neurons?  How many “man-years” and ruined lives do you need for this? .. I am afraid to suggest the answer to the last question.  Where better to automate such a configuration process is to make the network configure itself.  This process of automation is called learning.  And in order to give a superficial idea of ​​him, I will return to the original metaphor of the “very important issue”: </p><br><p>  We appear in this world with a pure, innocent brain and a neural network that is absolutely not in tune with women.  It needs to be somehow properly set up, so that happiness and joy come to our house.  For this, we need some experience, and here there are several ways to extract it: </p><br><p>  1) Training with a teacher (for romantics).  Watch a lot of Hollywood melodramas and read tearful novels.  Or look at their parents and / or friends.  After that, depending on the sample, go to check the knowledge gained.  After an unsuccessful attempt - to repeat everything anew, starting with the novels. </p><br><p>  2) Teaching without a teacher (for desperate experimenters).  To try to marry a dozen other women by the “spear” method.  After each marriage, in bewilderment scratching a turnip.  Repeat until you realize that you are tired, and you “already know how it happens.” </p><br><p>  3) Education without a teacher, option 2 (the path of desperate optimists).  To hammer on everything, to do something in life, and one day find yourself married.  After that, reconfigure your network in accordance with the current reality, so that all arranged. </p><br><p>  Further, according to the logic, I have to paint all this in detail, but without mathematics it will be too philosophical.  Therefore I consider that I should stop at this.  Perhaps another time? </p><br><p>  All of the above is true for an artificial perceptron neural network.  The rest of the networks are similar to it in basic principles, but they have their own nuances. </p><br><p>  Good weights and excellent training samples!  Well, if you don’t need it, then tell someone else about it. </p><br><p>  P.S. </p><br><p>  The weights of my neural network are not configured, and I just can not understand to which resource this article should belong. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/369349/">https://habr.com/ru/post/369349/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../369337/index.html">The Google Knowledge Graph Search API will replace Freebase</a></li>
<li><a href="../369341/index.html">Physical laws in numbers - large quantities</a></li>
<li><a href="../369343/index.html">Scientists from Oxford proved: fish can learn to distinguish people's faces</a></li>
<li><a href="../369345/index.html">Brute force against passwords</a></li>
<li><a href="../369347/index.html">Gifts from board games</a></li>
<li><a href="../369351/index.html">"Thin World". Chapter 4</a></li>
<li><a href="../369353/index.html">How Yandex created the first device with Alice. Yandex.The station on the basis of technology IO</a></li>
<li><a href="../369355/index.html">SignAloud gloves: translation of gestures into words</a></li>
<li><a href="../369359/index.html">Spanish engineers have created an Exeskeleton for children suffering from muscular atrophy</a></li>
<li><a href="../369361/index.html">Detective with "Proton" or how computers save rockets</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>