<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Backups via bacula on Amazon S3</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As you know, all people are divided into two types: those who have not yet done backups, and those who are already doing them. For those who are just ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Backups via bacula on Amazon S3</h1><div class="post__text post__text-html js-mediator-article">  As you know, all people are divided into two types: those who have not yet done backups, and those who are already doing them.  For those who are just starting to make backups, the first question that usually arises is how to archive the data.  We will not consider simple options (manually cutting blanks, archiving entire directories to other servers) - they have very modest possibilities in indexing and searching archive files.  Instead, we turn to automatic backup systems, in particular bacula.  This article does not address the question of why bacula.  The main reasons are that it is distributed under a free license, is available for heaps of platforms and has great flexibility. <br><br>  The second question after choosing the backup system is the choice of where to store backups.  Bacula allows you to use streamers, CDs, write archives to FIFO devices and to regular files.  The streamer is convenient on corporate servers where there is a permanent physical to the hardware.  Storage of archives in files is suitable when the volume of archives does not exceed the amount of hard drives, plus for reliable storage it is advisable to make a RAID array with redundancy, or even several physical servers for backups, preferably in different rooms.  Otherwise, all this before the first fire.  Cut into blanks is a homemade version, the main disadvantage of which is the need to regularly stick in fresh discs.  We set up bacula for archiving data on Amazon S3. <br><a name="habracut"></a><br>  Amazon S3 is a file storage on the Amazon cloud that is very inexpensive and is suitable for archiving any servers that are constantly connected to the Internet.  It can be home computers, and office servers, and servers at data center sites. <br><br>  So, proceed to the setting.  Our farm archives office network and a small cluster in the data center. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  Director </h1> Bacula is arranged in such a way that the main server in it is played by the main server - Director.  Its function is to store information about the entire archiving system, start the necessary tasks on a schedule and log the results of their execution.  We install the bacula-director-mysql package (as it is called in Debian) on the office network server. <br><br>  Bacula has excellent configuration documentation.  I will focus only on the key settings.  The Catalog section contains the address of the MySQL server where the archive index, database name, name and password will be stored.  In the Messages section, we write the administrator's e-mail, where the reports on the results of the execution will fall: <br><br><pre> <code class="hljs pgsql">mailcommand = "/usr/lib/bacula/bsmtp -h smtp.example.com -f \"\(Bacula\) %r\" -s \"Bacula daemon message\" %r" mail = sysadmin@example.com = <span class="hljs-keyword"><span class="hljs-keyword">all</span></span>, !skipped</code> </pre> <br><h1>  Storage </h1>  Bacula has a distributed architecture.  The servers to which the storage media is connected to which the archives will be recorded are called Storage.  It is the Storage servers that will interact with Amazon S3.  In our system, we needed two Storage servers - one installed in the office, directly on the server from the Director (all data from the office computers will be backed up), the other on one of the servers in the data center (there will go data from other computers in the data center).  The point of separation is not to drive paid traffic between the data center and the office. <br><br>  By signing up for Amazon AWS and creating a bucket with the name you chose, you will have the following account details in your hands: bucket name, access_key and secret_key.  The next step is to use the s3fs module for fuse to mount our bucket directly into the server's file system.  s3fs is not part of the Debian distribution - it will need to be built manually.  For some reason, fresh versions did not work right away (there were some suspensions after deleting files, and you had to rewire the file system), but version 1.16 started working right away without a single problem.  Register in server load: <br><br><pre> <code class="hljs pgsql">s3fs your-bucket-<span class="hljs-type"><span class="hljs-type">name</span></span> /mnt/backup -o allow_other,retries=<span class="hljs-number"><span class="hljs-number">10</span></span>,connect_timeout=<span class="hljs-number"><span class="hljs-number">30</span></span>,readwrite_timeout=<span class="hljs-number"><span class="hljs-number">30</span></span></code> </pre> <br>  And create the file / etc / passwd-s3fs with S3 passwords: <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">access_key</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">:secret_key</span></span></code> </pre> <br>  After the file system is mounted, we will install the bacula-sd package and ask bacula to save the archive files in S3.  To do this, in the bacula-sd.conf configuration file, in the Storage section, specify the Name so that we can easily identify it, for example Name = companyname-office-sd, Maximum Concurrent Jobs = 1, so that there are no simultaneous calls to different files via S3 .  In the Director section, write the name of our Director server and some random password.  In the Storage section we describe the Device - the actual physical storage space for archives: <br><br><pre> <code class="hljs pgsql">Device { <span class="hljs-type"><span class="hljs-type">Name</span></span>=S3-companyname-office Media <span class="hljs-keyword"><span class="hljs-keyword">Type</span></span>=file ArchiveDevice=/mnt/backup/office Label Media=yes; Random <span class="hljs-keyword"><span class="hljs-keyword">Access</span></span>=yes; AutomaticMount=yes; RemovableMedia=<span class="hljs-keyword"><span class="hljs-keyword">no</span></span>; AlwaysOpen=<span class="hljs-keyword"><span class="hljs-keyword">no</span></span>; }</code> </pre> <br>  Now let's return to the Director server for a minute and in its config we will create a new Storage section: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">Storage</span></span> { <span class="hljs-type"><span class="hljs-type">Name</span></span> = S3-companyname-office Address = <span class="hljs-keyword"><span class="hljs-keyword">storage</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.name SDPort = <span class="hljs-number"><span class="hljs-number">9103</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Password</span></span> = "storage-server-password" Device = S3-companyname-office Media <span class="hljs-keyword"><span class="hljs-keyword">Type</span></span> = File Maximum Concurrent Jobs = <span class="hljs-number"><span class="hljs-number">1</span></span> }</code> </pre> <br>  Password we specify the same as in the Storage configuration in the Director section. <br><br><h1>  File daemon </h1>  File Daemon is the actual daemon installed on computers that need to be backed up.  The bacula-fd package is installed on all computers of the cluster, on office computers where there is valuable data, and its bacula-fd.conf config is configured.  In the Director section, we register the identifier of our Director server and invent a new random password.  This completes its configuration, and we return to the Director server again to register a new client. <br><br>  In the Director config we create a new section: <br><br><pre> <code class="hljs pgsql">Client { <span class="hljs-type"><span class="hljs-type">Name</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-type"><span class="hljs-type">name</span></span>-fd Address = this.<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.host.name FDPort = <span class="hljs-number"><span class="hljs-number">9102</span></span> Catalog = MyCatalog <span class="hljs-keyword"><span class="hljs-keyword">Password</span></span> = "file-server-password" Maximum Concurrent Jobs = <span class="hljs-number"><span class="hljs-number">1</span></span> AutoPrune = yes Job Retention = <span class="hljs-number"><span class="hljs-number">365</span></span> days }</code> </pre> <br>  Password is specified the same as in the File Daemon config in the Director section. <br><br>  An important parameter is Job Retention.  After this time, old data will be deleted from the archive index.  The longer this time, the longer your old archive files will not be overwritten, and the more money you will pay for Amazon S3.  The smaller, the cheaper the backups will cost you, but the depth of the backup will also be less.  In addition, make sure that you have full (Full) archiving more often than Job Retention, otherwise you will have moments when the old data has already been deleted, and the new ones have not yet been archived. <br><br><h1>  Free up space </h1>  Please note that the physical data is not erased from the archive, even if the links to them are deleted from the index after the Retention interval expires.  Removing from the index simply means that new ones can be written in place of old files.  At the same time, the disk space is not released, and you will not pay less, even if you clear the entire index.  Physically, files can either be deleted manually, making sure that they no longer have any links in the index, or install a fresh version of bacula, which automatically can truncate freed volumes.  In practice, this is rarely needed, and we do not use this opportunity. <br><br><h1>  Firewall setup </h1>  During operation, bacula requires three types of TCP connections - from Director to Storage on port 9103, from Director to File Daemon to port 9102 and from File Daemon to Storage to port 9103. In all these areas, firewalls should be open, and addresses that registered in the Address parameters on Storage and File Daemon, must be available in the specified directions.  In particular, if your Storage suddenly finds itself inside a local network, then Director and File Daemons that will be archived on it should also be inside the same network.  If for some reason you need to keep the Storage inside the network, then you need to configure the routing so that the corresponding port is forwarded inside the network. <br><br><h1>  S3fs features </h1>  When writing to any file, the s3fs reads the entire previous version of the file to the computer, all modifications occur in the local copy, and after the file is closed, it is completely downloaded back to S3.  This means that even backing up a few bytes to an archive file of 500 megabytes will result in the transfer of a gigabyte over the network.  Since traffic on Amazon S3 is charged, you should not forget about this feature of s3fs.  The size of the files should not be very large, so that the downloads and backfills are small.  We have 3 pools on each Storage-server - for Full backups (Maximum Volume Bytes = 500000000, Volume Retention = 12 months), for Diff-backups (Maximum Volume Bytes = 300000000, Volume Retention = 7 months) and for Incremental backups (Maximum Volume Bytes = 100000000, Volume Retention = 2 months).  Please note that in this example, differential backups should be done at least once every 2 months (we have 1 month), otherwise there will be times when incremental backups have already been deleted, but there is no fresh differential yet.  Similarly, full backups should be done at least once every 7 months (we have 6). <br><br>  In addition, since you need a place to store local copies, you need to always have it on the file system.  Where to add local copies is specified in the use_cache option when mounting s3fs.  The default is the root FS.  The more simultaneous files you have openly, the more space is required there.  Therefore, we limit both Maximum Concurrent Jobs on one Storage server (so that many files are not kept open) and Maximum Volume Bytes.  If the place suddenly ends, s3fs will freeze and wait for the space to be freed. <br><br><h1>  Issue price </h1>  Storage prices range from $ 0.037 per gigabyte per month (for large storage volumes with a reduced reliability of 99.99%) to $ 0.14 per gigabyte per month (for small storage volumes with a standard reliability of 99.999999999%).  We chose standard reliability and store about a terabyte of archives - it costs (along with the cost of traffic) at about $ 180 a month. <br><br><h1>  Security </h1>  Here is a small security checklist: <ul><li>  close read access for all to the bacula configs and to the file / etc / passwd-s3fs, since  passwords recorded there are extremely dangerous to disclose; </li><li>  restrict access to ports 9101, 9102 and 9103, except for the directions required for bacula operation; </li><li>  configure bacula to use TLS when transmitting data over public networks; </li><li>  close directories with archives from prying eyes; </li><li>  fuse encryption encrypt data that will get to Amazon S3; </li><li>  start different S3 buckets on different Storage servers so that if one archive is compromised, the hacker will not get access to the others; </li><li>  Regularly perform test recoveries to make sure you don‚Äôt forget to put something important in the archives. </li></ul><h1>  Links </h1><ul><li>  Bacula - <a href="http://www.bacula.org/">www.bacula.org</a> </li><li>  Amazon S3 - <a href="http://aws.amazon.com/s3/">aws.amazon.com/s3</a> </li><li>  s3fs - <a href="http://code.google.com/p/s3fs/wiki/FuseOverAmazon">code.google.com/p/s3fs/wiki/FuseOverAmazon</a> </li><li>  fuse encryption - <a href="http://prefetch.net/blog/index.php/2007/05/29/encrypting-data-with-the-fuse-encryption-module/">prefetch.net/blog/index.php/2007/05/29/encrypting-data-with-the-fuse-encryption-module</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/111555/">https://habr.com/ru/post/111555/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../111544/index.html">Development of digital devices based on VLSI programmable logic</a></li>
<li><a href="../111545/index.html">Adding the ability to sort by rating in the search</a></li>
<li><a href="../111548/index.html">SCEA certification - will we discuss?</a></li>
<li><a href="../111552/index.html">Transferring a valid corporate email from a hoster to Google</a></li>
<li><a href="../111554/index.html">Why Delphi "dies" or "programmer is not a reader, programmer is a writer"</a></li>
<li><a href="../111556/index.html">Cancel VAT for hosting and domain name registration services</a></li>
<li><a href="../111558/index.html">Overview of the information security market of Ukraine</a></li>
<li><a href="../111559/index.html">China has 850 million mobile subscribers</a></li>
<li><a href="../111560/index.html">About compatibility of Android applications on various devices</a></li>
<li><a href="../111561/index.html">Replenishment of Webmoney wallet from Beeline SIM card balance</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>