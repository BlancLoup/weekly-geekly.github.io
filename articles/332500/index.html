<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Core ML Testing and Review</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At WWDC'17, Apple introduced a new framework for working with machine learning technologies Core ML. Based on it, iOS implements Apple‚Äôs own products:...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Core ML Testing and Review</h1><div class="post__text post__text-html js-mediator-article"><p>  At WWDC'17, Apple introduced a new framework for working with machine learning technologies Core ML.  Based on it, iOS implements Apple‚Äôs own products: Siri, Camera and QuickType.  Core ML allows you to simplify the integration of machine learning into applications and create various ‚Äúsmart‚Äù functions using a couple of lines of code. </p><br><p><img src="https://habrastorage.org/web/29d/4ba/83e/29d4ba83e85842409b357398a2180b4a.png" alt="image"></p><a name="habracut"></a><br><h2 id="vozmozhnosti-core-ml">  Core ML features </h2><br><p>  Using Core ML in an application, you can implement the following functions: </p><br><ul><li>  image recognition in real time; </li><li>  predictive text input; </li><li>  pattern recognition; </li><li>  tonality analysis; </li><li>  handwriting recognition; </li><li>  search ranking; </li><li>  stylization of images; </li><li>  face recognition; </li><li>  voice identification; </li><li>  definition of music; </li><li>  text referencing; </li><li>  and not only. </li></ul><br><p>  Core ML makes it easy to import various machine learning algorithms into your application, such as: tree ensembles, SVMs, and generalized linear models.  It uses low-level technologies such as Metal, Accelerate and BNNS.  The results of the calculations occur almost instantly. </p><br><p><img src="https://habrastorage.org/web/951/8d1/e75/9518d1e752e840d39fd99dbf3720b737.png" alt="image"></p><br><h2 id="vision">  Vision </h2><br><p>  The Vision framework is based on Core ML and helps with tracking and recognizing faces, text, objects, barcodes.  Also available is the definition of the horizon and getting the matrix to align the image. </p><br><h2 id="nslinguistictagger">  NSLinguisticTagger </h2><br><p>  With iOS 5, Apple introduced NSLinguisticTagger, which allows you to analyze natural language, supports many languages ‚Äã‚Äãand alphabets.  With the release of iOS 11, the class has been improved, now you can feed the string with text in different languages ‚Äã‚Äãand it will return the dominant language in this string and many more other improvements.  NSLinguisticTagger also uses machine learning for a deep understanding of the text and its analysis. </p><br><h2 id="core-ml-model">  Core ML Model </h2><br><p>  Apple provided 4 models on the <a href="https://developer.apple.com/machine-learning/">Core ML</a> promo <a href="https://developer.apple.com/machine-learning/">page</a> .  All of them analyze images.  Core ML models work locally and are optimized to run on mobile devices, minimizing memory usage and power consumption. <br>  You can generate your own models using <a href="https://developer.apple.com/documentation/coreml/converting_trained_models_to_core_ml">Core ML Tools</a> . </p><br><p><img src="https://habrastorage.org/web/461/e25/3ba/461e253ba8f54cc1b156a231314ea53b.png" alt="image"></p><br><p>  Working way to load models at runtime: </p><br><ol><li>  Put the model file in the application target. </li><li>  Compile new model from .mlmodel to .mlmodelc, without changing its interface. </li><li>  Put these files on the server. </li><li>  Download them inside the app. </li><li>  Initialize a new model, for example: </li></ol><br><pre><code class="hljs swift"><span class="hljs-type"><span class="hljs-type">CoreMLModelClass</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">init</span></span>(contentOf: <span class="hljs-type"><span class="hljs-type">URL</span></span>)</code> </pre> <br><p>  Performance after the release of the application in the App Store has not been tested. </p><br><h2 id="osobennosti-core-ml">  Core ML Features </h2><br><ul><li>  Apple‚Äôs decision cannot take data and train models.  Only accept some types of trained models, convert them into a proprietary format and make predictions. </li><li>  The model does not shrink. </li><li>  It is not encrypted.  You will have to take care of data protection yourself. </li></ul><br><h2 id="testiruem-core-ml">  Testing Core ML </h2><br><p>  I prepared a test project using Core ML.  We will make a simple cat locator that will distinguish everything in this universe from a cat. </p><br><p><img src="https://habrastorage.org/web/238/e49/363/238e493636eb4f0db5abdc955ae457ec.gif" alt="image"></p><br><p>  Create a project and select Single View Application.  First you need to download the Core ML model, which will analyze objects from the camera.  In this project I use Inception v3.  Next, you need to transfer the model to the Project Navigator, Xcode will automatically generate an interface for it. <br>  On a storyboard we add the whole View screen, there we will display the image from the camera.  Above we add the Visual Effect View and Label.  We throw outlets in ViewController. <br>  Do not forget to add permission to use the camera in plist. </p><br><p><img src="https://habrastorage.org/web/27b/e5a/22f/27be5a22f369492daff526f9b54dfd7b.jpg" alt="image"></p><br><p>  We need to display the image from the camera in real time, for this we will create AVCaptureSession and a queue for receiving new frames of DispatchQueue.  Add an AVCaptureVideoPreviewLayer layer to our View, it will display the image from the camera, you also need to create an array of VNRequest - these are requests to Vision.  Immediately in viewDidLoad check the availability of the camera. </p><br><pre> <code class="hljs objectivec">import <span class="hljs-built_in"><span class="hljs-built_in">UIKit</span></span> import <span class="hljs-built_in"><span class="hljs-built_in">AVFoundation</span></span> import Vision <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> ViewController: <span class="hljs-built_in"><span class="hljs-built_in">UIViewController</span></span> { @IBOutlet var resultLabel: <span class="hljs-built_in"><span class="hljs-built_in">UILabel</span></span>! @IBOutlet var resultView: <span class="hljs-built_in"><span class="hljs-built_in">UIView</span></span>! let session = <span class="hljs-built_in"><span class="hljs-built_in">AVCaptureSession</span></span>() var previewLayer: <span class="hljs-built_in"><span class="hljs-built_in">AVCaptureVideoPreviewLayer</span></span>! let captureQueue = DispatchQueue(label: <span class="hljs-string"><span class="hljs-string">"captureQueue"</span></span>) var visionRequests = [VNRequest]() override func viewDidLoad() { <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.viewDidLoad() guard let camera = <span class="hljs-built_in"><span class="hljs-built_in">AVCaptureDevice</span></span>.default(<span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: .video) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { previewLayer = <span class="hljs-built_in"><span class="hljs-built_in">AVCaptureVideoPreviewLayer</span></span>(session: session) resultView.layer.addSublayer(previewLayer) } catch { let alertController = <span class="hljs-built_in"><span class="hljs-built_in">UIAlertController</span></span>(title: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, message: error.localizedDescription, preferredStyle: .alert) alertController.addAction(<span class="hljs-built_in"><span class="hljs-built_in">UIAlertAction</span></span>(title: <span class="hljs-string"><span class="hljs-string">"Ok"</span></span>, style: .default, handler: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>)) present(alertController, animated: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, completion: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>) } } }</code> </pre> <br><p>  Next, configure cameraInput and cameraOutput, add them to the session and start it to get the data stream. </p><br><pre> <code class="hljs pgsql">let cameraInput = try AVCaptureDeviceInput(device: camera) let videoOutput = AVCaptureVideoDataOutput() videoOutput.setSampleBufferDelegate(self, queue: captureQueue) videoOutput.alwaysDiscardsLateVideoFrames = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span> videoOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> String: kCVPixelFormatType_32BGRA] <span class="hljs-keyword"><span class="hljs-keyword">session</span></span>.sessionPreset = .high <span class="hljs-keyword"><span class="hljs-keyword">session</span></span>.addInput(cameraInput) <span class="hljs-keyword"><span class="hljs-keyword">session</span></span>.addOutput(videoOutput) let <span class="hljs-keyword"><span class="hljs-keyword">connection</span></span> = videoOutput.<span class="hljs-keyword"><span class="hljs-keyword">connection</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">with</span></span>: .video) <span class="hljs-keyword"><span class="hljs-keyword">connection</span></span>?.videoOrientation = .portrait <span class="hljs-keyword"><span class="hljs-keyword">session</span></span>.startRunning()</code> </pre> <br><p>  Now we need to initialize the Core ML model for Vision and configure the query. </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> visionModel = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? <span class="hljs-type"><span class="hljs-type">VNCoreMLModel</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: <span class="hljs-type"><span class="hljs-type">Inceptionv3</span></span>().model) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">fatalError</span></span>(<span class="hljs-string"><span class="hljs-string">"Could not load model"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> classificationRequest = <span class="hljs-type"><span class="hljs-type">VNCoreMLRequest</span></span>(model: visionModel, completionHandler: handleClassifications) classificationRequest.imageCropAndScaleOption = <span class="hljs-type"><span class="hljs-type">VNImageCropAndScaleOptionCenterCrop</span></span> visionRequests = [classificationRequest]</code> </pre> <br><p>  Create a method that will process the results.  Taking into account the error, we take the 3 most probable according to the result model and look for the word cat among them. </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">handleClassifications</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(request: VNRequest, error: Error?)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> error = error { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(error.localizedDescription) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> results = request.results <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? [<span class="hljs-type"><span class="hljs-type">VNClassificationObservation</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(<span class="hljs-string"><span class="hljs-string">"No results"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> resultString = <span class="hljs-string"><span class="hljs-string">"  !"</span></span> results[<span class="hljs-number"><span class="hljs-number">0</span></span>...<span class="hljs-number"><span class="hljs-number">3</span></span>].forEach { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> identifer = $<span class="hljs-number"><span class="hljs-number">0</span></span>.identifier.lowercased() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> identifer.range(of: <span class="hljs-string"><span class="hljs-string">"cat"</span></span>) != <span class="hljs-literal"><span class="hljs-literal">nil</span></span> { resultString = <span class="hljs-string"><span class="hljs-string">" !"</span></span> } } <span class="hljs-type"><span class="hljs-type">DispatchQueue</span></span>.main.async { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.resultLabel.text = resultString } }</code> </pre> <br><p>  The last thing left for us to do is to add the AVCaptureVideoDataOutputSampleBufferDelegate delagate method, which is called for each new frame received from the camera.  In it, we configure the request and execute it. </p><br><pre> <code class="hljs swift"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extension</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ViewController</span></span></span><span class="hljs-class">: </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AVCaptureVideoDataOutputSampleBufferDelegate</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">captureOutput</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pixelBuffer = <span class="hljs-type"><span class="hljs-type">CMSampleBufferGetImageBuffer</span></span>(sampleBuffer) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> requestOptions: [<span class="hljs-type"><span class="hljs-type">VNImageOption</span></span>: <span class="hljs-type"><span class="hljs-type">Any</span></span>] = [:] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cameraIntrinsicData = <span class="hljs-type"><span class="hljs-type">CMGetAttachment</span></span>(sampleBuffer, kCMSampleBufferAttachmentKey_CameraIntrinsicMatrix, <span class="hljs-literal"><span class="hljs-literal">nil</span></span>) { requestOptions = [.cameraIntrinsics: cameraIntrinsicData] } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageRequestHandler = <span class="hljs-type"><span class="hljs-type">VNImageRequestHandler</span></span>(cvPixelBuffer: pixelBuffer, orientation: <span class="hljs-number"><span class="hljs-number">1</span></span>, options: requestOptions) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> imageRequestHandler.perform(visionRequests) } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(error) } } }</code> </pre> <br><p>  Done!  You have written an application that distinguishes cats from all other objects! </p><br><p>  ‚Üí <a href="https://github.com/DmitriyLis/CoreMLCatsDemo">Link</a> to repository. </p><br><h2 id="vyvody">  findings </h2><br><p>  Despite the features, Core ML will find its audience.  If you are not ready to put up with limitations and small features, there are many third-party frameworks.  For example, <a href="https://pjreddie.com/darknet/yolo/">YOLO</a> or <a href="https://github.com/Swift-AI/Swift-AI">Swift-AI</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/332500/">https://habr.com/ru/post/332500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../332488/index.html">New pack of Otus coding Owl stickers</a></li>
<li><a href="../332490/index.html">The main problem of CG in Russia and the first step towards its solution</a></li>
<li><a href="../332492/index.html">PHDays HackBattle: breaking one by one</a></li>
<li><a href="../332494/index.html">Postquantum reincarnation of the Diffie-Hellman algorithm: probable future (isogeny)</a></li>
<li><a href="../332496/index.html">Big Data at Raiffeisenbank</a></li>
<li><a href="../332502/index.html">Linux log files in order</a></li>
<li><a href="../332504/index.html">Who owns the data generated by devices from the Internet of things?</a></li>
<li><a href="../332506/index.html">How to confuse the analyst. Part Three Verbs and numerals</a></li>
<li><a href="../332508/index.html">Automata programming. Part 2. State and transition diagrams</a></li>
<li><a href="../332516/index.html">Generalized copying of connected object graphs in C # and nuances of their serialization</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>