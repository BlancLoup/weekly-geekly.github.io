<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to use the geodata analysis to predict the number of emergency calls in different parts of the city?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Try to solve the problem from the online hackathon Geohack.112 . Given: the territory of Moscow and the Moscow region was divided into squares of size...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to use the geodata analysis to predict the number of emergency calls in different parts of the city?</h1><div class="post__text post__text-html js-mediator-article">  Try to solve the problem from the online hackathon <a href="https://datasouls.com/c/mts-geohack/description">Geohack.112</a> .  Given: the territory of Moscow and the Moscow region was divided into squares of sizes from 500 to 500 meters.  The initial data is the average number of emergency calls per day (numbers 112, 101, 102, 103, 104, 010, 020, 030, 040).  The region under consideration was divided into western and eastern parts.  Participants are invited, having learned from the western part, to predict the number of emergency calls for all squares in the east. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/025/e43/fb1/025e43fb1fc6ea4cb4cb03aaf93d58bc.png" alt="image"><a name="habracut"></a><br><br>  The <b>zones.csv</b> table lists all the squares with their coordinates.  All squares are located in Moscow, or at a short distance from Moscow.  The squares located in the western part of the sample are designed to train the model ‚Äî the average number of emergency calls from a square per day is known for these squares: <br>  <b>calls_daily</b> : all days <br>  <b>calls_workday</b> : on workdays <br>  <b>calls_weekend</b> : on weekends <br>  <b>calls_wd {D}</b> : By the day of the week D (0 - Monday, 6 - Sunday) 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      On the squares from the eastern part of the sample, it is necessary to construct a forecast of the number of calls for all days of the week.  The quality assessment of the prediction will be made on a subset of squares, which does not include squares, from where calls are received extremely rarely.  A subset of target squares has is_target = 1 in the table.  For test squares, the values ‚Äã‚Äãcalls_ * and is_target are hidden. <br><br>  The map shows squares of three types: <br>  Green - from the training part, not targeted <br>  Red - from the training part, the target <br>  Blue - test, it is necessary to build a forecast for them <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a21/cf3/068/a21cf3068a5d9384311dead851a5bdc9.png" alt="image"><br><br>  As a solution, it is necessary to provide a CSV table with predictions for all test squares, for each square - for all days of the week. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3dc/ba6/a95/3dcba6a95e88f28cebd2d9d57cc8b897.png" alt="image"><br><br>  Quality is evaluated only by a subset of target squares.  The participants do not know which of the squares are target, however, the principle of choosing target squares in the training and test parts is identical.  During the competition, the quality is estimated at 30% of the test target squares (chosen randomly), at the end of the competition the results are summed up on the remaining 70% of the squares. <br><br>  The prediction quality metric, <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient">Kendall's Tau-b</a> rank correlation coefficient, is calculated as the proportion of pairs of objects with incorrectly ordered predictions corrected for pairs with the same value of the target variable.  The metric estimates the order in which the predictions relate to each other, rather than their exact values.  Different days of the week are considered independent elements of the sample, i.e.  the correlation coefficient is calculated according to the predictions for all test pairs (zone_id, day of the week). <br><br><div class="spoiler">  <b class="spoiler_title">Reading a table of squares with Pandas</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas df_zones = pandas.read_csv(<span class="hljs-string"><span class="hljs-string">'data/zones.csv'</span></span>, index_col=<span class="hljs-string"><span class="hljs-string">'zone_id'</span></span>) df_zones.head()</code> </pre> <br></div></div><br><br><h3>  Extracting features from OpenStreetMap </h3><br>  Predicting the number of calls can be done using machine learning methods.  To do this, each square needs to construct a vector with a feature description.  Having trained a model in the marked western part of Moscow, it can be used to predict the target variable in the eastern part. <br><br>  Under the terms of the competition, the data for solving the problem can be taken from any open source.  When it comes to describing a small area on a map, the first thing that comes to mind is OpenStreetMap, an open, non-commercial electronic map that is created by the hands of the community. <br><br>  An OSM card is a collection of <a href="https://wiki.openstreetmap.org/wiki/Elements">elements of</a> three types: <br>  Node: points on the map <br>  Way: roads, squares, given by a set of points <br>  Relation: links between elements, for example combining a multi-part road <br><br>  Elements may have a set of tags - key-value pairs.  Here is an example of a store that is listed on the map as an element of type Node: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfb/400/e7f/cfb400e7fffc3c5079afb941d23ea3d9.png" alt="image"><br><br>  The actual upload of OpenStreetMap data can be taken from the site <a href="http://gis-lab.info/projects/osm_dump/">GIS-Lab.info</a> .  Since we are interested in Moscow and its immediate environment, we‚Äôll upload the <a href="">RU-MOS.osm.pbf file</a> - part of OpenStreetMap from the corresponding region in the binary format <a href="https://pypi.python.org/pypi/osmread">osm.pbf</a> .  There is a simple osmread library for reading such files from Python. <br><br>  Before we start working, we consider from OSM all elements of the Node type from the area we need, which have tags (we will restrict the others and will not use them later). <br><br>  The organizers of the competition prepared a baseline, which is available <a href="https://github.com/datasouls/mts-geohack">here</a> .  All the code that follows is contained in this baseline. <br><br><div class="spoiler">  <b class="spoiler_title">Loading objects from OpenStreetMap</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> osmread <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook LAT_MIN, LAT_MAX = <span class="hljs-number"><span class="hljs-number">55.309397</span></span>, <span class="hljs-number"><span class="hljs-number">56.13526</span></span> LON_MIN, LON_MAX = <span class="hljs-number"><span class="hljs-number">36.770379</span></span>, <span class="hljs-number"><span class="hljs-number">38.19270</span></span> osm_file = osmread.parse_file(<span class="hljs-string"><span class="hljs-string">'osm/RU-MOS.osm.pbf'</span></span>) tagged_nodes = [ entry <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm_notebook(osm_file, total=<span class="hljs-number"><span class="hljs-number">18976998</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> isinstance(entry, osmread.Node) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(entry.tags) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (LAT_MIN &lt; entry.lat &lt; LAT_MAX) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> (LON_MIN &lt; entry.lon &lt; LON_MAX) ] <span class="hljs-comment"><span class="hljs-comment">#         with open('osm/tagged_nodes.pickle', 'wb') as fout: pickle.dump(tagged_nodes, fout, protocol=pickle.HIGHEST_PROTOCOL) #         with open('osm/tagged_nodes.pickle', 'rb') as fin: tagged_nodes = pickle.load(fin)</span></span></code> </pre> <br></div></div><br><br>  Working in Python, geodata can be quickly visualized on an interactive map using the <a href="https://github.com/python-visualization/folium">folium</a> library, which has <a href="http://leafletjs.com/">Leaflet.js</a> , the standard solution for displaying OpenStreetMap, under the hood. <br><br><div class="spoiler">  <b class="spoiler_title">An example of visualization with folium</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> folium fmap = folium.Map([<span class="hljs-number"><span class="hljs-number">55.753722</span></span>, <span class="hljs-number"><span class="hljs-number">37.620657</span></span>]) <span class="hljs-comment"><span class="hljs-comment">#  /  for node in tagged_nodes: if node.tags.get('railway') == 'station': folium.CircleMarker([node.lat, node.lon], radius=3).add_to(fmap) #       calls_thresh = df_zones.calls_daily.quantile(.99) for _, row in df_zones.query('calls_daily &gt; @calls_thresh').iterrows(): folium.features.RectangleMarker( bounds=((row.lat_bl, row.lon_bl), (row.lat_tr, row.lon_tr)), fill_color='red', ).add_to(fmap) #        fmap.save('map_demo.html')</span></span></code> </pre> <br></div></div><br><br>  We aggregate the resulting set of points by squares and construct simple signs: <br><br>  1. Distance from the center of the square to the Kremlin <br>  2. The number of points in the radius R from the center of the square (for different values ‚Äã‚Äãof R) <br>  a.  all points tagged <br>  b.  railway stations <br>  c.  of stores <br>  d.  public transport stops <br>  3. The maximum and average distance from the center of the square to the nearest points of the above species. <br><br>  To quickly find points in proximity to the center of the square, we will use <a href="https://en.wikipedia.org/wiki/K-d_tree">the kd tree data structure</a> implemented in the SciKit-Learn package in the NearestNeighbors class. <br><br><div class="spoiler">  <b class="spoiler_title">Building a table with a characteristic description of the squares</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NearestNeighbors kremlin_lat, kremlin_lon = <span class="hljs-number"><span class="hljs-number">55.753722</span></span>, <span class="hljs-number"><span class="hljs-number">37.620657</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dist_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(lat1, lon1, lat2, lon2)</span></span></span><span class="hljs-function">:</span></span> R = <span class="hljs-number"><span class="hljs-number">6373.0</span></span> lat1 = math.radians(lat1) lon1 = math.radians(lon1) lat2 = math.radians(lat2) lon2 = math.radians(lon2) dlon = lon2 - lon1 dlat = lat2 - lat1 a = math.sin(dlat / <span class="hljs-number"><span class="hljs-number">2</span></span>)**<span class="hljs-number"><span class="hljs-number">2</span></span> + math.cos(lat1) * math.cos(lat2) * \ math.sin(dlon / <span class="hljs-number"><span class="hljs-number">2</span></span>)**<span class="hljs-number"><span class="hljs-number">2</span></span> c = <span class="hljs-number"><span class="hljs-number">2</span></span> * math.atan2(math.sqrt(a), math.sqrt(<span class="hljs-number"><span class="hljs-number">1</span></span> - a)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> R * c df_features = collections.OrderedDict([]) df_features[<span class="hljs-string"><span class="hljs-string">'distance_to_kremlin'</span></span>] = df_zones.apply( <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> row: dist_calc(row.lat_c, row.lon_c, kremlin_lat, kremlin_lon), axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment">#   ,      POINT_FEATURE_FILTERS = [ ('tagged', lambda node: len(node.tags) &gt; 0), ('railway', lambda node: node.tags.get('railway') == 'station'), ('shop', lambda node: 'shop' in node.tags), ('public_transport', lambda node: 'public_transport' in node.tags), ] #      X_zone_centers = df_zones[['lat_c', 'lon_c']].as_matrix() for prefix, point_filter in POINT_FEATURE_FILTERS: #        coords = np.array([ [node.lat, node.lon] for node in tagged_nodes if point_filter(node) ]) #        neighbors = NearestNeighbors().fit(coords) #   "    R   " for radius in [0.001, 0.003, 0.005, 0.007, 0.01]: dists, inds = neighbors.radius_neighbors(X=X_zone_centers, radius=radius) df_features['{}_points_in_{}'.format(prefix, radius)] = \ np.array([len(x) for x in inds]) #   "   K " for n_neighbors in [3, 5, 10]: dists, inds = neighbors.kneighbors(X=X_zone_centers, n_neighbors=n_neighbors) df_features['{}_mean_dist_k_{}'.format(prefix, n_neighbors)] = \ dists.mean(axis=1) df_features['{}_max_dist_k_{}'.format(prefix, n_neighbors)] = \ dists.max(axis=1) df_features['{}_std_dist_k_{}'.format(prefix, n_neighbors)] = \ dists.std(axis=1) #   "   " df_features['{}_min'.format(prefix)] = dists.min(axis=1) #       features.csv df_features = pandas.DataFrame(df_features, index=df_zones.index) df_features.to_csv('data/features.csv') df_features.head()</span></span></code> </pre> <br></div></div><br><br>  As a result, for each square from the training and test sample, we have a trait description that can be used for prediction.  A small modification of the proposed code can be taken into account in the signs of objects of other types.  Participants can add their features, thereby giving the model more information about urban development. <br><br>  <b>Call number prediction</b> <br><br>  Experienced data analytics participants know that in order to get a high place, it is important not only to look at a public leaderboard, but also to do your own validation on a training set.  We make a simple division of the training part of the sample into subsamples for training and validation in the ratio of 70/30. <br><br>  Take only target squares and train a random forest model (RandomForestRegressor) to predict the average number of calls per day. <br><br><div class="spoiler">  <b class="spoiler_title">Isolation of the validation subsample and learning by RandomForest</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestRegressor df_zones_train = df_zones.query(<span class="hljs-string"><span class="hljs-string">'is_test == 0 &amp; is_target == 1'</span></span>) idx_train, idx_valid = train_test_split(df_zones_train.index, test_size=<span class="hljs-number"><span class="hljs-number">0.3</span></span>) X_train = df_features.loc[idx_train, :] y_train = df_zones.loc[idx_train, <span class="hljs-string"><span class="hljs-string">'calls_daily'</span></span>] model = RandomForestRegressor(n_estimators=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">4</span></span>) model.fit(X_train, y_train)</code> </pre> <br></div></div><br><br>  Let us evaluate the quality on the validation subsample, for all days of the week we construct the same prediction.  The quality metric is a non-parametric correlation coefficient of Kendall tau-b, it is implemented in the <a href="https://www.scipy.org/">SciPy</a> package as a function of scipy.stats.kendalltau. <br><br>  It turns out Validation score: 0.656881482683 <br>  This is not bad, because  a metric value of 0 means no correlation, and 1 means a complete monotonic correspondence between real values ‚Äã‚Äãand predicted ones. <br><br><div class="spoiler">  <b class="spoiler_title">Forecast and quality assessment on validation</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.stats <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> kendalltau X_valid = df_features.loc[idx_valid, :] y_valid = df_zones.loc[idx_valid, <span class="hljs-string"><span class="hljs-string">'calls_daily'</span></span>] y_pred = model.predict(X_valid) target_columns = [<span class="hljs-string"><span class="hljs-string">'calls_wd{}'</span></span>.format(d) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> d <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">7</span></span>)] df_valid_target = df_zones.loc[idx_valid, target_columns] df_valid_predictions = pandas.DataFrame(collections.OrderedDict([ (column_name, y_pred) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> column_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> target_columns ]), index=idx_valid) df_comparison = pandas.DataFrame({ <span class="hljs-string"><span class="hljs-string">'target'</span></span>: df_valid_target.unstack(), <span class="hljs-string"><span class="hljs-string">'prediction'</span></span>: df_valid_predictions.unstack(), }) valid_score = kendalltau(df_comparison[<span class="hljs-string"><span class="hljs-string">'target'</span></span>], df_comparison[<span class="hljs-string"><span class="hljs-string">'prediction'</span></span>]).correlation print(<span class="hljs-string"><span class="hljs-string">'Validation score:'</span></span>, valid_score)</code> </pre> <br></div></div><br><br>  Before joining the ranks of participants who receive an invitation to Data Fest, there remains one small step: to build a table with predictions on all test squares and send them to the system. <br><br><div class="spoiler">  <b class="spoiler_title">Building predictions on the test</b> <div class="spoiler_text"><pre> <code class="python hljs">idx_test = df_zones.query(<span class="hljs-string"><span class="hljs-string">'is_test == 1'</span></span>).index X_test = df_features.loc[idx_test, :] y_pred = model.predict(X_test) df_test_predictions = pandas.DataFrame(collections.OrderedDict([ (column_name, y_pred) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> column_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> target_columns ]), index=idx_test) df_test_predictions.to_csv(<span class="hljs-string"><span class="hljs-string">'data/sample_submission.csv'</span></span>) df_test_predictions.head()</code> </pre> <br></div></div><br><br>  <b>Why analyze geodata?</b> <br><br>  The main sources of data, not only spatial (geographic), but also temporal, for any telecom company are the complexes of equipment for receiving and transmitting a signal located throughout the countries of the service - Base Stations (BS).  Spatial analysis of data is more difficult technically, but it can bring significant benefits and get signs that add a significant contribution to the effectiveness of machine learning models. <br><br>  At MTS, using geographic data helps expand the knowledge base.  They can be used to improve the quality of the service provided when analyzing subscribers' complaints about the quality of communication, improving the coverage of the communication signal, planning the development of the network and solving other problems where space-time communication is an important factor. <br><br>  Increasing, especially in large cities, population density, the rapid development of infrastructure and road network, satellite images and vector maps, the number of buildings and POIs (points of interest) from open area maps related to the provision of services - all these spatial data can be obtained from external sources.  Such data can be used as an additional source of information, as well as provide an objective picture, regardless of network coverage. <br><br>  Did you like the task?  Then we invite you to take part in the online hackathon on geohack.112 geographic data <a href="https://datasouls.com/c/mts-geohack/description">analysis</a> .  Register and upload your solutions to the <a href="https://datasouls.com/c/mts-geohack/">site</a> until April 24th.  The authors of the three best results will receive cash prizes.  Separate nominations are provided for participants who submitted the best public solution of the problem and the best visualization of data journalism.  The total prize fund of MTS GeoHack is <b>500,000 rubles</b> .  We hope to see new interesting approaches to the generation of spatial features, visualization of geodata and the use of new open sources of information. <br><br>  The winners will be awarded on April 28 at the <a href="http://datafest.ru/">DataFest</a> conference. <cut></cut></div><p>Source: <a href="https://habr.com/ru/post/353334/">https://habr.com/ru/post/353334/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../353320/index.html">Vulnerability found in Vesta CP hosting control panel</a></li>
<li><a href="../353322/index.html">Visualizing Process Connections in Linux</a></li>
<li><a href="../353324/index.html">How is information security operational management center (SOC-center) built today?</a></li>
<li><a href="../353328/index.html">How to use getDerivedStateFromProps in React 16.3 (py subtitles)</a></li>
<li><a href="../353332/index.html">Own validations of fields for Rules in one class</a></li>
<li><a href="../353336/index.html">5 Differences technical product manager from business-oriented PM</a></li>
<li><a href="../353338/index.html">Binary tree numbering</a></li>
<li><a href="../353340/index.html">How to create a startup empire without selling your freedom</a></li>
<li><a href="../353342/index.html">How I learn Agile practices and values</a></li>
<li><a href="../353344/index.html">And we count you. Universal labeling of goods is coming in Russia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>