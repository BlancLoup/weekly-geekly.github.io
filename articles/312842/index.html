<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>As a programmer, I bought a car. Part II</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the previous article, on the example of buying a Mercedes-Benz E-klasse not older than the 2010 release worth up to 1.5 million rubles in Moscow, t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>As a programmer, I bought a car. Part II</h1><div class="post__text post__text-html js-mediator-article">  In the <a href="https://habrahabr.ru/post/302788/">previous article,</a> on the example of buying a Mercedes-Benz E-klasse not older than the 2010 release worth up to 1.5 million rubles in Moscow, the task of finding profitable cars was considered.  Under the best you should understand the proposals, the price of which is below the market at the moment among the ads collected from all the most reputable sites for the sale of used cars in the Russian Federation. <br><br>  At the first stage, the multiple linear regression was chosen as the machine learning method, the legitimacy of its use, as well as the pros and cons were considered.  A simple linear regression was chosen as an evaluation algorithm.  Obviously, there are still many machine learning methods for solving the set regression problem.  In this article I would like to tell you exactly how I chose the most optimal machine learning algorithm for the studied model, which is currently used in the service I have implemented - <a href="http://robasta.ru/">robasta.ru</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/529/6da/61f/5296da61f3b64c0b90de0a79f8849e9a.jpg"></div><br><a name="habracut"></a><br><h2>  Algorithm selection </h2><br>  Applicants for the title of "champion": 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  <a href="https://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">Multiple linear (simple) regression</a> </li><li>  <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Lasso regression</a> </li><li>  <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%25A0%25D0%25B8%25D0%25B4%25D0%25B6-%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">Ridge regression</a> </li><li>  <a href="https://en.wikipedia.org/wiki/Robust_regression">Robust regression</a> </li><li>  <a href="https://en.wikipedia.org/wiki/Vowpal_Wabbit">Vowpal wabbit</a> </li><li>  <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">Polynomial</a> and <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%259D%25D0%25B5%25D0%25BB%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">nonlinear</a> regression </li><li>  <a href="https://ru.wikipedia.org/wiki/Random_forest">Random forest</a> </li><li>  <a href="http://xgboost.readthedocs.io/en/latest/model.html">Xgboost</a> </li></ul><br>  Before making a choice, all the above algorithms were investigated, so I wanted to tell you in detail about each of them.  However, this way of searching ‚Äúhead on‚Äù is not quite optimal, it is wiser to first conduct additional research on the task. <br><br>  In addition to the Mercedes-Benz E-klasse, I was impressed by the Audi A5, especially with a 239 hp diesel engine, which has good dynamics (6 seconds to 100 km / h) and a reasonable tax.  Looking at the dependence of prices on the engine power of this creation of German engineers (visualization below), many questions disappear by themselves. <br><img src="https://habrastorage.org/files/619/85f/06d/61985f06d94942b99275c0f133c048d2.jpg"><br>  There can be no talk of linear dependence here, so the algorithms based on the linear dependence of the explained variable (cost, in our case) on the regressors can be safely discarded.  The use of polynomial and non-linear models is illegal for the reason that the type of dependence of one or another regressor on the price for each individual car model is unknown in advance. <br><br>  Thus, taking the above considerations into account, we can only consider algorithms based on <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B5%25D1%2580%25D0%25B5%25D0%25B2%25D0%25BE_%25D0%25BF%25D1%2580%25D0%25B8%25D0%25BD%25D1%258F%25D1%2582%25D0%25B8%25D1%258F_%25D1%2580%25D0%25B5%25D1%2588%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B9">decision trees</a> - <a href="https://en.wikipedia.org/wiki/Random_forest">Random forest</a> and <a href="http://xgboost.readthedocs.io/en/latest/model.html">Xgboost</a> (with two types of boosting - xgbDart, xgbTree), and choose the optimal one. <br><br>  It should be noted that the optimal algorithm is the one that will show itself best (min <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">RMSE</a> ) for <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a> and delayed selection. <br>  Before proceeding to the ‚Äúblind‚Äù application of the selected algorithms, in the next chapter I would like to highlight in more detail the question of their settings. <br><br><h2>  Cross-validation </h2><br>  Cross-validation (V) is often used to evaluate the real capabilities of the model and adjust its parameters in machine learning tasks.  There is a set of partitions of the initial sample into the training and control subsamples.  For each of the breaks, the algorithm is adjusted by the training subsample, then its control error is estimated at the control. <br><br>  The estimate of the cross-check is the average over all partitions of the error on the control subsamples. <br><br>  For an <a href="https://ru.wikipedia.org/wiki/%25D0%259D%25D0%25B5%25D1%2581%25D0%25BC%25D0%25B5%25D1%2589%25D1%2591%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BE%25D1%2586%25D0%25B5%25D0%25BD%25D0%25BA%25D0%25B0">unbiased estimate of the</a> probability of error obtained through cross-validation, it is necessary that the training and control samples form a non-intersecting subset, in order to avoid the phenomenon of <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B5%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2583%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">overtraining</a> . <br><br>  Cross-check variations: <br><br><ol><li>  k-block cross-validation (k-fold cross-validation). <br><br><div class="spoiler">  <b class="spoiler_title">Read more</b> <div class="spoiler_text">  This method randomly splits data into k non-overlapping blocks of approximately the same size.  Alternately, each block is treated as a validation sample, and the remaining k-1 blocks are treated as a training sample.  The model is trained in k-1 blocks and predicts a validation block.  The model's forecast is estimated using the selected indicator: accuracy (accuracy), standard deviation (RMSE), etc.  The process is repeated k times, and we get k estimates for which the average value is calculated, which is the final estimate of the model.  Usually k is chosen equal to 10, sometimes 5. If k is equal to the number of elements in the original data set, this method is called cross-validation on individual elements (this article is not considered). <br></div></div><br></li><li>  Multiple k-block cross-validation (repeated k-fold cross-validation). <br><br><div class="spoiler">  <b class="spoiler_title">Read more</b> <div class="spoiler_text">  In this method, k-block cross-validation is performed several times.  For example, a 5-fold 10-block cross-validation will give 50 estimates, on the basis of which the average estimate will then be calculated.  Note that this is not the same as 50-block cross-validation. <br></div></div><br></li><li>  Monte-Carlo-based cross validation (PEC, Monte Carlo cross-validation, leave-group-out cross-validation). <br><br><div class="spoiler">  <b class="spoiler_title">Read more</b> <div class="spoiler_text">  This method randomly splits the initial data set into a training and validation sample in a given proportion in a specified number of times. <br></div></div></li></ol><br>  Each of the above cross-validation methods can be characterized using bias and variance.  The offset characterizes the accuracy of the estimate.  Dispersion characterizes the accuracy (precision) assessment. <br><br>  In general, the offset of the cross-validation method depends on the size of the validation sample.  If the size of the validation sample is 50% of the source data (2-block cross-validation), the final estimate of the standard deviation will be more biased than in the case when this size is 10% of the source data.  On the other hand, a smaller size of the validation sample increases the variance, since each validation sample contains less data to obtain a stable MSE value. <br><br>  Thus, when it comes to k-block cross-validation, then to minimize displacement, choose the maximum k, and to reduce variance, use the multiple k-block method that does this task better than once. <br><br>  As for the MCMB, for this type of cross-validation, the size of the validation sample has a slightly larger effect on the variance than the number of repetitions of the process.  It should also be noted that the number of repetitions of the process does not have a significant effect on the displacement. <br><br>  Thus, for the MCMC method, it is recommended to use a validation sample of small size (for example, 10%) and perform a large number of repetitions to reduce the variance. <br><br>  However, other things being equal, the use of multiple 10-block HF provides less variance, which is primarily due to the fact that, for this method, the same data element cannot be found in different samples, unlike the MCMB. <br><br>  At the end of our reasoning, I would like to make a reservation that with large amounts of data a 10-block or even 5-block single KV gives quite acceptable results, in our task, we will use a multiple 10-block cross-check to adjust the model. <br><br><h2>  Random forest </h2><br>  <a href="https://ru.wikipedia.org/wiki/Random_forest">‚ÄúRandom Forest‚Äù</a> is an algorithm that randomly creates a set <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B5%25D1%2580%25D0%25B5%25D0%25B2%25D0%25BE_%25D0%25BF%25D1%2580%25D0%25B8%25D0%25BD%25D1%258F%25D1%2582%25D0%25B8%25D1%258F_%25D1%2580%25D0%25B5%25D1%2588%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B9">of decision trees</a> for the received data and then averages the results of their predictions.  The tree building algorithm is very fast, so it‚Äôs not hard to make as many trees as you need. <br><br>  From a practical point of view, the method described above has one huge advantage: it almost does not require configuration.  If we take any other machine learning algorithm, be it a regression or a neural network, they all have a lot of parameters, and we should be able to choose them for a specific task.  RF, in fact, has only one important parameter that requires adjustment - mtry (the size of a random subset selected at each step of building the tree).  However, even using the default value, you can get very acceptable results. <br><br>  As in the <a href="https://habrahabr.ru/post/302788/">previous article</a> , we replace the missing values ‚Äã‚Äã(N / A) with the median values ‚Äã‚Äãfor all regressors, exclude the engine size from the sample (due to the strong correlation of the parameter with the power) and look at the capabilities of this algorithm. <br><br><pre><code class="hljs swift">dat &lt;- read.csv(<span class="hljs-string"><span class="hljs-string">"dataset.txt"</span></span>) #    <span class="hljs-type"><span class="hljs-type">R</span></span> dat$mileage[<span class="hljs-keyword"><span class="hljs-keyword">is</span></span>.na(dat$mileage)] &lt;- median(na.omit(dat$mileage)) #  <span class="hljs-type"><span class="hljs-type">NA</span></span>    dat &lt;- dat[-<span class="hljs-built_in"><span class="hljs-built_in">c</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">11</span></span>)] #         <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>.seed(<span class="hljs-number"><span class="hljs-number">1</span></span>) #     ( ) <span class="hljs-built_in"><span class="hljs-built_in">split</span></span> &lt;- runif(dim(dat)[<span class="hljs-number"><span class="hljs-number">1</span></span>]) &gt; <span class="hljs-number"><span class="hljs-number">0.2</span></span> #    train &lt;- dat[<span class="hljs-built_in"><span class="hljs-built_in">split</span></span>,] #      (cross-validation)  test &lt;- dat[!<span class="hljs-built_in"><span class="hljs-built_in">split</span></span>,] #  (hold-out) </code> </pre> <br>  For cross-validation, we will use the <a href="http://caret.r-forge.r-project.org/">caret</a> package, which is more capable of assessing the quality of the model than <a href="https://r-how.com/packages/randomForest/rfcv">rfcv</a> . <br><br><pre> <code class="hljs django"><span class="xml"><span class="xml">library(caret) #   caret fit.control </span><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">trainControl</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">method</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"repeatedcv"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">number</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">10,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">repeats</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">10)</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train.rf.model</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt;</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">price</span></span></span></span><span class="xml"><span class="hljs-tag">~</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">.</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">data</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">train,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">method</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"rf"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">trControl</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">fit.control</span></span></span></span><span class="xml"><span class="hljs-tag"> , </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">metric</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"RMSE"</span></span></span></span><span class="xml"><span class="hljs-tag">) #  </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">10-</span></span></span></span><span class="xml"><span class="hljs-tag">  </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">10-</span></span></span></span><span class="xml"><span class="hljs-tag">  </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag">    </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train.rf.model</span></span></span></span><span class="xml"><span class="hljs-tag"> #    </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"></span></span></span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Read more</b> <div class="spoiler_text">  Random forest <br><br>  292 samples <br>  15 predictor <br><br>  No pre-processing <br>  Resampling: Cross-Validated (10 fold, repeated 10 times) <br>  Summary of sample sizes: 262, 262, 262, 263, 263, 263, ... <br>  Resampling results across tuning parameters: <br><br>  mtry RMSE Rsquared <br>  2 134565.8 0.4318963 <br>  8 117451.8 0.4378768 <br>  15 122897.6 0.3956822 <br><br>  RMSE was used for the smallest value. <br>  The final value is used. <br></div></div><br><pre> <code class="hljs cs">library(randomForest) <span class="hljs-meta"><span class="hljs-meta">#   random forest train.rf.model &lt;- randomForest(price ~ ., train,mtry=8) #        - </span></span></code> </pre><br>  Let us construct a graph visually illustrating the importance of each of the predictors of the model. <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">varImpPlot</span></span>(<span class="hljs-selector-tag"><span class="hljs-selector-tag">train</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.rf</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.model</span></span>) #   </code> </pre> <br><img src="https://habrastorage.org/files/614/2e0/a74/6142e0a74dc2492e98a8d850c60e0e93.jpg"><br><br><pre> <code class="hljs pgsql">rf.model.predictions &lt;- predict(train.rf.model, test) #       print(sqrt(sum((<span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.vector(rf.model.predictions - test$price))^<span class="hljs-number"><span class="hljs-number">2</span></span>)/length(rf.model.predictions))) #     ( ) [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">121760.5</span></span></code> </pre> <br>  The obtained average error in estimating the cost of a car is equivalent to the same value obtained for linear regression.  Let me remind you that when building a linear model, unlike RF, we got rid of <a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D1%258B%25D0%25B1%25D1%2580%25D0%25BE%25D1%2581_%2528%25D1%2581%25D1%2582%25D0%25B0%25D1%2582%25D0%25B8%25D1%2581%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0%2529">emissions</a> , which led to additional inaccuracies in the estimates of the cost of cars.  Thus, it can be argued about the <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25B1%25D0%25B0%25D1%2581%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">robustness of the</a> ‚Äúrandom forest‚Äù to emissions. <br><br><h2>  Xgboost </h2><br>  The idea of <a href="https://en.wikipedia.org/wiki/Gradient_boosting">gradient boosting</a> is to build an ensemble of elementary models sequentially refining each other.  Each subsequent elementary model is trained on the ‚Äúmistakes‚Äù of the ensemble from the previous elementary models, the model responses are weightedly summed up. <br><br>  ‚ÄúBusch‚Äù can be used for almost any model ‚Äî general linear, generalized linear, decision trees, K-nearest neighbors, and many others. <br><br>  The features of the implementation of the algorithm of boosting in <a href="http://xgboost.readthedocs.io/en/latest/model.html">xgboost</a> can be attributed, firstly, the use of the second derivative of the loss function in addition to the first, which increases the efficiency of the algorithm.  Secondly, the presence of built-in <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D0%25B3%25D1%2583%25D0%25BB%25D1%258F%25D1%2580%25D0%25B8%25D0%25B7%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F_(%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B5%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0)">regularization</a> , which helps to fight <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B5%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2583%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">retraining</a> .  Finally, the ability to define custom loss functions and quality metrics. <br><br>  Thanks to the experimental parameter num_parallel_tree, you can set the number of trees that are simultaneously created and present <a href="https://ru.wikipedia.org/wiki/Random_forest">Random Forest</a> as a special case of a booster model with one iteration.  And if you use more than one iteration, you will get the boosting of ‚Äúrandom forests‚Äù, when each ‚Äúrandom forest‚Äù acts as an elementary model. <br><br>  In this article, we will consider only one type of boosting - xgbTree, since  xgbDart gives similar results. <br><br><pre> <code class="hljs django"><span class="xml"><span class="xml">fit.control </span><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">trainControl</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">method</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"repeatedcv"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">number</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">10,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">repeats</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">10)</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train.xgb.model</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt;</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">price</span></span></span></span><span class="xml"><span class="hljs-tag"> ~</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">.</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">data</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">train,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">method</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"xgbTree"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">trControl</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">fit.control,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">metric</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"RMSE"</span></span></span></span><span class="xml"><span class="hljs-tag">) #  </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">10-</span></span></span></span><span class="xml"><span class="hljs-tag">  </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">10-</span></span></span></span><span class="xml"><span class="hljs-tag">  </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train.xgb.model</span></span></span></span><span class="xml"><span class="hljs-tag"> #    </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"></span></span></span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Read more</b> <div class="spoiler_text">  eXtreme Gradient Boosting <br><br>  292 samples <br>  15 predictor <br><br>  No pre-processing <br>  Resampling: Cross-Validated (10 fold, repeated 10 times) <br>  Summary of sample sizes: 263, 262, 262, 263, 264, 263, ... <br>  Resampling results across tuning parameters: <br><br>  eta max_depth colsample_bytree nrounds RMSE Rsquared <br>  0.3 1 0.6 50 114131.1 0.4705512 <br>  0.3 1 0.6 100 113639.6 0.4745488 <br>  0.3 1 0.6 150 113821.3 0.4734121 <br>  0.3 1 0.8 50 114234.6 0.4694687 <br>  0.3 1 0.8 100 113960.5 0.4712563 <br>  0.3 1 0.8 150 114337.1 0.4685121 <br>  0.3 2 0.6 50 115364.6 0.4604643 <br>  0.3 2 0.6 100 117576.4 0.4472452 <br>  0.3 2 0.6 150 119443.6 0.4358365 <br>  0.3 2 0.8 50 116560.3 0.4494750 <br>  0.3 2 0.8 100 119054.2 0.4350078 <br>  0.3 2 0.8 150 121035.4 0.4222440 <br>  0.3 3 0.6 50 117883.2 0.4422659 <br>  0.3 3 0.6 100 121916.7 0.4162103 <br>  0.3 3 0.6 150 125206.7 0.3968248 <br>  0.3 3 0.8 50 119331.3 0.4296062 <br>  0.3 3 0.8 100 124385.7 0.3987044 <br>  0.3 3 0.8 150 128396.6 0.3753334 <br>  0.4 1 0.6 50 113771.6 0.4727520 <br>  0.4 1 0.6 100 113951.6 0.4717968 <br>  0.4 1 0.6 150 114135.0 0.4710503 <br>  0.4 1 0.8 50 114055.0 0.4700165 <br>  0.4 1 0.8 100 114345.5 0.4680938 <br>  0.4 1 0.8 150 114715.8 0.4655844 <br>  0.4 2 0.6 50 116982.1 0.4499777 <br>  0.4 2 0.6 100 119511.9 0.4347406 <br>  0.4 2 0.6 150 122337.9 0.4163611 <br>  0.4 2 0.8 50 118384.6 0.4379478 <br>  0.4 2 0.8 100 121302.6 0.4201654 <br>  0.4 2 0.8 150 124283.7 0.4015380 <br>  0.4 3 0.6 50 118843.2 0.4356722 <br>  0.4 3 0.6 100 124315.3 0.4017282 <br>  0.4 3 0.6 150 128263.0 0.3796033 <br>  0.4 3 0.8 50 122043.1 0.4135415 <br>  0.4 3 0.8 100 128164.0 0.3782641 <br>  0.4 3 0.8 150 132538.2 0.3567702 <br><br>  Tuning parameter 'gamma' was held constant at a value of 0 <br>  Tuning parameter 'min_child_weight' was held constant at a value of 1 <br>  RMSE was used for the smallest value. <br>  The final values ‚Äã‚Äãused for the model were nrounds = 100, max_depth = 1, eta = 0.3, gamma = 0, colsample_bytree = 0.6 and min_child_weight = 1. <br></div></div><br><pre> <code class="hljs django"><span class="xml"><span class="xml">library(xgboost) #   xgboost xgb_train </span><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">xgb.DMatrix</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">as.matrix</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train</span></span></span></span><span class="xml"><span class="hljs-tag">[</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-c</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">1</span></span></span></span><span class="xml"><span class="hljs-tag">)] ), </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">label</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">train$price)</span></span></span></span><span class="xml"><span class="hljs-tag"> #   </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">xgb_test</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt;</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">xgb.DMatrix</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">as.matrix</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">test</span></span></span></span><span class="xml"><span class="hljs-tag">[</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-c</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">1</span></span></span></span><span class="xml"><span class="hljs-tag">)]), </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">label</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">test$price)</span></span></span></span><span class="xml"><span class="hljs-tag"> #   </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">xgb.param</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt;</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">list</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">booster</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"gbtree"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">max.depth</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">1,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">eta</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">0.3,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">gamma</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">0,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">subsample</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">0.5,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">colsample_bytree</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">0.6,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">min_child_weight</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">1,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">eval_metric</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"rmse"</span></span></span></span><span class="xml"><span class="hljs-tag">) </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train.xgb.model</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt;</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">xgb.train</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">data</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">xgb_train,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">nrounds</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">100,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">params</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">xgb.param)</span></span></span></span><span class="xml"><span class="hljs-tag"> #        </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span></span></span></code> </pre><br>  We construct a graph demonstrating the importance of each of the predictors of the model. <br><br><pre> <code class="hljs 1c">importance.frame &lt;- xgb.importance(colnames(train[-c(<span class="hljs-number"><span class="hljs-number">1</span></span>)]), model = train.xgb.model) <span class="hljs-meta"><span class="hljs-meta">#    library(Ckmeans.1d.dp) #   </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword"></span></span></span><span class="hljs-meta"> xgb.plot xgb.plot.importance(importance.frame)</span></span></code> </pre><br><img src="https://habrastorage.org/files/a15/f2f/a5f/a15f2fa5f31142bc82effabbdcc5f656.jpg"><br><br><pre> <code class="hljs pgsql">xgb.model.predictions &lt;- predict(train.xgb.model, xgb_test) #       print(sqrt(sum((<span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.vector(xgb.model.predictions - test$price))^<span class="hljs-number"><span class="hljs-number">2</span></span>)/length(xgb.model.predictions))) #     ( ) [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">118742.8</span></span></code> </pre><br>  XGboost for this particular case showed slightly more accurate estimates of the value of cars.  It is a matter of concern for a large number of hyperparameters that require reconfiguration depending on the brand and model of car chosen.  In this regard, for use on the <a href="http://robasta.ru/">robasta.ru</a> service <a href="http://robasta.ru/">,</a> preference was given to the Random Forest algorithm. <br><br><h2>  Approbation of the selected algorithm </h2><br>  Now, when the choice of "champion" is over, it's time to look at him in action. <br><br><pre> <code class="hljs 1c">library(randomForest) <span class="hljs-meta"><span class="hljs-meta">#   random forest rf.model &lt;- randomForest(price ~ ., dat,mtry=8) #        -  predicted.price &lt;- predict(rf.model, dat) #   </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword"></span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword"></span></span></span><span class="hljs-meta">  real.price &lt;- dat$price #      </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword"></span></span></span><span class="hljs-meta">  profit &lt;- predicted.price - real.price #        </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword"></span></span></span><span class="hljs-meta"> </span></span></code> </pre><br>  As for the linear regression <a href="https://habrahabr.ru/post/302788/">in the previous article</a> , we construct a graph of the dependence of the benefits on the price. <br><br><pre> <code class="hljs lisp">plot(<span class="hljs-name"><span class="hljs-name">real</span></span>.price,profit) abline(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre><br><img src="https://habrastorage.org/files/b24/aa9/a84/b24aa9a84e5a4f8f9966ec499b3cc992.jpg"><br><br>  And now we will calculate the benefit as a percentage. <br><br><pre> <code class="hljs pgsql">sorted &lt;- sort(predicted.price /<span class="hljs-type"><span class="hljs-type">real</span></span>.price, decreasing = <span class="hljs-keyword"><span class="hljs-keyword">TRUE</span></span>) sorted[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span>] <span class="hljs-number"><span class="hljs-number">69</span></span> <span class="hljs-number"><span class="hljs-number">42</span></span> <span class="hljs-number"><span class="hljs-number">122</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span> <span class="hljs-number"><span class="hljs-number">168</span></span> <span class="hljs-number"><span class="hljs-number">248</span></span> <span class="hljs-number"><span class="hljs-number">346</span></span> <span class="hljs-number"><span class="hljs-number">109</span></span> <span class="hljs-number"><span class="hljs-number">231</span></span> <span class="hljs-number"><span class="hljs-number">244</span></span> <span class="hljs-number"><span class="hljs-number">1.412597</span></span> <span class="hljs-number"><span class="hljs-number">1.363876</span></span> <span class="hljs-number"><span class="hljs-number">1.354881</span></span> <span class="hljs-number"><span class="hljs-number">1.256323</span></span> <span class="hljs-number"><span class="hljs-number">1.185104</span></span> <span class="hljs-number"><span class="hljs-number">1.182895</span></span> <span class="hljs-number"><span class="hljs-number">1.168575</span></span> <span class="hljs-number"><span class="hljs-number">1.158208</span></span> <span class="hljs-number"><span class="hljs-number">1.157928</span></span> <span class="hljs-number"><span class="hljs-number">1.154557</span></span></code> </pre><br>  The results obtained are very weakly similar to the results obtained using linear regression, and look more plausible, despite the almost identical RMS for both models. <br><br>  To compare the results in this article, we used a sample from the <a href="https://habrahabr.ru/post/302788/">last publication</a> , so let's see how many lucrative offers of a <a href="http://robasta.ru/%3Fcity%3D%25D0%259C%25D0%25BE%25D1%2581%25D0%25BA%25D0%25B2%25D0%25B0%26model%3DMercedes-Benz%2BE-klasse%26price_from%3D%26price_to%3D1500000%26power_from%3D%26power_to%3D%26year_from%3D2010%26year_to%3D2016%26volume_from%3D0.0%26volume_to%3D100500.0%26km_from%3D0%26km_to%3D100500%26lm%3D0%26state%3D2%26seller%3D1%26engine%3D0%26transmission%3D0%26drive%3D0%26body%3D0%26hasphoto%3D0%26new%3D0">Mercedes-Benz E-klasse are not older than the 2010 release, worth up to 1.5 million rubles in Moscow</a> on the market now. <br><br><img src="https://habrastorage.org/files/466/407/f72/466407f725fe4bfa9385d3c37cf0180f.jpg"><br><br>  Summarizing all the above, I can say with confidence that for the selection of used cars we got a powerful tool that is not sensitive to ‚Äúfake‚Äù ads, working in real time.  You no longer need to sit for hours on several sites with advertisements for the sale of cars and drive to watch potentially unprofitable offers. <br><br>  But that's not all, now, using the considered mathematical apparatus, <a href="http://robasta.ru/ocenka-avtomobilya-online">Robasta</a> can help not only those who want to buy, but also those who want to sell their car. <br><br><h2>  Car sales </h2><br>  When selling your car, of course, you want to at least not be cheap and sell it in a short time.  For a quick and profitable sale of your car you need to understand the contribution of various characteristics in its value. <br><br>  To solve this problem, on the basis of the same ‚Äúrandom forest‚Äù, a <a href="http://robasta.ru/ocenka-avtomobilya-online">service</a> was developed <a href="http://robasta.ru/ocenka-avtomobilya-online">to evaluate the car</a> .  You fill in all the fields of the search form, in accordance with the parameters of your car, after which the model is trained on the basis of market offers at the moment.  If there are five or more ads on the market, the algorithm for the data you have filled out predicts the price and provides several interesting features depending on the overall picture of the market.  It is worth emphasizing that in order to achieve the greatest accuracy, only cars of the same generation as yours are selected for analysis.  The results of the evaluation of your car are generated in the form of a <a href="http://robasta.ru/estimate_auto_pdf/docs/example.pdf">pdf report</a> , the cost of which is 99 ‚ÇΩ. <br><br><img src="https://habrastorage.org/files/22c/010/d21/22c010d21f5c4245a5ae21b5cfc1b19b.jpg"><br><br><h2>  At last </h2><br>  Currently, various areas for further development are being worked out, among which the following can be called the main ones: <br><br>  Relatively new cars (mileage up to 100 thousand km) are often sold before large expensive MOT, these data are useful to take into account in the model.  Therefore, now I am in search of reliable partners among medium and large car dealers. <br><br>  The opening of an offline center for the selection and evaluation of cars in Moscow, which, thanks to the implemented algorithm, will be much less expensive than its competitors. <br><br>  Creating a convenient API for providing functionality to ‚Äúintellectual resellers‚Äù. <br><br>  Do you want something to help in the implementation of the tasks I voiced or to offer your ideas?  Write, I am always ready to consider any kind of cooperation. <br><br><h3>  Links </h3><br><ul><li>  <a href="http://robasta.ru/dataset.txt">dat</a> (MB E-klasse sample) </li><li>  <a href="http://robasta.ru/dat_a5.txt">dat_a5</a> (sampling Audi A5) </li></ul></div><p>Source: <a href="https://habr.com/ru/post/312842/">https://habr.com/ru/post/312842/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312830/index.html">Problem on std :: multiset or search by structure fields</a></li>
<li><a href="../312832/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ232 (October 10 - 16, 2016)</a></li>
<li><a href="../312834/index.html">Excel, SQL and the legendary barometer - we solve a simple problem in different ways</a></li>
<li><a href="../312838/index.html">MariaDB at Google Summer of Code: GSoC16 Results</a></li>
<li><a href="../312840/index.html">Horse my black</a></li>
<li><a href="../312844/index.html">Own BaaS c subject area modeling, scripts and more for half an hour</a></li>
<li><a href="../312848/index.html">26 ways to increase the delivery of your letters</a></li>
<li><a href="../312850/index.html">Increase employee productivity: how to optimize workflow using checklists</a></li>
<li><a href="../312852/index.html">The loud history of the Opera browser</a></li>
<li><a href="../312856/index.html">New Intel RealSense SDK 2016 R2 Features</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>