<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Shazam: music recognition algorithms, signatures, data processing</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="An almost forgotten song played in the restaurant. You listened to her in the distant past. How many touching memories can cause chords and words ... ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Shazam: music recognition algorithms, signatures, data processing</h1><div class="post__text post__text-html js-mediator-article">  An almost forgotten song played in the restaurant.  You listened to her in the distant past.  How many touching memories can cause chords and words ... You desperately want to listen to this song again, but its name completely disappeared from your head!  How to be?  Fortunately, in our fantastic high-tech world there is an answer to this question. <br><br>  You have a smartphone in your pocket, which has a program for recognizing music.  This program is your savior.  In order to find out the name of the song, you will not have to walk from corner to corner in an attempt to extract the cherished line from your own memory.  And after all not the fact that it will turn out.  The program, if you let it ‚Äúlisten‚Äù to the music, immediately reports the name of the composition.  After that, you can listen to the sweet heart sounds again and again.  Until they become one with you, or - until you get tired of all this. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5d0/5ba/c54/5d05bac54e71721b94322631b36e4237.jpg"></div><br>  <a href="http://www.toptal.com/mobile/context-aware-apps-and-complex-event-processing">Mobile technologies</a> and incredible progress in the field of sound processing give <a href="http://www.toptal.com/algorithms">algorithm developers the</a> ability to create music recognition applications.  One of the most popular solutions of this kind is called <a href="http://www.shazam.com/">Shazam</a> .  If you give it 20 seconds of sound, no matter whether it is a piece of an intro, chorus or part of the main motive, Shazam will create a signature code, check the database and use its own music recognition algorithm to give the name of the piece. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      How does all this work? <a name="habracut"></a><br>  The description of the basic <a href="http://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">Shazam algorithm</a> in 2003 was published by its creator, Avery Li-Chung Wang (Avery Li-Chung Wang).  In this article, we will examine in detail the basics of the Shazam music recognition algorithm. <br><br><h2>  <font color="#c75733">From analog to digital: discretization</font> </h2><br>  What is sound, really?  Maybe it is some mysterious bodiless substance that penetrates our ears and allows us to hear? <br><br>  Of course, everything is not so mysterious.  It has long been known that sound is <a href="http://en.wikipedia.org/wiki/Mechanical_wave">mechanical vibrations</a> that propagate in solid, liquid and gaseous media in the form of elastic waves.  When the wave reaches the ear, in particular - the eardrum, the auditory ossicles are set in motion, which transmit vibrations further to the hair cells located in the inner ear.  As a result, mechanical vibrations are converted into electrical impulses that are transmitted through the auditory nerves to the brain. <br><br>  Devices for recording sound imitate the above process quite accurately, converting the pressure of a sound wave into an electrical signal.  A sound wave in air is a <a href="http://en.wikipedia.org/wiki/Continuous_signal">continuous</a> signal, represented by areas of compression and rarefaction.  The microphone, the first electronic component with which the sound signal is encountered, converts it into an electrical signal, which is still continuous.  Such signals in the digital world are not particularly useful, therefore, before storage and processing in digital systems, they need to be converted to <a href="http://en.wikipedia.org/wiki/Discrete-time_signal">discrete</a> form.  This is done by sampling the values ‚Äã‚Äãrepresenting the amplitude values ‚Äã‚Äãof the signal. <br><br>  In the process of such a conversion, the analog signal is <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B2%25D0%25B0%25D0%25BD%25D1%2582%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_(%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B1%25D0%25BE%25D1%2582%25D0%25BA%25D0%25B0_%25D1%2581%25D0%25B8%25D0%25B3%25D0%25BD%25D0%25B0%25D0%25BB%25D0%25BE%25D0%25B2)">quantized</a> .  It does not do without a small number of errors.  Thus, we are not dealing with a single-step conversion; the <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BD%25D0%25B0%25D0%25BB%25D0%25BE%25D0%25B3%25D0%25BE-%25D1%2586%25D0%25B8%25D1%2584%25D1%2580%25D0%25BE%25D0%25B2%25D0%25BE%25D0%25B9_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D1%2582%25D0%25B5%25D0%25BB%25D1%258C">analog-to-digital converter</a> performs many operations on the conversion of very small parts of an analog signal into a digital one.  This process is called <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D0%25BA%25D1%2580%25D0%25B5%25D1%2582%25D0%25B8%25D0%25B7%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F">sampling</a> or sampling. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/065/8c1/0b4/0658c10b4eaed93d6bb95ad74a1d4416.jpg"></div><br>  <i><font color="#999999">Analog (continuous) and digital (discrete) signals</font></i> <br><br>  Thanks to the Kotelnikov theorem, we know what sampling frequency is needed in order to accurately represent a continuous signal limited by a certain frequency.  In particular, in order to capture the entire frequency spectrum of sounds accessible to human hearing, we must use a sampling frequency twice as high as the upper limit of frequencies heard by humans. <br><br>  Namely, a person can hear sounds in the range of approximately from 20 Hz to 20,000 Hz.  As a result, sound is most often recorded at a sampling rate of 44,100 Hz.  It is this sampling rate that is used in <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25BC%25D0%25BF%25D0%25B0%25D0%25BA%25D1%2582-%25D0%25B4%25D0%25B8%25D1%2581%25D0%25BA">compact discs</a> .  It is also most often used for audio coding in the <a href="https://ru.wikipedia.org/wiki/MPEG-1">MPEG-1</a> standard group ( <a href="https://ru.wikipedia.org/wiki/Video_CD">VCD</a> , <a href="https://ru.wikipedia.org/wiki/Super_Video_CD">SVCD</a> , <a href="https://ru.wikipedia.org/wiki/MP3">MP3</a> ). <br><br>  The widespread use of the sampling rate of 44,100 Hz, we are obliged, mainly, to Sony.  At one time, audio tracks encoded in this way were conveniently combined with video in <a href="https://ru.wikipedia.org/wiki/PAL">PAL</a> (25 frames per second) and <a href="https://ru.wikipedia.org/wiki/NTSC">NTSC</a> (30 frames per second) <a href="https://ru.wikipedia.org/wiki/NTSC">standards</a> , and working with them using existing equipment.  It is also very important that this frequency is sufficient for high-quality sound transmission in the range up to 20,000 Hz.  Digital audio equipment using this sampling rate is quite consistent in quality with the analog equipment of those times when digital audio standards were becoming established.  As a result, choosing the sampling rate for sound when recording, you will most likely stop at 44,100 Hz. <br><br><h2>  <font color="#c75733">Record: capture sound</font> </h2><br>  Recording a sampled audio signal is a fairly simple task.  Modern sound cards contain built-in analog-to-digital converters.  Therefore, it is enough to choose a programming language, find a suitable library for working with sound, specify the sampling frequency, the number of channels (usually one or two, for monophonic and stereo sound, respectively), select the number of bits in one sample (for example, 16 bits are often used) .  Then you need to open the data line from the sound card, just like any input stream opens, and write its contents to the byte array.  This is how Java does it: <br><br><pre><code class="hljs pgsql">private AudioFormat getFormat() { <span class="hljs-type"><span class="hljs-type">float</span></span> sampleRate = <span class="hljs-number"><span class="hljs-number">44100</span></span>; <span class="hljs-type"><span class="hljs-type">int</span></span> sampleSizeInBits = <span class="hljs-number"><span class="hljs-number">16</span></span>; <span class="hljs-type"><span class="hljs-type">int</span></span> channels = <span class="hljs-number"><span class="hljs-number">1</span></span>; //  <span class="hljs-type"><span class="hljs-type">boolean</span></span> signed = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; //   ,        <span class="hljs-type"><span class="hljs-type">boolean</span></span> bigEndian = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; //   ,     (big-endian)   (little-endian)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> AudioFormat(sampleRate, sampleSizeInBits, channels, signed, bigEndian); } final AudioFormat <span class="hljs-keyword"><span class="hljs-keyword">format</span></span> = getFormat(); //   AudioFormat  DataLine.<span class="hljs-keyword"><span class="hljs-keyword">Info</span></span> <span class="hljs-keyword"><span class="hljs-keyword">info</span></span> = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> DataLine.<span class="hljs-keyword"><span class="hljs-keyword">Info</span></span>(TargetDataLine.<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">format</span></span>); final TargetDataLine <span class="hljs-type"><span class="hljs-type">line</span></span> = (TargetDataLine) AudioSystem.getLine(<span class="hljs-keyword"><span class="hljs-keyword">info</span></span>); <span class="hljs-type"><span class="hljs-type">line</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">open</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">format</span></span>); <span class="hljs-type"><span class="hljs-type">line</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>();</code> </pre> <br>  Now it suffices to read the data from the object of the <code>TargetDataLine</code> class.  In the example, the flag is <code>running</code> , it is a global variable that can be accessed from another thread.  For example, such a variable will allow us to stop capturing sound from the user interface stream using the Stop button. <br><br><pre> <code class="hljs pgsql">OutputStream <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> ByteArrayOutputStream(); running = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; try { <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (running) { <span class="hljs-type"><span class="hljs-type">int</span></span> count = <span class="hljs-type"><span class="hljs-type">line</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(buffer, <span class="hljs-number"><span class="hljs-number">0</span></span>, buffer.length); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (count &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">out</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">write</span></span>(buffer, <span class="hljs-number"><span class="hljs-number">0</span></span>, count); } } <span class="hljs-keyword"><span class="hljs-keyword">out</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">close</span></span>(); } catch (IOException e) { <span class="hljs-keyword"><span class="hljs-keyword">System</span></span>.err.println("I/O problems: " + e); <span class="hljs-keyword"><span class="hljs-keyword">System</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">exit</span></span>(<span class="hljs-number"><span class="hljs-number">-1</span></span>); }</code> </pre> <br><h2>  <font color="#c75733">Time and frequency domains</font> </h2><br>  In our array recorded a digital representation of the audio signal in the <a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D1%2580%25D0%25B5%25D0%25BC%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BE%25D0%25B1%25D0%25BB%25D0%25B0%25D1%2581%25D1%2582%25D1%258C">time domain</a> .  That is, we have information about how the signal amplitude has changed over time. <br><br>  In the 19th century, Jean Baptiste Joseph Fourier made an outstanding discovery.  It consists in the fact that any signal in the time domain is equivalent to the sum of a certain number (possibly infinite) of simple sinusoidal signals, provided that each sinusoid has a certain frequency, amplitude and phase.  The set of sinusoids that form the original signal is called the <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D1%258F%25D0%25B4_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5">Fourier series</a> . <br><br>  In other words, one can imagine practically any signal developed in time simply by specifying a set of frequencies, amplitudes and phases corresponding to each of the sinusoids that form this signal.  Such a representation of signals is called a <a href="https://en.wikipedia.org/wiki/Frequency_domain">set of frequency intervals</a> .  In a sense, information about frequency intervals is something like ‚Äúfingerprints‚Äù or signal signatures deployed in time, giving us a static representation of dynamic data. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/993/334/229/99333422982ae9162684ef7cfc23e76f.png"></div><br>  <i><font color="#999999">Signals deployed in time and their frequency characteristics</font></i> <br><br>  This is what an animated Fourier Series representation for a 1 Hz <a href="https://en.wikipedia.org/wiki/Square_wave">square wave</a> looks like.  It also shows the approximation of the original signal based on a set of sinusoids.  In the upper graph, the signal is shown in the amplitude-time domain; in the lower graph, its representation is given in amplitude-frequency form. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0d3/8a5/8fc/0d38a58fcbab4d9470f305db3bfe992b.gif"></div><br>  <i><font color="#999999">Fourier transform in action.</font></i>  <i><font color="#999999">Source:</font> <a href="">Rene Schwarz</a></i> <br><br>  Analysis of the frequency characteristics of signals greatly facilitates the solution of many problems.  It is very convenient to operate with such characteristics in the field of digital signal processing.  They allow studying the spectrum of a signal (its frequency characteristics), determining which frequencies are present in this signal and which are not.  After that, you can filter, amplify or weaken some frequencies, or simply recognize the sound of a certain height among the available set of frequencies. <br><br><h2>  <font color="#c75733">Discrete Fourier Transform</font> </h2><br>  So, you need to find a way to get the frequency characteristics of signals deployed in time.  The <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D0%25BA%25D1%2580%25D0%25B5%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5">discrete Fourier transform</a> (DFT, DFT, Discrete Fourier Transform) will help us in this.  DFT is a mathematical method <a href="https://en.wikipedia.org/wiki/Fourier_analysis">of Fourier analysis</a> for discrete signals.  It can be used to convert a final set of signal samples taken at equal intervals of time into a list of coefficients of the final combination of complex sinusoids ordered by frequency, taking into account that these sinusoids were disarmed at the same frequency. <br><br>  One of the most popular numerical algorithms for calculating the DFT is called the <a href="https://ru.wikipedia.org/wiki/%25D0%2591%25D1%258B%25D1%2581%25D1%2582%25D1%2580%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5">Fast Fourier Transform</a> (FFT, FFT, Fast Fourier Transformation).  In fact, the FFT is represented by a whole set of algorithms.  Among them, the most commonly used variants of <a href="http://en.wikipedia.org/wiki/Cooley%25E2%2580%2593Tukey_FFT_algorithm">the Cooley-Tukey algorithm</a> (Cooley-Tukey).  The basis of this algorithm is the principle of "divide and conquer."  During calculations, the recursive decomposition of the original DFT into small parts is used.  Direct computation of the DFT for some data set <b>n</b> requires <b>O (n <sup>2</sup> )</b> operations, and the use of the Cooley-Tukey algorithm allows solving the same problem in <b>O (n log n)</b> operations. <br><br>  It is easy to find a suitable library that implements the FFT algorithm.  Here are a few such libraries for different languages: <br><br><ul><li>  C - <a href="http://www.fftw.org/">FFTW</a> </li><li>  C ++ - <a href="http://eigen.tuxfamily.org/index.php%3Ftitle%3DEigenFFT">EigenFFT</a> </li><li>  Java - <a href="https://sites.google.com/site/piotrwendykier/software/jtransforms">JTransform</a> </li><li>  Python - <a href="http://docs.scipy.org/doc/numpy/reference/routines.fft.html">NumPy</a> </li><li>  Ruby - <a href="https://apps.ubuntu.com/cat/applications/quantal/ruby-fftw3-dbg/">Ruby-FFTW3</a> (interface to FFTW) </li></ul><br>  Here is an example of a function for calculating an FFT written in Java.  At its entrance serves complex numbers.  In order to understand the relationship between complex numbers and trigonometric functions, it is useful to read about <a href="https://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25BE%25D1%2580%25D0%25BC%25D1%2583%25D0%25BB%25D0%25B0_%25D0%25AD%25D0%25B9%25D0%25BB%25D0%25B5%25D1%2580%25D0%25B0">the Euler formula</a> . <br><br><pre> <code class="hljs perl">public static Complex[] fft(Complex[] <span class="hljs-keyword"><span class="hljs-keyword">x</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> N = x.length; <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> fft   Complex[] even = new Complex[N / <span class="hljs-number"><span class="hljs-number">2</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt; N / <span class="hljs-number"><span class="hljs-number">2</span></span>; k++) { even[k] = <span class="hljs-keyword"><span class="hljs-keyword">x</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span> * k]; } Complex[] <span class="hljs-keyword"><span class="hljs-keyword">q</span></span> = fft(even); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> fft   Complex[] odd = even; <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>    <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt; N / <span class="hljs-number"><span class="hljs-number">2</span></span>; k++) { odd[k] = <span class="hljs-keyword"><span class="hljs-keyword">x</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span> * k + <span class="hljs-number"><span class="hljs-number">1</span></span>]; } Complex[] r = fft(odd); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>  Complex[] <span class="hljs-keyword"><span class="hljs-keyword">y</span></span> = new Complex[N]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt; N / <span class="hljs-number"><span class="hljs-number">2</span></span>; k++) { double kth = -<span class="hljs-number"><span class="hljs-number">2</span></span> * k * Math.PI / N; Complex wk = new Complex(Math.cos(kth), Math.sin(kth)); <span class="hljs-keyword"><span class="hljs-keyword">y</span></span>[k] = <span class="hljs-string"><span class="hljs-string">q[k]</span></span>.plus(wk.times(r[k])); <span class="hljs-keyword"><span class="hljs-keyword">y</span></span>[k + N / <span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-string"><span class="hljs-string">q[k]</span></span>.minus(wk.times(r[k])); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">y</span></span>; }</code> </pre> <br>  Here is an example of a signal before and after FFT analysis. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b61/224/3db/b612243db46883995dd2f598d38fbaa8.png"></div><br>  <i><font color="#999999">Signal before and after FFT analysis</font></i> <br><br><h2>  <font color="#c75733">Music Recognition: Song Signatures</font> </h2><br>  One of the unpleasant side effects of FFT is that after analyzing, we lose time information.  (Although, theoretically, this can be avoided, but in practice this will require enormous computational power.) For example, for a three-minute song we can see sound frequencies and their amplitudes, but we don‚Äôt know exactly where these frequencies are in the work.  And this is the most important characteristic that makes a piece of music what it is!  We need to somehow find out the exact time values ‚Äã‚Äãwhen each of the frequencies appears. <br><br>  That is why we will use something like a sliding window, or a data block, and transform only that part of the signal that gets into this ‚Äúwindow‚Äù.  The size of each block can be determined using different approaches.  For example, if we record two-channel sound with a sample size of 16 bits and a sampling frequency of 44100 Hz, one second of such sound will take 176 KB of memory (44100 samples * 2 bytes * 2 channels).  If we set the size of the sliding window to 4 KB, then every second we will need to analyze 44 data blocks.  This is a fairly high resolution for a detailed analysis of the composition. <br><br>  Let's go back to programming. <br><br><pre> <code class="hljs markdown">byte audio [<span class="hljs-string"></span><span class="hljs-string"></span>] = out.toByteArray() int totalSize = audio.length int sampledChunkSize = totalSize/chunkSize; Complex[<span class="hljs-string"></span><span class="hljs-string"></span>][<span class="hljs-symbol"></span><span class="hljs-symbol"></span>] result = ComplexMatrix[<span class="hljs-string"><span class="hljs-string">sampledChunkSize</span></span>][<span class="hljs-symbol"></span><span class="hljs-symbol"></span>]; for(int j = 0;i <span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">sampledChunkSize</span></span></span></span><span class="xml"><span class="hljs-tag">; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">j</span></span></span></span><span class="xml"><span class="hljs-tag">++) { </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">Complex</span></span></span></span><span class="xml"><span class="hljs-tag">[</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">chunkSize</span></span></span></span><span class="xml"><span class="hljs-tag">] </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">complexArray</span></span></span></span><span class="xml"><span class="hljs-tag">; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">for</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">int</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">i</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">0;</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">i</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">chunkSize</span></span></span></span><span class="xml"><span class="hljs-tag">; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">i</span></span></span></span><span class="xml"><span class="hljs-tag">++) { </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">complexArray</span></span></span></span><span class="xml"><span class="hljs-tag">[</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">i</span></span></span></span><span class="xml"><span class="hljs-tag">] = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">Complex(audio[(j*chunkSize)+i],</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">0</span></span></span></span><span class="xml"><span class="hljs-tag">); } </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">result</span></span></span></span><span class="xml"><span class="hljs-tag">[</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">j</span></span></span></span><span class="xml"><span class="hljs-tag">] = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">FFT.fft(complexArray);</span></span></span></span><span class="xml"><span class="hljs-tag"> }</span></span></span></span></code> </pre> <br>  In the internal loop, we put the data from the time domain (sound samples) into complex numbers with an imaginary part equal to 0. In the external loop we go through all the data blocks and run the FFT analysis for each of them. <br><br>  As soon as we have information about the frequency characteristics of the signal, you can proceed to the formation of a digital signature of a musical work.  This is the most important part of the entire music recognition process that Shazam implements.  The main difficulty here is to choose from the huge number of frequencies precisely those that are most important.  Purely intuitively, we draw attention to frequencies with maximum amplitudes (usually called peaks). <br><br>  However, in one song the range of ‚Äústrong‚Äù frequencies can vary, say, from the note ‚Äúto‚Äù the counter-instrument (32.70 Hz), to the note ‚Äúto‚Äù the fifth octave (4186.01 Hz).  This is a huge interval.  Therefore, instead of analyzing the entire frequency range immediately, we can select several smaller intervals.  The choice can be made based on the frequencies that are usually inherent in important musical components, and analyzed separately.  For example, you can use the intervals that <a href="http://www.royvanrijn.com/blog/2010/06/creating-shazam-in-java/">this programmer</a> used to implement his Shazam algorithm.  Namely, it is 30 Hz - 40 Hz, 40 Hz - 80 Hz and 80 Hz - 120 Hz for low sounds (this includes, for example, a bass guitar).  For medium and higher sounds, frequencies of 120 Hz - 180 Hz and 180 Hz - 300 Hz are used (this includes vocals and most other instruments). <br><br>  Now that we have decided on intervals, you can simply find the frequencies with the highest levels in them.  This information and form the signature for a specific block of data being analyzed, and it, in turn, is part of the signature of the entire song. <br><br><pre> <code class="hljs markdown"> public final int[<span class="hljs-string"></span><span class="hljs-string"></span>] RANGE = new int[<span class="hljs-string"></span><span class="hljs-string"></span>] { 40, 80, 120, 180, 300 }; //    ,      public int getIndex(int freq) { int i = 0; while (RANGE[<span class="hljs-string"><span class="hljs-string">i</span></span>] <span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">freq</span></span></span></span><span class="xml"><span class="hljs-tag">) </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">i</span></span></span></span><span class="xml"><span class="hljs-tag">++; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">return</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">i</span></span></span></span><span class="xml"><span class="hljs-tag">; } //  ‚Äì   ,     </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">for</span></span></span></span><span class="xml"><span class="hljs-tag"> (</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">int</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">t</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">0;</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">t</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">result.length</span></span></span></span><span class="xml"><span class="hljs-tag">; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">t</span></span></span></span><span class="xml"><span class="hljs-tag">++) { </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">for</span></span></span></span><span class="xml"><span class="hljs-tag"> (</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">int</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">freq</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">40;</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">freq</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">300</span></span></span></span><span class="xml"><span class="hljs-tag"> ; </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">freq</span></span></span></span><span class="xml"><span class="hljs-tag">++) { //   </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">:</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">double</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">mag</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">Math.log(results[t][freq].abs()</span></span></span></span><span class="xml"><span class="hljs-tag"> + </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">1</span></span></span></span><span class="xml"><span class="hljs-tag">); // ,    </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">:</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">int</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">index</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">getIndex(freq);</span></span></span></span><span class="xml"><span class="hljs-tag"> //         </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">:</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">if</span></span></span></span><span class="xml"><span class="hljs-tag"> (</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">mag</span></span></span></span><span class="xml"><span class="hljs-tag"> &gt;</span></span></span></span> highscores[<span class="hljs-string"><span class="hljs-string">t</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">index</span></span>]) { points[<span class="hljs-string"><span class="hljs-string">t</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">index</span></span>] = freq; } } //  - long h = hash(points[<span class="hljs-string"><span class="hljs-string">t</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">0</span></span>], points[<span class="hljs-string"><span class="hljs-string">t</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">1</span></span>], points[<span class="hljs-string"><span class="hljs-string">t</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">2</span></span>], points[<span class="hljs-string"><span class="hljs-string">t</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">3</span></span>]); } private static final int FUZ<span class="hljs-emphasis"><span class="hljs-emphasis">_FACTOR = 2; private long hash(long p1, long p2, long p3, long p4) { return (p4 - (p4 % FUZ_</span></span>FACTOR)) <span class="hljs-bullet"><span class="hljs-bullet">* 100000000 + (p3 - (p3 % FUZ_FACTOR)) *</span></span> 100000 + (p2 - (p2 % FUZ<span class="hljs-emphasis"><span class="hljs-emphasis">_FACTOR)) * 100 + (p1 - (p1 % FUZ_</span></span>FACTOR)); }</code> </pre> <br>  Note that we must take into account the fact that the recording was not made in ideal conditions (that is, not in a soundproof room).  As a result, it is necessary to provide for the presence of extraneous noise in the recording and possible distortion of the recorded sound, depending on the characteristics of the room.  This issue should be approached very seriously, in real systems it is necessary to implement the setting of the analysis of possible distortions and extraneous sounds (fuzz factor) depending on the conditions in which the recording is carried out. <br><br>  To simplify the search for musical compositions, their signatures are used as keys in a hash table.  The keys correspond to the time values ‚Äã‚Äãwhen the set of frequencies for which the signature was found appeared in the work, and the identifier of the work itself (the name of the song and the name of the artist, for example).  Here is a variant of how such records may look in the database. <br><br><table><tbody><tr><td>  <b>Hash tag</b> <br></td><td>  <b>Time in seconds</b> <br></td><td>  <b>Song</b> <br></td></tr><tr><td>  30 51 99 121 195 <br></td><td>  53.52 <br></td><td>  Song A Artist A <br></td></tr><tr><td>  33 56 92 151 185 <br></td><td>  12.32 <br></td><td>  Song B Artist B <br></td></tr><tr><td>  39 26 89 141 251 <br></td><td>  15.34 <br></td><td>  Song C Artist C <br></td></tr><tr><td>  32 67,100 128,270 <br></td><td>  78.43 <br></td><td>  Song D Artist D <br></td></tr><tr><td>  30 51 99 121 195 <br></td><td>  10.89 <br></td><td>  Song E of artist E <br></td></tr><tr><td>  34 57 95 111 200 <br></td><td>  54.52 <br></td><td>  Song A Artist A <br></td></tr><tr><td>  34 41 93 161 202 <br></td><td>  11.89 <br></td><td>  Song E of artist E <br></td></tr></tbody></table><br>  If we process a certain library of music records in this way, it will be possible to build a database with full signatures of each piece. <br><br><h2>  <font color="#c75733">Match Search</font> </h2><br>  In order to find out what song is playing now in a restaurant, you need to record the sound using the phone and drive it through the above-described process of calculating signatures.  You can then start a search for the calculated hash tags in the database. <br><br>  But not everything is so simple.  The fact is that many fragments of different works of hash tags are the same.  For example, it may turn out that some fragment of song A sounds just like a certain section of song E. And there is nothing surprising.  Musicians and composers constantly ‚Äúborrow‚Äù successful musical figures from each other. <br><br>  Whenever a matching hash tag is found, the number of possible matches decreases, but it is highly likely that only this information will not allow us to narrow the search range so much as to stop on the only correct song.  Therefore, in the music recognition algorithm, we need to check something else.  Namely - we are talking about time stamps. <br><br>  The fragment of a song recorded in a restaurant may be from any of its places, so we simply cannot directly compare the relative time inside the recorded fragment with what is in the database. <br><br>  However, if several matches are found, you can analyze the relative timing of matches, and thus increase the accuracy of the search. <br><br>  For example, if you look at the table above, you can find that the hash tag 30 51 99 121 195 applies to song A and song E. If a second later we check the hash tag 34 57 95 111 200, we will find another coinciding with song A, besides, in a similar case we will know that both hash tags and their distribution in time coincide. <br><br><pre> <code class="hljs pgsql">// ,       private <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> DataPoint { private <span class="hljs-type"><span class="hljs-type">int</span></span> <span class="hljs-type"><span class="hljs-type">time</span></span>; private <span class="hljs-type"><span class="hljs-type">int</span></span> songId; <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> DataPoint(<span class="hljs-type"><span class="hljs-type">int</span></span> songId, <span class="hljs-type"><span class="hljs-type">int</span></span> <span class="hljs-type"><span class="hljs-type">time</span></span>) { this.songId = songId; this.time = <span class="hljs-type"><span class="hljs-type">time</span></span>; } <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> <span class="hljs-type"><span class="hljs-type">int</span></span> getTime() { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-type"><span class="hljs-type">time</span></span>; } <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> <span class="hljs-type"><span class="hljs-type">int</span></span> getSongId() { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> songId; } }</code> </pre> <br>  Let <b>i1</b> and <b>i2</b> be the time stamps in the recorded song, <b>j1</b> and <b>j2</b> the time <b>stamps</b> in the song from the database.  We can say that there are two coincidences, taking into account the coincidence of the time difference, if the following condition is met: <br><br><pre> <code class="hljs lisp">RecordedHash(<span class="hljs-name"><span class="hljs-name">i1</span></span>) = SongInDBHash(<span class="hljs-name"><span class="hljs-name">j1</span></span>) AND RecordedHash(<span class="hljs-name"><span class="hljs-name">i2</span></span>) = SongInDBHash(<span class="hljs-name"><span class="hljs-name">j2</span></span>) AND abs(<span class="hljs-name"><span class="hljs-name">i1</span></span> - i2) = abs (<span class="hljs-name"><span class="hljs-name">j1</span></span> - j2)</code> </pre> <br>  This makes it possible not to care about exactly what part of the song the recording has: the beginning, the middle, or the very end. <br><br>  And, finally, it is unlikely that each processed fragment of a song recorded in the ‚Äúwild‚Äù conditions will coincide with a similar fragment from a database built on the basis of studio recordings.  Record, on the basis of which we want to find the name of the work, will include a lot of noise, which will lead to some discrepancies in the comparison.  Therefore, instead of trying to exclude everything from the list of matches, except for the only correct composition, at the end of the database mapping procedure, we will sort the records in which there were matches.  We will sort in descending order.  The more matches there are, the more likely it is that we find the right composition.  Accordingly, she will be at the top of the list. <br><br><h2>  <font color="#c75733">Music Recognition Review</font> </h2><br>  Here is an overview of the entire procedure for recognizing music.  Walk on it from start to finish. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/813/d0d/cae/813d0dcaeb3d251e74fe31be6c3842e6.jpg"></div><br>  <i><font color="#999999">Music Recognition Review</font></i> <br><br>  It all starts with the original sound.  Then it is captured, find the frequency characteristics, compute hash tags and compare them with those stored in the music database. <br><br>  In such systems, databases can be huge, so it is important to use solutions that can be scaled.  There is no particular need for database table links, the data model is very simple, so some kind of NoSQL database is quite suitable here. <br><br><h2>  <font color="#c75733">Shazam!</font> </h2><br>  Programs like the one we talked about here are suitable for finding similar places in musical works.  Now that you understand how Shazam works, you can see that the music recognition algorithms are applicable not only as ‚Äúreminders‚Äù of the names of forgotten songs from the past that are heard on the radio in a taxi. <br><br>  For example, you can use them to look for musical plagiarism, or use them to find performers who inspired some pioneers in blues, jazz, rock music, pop music, and in any other genre. <br><br>  Perhaps a good experiment will be filling the database with classics ‚Äî the writings of Bach, Beethoven, Vivaldi, Wagner, Chopin, and Mozart and searching for similar things in their works.  It is quite possible to find out that even Bob Dylan, Elvis Presley and Robert Johnson were not averse to borrow anything from others! <br><br>  But can we blame them for it?  I'm sure not.  After all, music is just a sound wave that a person hears, remembers and repeats in his head.  There it develops, changes - until it is recorded in the studio and released into the wild, where it can quite inspire another genius from music. <br><br><blockquote><div class="spoiler">  <b class="spoiler_title">Oh, and come to work with us?</b>  <b class="spoiler_title">:)</b> <div class="spoiler_text">  <a href="http://wunderfund.io/"><b>wunderfund.io</b></a> is a young foundation that deals with <a href="https://en.wikipedia.org/wiki/High-frequency_trading">high-frequency algorithmic trading</a> .  High-frequency trading is a continuous competition of the best programmers and mathematicians of the whole world.  By joining us, you will become part of this fascinating fight. <br><br>  We offer interesting and challenging data analysis and low latency tasks for enthusiastic researchers and programmers. <br>  Flexible schedule and no bureaucracy, decisions are quickly made and implemented. <br><br>  Join our team: <a href="http://wunderfund.io/">wunderfund.io</a> </div></div></blockquote></div><p>Source: <a href="https://habr.com/ru/post/275043/">https://habr.com/ru/post/275043/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../275031/index.html">A schoolboy hacked email and got access to personal data of the head of the US National Intelligence</a></li>
<li><a href="../275033/index.html">Are you sure that all All-Flash storage systems are ready for use in the corporate sector?</a></li>
<li><a href="../275035/index.html">DLP do-it-yourself system</a></li>
<li><a href="../275037/index.html">Analyze this or about software quality.</a></li>
<li><a href="../275039/index.html">We read the container of the private key CryptoPro by means of OpenSSL</a></li>
<li><a href="../275045/index.html">Iosevka - another font for coding</a></li>
<li><a href="../275047/index.html">Email from your server: pitfalls</a></li>
<li><a href="../275053/index.html">Cross-platform IDE for .NET / C # from JetBrains</a></li>
<li><a href="../275063/index.html">Where the Pixie Unicorn lives. Indie storytelling</a></li>
<li><a href="../275065/index.html">Yii 1.1.17</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>