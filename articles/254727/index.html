<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Asynchronous work with Tarantool on Python</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="On Habr√© there are already articles about NoSQL DBMS Tarantool and how it is used in Mail.Ru Group (and not only). However, there is no recipe for how...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Asynchronous work with Tarantool on Python</h1><div class="post__text post__text-html js-mediator-article">  On Habr√© there are already articles about NoSQL DBMS <a href="http://tarantool.org/">Tarantool</a> and how it is used in Mail.Ru Group (and not only).  However, there is no recipe for how to work with Tarantool on Python.  In my article, I want to talk about how we prepare Tarantool Python in our projects, what problems and difficulties arise in this case, pros, cons, pitfalls, and, of course, ‚Äúwhat is the trick‚Äù.  So, first things first. <br><br><img src="https://habrastorage.org/files/716/488/7c9/7164887c961446a09aea38a920a4019f.jpg"><br><br>  Tarantool is an <a href="http://habrahabr.ru/company/mailru/blog/252065/">Application Server for Lua</a> .  He is able to store data on disk, provides quick access to them.  Tarantool is used in tasks with large data streams per unit of time.  If we talk about numbers, these are tens and hundreds of thousands of operations per second.  For example, in one of my projects, more than 80,000 requests per second are generated (sample, insert, update, delete), while the load is evenly distributed across 4 servers with 12 instances of Tarantool.  Not all modern DBMSs are ready to work with such loads.  In addition, with such a large amount of data, it is very expensive to wait for the request to be completed, so the programs themselves must quickly switch from one task to another.  For effective and uniform loading of the server's CPU (all its cores), Tarantool and asynchronous techniques in programming are needed. <br><a name="habracut"></a><br><h2>  How does the tarantool-python connector work? </h2><br>  Before talking about asynchronous Python code, you need a good understanding of how regular synchronous Python code interacts with Tarantool.  I will use the version of Tarantool 1.6 under CentOS, its installation is simple and trivial and is described in detail on the project site, there you can also find an extensive <a href="http://tarantool.org/doc/book/index.html">user guide</a> .  I want to note that recently, with the advent of good documentation, it has become much easier to understand the launch and use of the Tarantool instance.  More on Habr√© quite recently appeared a useful article " <a href="http://habrahabr.ru/post/254533/">Tarantool 1.6 - let's begin</a> ." 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So, Tarantool is installed, running and ready to go.  To work with Python 2.7, we take the <a href="https://github.com/tarantool/tarantool-python">tarantool-python</a> connector from <a href="https://github.com/tarantool/tarantool-python">pypi</a> : <br><br><pre><code class="hljs sql">$ pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> tarantool-python</code> </pre> <br>  This is still enough to solve our problems.  And what are they?  In one of my projects, it became necessary to ‚Äústack‚Äù the data stream in Tarantool for further processing, with the size of one data packet being approximately 1.5 KB.  Before proceeding to the solution of the problem, one should study the issue well and test the chosen approaches and tools.  The script for testing performance looks elementary and is written in a couple of minutes: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tarantool <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> string mod_len = len(string.printable) data = [string.printable[it] * <span class="hljs-number"><span class="hljs-number">1536</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> it <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(mod_len)] tnt = tarantool.connect(<span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span>, <span class="hljs-number"><span class="hljs-number">3301</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> it <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">100000</span></span>): r = tnt.insert(<span class="hljs-string"><span class="hljs-string">"tester"</span></span>, (it, data[it % mod_len]))</code> </pre><br>  It's simple: in a cycle we consistently make 100 thousand inserts in Tarantool.  On my virtual machine, this code is executed on average in 32 seconds, that is, about three thousand inserts per second.  The program is simple, and if the resulting performance is enough, then you can do nothing more, because, as you know, "premature optimization is evil."  However, this was not enough for our project, moreover, Tarantool itself can show much <a href="http://tarantool.org/benchmark.html">better</a> results. <br><br><h2>  Profile the code </h2><br>  Before taking thoughtless steps, we will try to carefully examine our code and how it works.  Thanks to my colleague <a href="http://habrahabr.ru/users/Dreadatour/">Dreadatour</a> for his series of articles on <a href="http://habrahabr.ru/company/mailru/blog/201594/">profiling</a> Python code. <br><br>  Before launching the profiler, it is helpful to understand how the program works; after all, the best tool for profiling is the developer‚Äôs head.  The script itself is simple, there is nothing special to study there, let's try to "dig deeper."  If you look into the implementation of the connector driver, you can understand that the request is packaged using the <a href="https://pypi.python.org/pypi/msgpack-python/">msgpack</a> library, sent to the socket using the <b>sendall</b> call, and then the length of the response and the response is read from the socket.  Already more interesting.  How many operations with a Tarantool socket will be made as a result of executing this code?  In our case, one call to <b>socket.sendall</b> (sent data) and two calls to <b>socket.recv</b> (received the answer length and the response itself) will be made for one <b>tnt.insert</b> request.  The ‚Äúclose look‚Äù method says that 200k + 100k = 300k read / write system calls will be made to insert one hundred thousand records.  And the profiler (I used <a href="https://docs.python.org/2/library/profile.html">cProfile</a> and <a href="http://kcachegrind.sourceforge.net/">kcachegrind</a> to interpret the results) confirms our conclusions: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/3e7/8a5/c3f/3e78a5c3ffe14dcdbde60d28860826bc.png"></div><br><br>  What can be changed in this scheme?  First of all, of course, I want to reduce the number of system calls, that is, operations with a Tarantool socket.  This can be done by grouping <b>tnt.insert</b> requests into a ‚Äúbundle‚Äù and calling <b>socket.sendall</b> for all requests at once.  Likewise, you can read a ‚Äúpacket‚Äù of responses from Tarantool for one <b>socket.recv</b> from the socket.  With the usual classical programming style, this is not so easy: you need a buffer for the data, a delay to accumulate data into the buffer, and you still need to return the results of the queries without delay.  And what to do if there were a lot of requests and suddenly there was very little?  There will again be delays that we are trying to avoid.  In general, a fundamentally new approach is needed, but most importantly, I want to leave the source code of the original task as simple as it was originally.  Asynchronous frameworks come to the rescue of our task. <br><br><h2>  Gevent and Python 2.7 </h2><br>  I had to deal with several asynchronous frameworks: <a href="https://twistedmatrix.com/">twisted</a> , <a href="http://www.tornadoweb.org/">tornado</a> , <a href="http://www.gevent.org/">gevent,</a> and others.  On Habr√©, the question of comparison and benchmarks of these tools, for example, <a href="http://habrahabr.ru/post/117918/">once</a> and <a href="http://habrahabr.ru/post/228455/">twice</a> , has been raised <a href="http://habrahabr.ru/post/117918/">many times</a> . <br><br>  My choice fell on gevent.  The main reason is the efficiency of working with I / O operations and the simplicity of writing code.  A good tutorial on using this library can be found <a href="http://sdiehl.github.io/gevent-tutorial/">here</a> .  And in <a href="http://sdiehl.github.io/gevent-tutorial/">this</a> tutorial there is a classic example of a fast crawler: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gevent.monkey gevent.monkey.patch_socket() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gevent <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(pid)</span></span></span><span class="hljs-function">:</span></span> url = <span class="hljs-string"><span class="hljs-string">'http://json-time.appspot.com/time.json'</span></span> response = urllib2.urlopen(url) result = response.read() json_result = json.loads(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> json_result[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">synchronous</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>): fetch(i) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">asynchronous</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> threads = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>): threads.append(gevent.spawn(fetch, i)) gevent.joinall(threads) t1 = time.time() synchronous() t2 = time.time() print(<span class="hljs-string"><span class="hljs-string">'Sync:'</span></span>, t2 - t1) t1 = time.time() asynchronous() t2 = time.time() print(<span class="hljs-string"><span class="hljs-string">'Async:'</span></span>, t2 - t1)</code> </pre><br>  On my virtual machine for this test, the following results were obtained: <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">Sync</span></span>: 1<span class="hljs-selector-class"><span class="hljs-selector-class">.529</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Async</span></span>: 0<span class="hljs-selector-class"><span class="hljs-selector-class">.238</span></span></code> </pre><br>  A good performance boost!  To make the synchronous code work asynchronously using gevent, it was necessary to wrap the <b>fetch</b> call into <b>gevent.spawn</b> , as if parallelizing the downloading of the URLs themselves.  It also took <b>monkey.patch_socket ()</b> , after which all calls for working with sockets become cooperative.  Thus, while one URL is being downloaded and the program is waiting for a response from a remote service, the gevent engine switches to other tasks and instead of useless waiting, tries to download other available documents.  In the depths of Python, all gevent threads are executed sequentially, but due to the fact that there are no expectations ( <b>wait</b> system calls), the final result is faster. <br>  It looks good, and most importantly - this approach is very well suited for our task.  However, the tarantool-python driver does not know how to work with a gevent out of the box, and I had to write a gtarantool connector on top of it. <br><br><h2>  Gevent and Tarantool </h2><br>  The <a href="https://github.com/shveenkov/gtarantool">gtarantool</a> connector works with gevent and Tarantool 1.6 and is now available on pypi: <br><br><pre> <code class="hljs sql">$ pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> gtarantool</code> </pre> <br>  In the meantime, the new solution to our problem takes the following form: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gevent <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gtarantool <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> string mod_len = len(string.printable) data = [string.printable[it] * <span class="hljs-number"><span class="hljs-number">1536</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> it <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(mod_len)] cnt = <span class="hljs-number"><span class="hljs-number">0</span></span> def insert_job(tnt): <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> cnt <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10000</span></span>): cnt += <span class="hljs-number"><span class="hljs-number">1</span></span> tnt.<span class="hljs-keyword"><span class="hljs-keyword">insert</span></span>("tester", (cnt, data[it % mod_len])) tnt = gtarantool.<span class="hljs-keyword"><span class="hljs-keyword">connect</span></span>("127.0.0.1", <span class="hljs-number"><span class="hljs-number">3301</span></span>) jobs = [gevent.spawn(insert_job, tnt) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>)] gevent.joinall(jobs)</code> </pre><br>  What has changed compared to synchronous code?  We divided the insertion of 100k records between ten asynchronous "green" threads, each of which makes about 10k calls to <b>tnt.insert</b> in a loop, and all this through one connection to Tarantool.  The program execution time was reduced to 12 seconds, which is almost 3 times more efficient than the synchronous version, and the number of data inserts in the database increased to 8 thousand per second.  Why does such a scheme work faster?  What is the trick? <br><br>  The gtarantool connector internally uses a buffer of requests to the Tarantool socket and separate ‚Äúgreen streams‚Äù of read / write to this socket.  We try to look at the results in the profiler (this time I used the <a href="http://emptysqua.re/blog/greenletprofiler/">Greenlet Profiler</a> - this is an adapted profiler for greenlets yappi): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ab5/e63/8fb/ab5e638fb929405f9663f52e84bb5634.png"></div><br>  Analyzing the results in kcachegrind, we see that the number of calls to <b>socket.recv</b> decreased from 100k to 10k, and the number of calls to <b>socket.send</b> dropped from 200k to 2.5k.  Actually, this makes working with Tarantool more efficient: less heavy system calls due to lighter and ‚Äúcheaper‚Äù grinlets.  And the most important and pleasant thing is that the source program code remained, in fact, ‚Äúsynchronous‚Äù.  There are no ugly twisted-callbacks in it. <br><br>  We successfully use this approach in our project.  What is the profit: <br><ol><li>  We refused to fork.  You can use several Python processes, and in each process use one gtarantool connection (or connection pool). </li><li>  Inside greenlets, switching is much faster and more efficient than switching between Unix processes. </li><li>  Reducing the number of processes has greatly reduced memory consumption. </li><li>  The reduction in the number of operations with a Tarantool socket has increased the efficiency of working with the Tarantool itself, it has begun to consume less CPU. </li></ol><br><h2>  And what about Python 3 and Tarantool? </h2><br>  One of the differences between different asynchronous frameworks is the ability to work under Python 3. For example, gevent does not support it.  Moreover, the tarantool-python library will not work under Python 3 either (they have not had time to port yet).  How so? <br><br>  The path of the Jedi is thorny.  I really wanted to compare asynchronous work with tarantool from under the second and third versions of Python, and then I decided to rewrite everything in Python 3.4.  After Python 2.7 it was a bit unusual to write code: <br><ul><li>  <b>print</b> does not work <b>‚Äúfoo‚Äù</b> </li><li>  all strings are objects of class <b>str</b> </li><li>  no type <b>long</b> </li><li>  ... </li></ul><br>  But the addiction was successful, and now I try to write the code for Python 2.7 right away so that it works in Python 3 without any changes. <br><br>  The tarantool-python connector had to be slightly modified: <br><ul><li>  <b>StandartError</b> replaced by <b>Exception</b> </li><li>  <b>basestring</b> replaced by <b>str</b> </li><li>  <b>xrange</b> replaced by <b>range</b> </li><li>  <b>long</b> - deleted </li></ul><br>  It turned out <a href="">fork of the synchronous connector</a> working under Python 3.4.  After a thorough check, this code may be poured into the main branch of the library, but for now you can install it directly from GitHub: <br><br><pre> <code class="hljs ruby">$ pip install git+<span class="hljs-symbol"><span class="hljs-symbol">https:</span></span>/<span class="hljs-regexp"><span class="hljs-regexp">/github.com/shveenkov</span></span><span class="hljs-regexp"><span class="hljs-regexp">/tarantool-python.git@for_python3.4</span></span></code> </pre> <br>  The first results of benchmarks did not cause delight.  The usual synchronous version of inserting 100k records, 1.5 KB in size, began on average a little more than a minute ‚Äî twice as long as the same code under the second version of Python!  Profiling again comes to the rescue: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/414/e21/c27/414e21c273964546b6c701f1011e920c.png"></div><br>  Wow!  Well, where did 400k call <b>socket.recv come from</b> ?  Where <b>did the</b> 200k <b>socket.sendall</b> calls <b>come from</b> ?  I had to dive into the tarantool-python connector code again: as it turned out, this is the result of the work of Python strings and bytes as dict keys.  For example, you can compare this code: <br><br>  Python 3.4: <br><pre> <code class="hljs pgsql">&gt;&gt;&gt; a=dict() &gt;&gt;&gt; a[b"key"] = <span class="hljs-number"><span class="hljs-number">1</span></span> &gt;&gt;&gt; a["key"] Traceback (most recent <span class="hljs-keyword"><span class="hljs-keyword">call</span></span> last): File "&lt;stdin&gt;", <span class="hljs-type"><span class="hljs-type">line</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;module&gt; KeyError: <span class="hljs-string"><span class="hljs-string">'key'</span></span></code> </pre><br>  Python 2.7: <br><pre> <code class="hljs ruby"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;</span></span>&gt; a=dict() &gt;&gt;&gt; a[b<span class="hljs-string"><span class="hljs-string">"key"</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span> &gt;&gt;&gt; a[<span class="hljs-string"><span class="hljs-string">"key"</span></span>] <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre><br>  These little things are a vivid example of the complexity of porting code to Python 3, and even tests here do not always help, because formally everything works, but works twice as slowly, and for our realities this is a significant difference.  Replacing the code, adding ‚Äúa couple of bytes‚Äù to the connector (link to changes in <a href="https://github.com/shveenkov/tarantool-python/commit/b756c851ac92c4e61cb5d7cee520f1c9e5cbe333">the connector code</a> , as well as another <a href="https://github.com/shveenkov/tarantool-python/commit/273fec3b4999a6681c792a953c9030da7644cfd6">change</a> ) - there is a result! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/579/320/0f5/5793200f5b354e189ee167342c949257.png"></div><br>  Well, now not bad!  The synchronous version of the connector began to cope with the task in an average of 35 seconds, which is slightly slower than Python 2.7, but you can live with it. <br><br><h2>  Moving to asyncio in Python 3 </h2><br>  Asyncio is Cortina for Python 3 out of the box.  There is <a href="https://docs.python.org/3/library/asyncio.html">documentation</a> , there are examples, there are ready-made <a href="http://asyncio.org/">libraries</a> for asyncio and Python 3. At first glance, everything is quite complicated and confusing (at least compared to gevent), but upon further consideration everything falls into place.  And so, after some effort, I wrote a version of the connector for Tarantool for asyncio - <a href="https://github.com/shveenkov/aiotarantool">aiotarantool</a> . <br><br>  This connector is also available via pypi: <br><br><pre> <code class="hljs sql">$ pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> aiotarantool</code> </pre> <br>  I want to note that the code of our original task on asyncio has become a bit more complicated than its original version.  There were designs <b>yield from</b> , decorators <b>@ asyncio.coroutine appeared</b> , but in general I like it, and there are not so many differences from gevent: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> aiotarantool <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> string mod_len = len(string.printable) data = [string.printable[it] * <span class="hljs-number"><span class="hljs-number">1536</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> it <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(mod_len)] cnt = <span class="hljs-number"><span class="hljs-number">0</span></span> @asyncio.coroutine <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">insert_job</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(tnt)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> cnt <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> it <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10000</span></span>): cnt += <span class="hljs-number"><span class="hljs-number">1</span></span> args = (cnt, data[it % mod_len]) <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tnt.insert(<span class="hljs-string"><span class="hljs-string">"tester"</span></span>, args) loop = asyncio.get_event_loop() tnt = aiotarantool.connect(<span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span>, <span class="hljs-number"><span class="hljs-number">3301</span></span>) tasks = [asyncio.<span class="hljs-keyword"><span class="hljs-keyword">async</span></span>(insert_job(tnt)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>)] loop.run_until_complete(asyncio.wait(tasks)) loop.close()</code> </pre><br>  This option copes with the task, on average, in 13 seconds (it turns out about 7.5k inserts per second), which is slightly slower than the version in Python 2.7 and gevent, but much better than all synchronous versions.  Aiotarantool has one small, but very important difference from other libraries available on <a href="http://asyncio.org/">asyncio.org</a> : the <b>tarantool.connect</b> call is made outside of <b>asyncio.event_loop</b> .  In fact, this call does not create a real connection: it will be made later, inside one of the corutins when you first call <b>yield from tnt.insert</b> .  This approach seemed to me easier and more convenient when programming in asyncio. <br><br>  By tradition, the results of profiling (I used the <a href="https://code.google.com/p/yappi/">yappi</a> profiler, but there is a suspicion that he does not quite correctly count the number of function calls when working with asyncio): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b52/1a0/6a7/b521a06a7b634cd3b317e6a56c6b5d76.png"></div><br>  As a result, we see 5k calls of <b>StreamReader.feed_data</b> and <b>StreamWriter.write</b> , which is undoubtedly much better than 200k of <b>socket.recv</b> calls and 100k of <b>socket.sendall</b> calls in a synchronous version. <br><br><h2>  Comparison of approaches </h2><br>  I present the results of the comparison of the considered options for working with Tarantool.  Benchmark code can be found in the tests directory of the <a href="https://github.com/shveenkov/gtarantool/blob/master/tests/benchmark.py">gtarantool</a> and <a href="https://github.com/shveenkov/aiotarantool/blob/master/tests/benchmark.py">aiotrantool libraries</a> .  The benchmark performs the insertion, search, modification and deletion of 100,000 records 1.5 KB in size.  Each test was run ten times, the tables show the average rounded value, since it is not the exact figures that are important (they depend on the particular iron), but their ratio. <br><br>  Are compared: <br><ul><li>  synchronous tarantool-python under Python 2.7; </li><li>  synchronous tarantool-python under Python 3.4; </li><li>  asynchronous version with gtarantool under Python 2.7; </li><li>  asynchronous version with aiotarantool under Python 3.4. </li></ul><br>  Test run time in seconds (less is better): <table><tbody><tr><th>  Operation <br>  (100k records) </th><th>  tarantool-python <br>  2.7 </th><th>  tarantool-python <br>  3.4 </th><th>  gtarantool <br>  (gevent) </th><th>  aiotarantool <br>  (asyncio) </th></tr><tr><th>  insert </th><td>  34 </td><td>  38 </td><td>  eleven </td><td>  13 </td></tr><tr><th>  select </th><td>  23 </td><td>  23 </td><td>  ten </td><td>  13 </td></tr><tr><th>  update </th><td>  34 </td><td>  33 </td><td>  ten </td><td>  14 </td></tr><tr><th>  delete </th><td>  35 </td><td>  35 </td><td>  ten </td><td>  13 </td></tr></tbody></table>  The number of operations per second (more - better): <table><tbody><tr><th>  Operation <br>  (100k records) </th><th>  tarantool-python <br>  2.7 </th><th>  tarantool-python <br>  3.4 </th><th>  gtarantool <br>  (gevent) </th><th>  aiotarantool <br>  (asyncio) </th></tr><tr><th>  insert </th><td>  3000 </td><td>  2600 </td><td>  9100 </td><td>  7700 </td></tr><tr><th>  select </th><td>  4300 </td><td>  4300 </td><td>  10,000 </td><td>  7700 </td></tr><tr><th>  update </th><td>  2900 </td><td>  3000 </td><td>  10,000 </td><td>  7100 </td></tr><tr><th>  delete </th><td>  2900 </td><td>  2900 </td><td>  10,000 </td><td>  7700 </td></tr></tbody></table>  The gtarantool performance is slightly better than that of aiotarantool.  We have been using gtarantool for a long time, it is a proven solution for large loads, however gevent is not supported in Python 3. In addition, it should be remembered that gevent is a third-party library that requires compilation during installation.  Asyncio attracts with its speed and novelty, it goes into Python 3 "out of the box", and there are no "crutches" in the form of "monkey.patch".  But under the real load aiotarantool in our project has not yet worked.  All ahead! <br><br><h2>  We squeeze the maximum out of the server </h2><br>  To maximize the use of resources of our server, we will try to complicate the code of our benchmark a little.  We make simultaneous deletion, insertion, modification and selection of data (a fairly common load profile) in one Python process, and we will create several, say, 22 (magic number) such processes.  If there are 24 total cores on the machine, then we will leave one core to the system (just in case), give one core to Tarantool (that's enough for it!), And take the remaining 22 to the Python processes.  We will do the comparison on gevent, and on asyncio, the benchmark code can be found <a href="https://github.com/shveenkov/gtarantool/blob/master/tests/benchmark_hot.py">here</a> for gtarantool, and <a href="https://github.com/shveenkov/aiotarantool/blob/master/tests/benchmark_hot.py">here</a> for aiotarantool. <br><br>  It is very important to visually and beautifully display the results for later comparison.  It's time to evaluate the capabilities of the new version of Tarantool 1.6: in fact, it is a Lua interpreter, which means that we can run absolutely any Lua code directly in the database.  We write the simplest program, and our Tarantool is already able to send any of its statistics to the <a href="http://graphite.wikidot.com/">graphite</a> .  Add the code to our Tarantool init script (in a real project, of course, it‚Äôs better to put such things into a separate module): <br><br><pre> <code class="lua hljs">fiber = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'fiber'</span></span>) socket = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'socket'</span></span>) <span class="hljs-built_in"><span class="hljs-built_in">log</span></span> = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'log'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> host = <span class="hljs-string"><span class="hljs-string">'127.0.0.1'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> port = <span class="hljs-number"><span class="hljs-number">2003</span></span> fstat = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> sock = socket(<span class="hljs-string"><span class="hljs-string">'AF_INET'</span></span>, <span class="hljs-string"><span class="hljs-string">'SOCK_DGRAM'</span></span>, <span class="hljs-string"><span class="hljs-string">'udp'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-literal"><span class="hljs-literal">true</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> ts = <span class="hljs-built_in"><span class="hljs-built_in">tostring</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">math</span></span>.<span class="hljs-built_in"><span class="hljs-built_in">floor</span></span>(fiber.<span class="hljs-built_in"><span class="hljs-built_in">time</span></span>())) info = { <span class="hljs-built_in"><span class="hljs-built_in">insert</span></span> = box.stat.INSERT.rps, <span class="hljs-built_in"><span class="hljs-built_in">select</span></span> = box.stat.SELECT.rps, update = box.stat.UPDATE.rps, delete = box.stat.DELETE.rps } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k, v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-built_in"><span class="hljs-built_in">pairs</span></span>(info) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> metric = <span class="hljs-string"><span class="hljs-string">'tnt.'</span></span> .. k .. <span class="hljs-string"><span class="hljs-string">' '</span></span> .. <span class="hljs-built_in"><span class="hljs-built_in">tostring</span></span>(v) .. <span class="hljs-string"><span class="hljs-string">' '</span></span> .. ts sock:sendto(host, port, metric) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> fiber.sleep(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-built_in"><span class="hljs-built_in">log</span></span>.info(<span class="hljs-string"><span class="hljs-string">'send stat to graphite '</span></span> .. ts) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> fiber.<span class="hljs-built_in"><span class="hljs-built_in">create</span></span>(fstat)</code> </pre><br>  Run Tarantool and automatically get graphs with statistics.  Cool?  I really liked this feature! <br><br>  Now we will conduct two benchmarks: in the first we will perform simultaneous deletion, insertion, modification and selection of data.  In the second benchmark we will perform only the sample.  On all graphs, the abscissa is time, and the ordinate is the number of operations per second: <br><br><ul><li>  gtarantool (insert, select, update, delete): <br><div style="text-align:center;"><img src="https://habrastorage.org/files/11b/cb6/5e9/11bcb65e9d914e9eaf2db4090e203d68.png"></div><br></li><li>  aiotarantool (insert, select, update, delete): <br><div style="text-align:center;"><img src="https://habrastorage.org/files/204/1e6/db5/2041e6db5276439f9a9db4ed57dfe042.png"></div><br></li><li>  gtarantool (select only): <br><div style="text-align:center;"><img src="https://habrastorage.org/files/4cb/f76/c21/4cbf76c214e54623bcce816c1784f001.png"></div><br></li><li>  aiotarantool (select only): <br><div style="text-align:center;"><img src="https://habrastorage.org/files/7cd/3c4/370/7cd3c43708214dfabcb2b9cd90320079.png"></div></li></ul><br>  Let me remind you that the process Tarantool used only one core.  In the first benchmark, the CPU load (of this core) at the same time was 100%, and in the second test, the Tarantool process only recycled its core by 60%. <br><br>  The results obtained allow us to conclude that the techniques discussed in the article are suitable for working with large loads in our projects. <br><br><h2>  findings </h2><br>  Examples in the article are, of course, artificial.  The real tasks are a bit more complicated and diverse, but their solutions in the general case look exactly as shown in the above code.  Where can I apply this approach?  Where ‚Äúmany, many, many requests per second‚Äù are required: in this case, asynchronous code is needed to work effectively with Tarantool.  Korutiny are effective where there is an expectation of events (system calls), and the classic example of such a task is the crawler. <br><br>  Writing code in asyncio or gevent is not as difficult as it seems, but you should definitely pay a lot of attention to code profiling: often asynchronous code does not work at all as expected. <br><br>  Tarantool and its protocol are very well suited for working with asynchronous development style.  One has only to plunge into the world of Tarantool and Lua, and one can be endlessly surprised at their powerful capabilities.  Python code can work effectively with Tarantool, and in Python 3 there is a good potential for developing on asyncio quiches. <br><br>  I hope that the material of this article will benefit the community and expand the knowledge base about Tarantool and about asynchronous programming.  I think that asyncio and aiotarantool will be used in production and in our projects, and I will have something to share with Habr's readers. <br><br><h2>  Links that were used when writing the article: </h2><br><ul><li>  <a href="http://tarantool.org/">tarantool.org</a> </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/252065/">habrahabr.ru/company/mailru/blog/252065</a> - Tarantool 1.6 first-person </li><li>  <a href="http://habrahabr.ru/post/254533/">habrahabr.ru/post/254533</a> - Tarantool 1.6 - let's start </li><li>  <a href="http://emptysqua.re/blog/greenletprofiler/">emptysqua.re/blog/greenletprofiler</a> - profiler for gevent </li><li>  <a href="https://code.google.com/p/yappi/">code.google.com/p/yappi</a> - another profiler </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/202832/">habrahabr.ru/company/mailru/blog/202832</a> - article about profiling Python code </li><li>  <a href="https://docs.python.org/3/library/asyncio.html">docs.python.org/3/library/asyncio.html</a> - documentation for asyncio </li><li>  <a href="http://asyncio.org/">asyncio.org</a> - examples of ready-made libraries </li><li>  <a href="http://www.gevent.org/">www.gevent.org</a> - gevent </li></ul><br>  And, of course, versions of connectors for Tarantool: <br><ul><li>  <a href="https://github.com/shveenkov/aiotarantool">github.com/shveenkov/aiotarantool</a> </li><li>  <a href="https://github.com/shveenkov/gtarantool">github.com/shveenkov/gtarantool</a> </li></ul><br>  It's time to try them in your case! </div><p>Source: <a href="https://habr.com/ru/post/254727/">https://habr.com/ru/post/254727/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../254713/index.html">Even more jQuery?</a></li>
<li><a href="../254715/index.html">What are good free monads</a></li>
<li><a href="../254717/index.html">On middleware</a></li>
<li><a href="../254719/index.html">The Bresenham algorithm in a soldering furnace - theory</a></li>
<li><a href="../254721/index.html">Practical use of a small vocabulary</a></li>
<li><a href="../254731/index.html">Improving xaml: Bindable Converters, Switch Converter, Sets</a></li>
<li><a href="../254733/index.html">Using Asterisk to receive data from security systems</a></li>
<li><a href="../254737/index.html">Talking panda or what can be done with FFmpeg and OpenCV on Android</a></li>
<li><a href="../254739/index.html">Techno-Designed Alarm Clock - Arduino Based Desk Clock</a></li>
<li><a href="../254741/index.html">Traffic Inspector: full reboot</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>