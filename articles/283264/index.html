<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Search for the spine line in photos of book spreads</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When shooting a book spread with the help of a camera of a mobile device, inevitably some of the following defects appear (and maybe all at once): 

 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Search for the spine line in photos of book spreads</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/b2c/674/d84/b2c674d841f14d5d8d563eeb39d08306.jpg" align="left">  When shooting a book spread with the help of a camera of a mobile device, inevitably some of the following defects appear (and maybe all at once): <br><br>  ‚Ä¢ digital noise, <br>  ‚Ä¢ shadows and highlights, <br>  ‚Ä¢ defocusing and lubrication, <br>  ‚Ä¢ skew <br>  ‚Ä¢ perspective distortion, <br>  ‚Ä¢ curved lines <br>  ‚Ä¢ extra objects in the frame. <br><br>  Processing such photos for the subsequent OCR is a rather laborious task, even for a person who is well versed in Photoshop skills.  What if we want to do this automatically using the program?  Immediately make a reservation that a detailed description of all stages of the algorithm would make the publication too voluminous, so we will now tell only how to solve one of the subtasks - to find the spine line in such photos.  We <a href="https://habrahabr.ru/company/abbyy/blog/218285/">already told</a> about how to eliminate shadows and glares in photos.  Many articles have been written about eliminating digital noise.  And about the automatic correction of perspectives and curved rows, we will tell you next time. <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      At first glance, the task is not difficult: we select all the contours in the image using one of the gradient operators (for example, Sobel) and look for the strongest and longest of them using the Hough transform: <br><br><img src="https://habrastorage.org/files/907/6d2/ab7/9076d2ab7309430e8d164d3c7f92325b.jpg"><br><br><img src="https://habrastorage.org/files/d53/e59/c9d/d53e59c9da304b01931de4c7260e550f.jpg"><br><br>  We need to find the brightest pixel in the picture on the right and get the equation of the line from its coordinates.  And it's all?  Someone may decide that you can still reduce the image first so as not to do all this in an image of 5-10 megapixels.  But something suggests that it will not always work so easily.  Consider the possible situations: <br><br>  The spine has no shadow: <br><br><img src="https://habrastorage.org/files/b77/30c/2dc/b7730c2dc2fc46c0ab3cc0bb110e8033.jpg"><br><br>  On the page there is a photo with a dark frame: <br><br><img src="https://habrastorage.org/files/2c4/916/fae/2c4916fae9a44218975402367797d93a.jpg"><br><br>  Or just a big dark photo: <br><br><img src="https://habrastorage.org/files/683/63a/1e0/68363a1e0955424fabb0ab442d39a20a.jpg"><br><br>  Table: <br><br><img src="https://habrastorage.org/files/2ec/9eb/016/2ec9eb016268456487595ad7f8cc244f.jpg"><br><br>  Multicolumn text with separators: <br><br><img src="https://habrastorage.org/files/583/4c5/057/5834c5057be0402aabe9b17182723746.jpg"><br><br>  In such situations, the trivial algorithm given above will err too often.  Let's try to improve it a little and take into account the examples given. <br><br><h1>  Pre-processing to emphasize a weak shadow at the spine </h1><br>  We convert the image into a halftone (gray) and apply the UnsharpMask filter with the following parameters: radius = 41, strength = 300. <br><br><img src="https://habrastorage.org/files/28d/936/cc2/28d936cc2d6c466c9f49ac940df98487.jpg"><br><br><h1>  Quickly determine the orientation of text lines </h1><br>  To determine in which direction we should cut the image, we look for the direction of the lines of text.  This can be done on the binarized image from the histograms of the lengths of the white RLE-strokes.  It is known that the distance between lines is usually greater than the spacing between letters in a multi-line text (otherwise it would be difficult to read).  The bar length length histogram should be collected over the area of ‚Äã‚Äãthe image containing the text.  You can use the simplest classifier of text blocks or simply retreat from the edges of the image by 10-15% so that the fields and the background do not ‚Äúobscure‚Äù the collected statistics.  Denote the sum of the areas of horizontal white strokes having a length not exceeding a certain threshold L, as S <sub>h</sub> , and the sum of the areas of vertical strokes as S <sub>v</sub> .  Then, by changing the threshold L, we can follow the ratio max (S <sub>h</sub> , S <sub>v</sub> ) / min (S <sub>h</sub> , S <sub>v</sub> ), and as soon as it becomes greater than 2, we can say with confidence that we have found the letter spacing.  And at the same time they determined the direction of the lines: if max (S <sub>h</sub> , S <sub>v</sub> ) = S <sub>h</sub> , it is horizontal, otherwise it is vertical.  We took the ratio equal to 2, so as not to make too many gaps in the definition of orientation and at the same time, not to be mistaken too often.  By changing this value, you can get different points on the precision / recall graph.  You can use additional features from the same histograms.  In cases where we fail to determine the orientation in a uniquely simple way, we launch a search for a strong root (shadow) hypothesis in both directions (horizontal and vertical) and evaluate the direction of the text lines as perpendicular to the direction of the root, which has a stronger response. <br><br><img src="https://habrastorage.org/files/bde/b4e/bad/bdeb4ebadb9c46e5a4ae7216f3f6dbbf.png"><br><br><h1>  Strong hypothesis (shadow) </h1><br>  Suppose there is a shadow in the photograph in the spine.  Prepare an image to search for this line: <br><br>  a) reduce the image to a specified size, for example, to 800 pixels on the long side; <br>  b) we get rid of large shadows with the help of the morphological operation TopHat: we subtract its opening from the original image, i.e.  build-up from erosion (r = 5), by signal = 1 we mean black, and white background = 0; <br>  c) we remove the lines (short vertical black strokes) with the help of vertical erosion (r = 3); <br>  d) after receiving the image of the lines as the difference between the two previous results, we use it as a penalty, adding to the current one. <br><br>  a) <img src="https://habrastorage.org/files/476/917/bf1/476917bf1ac546b18804cf7296c17ccc.jpg"><br><br>  b) <img src="https://habrastorage.org/files/d7f/ea6/305/d7fea630575145e798eb5da4e4deff7e.jpg"><br><br>  c) <img src="https://habrastorage.org/files/522/05a/4fc/52205a4fcb484b84bb4ebbb8991ebff4.jpg"><br><br>  d) <img src="https://habrastorage.org/files/255/120/ff9/255120ff998d472081ec98fd612ba619.jpg"><br><br>  We apply the fast Hough transform to the last image and look for the global maximum in the inverted image: <br><br><img src="https://habrastorage.org/files/364/ff0/799/364ff079913845c48230802053d7b7c7.jpg"><br><br>  You can take into account the statistical distribution of the angle from the vertical and horizontal displacement of the spine line.  As a rule, in 99.9% of cases the angle does not exceed 20‚Äì25 degrees in absolute value, and the middle of the spine line has a coordinate from w / 3 to 2w / 3 (w is the image width).  In this case, the extreme values ‚Äã‚Äãof angles and coordinates are much less likely than the average.  It is possible to take into account this distribution in the values ‚Äã‚Äãof points in the Hough space, imposing a penalty for deviation from the most likely position in the angle and coordinate (0, w / 2). <br><br>  If the found global maximum exceeds the threshold for the detection of a strong hypothesis, we assume that we have found the line of the root along the shadow.  In this case, we transform the coordinates of the maximum into the equation of the line.  We select the threshold value experimentally on a large sample of photos, minimizing the number of errors and omissions. <br><br><h1>  Weak hypothesis (lumen) </h1><br>  With a selected threshold value, in about 10% of cases, a strong hypothesis does not find a solution.  As we know, the shadow may be absent in the spine.  This can happen with a strong reversal of the turn or if a flash was used when shooting.  Let's try to find the line of the spine in the central lumen. <br><br>  We calculate the gradient modulus (b) on a reduced half-tone image (a) (Sobel operator): <br><br>  a) <img src="https://habrastorage.org/files/e5f/0b5/fa4/e5f0b5fa44ba43c2813fe9afee6869d0.jpg"><br><br>  b) <img src="https://habrastorage.org/files/ce5/659/5a2/ce56595a27824e2fbf7a6e7d30eb825f.jpg"><br><br>  Here another example was specially chosen, since  the presence of a strong shadow will interfere with this algorithm. <br><br>  On the binarized image c) we glue the text into blocks using the morphological operation of dilation (d, r = 6 for an image of 800 pixels).  Apply the resulting mask of text areas to the image of the modulus of the gradient (e, the signal was amplified 4 times). <br><br>  c) <img src="https://habrastorage.org/files/041/581/8a3/0415818a30eb4db281060d8cc86cc5b8.jpg"><br><br>  d) <img src="https://habrastorage.org/files/bfe/626/9da/bfe6269da57c4ae7bc9a1afafcb1098d.jpg"><br><br>  e) <img src="https://habrastorage.org/files/fb6/226/9cf/fb62269cf5f74fb483bd6b29a4509aef.jpg"><br><br>  Now, smooth the mask of text areas (d) with Gaussian blur (f) (r = 8) and add to it the resulting enhanced gradient of non-text areas (g). <br><br>  f) <img src="https://habrastorage.org/files/527/cd6/2d6/527cd62d640a41d89d1a289d91ce30db.jpg"><br><br>  g) <img src="https://habrastorage.org/files/4fd/603/9d6/4fd6039d61004e6d93e05f874775f1aa.jpg"><br><br>  Now we have an image where the spine line, if it contains at least a weak gradient, gives an additional contribution to the signal of the lumen region.  If there is no gradient, i.e.  If there is no visible line in the image, we will select a line that is sufficiently distant from the text on both sides due to Gaussian blur.  With a narrow spine, it will be approximately in the middle. <br><br>  To search for the line, we will again apply the Hough transform, and look for the global maximum, taking into account the statistical distribution of the angle and offset: <br><br><img src="https://habrastorage.org/files/be8/c69/871/be8c698712e74e718b4dae8f5a13b5b6.jpg"><br><br>  The coordinates of the maximum transform into the equation of the line of the spine.  Done! <br><br>  This simple algorithm on the basis of&gt; 1800 photos of book spreads available in our database gives less than 1.5% errors. <br><br>  Of course, there are many opportunities to improve it: you can select additional features in the image, calculate not two hypotheses sequentially, but several at once, evaluate their mutual arrangement, select objects in the image (lines, separators) and analyze them ... the moment there will be a need to once again expand the training (and test!) sample in order to avoid possible retraining.  All this is an endless struggle for the quality of the algorithm. <br><br>  Solving the problem of finding the line of the spine, we forgot to say, but why do we even need it?  Why do I need to look for this line in the photo?  Very simple: the spine line allows you to eliminate the skew, i.e.  rotate the image so that this line becomes vertical, it divides the image into two pages for the subsequent application of the row extension algorithm, it helps to identify perspective distortions (although it will need to find more perspective vanishing points).  In general, without solving this problem, it is hardly possible to prepare such photographs for the subsequent OCR.  These algorithms have already found their use in the BookScan technology, which is part of our mobile application <a href="http://qrs.ly/ls55i9u">ABBYY FineScanner</a> . </div><p>Source: <a href="https://habr.com/ru/post/283264/">https://habr.com/ru/post/283264/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../283254/index.html">9 secrets of online payments. Part 6: one click payment</a></li>
<li><a href="../283256/index.html">Trend Analysis in Mobile Broadband Access (MBB)</a></li>
<li><a href="../283258/index.html">[Peter] Meeting about OpenOnload: high-performance network stack for Linux</a></li>
<li><a href="../283260/index.html">Perfect - REST server on Swift</a></li>
<li><a href="../283262/index.html">Paul Graham, ‚ÄúHackers and Artists,‚Äù Chapter 5: The Other Road Ahead, continued</a></li>
<li><a href="../283270/index.html">Analysis of the tasks of the first qualifying round of the RCC 2016</a></li>
<li><a href="../283274/index.html">There are no hares under Android - the history of creation</a></li>
<li><a href="../283276/index.html">Veeam Backup & Replication: workaround for one problem with backup job metadata</a></li>
<li><a href="../283278/index.html">[PF] Print PDF under .NET, vector approach, theory</a></li>
<li><a href="../283280/index.html">Product design digest, April 2016</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>