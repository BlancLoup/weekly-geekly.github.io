<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Coding and testing kNN in Julia</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="New language in Data Science. In Russia, Julia is a rather rare language, although it has been used abroad for 5 years (I was also surprised). There a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Coding and testing kNN in Julia</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/hx/ll/o1/hxllo1o7cjoe3cc4qu5ozcz-_lk.jpeg"><br><br>  New language in Data Science.  In Russia, Julia is a rather rare language, although it has been used abroad for 5 years (I was also surprised).  There are no sources in Russian, so I decided to make an illustrative example of the work of Julia, taken from one wonderful book.  The best way to learn a language is to write something on it.  <s>And so that it also attracted attention, use machine learning.</s> <br><a name="habracut"></a><br>  Hello Habrozhitelyami. <br><br>  Some time ago I started learning a new language Julia.  Well, like new.  This is something between Matlab and Python, the syntax is very similar, and the language itself is written in C / C ++.  In general, the history of creation, what, why and why is on Wikipedia and in a couple of articles on Habr√©. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The first thing that started my language study was right, I naguglitla Coursera <a href="https://www.coursera.org/learn/julia-programming">online course</a> in English.  There, about the basic syntax + in parallel, a mini-project on the prediction of diseases in Africa is being written.  Basics and immediately practice.  If you need a certificate, buy the full version.  I was free.  The difference of this version is that no one will check your tests and DM.  It was more important for me to get familiarization than a certificate.  (Read squeezed 50 bucks) <br><br>  After I decided that I should read a book on Julia.  Google issued a list of books and further studying reviews and reviews, chose one of them and ordered it on Amazon.  Book versions are always more pleasant to read and crayon in them. <br><br>  The book is called <a href="https://www.amazon.com/Julia-Data-Science-Zacharias-Voulgaris/dp/1634621301/ref%3Dpd_lpo_sbs_14_t_0%3F_encoding%3DUTF8%26psc%3D1%26refRID%3DFNKKBP440NNQ4HC7S8GD">Julia for Data Science</a> , by Zacharias Voulgaris, PhD.  The excerpt, which I want to submit, contains many typos in the code, which I corrected and therefore present the working version + my results. <br><br><h3>  kNN </h3><br>  This is an example of the application of the classification algorithm of the method of nearest neighbors.  Probably one of the oldest machine learning algorithms.  The algorithm does not have a learning phase and is also quite fast.  Its meaning is quite simple: in order to classify a new object, you need to find similar ‚Äúneighbors‚Äù from the data set (base) and then determine the class by voting. <br><br>  I‚Äôll make a reservation at once that there are ready-made packages in Julia, and it‚Äôs better to use them to reduce time and reduce errors.  But this code is, in some way, indicative of the Julia syntax.  It is more convenient for me to learn a new language in examples, rather than reading the dry excerpts of the general form of a particular function. <br><br>  So, what we have at the entrance: <br><br>  <i>Training data X</i> (training sample), <i>training data labels x</i> (corresponding tags), <i>testing data Y</i> (test sample), <i>number of neighbors k</i> (number of neighbors). <br><br>  Three functions will be needed: <i>distance calculation function, classification function</i> and <i>main</i> . <br><br>  The essence is this: we take one element of the test array, we calculate the distances from it to the elements of the training array.  Then we select the indices of those <i>k</i> elements that turned out to be as close as possible.  The tested element is assigned to the class that is the most common among the <i>k</i> nearest neighbors. <br><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> CalculateDistance{T&lt;:Number}(x::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{T,<span class="hljs-number"><span class="hljs-number">1</span></span>}, y::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{T,<span class="hljs-number"><span class="hljs-number">1</span></span>}) dist = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:length(x) dist += (x[i] - y[i])^<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> dist = sqrt(dist) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dist <span class="hljs-keyword"><span class="hljs-keyword">end</span></span></code> </pre> <br>  The main function of the algorithm.  The input is a matrix of distances between the objects of the training and test sample, the tags of the training sample, the number of the nearest "neighbors".  The output predicted labels for new objects and the likelihood of each label. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> Classify{T&lt;:<span class="hljs-keyword"><span class="hljs-keyword">Any</span></span>}(distances::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{Float64,<span class="hljs-number"><span class="hljs-number">1</span></span>}, labels::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{T,<span class="hljs-number"><span class="hljs-number">1</span></span>}, k::<span class="hljs-type"><span class="hljs-type">Int</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">unique</span></span>(labels) nc = length(<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>) #number <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> classes indexes = <span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>(<span class="hljs-type"><span class="hljs-type">Int</span></span>,k) #initialize vector <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> indexes <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> the nearest neighbors M = typemax(typeof(distances[<span class="hljs-number"><span class="hljs-number">1</span></span>])) #the largest possible number that this vector can have class_count = zeros(<span class="hljs-type"><span class="hljs-type">Int</span></span>, nc) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:k indexes[i] = indmin(distances) #<span class="hljs-keyword"><span class="hljs-keyword">returns</span></span> <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> the minimum element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a collection distances[indexes[i]] = M #make sure this element <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> selected again <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> klabels = labels[indexes] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:nc <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:k <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> klabels[j] == <span class="hljs-keyword"><span class="hljs-keyword">class</span></span>[i] class_count[i] +=<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> m, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> = findmax(class_count) conf = m/k #confidence <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> prediction <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span>[<span class="hljs-keyword"><span class="hljs-keyword">index</span></span>], conf <span class="hljs-keyword"><span class="hljs-keyword">end</span></span></code> </pre><br>  And of course, all the functions. <br><br>  At the input we will have a training sample <i>X</i> , a label of training sample <i>x</i> , a test sample <i>Y</i> and the number of ‚Äúneighbors‚Äù <i>k</i> . <br><br>  At the output we will receive the predicted labels and the corresponding probabilities of awarding each class. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> main{T1&lt;:Number, T2&lt;:<span class="hljs-keyword"><span class="hljs-keyword">Any</span></span>}(X::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{T1,<span class="hljs-number"><span class="hljs-number">2</span></span>}, x::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{T2,<span class="hljs-number"><span class="hljs-number">1</span></span>}, Y::<span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>{T1,<span class="hljs-number"><span class="hljs-number">2</span></span>}, k::<span class="hljs-type"><span class="hljs-type">Int</span></span>) N = size(X,<span class="hljs-number"><span class="hljs-number">1</span></span>) n = size(Y,<span class="hljs-number"><span class="hljs-number">1</span></span>) D = <span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>(Float64,N) #initialize distance matrix z = <span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>(eltype(x),n) #initialize labels vector c = <span class="hljs-keyword"><span class="hljs-keyword">Array</span></span>(Float64, n) #confidence <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> prediction <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:N D[j] = CalculateDistance(X[j,:], vec(Y[i,:])) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> z[i], c[i] = Classify(D,x,k) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z, c <span class="hljs-keyword"><span class="hljs-keyword">end</span></span></code> </pre><br><h3>  Testing </h3><br>  Let's test what we did.  For convenience, the algorithm will be saved in the file kNN.jl. <br><br>  The base is borrowed from the <a href="https://medium.com/open-machine-learning-course">Open Machine Learning Course</a> .  The data set is called Samsung Human Activity Recognition.  The data comes from accelerometers and gyroscopes on the Samsung Galaxy S3 mobile phones, and the type of human activity with a phone in his pocket is also known - whether he walked, stood, lay, sat or walked up / down the stairs.  We solve the problem of determining the type of physical activity precisely as a classification problem. <br><br>  The tags will correspond to the following: <br>  1 - walking <br>  2 - climb up the stairs <br>  3 - descend the stairs <br>  4 - seat <br>  5 - a man stood at this time <br>  6 - lay man <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">include</span></span>("kNN.jl") training = readdlm("samsung_train.txt"); training_label = readdlm("samsung_train_labels.txt"); testing = readdlm("samsung_test.txt"); testing_label = readdlm("samsung_test_labels.txt"); training_label = map(<span class="hljs-type"><span class="hljs-type">Int</span></span>, training_label) testing_label = map(<span class="hljs-type"><span class="hljs-type">Int</span></span>, testing_label) z = main(training, vec(training_label), testing, <span class="hljs-number"><span class="hljs-number">7</span></span>) n = length(testing_label) println(sum(testing_label .== z[<span class="hljs-number"><span class="hljs-number">1</span></span>]) / n)</code> </pre><br>  <i><u>Result:</u> 0.9053274516457415</i> <br><br>  Quality is evaluated by the ratio of correctly predicted objects to the entire test sample.  It seems not so bad.  But my goal is rather to show Julia, and that he has a place to be in Data Science. <br><br><h3>  Visualization </h3><br>  Then I wanted to try to visualize the results of the classification.  For this you need to build a two-dimensional image, with 561 signs and not knowing which of them is the most revealing.  Therefore, it was decided to use <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principal Component Analysis</a> (PCA) to reduce the dimension and then project the data onto the orthogonal subspace of features.  In Julia, as in Python, there are ready-made packages, so we can simplify our life a bit. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> MultivariateStats #<span class="hljs-keyword"><span class="hljs-keyword">for</span></span> PCA A = testing[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span>,:] #PCA <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> A M_A = fit(PCA, A<span class="hljs-string"><span class="hljs-string">'; maxoutdim = 2) Jtr_A = transform(M_A, A'</span></span>); #PCA <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> training M = fit(PCA, training<span class="hljs-string"><span class="hljs-string">'; maxoutdim = 2) Jtr = transform(M, training'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> Gadfly #shows training points <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> uncertain <span class="hljs-type"><span class="hljs-type">point</span></span> pl1 = plot(training, layer(x = Jtr[<span class="hljs-number"><span class="hljs-number">1</span></span>,:], y = Jtr[<span class="hljs-number"><span class="hljs-number">2</span></span>,:],color = training_label, Geom.point), layer(x = Jtr_A[<span class="hljs-number"><span class="hljs-number">1</span></span>,:], y = Jtr_A[<span class="hljs-number"><span class="hljs-number">2</span></span>,:], Geom.point)) #predicted <span class="hljs-keyword"><span class="hljs-keyword">values</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> uncertain points <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> testing data z1 = main(training, vec(training_label), A, <span class="hljs-number"><span class="hljs-number">7</span></span>) pl2 = plot(training, layer(x = Jtr[<span class="hljs-number"><span class="hljs-number">1</span></span>,:], y = Jtr[<span class="hljs-number"><span class="hljs-number">2</span></span>,:],color = training_label, Geom.point), layer(x = Jtr_A[<span class="hljs-number"><span class="hljs-number">1</span></span>,:], y = Jtr_A[<span class="hljs-number"><span class="hljs-number">2</span></span>,:],color = z[<span class="hljs-number"><span class="hljs-number">1</span></span>], Geom.point)) vstack(pl1, pl2)</code> </pre><br>  In the first picture, a training sample is laid out and several objects from the test sample that will need to be assigned to their class.  Accordingly, the second figure shows that these objects were marked up. <br><br><img src="https://habrastorage.org/webt/uh/zw/31/uhzw311gbulqnu5dokanhemvpc0.png"><br><img src="https://habrastorage.org/webt/qv/jl/w3/qvjlw39ux5t7dgq-ahepadrhutq.png"><br><br><pre> <code class="hljs markdown">println(z[<span class="hljs-string"><span class="hljs-string">1</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">1:10</span></span>], z[<span class="hljs-string"><span class="hljs-string">2</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">1:10</span></span>]) &gt; [<span class="hljs-string"><span class="hljs-string">5, 5, 5, 5, 5, 5, 5, 5, 5, 4</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">1.0, 0.888889, 0.888889, 0.888889, 1.0, 1.0, 1.0, 1.0, 0.777778, 0.555556</span></span>]</code> </pre><br>  Looking at the images, I want to ask the question "why are such clusters ugly?".  I will explain.  Individual clusters are not very clearly demarcated due to the nature of the data and the use of PCA.  For PCA, just walking and walking upstairs is like one class ‚Äî movement class.  Accordingly, the second class is the rest class (sitting, standing, lying, which are not very distinguishable between them).  And so a clear division can be traced to two classes instead of six. <br><br><h3>  Conclusion </h3><br>  For me, this is just the initial immersion in Julia and the use of this language in machine learning.  By the way, in which I am also rather an amateur than a professional.  But while I'm interested, I will continue to study this matter deeper.  Many foreign sources place bets on Julia.  Well, wait and see. <br><br>  PS: If it is interesting, I can in the following posts tell about the features of the syntax, about the IDE, with the installation of which I had problems. </div><p>Source: <a href="https://habr.com/ru/post/417967/">https://habr.com/ru/post/417967/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../417955/index.html">How to become an interface designer. Necessary skills and powerful tools that we are not told about</a></li>
<li><a href="../417957/index.html">Open webinar "Linux containerization mechanisms"</a></li>
<li><a href="../417959/index.html">10 interface design tips</a></li>
<li><a href="../417963/index.html">Wind, locust and deadline: how we built the power substation</a></li>
<li><a href="../417965/index.html">Open lesson "Writing our library to work with xlsx files"</a></li>
<li><a href="../417969/index.html">My turn is the slowest: businesses are trying to get rid of queues</a></li>
<li><a href="../417971/index.html">Time-to-Market as a trump card for the introduction of DevOps</a></li>
<li><a href="../417973/index.html">Ask Ethan: Which films correctly show time travel?</a></li>
<li><a href="../417975/index.html">Execute can not be pardoned</a></li>
<li><a href="../417977/index.html">Results Discussions on the topic: Personal, Team and Organizational Thinking ‚Äù(LAF 2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>