<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Experience of moving to a Single Page Application with an emphasis on SEO</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello to all. 


 We are a classic web 2.0 site made on Drupal. We can say that we are a media site, because we have a lot of various articles, and ne...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Experience of moving to a Single Page Application with an emphasis on SEO</h1><div class="post__text post__text-html js-mediator-article"><p>  Hello to all. </p><br><p>  We are a classic web 2.0 site made on Drupal.  We can say that we are a media site, because  we have a lot of various articles, and new ones are constantly coming out.  We pay a lot of attention to SEO.  We even have specially trained people who work full time for this. </p><br><p>  More than 400k unique users come to us per month.  Of these, 90% comes from Google search. </p><br><p>  And now, for almost half a year, we have developed the <a href="https://en.wikipedia.org/wiki/Single-page_application">Single Page Application</a> version of our site. </p><br><p>  As you probably already know, JS is the eternal pain of SEOs.  And you can not just take and make a site on JS. </p><br><p>  Before starting the development, we began to explore this question. <br>  And they found out that the generally accepted way is to give the google bot a rendered version of the page. <br>  <a href="https://developers.google.com/webmasters/ajax-crawling/docs/learn-more">Making AJAX applications crawlable</a> </p><br><p>  It also turned out that this method is <a href="https://webmasters.googleblog.com/2015/10/deprecating-our-ajax-crawling-scheme.html">no longer recommended by Google</a> and they assure that their bot can open js sites, not worse than modern browsers. </p><br><blockquote>  Understand your web pages like modern browsers. </blockquote><br><p>  Since  at the time of our decision, Google had just abandoned this method, and no one had yet time to check how Google Crawler actually indexes websites made in JS.  We decided to take a chance and make a SPA site without additional page rendering for bots. </p><a name="habracut"></a><br><h2>  What for? </h2><br><p>  Due to the uneven load on the server, and the inability to flexibly optimize pages, it was decided to divide the site into a backend (current version on Drupal) and a frontend (SPA on AngularJS). </p><br><p>  Drupal will be used exclusively for moderating content and sending all kinds of mail. <br>  AngularJS will draw everything that should be available to users of the site. </p><br><h2>  Technical details </h2><br><p>  As a server for the frontend, it was decided to use <a href="https://nodejs.org/">Node.js</a> + <a href="http://expressjs.com/">Express</a> . </p><br><h3>  REST Server </h3><br><p>  From Drupal, we made a REST server by simply creating a new prefix / v1 / <em>i.</em>  <em>all requests coming to / v1 / were</em> perceived as requests to REST.  All other addresses remain unchanged. </p><br><h3>  Page addresses </h3><br><p> It is very important for us that all public pages live at the same addresses as before.  Therefore, before developing the SPA version, we structured all the pages so that they have common prefixes.  For example: <br>  All forum pages should live at / forum / *, while the forum has categories and the topics themselves.  For them, the url will look like this <code>/forum/{category}/{topic}</code> .  There should be no random pages at random addresses, everything should be logically structured. </p><br><h3>  Redirects </h3><br><p>  The site has been available since 2007, and during that time a lot has changed.  Including page addresses.  We have saved the whole story, as the pages moved from one address to another.  And when you try to request any old address, you will be forwarded to a new one. </p><br><p>  In order for the new frontend to also redirect, we before sending the page to the nodejs send the request back to Drupal, and ask what is the status of the requested address.  It looks like this: </p><br><pre> <code class="hljs scala">curl -<span class="hljs-type"><span class="hljs-type">X</span></span> <span class="hljs-type"><span class="hljs-type">GET</span></span> --header <span class="hljs-symbol"><span class="hljs-symbol">'Accept</span></span>: application/json' <span class="hljs-symbol"><span class="hljs-symbol">'https</span></span>:<span class="hljs-comment"><span class="hljs-comment">//api.example.com/v1/path/lookup?url=node/1'</span></span></code> </pre> <br><p>  To which Drupal replies: </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>: <span class="hljs-number"><span class="hljs-number">301</span></span>, <span class="hljs-attr"><span class="hljs-attr">"url"</span></span>: <span class="hljs-string"><span class="hljs-string">"/content/industry/accountancy-professional-services/accountancy-professional-services"</span></span> }</code> </pre> <br><p>  After that, nodeJS decides to remain at the current address, if it is 200, or redirect to another address. </p><br><pre> <code class="hljs lua">app.get(<span class="hljs-string"><span class="hljs-string">'*'</span></span>, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(req, res)</span></span></span></span> { request.get({url: <span class="hljs-string"><span class="hljs-string">'https://api.example.com/v1/path/lookup'</span></span>, qs: {url: req.<span class="hljs-built_in"><span class="hljs-built_in">path</span></span>}, json: <span class="hljs-literal"><span class="hljs-literal">true</span></span>}, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(error, response, data)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!<span class="hljs-built_in"><span class="hljs-built_in">error</span></span> &amp;&amp; data.<span class="hljs-built_in"><span class="hljs-built_in">status</span></span>) { switch (data.<span class="hljs-built_in"><span class="hljs-built_in">status</span></span>) { case <span class="hljs-number"><span class="hljs-number">301</span></span>: case <span class="hljs-number"><span class="hljs-number">302</span></span>: res.redirect(data.<span class="hljs-built_in"><span class="hljs-built_in">status</span></span>, <span class="hljs-string"><span class="hljs-string">'https://www.example.com'</span></span> + data.url); <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; case <span class="hljs-number"><span class="hljs-number">404</span></span>: res.<span class="hljs-built_in"><span class="hljs-built_in">status</span></span>(<span class="hljs-number"><span class="hljs-number">404</span></span>); default: res.render(<span class="hljs-string"><span class="hljs-string">'index'</span></span>); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { res.<span class="hljs-built_in"><span class="hljs-built_in">status</span></span>(<span class="hljs-number"><span class="hljs-number">503</span></span>); } }); });</code> </pre> <br><h3>  Images </h3><br><p>  In the content coming from Drupal there may be files that do not exist in the frontend version.  That's why we decided to just stream them from Drupal through nodejs. </p><br><pre> <code class="hljs matlab">app.get([<span class="hljs-string"><span class="hljs-string">'*.png'</span></span>, <span class="hljs-string"><span class="hljs-string">'*.jpg'</span></span>, <span class="hljs-string"><span class="hljs-string">'*.gif'</span></span>, <span class="hljs-string"><span class="hljs-string">'*.pdf'</span></span>], <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(req, res)</span></span></span><span class="hljs-function"> { </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">request</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">('https://api.example.com' + req.url)</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pipe</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(res)</span></span></span><span class="hljs-function">; });</span></span></code> </pre> <br><h2>  sitemap.xml </h2><br><p>  Since  Since sitemap.xml is constantly generated in Drupal, and the page addresses match the frontend, it was decided to simply stream sitemap.xml.  Absolutely the same as with pictures: </p><br><pre> <code class="hljs matlab">app.get(<span class="hljs-string"><span class="hljs-string">'/sitemap.xml'</span></span>, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(req, res)</span></span></span><span class="hljs-function"> { </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">request</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">('https://api.example.com/sitemap.xml')</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pipe</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(res)</span></span></span><span class="hljs-function">; });</span></span></code> </pre> <br><p>  The only thing you should pay attention to is that Drupal substituted the correct address of the site that is used on the frontend.  There is a setting in the admin panel. </p><br><h2>  robots.txt </h2><br><ul><li>  The content available to the google crawler bot should not be duplicated between our two servers. </li><li>  All Drupal content requested through the frontend should be available for viewing by the bot. </li></ul><br><p>  As a result, our robots.txt looks like this: </p><br><p>  In Drupal, forbid everything except / v1 /: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">User</span></span>-agent: * Disallow: / Allow: /v1/</code> </pre> <br><p>  In the frontend, just allow everything: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">User</span></span>-agent: *</code> </pre> <br><h2>  Release preparation </h2><br><p>  Before the release, we placed the frontend version at <a href="https://new.example.com/">https://new.example.com</a> address. <br>  And for the Drupal version reserved additional subdomain <a href="https://api.example.com/">https://api.example.com/</a> </p><br><p>  After that, we linked the frontend so that it works with the <a href="https://api.example.com/">https://api.example.com/</a> address. </p><br><h2>  Release </h2><br><p>  The release itself looks like a simple rearrangement of servers in the DNS.  We point our current @ address to the frontend server.  Then we sit and see how everything works. </p><br><p>  It is worth noting that if you use <code>CNAME</code> records, the server will be replaced instantly.  Record <code>A</code> will resolve to DNS up to 48 hours. </p><br><h2>  Performance </h2><br><p>  After dividing the site into frontend and backend, the server load became measured.  It is also worth noting that we didn‚Äôt particularly optimize sql queries, all queries pass through without caching.  All optimization was planned after the release. </p><br><p>  I do not have a metric before the release, but there is a metric after we rolled back :) </p><br><p><img src="https://habrastorage.org/files/a5d/c51/3ea/a5dc513ea58a4bc0996771125dcb9b28.png" alt="Web transactions response time"></p><br><p><img src="https://habrastorage.org/files/2d6/14f/639/2d614f63929e4b69b268eba3543a30dd.png" alt="Throughput"></p><br><p><img src="https://habrastorage.org/files/489/f2f/c41/489f2fc412e04f23bdc30a233a448b58.png" alt="Top 5 database operations by wall clock time"></p><br><p><img src="https://habrastorage.org/files/8aa/076/688/8aa0766887dd41969a8d27e07397726d.png" alt="Database"></p><br><p><img src="https://habrastorage.org/files/c99/d13/46d/c99d1346d8ba4dc59bb46b88dede4c32.png" alt="Views usage"></p><br><h2>  SEO </h2><br><p>  Here everything was not as good as we would like.  After a little more than a week of testing, traffic to the site fell by 30%. </p><br><p><img src="https://habrastorage.org/files/d94/cb9/bfb/d94cb9bfb9ea491daa3092029954ccce.png" alt="google analytics"></p><br><p>  Some pages fell out of the google index, some became very oddly indexed, without meta description. </p><br><p>  An example of how Google has indexed <a href="https://www.wikijob.co.uk/content/interview-advice/interview-questions/what-are-your-weaknesses">this</a> page. <br><img src="https://habrastorage.org/files/920/6a9/9e7/9206a99e750b42069a025fcd4b6ee1db.png" alt="missing meta"></p><br><p>  We also noticed that after the release of the new site, Google noticed this, and began to pande the entire site.  Thereby updating all your cache. <br><img src="https://habrastorage.org/files/bb1/55e/48e/bb155e48e4a64696a0519f9702b208b0.png" alt="Crawl stats"></p><br><p>  After that, Crawler found a huge number of old pages, which should not have been in the index long ago. <br>  The graph below shows the graph found 404 pages.  It can be seen that before the release, we did a sweep of the content, and Google slowly deleted the old pages.  But after the release, he began to do it much more actively. <br><img src="https://habrastorage.org/files/b7d/b2b/c72/b7db2bc72ed346d190e1a54c69200e7a.png" alt="404's"></p><br><h2>  Result / Conclusions </h2><br><p>  Due to problems with indexing, it was decided to roll back to Drupal, and to think that we did wrong. </p><br><p>  Everything is complicated by the fact that google is a kind of black box, which, if something goes wrong, doesn't just remove the pages from the index.  And any of our experiments require a couple of days for this to be reflected in the search results. </p><br><p>  One of the more likely versions is that Google Crawler has certain limitations.  This can be a memory or a page rendering time. </p><br><p>  I made a small test by creating a page with a stopwatch, and tried to draw it as a crawler in the Google Search Console.  In the screenshot, the stopwatch stopped at 5.26 seconds.  I think the crawler waits for the page for about 5 seconds, and then it takes a snapshot, and everything loaded after - the index does not fit. </p><br><p><img src="https://habrastorage.org/files/a5f/a86/fa4/a5fa86fa42ad4b3a9cbebe16860b4e03.jpeg" alt="reverse engineering of google crawler bot"></p><br><h2>  useful links </h2><br><ul><li>  <a href="https://plus.google.com/%2BJohnMueller/posts/LT4fU7kFB8W">An update (March 2016) for JavaScript and JavaScript sites.</a> </li></ul><br><h2>  Update </h2><br><ul><li>  Added a chart from google analytics showing how traffic sank. </li><li>  I found out that Google Crawler has about 5 seconds to render the page. </li><li>  I found out that Google Crawler understands when the site is updated, and re-indexes it. </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/301288/">https://habr.com/ru/post/301288/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../301274/index.html">Fifth "Webmaster" right now</a></li>
<li><a href="../301276/index.html">Chew linear-square regulator to control the inverted pendulum</a></li>
<li><a href="../301278/index.html">Why automation of work with the client sometimes does not help, but hinders</a></li>
<li><a href="../301282/index.html">Router on Golang</a></li>
<li><a href="../301286/index.html">What are the bad sample solutions for ‚Äúquick launch‚Äù of your own business?</a></li>
<li><a href="../301290/index.html">UX for beginners: a practical guide. Part 1</a></li>
<li><a href="../301292/index.html">Yum, cheat sheet</a></li>
<li><a href="../301294/index.html">In Russia, launched the first accelerator for FMCG startups</a></li>
<li><a href="../301296/index.html">Air quality control (CO2 and temperature) in the office and at home, with their own hands</a></li>
<li><a href="../301298/index.html">Asynchronous Symphony: JavaFX Tasks and Netty Sockets</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>