<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We train a neural network written in TensorFlow in the cloud using Google Cloud ML and Cloud Shell</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the previous article, we discussed how to train a chat bot based on a recurrent neural network on an AWS GPU instance . Today we will see how easy ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We train a neural network written in TensorFlow in the cloud using Google Cloud ML and Cloud Shell</h1><div class="post__text post__text-html js-mediator-article">  In the previous article, we <a href="https://habrahabr.ru/post/317732">discussed how to train a chat bot based on a recurrent neural network on an AWS GPU instance</a> .  Today we will see how easy it is to train the same network using <a href="https://cloud.google.com/ml/">Google Cloud ML</a> and <a href="https://cloud.google.com/shell">Google Cloud Shell</a> .  Thanks to Google Cloud Shell, you won't need to do almost anything on your local computer!  By the way, we took the network from the previous article only for an example, you can safely take any other network that uses TensorFlow. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d39/895/da6/d39895da69d596c380e88f64e5ae88e2.png" alt="image"><br><a name="habracut"></a><br><h2>  Instead of the preface </h2><br>  Special thanks to <a href="https://www.patreon.com/b0noi">my patrons</a> who made this article possible: Aleksandr Shepeliev, Sergei Ten, Alexey Polietaiev, Nikita Penzin, Karnaukhov Andrey, Matveev Evgeny, Anton Potemkin. <br><br>  I tried to make the article a self-sufficient guide, but I strongly advise you to look at each link in order to understand what is happening under the hood, and not just copy and paste the commands step by step. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Prerequisites </h2><br>  There is only one requirement that the reader must satisfy in order to go through all the steps described in the article: to have a Google Cloud account with billing enabled, since we will use paid functionality. <br><br>  Let's begin our journey with answers to two main questions: <br><br><ul><li>  What is Google Cloud ML? </li><li>  What is Google Cloud Shell? </li></ul><br><h3>  What is Google Cloud ML? </h3><br>  <a href="https://cloud.google.com/ml/docs/">The official definition</a> says the following: <br><br><blockquote>  Google Cloud Machine Learning brings the cloud to the cloud.  If you‚Äôre using your data management tools, you can use your Google Cloud Platform. </blockquote><br>  I do not know about you, but this definition tells me very little.  Let me explain what Google Cloud ML can give you: <br><br><ul><li>  deploy your code in the cloud on a machine that has everything you need to learn the TensorFlow model; </li><li>  provide access to Google Cloud Storage baktema for your code on the machine in the cloud; </li><li>  run your learning code to execute; </li><li>  store a model in the cloud; </li><li>  use a trained model to predict future data. </li></ul><br>  The focus of this article will be on the first 3 points.  Later, in subsequent articles, we will look at how to deploy a trained model in Google Cloud ML and how to predict data using the cloud model. <br><br><h3>  What is Google Cloud Shell? </h3><br>  And again, the <a href="https://cloud.google.com/shell/docs/">official definition</a> : <br><br><blockquote>  Google Cloud Shell is a shell environment for Google Cloud Platform. </blockquote><br>  And again, I'll add a few details, Google Cloud Shell is: <br><br><ul><li>  cloud instance (type?) provided to you, </li><li>  with Debian OS on board, </li><li>  the Shell of which you can access via the Web, </li><li>  where is everything you need to work with Google Cloud. </li></ul><br>  Yes, you understood correctly, you have a completely free instance with Shell access, which you can access from your Web console. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/52a/e90/a70/52ae90a7012e90462df966eb8fbe59c3.png" alt="image"><br><br>  But nothing comes for free, in the case of Cloud Shell there are some offensive limitations - you can access it only through the Web console, and not via ssh (I personally don‚Äôt like to use any other terminals except iTerm).  I asked a question on StackOverflow, is <a href="http://stackoverflow.com/questions/41324702/is-it-possible-to-use-the-google-cloud-shell-via-a-ssh">it possible to use Cloud Shell via ssh</a> and, like, it‚Äôs impossible.  But at least there is a way to make your life easier by installing a special Chrome plugin, which, at a minimum, allows you to use the normal binding of the keys, so that the terminal works as a terminal, and not as a browser window (which means =)). <br><br>  More information about Cloud Shell features can be found <a href="https://cloud.google.com/shell/docs/features">here</a> . <br><br><h2>  The steps that we have to go: </h2><br><ul><li>  Cloud Shell preparation for training </li><li>  Cloud Storage Preparation </li><li>  Preparation of data for training </li><li>  Preparation of the training script </li><li>  Testing the learning process locally </li><li>  Training </li><li>  Talking with the bot </li></ul><br><h3>  Preparing Cloud Shell Environment for Learning </h3><br>  It's time to open the Cloud Shell.  If you haven‚Äôt done this before, it‚Äôs very simple, you need to open the console <a href="https://console.cloud.google.com/">console.cloud.google.com</a> and click on the Shell icon in the upper right corner: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e46/691/25b/e4669125bc398c8cb31f79991124c1be.png" alt="image"><br>  In case of any problems, <a href="https://cloud.google.com/shell/docs/starting-cloud-shell">here is a small instruction</a> that describes how to run the console in detail. <br><br>  <i>All subsequent examples will be run in Cloud Shell.</i> <br><br>  In addition, if this is your first time when you are going to use Cloud ML with Cloud Shell - you need to prepare all the necessary dependencies.  To do this, you need to execute just one line of code right in the Shell: <br><br><pre><code class="bash hljs">curl https://raw.githubusercontent.com/GoogleCloudPlatform/cloudml-samples/master/tools/setup_cloud_shell.sh | bash</code> </pre> <br>  It will install all the necessary packages. <br><br>  If at this stage everything stumbled on the pillow installation: <br><br><pre> <code class="bash hljs">Command <span class="hljs-string"><span class="hljs-string">"/usr/bin/python -u -c "</span></span>import setuptools, tokenize;__file__=<span class="hljs-string"><span class="hljs-string">'/tmp/pip-build-urImDr/olefile/setup.py'</span></span>;f=getattr(tokenize, <span class="hljs-string"><span class="hljs-string">'open'</span></span>, open)(__file__);code=fr ead().replace(<span class="hljs-string"><span class="hljs-string">'\r\n'</span></span>, <span class="hljs-string"><span class="hljs-string">'\n'</span></span>);f.close();<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>(compile(code, __file__, <span class="hljs-string"><span class="hljs-string">'exec'</span></span>))<span class="hljs-string"><span class="hljs-string">" build_ext --disable-jpeg install --record /tmp/pip-GHGxvS-record/install-record.txt - -single-version-externally-managed --compile --user --prefix="</span></span> failed with error code 1 <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /tmp/pip-build-urImDr/olefile/</code> </pre> <br>  This is a manual installation: <br><br><pre> <code class="bash hljs">pip install --user --upgrade pillow</code> </pre> <br>  Thanks for the tip @ Sp0tted_0wl.  Next you have to update the PATH variable: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">${HOME}</span></span>/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin:<span class="hljs-variable"><span class="hljs-variable">${PATH}</span></span></code> </pre> <br>  If this is the first time you use Cloud ML with the current project, you need to initialize the ML module.  This can be done in one line: <br><br><pre> <code class="bash hljs">‚ûú gcloud beta ml init-project Cloud ML needs to add its service accounts to your project (ml-lab-123456) as Editors. This will <span class="hljs-built_in"><span class="hljs-built_in">enable</span></span> Cloud Machine Learning to access resources <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> your project when running your training and prediction <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span>. Do you want to <span class="hljs-built_in"><span class="hljs-built_in">continue</span></span> (Y/n)? Added serviceAccount:cloud-ml-service@ml-lab-123456-1234a.iam.gserviceaccount.com as an Editor to project <span class="hljs-string"><span class="hljs-string">'ml-lab-123456'</span></span>.</code> </pre> <br>  To check whether everything is installed successfully, you need to run one simple command: <br><br><pre> <code class="bash hljs">‚ûú curl https://raw.githubusercontent.com/GoogleCloudPlatform/cloudml-samples/master/tools/check_environment.py | python ... You are using pip version 8.1.1, however version 9.0.1 is available. You should consider upgrading via the <span class="hljs-string"><span class="hljs-string">'pip install --upgrade pip'</span></span> <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>. You are using pip version 8.1.1, however version 9.0.1 is available. You should consider upgrading via the <span class="hljs-string"><span class="hljs-string">'pip install --upgrade pip'</span></span> <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>. Your active configuration is: [cloudshell-12345] Success! Your environment is configured</code> </pre> <br>  Now it's time to decide which Google Cloud project you will use for network training.  I have a special project for all my experiments with ML.  In any case, this is up to you, but I will show you my commands, which I use to switch between projects: <br><br><pre> <code class="bash hljs">‚ûú gprojects PROJECT_ID NAME PROJECT_NUMBER ml-lab-123456 ml-lab 123456789012 ... ‚ûú gproject ml-lab-123456 Updated property [core/project].</code> </pre> <br>  If you want to use the same magic, then you need to add the following to your .bashrc / .zshrc / other_rc file: <br><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gproject</span></span></span></span>() { gcloud config <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> project <span class="hljs-variable"><span class="hljs-variable">$1</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gprojects</span></span></span></span>() { gcloud projects list }</code> </pre> <br>  All right, if you are already here, it means that we have prepared Cloud Shell and moved on to the right project and now we can say with confidence that Cloud Shell has been prepared and we can proceed to the next step with a clear conscience. <br><br><h3>  Cloud Storage Preparation </h3><br>  First of all, you need to explain why we need cloud storage at all?  Since we will be teaching the model in the cloud, the learning process will not have any access to the local file system of your current machine.  This means that all the necessary source data must be stored somewhere in the cloud.  As well as the trained model will also need to be stored somewhere.  This somewhere cannot be the machine on which the training is going, for you have no access to it;  and can not be your car, because it does not have access to the learning process.  Such a vicious circle that can be broken by introducing a new link - cloud storage for data. <br><br>  Let's create a new cloud baket that will be used for training: <br><br><pre> <code class="bash hljs">‚ûú PROJECT_NAME=chatbot_generic ‚ûú TRAIN_BUCKET=gs://<span class="hljs-variable"><span class="hljs-variable">${PROJECT_NAME}</span></span> ‚ûú gsutil mb <span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span> Creating gs://chatbot_generic/...</code> </pre> <br>  Here I have to tell you something, if you look at the <a href="https://cloud.google.com/ml/docs/how-tos/getting-set-up">official manual</a> , you will find the following text there: <br><br><blockquote>  Warning: You must specify a region (like us-central1) for your bucket, not a multi-region location (like us). </blockquote><br>  Free translation: <br><br><blockquote>  Note: You must specify a region (us-central1) for your baket, not a multi-regional location as a country (for example: us). </blockquote><br>  However, if you use this advice and create a regional baket, the script will not be able to write something 0_o into it (to keep silence for the gussars, the <a href="https://github.com/tensorflow/tensorflow/issues/6493">bug is already written down</a> ). <br><br>  In an ideal world where everything works, it is expected that it is very important to establish a region, and it must correspond to the region that will be used during the training.  Otherwise, it can have a negative impact on the speed of learning. <br><br>  Now we are ready to prepare input data for the upcoming training. <br><br><h3>  Preparation of data for training </h3><br>  If you are using your own network, then this part probably can be omitted, well, or selectively read only the part where it is described where this data should be downloaded. <br><br>  This time (compared to the <a href="https://habrahabr.ru/post/317732/">previous article</a> ) we will use a slightly modified version of the script that prepares the input data.  I want to encourage you to read how the script works in the <a href="">readme</a> file.  But now, you can prepare the input data in the following way (you can replace ‚Äútd src‚Äù with ‚Äúmkdir src; cd src"): <br><br><pre> <code class="bash hljs">‚ûú td src ‚ûú ~/src$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/b0noI/dialog_converter.git Cloning into <span class="hljs-string"><span class="hljs-string">'dialog_converter'</span></span>... remote: Counting objects: 63, <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. remote: Compressing objects: 100% (4/4), <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. remote: Total 63 (delta 0), reused 0 (delta 0), pack-reused 59 Unpacking objects: 100% (63/63), <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. Checking connectivity... <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. ‚ûú ~/src$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> dialog_converter/ ‚ûú ~/src/dialog_converter$ git checkout converter_that_produces_test_data_as_well_as_train_data Branch converter_that_produces_test_data_as_well_as_train_data <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> up to track remote branch converter_that_produces_test_data_as_well_as_train_data from origin. Switched to a new branch <span class="hljs-string"><span class="hljs-string">'converter_that_produces_test_data_as_well_as_train_data'</span></span> ‚ûú ~/src/dialog_converter$ python converter.py ‚ûú ~/src/dialog_converter$ ls converter.py LICENSE movie_lines.txt README.md test.a test.b train.a train.b</code> </pre> <br>  Looking at the code above, you may ask, what is ‚Äútd‚Äù? .. This is just a short form ‚Äúto dir‚Äù, and this is one of the commands that I use most often.  In order for you to use this magic, you need to update the rc file by adding the following: <br><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">td</span></span></span></span>() { mkdir <span class="hljs-variable"><span class="hljs-variable">$1</span></span> <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> <span class="hljs-variable"><span class="hljs-variable">$1</span></span> }</code> </pre> <br>  This time we will improve the quality of our model by dividing the data into 2 samples: a training sample and a test one.  That is why we see four files instead of two, as it was the previous time. <br><br>  Great, we finally have the data, let's upload them to the baket: <br><br><pre> <code class="bash hljs">‚ûú ~/src/dialog_converter$ gsutil cp <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>.* <span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input Copying file://test.a [Content-Type=application/octet-stream]... Copying file://test.b [Content-Type=chemical/x-molconn-Z]... \ [2 files][ 2.8 MiB/ 2.8 MiB] 0.0 B/s Operation completed over 2 objects/2.8 MiB. ‚ûú ~/src/dialog_converter$ gsutil cp train.* <span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input Copying file://train.a [Content-Type=application/octet-stream]... Copying file://train.b [Content-Type=chemical/x-molconn-Z]... - [2 files][ 11.0 MiB/ 11.0 MiB] Operation completed over 2 objects/11.0 MiB. ‚ûú ~/src/dialog_converter$ gsutil ls <span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span> gs://chatbot_generic/input/ ‚ûú ~/src/dialog_converter$ gsutil ls <span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input gs://chatbot_generic/input/test.a gs://chatbot_generic/input/test.b gs://chatbot_generic/input/train.a gs://chatbot_generic/input/train.b</code> </pre> <br><h3>  Preparation of the training script </h3><br>  Now we can prepare a training script.  We will use <a href="https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/translate.py">translate.py</a> .  However, its current implementation does not allow using it with Cloud ML, so it is necessary to do a little refactoring.  As usual, I created a <a href="https://github.com/tensorflow/models/issues/814">feature request</a> and prepared a <a href="https://github.com/b0noI/models/tree/translate_tutorial_supports_google_cloud_ml">brunch with all the necessary changes</a> .  And so, let's start with the fact that we slope it: <br><br><pre> <code class="bash hljs">‚ûú ~/src/dialog_converter$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> .. ‚ûú ~/src$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/b0noI/models.git Cloning into <span class="hljs-string"><span class="hljs-string">'models'</span></span>... remote: Counting objects: 1813, <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. remote: Compressing objects: 100% (39/39), <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. remote: Total 1813 (delta 24), reused 0 (delta 0), pack-reused 1774 Receiving objects: 100% (1813/1813), 49.34 MiB | 39.19 MiB/s, <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. Resolving deltas: 100% (742/742), <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. Checking connectivity... <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. ‚ûú ~/src$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> models/ ‚ûú ~/src/models$ git checkout translate_tutorial_supports_google_cloud_ml Branch translate_tutorial_supports_google_cloud_ml <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> up to track remote branch translate_tutorial_supports_google_cloud_ml from origin. Switched to a new branch <span class="hljs-string"><span class="hljs-string">'translate_tutorial_supports_google_cloud_ml'</span></span> ‚ûú ~/src/models$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> tutorials/rnn/translate/</code> </pre> <br>  Please note that we use a non- <b>master</b> branch! <br><br><h3>  Testing the learning process locally </h3><br>  Since distance learning costs money, for testing, you can simulate the learning process locally.  The problem here is the truth is that local training of our network on a typewriter on which Cloud Shell is spinning will surely trample it into dirt and crush it.  And you have to overload the instance without seeing the result.  But do not worry, even in this case nothing will be lost.  Fortunately, our script has a self-test mode, which we can use.  Here's how to use it: <br><br><pre> <code class="bash hljs">‚ûú ~/src/models/tutorials/rnn/translate$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> .. ‚ûú ~/src/models/tutorials/rnn$ gcloud beta ml <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> train \ &gt; --package-path=translate \ &gt; --module-name=translate.translate \ &gt; -- \ &gt; --self_test Self-test <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> neural translation model.</code> </pre> <br>  Pay attention to the folder from which we execute the command! <br><br>  It looks like the self-test was completed successfully.  Let's talk about the keys that we used here: <br><br><ul><li>  package-path - the path to the python package that must be deployed on a remote machine in order to perform training; </li><li>  "-" - everything that follows will be sent as input arguments to your module; </li><li>  self_test - tells the module to run a self-test without actual training. </li></ul><br><h3>  Training </h3><br>  Finally we got to the most interesting part of the process, for which we, in fact, started all this.  But we still have a small detail, we need to prepare all the necessary buckets that will be used in the learning process and set all local variables: <br><br><pre> <code class="bash hljs">‚ûú ~/src/models/tutorials/rnn$ INPUT_TRAIN_DATA_A=<span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input/train.a ‚ûú ~/src/models/tutorials/rnn$ INPUT_TRAIN_DATA_B=<span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input/train.b ‚ûú ~/src/models/tutorials/rnn$ INPUT_TEST_DATA_A=<span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input/test.a ‚ûú ~/src/models/tutorials/rnn$ INPUT_TEST_DATA_B=<span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/input/test.b ‚ûú ~/src/models/tutorials/rnn$ JOB_NAME=<span class="hljs-variable"><span class="hljs-variable">${PROJECT_NAME}</span></span>_$(date +%Y%m%d_%H%M%S) ‚ûú ~/src/models/tutorials/rnn$ <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">${JOB_NAME}</span></span> chatbot_generic_20161224_203332 ‚ûú ~/src/models/tutorials/rnn$ TRAIN_PATH=<span class="hljs-variable"><span class="hljs-variable">${TRAIN_BUCKET}</span></span>/<span class="hljs-variable"><span class="hljs-variable">${JOB_NAME}</span></span> ‚ûú ~/src/models/tutorials/rnn$ <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">${TRAIN_PATH}</span></span> gs://chatbot_generic/chatbot_generic_20161224_203332</code> </pre> <br>  It is important to note here that the name of our remote work (JOB_NAME) must be unique each time we start learning.  Now let's change the current folder for translation (do not ask =)): <br><br><pre> <code class="bash hljs">‚ûú ~/src/models/tutorials/rnn$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> translate/</code> </pre> <br>  Now we are ready to start learning.  Let's write the command first (but we will not execute it) and discuss its main keys: <br><br><pre> <code class="bash hljs">gcloud beta ml <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span> submit training <span class="hljs-variable"><span class="hljs-variable">${JOB_NAME}</span></span> \ --package-path=. \ --module-name=translate.translate \ --staging-bucket=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_BUCKET}</span></span></span><span class="hljs-string">"</span></span> \ --region=us-central1 \ -- \ --from_train_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TRAIN_DATA_A}</span></span> \ --to_train_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TRAIN_DATA_B}</span></span> \ --from_dev_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TEST_DATA_A}</span></span> \ --to_dev_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TEST_DATA_B}</span></span> \ --train_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ --data_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ --steps_per_checkpoint=5 \ --from_vocab_size=45000 \ --to_vocab_size=45000</code> </pre> <br>  We first discuss some of the new flags of the training team: <br><br><ul><li>  staging-bucket - the bakt to be used during deployment;  it makes sense to use the same bake as for training; </li><li>  region - the region where you want to start the learning process. </li></ul><br>  Also let's touch on new flags that will be passed to the script: <br><br><ul><li>  from_train_data / to_train_data is the former en_train_data / fr_train_data, details can be found <a href="https://habrahabr.ru/post/317732/">in the last article</a> ; </li><li>  from_dev_data / to_dev_data is the same as from_train_data / to_train_data, but for test (or ‚Äúdev‚Äù, as they are called in the script) data that will be used to estimate losses after training; </li><li>  train_dir - folder where learning results will be saved; </li><li>  steps_per_checkpoint - how many steps must be performed before saving the temporary results.  5 - too small a value, I set it only to check that the learning process goes without any problems.  Later I will restart the process with a large value (200, for example); </li><li>  from_vocab_size / to_vocab_size - to understand what it is, you need to read the <a href="https://habrahabr.ru/post/317732/">previous article.</a>  There you find out that the default value (40k) is less than the number of unique words in the dialogs, therefore this time we increased the size of the dictionary. </li></ul><br>  It seems that everything is ready to start learning, so we start (you will need a little patience for the process takes some time) ... <br><br><pre> <code class="bash hljs">‚ûú ~/src/models/tutorials/rnn/translate$ gcloud beta ml <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span> submit training <span class="hljs-variable"><span class="hljs-variable">${JOB_NAME}</span></span> \ &gt; --package-path=. \ &gt; --module-name=translate.translate \ &gt; --staging-bucket=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_BUCKET}</span></span></span><span class="hljs-string">"</span></span> \ &gt; --region=us-central1 \ &gt; -- \ &gt; --from_train_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TRAIN_DATA_A}</span></span> \ &gt; --to_train_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TRAIN_DATA_B}</span></span> \ &gt; --from_dev_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TEST_DATA_A}</span></span> \ &gt; --to_dev_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TEST_DATA_B}</span></span> \ &gt; --train_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ &gt; --data_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ &gt; --steps_per_checkpoint=5 \ &gt; --from_vocab_size=45000 \ &gt; --to_vocab_size=45000 INFO 2016-12-24 20:49:24 -0800 unknown_task Validating job requirements... INFO 2016-12-24 20:49:25 -0800 unknown_task Job creation request has been successfully validated. INFO 2016-12-24 20:49:26 -0800 unknown_task Job chatbot_generic_20161224_203332 is queued. INFO 2016-12-24 20:49:31 -0800 service Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> job to be provisioned. INFO 2016-12-24 20:49:36 -0800 service Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> job to be provisioned. ... INFO 2016-12-24 20:53:15 -0800 service Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> job to be provisioned. INFO 2016-12-24 20:53:20 -0800 service Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> job to be provisioned. INFO 2016-12-24 20:53:20 -0800 service Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> TensorFlow to start. ... INFO 2016-12-24 20:54:56 -0800 master-replica-0 Successfully installed translate-0.0.0 INFO 2016-12-24 20:54:56 -0800 master-replica-0 Running <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>: python -m translate.translate --from_train_data=gs://chatbot_generic/input/train.a --to_train_data=gs://chatbot_generic/input/train.b --from_dev_data=gs://chatbot_generic/input/test.a --to_dev_data=gs://chatbot_generic/input/test.b --train_dir=gs://chatbot_generic/chatbot_generic_20161224_203332 --steps_per_checkpoint=5 --from_vocab_size=45000 --to_vocab_size=45000 INFO 2016-12-24 20:56:21 -0800 master-replica-0 Creating vocabulary /tmp/vocab45000 from data gs://chatbot_generic/input/train.b INFO 2016-12-24 20:56:21 -0800 master-replica-0 processing line 100000 INFO 2016-12-24 20:56:21 -0800 master-replica-0 Tokenizing data <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> gs://chatbot_generic/input/train.b INFO 2016-12-24 20:56:21 -0800 master-replica-0 tokenizing line 100000 INFO 2016-12-24 20:56:21 -0800 master-replica-0 Tokenizing data <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> gs://chatbot_generic/input/train.a INFO 2016-12-24 20:56:21 -0800 master-replica-0 tokenizing line 100000 INFO 2016-12-24 20:56:21 -0800 master-replica-0 Tokenizing data <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> gs://chatbot_generic/input/test.b INFO 2016-12-24 20:56:21 -0800 master-replica-0 Tokenizing data <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> gs://chatbot_generic/input/test.a INFO 2016-12-24 20:56:21 -0800 master-replica-0 Creating 3 layers of 1024 units. INFO 2016-12-24 20:56:21 -0800 master-replica-0 Created model with fresh parameters. INFO 2016-12-24 20:56:21 -0800 master-replica-0 Reading development and training data (<span class="hljs-built_in"><span class="hljs-built_in">limit</span></span>: 0). INFO 2016-12-24 20:56:21 -0800 master-replica-0 reading data line 100000</code> </pre> <br>  You can monitor the state of your learning.  To do this, simply open another tab in your Cloud Shell (or tmux window), then create the necessary variables and run the command: <br><br><pre> <code class="bash hljs">‚ûú JOB_NAME=chatbot_generic_20161224_213143 ‚ûú gcloud beta ml <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span> describe <span class="hljs-variable"><span class="hljs-variable">${JOB_NAME}</span></span> ...</code> </pre> <br>  Now, if everything goes well, we can stop the work and restart it with a large number of steps, for example 200, this is the default number.  The new team will look like this: <br><br><pre> <code class="bash hljs">‚ûú ~/src/models/tutorials/rnn/translate$ gcloud beta ml <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span> submit training <span class="hljs-variable"><span class="hljs-variable">${JOB_NAME}</span></span> \ &gt; --package-path=. \ &gt; --module-name=translate.translate \ &gt; --staging-bucket=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_BUCKET}</span></span></span><span class="hljs-string">"</span></span> \ &gt; --region=us-central1 \ &gt; -- \ &gt; --from_train_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TRAIN_DATA_A}</span></span> \ &gt; --to_train_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TRAIN_DATA_B}</span></span> \ &gt; --from_dev_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TEST_DATA_A}</span></span> \ &gt; --to_dev_data=<span class="hljs-variable"><span class="hljs-variable">${INPUT_TEST_DATA_B}</span></span> \ &gt; --train_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ &gt; --data_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ &gt; --from_vocab_size=45000 \ &gt; --to_vocab_size=45000</code> </pre> <br><h3>  Conversation with the bot </h3><br>  Probably the biggest advantage of using Cloud Storage to save intermediate states of the model in the learning process is the ability to start communication without interrupting the learning process. <br><br>  Now, for example, I will show how you can start chatting with a bot after only 1600 training iterations.  By the way, this is the only step that needs to be performed on the local machine.  I think the reasons are obvious =) <br><br>  Here's how to do it: <br><br><pre> <code class="bash hljs">mkdir ~/tmp-data gsutil cp gs://chatbot_generic/chatbot_generic_20161224_232158/translate.ckpt-1600.meta ~/tmp-data ... gsutil cp gs://chatbot_generic/chatbot_generic_20161224_232158/translate.ckpt-1600.index ~/tmp-data ... gsutil cp gs://chatbot_generic/chatbot_generic_20161224_232158/translate.ckpt-1600.data-00000-of-00001 ~/tmp-data ... gsutil cp gs://chatbot_generic/chatbot_generic_20161224_232158/checkpoint ~/tmp-data TRAIN_PATH=... python -m translate.translate \ --data_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ --train_dir=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${TRAIN_PATH}</span></span></span><span class="hljs-string">"</span></span> \ --from_vocab_size=45000 \ --to_vocab_size=45000 \ --decode Reading model parameters from /Users/b0noi/tmp-data/translate.ckpt-1600 &gt; Hi there you ? . . . . . . . . &gt; What <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> you want? i . . . . . . . . . &gt; yes, you i ? . . . . . . . . &gt; hi you ? . . . . . . . . &gt; who are you? i . . . . . . . . . &gt; yes you! what ? . . . . . . . . &gt; who are you? i . . . . . . . . . &gt; you <span class="hljs-string"><span class="hljs-string">' . . . . . . . .</span></span></code> </pre> <br>  The TRAIN_PATH variable should lead to the ‚Äútmp_data‚Äù folder, and the current directory should be ‚Äúmodels / tutorials / rnn‚Äù. <br><br>  As you can see, the chat bot is far from perfect after just 1600 steps.  If you want to see how he can communicate after 50 thousand iterations, I will refer you again to the previous article, since the goal of this is not training the perfect chat bot, but learning how to train any network in the cloud using Google Cloud ML. <br><br><h2>  Post factum </h2><br>  I hope that my article has helped you learn the subtleties of working with Cloud ML and Cloud Shell, and you can use them to train your networks.  I also hope that you liked the writing and, if so, you can support me on my patreon page and / or by adding likes to the article and helping to distribute it =) <br><br>  If you notice any problems in any of the steps, please let me know so that I can fix this promptly. </div><p>Source: <a href="https://habr.com/ru/post/318922/">https://habr.com/ru/post/318922/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../318908/index.html">Stretching the OP on the PLO</a></li>
<li><a href="../318910/index.html">Information technology in the New Year musical "The Magicians"</a></li>
<li><a href="../318914/index.html">How to grow old in IT</a></li>
<li><a href="../318916/index.html">Writing websites in assembler is useful and pleasant.</a></li>
<li><a href="../318918/index.html">Expansion of API from Vk for stickers on Elixir</a></li>
<li><a href="../318924/index.html">Problem Statement: Accounting Objects and Modeling Relationships Between Them</a></li>
<li><a href="../318926/index.html">GitLab 8.15 released</a></li>
<li><a href="../318928/index.html">Promotion of new agency on upwork from scratch - personal experience</a></li>
<li><a href="../318930/index.html">Client communities at a glance</a></li>
<li><a href="../318934/index.html">Abstracted from hotkeys in desktop applications, or how to debug in any IDE with the same buttons</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>