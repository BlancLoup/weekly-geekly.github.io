<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural networks in number detection</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="License plate recognition is still the best-selling computer vision solution. Hundreds, if not thousands of products have been competing in this marke...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural networks in number detection</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/2c9/859/689/2c9859689bb740c78f93b6ac0770496a.png"><br><br>  License plate recognition is still the best-selling computer vision solution.  Hundreds, if not thousands of products have been competing in this market for the past 20-25 years.  This is partly why convolutional neural networks (CNN) do not beat the previous algorithmic approaches on the market. <br><br>  But the experience of recent years says that the CNN algorithms make it possible to make reliable and flexible solutions for application.  There is one more convenience: with this approach, you can always improve the reliability of the solution by an order of magnitude after the actual implementation due to retraining.  In addition, such algorithms are perfectly implemented on GPU (graphics modules), which are much more efficient from the point of view of energy consumption than conventional processors.  And <a href="http://www.nvidia.ru/object/jetson-tx1-dev-kit-ru.html">NVidia's Jetson TX</a> platform so simply consumes very little by the standards of modern computing devices.  Visual "energy superiority": <br><a name="habracut"></a><br><img src="https://habrastorage.org/web/88b/3cf/fcd/88b3cffcdcd84a749ccb687c011f45fb.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Of course, the superiority of the Jetson TX1 over the Intel Core i7 is exaggerated, because  There are always side problems: capturing images from the camera, working with memory, it is advisable not to transfer all calculations to the GPU.  And yet, it looks tempting. <br><br>  It is easy to estimate the consumption budget for the complete system: <br><br><img src="https://habrastorage.org/web/fb2/983/75c/fb298375cf3d4b14881a4a7cee0aa40a.png"><br><br>  So, even for an autonomous solution, powered from the sun and wind, you can install 3-4 cameras with infrared sources and 2 Jetson. <br><br>  It became even more attractive!  So you need to do the recognition on the Jetson TX1, and do it well. <br>  <i>Just say thanks to the NVidia team in Russia.</i>  <i>Thanks to their help, everything worked out.</i>  <i>The guys gave us Jetson TX1 for the experiments and promised to let us test out the TX2</i> . <br><br><h2>  Number Search Algorithm </h2><br>  The search for the boundaries and corners of license plates in the photographs consisted of three stages, implemented by various trained CNNs. <br><br>  Determining the position of the license plate (center): <br><br><img src="https://habrastorage.org/web/005/8c9/668/0058c9668530410aaea72d5a76052d20.jpg"><br><br>  The output layer of the convolution network is the probability field of finding the center of a number at a given point.  The output is such beautiful ‚ÄúGauss‚Äù.  Of course, false positives are possible here.  Moreover, the thresholds are chosen in order to minimize the probability of missing a number (by increasing the number of false notes). <br><br>  Over the past couple of years, tens of thousands of various numbers have come to our freely accessible server.  With such a base, we managed to train a much more reliable detector than the previously used Haar. <br><br>  Estimation of license plate numbers: <br><br><img src="https://habrastorage.org/web/e50/98a/d48/e5098ad483784b2c882ce2379020d6fb.jpg"><br><br>  Here at the same time we screen out some of the false positives. <br><br>  Searching for the best ‚Äúhomography‚Äù transformation bringing the car number into the familiar look: <br><br>  Here 2 more convolutional neural networks worked: detecting the boundaries of the number, determining the most plausible hypothesis. <br><br>  The result of the first: <br><br><img src="https://habrastorage.org/web/2c9/859/689/2c9859689bb740c78f93b6ac0770496a.png"><br><br>  And the second one chooses the best homography: <br><br><img src="https://habrastorage.org/web/e48/20f/656/e4820f65626d4732a7afc34f7c4bd417.png"><br><br>  The result is a normalized image of the license plate number, which must be recognized further.  Below are a few examples of such normalized tablets (some of them are not readable even by the eye): <br><br><img src="https://habrastorage.org/web/9f6/732/b5f/9f6732b5f7164653ad9ed240e5f4d453.png"><br><br>  Such a multi-level approach proved to be very reliable.  At each stage, the probability of missing is minimized, and the convolutional neural network at each next level learns not only to perform its main function, but also to remove false positives.  Thus, the inaccuracy of each CNN is compensated for in the next step. <br><br>  In order to make all this work, we used 2 types of convolutional networks: <br><br>  1) Standard classification option, similar to VGG: <br><br><img src="https://habrastorage.org/web/d7b/1f4/4f1/d7b1f44f1392417abbf67027ecd50f51.png"><br><br>  2) The architecture intended for segmentation, described <a href="https://habrahabr.ru/company/recognitor/blog/277781/">in</a> more detail <a href="https://habrahabr.ru/company/recognitor/blog/277781/">in a previous article</a> . <br><br><img src="https://habrastorage.org/web/feb/bff/55d/febbff55dd314aa59e148a1dfa3b4d46.png"><br><br>  Of course, these architectures had to be a little easier to work on the Jetson TX1.  In addition, several tricks with loss functions and output layers helped to improve the generalization when training on a not-so-huge base that was available. <br><br><h2>  Number Recognition Algorithm </h2><br>  To be honest, it seemed that the problems with text recognition had been thoroughly solved for several years by modern Deep Learning algorithms.  But for some reason not. <br><br>  Here is a relatively recent <a href="https://handong1587.github.io/deep_learning/2015/10/09/ocr.html">overview of existing problems and solutions</a> . <br><br>  On Habr√© <a href="https://habrahabr.ru/company/smartengines/blog/328000/">recently there was an article</a> about using LSTM and CNN for text recognition in the passport. <br><br>  But the described approach requires manual marking of the entire base (the border between the characters).  And we had a serious size base with a different layout (image + text): <br><br><img src="https://habrastorage.org/web/008/e56/160/008e561603f4450f8d8581469c819106.png"><br><br>  After all, there was the algorithm of the previous generation, which often quite successfully recognized the car number (sometimes making mistakes).  So, it was necessary to come up with an approach that would allow to train the neural network without attracting information about the position of each character.  This approach is even more valuable due to the fact that it is much easier to automatically increase the training sample.  In a system in which the eyes check and correct errors (for example, to send a fine), an extension of the training set is automatically generated.  Yes, even if the correction is not carried out, retraining will help after the accumulation of recognized numbers. <br><br>  Any convolutional network has a pre-programmed structure in which it is assumed that the same cores (convolutions) are applied to different positions of the image.  Due to this, a significant reduction in the number of scales is achieved. <br><br>  You can take a look at this property of convolution networks on the other hand, as suggested by <a href="https://habrahabr.ru/users/alexeyr/" class="user_link">AlexeyR</a> ( <a href="https://habrahabr.ru/post/320866/">read here</a> ).  In short, the task of generalization is inextricably linked to the task of transforming input information into a context in which it is more common or better described.  Armed with this concept (or inspired), we will try to solve this seemingly simple task of recognizing text in an image with the markup we have (no position of signs, just a list of them). <br><br>  Let's build a small context-dependent area of ‚Äã‚Äã36 minicolumns ( <a href="https://habrahabr.ru/post/317712/">more</a> ): <br><br><img src="https://habrastorage.org/web/6db/dfd/c61/6dbdfdc616a146cbb22d555efd289af9.png"><br><br>  The image shows only 10 transformations.  Here's what the responses to each of the contexts should look like in the above picture. <br><br><img src="https://habrastorage.org/web/a7c/8a7/61a/a7c8a761a0c94317ba372af276afe5ad.png"><br><br>  It should be noted here that far the most efficient coding inside minicolumns was used, but given the 22 concepts, this is not a big problem. <br><br>  Convolutional networks are conceived so well that these contextual transformations are automatically obtained at the output of any convolutional layer, which means there is no point in shifting the input images, it is enough to take the output of any convolutional layer, perform several transformations already implemented by the layers in Caffe, and run SGD training. <br><br>  And as a result of the training, we will get a ‚Äúcut‚Äù for 36 minicolumns: <br><br><img src="https://habrastorage.org/web/649/a55/7b1/649a557b1d324902b9c9f8201547b95e.png"><br><br>  Let us single out local maxima and let us know at the output of the combination: what they learned and in what context.  And then we will collect everything in order from left to right: A902YT190 <br><br>  This problem was solved with the help of CAFFE and the convolution network architecture.  But if we had to consider more complex and non-obvious transformations (scale, turns in space, perspective), then we would have to use more computing resources and create much more serious algorithms. <br><br>  In addition, we had quite a bit to sweat over the regions, the quality of which leaves much to be desired.  But it‚Äôs such a big story that you don‚Äôt want to include it in this long article. <br><br>  At the same time, it is worth mentioning separately.  If there are no regions, then any numbers with monotonous font are recognized by the same grid.  Just enough to provide a fairly large base of examples. <br><br><h2>  Applications </h2><br>  Of course, the most obvious is traffic control.  But there are a few more applications that we have encountered.  We wanted to make a fairly universal algorithm.  So I had to think about what kind of use there are: <br><br>  1) Traffic Control (application 1) <br><br><img src="https://habrastorage.org/web/e67/cef/d4e/e67cefd4e4704c3782a87269b4d5951e.jpg"><br><br>  - High resolution cameras: 3-8MP <br>  - IR illuminator <br>  - Predictable orientation and scale <br>  - Possible manual adjustment after installation <br>  - Up to 10-20 numbers per frame <br><br>  2) Traffic control at the checkpoint (application 2) <br><br><img src="https://habrastorage.org/web/017/a08/88f/017a0888f03644949f1bacaccbd13d0f.jpg"><br><br>  - Low resolution cameras (0.3MP - 1MP) <br>  - IR illuminator <br>  - Predictable size and number area <br>  - Possible manual adjustment after installation <br>  - Only one number at a time in the frame <br><br>  3) Photos ‚Äúwith hands‚Äù (application 3) <br><br><img src="https://habrastorage.org/web/019/620/038/01962003870d4dc38c794bae70cfbb7a.jpg"><br><br>  - High resolution camera <br>  - No IR illumination <br><br>  Unpredictable room size and area.  It turned out that the latter application is the most expensive in terms of computing resources.  Mainly due to the fact that the scale of numbers is poorly predictable.  The simplest application is the second.  In the frame is not more than one number.  The scale of the rooms varies slightly.  The first application is also quite successful and is based on computational needs in the middle.  But with all these situations Jetson TX1 successfully copes.  Only the latter does not fit into the real-time scale, but takes about 1 second to be calculated in a non-optimized code. <br><br><h2>  Jetson TX1 frame calculation time budget </h2><br><img src="https://habrastorage.org/web/ecf/2f9/47e/ecf2f947e018494e87a00d00a95a92e4.png"><br>  Performance tests are preliminary, optimization is still possible, especially for specific applications. <br><br>  And, of course, if you run the same algorithm on 1080 / Titan video cards, you can get almost a tenfold increase in speed.  For the third application it is already ~ 100ms per image. <br><br><h2>  Telegram Bot </h2><br>  That article is bad on the habr, which does not end with the story of writing Telegram bot!  So, of course, we did one on Jetson TX1 so that you could take a picture and test the algorithm.  The bot name is <a href="https://t.me/Recognitor_bot">Recognitor</a> <br><br>  This bot is now running on the Jetson TX1 demo board: <br><br><img src="https://habrastorage.org/web/81a/496/3e5/81a4963e5788422eb592f457ad255082.jpg"><br><br>  The Jetson TX1 recognizes images at home (notice the fan ‚Äî it turns on every time a new image arrives). <br><br><img src="https://habrastorage.org/web/2ac/58d/612/2ac58d612b0346dd9f7447f02721d42d.png"><br><br>  It turned out that Telegram Bot is an excellent support tool when working with computer vision programs.  For example, you can organize manual verification of recognition results with it.  The Telegram API provides an excellent feature set for this.  <a href="https://habrahabr.ru/users/zlodeibaal/" class="user_link">ZlodeiBaal</a> here already used the <a href="https://habrahabr.ru/post/322520/">bot telegram</a> . <br><br>  It's simple: you attach an image to a message (one! It seems the telegram allows you to send several, but only the last will be analyzed).  An image is returned with marked frames and a few lines with all the likely-found numbers.  Each line also shows the percentage - this is the conditional probability that the number is actually recognized.  Less than 50% - something with the number is not that (the part did not fit into the frame or it is not a number at all). <br><br>  If you want to leave us a comment on a specific photo, then just write it with the text, without attaching the picture.  It will definitely be saved in the file log.txt, which we will very likely read. <br><br>  Do not forget that the algorithm is now launched in test mode and only standard Russian numbers or yellow taxi numbers are expected (no transit, trailers, etc.). <br><br><h2>  Learning set </h2><br>  We had about 25,000 images at our disposal.  Most of the base - snapshots from a phone with a random position and number scale: <br><br><img src="https://habrastorage.org/web/742/c1a/a3b/742c1aa3b2fb433d82491f5f6cdd7d6d.jpg"><br><br>  Several thousand pictures were taken from checkpoints: <br><br><img src="https://habrastorage.org/web/d42/f3c/93f/d42f3c93f19f43e3bcb629161c73265d.jpg"><br><br>  About a thousand shots - the standard view for cameras recording violations of traffic rules. <br><br><img src="https://habrastorage.org/web/84d/e98/010/84de980100b745d1abd17fcdcbec56aa.jpg"><br><br>  Most of the base was based on the sample, which we laid out in open access a long time ago: <br><br>  <a href="https://yadi.sk/d/EAfnQ947criHW">yadi.sk/d/EAfnQ947criHW</a> <br>  <a href="https://yadi.sk/d/0H2AipxrcrXqy">yadi.sk/d/0H2AipxrcrXqy</a> <br>  <a href="https://yadi.sk/d/U41QZ8v7cpJ6R">yadi.sk/d/U41QZ8v7cpJ6R</a> <br><br><h2>  Eventually </h2><br>  We collected the whole stack of license plate recognition algorithms based on convolutional neural networks for Jetson TX1 with sufficient speed to work with real-time video. <br><br>  Recognition reliability has improved significantly relative to the <a href="https://habrahabr.ru/company/recognitor/blog/225913/">previous algorithm</a> .  It is difficult to cite specific figures, since  they vary greatly depending on the application.  But the difference is well visible to the naked eye - <a href="https://t.me/Recognitor_bot">Recognitor</a> <br><br>  Due to the fact that all algorithms are retraining, you can easily expand the applicability of the solution.  Up to change of objects of recognition. </div><p>Source: <a href="https://habr.com/ru/post/329636/">https://habr.com/ru/post/329636/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../329624/index.html">The story of the move from Odessa to Russia</a></li>
<li><a href="../329626/index.html">Answers to topical questions of young web studios / digital agencies</a></li>
<li><a href="../329628/index.html">Create a PDF viewer for a couple of hours</a></li>
<li><a href="../329632/index.html">How to start working with Emer blockchain</a></li>
<li><a href="../329634/index.html">The digest of interesting materials for the mobile # 205 developer (May 22-28)</a></li>
<li><a href="../329638/index.html">Acquaintance with IaaS-provider: what we write on Habr√© and in our blog</a></li>
<li><a href="../329642/index.html">IBM Cognos Analytics Software integration with IBM Power. Useful tips and solutions</a></li>
<li><a href="../329646/index.html">Life and amazing adventures in exotic JavaScript environments</a></li>
<li><a href="../329648/index.html">Two-factor authentication when mounting an encrypted LUKS partition using Yubikey 4</a></li>
<li><a href="../329650/index.html">HCIBench - load testing of vSphere repositories</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>