<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Chalk-cepstral coefficients (MFCC) and speech recognition</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently I came across an interesting article published by rgen3 , which describes the DTW-speech recognition algorithm. In general terms, this is a c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Chalk-cepstral coefficients (MFCC) and speech recognition</h1><div class="post__text post__text-html js-mediator-article">  Recently I came across an interesting <a href="http://habrahabr.ru/post/135087/">article</a> published by <a href="http://habrahabr.ru/users/rgen3/" class="user_link">rgen3</a> , which describes the DTW-speech recognition algorithm.  In general terms, this is a comparison of speech sequences using dynamic programming. <br><br>  Interested in the topic, I tried to apply this algorithm in practice, but in this way I waited for a number of rakes.  First of all, what exactly needs to be compared?  Directly sound signals in the time domain are long and not very effective.  Spectrograms are faster, but not much more efficient.  The search for the most rational representation led me to the <acronym>MFCC</acronym> or the Chalk-frequency cepstral coefficients, which are often used as a characteristic of speech signals.  Here I will try to explain what they are. <a name="habracut"></a><br><br><h4>  Basic concepts </h4><br>  The explanation will start with the first word in the title.  What is chalk?  <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D0%25BB_(%25D0%25B2%25D1%258B%25D1%2581%25D0%25BE%25D1%2582%25D0%25B0_%25D0%25B7%25D0%25B2%25D1%2583%25D0%25BA%25D0%25B0)">Wikipedia</a> tells us that chalk is a unit of pitch based on the perception of this sound by our organs of hearing.  As you know, the frequency response of the human ear does not even remotely resemble a straight line, and the amplitude is not an entirely accurate measure of the volume of the sound.  Therefore, empirically selected units of volume were introduced, for example, <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25BE%25D0%25BD_(%25D0%25B5%25D0%25B4%25D0%25B8%25D0%25BD%25D0%25B8%25D1%2586%25D0%25B0_%25D0%25B8%25D0%25B7%25D0%25BC%25D0%25B5%25D1%2580%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F)">background</a> . <br><div style="text-align:center;"><img src="https://habrastorage.org/storage2/8da/e29/ef5/8dae29ef5c4af820b0af78acca5c8590.png"></div><br>  Similarly, the pitch of the sound perceived by human hearing does not quite linearly depend on its frequency. <br><img src="https://habrastorage.org/storage2/1d8/352/b53/1d8352b5391a3ef82eeb37eaf25f6e73.png"><br>  Such a dependence does not claim to be more accurate, but is described by a simple formula <br><img src="https://habrastorage.org/storage2/60f/d6d/42a/60fd6d42aa74673955637ae5cbf5271f.gif">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Such units of measure are often used in solving problems of recognition, as they allow you to get closer to the mechanisms of human perception, which is still leading among the well-known speech recognition systems. <br><br>  It is necessary to tell a little about the second word in the title - <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B5%25D0%25BF%25D1%2581%25D1%2582%25D1%2580">kepstrum</a> . <br><br>  In accordance with the theory of speech production, speech is an acoustic wave that is emitted by a system of organs: the lungs, bronchi and trachea, and then is transformed in the vocal tract.  If we assume that the sources of excitation and the shape of the vocal tract are relatively independent, the human speech apparatus can be represented as a set of tonal and noise generators, as well as filters.  Schematically it can be represented as follows: <br><br><img src="https://habrastorage.org/storage2/5c1/951/7f8/5c19517f848ec92419c5a6035f501cd4.png"><br><br>  1. Pulse sequence generator (tones) <br>  2. The random number generator (noise) <br>  3. Digital filter coefficients (voice path parameters) <br>  4. Non-stationary digital filter <br><br>  The signal at the output of the filter (4) can be represented in the form of convolution <br><br><img src="https://habrastorage.org/storage2/9e5/dbf/1c6/9e5dbf1c6c351d3921ccb5edd710cf4f.gif"><br><br>  where s (t) is the initial form of the acoustic wave, and h (t) is the filter characteristic (depends on the parameters of the vocal tract) <br><br>  In the frequency domain, it looks like this <br><br><img src="https://habrastorage.org/storage2/90f/110/d49/90f110d49337dd4b5d174641a5c9bf46.gif"><br><br>  The work can be calibrated to get the amount instead. <br><br><img src="https://habrastorage.org/storage2/05f/c68/ea5/05fc68ea5102453c724189119d893966.gif"><br><br>  Now we need to convert this sum so as to obtain non-overlapping sets of characteristics of the original signal and filter.  There are several options for this, for example, the inverse <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5">Fourier transform</a> will give us this <br><br><img src="https://habrastorage.org/storage2/e97/795/a73/e97795a73b99c35f782f339ed74c67a8.gif"><br><br>  Also, depending on the target, you can use the direct Fourier transform or the <a href="http://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D0%25BA%25D1%2580%25D0%25B5%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BA%25D0%25BE%25D1%2581%25D0%25B8%25D0%25BD%25D1%2583%25D1%2581%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5">discrete cosine transform</a> <br><br>  I hope I clarified the basic concepts a little.  It remains to understand how to convert a speech signal into a set of MFCC coefficients. <br><br><h4>  Example </h4><br>  As an experimental, we take a simple figure 1, here is its temporary representation <br><img src="https://habrastorage.org/storage2/574/98b/d0c/57498bd0c3ce979cdd5e072c244a3cf0.png"><br>  First of all, we need the spectrum of the original signal, which we obtain using <a href="http://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D0%25BA%25D1%2580%25D0%25B5%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5">the Fourier transform</a> .  For simplicity of the example, we will not break the signal into parts, therefore we take the spectrum along the entire time axis <br><br><img src="https://habrastorage.org/storage2/724/db7/015/724db7015a75b1f2b70e8a4616dec28c.png"><br>  Now the most interesting begins, we need to place the resulting spectrum on a chalk scale.  For this, we use windows evenly spaced on the chalk axis. <br><img src="https://habrastorage.org/storage2/012/2db/274/0122db274ef2832248f95ac8242277ee.png"><br>  If you translate this graph into a frequency scale, you can see such a picture <br><img src="https://habrastorage.org/storage2/f76/796/1b3/f767961b390a5e09942b9552cf4b81d6.png"><br>  On this graph, it is noticeable that the windows are ‚Äúcollected‚Äù in the low-frequency region, providing a higher ‚Äúresolution‚Äù where it is necessary for recognition. <br>  By a simple multiplication of the vectors of the signal spectrum and the window function, we find the energy of the signal that falls into each of the analysis windows.  We received a certain set of coefficients, but these are not the MFCCs we are looking for.  While they could be called Mel-frequency <b>spectral</b> coefficients.  We square them and logarithmize them.  It remains for us to only get one of them cepstral, or "spectrum spectrum."  For this, we could once again apply the Fourier transform, but it is better to use the <a href="http://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D0%25BA%25D1%2580%25D0%25B5%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BA%25D0%25BE%25D1%2581%25D0%25B8%25D0%25BD%25D1%2583%25D1%2581%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5">discrete cosine transform</a> . <br><br>  As a result, we obtain a sequence of approximately the following form: <br><img src="https://habrastorage.org/storage2/bf6/9a7/20d/bf69a720d757d8f0302e951df458a13e.png"><br><br><h4>  Conclusion </h4><br>  Thus, we have a very small set of values, which, when recognized, successfully replaces thousands of samples of the speech signal.  They write in the books that it is possible to take the first 13 of the 24 calculated coefficients for the word recognition problem, but in my case any suitable results started from 16. In any case, this is a much smaller amount of data than the spectrogram or the temporal representation of the signal. <br>  For best results, you can split the source word into short lengths, and calculate the coefficients for each of them.  ‚ÄúWeighting‚Äù window functions can also help.  It all depends on the recognition algorithm to which you feed the result. <br><br><h4>  Formulas </h4><br>  I do not want to load the main part of the article with a large number of formulas, but suddenly they will be interesting to someone.  Therefore, I will bring them here. <br><br>  The original speech signal is written in discrete form as <br><img src="https://habrastorage.org/storage2/d94/3c9/aaa/d943c9aaa0edb6e9f628fb607a8388eb.gif"><br><br>  Apply the Fourier transform to it. <br><img src="https://habrastorage.org/storage2/f4f/0bc/556/f4f0bc556ff9fff89ade82d5412067d1.gif"><br><br>  We make a combination of filters using the window function <br><img src="https://habrastorage.org/storage2/083/1d4/2fe/0831d42fe9122f394d5c5cf38e32a09b.gif"><br><br>  For which the frequency f [m] is obtained from the equation <br><img src="https://habrastorage.org/storage2/e50/0f9/489/e500f9489367addaa6d0ed4b482bcbd9.gif"><br><br>  B (b) - conversion of the frequency value into a chalk scale, respectively, <br><img src="https://habrastorage.org/storage2/3ae/bba/1b3/3aebba1b385e3fb449405829afb33889.gif"><br><br>  We calculate energy for each window <br><img src="https://habrastorage.org/storage2/71c/b7e/adb/71cb7eadb7a222e6b65409227d65bcb1.gif"><br><br>  Apply DCT <br><img src="https://habrastorage.org/storage2/082/bbc/14c/082bbc14c78e0847e9080a7d30763e14.gif"><br><br>  We receive the MFCC set <br><br><h4>  Sources </h4><br>  [1] Wikipedia <br>  [2] Xuedong Huang, Alex Acero, Hsiao-Wuen Hon, Spoken Language Processing, Algorithm, System Development, Prentice Hall, 2001, ISBN: 0130226165 </div><p>Source: <a href="https://habr.com/ru/post/140828/">https://habr.com/ru/post/140828/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../140822/index.html">Psychology and digital reality</a></li>
<li><a href="../140824/index.html">Pirate party passed to the parliament of another German land</a></li>
<li><a href="../140825/index.html">Creating a cross-browser shell for custom scripts</a></li>
<li><a href="../140826/index.html">Ajax site indexed by all search engines</a></li>
<li><a href="../140827/index.html">Eight principles of programming that can make your life easier</a></li>
<li><a href="../140829/index.html">Web archive for Evernote</a></li>
<li><a href="../140830/index.html">And which exchange do you use?</a></li>
<li><a href="../140831/index.html">World frontend stars</a></li>
<li><a href="../140833/index.html">Runetology (140): founder of KupiVIP.ru Oscar Hartmann</a></li>
<li><a href="../140835/index.html">Semi-automatic version numbering with git</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>