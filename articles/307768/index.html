<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The tale of virtualization-clustering and storage Fujitsu</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Here is how it was. 


 One small state-scale organization decided to upgrade its server equipment in its local ownership. And her men turned to our v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The tale of virtualization-clustering and storage Fujitsu</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/90b/48d/7b0/90b48d7b02544c7186a77ee8661eea4d.jpg"><br><p>  Here is how it was. </p><br><p>  One small state-scale organization decided to upgrade its server equipment in its local ownership.  And her men turned to our valiant managers, they say, we want servers with disks for our important services.  And they learned from managers about virtualization overseas, fault tolerant, and clustering. </p><br><p>  Actually, the fairy tale has a long effect, but it's done quickly. </p><br><p>  This is how a bundle of two Fujitsu PRIMERGY RX 200 S8 servers and the ETERNUS DX 100 S3 storage system appeared in the organization.  And no one at that time thought that very soon those server resources would not be enough.  On the contrary, they considered and were sure that it was enough for a long time.  But quickly the virtual machines became fertile and voracious, they were fat.  And then the disk space was expanded, and their two young Fujitsu PRIMERGY RX2530 M1 got hooked to the two RX 200. </p><br><p>  We will tell you about sharing the new server in the cluster, as well as adding new expansion cards with additional FC interfaces to the controller blocks.  Or rather, about the simplicity, security and convenience of all these and other engineering manipulations that are possible (in our case) with VMware virtualization and Fujitsu hardware.  Those who already have storage and one or another implementation of server virtualization (or just a thread) will not be surprised and, probably, will not learn anything new from this text.  But there are still many organizations where any actions with the equipment, its rebooting and stopping cause horror and force meticulously plan and minimize the upcoming downtime. </p><br><a name="habracut"></a><br><h3>  About the storage system </h3><br><p>  As is known, in order to add or remove a component (not supporting hot swap) in an already running device that provides services and constantly exchanging data, this device needs to be turned off.  In the case of the server, such a stop is inevitable, in the case of modern storage systems that have two controllers, everything is done without stopping or pauses.  Indeed, in addition to fault tolerance through multipath I / O (MultiPathing - each of the hosts (servers) has several data channels from its I / O ports to the ports of each of the storage controllers), modern data storage systems (in particular, this is Fujitsu ETERNUS DX 100 S3) are able to distribute / parallelize the transfer of data on these channels, reducing the load on the channel and increasing bandwidth.  Idle time in case of failure of one of the channels is reduced to zero (active / active mode) or minimized when automatically switching from the active (but "lost") channel to the passive - "waiting" (active / passive mode).  Actually, these features, as well as features of the operating system, allow us to make changes to the controller units (or replace them completely) without downtime and reboot. </p><br><p>  With the DX 100 S3, this is easily and simply performed as follows, reflecting all the safety and reasonableness of the manipulations: </p><br><ol><li><p>  Having entered the GUI under the service engineer account (f.ce), we transfer the whole system to the maintenance mode </p><br><img src="https://habrastorage.org/files/cba/27c/d12/cba27cd12c9844b4b518af1e3241f595.jpg"><br></li><li>  Next, choosing the controller module we need, we transfer it to the maintenance mode <br><img src="https://habrastorage.org/files/c60/960/278/c60960278d9a416683e49cad98813e2d.jpg"></li></ol><br><p>  The system before performing the required unit in maintenance mod performs a series of security tests and implements the request only if the second controller and dependent components are working properly and the data integrity is not compromised.  All logical drives for which the disabled controller was the ‚Äúowner‚Äù will go into the service of the second controller almost instantly and seamlessly after synchronizing the cache and changing the data transfer paths. </p><br><ol><li>  The graphical interface will show that the controller is no longer available and can be removed.  At the end of the manipulations, also in online mode, we return it to its place; the system automatically, without rebooting the controller blocks themselves, recognizes and returns the previous work pattern.  New devices that appear (we have FC adapters) need to be activated by adding to the system.  That's all, truly ETERNUS DX has a real-time operating system. </li></ol><br><p>  <i>In the IBM (Lenovo) Storwize line, for example, these manipulations also go online, but the controllers themselves perform a cycle of several alternate reloads after indicating that this is not an error at all and that we have added one or another component.</i>  <i>And the reboot can last, according to the testimony of the system, up to 30 (!!!) minutes each.</i> </p><br><img src="https://habrastorage.org/files/46d/518/e94/46d518e94c994c7d80e30edd0b6447f6.jpg"><br><p>  I would like to add a few more words about the security algorithm implemented here, it can be said, protection against rash actions.  And its essence is simple and elegant: you can not remove anything by accidental pressing is not where it should be.  For example, we cannot remove a RAID or a logical disk until we analyze the whole chain of interconnections from the very end, namely, we first need to remove the LUN groups from the Host Affinity communication settings, then remove the logical disks themselves from the LUN -groups, remove logical drives and only then destroy the RAID.  Agree, to do this by accident and inadvertently almost impossible. </p><br><img src="https://habrastorage.org/files/1fd/c34/dda/1fdc34ddaa4e43bfa7183e0f396bddff.jpg"><br><img src="https://habrastorage.org/files/cd4/c0e/812/cd4c0e81256c4b45af2e032b71f6aeaa.jpg"><br><p>  <i>The "Delete" tabs of the LUN Group and the RAID Group are not active until the "connections" are broken.</i> </p><br><p>  It is worth mentioning that from the command line (SSH), if <u>necessary, the</u> forced removal of any elements is available immediately. </p><br><h3>  About servers and virtualization </h3><br><p>  As mentioned earlier, the server part of the cluster initially consisted of 2 Fujitsu PRIMERGY RX200 S8 servers, to which they later added a Fujitsu PRIMERGY RX 2530 M1 device of similar class and performance.  In fact, the architecture of the device is very similar, but the new line of Intel processors (as a result, new functions, instructions, protocols) in the RX 2530 M1 promised us problems at the VMware cluster level, namely, problems with the migration of machines between hosts.  What appeared after the implementation: some of the existing machines during the migration produced an error related to the CPU of the target server. </p><br><p>  Of course, VMware has provided a solution for this kind of problems, its EVC (Enhanced vMotion Compatibility) function is designed to ‚Äúmask‚Äù the differences in processors of different generations.  Alas, initially the cluster was raised on the fifth version of the VMware virtual realm (VMware vSphere 5.5), which at that time still had no idea about the new Intel processors.  However, the point is that for our situation this trouble is not a problem at all.  Having a failover cluster, upgrading to VMware vSphere 6.0 (the EVC of which has the ability to work with all versions of processors) takes only a few hours.  With proper use and planning of the cluster, any of the servers available in it can be freely maintained by distributing its machines on the remaining hosts using live migration. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/089/c7a/341/089c7a341cd341559a73cdccf9fd5cc9.jpg"></div><br><p>  <i>The machine was migrated with a change not only of the host, but also of the data storage, since the storage space was reorganized.</i>  <i>This process proceeds by complete cloning of the machine, the original of which is automatically deleted after synchronization.</i>  <i>Simultaneous migration (server and disk) is possible only when the virtual machine is turned off.</i> </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/373/055/dec/373055dec1dc459597e34e9a2f3c2321.jpg"></div><br><p>  <i>In VMware vSphere 5.5, processor support ends with the generation of "Sandy Bridge"</i> </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/50c/79b/e79/50c79be796b841a4863f5489b3e209cd.jpg"></div><br><p>  <i>In VMware vSphere 6.0, we can observe "Ivy Bridge" and "Haswell"</i> </p><br><p>  Summing up this small story about cluster virtualization, I want to quote a line from the song - ‚ÄúIt was difficult for me to fly with you, but without you I can't breathe!‚Äù.  For it is difficult to decide this, and it is expensive.  But then it‚Äôs scary to imagine how people used to do without all this, remembering the spent weekends, dinners and nights, nerves, worries and hopes to have time to complete their plans before the end of the break or the beginning of the working day. </p><br><p>  <i>Prepared on the material of Tretyakov Vyacheslav, an engineer of the company "Paradigma".</i>  <i>See the full article <a href="http://www.itparadigma.ru/blog/trogwar_clasterfujitsu1/">here</a> .</i> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/307768/">https://habr.com/ru/post/307768/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../307758/index.html">Restore from backup using Veeam Agent for Linux</a></li>
<li><a href="../307760/index.html">How to plan and evaluate projects in Agile?</a></li>
<li><a href="../307762/index.html">Refactoring - power hidden in quality code</a></li>
<li><a href="../307764/index.html">Mitap Haskell programmers at Kaspersky Lab (in the sense of - waiting)</a></li>
<li><a href="../307766/index.html">Adobe AIR + Starling + rasterizing vector graphics</a></li>
<li><a href="../307770/index.html">Secrets of cloud PBX: a few words about recording conversations</a></li>
<li><a href="../307774/index.html">Android application traffic analysis: certificate pinning bypass without reverse engineering</a></li>
<li><a href="../307776/index.html">Basics of game design: 20 board games. Part Six: Nuclear War, Paranoia, Call of Cthulhu</a></li>
<li><a href="../307778/index.html">Record time: how we increased the launch speed of Mail.Ru Mail application on iOS</a></li>
<li><a href="../307780/index.html">Breaking Equation Group: Stuxnet, Duqu and Flame creator files are sold at auction</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>