<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Let's transform the image into a sound - what can be heard?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi Habr. 

 A recent publication here on the site described a device that allows blind people to "see" the image, transforming it with the help of sou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Let's transform the image into a sound - what can be heard?</h1><div class="post__text post__text-html js-mediator-article">  Hi Habr. <br><br>  A recent publication here on the site described a device that allows blind people to "see" the image, transforming it with the help of sound waves.  From a technical point of view, in that article there were no details at all ( <s>and suddenly they stole the idea for a million</s> ), but the concept itself seemed interesting.  Having some experience in signal processing, I decided to experiment on my own. <br><br><img src="https://habrastorage.org/webt/ki/st/ip/kistiptqvnn-pmxshurxrawkqze.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      What came out of it, the details and examples of files under the cut. <br><a name="habracut"></a><br><h2>  Convert 2D to 1D </h2><br>  The first obvious task that awaits us is to transform a two-dimensional ‚Äúflat‚Äù image into a ‚Äúone-dimensional‚Äù sound wave.  As suggested in the comments to that article, it is convenient to use <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D1%2580%25D0%25B8%25D0%25B2%25D0%25B0%25D1%258F_%25D0%2593%25D0%25B8%25D0%25BB%25D1%258C%25D0%25B1%25D0%25B5%25D1%2580%25D1%2582%25D0%25B0">the Hilbert curve</a> for this. <br><img src="https://habrastorage.org/webt/kk/n9/2o/kkn92oz48liofrdsozg5jamskcq.gif"><br>  It is essentially similar to a fractal, and the idea is that when you increase the image resolution, the relative position of objects does not change (if the object was in the upper left corner of the picture, then it <a href="https://youtu.be/3s7h2MHQtxc%3Ft%3D759">will remain there</a> ).  Different dimensions of the Hilbert curves can give us different images: 32x32 for N = 5, 64x64 for N = 6, and so on.  ‚ÄúBypassing‚Äù the image along this curve, we get a line, a one-dimensional object. <br><br>  The next question is the size of the picture.  Intuitively, I want to take a larger image, but there is a big ‚Äúbut‚Äù: even the picture is 512x512, this is 262144 pixels.  If we transform each point into a sound pulse, then at a sampling rate of 44100, we get a sequence that is as long as 6 seconds, and this is too long - the images should be updated quickly, for example using a webcam.  It makes no sense to make the sampling rate higher, we will get ultrasonic frequencies that are inaudible by the ear (although it may and will work for an owl or a bat).  As a result, the resolution of 128x128 was chosen <s>by the method of scientific typing</s> , which will give impulses 0.37c long - on the one hand, it is fast enough to navigate in real time, on the other hand, it is enough to catch any changes in the waveform by ear. <br><br><h2>  Image processing </h2><br>  The first step is to load the image, convert it to b / w and scale it to the desired size.  Image size depends on the dimension of the Hilbert curve. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> hilbertcurve.hilbertcurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HilbertCurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.signal <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> butter, filtfilt <span class="hljs-comment"><span class="hljs-comment"># Create Hilbert curve dimension = 7 hilbert = HilbertCurve(dimension, n=2) print("Hilbert curve dimension:", dimension) # Maximum distance along curve print("Max_dist:", hilbert.max_h) # Maximum distance along curve print("Max_coord:", hilbert.max_x) # Maximum coordinate value in any dimension # Load PIL image f_name = "image01.png" img = Image.open(f_name) width, height = img.size out_size = hilbert_curve.max_x + 1 if width != out_size: img = img.resize((out_size, out_size), Image.ANTIALIAS) # Get image as grayscale numpy array img_grayscale = img.convert(mode='L') img_data = np.array(img_grayscale)</span></span></code> </pre> <br>  The next step is to form a sound wave.  Here, of course, there can be a great variety of algorithms and know-how, for the test I just took the brightness component.  Of course, there are certainly better ways. <br><br><pre> <code class="python hljs">width, height = img_grayscale.size sound_data = np.zeros(width*height) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ii <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(width*height): coord_x, coord_y = hilbert_curve.coordinates_from_distance(ii) pixel_l = img_data[coord_x][coord_y] <span class="hljs-comment"><span class="hljs-comment"># Inverse colors (paper-like, white = 0, black = 255) pixel_l = 255 - pixel_l # Adjust values 0..255 to 0..8192 ampl = pixel_l*32 sound_data[ii] = ampl</span></span></code> </pre> <br>  From the code, I hope everything is clear.  The coordinates_from_distance function does all the work for us to transform the coordinates (x, y) into the distance on the Hilbert curve, we invert and convert the brightness value L to color. <br><br>  That's not all.  Because  There may be large blocks of the same color in the image, this may lead to the appearance of ‚Äúdc-components‚Äù in the sound - a long series of non-zero values, for example [100,100,100, ...].  To remove them, apply to our array of high-pass filter ( <a href="https://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B8%25D0%25BB%25D1%258C%25D1%2582%25D1%2580_%25D0%2591%25D0%25B0%25D1%2582%25D1%2582%25D0%25B5%25D1%2580%25D0%25B2%25D0%25BE%25D1%2580%25D1%2582%25D0%25B0">Butterworth filter</a> ) with a cut-off frequency of 50 Hz (coincidence with the frequency of the network randomly).  The synthesis of filters is in the scipy library, which we will use. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> nyq = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * fs normal_cutoff = cutoff / nyq b, a = butter(order, normal_cutoff, btype=<span class="hljs-string"><span class="hljs-string">'high'</span></span>, analog=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> b, a <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass_filter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> b, a = butter_highpass(cutoff, fs, order) y = filtfilt(b, a, data) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y <span class="hljs-comment"><span class="hljs-comment"># Apply high pass filter to remove dc component cutoff_hz = 50 sample_rate = 44100 order = 5 wav_data = butter_highpass_filter(sound_data, cutoff_hz, sample_rate, order)</span></span></code> </pre> <br>  The last step is to save the image.  Because  the length of one impulse is short, we repeat it 10 times, it will be by ear more close to a real repeating image, for example, from a webcam. <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Clip data to int16 range sound_output = np.clip(wav_data, -32000, 32000).astype(np.int16) # Save repeat = 10 sound_output_ntimes = np.tile(sound_output, repeat) wav_name = "ouput.wav" scipy.io.wavfile.write(wav_name, sample_rate, sound_output_ntimes)</span></span></code> </pre> <br><h2>  results </h2><br>  The above algorithm is, of course, quite primitive.  I wanted to check three points - how much can be distinguished between different simple figures, and how much can one estimate the distance to the figures. <br><br>  <b>Test 1</b> <br><br><img src="https://habrastorage.org/webt/ft/te/9m/ftte9mjfgwj6nib_lj76pfrqmre.png"><br><br>  The image corresponds to the following audio signal: <br><img src="https://habrastorage.org/webt/bd/gw/qu/bdgwquzss88fzb1s8hzyydf-das.png"><br><br>  <a href="https://cloud.mail.ru/public/nt2R/2kwBvyRup">Wav</a> : <a href="https://cloud.mail.ru/public/nt2R/2kwBvyRup">cloud.mail.ru/public/nt2R/2kwBvyRup</a> <br><br>  <b>Test 2</b> <br><br><img src="https://habrastorage.org/webt/vr/jt/6u/vrjt6ufndqzfdsywsgrpbnwlqiw.png"><br><br>  The idea of ‚Äã‚Äãthis test is to compare the ‚Äúsound‚Äù of an object of another form.  Sound signal: <br><img src="https://habrastorage.org/webt/6z/bq/9a/6zbq9axxuoknevsj_iuxc94unre.png"><br><br>  <a href="https://cloud.mail.ru/public/2rLu/4fCNRxCG2">Wav</a> : <a href="https://cloud.mail.ru/public/2rLu/4fCNRxCG2">cloud.mail.ru/public/2rLu/4fCNRxCG2</a> <br><br>  You may notice that the sound is really different, and there is a difference in the ear. <br><br>  <b>Test 3</b> <br><br><img src="https://habrastorage.org/webt/cv/cp/3h/cvcp3h7itiq8srj-rs_j6ntb6lk.png"><br><br>  The test idea is to test a smaller object.  Sound signal: <br><img src="https://habrastorage.org/webt/yk/ra/x3/ykrax3udam03yphwwtlouygkgdk.png"><br><br>  <a href="https://cloud.mail.ru/public/5GLV/2HoCHvoaY">Wav</a> : <a href="https://cloud.mail.ru/public/5GLV/2HoCHvoaY">cloud.mail.ru/public/5GLV/2HoCHvoaY</a> <br><br>  In principle, the smaller the object's size, the smaller the ‚Äúbursts‚Äù in the sound will be, so the dependence here is quite straightforward. <br><br>  <b>Edit:</b> <br><br>  As suggested in the comments, you can use the Fourier transform to directly convert the image into sound.  A quick test shows the following results (pictures are the same): <br>  Test-1: <a href="https://cloud.mail.ru/public/2C5Z/5MEQ8Swjo">cloud.mail.ru/public/2C5Z/5MEQ8Swjo</a> <br>  Test-2: <a href="https://cloud.mail.ru/public/2dxp/3sz8mjAib">cloud.mail.ru/public/2dxp/3sz8mjAib</a> <br>  Test-3: <a href="https://cloud.mail.ru/public/3NjJ/ZYrfdTYrk">cloud.mail.ru/public/3NjJ/ZYrfdTYrk</a> <br><br>  Tests sound interesting, at least for small and large squares (files 1 and 3), the difference in hearing is clearly noticeable.  But the shape of the figures (1 and 2) is almost the same, so here too there is something to think about.  But in general, the sound received using FFT, I like the ear more. <br><br><h2>  Conclusion </h2><br>  This test, of course, is not a dissertation, but simply a proof of concept, made in a few hours of free time.  But even so, it basically works, and the difference in hearing is quite real.  I do not know whether it is possible to learn to navigate in space with such sounds, hypothetically probably after some training.  Although there is a huge field for improvements and experiments, for example, you can use stereo sound, which will allow you to better separate objects from different sides, you can experiment with other ways of converting an image into sound, for example, encode a color with different frequencies, etc. Finally, the promising use of 3d-cameras capable of perceiving depth (alas, there is no such camera available).  By the way, with the help of a simple code on OpenCV, the above algorithm can be adapted to the use of a web-camera, which will allow you to experiment with dynamic images. <br><br>  Well, as usual, all successful experiments. </div><p>Source: <a href="https://habr.com/ru/post/458962/">https://habr.com/ru/post/458962/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458952/index.html">Setting PostgreSQL Options for Performance Optimization</a></li>
<li><a href="../458954/index.html">What types of detection are useful in video surveillance. Mechanisms and functions</a></li>
<li><a href="../458956/index.html">Machine Learning vs. analytical approach</a></li>
<li><a href="../45896/index.html">Do not allocate Bold</a></li>
<li><a href="../458960/index.html">Corporate Quest</a></li>
<li><a href="../458964/index.html">TestMace. Fast start</a></li>
<li><a href="../458966/index.html">Scientists and heads of technology corporations consider the withdrawal of industrial enterprises into space a reality</a></li>
<li><a href="../45897/index.html">How to connect PC and smartphone via WiFi Ad-Hoc</a></li>
<li><a href="../458970/index.html">Use UIViewPropertyAnimator to create custom animations</a></li>
<li><a href="../458972/index.html">News of the week: Yandex and Western intelligence agencies, FAS is fighting online casinos, the Ministry of Transport regulates the work of BlaBlaCar</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>