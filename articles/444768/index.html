<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Decreased dependence on tagged data on generative-contention networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Generative Adversarial Networks (GAN) is a class of deep generative models with interesting capabilities. Their main idea is to train two neural netwo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Decreased dependence on tagged data on generative-contention networks</h1><div class="post__text post__text-html js-mediator-article">  Generative Adversarial Networks (GAN) is a class of deep generative models with interesting capabilities.  Their main idea is to train two neural networks, a generator that learns to synthesize data (for example, images), and a discriminator who learns how to distinguish real data from those synthesized by the generator.  This approach has been successfully used for <a href="https://arxiv.org/abs/1809.11096">high-quality image synthesis</a> , <a href="https://arxiv.org/abs/1805.11057">improved image compression</a> , and others. <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/6c1/e57/7e2/6c1e577e2448d132cbf99ee46ffee4ff.gif"><br>  <i>The evolution of the generated samples in the process of learning on ImageNet.</i>  <i>The generator is limited to the image class (for example, "bearded owl" or "golden retriever").</i> <br><br>  In the field of the synthesis of natural images, the best GGSs achieve the best results, which, unlike the unconditional ones, use labels (‚Äúmachine‚Äù, ‚Äúdog‚Äù, etc.) during training.  And although this facilitates the task and provides a significant improvement in the result, such an approach requires a large amount of tagged data, which are rarely encountered in practice. <br><br>  In our <a href="https://arxiv.org/abs/1903.02271">work</a> ‚ÄúGenerating high-quality images with fewer tags‚Äù, we propose a new approach to reduce the amount of tagged data needed to train advanced conventional GSS.  Combining this approach with recent breakthroughs in the development of large-scale GSS, we produce comparable in quality natural images using 10 times less tags.  We are also releasing a large update of <a href="https://github.com/google/compare_gan">the Compare GAN library</a> based on this study, which contains all the necessary components for training and evaluating modern GSS. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Improvements through semi-surveillance and self-supervision </h2><br>  In conditional GSS, the generator and discriminator are usually limited to class labels.  In our work, we propose to replace manually stamped labels with supposed ones.  To derive good quality labels for a large set of mostly unmarked data, we use a two-step approach.  First, we learn how to present the features of the image only by the example of the unpartitioned part of the base.  To learn the presentation of features, we use self-supervision in the form of a <a href="https://arxiv.org/abs/1803.07728">recently proposed approach</a> , in which unmarked data is randomly mixed, and the deep convolutional neural network predicts the angle of rotation.  The idea is that models must be able to recognize the main objects and their forms in order to successfully accomplish this task: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f34/2f8/66e/f342f866e7c1b83d60a5367d99502f27.png"><br><br>  Then we consider the activation sequence of one of the intermediate layers of the trained network as a new representation of the features of the input data, and train the classifier to recognize the label of these input data using the marked part of the initial data set.  Since the network was previously trained to extract semantically meaningful data features (on a task with turn prediction), learning this classifier is more effective in examples than learning a whole network from scratch.  Finally, we use this classifier to mark up unallocated data. <br><br>  In order to further enhance the quality of the model and the stability of training, we encourage the discriminator's network to learn meaningful ideas about features that are not forgotten during training due to the auxiliary losses presented by us <a href="https://arxiv.org/abs/1811.11212">earlier</a> .  These two advantages, together with large-scale training, are provided by advanced conditional GSS, which are well suited for image synthesis from ImageNet, judging by the <a href="https://arxiv.org/abs/1706.08500">Frechet distance</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db8/1e9/32f/db81e932fa204d28b66ec4c2e709af9d.png"><br>  <i>The generator network produces an image based on its own vector.</i>  <i>In each row, linear interpolation of the own codes of the leftmost and rightmost images leads to semantic interpolation in the image space.</i> <br><br><h2>  Compare GAN library for training and assessment of GSS </h2><br>  Advanced research in the field of GSS is highly dependent on well-developed and proven code, since even the reproduction of previous results and techniques require great effort.  To support open science and allow the research community to develop on the basis of recent breakthroughs, we are releasing a large update of the Compare GAN library.  It includes loss functions, regularization and normalization schemes, neural network architectures and numerical metrics often used in modern GSS.  She also supports: <br><br><ul><li>  Training on the GPU and TPU. </li><li>  Simple setup using <a href="https://github.com/google/gin-config">Gin</a> ( <a href="https://github.com/google/compare_gan/tree/master/example_configs">examples</a> ). </li><li>  A huge number of data sets through the library <a href="https://github.com/tensorflow/datasets">TensorFlow</a> . </li></ul><br><h2>  Conclusion and plans for the future </h2><br>  Given the gap between labeled and unmarked data sources, <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">it is becoming increasingly important to</a> be able to learn from only partially tagged data.  We have shown that a simple but powerful combination of self-supervision and semi-surveillance can help bridge this gap for the GSS.  We believe that self-supervision is a promising idea that needs to be explored for other areas of generative modeling. </div><p>Source: <a href="https://habr.com/ru/post/444768/">https://habr.com/ru/post/444768/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../444758/index.html">Technical differences between BI systems (Power BI, Qlik Sense, Tableau)</a></li>
<li><a href="../444760/index.html">CNC machine from what was lying around in the garage</a></li>
<li><a href="../444762/index.html">CSTroN - a homemade monitor on a vintage CSTN-matrix with a VGA-input and control board on the FPGA</a></li>
<li><a href="../444764/index.html">Java cryptography</a></li>
<li><a href="../444766/index.html">Facebook employees had access to the passwords of Facebook and Instagram users.</a></li>
<li><a href="../444770/index.html">How we looked for data leakage in SimilarWeb</a></li>
<li><a href="../444774/index.html">Error with ru-RU locale migration to Google Chrome and how to get rid of it</a></li>
<li><a href="../444776/index.html">Do not be afraid to try, or How I became a programmer at an age far beyond 18</a></li>
<li><a href="../444778/index.html">As I did not become a machine learning specialist</a></li>
<li><a href="../444780/index.html">Self-timed circuits. Calculation of logical functions directly on the event graph. Part 3. Decomposition</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>