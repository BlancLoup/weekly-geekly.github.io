<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Cook ML Boot Camp III: Starter Kit</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="March 16 ended the machine learning competition ML Boot Camp III . I am not a real welder, but, nevertheless, I was able to achieve the 7th place in t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Cook ML Boot Camp III: Starter Kit</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/files/26e/678/ae8/26e678ae84194809860d400f066ec2bc.png"></div><br><p>  March 16 ended the machine learning competition <a href="http://mlbootcamp.ru/championship/10/">ML Boot Camp III</a> .  I am not a real welder, but, nevertheless, I was able to achieve the 7th place in the final results table.  In this article I would like to share how to start participating in such kind of championships, what you should pay attention to for the first time when solving a problem, and tell about your approach. </p><a name="habracut"></a><br><h1 id="ml-boot-camp-iii">  ML Boot Camp III </h1><br><p>  This is an open machine learning championship organized by the Mail.Ru Group.  As a task, it was proposed to predict whether the player will remain in the online game or leave it.  As data, the organizers gave already processed statistics on users for the last 2 weeks. </p><br><div class="spoiler">  <b class="spoiler_title">Data description</b> <div class="spoiler_text"><ul><li>  maxPlayerLevel - the maximum level of the game that the player has passed; </li><li>  numberOfAttemptedLevels - the number of levels that the player tried to pass; </li><li>  attemptsOnTheHighestLevel - the number of attempts made at the highest level; </li><li>  totalNumOfAttempts - total number of attempts; </li><li>  averageNumOfTurnsPerCompletedLevel - the average number of moves performed on successfully completed levels; </li><li>  doReturnOnLowerLevels - whether the player made returns to the game at levels already completed; </li><li>  numberOfBoostersUsed - the number of boosters used; </li><li>  fractionOfUsefullBoosters - the number of boosters used during successful attempts (the player has passed the level); </li><li>  totalScore - total points scored; </li><li>  totalBonusScore - total bonus points earned; </li><li>  totalStarsCount - the total number of stars scored; </li><li>  numberOfDaysActuallyPlayed - the number of days the user played the game. </li></ul></div></div><br><p>  More details about the championship can be found on <a href="http://mlbootcamp.ru/championship/10/">the project website</a> . </p><br><h1 id="chitaem-pravila">  Read the rules </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/01e/7f4/eeb/01e7f4eebeaa44d2b2ccea886274be6b.png"></div><br><p>  In contrast to the instructions for household appliances, there is useful information.  What to look for: </p><br><ul><li>  input and output formats; </li><li>  maximum number of packages per day; </li><li>  quality criterion / evaluation function. </li></ul><br><p>  The latter is perhaps the most important part of the rules, since  it is precisely this function that we will need to minimize (sometimes maximize).  This time the <a href="https://www.kaggle.com/wiki/LogarithmicLoss">logarithmic loss function</a> was used: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/5de/c68/162/5dec68162286427c957b7f9468459b40.png"></div><br><p>  Here <br>  N is the number of examples. <br>  M is the number of classes (there are only two) <br>  Pij is the predicted probability of class i belonging to example i <br>  Yij - equals 1 if example i really belongs to class j, and 0 otherwise </p><br><p>  It is important to note that this formula strongly ‚Äúpunishes‚Äù self-confidence in the answers.  Therefore, as a solution, it is more profitable to send the probability that the player will continue to play instead of the unambiguous "1" and "0". </p><br><p>  Sometimes studying the evaluation function allows you to cheat a little and get extra points (as the winner of the past and the current competition <a href="https://habrahabr.ru/company/mailru/blog/321016/">did</a> ). </p><br><p>  More information on different metrics can be read <a href="https://www.kaggle.com/wiki/Metrics">here</a> . </p><br><h1 id="instrumentariy">  Tools </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/48b/38d/39d/48b38d39d8ad464fbc3e01ca33a053f3.png"></div><br><p>  There are <a href="https://www.kaggle.com/wiki/Software">many</a> tools that can be used during the championship.  If the conversations of people about machine learning sound like curses to you, I can advise you to gallop around ML and familiarize yourself with the basic algorithms <a href="http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/">here</a> . </p><br><p>  This time most of the participants chose between Python and R. The general recommendation is: stick to one language and explore the possibilities of the available tools more deeply.  For both languages ‚Äã‚Äãthere are good solutions, and the most popular libraries (for example XGBoost) are available both there and there. </p><br><p>  In the case of urgent need, you can always do some separate calculation using a different package.  For example, the t-SNE transform, which in the python implementation drops helplessly, eating up all the memory. </p><br><p>  I chose python, and my final solution used the following libraries: </p><br><ul><li>  <a href="http://scikit-learn.org/stable/">scikit learn</a> is a great toolkit for machine learning.  Initially, you can only be limited to her. </li><li>  <a href="http://xgboost.readthedocs.io/en/latest/">XGBoost</a> - gradient boosting.  One of the most favorite libraries of participants in machine learning championships. </li><li>  <a href="https://github.com/Microsoft/LightGBM">LightGBM</a> is an alternative to XGBoost, in my case it worked an order of magnitude faster than the latter, but produced slightly less accurate results. </li><li>  <a href="https://github.com/Lasagne/Lasagne">Lasagne</a> is a library for creating and training neural networks using Theano.  As an alternative, you can try Keras - it looks a little more simple and there is more documentation on it.  But the horses at the crossing do not change and I decided to stick with the initial choice. </li></ul><br><h1 id="pervyy-sabmit">  First submit </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ead/9e2/70e/ead9e270e109436d9f9e28526098e750.png"></div><br><p>  To begin with, let's try to read all the input data and display a test answer consisting of only zeros. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd &gt;&gt;&gt; X_train = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'x_train.csv'</span></span>, sep=<span class="hljs-string"><span class="hljs-string">';'</span></span>) &gt;&gt;&gt; X_test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'x_test.csv'</span></span>, sep=<span class="hljs-string"><span class="hljs-string">';'</span></span>) &gt;&gt;&gt; y_train = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'y_train.csv'</span></span>, header=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>).values.ravel() &gt;&gt;&gt; print(X_train.shape, X_test.shape, y_train.shape) (<span class="hljs-number"><span class="hljs-number">25289</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>) (<span class="hljs-number"><span class="hljs-number">25289</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>) (<span class="hljs-number"><span class="hljs-number">25289</span></span>,) &gt;&gt;&gt; result = np.zeros((X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])) &gt;&gt;&gt; pd.DataFrame(result).to_csv(<span class="hljs-string"><span class="hljs-string">'submit.csv'</span></span>, index=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, header=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> </div></div><br><p>  After you have checked the load / save data and obtained a point of reference for evaluation, you can train a simple model.  As an example, I took RandomForestClassifier. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier &gt;&gt;&gt; clf = RandomForestClassifier() &gt;&gt;&gt; clf.fit(X_train, y_train) &gt;&gt;&gt; result = clf.predict_proba(X_test)[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] &gt;&gt;&gt; pd.DataFrame(result).to_csv(<span class="hljs-string"><span class="hljs-string">'submit.csv'</span></span>, index=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, header=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> </div></div><br><p>  If we run the previous example again and send the result for verification, then, with a high probability, we will get another assessment.  This is due to the fact that within many algorithms a random number generator is used.  This behavior greatly complicates the assessment of the impact of future changes in the model on the final result.  To avoid this problem, we can: </p><br><div class="spoiler">  <b class="spoiler_title">Fix the seed value</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>np.random.seed(<span class="hljs-number"><span class="hljs-number">2707</span></span>) &gt;&gt;&gt; clf = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>) ...</code> </pre> </div></div><br><p>  or </p><br><div class="spoiler">  <b class="spoiler_title">Run the algorithm with different seed and take the average result</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>runs = <span class="hljs-number"><span class="hljs-number">1000</span></span> &gt;&gt;&gt; results = np.zeros((runs, X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])) &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(runs): ‚Ä¶ clf = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>+i) ‚Ä¶ clf.fit(X_train, y_train) ‚Ä¶ results[i, :]=clf.predict_proba(X_test)[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] &gt;&gt;&gt; result = results.mean(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> </div></div><br><p>  In the second variant, we get a more stable result, but it is obvious that it takes much more time to calculate, so I used it already for the final checks. </p><br><p>  More examples can be found in the <a href="http://mlbootcamp.ru/article/tutorial/">training article</a> from the organizers.  There you can also find information about working with categorical features, which I do not touch on in this article. </p><br><h1 id="podgotovka-dannyh">  Data preparation </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/7d6/bb2/fc3/7d6bb2fc33e5449dbdd1b11e72fff250.png"></div><br><p>  In order to lower the threshold of entry, the organizers prepared the data fairly well, and no further cleaning was required.  Moreover, attempts to remove duplicates or outliers in a training set only led to a deterioration in the result. </p><br><p>  About duplicates, it is worth noting that they often belonged to different classes (users with the same data could either stay or leave the game), and without additional information, it is difficult to make an accurate prediction.  Fortunately, most models coped with this on their own, deriving probabilities that minimize the estimated function, in our case, log loss. </p><br><p>  UPD: the participant from third place still <a href="https://habrahabr.ru/post/324590/">managed to</a> use this fact to his advantage. </p><br><p>  The data prepared by the organizers is rather an exception to the rules, which means you need to be ready to process them yourself.  In addition to duplicate rows and outliers, the data may contain missing values.  It is too wasteful to delete lines with missing values, since  they still contain useful information.  Therefore, we have 2 options left: </p><br><ul><li>  leave everything as it is: some algorithms can work with missing (NA) values; </li><li>  try to restore them. </li></ul><br><p>  To restore, you can simply replace with the more common (categorical signs), average or median value.  In python, you can use the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html">sklearn.preprocessing.Imputer</a> class for this.  There are more complex methods using other features (for example, the average value among users of the same level), I even tried to train another model that predicts the missing value for other columns.  Oh yeah, I wrote above that the data is prepared and there are no missing values, in fact this is not quite so. </p><br><p>  If you read the rules carefully, it becomes clear that almost all signs are statistics based on logs for 2 weeks.  A more detailed study of the data shows that quite a few users started playing earlier than 2 weeks ago.  If we screen them out, then I received incredibly good marks for cross-validation, which led me to believe that improving predictions for the remaining ‚Äúdirty‚Äù data might be the key to victory.  Attempts to restore data to the user at the time of 2 weeks ago did not give a strong increase, but I left this decision and later used it together with others. </p><br><p>  Another trick that came to my mind is to multiply the number of signs of such users by -1.  This separates them from the rest of the mass in training and shows itself well, especially considering the simplicity of the method. </p><br><div class="spoiler">  <b class="spoiler_title">Some charts</b> <div class="spoiler_text"><p>  All data: <br><img src="https://habrastorage.org/files/831/72a/45c/83172a45cec04a0280636cd89665546a.png" alt="image"></p><br><p>  Only users who started playing during the 2-week period: <br><img src="https://habrastorage.org/files/eb7/5d6/ebb/eb75d6ebbc904a299cece3bb81759e8d.png" alt="image"></p><br><p>  Attempt to recover data in other columns: <br><img src="https://habrastorage.org/files/3ce/01d/3bf/3ce01d3bff86423f9e86b7d7dd01c04d.png" alt="image"></p><br><p>  ‚ÄúInvert‚Äù for users who started playing earlier than 2 weeks ago: <br><img src="https://habrastorage.org/files/040/b0a/187/040b0a18745943a2aaa38829851b3f02.png" alt="image"></p></div></div><br><p>  In certain cases, it makes sense to immediately get rid of some signs: </p><br><ul><li>  constant signs; </li><li>  two strongly correlated traits (only one of them is needed); </li><li>  signs with close to zero variance. </li></ul><br><p>  Although this increases the speed of calculations, and sometimes improves the overall quality of models, but with the removal of signs, you need to be extremely careful. </p><br><p>  The last thing you can do with the initial data is scaling.  By itself, it does not change the dependencies between features, but it can significantly improve the predictions for some (for example, linear) models.  In python, you can use the following classes: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">sklearn.preprocessing.StandardScaler</a> , <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html">sklearn.preprocessing.MinMaxScaler</a> and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html">sklearn.preprocessing.MaxAbsScaler</a> . </p><br><p>  <strong>Each of the data transformations should be carefully checked.</strong>  <strong>What works in one case can have a negative effect in another, and vice versa.</strong> </p><br><p>  <strong>Always (!) Check that the test sample passes through the exact same transformations as the training one.</strong> </p><br><h1 id="proveryaem-sebya">  We check ourselves </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/253/8f4/f30/2538f4f306a9482ab5e11f766141d623.png"></div><br><p>  The entire data set is divided into two parts: the training and test samples.  The test sample is divided in a 40/60 ratio into public and hidden.  How well the model predicted the result for the public part determines the position in the leaderboard throughout the championship, and the prediction score for the hidden part becomes available only at the very end and determines the final positions of the participants. </p><br><p>  If we focus only on the results of the public part of the test sample, then this will most likely lead to a retraining of the model and a strong drop in the rating after the discovery of hidden results.  To avoid this, as well as to be able to locally check how much the model has improved / deteriorated, cross-validation is used. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ce0/23b/708/ce023b708e34401991dfc8091a304bf6.png"></div><br><p>  We break the data into K-folds: we fold the K-1 folds, and for the rest we predict and consider the prediction estimate.  So repeat for all K folds.  The final score is calculated as the average of the scores for each fold. </p><br><p>  In addition to the average value, you should pay attention to the standard deviation of the estimates (std), this parameter may be even more important than the average fold score, since  Shows how strong the spread in the predictions for different folds.  The value of std can grow strongly with increasing K, you should bear this in mind and not be afraid. </p><br><p>  An important role is played by the quality of splitting into folds.  To preserve the distribution of classes at the breakdown, I used <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html">sklearn.model_selection.StratifiedKFold</a> .  This is especially important if the classes are initially highly unbalanced.  In addition, there may be other problems with the distribution of data on the folds (days of the week, time, users, etc.) that need to be checked and corrected separately. </p><br><p>  As before, wherever a random number generator is used, we fix the seed value so that any result can be reproduced. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StratifiedKFold, cross_val_score &gt;&gt;&gt; clf = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>) &gt;&gt;&gt; kf = StratifiedKFold(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>, n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) &gt;&gt;&gt; scores = cross_val_score(clf, X_train, y_train, cv=kf) &gt;&gt;&gt; print(<span class="hljs-string"><span class="hljs-string">"CV scores:"</span></span>, scores) CV scores: [ <span class="hljs-number"><span class="hljs-number">0.8082625</span></span> <span class="hljs-number"><span class="hljs-number">0.81059707</span></span> <span class="hljs-number"><span class="hljs-number">0.8024911</span></span> <span class="hljs-number"><span class="hljs-number">0.81431679</span></span> <span class="hljs-number"><span class="hljs-number">0.81926043</span></span>] &gt;&gt;&gt; print(<span class="hljs-string"><span class="hljs-string">"mean:"</span></span>, np.mean(scores)) mean: <span class="hljs-number"><span class="hljs-number">0.810985579862</span></span> &gt;&gt;&gt; print(<span class="hljs-string"><span class="hljs-string">"std:"</span></span>, np.std(scores)) std: <span class="hljs-number"><span class="hljs-number">0.00564433052781</span></span></code> </pre> </div></div><br><p>  Using different schemes for cross-validation, it is desirable to achieve a minimum difference of local and public assessment.  If the estimates do not coincide and local cross-validation is considered correct, it is customary to rely on a local assessment. </p><br><h1 id="uslozhnyaem-model-chto-rabotaet-to-ne-bezobrazno">  Complicate the model (what works is not ugly) </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/499/822/8b2/4998228b2902470b9c95c98eefc7da61.png"></div><br><p>  <strong>Tuning</strong> </p><br><p>  The selection of hyper-parameters for MO algorithms can be considered as the task of minimizing a function that returns an estimate of the model with these parameters for cross-validation. </p><br><p>  Consider several options for solving this problem. </p><br><ul><li>  Bruteforce ( <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">sklearn.model_selection.GridSearchCV</a> ).  Despite brute force, this method can be quite effective.  XGBoost models I tuned them.  And here is <a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">a</a> good guide how you can do it and not wait a few days.  The method is also good because in order to save time, it makes you better understand the value of hyper-parameters. </li><li>  Randomized bust ( <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">sklearn.model_selection.RandomizedSearchCV</a> ).  As an advantage, it can be noted that the number of rebounds can be set regardless of the number of parameters. </li><li>  <a href="https://github.com/hyperopt/hyperopt">hyperopt</a> .  It allows you to select many hyper-parameters at once, including for neural networks with different number of layers, which is especially convenient if you need to find a configuration from which you will then push off. </li><li>  <a href="https://en.wikipedia.org/wiki/Differential_evolution">Differential evolution</a> . </li><li>  Manual fit, etc. </li></ul><br><p><del>  By the way, if for cross-validation you use the <code>cros_val_score</code> Learn library cros_val_score method, then you should pay attention to the fact that some algorithms can take into their <code>fit</code> method a metric that they will minimize when training.  And in order to set this parameter during cross-validation, you need to use <code>fit_params</code> . </del></p><br><p>  The UPD: <code>eval_metric</code> parameter in the xgboost and LightGBM libraries sets the metric by which eval_set is evaluated for early stopping.  In other words, in the fit method, the data set is transferred, on which the model is evaluated using <code>eval_metric</code> at each step of the gradient boosting, in the case where the <code>early_stopping_rounds</code> steps in a row the assessment for <code>eval_set</code> does not improve, then the learning stops. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs">clf = xgb.XGBClassifier(seed=<span class="hljs-number"><span class="hljs-number">2707</span></span>) kf = StratifiedKFold(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>, n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>, fit_params={<span class="hljs-string"><span class="hljs-string">'eval_metric'</span></span>:<span class="hljs-string"><span class="hljs-string">'logloss'</span></span>})</code> </pre> </div></div><br><p>  <strong>Calibration (Hello Garus!)</strong> </p><br><p>  The idea of ‚Äã‚Äãcalibration is that if the model gives a prediction of belonging to the class of 0.6, then among all the samples to which she gave this prediction, 60% really belong to this class.  The Scikit Learn library contains the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html">sklearn.calibration.CalibratedClassifierCV</a> class for this.  This can improve the assessment, but we must remember that the calibration mechanism is used for cross-validation, which means that it will greatly increase the training time. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.calibration <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CalibratedClassifierCV kf = StratifiedKFold(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>, n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) clf = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>) scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring=<span class="hljs-string"><span class="hljs-string">"neg_log_loss"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"CV scores:"</span></span>, -scores) print(<span class="hljs-string"><span class="hljs-string">"mean:"</span></span>, -np.mean(scores)) clf = CalibratedClassifierCV(clf,method=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>, cv=StratifiedKFold(random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>, n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring=<span class="hljs-string"><span class="hljs-string">"neg_log_loss"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"CV scores:"</span></span>, -scores) print(<span class="hljs-string"><span class="hljs-string">"mean:"</span></span>, -np.mean(scores)) CV scores: [ <span class="hljs-number"><span class="hljs-number">1.12679227</span></span> <span class="hljs-number"><span class="hljs-number">1.01914874</span></span> <span class="hljs-number"><span class="hljs-number">1.24362513</span></span> <span class="hljs-number"><span class="hljs-number">0.97109882</span></span> <span class="hljs-number"><span class="hljs-number">1.07280166</span></span>] mean: <span class="hljs-number"><span class="hljs-number">1.08669332288</span></span> CV scores: [ <span class="hljs-number"><span class="hljs-number">0.41028741</span></span> <span class="hljs-number"><span class="hljs-number">0.4055759</span></span> <span class="hljs-number"><span class="hljs-number">0.4134125</span></span> <span class="hljs-number"><span class="hljs-number">0.40244068</span></span> <span class="hljs-number"><span class="hljs-number">0.39892905</span></span>] mean: <span class="hljs-number"><span class="hljs-number">0.406129108769</span></span> &lt;--- </code> </pre> </div></div><br><p>  <strong>Bagging</strong> </p><br><p>  The idea is to run the same algorithm on different (not complete) sets of training samples and traits and then use the average prediction of such models.  As always, Scikit Learn already contains everything that we need, which greatly saves our time, just use the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html">sklearn.ensemble.BaggingClassifier</a> class. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier, BaggingClassifier‚Äã kf = StratifiedKFold(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>, n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) clf = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">2707</span></span>)‚Äã scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring=<span class="hljs-string"><span class="hljs-string">"neg_log_loss"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"CV scores:"</span></span>, -scores) print(<span class="hljs-string"><span class="hljs-string">"mean:"</span></span>, -np.mean(scores))‚Äã clf = BaggingClassifier(clf, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>) scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring=<span class="hljs-string"><span class="hljs-string">"neg_log_loss"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"CV scores:"</span></span>, -scores) print(<span class="hljs-string"><span class="hljs-string">"mean:"</span></span>, -np.mean(scores)) CV scores: [ <span class="hljs-number"><span class="hljs-number">1.12679227</span></span> <span class="hljs-number"><span class="hljs-number">1.01914874</span></span> <span class="hljs-number"><span class="hljs-number">1.24362513</span></span> <span class="hljs-number"><span class="hljs-number">0.97109882</span></span> <span class="hljs-number"><span class="hljs-number">1.07280166</span></span>] mean: <span class="hljs-number"><span class="hljs-number">1.08669332288</span></span> CV scores: [ <span class="hljs-number"><span class="hljs-number">0.51778172</span></span> <span class="hljs-number"><span class="hljs-number">0.46840953</span></span> <span class="hljs-number"><span class="hljs-number">0.52678512</span></span> <span class="hljs-number"><span class="hljs-number">0.5137191</span></span> <span class="hljs-number"><span class="hljs-number">0.52285478</span></span>] mean: <span class="hljs-number"><span class="hljs-number">0.509910050424</span></span></code> </pre> </div></div><br><p>  Of course, no one forbids using it in conjunction with calibration. </p><br><p>  <strong>Composite models</strong> </p><br><p>  It is not uncommon for data to be divided into groups for which it is more advantageous to predict using different models.  For example, some participants divided into different groups by player level and predicted them by different models. </p><br><p>  My best model used such a principle.  I divided into two groups: those who started playing within 2 weeks, and those who started earlier.  And in the first group I added also those who at the time of the beginning of logging were of the 1st level, since  this improved the overall rating.  As models, I took xgboost with different hyper-parameters and used for them different sets of features.  And when teaching the second model, I used all the data, but for users who started playing earlier than 2 weeks ago, I gave a weight equal to 3. </p><br><p>  <strong>Dirty tricks</strong> </p><br><p>  It should be understood that the competition and the actual use of machine learning algorithms are completely different things.  Here you can make huge and slow models, which at the expense of extra days of calculations will give a fraction of percent accuracy in the assessment, or even use the manual adjustment of the answers to increase accuracy.  Most importantly, beware of retraining in a public assessment. </p><br><h1 id="bolshe-dannyh">  More data! </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/261/071/b98/261071b9860343118c2799afae2efffd.png"></div><br><p>  In order to squeeze the last drops of information from the data provided to us, you can (need!) Try to generate new signs.  Creating a good feature set from the data provided is often a key factor in winning machine learning championships. </p><br><ul><li>  Multiplying or dividing existing features is a simple but effective way. </li><li>  Extraction of new signs.  For example, the day of the week from the date, the number of characters from the text, etc. </li><li>  Nonlinear transformation of an existing trait allows one to bring the distribution of magnitude closer to normal, which in some cases (the same neural networks) gives the best result.  Examples: log (x), log (x + 1), sqrt (x), sqrt (x + 1), etc. </li><li>  Other.  All that you have enough imagination: the maximum degree of two, which is divided into a number, the difference in age with the president, etc.  One of the signs I generated, which was used in the final models, was calculated by the formula: </li></ul><br><pre> <code class="python hljs">raw_data[<span class="hljs-string"><span class="hljs-string">'totalScore'</span></span>] / (<span class="hljs-number"><span class="hljs-number">1</span></span> + np.log(<span class="hljs-number"><span class="hljs-number">1</span></span>+raw_data[<span class="hljs-string"><span class="hljs-string">'maxPlayerLevel'</span></span>]) * raw_data[<span class="hljs-string"><span class="hljs-string">'maxPlayerLevel'</span></span>])</code> </pre> <br><p>  Now, when we have a lot of new signs, we need to somehow select the optimal set, which gives the best estimate. </p><br><p>  Using <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">PCA</a> or <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">TruncatedSVD,</a> you can reduce the dimension of the attribute space to increase the speed of the algorithms.  However, there is a big risk of ignoring non-linear dependencies between the data, as well as losing important signs completely. </p><br><p>  Many algorithms, such as, for example, gradient boosting, due to their device make it quite easy to obtain information about the importance of a particular feature in a trained model.  This information can be used to filter out unimportant columns. </p><br><div class="spoiler">  <b class="spoiler_title">Example</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> xgboost <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> xgb <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> xgboost <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plot_importance clf = xgb.XGBClassifier(seed=<span class="hljs-number"><span class="hljs-number">2707</span></span>) clf.fit(X_train, y_train, eval_metric=<span class="hljs-string"><span class="hljs-string">'logloss'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> a, b <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sorted(zip(clf.feature_importances_, X_train.columns)): print(a,b, sep=<span class="hljs-string"><span class="hljs-string">'\t\t'</span></span>) plot_importance(clf) plt.show()</code> </pre> <br><pre> <code class="hljs css">0<span class="hljs-selector-class"><span class="hljs-selector-class">.014771</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">numberOfAttemptedLevels</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.014771</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">totalStarsCount</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.0221566</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">totalBonusScore</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.0295421</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">doReturnOnLowerLevels</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.0354505</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">fractionOfUsefullBoosters</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.0531758</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">attemptsOnTheHighestLevel</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.0886263</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">numberOfBoostersUsed</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.118168</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">totalScore</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.128508</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">averageNumOfTurnsPerCompletedLevel</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.144756</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">maxPlayerLevel</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.172821</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">numberOfDaysActuallyPlayed</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.177253</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">totalNumOfAttempts</span></span></code> </pre> <br><p><img src="https://habrastorage.org/files/418/6c8/c74/4186c8c74fe1443f9a7c20fd2218c7ed.png" alt="image"></p></div></div><br><p>  As always, you need to be extremely careful with the removal of signs.  Removing unimportant signs can spoil the accuracy of prediction, and removing the most important ones, on the contrary, can improve.  I used this method to screen out completely hopeless signs. </p><br><p>  There are more classical approaches for the selection of signs.  In this competition, I intensively used the greedy algorithm, the idea of ‚Äã‚Äãwhich is to add new features one by one to the set and choose the one that gives the best estimate for cross-validation.  You can also throw away signs one by one.  Alternating these approaches, I scored the final samples.  This is an easy-to-write algorithm, but it ignores features that increase accuracy well in a set with several others.  From this point of view, it would be more productive to encode the use of signs by a binary vector and use a genetic algorithm. </p><br><h1 id="rabota-nad-oshibkami">  Bug work </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/1a6/634/ed3/1a6634ed33b642a0a5b4a8b10720e621.png"></div><br><div class="spoiler">  <b class="spoiler_title">Trite but true</b> <div class="spoiler_text"><p>  Glory and prizes are nice, of course, but my main motivation this time was to gain experience and knowledge.  And, of course, the learning process is not without errors.  Analysis of which brought me the most understanding of what I was doing.  And if you are a newbie like me, then my advice is: try everything.  Having several different results, it is easier to evaluate each of them relative to the others, to compare them with each other.  And attempts to explain to ourselves why what is happening, lead to a deeper understanding of the operation of algorithms. </p></div></div><br><p>  The process of working with data and models described above in the article is not linear, and during the championship I occasionally returned to new models, now to generate new features and tuning models for them.  As a result, several good models have accumulated, the results of which I used for the final prediction. </p><br><p>  In case you are stuck at dead center: </p><br><ul><li>  remember the local minimum: perhaps, some idea will first give a result worse than the current one, but its further development or combination with other ideas will be your ‚Äúkiller feature‚Äù; </li><li>  one can almost always find scientific papers on the subject of the assignment, which may give rise to thoughts; </li><li>  study the decisions of participants of other championships (kaggle); </li><li>  Try different models or even more feature generation. </li></ul><br><h1 id="bolshe-modeley">  More models! </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/bcd/2e6/92a/bcd2e692a19f47fea05440314a711752.png"></div><br><p>  Suppose, after many agonies and sleepless nights, we got one good model with a good rating on a local CV and, ideally, a good rating in public.  In addition, it turned out a couple more models of slightly worse quality.  Do not immediately throw the last.  The fact is that the predictions of several models can be combined in different ways and get even more accurate.  This is a pretty big topic and I recommend starting with <a href="http://mlwave.com/kaggle-ensembling-guide/">this article</a> .  Here I will share two methods of different complexity that I managed to bring to mind. </p><br><p>  The simplest approach, and in my case also a more efficient one, turned out to be a banal arithmetic average between solutions of several models.  As variations of this method, you can use the geometric mean, as well as add weight to the models. </p><br><p>  The second approach is stacking.  Here you can eat oats ... The idea is simple: use the predictions of the first level models as input to another algorithm.  Sometimes initial data is added to these predictions or the results of first-level models are used to generate new features.    ,       (   -),     .       : holdout set  out-of-fold predictions. </p><br><p> Holdout set ‚Äî   (~10%)   ,       ,      .   ,         . </p><br><p> OOF predictions ‚Äî     K        ,    K-1 .         .        :  ,      (Variant   ),        ,       -1 ,       (Variant A). </p><br><p><img src="https://habrastorage.org/files/663/29f/824/66329f824a2f40a5b872a71f93425091.png" alt="image"></p><br><div class="spoiler">  <b class="spoiler_title">Example</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_oof</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf)</span></span></span><span class="hljs-function">:</span></span> oof_train = np.zeros((X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],)) oof_test = np.zeros((X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],)) oof_test_skf = np.empty((NFOLDS, X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, (train_index, test_index) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(kf.split(X_train, y_train)): x_tr = X_train[train_index] y_tr = y_train[train_index] x_te = X_train[test_index] clf.train(x_tr, y_tr) oof_train[test_index] = clf.predict_proba(x_te)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] oof_test_skf[i, :] = clf.predict_proba(X_test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] oof_test[:] = oof_test_skf.mean(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> oof_train.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), oof_test.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> </div></div><br><p>     ?    ,        (data leak),        ,     .        , ,  ,     . </p><br><p>  1: OOF predictions                 -. </p><br><p>  2:         K~=10,      1      holdout set. </p><br><p>  ,        ,     .          -, ,  ,    . </p><br><h1 id="dont-repeat-yourself"> Don't Repeat Yourself </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/files/d07/e5f/468/d07e5f46801c4f03af40da25c572f87d.png"></div><br><p>       ,     .       . ,  /   , -,  OOF ,   -  ..  , ,   ,  . ,      ,   . </p><br><p>     ,         ,    .          . </p><br><p> ,   Scikit Learn         ,    ,        ( <a href="http://scikit-learn.org/stable/developers/contributing.html"></a> ).     ,       ,              . </p><br><h1 id="itogi">  Results </h1><br><p>       .               <a href="https://t.me/mailrucontests"> telegram </a> .   ,    6    8            . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/990/2ef/724/9902ef724acf462093c1c75d261f75da.png"></div><br><p>        <a href="https://github.com/mortido/ML-Boot-Camp-III">GitHub</a> . </p><br><p>       ,       ,      ,      . </p><br><p>   ,   . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/324924/">https://habr.com/ru/post/324924/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../324914/index.html">We develop video chat between the browser and the mobile application</a></li>
<li><a href="../324916/index.html">The winning decision of the ML Boot Camp III contest</a></li>
<li><a href="../324918/index.html">Docker and detection of available resources inside the container</a></li>
<li><a href="../324920/index.html">How the CIA caused the rain: using Rain Maker to gather information from closed objects</a></li>
<li><a href="../324922/index.html">Threat Horizon 2017-2019 by the International Security Forum (executive executive)</a></li>
<li><a href="../324926/index.html">We are friends of Angular with Google (Angular Universal)</a></li>
<li><a href="../324930/index.html">WhatsApp messages may be available to outsiders: a serious vulnerability allows access to your correspondence</a></li>
<li><a href="../324932/index.html">Everything you wanted to know about stack traces and hip dumps. Part 1</a></li>
<li><a href="../324934/index.html">Getting ready for a PHP interview: Everything about iteration and a little about the ‚Äúiterable‚Äù pseudotype</a></li>
<li><a href="../324936/index.html">SQL or NoSQL - that is the question</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>