<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Security Scanners: Automatic Vulnerability Classification</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The growing number of threats is forcing developers of security analysis tools to constantly improve their solutions. Now on the information security ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Security Scanners: Automatic Vulnerability Classification</h1><div class="post__text post__text-html js-mediator-article"> <a href="http://habrahabr.ru/company/pt/blog/274241/"><img src="https://habrastorage.org/files/e48/eaa/e82/e48eaae8219e4535aea9e6d55bfd30ef.png"></a> <br><br>  The growing number of threats is forcing developers of security analysis tools to constantly improve their solutions.  Now on the information security market there is a wide range of security scanners from different manufacturers, which differ in their effectiveness.  This makes it impossible to release new versions of scanners without a competitive analysis of similar products. <br><br>  <a href="http://www.ptsecurity.ru/">Positive Technologies has</a> developed its own competitive analysis methodology for testing and comparing scanners according to objective criteria, such as the types and number of vulnerabilities found, the completeness of scanning various targets.  In addition, a database of competitive analysis was created (DBCA - Database of Competitive Analysis), which collected unique vulnerabilities found in the process of manual checks and automatic scanning of synthetic targets, real sites, CMS, web applications and other information systems by security scanners ( WebEngine - built-in <a href="http://www.ptsecurity.ru/appsecurity/application-firewall/">PT AF</a> and <a href="http://www.ptsecurity.ru/appsecurity/application-inspector/">PT AI</a> , <a href="https://www.acunetix.com/">Acunetix</a> , <a href="http://www-03.ibm.com/software/products/ru/appscan">AppScan</a> , etc.).  DBCA is used to compare the results of scanning with new versions of Positive Technologies scanners with the results of third-party scanners and screening false positives (false positive). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      However, filling a DBCA requires months of manual labor by highly qualified testing engineers.  The process of setting up environments and scanning takes a lot of time, sometimes weeks.  Validation of found vulnerabilities takes place even longer.  So, three engineers of the QA department worked on filling out the current base for a year.  In this regard, the need to accelerate and automate the work. <br><br>  The solution was the use of the <a href="http://math-n-algo.blogspot.ru/2013/04/blog-post.html">mathematical apparatus of neural networks</a> (NA) and fuzzy measuring scales.  We wrote about this in detail in the previous article ‚Äú <a href="http://habrahabr.ru/company/pt/blog/246197/">Security Scanners: Automatic Validation of Vulnerabilities Using Fuzzy Sets and Neural Networks</a> ‚Äù.  Theoretical studies have become the basis of a practical experiment set by Positive Technologies engineers: Timur Gilmullin, Vladimir Sofin, Artem Yushkovsky. <br><br>  The formal task of transforming the DBCA into a knowledge base was solved by using the NA (as a decisive rule) and fuzzy measuring scales (for linguistic evaluation of the classification results in a form understandable to man).  Practically, DBCA was supplemented by rules and mechanisms for screening out false positives, pre-sorted according to the degree of confidence in their presence, assessed on a fuzzy measuring scale.  This allowed us to speed up the work of testers in analyzing the results of scanning and screening out false positives. <a name="habracut"></a><br><br><h4>  Retrospective, acceptance criteria and main results </h4><br>  After completion of the initial filling of DBCA vulnerabilities, the database contained several tens of thousands of vulnerabilities.  Of these, testing engineers classified only about half during the year.  The results of our analysis showed that they performed up to 70% of unnecessary actions to screen out false positives for the entire scope of work. <br><br>  With regular competitive analysis, the use of an automatic system for validating vulnerabilities gives a huge performance increase and increases the efficiency of manual labor - you can reduce up to 70% of the amount of work required!  In addition, the use of the automatic system will free engineers for other priority tasks, which will increase the number of scanners participating in the competitive analysis and the number of scanned CMS. <br><br>  From the testing side, the following acceptance criteria and performance requirements were obtained: <br><br><ul><li>  The main criterion: after the introduction of an automated system for validating vulnerabilities, the number of false rejections (false rejects) should not exceed 10% of the total number of processed vulnerabilities. </li><li>  A new algorithm for confirming vulnerabilities will increase the number of confirmed vulnerabilities (confirmed) and reduce the number of slightly different from standard vulnerabilities (semi-confirmed) by at least 5-10%. </li><li>  The new algorithm for confirming vulnerabilities will give fewer errors than a simple algorithm that testing engineers already have, by at least 10%. </li><li>  An automatic vulnerability validation system will be introduced into the competitive analysis process. </li></ul><br>  During the experiment, engineers have developed: <br><br><ul><li>  Vulnerability coding matrix.  These are the rules for converting data about vulnerabilities and representing their properties in the form of a numeric or fuzzy vector.  Such a matrix is ‚Äã‚Äãunique for each specific subject area and problem to be solved. </li><li>  Software scripts for obtaining data from DBCA, presented in XML format. </li><li>  Software scripts for encoding obtained data on vulnerabilities in the form of numeric or fuzzy vectors (stored in text files of a specific format), according to the encoding matrix.  These files are used when training the neural network. </li><li>  A trained neural network for the task of classifying vulnerabilities with additional training and retraining, in the XML format of the FuzzyClassificator program. </li><li>  Adapted to solve the task, the FuzzyClassificator scripts implement all stages of working with the neural network, including its creation, training and the stage of classification of a trained neural network. </li><li>  Mechanisms to manage all the validation processes for vulnerabilities based on the continuous integration system TeamCity. </li></ul><br><h4>  Functional Vulnerability Classification Scheme </h4><br>  The whole complex of process automation for the classification of vulnerabilities was described by the functional IDEF0 scheme. <br><br> <a href=""><img src="https://habrastorage.org/files/e48/eaa/e82/e48eaae8219e4535aea9e6d55bfd30ef.png"></a> <br><br>  <i>Fig.</i>  <i>1 Functional IDEF0 Diagram</i> <br><br>  The diagram reflects the main stages of the classification of vulnerabilities: <br><br><ol><li>  CMS scan. </li><li>  Recording results in DBCA. </li><li>  Retrieving all data from DBCA, including previously found vulnerabilities and current scan results. </li><li>  Encoding vulnerabilities into numeric vectors in a format understood by the <a href="https://github.com/Tim55667757/FuzzyClassificator">FuzzyClassificator</a> program. </li><li>  NA training with FuzzyClassificator on early found vulnerabilities. </li><li>  Obtaining classification results for new vulnerabilities found in the current scan iteration. </li><li>  Publish results to DBCA. </li></ol><br>  Detailed descriptions of all elements of the functional scheme are given under the spoiler. <br><br><div class="spoiler">  <b class="spoiler_title">Elements of the functional diagram</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/a7b/e22/b60/a7be22b60acd415f9afd41ef2c416dda.png"><br><img src="https://habrastorage.org/files/d6c/fb0/1cc/d6cfb01ccb884623a973e3e3872e084c.png"><br><img src="https://habrastorage.org/files/e62/33f/f77/e6233ff77ee145e6b89cd1b2f22c2da4.png"><br></div></div><br>  A universal fuzzy measuring scale was used as measuring scales for assessing the properties of information systems (Fig. 2). <br><br><img src="https://habrastorage.org/files/2e9/3b3/1e9/2e93b31e90f04173b5cb281df7db3e00.png"><br><br>  <i>Fig.</i>  <i>2. Distribution of levels on a fuzzy universal scale</i> <br><br>  <b>The fuzzy scale</b> (FuzzyScale) is a set of ordered fuzzy variables, presented in the form of linguistic variables, describing some properties of an object: <br><br> <code>FuzzyScale = {Min, Low, Med, High, Max}</code> <br> <br>  Here: <br><br><ul><li>  <b>Min</b> is a fuzzy value meaning a minimal degree of confidence in something; </li><li>  <b>Low</b> is a slightly higher degree of confidence; </li><li>  <b>Med</b> is a moderate degree of confidence; </li><li>  <b>High</b> is a higher degree of confidence; </li><li>  <b>Max</b> is a fuzzy level, meaning the maximum degree of confidence in something. </li></ul><br>  Compared with other validation algorithms used vulnerabilities, which are based on a clear measuring scale, this approach helps to solve the problem of prioritizing vulnerabilities on a more human-understandable scale consisting of levels, which significantly reduces their further analysis. <br><br><h4>  Vulnerability properties coding matrix and its storage format </h4><br>  Any way to classify vulnerabilities involves coding, so one of the important steps in classifying vulnerabilities was encoding the input data.  As the main element, we used the coding matrix of vulnerability properties (Coding Matrix).  It is used to convert vulnerabilities received from the TFS database in XML format into a <a href="http://math-n-algo.blogspot.ru/2014/08/FuzzyClassificator.html">text DAT file of a special format</a> that is fed to the input of the neural network of the FuzzyClassificator program.  After constructing the matrix, writing scripts (support scripts) for encoding using a matrix is ‚Äã‚Äãeasy.  Read more in the blog ( <a href="http://math-n-algo.blogspot.ru/2014/08/FuzzyClassificator.html">Input coding</a> ). <br><br>  For more effective training of the neural network, it was necessary to select the optimal matrix that describes the method of encoding the most significant properties of vulnerabilities supplied to the inputs of the neural network.  The matrix was implemented using a simple JSON file. <br><br><div class="spoiler">  <b class="spoiler_title">Coding Matrix json-format:</b> <div class="spoiler_text"><pre> <code class="javascript hljs">{ <span class="hljs-string"><span class="hljs-string">"&lt;PROPERTY_NAME_1&gt;"</span></span>: { <span class="hljs-string"><span class="hljs-string">"values"</span></span>: { <span class="hljs-string"><span class="hljs-string">"unknown"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"&lt;value_1&gt;"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"&lt;value_2&gt;"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, ..., &lt;value_N&gt;: N }, <span class="hljs-string"><span class="hljs-string">"comment"</span></span>: <span class="hljs-string"><span class="hljs-string">"   ,     . PROPERTY_NAME -     "</span></span> }, ..., <span class="hljs-string"><span class="hljs-string">"&lt;PROPERTY_NAME_M&gt;"</span></span>: { <span class="hljs-string"><span class="hljs-string">"values"</span></span>: { <span class="hljs-string"><span class="hljs-string">"unknown"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"&lt;value_1&gt;"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"&lt;value_2&gt;"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, ..., &lt;value_K&gt;: K }, <span class="hljs-string"><span class="hljs-string">"comment"</span></span>: <span class="hljs-string"><span class="hljs-string">"         ,    : 0 ( ), 1, 2, ..."</span></span> }, <span class="hljs-string"><span class="hljs-string">"&lt;PROPERTY_NAME_X&gt;"</span></span>: { <span class="hljs-string"><span class="hljs-string">"values"</span></span>: { <span class="hljs-string"><span class="hljs-string">"unknown"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"exists"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span> }, <span class="hljs-string"><span class="hljs-string">"comment"</span></span>: <span class="hljs-string"><span class="hljs-string">"     ,      ,    (exists = 1)    (unknown = 0)   "</span></span> } }</code> </pre></div></div><br><h4>  Automating the classification of vulnerabilities in TeamCity </h4><br>  For the convenience of testers, the entire process, presented on the functional diagram, was automated in the system of integration TeamCity.  The configuration part shown in fig.  3 illustrates an entry point for implementing blocks 4, 5, 6 (7) of the functional diagram. <br><br> <a href=""><img src="https://habrastorage.org/files/6b5/023/217/6b50232179044fc0a2de9b3a872a9450.png"></a> <br><br>  <i>Fig.</i>  <i>3. Configuration in TeamCity, which launches the vulnerability classification process</i> <br><br>  After completing the vulnerability analysis process, TeamCity provides text files with reports on the classification of candidate vulnerabilities and statistics with an assessment of the quality of neural network training at the standards. <br><br>  In addition, before obtaining the final results, it is possible to assess the quality of neural network learning by the errors that it gives out on the reference vectors.  The training process takes place in a convenient format for the engineer: all the necessary information is displayed in the Training network configuration (see Fig. 4) in real time. <br><br> <a href=""><img src="https://habrastorage.org/files/d35/f35/921/d35f35921fb64980a369c1c7bf079d4e.png"></a> <br><br>  <i>Fig.</i>  <i>4. Conclusion of intermediate results on the quality of training of neural networks</i> <br><br>  Parameters in fig.  4 reflect the main learning indicators on the reference vectors: <br><br><ul><li>  <b>Epoch</b> - the current epoch of learning (or the last after graduation); </li><li>  <b>False</b> - the total number of erroneously classified reference vulnerabilities (rules for calculating statistics in training are given below); </li><li>  <b>Best</b> - the number of erroneously classified reference vulnerabilities for the best neural network in this training. </li></ul><br><h4>  Report examples </h4><br>  For the convenience of interpreting the results, the statistics in all reports are divided into separate blocks, i.e., at the output, the tester gets a clear and detailed report.  Under the spoiler are explanations for each unit. <br><br><div class="spoiler">  <b class="spoiler_title">Report blocks</b> <div class="spoiler_text">  In the <b>Overview</b> report header: <br><br><blockquote>  ‚Ä¢ <b>Neuronet</b> - the network used; <br>  ‚Ä¢ <b>Input file with encoded vectors</b> - file with input data for training or classification (depending on the report); <br>  ‚Ä¢ <b>Network configuration</b> - neural network configuration; <br>  ‚Ä¢ <b>Report legend</b> - a description of fuzzy levels used to assess whether a vulnerability belongs to a class of confirmed or unproven vulnerabilities. </blockquote><br>  In the table <b>Main statistics</b> : <br><br><blockquote>  ‚Ä¢ <b>Total classificated vectors' count</b> - the number of processed vulnerabilities during classification; <br>  ‚Ä¢ <b>Allocation table of sorted levels vectors' count</b> - a table of the distribution of the number of vectors of vulnerabilities among various fuzzy levels. </blockquote><br>  In the table of <b>Neural network quality statistics (for ethalon vectors only)</b> : <br><br><blockquote>  ‚Ä¢ <b>False classificated vectors' count</b> - the number of erroneously classified vulnerability vectors when training on standards, according to the rules for calculating statistics on the quality of training of a neural network (incomplete coincidence is counted as a correct result); </blockquote><ul><li>  a) <b>False confirmed vectors' count</b> - the number of vulnerability vectors for which only the Level Confirm level did not match the standard, </li><li>  b) <b>False rejected vectors' count</b> - the number of vectors of vulnerabilities in which only the Level Reject level did not match the standard, </li><li>  c) <b>Both the</b> number of vulnerabilities <b>confirmed and rejected vectors' count</b> - the number of vectors of vulnerabilities with which Level Confirm and Level Reject did not coincide with the standard at the same time; </li></ul><br><blockquote>  ‚Ä¢ <b>Allocation table of sorted levels levels false classificated vectors</b> - the number of classification errors grouped by various fuzzy levels. </blockquote><br>  In the <b>Classification Result</b> table: <br><blockquote>  ‚Ä¢ <b>TFSID</b> - link to DBCA vulnerability; <br>  ‚Ä¢ <b>Level Confirm</b> - the result of the classification of vulnerability by the neural network, showing the degree of confidence that the vulnerability is confirmed; <br>  ‚Ä¢ <b>Level Reject</b> - the result of the classification of vulnerability by the neural network, showing the degree of confidence that the vulnerability is not confirmed; <br>  ‚Ä¢ <b>Interpreting as</b> - how to interpret the result of the composition of two levels (Level Confirm, Level Reject), a clear final result of the classification: </blockquote><ul><li>  <b>Confirmed</b> - the neural network believes that vulnerability is more likely confirmed, </li><li>  <b>Rejected</b> - the neural network believes that vulnerability is more likely rejected, </li><li>  <b>ERROR</b> - classification error, which means that the neural network cannot unambiguously classify the vulnerability and requires manual validation. </li></ul></div></div><br> <a href=""><img src="https://habrastorage.org/files/bb3/fd0/e3e/bb3fd0e3eb7e4d38a11c8d5c9762a1a7.png"></a> <br><br>  <i>Fig.</i>  <i>5. An example of a report on the classification of standard vulnerabilities, containing statistics on the quality of training of a neural network.</i> <br><br>  In fig.  Figure 5 shows an example of a standard vulnerability classification report.  The data obtained by the neural network after training (the Classification Result block) is compared with the standard and the result is True or False (count the answer as correct or false).  According to the results of the classification, the number of erroneously classified vulnerabilities is calculated when learning at the standards, according to the rule for calculating statistics on the quality of training of a neural network.  We have reduced this rule to tab.  1, where indicated levels that can be considered the correct result in the classification, based on practical considerations. <br><br>  <i>Tab.</i>  <i>1. Interpretation of neural network responses during training</i> <br><br> <a href=""><img src="https://habrastorage.org/files/546/7e6/951/5467e69514bf4df089c472a33a08540f.png"></a> <br><br>  In the course of the study, we came to the conclusion that it is impossible to require a 100% coincidence of levels from a neural network when classifying vulnerabilities, since some levels are close in meaning to each other.  For example, a person, having received Level Reject = High instead of Max as a result of classification, will count such a vulnerability as refuted.  Therefore, if the result given by the neural network is ‚Äúclose‚Äù to the true value (High instead of Max and Low / Med instead of Min), then we consider it correct when learning True (weak), if the values ‚Äã‚Äãare exactly the same, then True (strong).  Note that the rules for real vulnerabilities are stricter than for false ones, since identifying real vulnerabilities is a higher priority.  All other options not listed in the table are considered a false answer (False). <br><br> <a href=""><img src="https://habrastorage.org/files/37f/5b8/d3d/37f5b8d3d09f41a3ab1b50ba88223011.png"></a> <br><br>  <i>Fig.</i>  <i>6. An example of a report on the classification of vulnerabilities, candidates, containing the values ‚Äã‚Äãof fuzzy levels and their interpretation</i> <br><br>  Similar to the report on the classification of vulnerabilities, standards looks like a report with the results of classification by candidates.  The neural network provides the answer to how to interpret the fuzzy Level Confirm and Level Reject levels for each vulnerability: Confirmed, Rejected or ERROR, according to the rules for unambiguous interpretation of the results of fuzzy classification of vulnerabilities (see Table 2). <br><br>  <i>Tab.</i>  <i>2. Rules unambiguous interpretation of the results of fuzzy classification of vulnerabilities</i> <br><br><img src="https://habrastorage.org/files/370/bcf/293/370bcf2932fa41e3a5a1fff1784e3e8b.png"><br><br>  Using the rules allows you to give a clear answer in a human-readable form: the vulnerability is confirmed, refuted, or an ambiguous classification result is obtained - an error.  In case of an error, manual classification is required.  By analogy with the rules of table.  1, candidate vulnerabilities should be considered rejected if, according to the classification results, a fuzzy Level Reject level is high (Max, High) and a fuzzy Level Confirm level is medium or low (Med, Low, Min).  Accordingly, the vulnerability will be confirmed with opposite results.  The rules for confirmed vulnerabilities are also more stringent. <br><br><h4>  Research results </h4><br>  Working with the neural network involved several stages - training at the standards and analysis of vulnerabilities in the operating mode on the new scan results. <br><br>  So, in the course of the experiment, several neural networks were trained simultaneously, but with different configurations.  At the moment, the best neural network with the following configuration has been obtained as a result of training in TeamCity: <code>Config = &lt;336, 336, 168, 2&gt;</code> .  Its training took place during 1155 epochs on 11004 standard vectors of vulnerabilities.  At the same time, according to the rules for interpreting responses (see Table 1), the neural network mistakenly classified only 555 (5.0%) of vectors in the learning mode. <br><br>  Analysis of vulnerabilities in the operating mode consisted of two stages.  The first stage included the manual analysis of scan data and the classification of vulnerabilities.  At the second stage, the analyzed vulnerabilities were proposed to the neural networks that had not previously been trained on them, for analysis (both as candidates for analyzing vulnerabilities and as benchmarks). <br><br>  In the working mode, while classifying previously unknown vulnerabilities, the neural network produced the following results: out of 2998 analyzed vulnerabilities, 595 (19.8%) were mistakenly classified. <br><br>  At the moment, all the formal requirements of the testing department are met, and we continue to work on improving the classification results: we optimize the parameters of the neural network, we filter out the ‚Äúbad‚Äù properties from the coding matrix. <br><br>  Full use of all the advantages of automatic classification of vulnerabilities using neural networks is expected in early 2016.  However, now the results of the analysis of vulnerabilities are automatically recorded for vulnerabilities in the DBCA. <br><br>  In fig.  Figure 7 shows an example of a typical record of a vulnerability from DBCA, for which the neural network made the correct assumption that this vulnerability, found by the PT AI scanner, needs to be refuted as a false positive.  This is indicated by the field values: ‚ÄúLevel Confirm: 5 - Min‚Äù, ‚ÄúLevel Reject: 1 - Max‚Äù, ‚ÄúNotes: Interpreting as: Reject‚Äù.  Similarly, the results are recorded for all other vulnerabilities. <br><br> <a href=""><img src="https://habrastorage.org/files/a22/a5e/6a5/a22a5e6a56c84ec299e6eb6ffd2a510d.png"></a> <br><br>  <i>Fig.</i>  <i>7. Record in DBCA with the results of neural network classification</i> <br><br>  I express my gratitude to my colleagues: Positive Technologies QA-engineers <a href="https://www.linkedin.com/in/%25D0%25B2%25D0%25BB%25D0%25B0%25D0%25B4%25D0%25B8%25D0%25BC%25D0%25B8%25D1%2580-%25D1%2581%25D0%25BE%25D1%2584%25D0%25B8%25D0%25BD-24900583">Vladimir Sofin</a> and <a href="https://www.linkedin.com/in/ayushkovsky">Artem Yushkovsky</a> for help in the practical implementation of some tools and a huge contribution to carrying out numerous experiments, as well as associate professor of the department of mathematical analysis, algebra and geometry, K. ped.  n  Kazan (Volga Region) Federal University <a href="https://ru.linkedin.com/in/mansur-gilmullin-38b105bb">Mansur Gilmullin</a> for helping to prepare a theoretical base for research and experiments. <br><br>  <b>Author:</b> <a href="https://www.linkedin.com/in/tgilmullin">Timur Gilmullin</a> , Ph.D., DevOps Engineer Positive Technologies. </div><p>Source: <a href="https://habr.com/ru/post/274241/">https://habr.com/ru/post/274241/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../274233/index.html">Hackathon and the winter scientific school on deep learning and question-answer systems</a></li>
<li><a href="../274237/index.html">The work of an ‚ÄúIT astronaut‚Äù: how we engineers go on a visit to bears and seals</a></li>
<li><a href="../274239/index.html">Working with the database in Google App Engine / Google Cloud Endpoints in Java: Objectify framework</a></li>
<li><a href="../274245/index.html">GlassRAT: Trojan analysis from China using RSA Security Analytics and RSA ECAT</a></li>
<li><a href="../274247/index.html">Sociology of algorithms: How financial markets and high-frequency trading are connected (Part 1)</a></li>
<li><a href="../274249/index.html">Authorization in Ubuntu through Microsoft Azure AD / Office 365</a></li>
<li><a href="../274251/index.html">Build and configure FreeRADIUS 3 with SQLITE support</a></li>
<li><a href="../274253/index.html">Problems using Math.random ()</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>