<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Spark local mode: handling large files on a regular laptop</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello. 
 On January 4, a new version of Apache Spark 1.6 was released with bug fix with new features for processing big data. On Habr√© written many ar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Spark local mode: handling large files on a regular laptop</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/e89/c5c/790/e89c5c79016441a193d6f5e1eb70b059.jpg" alt="image"><br>  Hello. <br>  On January 4, a new version of <a href="http://spark.apache.org/releases/spark-release-1-6-0.html">Apache Spark 1.6 was released</a> with <s>bug fix</s> with new features for processing big data.  On Habr√© written many articles on the use of this tool from the <a href="http://habrahabr.ru/company/mlclass/blog/250811/">introduction</a> to the <a href="http://habrahabr.ru/company/bitrix/blog/273279/">experience of use in projects</a> .  Spark runs on most operating systems and can be run in local mode even on a regular laptop.  Using the simplicity of Spark settings in this case is a sin not to use the main functions.  In this article, we will look at how to quickly configure a large file (more RAM) on a laptop using standard SQL queries.  This will allow making requests even to an unprepared user.  Additional connection iPython ( <a href="http://jupyter.readthedocs.org/en/latest/install.html">Jupyter</a> ) notebook will allow to make full reports.  The article explores a simple example of file processing, other examples in Python are <a href="https://github.com/apache/spark/tree/master/examples/src/main/python">here</a> . <br><a name="habracut"></a><br>  Input data: file (s) of several GB with ordered data, a laptop with free RAM &lt;1GB.  It is necessary to obtain various analytical data using SQL- or similar simple file requests.  Let us examine an example when the statistics of search queries for a month lies in the files (the data on the screenshots are shown for example and do not correspond to reality): <br><img src="https://habrastorage.org/files/cf0/92e/a83/cf092ea838a34bd097cccd0913cc180e.jpg" alt="image"><br><br>  It is necessary to obtain the distribution of the number of words in the search query for queries of a particular subject  For example, containing the word "real estate".  That is, in this example, we simply filter the search queries, count the number of words in each query, group them by the number of words, and build the distribution: <br><img src="https://habrastorage.org/files/70a/cea/7d2/70acea7d2e86476599aa2a353a528758.jpg" alt="image"><br><br>  Installing Spark in local mode is almost the same for major operating systems and comes down to the following actions: <br>  1. <a href="http://spark.apache.org/downloads.html">Download Spark</a> (this example works for version 1.6) and unzip to any folder. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      2. Install Java (if not) <br>  - for Windows and MAC, download and install version 7 from java.com <br>  - for Linux: $ sudo apt-get update and $ sudo apt-get install openjdk-7-jdk + may need to be added to the .bashrc JAVA installation address: JAVA_HOME = "/ usr / lib / jvm / java-7-openjdk-i386 " <br>  If there is no Python, then you can simply install <a href="https://www.continuum.io/downloads">Anaconda</a> . <br><br>  Run pySpark (you can run spark-shell to work in Scala as in the native language): go to the unpacked Spark archive and launch the pyspark in the bin folder (example: <a href="http://spark.apache.org/docs/latest/quick-start.html">spark.apache.org/docs/latest/quick-start.html</a> ).  With a successful launch, we get: <br><img src="https://habrastorage.org/files/847/d9b/d93/847d9bd937c94921bbf72cf37a97d650.jpg" alt="image"><br><br>  It remains to ‚Äúprepare‚Äù our file for SQL queries (in Spark 1.6, for some file types, you can directly make SQL queries <a href="https://issues.apache.org/jira/browse/SPARK-11197">without creating a table</a> ).  That is, we create a DataFrame (the DataFrame also has a bunch of <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">useful functions</a> ) and from it a table for SQL queries: <br>  1. Download the necessary libraries <br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pyspark.sql <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SQLContext, Row &gt;&gt;&gt; sqlContext = SQLContext(sc)</code> </pre> <br><br>  2. Start the text variable as the source file for processing and see what is in the first line: <br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>text = sc.textFile(<span class="hljs-string"><span class="hljs-string">'  '</span></span>) &gt;&gt;&gt; text.first() <span class="hljs-string"><span class="hljs-string">u'2015-09-01\tu'</span></span> <span class="hljs-string"><span class="hljs-string">'\t101753'</span></span></code> </pre><br><br>  In our file lines are separated by tabs.  For correct column separation, we use the Map and Split functions using tabs as a separator: map (lambda l: l.split ('\ t')).  Select the desired columns from the result of the partition.  For this task, we need to know the number of words in a particular search query.  Therefore, we take only the query (query column) and the number of words in it (wc column): map (lambda l: Row (query = l [1], wc = len (l [1] .split ('')))). <br><br>  You can take all the columns of the table in order to make arbitrary SQL queries to it in the future: <br>  map (lambda l: Row (date = l [0], query = l [1], stat = l [2], wc = len (l [1] .split ('')))) <br><br>  Perform these actions in one line <br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>schema = text.map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> l: l.split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>)).map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> l: Row(query=l[<span class="hljs-number"><span class="hljs-number">1</span></span>], wc=len(l[<span class="hljs-number"><span class="hljs-number">1</span></span>].split(<span class="hljs-string"><span class="hljs-string">' '</span></span>))))</code> </pre><br><br>  It remains to convert the schema to a DataFrame, with which you can perform many useful processing operations (examples <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">spark.apache.org/docs/latest/sql-programming-guide.html#dataframe-operations</a> ): <br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>df = sqlContext.createDataFrame(schema) &gt;&gt;&gt; df.show() +--------------------+---+ | query| wc| +--------------------+---+ | ...| <span class="hljs-number"><span class="hljs-number">2</span></span>| |  | <span class="hljs-number"><span class="hljs-number">2</span></span>| |  | <span class="hljs-number"><span class="hljs-number">3</span></span>| ...</code> </pre><br><br>  3. Translate the DataFrame into a table to make SQL queries: <br><pre> <code class="python hljs"> &gt;&gt;&gt; df.registerTempTable(<span class="hljs-string"><span class="hljs-string">'queryTable'</span></span>)</code> </pre><br><br>  4. Create a SQL query for the entire file and upload the result to the output variable: <br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>output = sqlContext.sql(<span class="hljs-string"><span class="hljs-string">'SELECT wc, COUNT(*) FROM queryTable GROUP BY wc'</span></span>).collect()</code> </pre><br><br>  For a 2GB file with 700MB of free RAM, this request took 9 minutes.  The progress of the processing process can be seen in the line of the form (... of 53): <br>  INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 61) in 11244 ms on localhost (1/53) <br><br>  We can add additional restrictions: <br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>outputRealty = sqlContext.sql(<span class="hljs-string"><span class="hljs-string">'SELECT wc, COUNT(*) FROM queryTable WHERE query like "%%" GROUP BY wc'</span></span>).collect()</code> </pre><br><br>  It remains to draw a histogram according to this distribution.  For example, you can write the output result to the file 'output.txt' and draw the distribution simply in Excel: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'output.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: ... f.write(<span class="hljs-string"><span class="hljs-string">'wc \t count \n'</span></span>) ... <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> output: ... f.write(str(line[<span class="hljs-number"><span class="hljs-number">0</span></span>]) + <span class="hljs-string"><span class="hljs-string">'\t'</span></span> + str(line[<span class="hljs-number"><span class="hljs-number">1</span></span>]) + <span class="hljs-string"><span class="hljs-string">'\n'</span></span>)</code> </pre></div><p>Source: <a href="https://habr.com/ru/post/274705/">https://habr.com/ru/post/274705/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../274687/index.html">IBDesignable magic or extend Interface Builder functionality in Xcode</a></li>
<li><a href="../274689/index.html">Calculation of binomial coefficients in C (C ++) and Python</a></li>
<li><a href="../274695/index.html">New WhatsApp vulnerability: a wave of emoticons that can block an application</a></li>
<li><a href="../274697/index.html">Results of the contest on programming on JS: Mail filters</a></li>
<li><a href="../274703/index.html">Security Week 01: Javascript Ransommer, $ 100k for a bug in Adobe Flash, an encrypted bright future</a></li>
<li><a href="../274707/index.html">The total capacity of LeaseWeb networks reached 5 Tbit / s: instant dedicated servers in the Netherlands from $ 39 only a week</a></li>
<li><a href="../274709/index.html">Trouble for server farms from Vodafone and Interxion</a></li>
<li><a href="../274713/index.html">Cooking rutracker for spring and kotlin</a></li>
<li><a href="../274717/index.html">Gospel Information Architecture Site</a></li>
<li><a href="../274719/index.html">Parametric design. Next half step after Design in browser</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>