<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>DevOps with Kubernetes and VSTS. Part 2: Cloud History</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continuation of the story about Kubernetes, containers and organization of the CI / CD pipeline. The Azure cloud and Visual Studio Team Services final...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>DevOps with Kubernetes and VSTS. Part 2: Cloud History</h1><div class="post__text post__text-html js-mediator-article">  Continuation of the story about Kubernetes, containers and organization of the CI / CD pipeline.  The Azure cloud and Visual Studio Team Services finally appear.  Interestingly, the VSTS CI / CD Pipeline uses the kubectl cluster for working with the k8s, so the application can be deployed not only in Azure Container Services, but also in any other Kubernetes installation. <br><br><img src="https://habrastorage.org/web/e1f/553/79a/e1f55379ab224485bc0f1b9b12fbc601.jpg"><br><br>  Read the translation of the second part of the article DevOps with Kubernetes and VSTS. <br><a name="habracut"></a><br><h2>  A series of articles "We are talking about containers": </h2><br>  1. <a href="https://habrahabr.ru/company/microsoft/blog/334682/">Containers for rapid deployment</a> . <br>  2. <a href="https://habrahabr.ru/company/microsoft/blog/337626/">DevOps with Kubernetes and VSTS.</a>  <a href="https://habrahabr.ru/company/microsoft/blog/337626/">Part 1: Local history.</a> <br>  3. <a href="https://habrahabr.ru/company/microsoft/blog/337708/">DevOps with Kubernetes and VSTS.</a>  <a href="https://habrahabr.ru/company/microsoft/blog/337708/">Part 2: Cloud history.</a> <br>  4. A <a href="https://habrahabr.ru/company/microsoft/blog/338686/">node with infinite capacity for Kubernetes.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the <a href="https://habrahabr.ru/company/microsoft/blog/337626/">first part,</a> I demonstrated an approach to developing multi- <a href="https://kubernetes.io/">container</a> applications using <a href="https://kubernetes.io/">Kubernetes</a> (k8s), or rather <a href="https://github.com/kubernetes/minikube">minikube</a> , a full-fledged k8s environment that runs one node on a virtual machine on your laptop.  In the previous article I <a href="https://github.com/colindembovsky/AzureAureliaDemo">cloned this repository</a> (make sure the docker branch is deployed) with two containers: the DotNet Core API and the frontend SPA ( <a href="http://aurelia.io/">Aurelia</a> ) (as static files in the DotNet Core app).  I showed how to create containers locally and run them in the minikube, as well as use the features of ConfigMaps to work with configurations. <br><br>  In this article I will tell you how to transfer local development to CI / CD and create a pipeline for automated assembly / release generation using VSTS.  We will create a container registry and container services in Azure, using k8s as the orchestration mechanism. <br><br><h2>  CI / CD Pipeline for Kubernetes in VSTS </h2><br>  I strongly recommend that you study <a href="https://twitter.com/nigelpoulton">Nigel Poulton's</a> excellent initial course entitled <a href="https://www.pluralsight.com/courses/getting-started-kubernetes">Getting Started with Kubernetes on PluralSight</a> (note the translator - in English, you need a paid subscription), as well as the Atul Malaviya article from Microsoft.  Nigel's course was an excellent Kubernetes dive for beginners, and Atula‚Äôs article helped to understand the principles of interaction between VSTS and k8s, but neither the course nor the article covered the entire conveyor.  Of these, I did not understand how the image update was implemented in the CI / CD pipeline.  Well, I had to conduct a series of experiments myself and prepare this article! <br><br><h2>  Deploy your k8s environment using Azure Container Services </h2><br>  k8s can be run locally, in AWS or Google Cloud or Azure.  We will use the Azure Container Service.  However, the CI / CD pipeline that I demonstrate in this article does not depend on the specific cloud hosting, it is suitable for any k8s cluster.  We will also create a private container registry in Azure, but again, you can use any container registry of your choice. <br><br>  You can also create a k8s cluster in the Azure portal.  However, Azure CLI allows you to do this faster, and you save the keys that you need to connect, so I decided to use this mechanism.  I will also use Bash for Windows with kubectl, but any platform with kubectl and Azure CLI will do. <br><br>  Here are the commands: <br><br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># set some variables export RG="cd-k8s" export clusterName="cdk8s" export location="westus" # create a folder for the cluster ssh-keys mkdir cdk8s # login and create a resource group az login az group create --location $location --name $RG # create an ACS k8s cluster az acs create --orchestrator-type=kubernetes --resource-group $RG --name=$ClusterName --dns-prefix=$ClusterName --generate-ssh-keys --ssh-key-value ~/cdk8s/id_rsa.pub --location $location --agent-vm-size Standard_DS1_v2 --agent-count 2 # create an Azure Container Registry az acr create --resource-group $RG --name $ClusterName --location $location --sku Basic --admin-enabled # configure kubectl az acs kubernetes get-credentials --name $ClusterName --resource-group $RG --file ~/cdk8s/kubeconfig --ssh-key-file ~/cdk8s/id_rsa export KUBECONFIG="~/cdk8s/kubeconfig" # test connection kubectl get nodes NAME STATUS AGE VERSION k8s-agent-96607ff6-0 Ready 17m v1.6.6 k8s-agent-96607ff6-1 Ready 17m v1.6.6 k8s-master-96607ff6-0 Ready,SchedulingDisabled 17m v1.6.6</span></span></code> </pre> <br>  <b>Notes:</b> <br><br><ul><li>  Lines 2‚Äì4: create variables. </li><li>  Line 6: create a directory for ssh keys and a kubeconfig configuration file. </li><li>  Line 9: Log in to Azure (request to open a page with a login menu in the browser; if you do not have an Azure subscription, create a free one now!). </li><li>  Line 10: create a group to hold all the resources we are going to create. </li><li>  Line 13: Deploy the k8s cluster using the resource group we just created and the name we give;  generate ssh-keys and place in the specified directory;  we need two agents (nodes) with the specified size of the virtual machine. </li><li>  Line 16: Create a registry of Azure containers in the same resource group with administrator access. </li><li>  Line 19: we get credentials for connecting to the cluster using kubectl;  use the resulting ssh-key and save the credentials in the specified kubeconfig file. </li><li>  Line 20: ask kubectl to use this configuration instead of the default configuration (which may have other k8s clusters or minikube configuration). </li><li>  Line 23: check the connectivity to the cluster. </li><li>  Lines 24‚Äì27: we are successfully connecting! </li></ul><br>  If you launch the browser, navigate to the Azure portal and open your resource group, you will see how much has been created by these simple commands: <br><br><img src="https://habrastorage.org/web/764/c3e/dba/764c3edba0b74a009fc77d7bbcc541dc.png"><br><br>  Do not worry, you will not have to manage resources yourself.  Azure and the k8s cluster take it upon themselves! <br><br><h2>  Namespaces </h2><br>  Before we create an assembly and release for our container applications, let's look at the promotion model.  Typically, the scheme is approximately as follows: development ‚Üí user acceptance testing ‚Üí production environment (Dev ‚Üí UAT ‚Üí Prod).  In the case of c k8s, minikube is a local development environment, which is great.  This is a full-featured k8s cluster on your laptop, so you can run your code locally, including using such k8s constructs as configMaps.  What about UAT and Prod?  Option - to deploy individual clusters, but this approach can be costly.  You can also share cluster resources using namespaces. <br><br>  Namespaces in k8s act as security boundaries, but they can also become isolation boundaries.  I can deploy new versions of my application in the dev namespace, which will use the prod namespace resources, but remain completely invisible (own IP addresses, etc.).  Of course, you should not conduct load testing within this configuration, since we will consume significant resources for applications in a production environment.  This concept is reminiscent of deployment slots in Azure Application Services, which are used to seamlessly test applications before transferring them to production. <br><br>  If you create a k8s cluster, then in addition to the kube-system and kube-public namespaces (with k8s subsets) you get the default namespace.  In the absence of clear instructions on your part, any services, deployments, or approaches that you create will fall into this namespace.  But we will create two additional namespaces: dev and prod.  Here is our yaml: <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: v1 kind: Namespace metadata: name: prod</code> </pre><br>  This file contains definitions for both namespaces.  Run the Apply command to create namespaces.  After completing all the procedures, you can list all namespaces in the cluster: <br><br><pre> <code class="bash hljs">kubectl apply -f namespaces.yml namespace <span class="hljs-string"><span class="hljs-string">"dev"</span></span> created namespace <span class="hljs-string"><span class="hljs-string">"prod"</span></span> created kubectl get namespaces NAME STATUS AGE default Active 27m dev Active 20s kube-public Active 27m kube-system Active 27m prod Active 20s</code> </pre><br><h2>  Setting a secret for the registry of containers </h2><br>  Before proceeding to the code, we‚Äôll perform the final settings: when the k8s cluster retrieves the images to be launched, it must refer to the container registry we created.  This registry has secure access, as the registry is private.  Therefore, we need to configure a registry secret that can be simply referenced in our yaml deployment files.  Here are the commands: <br><br><pre> <code class="bash hljs">az acr credential show --name <span class="hljs-variable"><span class="hljs-variable">$ClusterName</span></span> --output table USERNAME PASSWORD PASSWORD2 ---------- -------------------------------- -------------------------------- cdk8s some-long-key-1 some-long-key-2 kubectl create secret docker-registry regsecret --docker-server=<span class="hljs-variable"><span class="hljs-variable">$ClusterName</span></span>.azurecr.io --docker-username=<span class="hljs-variable"><span class="hljs-variable">$ClusterName</span></span> --docker-password=&lt;some-long-key-1&gt; --docker-email=admin@azurecr.io secret <span class="hljs-string"><span class="hljs-string">"regsecret"</span></span> created</code> </pre><br>  The first command uses az to get the keys for a user with administrator rights (the user name with administrator rights is the same as the container registry name, so I created cdk8s.azurecr.io, and the administrator user name is cdk8s).  Pass one of the keys (no matter which one) as a password.  Email address is not used, so you can specify any.  We now have a registry secret named regsecret that we can reference when deploying to the k8s cluster.  K8s will use this secret to authenticate the registry. <br><br><h2>  Configuring VSTS Endpoints </h2><br>  We set up a k8s cluster and a container registry.  Now add these endpoints to VSTS so that we can transfer containers to the registry when creating the assembly and execute commands for the k8s cluster during release preparation.  Endpoints allow us to abstract authentication in order not to store credentials directly in the definitions of our releases.  You can also create roles to restrict access to view and use of endpoints. <br><br>  Start VSTS and open a team project (or just create a new one).  Go to the team project and click the gear icon to open the settings node for this team project.  Click Services.  Click + New Services and create a new Docker Registry endpoint.  Enter the same credentials that you used to create a registry secret in k8s using kubectl: <br><br><img src="https://habrastorage.org/web/2d9/ba5/e54/2d9ba5e542234598a1ca08c07055a628.png"><br><br>  Now create the end point of k8s.  Enter the URL: https: //$ClusterName.$location.cloudapp.azure.com (clustername and location are the variables that we used when creating the cluster).  All the contents of the file ~ / cdk8s / kubeconfig (you could call it differently), which was created after executing the command az acs kubernetes get-credential, should be copied into the credentials text field: <br><br><img src="https://habrastorage.org/web/788/28c/889/78828c88952c410284c680fb189cfa88.png"><br><br>  We now have two endpoints that we can use in assembly and release definitions: <br><br><img src="https://habrastorage.org/web/610/cfa/564/610cfa564ab644a180e572426c2f5c50.png"><br><br><h2>  Assembly </h2><br>  Now we can create an assembly that will compile / test our code, create docker images and put them in the container registry, marking them accordingly.  Click Build &amp; Release, and then Builds to open the build node.  Create a new build definition.  Select an ASP.NET Core template and click Apply.  The following settings must be made: <br><br><ul><li>  Tasks ‚Üí Process: Enter a name, for example k8s-demo-CI, and select the Hosted Linux Preview queue. </li><li>  Optional: change the build number format to 1.0.0 $ (rev: .r) so that your builds have the format 1.0.0.x. </li><li>  Tasks ‚Üí Get Sources: select a Github repository with OAuth or PAT authentication.  Select AzureAureliaDemo and then docker as the default branch.  You may have to create a ‚Äúfork‚Äù for the repository (or just import it into VSTS) if you perform actions with me. </li><li>  Tasks ‚Üí DotNet Restore: do not make any changes. </li><li>  Tasks ‚Üí DotNet Build: Add --version-suffix $ (Build.BuildNumber) to the assembly arguments to ensure that the version and build number match. </li><li>  Tasks ‚Üí DotNet Test: turn off this task, because in our solution DotNet tests are not used (of course, if you have tests, the task can be re-enabled). </li><li>  Tasks ‚Üí add task npm.  Select frontend as the working directory and make sure that the install command is used. </li><li>  Tasks ‚Üí add command line task.  Select node as a tool (tool), specify the arguments: node_modules / aurelia-cli / bin / aurelia-cli.js test and working directory: frontend.  So you run the Aurelia tests. </li><li>  Tasks ‚Üí add a task to publish test results.  In the Test Results files field, type test * .xml, and in the Search Folder field, type $ (Build.SourcesDirectory) / frontend / testresults.  So you publish the results of the tests Aurelia. </li><li>  Tasks ‚Üí add a task to publish code coverage.  In the Coverage Tool field, enter Cobertura, in the Summary File field - $ (Build.SourcesDirectory) /frontend/reports/coverage/cobertura.xml, in the Report Directory field - $ (Build.SourcesDirectory) / frontend / reports / coverage / html.  This will publish your Aurelia test coverage data. </li><li>  Tasks ‚Üí add command line task.  Select node as a tool (tool), specify the arguments: node_modules / aurelia-cli / bin / aurelia-cli.js build --env prod and working directory: frontend.  So you compile, process and package the Aurelia SPA application. </li><li>  Tasks ‚Üí DotNet Publish.  For the arguments, type -c $ (BuildConfiguration) -o publish and uncheck the Zip Published Projects checkbox. </li><li>  Tasks ‚Üí add the Docker Compose task.  In the Container Registry Type field, specify the Azure Container Registry; as a subscription and the Azure container registry, specify the registry for which we created the end point earlier.  In the Additional Docker Compose Files field, specify docker-compose.vsts.yml, in the Action field - Build service images, in the Additional Image Tags field - $ (Build.BuildNumber), in order for the build number to be used as a tag for images. </li><li>  Create a Docker Compose task clone.  For the name, enter Push service images and select the action Push service images.  Check the Include Latest Tag box. </li><li>  Tasks ‚Üí Publish Artifact.  In the Path to Publish and Artifact Name fields, select k8s.  So you will publish the yaml k8s files to include them in the release. </li></ul><br>  The final task list should look like this: <br><br><img src="https://habrastorage.org/web/c56/ad8/0ba/c56ad80ba71741ababbac6b90b529603.png"><br><br>  You can now click Save and Queue to save the assembly and put it in a queue.  Upon completion of the build process, you will see a summary of the testing / coverage. <br><br><img src="https://habrastorage.org/web/360/cb7/4e7/360cb74e7db147a790fbc85b79dd1d5d.png"><br><br>  You can also view the contents of your container registry to see newly migrated service images with a label corresponding to the build number. <br><br><img src="https://habrastorage.org/web/aea/b72/164/aeab721648b24758b43e772af1f37d97.png"><br><br><h2>  Release </h2><br>  Now we can customize the release that will create / update the necessary services.  For this, configuration management should be provided.  It was possible to simply include the configuration in the code, but in that case confidential data (for example, passwords) would be included in the version control tool.  I prefer to ‚Äútokenize‚Äù any configuration so that the release management solution places sensitive data outside the zone controlled by the version control tool.  VSTS Release Management solution allows you to create secrets for individual environments or releases, you can also create them in variable groups with reusability support.  In addition, seamless <a href="https://www.visualstudio.com/en-us/docs/build/concepts/library/variable-groups">integration with Azure Key Vault is</a> now supported. <br><br>  In order to use environment-specific values ‚Äã‚Äãinstead of tokens, we need a task to replace the token.  Fortunately, I have the cross-platform ReplaceTokens task from the <a href="http://bit.ly/cacbuildtasks">Colin's ALM Corner Build &amp; Release Tasks</a> extension module, which I downloaded from the VSTS Marketplace.  Click the link to go to the desired page, then click Install to install the extension for your account. <br><br>  On the build summary page, scroll to the Deployments section on the right and click the Create release link.  You can also click Releases and create a new definition from there.  Start with an empty template, select your team project and the assembly you just created as the source assembly.  Check the Continuous Deployment checkbox so that the release is created automatically for each correct build. <br><br>  As a name for the definition, specify k8s or something descriptive.  On the General tab, change the format of the release number to $ (Build.BuildNumber) - $ (rev: r) so that by the release name you can always easily determine the build number.  Return to the Environments section and instead of Environment 1 enter dev.  Click the Run on Agent link and make sure that Hosted Linux Preview is selected in the Deployment queue field. <br><br>  Add the following tasks: <br><br><ul><li>  Replace Tokens. <ul><li>  Source Path: In Explorer, open the k8s directory. </li><li>  Target File Pattern: * -release.yml.  Thus, the token will be replaced in any yml file with a name that ends with -release.  There are three such files: the service / deployment files for the server and the client, and the client configuration file.  This task finds tokens in a file (with a prefix and a postfix __) and searches for variables with the same name.  Each variable is replaced by its value.  After a while we will create variables. </li></ul></li><li>  Kubernetes Task 1 (apply configuration for client). <ul><li>  Configure the k8s connection to the endpoint you created earlier.  You also need to set up a connection to the Azure Container Registry.  This applies to all Kubernetes tasks.  In the Command field, select apply, select the Use Configuration Files check box and specify the file k8s / app-demo-frontend-config-release.yml using the file picker.  Specify --namespace $ (namespace) in the text box for the arguments. <br><img src="https://habrastorage.org/web/872/731/f2a/872731f2af164457b871fa8f3b2f6d07.png"></li></ul></li><li>  Kubernetes Task 2 (apply service / deployment definition on server side). <ul><li>  Set the same connection settings for the k8s service and the Azure Container Registry.  This time in the Secret Name field, specify regsecret (this is the name of the secret that we created when setting up the k8s cluster, and the name we refer to in the imagePullSecret parameter in the deployment definitions).  Check the Force update secret box.  This will ensure that the values ‚Äã‚Äãof the k8s secret and the key from Azure match.  This parameter could be skipped because we created the key manually. </li><li>  In the Command field, select apply, select the Use Configuration Files check box, and specify the k8s / app-demo-backend-release.yml file using the file picker.  Specify --namespace $ (namespace) in the text box for the arguments. <br><img src="https://habrastorage.org/web/872/731/f2a/872731f2af164457b871fa8f3b2f6d07.png"><br></li></ul></li><li>  Kubernetes Task 3 (apply service / deployment definition on client side). <ul><li>  The settings are similar to the previous task, just select the file k8s / app-demo-frontend-release.yml. </li></ul></li><li>  Kubernetes Task 4 (update server side image). <ul><li>  Set the same connection settings for the k8s service and the Azure Container Registry.  The secret is not required here.  In the Command field, select set, and in the Arguments field, select image deployment / demo-backend-deployment backend = $ (ContainerRegistry) / api: $ (Build.BuildNumber) --record --namespace = $ (namespace). </li><li>  This will update the version (tag) of the used container image.  K8s will perform a sequential update, launching new containers and disabling old ones, and the service will be operational all the time. <br><img src="https://habrastorage.org/web/d8b/223/230/d8b2232307a647379d1c6871f68e9bf9.png"><br></li></ul></li><li>  Kubernetes Task 5 (update image on client side). <ul><li>  The parameters are similar to the previous task, only in the Arguments field you must specify image deployment / demo-frontend-deployment frontend = $ (ContainerRegistry) / frontend: $ (Build.BuildNumber) --record --namespace = $ (namespace) </li></ul></li><li>  Click the "..." button on the dev card and click Configure Variables to configure variables.  Set the following values: <ul><li>  BackendServicePort: 30081 </li><li>  FrontendServicePort: 30080 </li><li>  ContainerRegistry: &lt;your registry of containers&gt; .azurecr.io </li><li>  namespace: $ (Release.EnvironmentName) </li><li>  AspNetCoreEnvironment: development </li><li>  baseUri: http: // $ (BackendServiceIP) / api </li><li>  BackendServiceIP: 10.0.0.1 <br><img src="https://habrastorage.org/web/906/cbf/806/906cbf80645148b78b29595885e4e282.png"><br></li></ul></li></ul><br>  This sets the environment-specific values ‚Äã‚Äãfor all variables in the yml files.  The Replace Tokens task will write the necessary values ‚Äã‚Äãfor us to the files.  Let's quickly take a look at one of the tokenized files (tokenized lines are highlighted): <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Service metadata: name: demo-frontend-service labels: app: demo spec: selector: app: demo tier: frontend ports: - protocol: TCP port: 80 nodePort: __FrontendServicePort__ type: LoadBalancer --- apiVersion: apps/v1beta1 kind: Deployment metadata: name: demo-frontend-deployment spec: replicas: 2 template: metadata: labels: app: demo tier: frontend spec: containers: - name: frontend image: __ContainerRegistry__/frontend ports: - containerPort: 80 env: - name: "ASPNETCORE_ENVIRONMENT" value: "__AspNetCoreEnvironment__" volumeMounts: - name: config-volume mountPath: /app/wwwroot/config/ imagePullPolicy: Always volumes: - name: config-volume configMap: name: demo-app-frontend-config imagePullSecrets: - name: regsecret</code> </pre><br>  Comment on the value for BackendServiceIP: we use 10.0.0.1 as the replacement text, as Azure will assign the IP address to this service when k8s starts the server-side service (you will see the public IP address in the resource group in the Azure portal).  We will need to do this once to create the services and then update to get the real IP address and ensure that the service is working on the client side.  We also use $ (Release.EnvironmentName) as the value for the namespace, so for dev (and then for prod) the namespaces should be the same as what we created (including the case of characters). <br><br>  If the service / deployment and configuration do not change, then the first three tasks of the k8s essentially do not work.  Some result will be given only by the set command.  But this is just great, since the service / deployment and configuration files can be used idempotently!  They change when necessary, and do not cause any disturbances in all other situations - an ideal approach for recurring releases! <br><br>  Save the definition.  Click + Release to create a new release.  Click on the release number (it will be something like 1.0.0.1-1) to open it.  Click logs to view the logs. <br><br><img src="https://habrastorage.org/web/e26/7b3/4ae/e267b34ae91d45f3a03061d79646af6c.png"><br><br>  When the release is complete, you will see a deployment in the Kubernetes dashboard.  Use the following command to open the information panel: <br><br><pre> <code class="bash hljs">az acs kubernetes browse -n <span class="hljs-variable"><span class="hljs-variable">$ClusterName</span></span> -g <span class="hljs-variable"><span class="hljs-variable">$RG</span></span> --ssh-key-file ~/cdk8s/id_rsa Proxy running on 127.0.0.1:8001/ui Press CTRL+C to close the tunnel... Starting to serve on 127.0.0.1:8001</code> </pre><br>  The last argument is the path to the SSH key file that is generated when the cluster is created (specify the current path).  Now you can open the browser page <a href="http://localhost:8001/ui">http: // localhost: 8001 / ui</a> .  In the namespace drop-down menu, select dev and click Deployments.  You should see two successful deployments with two workable balers in each.  You can also see the images that run in the deployment.  Pay attention to the build number specified as a tag! <br><br><img src="https://habrastorage.org/web/6cb/2d5/f59/6cb2d5f59436491fbfa204a3bb330c1c.png"><br><br>  To see the services, click Services. <br><br><img src="https://habrastorage.org/web/b67/554/183/b675541833e04e0bb334bedeb07872da.png"><br><br>  We now have the server-side IP address of the service, so we can update the variable in the release.  Then we can queue the new version, and this time the correct IP address for the server-side service will be specified in the client's configuration (in our case, 23.99.58.48).  We can enter the IP address of our customer service in the browser and make sure that everything is working now! <br><br><img src="https://habrastorage.org/web/c3c/929/24b/c3c92924b55f4c5591584272dea228a5.png" width="300"><br><br><h2>  Creating a production environment </h2><br>  Now that we have verified that the dev environment is working, we can go back to release, clone the dev environment and name the copy prod.  Specify post factum approval for dev (or prior approval for prod) so that there is a control point between the two environments. <br><br><img src="https://habrastorage.org/web/ab7/3f8/ae2/ab73f8ae2d1342ebb9c3a0e0a73ea0d6.png"><br><br>  Then we can simply change the ports for the nodes, as well as the values ‚Äã‚Äãof the AspNetCoreEnvironment and BackendServiceIP variables, and you're done!  Of course, we need to first deploy the prod namespace before we see the IP address assigned by k8s / Azure to the prod server.  Then you need to rerun the issue creation procedure to update the configuration. <br><br><img src="https://habrastorage.org/web/e00/a0c/1b7/e00a0c1b70d9490cac86d20a0d080da6.png"><br><br>      nodePort      k8s    ,      ,     ,        (   ). <br><br>     --namespace   ,   ,     <a href="https://github.com/Microsoft/vsts-tasks/pull/4657">Pull Request</a>   vsts-tasks  Github,            ! <br><br><h2>    CI/CD  </h2><br> ,    dev  prod   CI/CD ,      .       ¬´K8s demo¬ª   .    ,        , ,   ,     dev.       dev ( 1.0.0.3   ,   ,  1.0.0.1),      prod    1.0.0.1. <br><br><img src="https://habrastorage.org/web/816/f53/d4a/816f53d4a9904944b57743632109eb15.png"><br><br>  dev     ,    prod ,     prod    1.0.0.3. <br><br>    json       ,      (  ,   ,         ). <br><br><h2>  Conclusion </h2><br> k8s        .  yml    ¬´  ¬ª      .            ,    configMaps      .    Azure CLI    k8s    Azure     .   VSTS    k8s    CI/CD,       .     minikube,                 k8s      ,      ,      (Dev/CI/CD). <br><br> ,  CI/CD         !         k8s   .   ,          k8s   ! <br><br>    k8sing! <br><br><hr><br> <b>PS</b>    ( <a href="https://t.me/quantumquintum">Quantum Quintum</a> )     . </div><p>Source: <a href="https://habr.com/ru/post/337708/">https://habr.com/ru/post/337708/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../337694/index.html">VMware Announces ‚ÄúEnd‚Äù vCenter Server for Windows</a></li>
<li><a href="../337698/index.html">Writing operator for Kubernetes at Golang</a></li>
<li><a href="../337700/index.html">10 interesting innovations in JUnit 5</a></li>
<li><a href="../337702/index.html">From Toronto to Tomsk: summing up and planning future seminars on microelectronics in Russia</a></li>
<li><a href="../337704/index.html">Moving Java forward faster</a></li>
<li><a href="../337710/index.html">History 13 places on Highload Cup 2017</a></li>
<li><a href="../337712/index.html">Parrot Security OS - an alternative to Kali Linux</a></li>
<li><a href="../337714/index.html">The book "Security Audit Information Systems"</a></li>
<li><a href="../337716/index.html">How to switch to gRPC, saving REST</a></li>
<li><a href="../337718/index.html">Creating and normalizing dictionaries. Choose the best, remove too much</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>