<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to start a search engine, or a few thoughts about the crawler</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In continuation of the started topic about your own search engine 

 So, there are several major tasks that the search system should solve. Let's star...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to start a search engine, or a few thoughts about the crawler</h1><div class="post__text post__text-html js-mediator-article">  In continuation of the started topic about your own search engine <br><br>  So, there are several major tasks that the search system should solve. Let's start with the fact that a separate page should be obtained and saved. <br>  There are several ways, depending on which processing methods you choose in the future. <br><br>  Obviously, it is necessary to have a queue of pages that need to be downloaded from the web, at least in order to later look at them on long winter evenings, if there is nothing better to come up with.  I prefer to have a queue of sites and their main pages, and a local mini queue of what I will handle at this time.  The reason is simple - a list of all the pages that I would like to download just for a month can significantly exceed the amount of my rather big hard drive :), so I only store what is really needed - the websites, there are currently 600 thousand of them, and their priorities and download times. <br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      When loading a regular page, all links from this page should either be added to the local queue if they remain within the site that I am processing, or to the main list of sites to which I have to return sooner or later. <br><br>  How many pages to get from one site at a time?  Personally, I prefer no more than 100 thousand, although from time to time I change this limit to only 1000 pages.  Yes, and sites on which pages more - not so much. <br>  Now let's take a closer look: <br><br>  If we get 1 page at a time, all the pages in sequence, then how many pages will we process, say, in an hour? <br>  - time to get the page consists of: <br>  ¬∑ The time we are waiting for the CSN response (it is, as practice shows, quite a bit).  DNS matches the name of the site ‚Äúsite.ru‚Äù ip address of the server on which it lies, and this is not the easiest task, given that sites are used to move, packet routing routes vary and much more.  In short, DNS server stores a table of addresses, and each time we knock to it in order to understand the address - where to go after the page. <br>  ¬∑ Time to connect and send the request (quickly if you have at least an average channel) <br>  ¬∑ Time to receive the actual answer - page <br><br>  That is why Yandex, according to rumors, once faced the very first problem - if you really get many pages, then the DNS provider is not able to cope with this - in my experience the delay was up to 10 seconds per address, all the more you have to send an answer here and there over the network, and I‚Äôm not one at the provider.  I note that when you request 1000 pages in succession from one site, you will be pulling each of the provider 1000 times. <br><br>  With modern hardware, it‚Äôs quite simple to set yourself a local DNS-caching DNS server and load it with your work, and not a provider - then the provider will send your packets faster.  However, you can be confused and write the cache within your page loader if you write at a sufficiently low level. <br>  If you use ready-made solutions such as LWP or HTTP modules for Perl, then the local DNS server will be optimal. <br><br>  Now suppose that the answer comes to you 1-10 seconds on average - there are fast servers, and there are very slow servers.  Then per minute you received 6-60 pages, per hour 360-3600, about 8,000 to 60,000 per day (consciously round down to all sorts of delays: in reality, when requesting 1 page at a time without local DNS, on a 100mbit / s channel You will get 10,000 pages per day, of course, if the sites are different, and not one is very fast) <br><br>  And even considering that time for processing is not taken into account here, saving pages is the result, frankly, scanty. <br><br>  Ok, I said, and made 128 requests at a time in parallel, everything flew perfectly - a peak of 120 thousand pages per hour, until we started receiving raw logs from server admins where I knocked about DDoS attacks, yes, 5000 requests in 5 minutes Not any hosting allows. <br><br>  Everything was decided by the fact that at the same time I started shipping 8-16 different sites, not more than 2-3 pages in parallel.  It turned out something about 20-30 thousand pages per hour, and it suited me.  I must say at night the indicators grow much <br><br>  The full content and list of my articles on the search engine will be updated here: <a href="http://habrahabr.ru/blogs/search_engines/123671/">http://habrahabr.ru/blogs/search_engines/123671/</a> </div><p>Source: <a href="https://habr.com/ru/post/123703/">https://habr.com/ru/post/123703/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../123697/index.html">How to tame clouds: examples of practical use. What is there on the technical side?</a></li>
<li><a href="../123698/index.html">On the dangers of copyright and the benefits of licensed programs</a></li>
<li><a href="../123699/index.html">Alteration of the D-link DIR-620 router in Zyxel Keenetic or making candy from the city</a></li>
<li><a href="../123700/index.html">Once again about ‚ÄúMercurial vs. Git‚Äù (with pictures)</a></li>
<li><a href="../123702/index.html">Virtual store in the Korean subway</a></li>
<li><a href="../123704/index.html">GTD. The most frequent problems in the use and solutions</a></li>
<li><a href="../123705/index.html">The e-commerce system nopCommerce is now on ASP.NET MVC 3</a></li>
<li><a href="../123707/index.html">Development of productive applications</a></li>
<li><a href="../123711/index.html">Skype + FSB = ‚ô•</a></li>
<li><a href="../123712/index.html">PHP modification: its extension</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>