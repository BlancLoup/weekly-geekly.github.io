<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Sharing is not always useful: we optimize work with cache memory.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="To share with our neighbors for us, the beasts of God, this is very characteristic, considered a virtue, and in general, as the original source assert...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Sharing is not always useful: we optimize work with cache memory.</h1><div class="post__text post__text-html js-mediator-article"><img align="left" src="https://habrastorage.org/getpro/habr/post_images/93c/374/6a5/93c3746a544ff81773ed707e12b4c5bd.jpg">  To share with our neighbors for us, the beasts of God, this is very characteristic, considered a virtue, and in general, as the <a href="http://bibleonline.ru/">original source</a> asserts, has a positive effect on karma.  However, in the <a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html">world</a> created by microprocessor architects, this behavior does not always lead to good results, especially when it comes to sharing memory between threads. <br><br>  We all read a little about memory optimization, and it was postponed for us, which is useful when the cache remains hot, that is, the data that the threads often access should be compact and located in the cache closest to the processor core.  That's right, but when it comes to sharing access, streams become the worst enemies [of performance], and the cache is not just hot, it already ‚Äú <a href="http://en.wikipedia.org/wiki/MESI_protocol">burns with hellfire</a> ‚Äù - this is how the struggle unfolds around it. <br><br>  Below we will consider a simple but illustrative case of multi-threaded program performance problems, and then I will give some general recommendations on how to avoid the problem of loss of computational efficiency due to the separation of the cache between threads. <br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Consider a case that is well described in the <a href="http://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-optimization-manual.html">Intel64 and IA-32 Architectures Optimization Manual</a> ; however, programmers often forget about it when working with arrays of structures in a continuous flow mode.  They allow accessing (with modification) of streams to data of structures located very close to each other, namely, in a block equal to the length of one cache line (64 bytes).  We call this <i>Cache line sharing</i> .  There are two types of split lines: <i>true sharing</i> and <i>false sharing</i> . <br>  <i>True sharing</i> is when threads have access to the same memory object, for example, a common variable or a synchronization primitive.  <i>False sharing</i> ( <s>from the evil one</s> ) is access to different data, but for some reason, it turns out in the same cache line of the processor.  Immediately, we note that both cases hurt performance due to the need for hardware synchronization of the processor's cache memory, but if the first case is often unavoidable, then the second one can and should be excluded. <br><br>  Why performance suffers, we will explain with an example.  Suppose we process a sequence of queued data structures in multi-threaded mode.  Active threads one by one take out the following structure from the queue and in some way process it, modifying the data.  What can happen at the hardware level, if, for example, the size of this structure is small and does not exceed several tens of bytes? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eee/b72/59e/eeeb7259e80ef4fbf102de85b25c3073.jpg" alt="image"><br>  <i>Conditions for the problem:</i> <i><br></i>  <i>Two or more streams write to the same cache line;</i> <i><br></i>  <i>One thread writes, the rest read from the cache line;</i> <i><br></i>  <i>One thread writes, in the rest of the kernels HW prefetcher has been working.</i> <i><br></i> <br><br>  It may turn out that the variables in the fields of different structures are so located in the memory that, being read in the processor's L1 cache, are in the same cache line as in the figure.  In this case, if one of the threads modifies the field of its structure, then the entire cache line is declared invalid for the remaining processor cores in accordance with the cache coherency protocol.  Another thread can no longer use its structure, despite the fact that it already lies in the L1 cache of its core.  In old P4 processors in such a situation, a long synchronization with the main memory would be required, that is, the modified data would be sent to the main memory and then read into the L1 cache of another core.  In the current generation of processors (codenamed Sandy Bridge), the synchronization mechanism uses a shared third-level cache (or LLC - Last Level Cache), which is inclusive for the cache memory subsystem and contains all the data in both L2 and L1 all processor cores.  Thus, synchronization does not occur with the main memory, but with the LLC, which is part of the implementation of the cache coherence mechanism protocol, which is much faster.  But it still happens, and it takes time, although measured in just a few dozen processor cycles.  And if the data in the cache lines are divided between threads that run in different physical processors?  Then it will be necessary to sync between LLCs of different chips, and this is much longer - already hundreds of cycles.  Now imagine that the program is only concerned with the fact that in a cycle it processes the stream of data received from any source.  Losing hundreds of cycles on each iteration of the cycle, we run the risk of "dropping" our performance at times. <br><br>  Let's look at the following example, specially simplified in order to make it easier to understand the causes of the problem.  Do not hesitate, in real applications the same cases occur very often, and unlike the refined example, even to detect the existence of a problem is not so simple.  Below we show how to quickly find such situations using the performance profiler. <br><br>  In a loop, the stream function runs through two arrays float a [i] and b [i], multiplies their values ‚Äã‚Äãby the array index and adds localSum [tid] to the local thread variables.  To enhance the effect, this operation is done several times (ITERATIONS). <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">work</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *pArg)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>, i = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tid = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) pArg; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; ITERATIONS; j++){ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i = tid; i &lt; MAXSIZE; i+= NUM_PROCS){ a[i] = i + a[i] * b[i]; localSum[tid] += a[i];}} }</code> </pre> <br><br>  The trouble is that the method of interleaving cycle indexes is selected for data sharing between threads.  That is, if we have two streams, the first will refer to the elements of the arrays a [0] and b [0], the second to the elements a [1] and b [1], the first to a [2] and b [2 ], the second is a [3] and b [3], and so on.  In this case, the elements of the array a [i] are modified by threads.  It is not difficult to see that 16 elements of the array will fall into one cache line, and the threads will simultaneously access neighboring elements, ‚Äúdriving the processor caches synchronization mechanism‚Äù to mind. <br><br><img src="http://habrastorage.org/storage3/924/32d/5ef/92432d5efb202e4c1f30438dd2e5ef20.jpg" alt="image"><br><br>  The most annoying thing is that we will not even notice the existence of this problem by the work of the program.  It will just work slower than it can, that's all.  How to evaluate the effectiveness of the program using the profiler VTune Amplifier XE, I have already described in <a href="http://habrahabr.ru/company/intel/blog/140965/">one of the posts</a> on Habr√©.  Using the <b>General Exploration</b> profile that I mentioned there, you can see the problem being described, which will be highlighted by the tool in the profiling results in the <b>Contested Access</b> column.  This metric just measures the ratio of the cycles spent on synchronization of processor caches when they are modified by threads. <br><br><img src="http://habrastorage.org/storage3/09f/cbd/0af/09fcbd0aff78c34d2ab07e3550935ae8.jpg" alt="image"><br><br>  If someone is interested in what is behind this metric, then during complex profiling, the tool collects meter data among other hardware counters: <br>  <b>MEM_LOAD_UOPS_LLC_HIT_RETIRED.XSNP_HITM_PS</b> - Exact counter (PS) of the performed (RETIRED) operation (OUPS) load (LOAD) data (MEM), which turned out (HIT) in LLC and modified (M).  An ‚Äúaccurate‚Äù counter means that the data collected by such a counter in sampling refers to an instruction pointer (IP) following the instruction that was the same load that led to the synchronization of the caches.  Having collected statistics on this metric, we can specify with some accuracy the address of the instruction, and, accordingly, the source code line where the reading was performed.  VTune Amplifier XE can show which threads read this data, and then we have to find out for ourselves how multithreaded data access is implemented and how to correct the situation. <br><br><img src="http://habrastorage.org/storage3/7e2/cfb/8ee/7e2cfb8ee4a7211585cda64522199e64.jpg" alt="image"><br><br>  Regarding our simple example, it's very easy to fix the situation.  You just need to divide the data into blocks, while the number of blocks will be equal to the number of threads.  Someone may argue: if the arrays are large enough, the blocks may simply not fit into the cache, and the data loaded from memory for each stream will displace each other from the cache.  This will be true if all block data is used continuously, and not once.  For example, when multiplying matrices, we walk through the elements of a two-dimensional array, first in rows, then in columns.  And if both matrices do not fit in the cache (of any level), then they will be pushed out, and repeated access to the elements will require reloading from the next level, which negatively affects performance.  In the general case with matrices, modified matrix multiplication is applied block by block, and the matrices are divided into blocks, which are deliberately placed in a given cache memory, which significantly increases the performance of the algorithm. <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">work</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *pArg)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>, i = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tid = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) pArg; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; ITERATIONS; j++){ chunks = MAXSIZE / NUM_PROCS; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i = tid * chunks; i &lt; (tid + <span class="hljs-number"><span class="hljs-number">1</span></span>) * chunks; i++){ a[i] = i + a[i] * b[i]; localSum[tid] += a[i];}} }</code> </pre><br><br>  <b>False sharing</b> <br><img src="http://habrastorage.org/storage3/9e4/bde/df7/9e4bdedf7701f4574628139a8cdbe199.jpg" alt="image"><br>  <b>No False sharing</b> <br><img src="http://habrastorage.org/storage3/b4e/82c/bf9/b4e82cbf921b99848c6b78e7aa136794.jpg" alt="image"><br>  <i>Comparing access of streams to array elements in the case of False sharing and in the corrected code</i> <br><br>  In our simple case, the data is used only once, and even if they are pushed out of the cache memory, we will no longer need it.  And the data of both arrays a [i] and b [i], located far from each other in the address space, are in the cache in time taken care of by the hardware prefetcher - a mechanism for pumping data from the main memory implemented in the processor.  It works fine if access to the elements of an array is sequential. <br><br>  In conclusion, we can give some general recommendations on how to avoid the problem of loss of computational efficiency due to the separation of the cache between threads.  From the very name of the problem, it can be understood that coding should be avoided where streams access common data very often.  If this is true sharing of a mutex by threads, then there may be a problem of excessive synchronization, and the approach to sharing the resource protected by this mutex should be reconsidered.  In general, try to avoid global and static variables that need access from streams.  Use local thread variables. <br><br>  If you work with data structures in multi-threaded mode, pay attention to their size.  Use padding to increase the size of the structure to 64 bytes: <br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">data_packet</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> address[<span class="hljs-number"><span class="hljs-number">4</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> data[<span class="hljs-number"><span class="hljs-number">8</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> attribute; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> padding[<span class="hljs-number"><span class="hljs-number">3</span></span>]; }</code> </pre><br>  Allocate memory for structures at the aligned address: <br><pre> <code class="cpp hljs">__declspec(align(<span class="hljs-number"><span class="hljs-number">64</span></span>)) <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">data_packet</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sendpack</span></span></span></span></code> </pre><br>  Use arrays of structures instead of array structures: <br><pre> <code class="cpp hljs">data_packet sendpack[NUM];</code> </pre><br>  instead <br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">data_packet</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> address[<span class="hljs-number"><span class="hljs-number">4</span></span>][NUM]; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> data[<span class="hljs-number"><span class="hljs-number">8</span></span>][NUM]; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> attribute[NUM]; }</code> </pre><br>  As you can see, in the latter case, streams modifying one of the fields will trigger the cache synchronization mechanism. <br><br>  For objects allocated in dynamic memory using malloc or new, create local memory pools for threads, or use parallel libraries that can do this themselves.  For example, the TBB library contains scalable and leveling <a href="http://threadingbuildingblocks.org/files/documentation/a00235.html">allocators</a> that are useful for scalable multithreaded programs. <br><br>  Well, the final advice: you should not rush to solve the problem, if it does not greatly affect the overall performance of the application.  Always evaluate the potential gain that you receive as a result of the cost of optimizing your code.  Use the profiling tools to evaluate this gain. <br><br>  PS Try my primerchik, and tell me how many percent increased test performance on your platform. </div><p>Source: <a href="https://habr.com/ru/post/143446/">https://habr.com/ru/post/143446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../143439/index.html">Simple, convenient - Mouse gestures</a></li>
<li><a href="../143440/index.html">Strange access bug to corporate google mail</a></li>
<li><a href="../143441/index.html">About code reuse</a></li>
<li><a href="../143443/index.html">An evening with Sinatra to create a TwitterBar service</a></li>
<li><a href="../143444/index.html">The list of speakers at the MobileOptimized 2012 conference is defined</a></li>
<li><a href="../143447/index.html">Oracle vs Google: Jury Delivers Verdict</a></li>
<li><a href="../143448/index.html">iOS 5.1.1 available for download</a></li>
<li><a href="../143450/index.html">garage48 for the first time in Kiev!</a></li>
<li><a href="../143451/index.html">A vulnerability was found inside the HTTP server embedded in Node.</a></li>
<li><a href="../143452/index.html">Google HTML / CSS Code Guide</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>