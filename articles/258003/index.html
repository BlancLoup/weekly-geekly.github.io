<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Artificial Intelligence in Wolfram Language: Image Identification Project</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Translation of Stephen Wolfram's post (Stephen Wolfram) " Wolfram Language Artificial Intelligence: The Image Identification Project ". 
 I express my...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Artificial Intelligence in Wolfram Language: Image Identification Project</h1><div class="post__text post__text-html js-mediator-article">  <i>Translation of Stephen Wolfram's post (Stephen Wolfram) " <a href="http://blog.stephenwolfram.com/2015/05/wolfram-language-artificial-intelligence-the-image-identification-project/">Wolfram Language Artificial Intelligence: The Image Identification Project</a> ".</i> <i><br></i>  <i>I express my deep gratitude to <a href="http://vk.com/ld742">Kirill Guzenko</a> for his help in translating.</i> <br><hr>  ‚ÄúWhat is depicted in this picture?‚Äù People almost immediately can answer this question, and earlier it seemed that this was an impossible task for computers.  For the past 40 years I have known that computers will learn how to solve such problems, but did not know when this would happen. <br><br>  I created systems that give computers different components of the intellect, and these components are often far beyond human capabilities.  From a long time ago we integrate the development of artificial intelligence in <a href="http://www.wolfram.com/language/">Wolfram Language</a> . <br><br>  And now I am very pleased to report that we have crossed the new frontier: a new Wolfram Language function - <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> , which you can ask - ‚Äúwhat is shown in the picture?‚Äù, <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">Was</a></b> released and get an answer. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Today we are launching the <b><a href="https://www.imageidentify.com/">Wolfram Language Image Identification Project</a></b> , an image identification project that works over the Internet.  You can send an image from the phone‚Äôs camera, from the browser, or drag-and-drop it into the appropriate form, or simply upload the file.  After that, <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> will <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">return</a></b> its result: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ca7/0a3/45b/ca70a345b2e53e2a9f4c82b674f7fa1b.png" alt="Give the Wolfram Language Image Identify Project a picture, and it uses the language's ImageIdentify function to identify it" title="The Language ImageIdentify is a function to identify it." width="620" height="554"></div><br><h2>  Content </h2><br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">Now in Wolfram Language</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">Personal background</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">Machine learning</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">All this is connected with attractors.</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">Automatically created programs</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">Why now?</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">I see only a hat</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">We lost anteaters!</a> <br>  <a href="http://habrahabr.ru/company/wolfram/blog/258003/">Back to nature</a> <br><a name="habracut"></a><br>  Of course, the answer will not always be correct, but in most cases the function works very well.  And the fact that if the function makes any mistakes is remarkable, they are similar to the ones that a person would make. <br><br>  This is a good practical example of artificial intelligence.  However, for me, the more important point is that we integrate such interaction with artificial intelligence directly into Wolfram Language - another powerful stone of the foundation of the knowledge-based programming paradigm. <br><br><a name="NowInTheWolframLanguage"></a><h2>  Now in Wolfram Language </h2><br>  In order to recognize an image when working with the Wolfram Language, you just need to apply the <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> function to this image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a15/ec9/a68/a15ec9a689f0db2f132ff7d962dd601c.png" alt="In[1]:= ImageIdentify[image:giant anteater]" title="In [1]: = ImageIdentify [image: giant anteater]" width="369" height="177"><br><br>  At the exit, you get some <a href="http://www.wolfram.com/language/fast-introduction-for-programmers/real-world-entities/">character object</a> with which you can continue to work in the Wolfram Language.  As in this example, find out that this is an animal, a mammal, and so on.  Or just ask the definition: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/374/b9b/fd6/374b9bfd6d298d9fbf8c1693519e21f3.png" alt="In[2]:= giant anteater [&amp;quot;Definition&amp;quot;]" title="In [2]: = giant anteater [&amp; quot; Definition &amp; quot;]" width="385" height="85"><br><br>  Or, for example, generate a cloud from the words found in the Wikipedia article devoted to the object in the picture: <br><br> <a href="http://en.wikipedia.org/wiki/Giant_anteater"><img src="https://habrastorage.org/getpro/habr/post_images/723/9ff/c2a/7239ffc2a8002c8cbe51e9fe46876097.png" alt="In[3]:= WordCloud[DeleteStopwords[WikipediaData[giant anteater]]]" title="In [3]: = WordCloud [DeleteStopwords [WikipediaData [giant anteater]]]" width="504" height="341"></a> <br><br>  If you have an array of photos, then you can almost instantly write a program on the Wolfram Language, which, for example, would give out statistics about which animals, devices, boards - no matter what - how often they are found in this array . <br><br>  With the help of the <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> function, built directly into the Wolfram Language, it is very easy to create some kind of API, applications in which it is used.  And using the <a href="http://www.wolfram.com/cloud/">Wolfram Cloud is</a> very easy to create websites - like, for example, the <a href="https://www.imageidentify.com/">Wolfram Language Image Identification Project</a> website. <br><br><a name="PersonalBackstory"></a><h2>  Personal background </h2><br>  Personally, I waited a long time for <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> .  Somewhere 40 years ago I was reading a book called <a href="http://en.wikipedia.org/wiki/The_Computer_and%2520_the%2520_Brain"><em>The Computer and the Brain</em></a> , which was penetrated by a thought - sooner or later we will create artificial intelligence, most likely by emulating electrical connections in the brain.  And in 1980, after I had achieved some success with <a href="http://blog.stephenwolfram.com/2013/06/there-was-a-time-before-mathematica/">my first computer language</a> , I began to reflect on what needs to be done in order to create a full-fledged artificial intelligence. <br><br>  I was inspired by the ideas that were later implemented in the Wolfram Language - an idea in <a href="http://reference.wolfram.com/language/guide/Patterns.html">symbolic comparison with samples</a> , which, I thought, <a href="">could reflect some aspects of</a> human thinking.  But I knew that if image recognition is based on pattern matching, then something else is needed - a fuzzy juxtaposition. <br><br>  I tried to create fuzzy caching algorithms.  And he never stopped thinking about how the brain realizes all this.  We must borrow its principles of operation.  And this led me to begin the study of idealized neural networks and their behavior. <br><br>  In the meantime, I also thought about some fundamental issues in the natural sciences - about <a href="http://www.stephenwolfram.com/publications/academic/%3Fcat%3Dcosmology">cosmology</a> , about how large-scale structures arise in our universe, how particles self-organize. <br><br>  And <a href="http://www.wolframscience.com/nksonline/page-880b-text">at some point I realized</a> that both neural networks and self-attracting particle clusters are examples of systems that, although they had simple basic components, for some reason achieved complex collective behavior.  Digging deeper, I got to <a href="http://www.stephenwolfram.com/publications/academic/%3Fcat%3Dcellular-automata">cellular automata</a> , which led me to all the ideas and discoveries that resulted in the book <a href="http://www.wolframscience.com/nksonline/toc.html"><em>A New Kind of Science</em></a> . <br><br>  So what about neural networks?  They were not my favorite systems ‚Äî they seemed too arbitrary and complex in their structure compared to other systems that I researched in the computing world.  However, I continued to think about them again and again, conducted simulations in order to better understand the basics of their behavior, tried to use them for some specific tasks, like, for example, a fuzzy comparison with a sample: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/444/69c/a72/44469ca722b47f4ecdeb20b5703b7926.png" alt="Some of my early work on neural networks--from 1983..." title="Some of my early work on neural networks - from 1983 ..." width="547" height="659"></div><br><br>  <a href="http://www.wolframscience.com/nksonline/page-1099a-text">The history of</a> neural networks was associated with a series of ups and downs.  Networks suddenly appear in the 1940s.  However, by the 60s, interest in them had decreased, and there was a perception that they were rather useless and there was little that could be done with their help. <br><br>  However, this was true only for a single-layer perceptron (one of the first models of a neural network).  The revival of interest came at the beginning of the eighties - models of neural networks with a hidden layer appeared.  And despite the fact that I know many of the foremost in this direction, I still remained somewhat skeptical.  I did not leave the impression that those problems that are solved using neural networks can be solved much more easily in many other ways. <br><br>  And it seemed to me that neural networks were too complex formal systems;  somehow I even tried to develop <a href="http://www.stephenwolfram.com/publications/academic/approaches-complexity-engineering.pdf">my own alternative</a> .  However, I still supported people at the neural network research center and included their articles in my journal, <a href="http://www.complex-systems.com/"><em>Complex Systems</em></a> . <br><br>  Indeed, there were some practical applications for neural networks ‚Äî for example, visual character recognition ‚Äî however, there were few of them and they were scattered.  Years passed and, it seemed, almost nothing new appeared in this area. <br><br><a name="MachineLearning"></a><h2>  Machine learning </h2><br>  In the meantime, we were developing a set of powerful applied data analysis algorithms in <a href="http://www.wolfram.com/mathematica/"><em>Mathematica</em></a> and then turned into the <a href="http://www.wolfram.com/language/">Wolfram Language</a> .  And a few years ago we came to the conclusion that it was time to move on and try to integrate <a href="https://reference.wolfram.com/language/guide/MachineLearning.html">highly automated machine learning</a> into the system.  The idea was to create very powerful and common functions;  for example, the <b><a href="http://reference.wolfram.com/language/ref/Classify.html">Classify</a></b> function, which will categorize things of any kind: say, <a href="http://blog.stephenwolfram.com/2015/03/frontiers-of-computational-thinking-a-sxsw-report/">which photo is the day, and at what night</a> , the sounds of various musical instruments, the importance of email messages, and so on. <br><br>  We use a large number of modern methods.  But, more importantly, we tried to achieve complete automation, so that users could not know anything about machine learning at all: just call <b><a href="http://reference.wolfram.com/language/ref/Classify.html">Classify</a></b> . <br><br>  At first I was not sure that it would work.  But it works, and very well. <br><br>  You can use almost anything as training data, and the Wolfram Language will work with classifiers automatically.  We also introduce more and more various classifiers already built in: for example, for languages, flags of countries: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d19/8e2/cfc/d198e2cfc0ed5b3636293646831d5fd2.png" alt="In[4]:= Classify[&amp;quot;Language&amp;quot;, {&amp;quot;Ê¨¢ËøéÂÖâ‰∏¥&amp;quot;, &amp;quot;Welcome&amp;quot;, &amp;quot;Bienvenue&amp;quot;, &amp;quot; &amp;quot;, &amp;quot;Bienvenidos&amp;quot;}]" title="In [4]: ‚Äã‚Äã= Classify [&amp; quot; Language &amp; quot ;, {&amp; quot; Ê¨¢Ëøé ÂÖâ‰∏¥ &amp; quot ;, &amp; quot; Welcome &amp; quot ;, &amp; quot; Bienvenue &amp; quot ;, &amp; quot; Welcome &amp; quot ;, &amp; quot; Bienvenidos &amp; quot;}]" width="415" height="93"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6bb/57a/fdd/6bb57afddf560c433f94bd162cf161b9.png" alt="In[5]:= Classify[&amp;quot;CountryFlag&amp;quot;, {images:flags}]" title="In [5]: = Classify [&amp; quot; CountryFlag &amp; quot ;, {images: flags}]" width="427" height="137"><br><br>  And some time ago we came to the conclusion that it was time to tackle the large-scale problem of classification - image recognition.  And our result is <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> . <br><br><a name="ItsAllAboutAttractors"></a><h2>  All this is connected with attractors. </h2><br>  What is image recognition?  In the world there are a large number of the most diverse things that people gave the name.  The essence of recognition is to determine which of these things are represented in this image.  If it is more formal - to display all possible images in a certain set of object names in symbolic form. <br><br>  That is, we have no way to describe, for example, a chair.  But we can give many examples of how a chair looks, as if to say: ‚Äúeverything that looks like this here, let it be defined by the system as a chair.‚Äù  That is, we want all images that contain something similar to a chair to have a match with the word chair, while other images would not have such a match. <br><br>  There are many different systems with similar " <a href="">attractor</a> " behavior.  As an example from the physical world, one can cite the mountainside.  Raindrops can fall on any part of the mountain, however (at least in the ideal model) they will flow down to the lowest possible points.  Drops that are nearby, will tend to the same points.  Far away drops will flow to different points. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/70e/a90/af3/70ea90af3858620cb9954f047630072d.png" alt="In a mountainscape, water flows to different lowest points depending on where it falls on the terrain" title="It falls on the terrain." width="547" height="198"></div><br><br>  Raindrops are like images, and points of the foot of a mountain are like types of objects.  By raindrops we mean some physical objects that move under the influence of gravity.  However, the images are composed of pixels.  And instead of physical movement, we need to think about how these digital values ‚Äã‚Äãshould be processed by the program. <br><br>  And exactly the same attractor behavior occurs here.  For example, there are many cellular automata in which each automaton can change the colors of several neighboring cells, but in any case it will end in some <a href="">steady state</a> (most cellular automata actually have more <a href="">interesting behavior</a> that does not have any final state , but then we would not be able to draw an analogy to the tasks of recognition). <br><br><div style="text-align:center;"> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/e8d/10a/284/e8d10a284a49f4d52855ef4fdf26cfaf.png" alt="Cellular automata with different initial states but same final states. Like rain on a mountainscape, initial cells can &amp;quot;fall&amp;quot; in any of many different places and wind up in the same final position." title="Cellular auto states with different states. Initial cells can &amp; quot; fall &amp; quot; up in the same final position." width="550" height="190"></a> </div><br><br>  So what happens if we take an image and apply cellular automata algorithms to it?  In fact, when we process images, some of the usual operations (on computers or using visual inspection by humans) are simply algorithms of two-dimensional cellular automata. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/467/181/c4d/467181c4de830ad7e8fcbe89ac3084fd.png" alt="A lot of image processing can be--and is--done with cellular automata" title="A lot of image automata" width="485" height="107"></div><br><br>  It is easy to make cellular automata discern some features of an image like dark spots, for example.  However, image recognition requires more.  If we again apply that analogy with the mountain, then we need to create a mountainside with all its properties so that the drops from the corresponding part of the mountain flow down to the corresponding part of its base. <br><br><a name="ProgramsAutomaticallyMade"></a><h2>  Automatically created programs </h2><br>  So how do we do this?  In the case of digital data such as images - no one knows how to do it in one fell swoop.  This is an iterative process.  At the beginning we have some preparation, and then constantly change its shape, fashioning what we need. <br><br>  Many things in this process are hidden from us.  I <a href="http://www.wolframscience.com/nksonline/section-12.11-text">diligently thought</a> about this, how it all relates to discrete programs like cellular automata, Turing machines and the like.  And I am sure that here you can get very interesting results.  But I never understood - how exactly? <br><br><div style="text-align:center;"> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/4a2/074/99d/4a207499dc950d55f51be2aac47e3b02.png" alt="Cellular automata can be used for a kind of iterative sculpting" title="Cellular automata can be used for a iterative sculpting" width="525" height="139"></a> </div><br><br>  For systems with a finite real number of parameters, there is an excellent method called back propagation, which is based on calculations.  It is, in fact, a variant of a very simple method - the gradient inheritance method, in which derivatives are calculated, and then used to determine how to change the parameters so that the system has the desired behavior. <br><br>  So what type of system should we use?  Somewhat unexpectedly, but the main option is neural networks.  The name evokes thoughts about the brain and about something biological.  However, in our case, neural networks are formal computing systems that consist of some combination of functions from many arguments with continuous parameters and discrete threshold values. <br><br>  How easy is it to make such a neural network perform some interesting tasks?  It's hard to say, really.  At least for the last 20 years, I have believed that neural networks can only do those things that can be implemented without any other, simpler methods. <br><br>  But a few years ago, everything began to change.  And now you can often hear about some other successful application of neural networks to solve some applied problems like, say, image recognition. <br><br>  How did this happen?  Computers (and especially linear algebra in graphics processors) became fast enough to cope with various algorithmic tricks, including cellular automata - it became possible to create neural networks with millions of neurons (and yes, now these are deep neural networks with many levels) .  And all this gave rise to many different new applications. <br><br><a name="WhyNow"></a><h2>  Why now? </h2><br>  I don‚Äôt think it‚Äôs a coincidence that it happened just when the number of artificial neurons became comparable to the number of neurons in the corresponding parts of our brain. <br><br>  And the point is not that quantity in itself means something.  Rather, the fact is that if we solve some tasks like image recognition, those tasks that the human brain solves, it is not surprising that we need a system of the appropriate scale. <br><br>  People can easily recognize thousands of different objects - about as many as there are nouns in the language that can be portrayed.  Other animals distinguish far fewer objects.  But if we try to recognize images in the way that a person does, effectively transforming them into words that exist in human languages, then we will encounter the whole scale of the problem.  The key to its solution is the neural network of the scale of the human brain. <br><br>  Undoubtedly, there are differences between computational and biological neural networks, although after the network is trained, the process of obtaining a result from an image is very similar.  But the methods used to train computational neural networks are significantly different from those that should be used in biological networks. <br><br>  However, during the development of <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify,</a></b> I was really amazed how much her behavior resembled a biological neural network.  First of all, the number of images for training - several tens of millions - is comparable with the number of objects that people encounter in the first couple of years of their life. <br><br><a name="AllItSawWasTheHat"></a><h2>  I see only a hat </h2><br>  There were also features in training that are very similar to those that arise for biological neural networks.  For example, we somehow made a mistake by not putting images of people's faces in a training compilation.  And when we showed the picture, which was <a href="http://www.wolframalpha.com/input/%3Fi%3Dindiana%2Bjones">Indiana Jones</a> , the system did not understand at all that there was some kind of face and issued that the picture shows a hat.  Perhaps this is not surprising, but as it resembles a classic experiment with kittens, who throughout their life have only seen vertical bands, after which they could not see horizontal ones. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/10a/a47/20b/10aa4720ba66577e85a7056c2beb3a26.png" alt="When we gave it a picture of Indiana Jones, it zeroed in on the hat" title="Indiana Jones, it is zeroed in on the hat" width="233" height="140"><br><br>  Probably, like the brain, the neural network <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> has many layers that contain neurons of different types (the general structure, of course, is well described by the symbolic representation of the Wolfram Language). <br><br>  It is difficult to say something meaningful about what is happening inside the network.  But if you look into the upper layers, you can select some features that are distinguished by the system.  And, perhaps, they are very similar to those features that <a href="http://www.wolframscience.com/nksonline/page-1075b-text">differ in real neurons</a> in the primary visual cortex. <br><br>  I myself have long been interested in such things as visual textural recognition, (the definition of some texture primitives, like the base color) and I believe that we can now understand a lot from this.  I also think it would be very interesting to look into the deeper layers of the neural network and see what happens there.  We could find there <a href="http://blog.stephenwolfram.com/2015/03/frontiers-of-computational-thinking-a-sxsw-report/">some concepts</a> that actually describe classes of objects, including those for which so far there are no words in natural human languages. <br><br><a name="WeLostTheAnteaters"></a><h2>  We lost anteaters! </h2><br>  As with many other projects for Wolfram Language, when creating an <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify,</a></b> we needed to do many different things.  Work with a lot of educational images.  Development of ontology of rendered objects and its transfer to Wolfram Language.  Analysis of the dynamics of neural networks using methods that are used in physics.  Tedious optimization of parallel code.  Even some research in the style of <i>A New Kind of Science</i> for programs of the computing world.  And a lot of subjective opinions on how to introduce functionality that would be useful in practice. <br><br>  At the very beginning, I was not sure whether <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify would</a></b> work.  And at the very beginning the number of absolutely incorrectly recognized images was very high.  However, step by step, we gradually approached the moment when using <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> it was already possible to get something useful. <br><br>  But there are still a lot of unsolved problems.  The system coped well with some things, but seriously skidded in others.  We changed something, tuned something, and then there were new failures and a flurry of messages in the ‚Äúwe lost the anteater again!‚Äù Style (for <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">example</a></b> , how those images that <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> used for correct recognition of anteaters were recognized as something completely different). <br><br>  Debugging <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> was a very exciting process.  What can be considered meaningful input data?  And what is meaningful data at the output?  How to choose - a more general and reliable result, or more specific, but less reliable (just a dog, or a hunting dog, or a beagle)? <br><br>  There have been things that at first glance seemed completely crazy.  A pig that was identified as a harness.  A piece of stonework was defined as a moped.  But the good news was that we always found the reason ‚Äî for example, that some irrelevant objects were constantly on the training images (the only masonry that <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> saw was Asian, against which mopeds were constantly present). <br><br>  To test the system, I often tried non-standard images: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b0b/45f/268/b0b45f2686b543617bfafc033dfbfac4.png" alt="Unexpected images often gave unexpected results" title="Unexpected images often gave unexpected results" width="610" height="426"></div><br><br>  And I was struck by what I discovered.  Yes, <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> may be wrong.  But for some reason the mistakes seemed very understandable and in some sense human.  It seemed that <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> very successfully copies some aspects of how a person himself recognizes images. <br><br>  What about abstract art?  This is something like the Rorshak test for both machines and people - a very interesting insight into the features of <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e17/587/939/e1758793979ecdb08ff5fc4d27904aab.png" alt="Abstract art gets fascinating interpretations, sort of like Rorschach-blot interpretations from humans" title="Abstract art gets fascinating interpretations, sort of like Rorschach-blot interpretations from humans" width="610" height="149"></div><br><br><a name="OutIntoTheWild"></a><h2>  Back to nature </h2><br>  Projects such as creating an <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> never end.  But a couple of months ago (see the article on Habrahabr " <a href="http://habrahabr.ru/company/wolfram/blog/255579/">Stephen Wolfram: Frontiers of computational thinking (report from the SXSW festival)</a> ") we released a preliminary version on the Wolfram Language.  And today we have released a <a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">new version</a> and used it as the basis for the <a href="https://www.imageidentify.com/">Wolfram Language Image Identification Project</a> . <br><br>  We will continue the training and development of <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> , especially focusing on feedback and statistics from the site.  As for Wolfram | Alpha in the field <a href="http://www.wolfram.com/natural-language-understanding/">of natural language understanding</a> , without active use by people, there is no way to realistically assess progress, or even determine what the goals for the recognition of real images should be. <br><br>  I must say that I find it fun to even play with the Wolfram Language Image Identification Project.  It excites - to see how, after many years of work, artificial intelligence has turned out, which really works.  Moreover, when you see that <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> responds to an unusual or complex image, it feels as if it is a person who makes guesses or just jokes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4be/c7b/d1b/4bec7bd1ba21a07cbe6666b1987799c9.png" alt="Some of ImageIdentify's errors are quite funny" title="Some of the ImageIdentify's errors are quite funny" width="620" height="285"></div><br><br>  Under the hood of all this, of course, is just a code, with very simple cycles.  This code is almost the same as the one I, for example, wrote for my neural networks in the eighties (of course, this is now the code on Wolfram Language, not on the low-level C). <br><br>  This is a very unusual example from the history of ideas - neural networks have been explored for more than seventy years, but interest in them has repeatedly faded.  For us, neural networks are what led us to success in solving such an exemplary artificial intelligence problem as image recognition.  I believe that such leaders in the study of neural networks such as <a href="http://www.wolframscience.com/nksonline/page-1099a-text">Warren McCulloch and Walter Pitts</a> would be somewhat surprised by what the <a href="https://www.imageidentify.com/">Wolfram Language Image Identification Project</a> core does.  They would probably be amazed that it took as much as 70 years. <br><br>  But for me, much more important is how things like <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> can be built into the Wolfram Language symbol structure.  What <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> does is what people do from generation to generation.  But the symbolic language gives us the opportunity to present all the baggage of intellectual achievements of mankind.  And to make all this computational, I believe, will be something so ambitious that I am only now beginning to realize the significance of this. <br><br>  As for the current moment, I hope that you will like the <a href="https://www.imageidentify.com/">Wolfram Language Image Identification Project</a> .  Consider it as a holiday to achieve new frontiers of artificial intelligence.  Consider it as a rest for the mind, evoking thoughts about the future of artificial intelligence.  But one should not forget the most important, in my opinion: it is also an applied technology that you <b><a href="https://www.wolfram.com/programming-cloud/">can use here and now</a></b> in the <a href="http://www.wolfram.com/language/">Wolfram Language</a> and unload it wherever you want. <hr><br><h4>  Finally from the Wolfram Blog team ... </h4><br>  Once on Habrahabr, you get sick in the good sense of the word and <b><a href="http://reference.wolfram.com/language/ref/ImageIdentify.html">ImageIdentify</a></b> seems to know why. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b72/9ce/b90/b729ceb900ae4fc9a7e046b2e5ce0d96.png" width="500"></div></div><p>Source: <a href="https://habr.com/ru/post/258003/">https://habr.com/ru/post/258003/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../257977/index.html">Wiren Board 4 - controller for automation</a></li>
<li><a href="../257979/index.html">How I started working with nRF24LE or another way to program this chip</a></li>
<li><a href="../257981/index.html">Automatically Testing JavaFX Applications</a></li>
<li><a href="../257985/index.html">Development of MMO RPG - a practical guide. Server (Part 1)</a></li>
<li><a href="../257991/index.html">Features of API development on symfony2</a></li>
<li><a href="../258005/index.html">Development for Microsoft SQL Server (and not only): version control, continuous integration and procedures - as we do</a></li>
<li><a href="../258007/index.html">HP P2000 G3 MSA Array System Firmware Update</a></li>
<li><a href="../258009/index.html">Lock for the designer</a></li>
<li><a href="../258015/index.html">Ensuring backward compatibility of .NET applications when using WinRT</a></li>
<li><a href="../258019/index.html">Asm.js came to Chakra and Microsoft Edge</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>