<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Adiabatic cooling data center</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Up to 35-40% of all energy consumed by the data center is spent on cooling the server racks and engineering systems. The adiabatic principle of coolin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Adiabatic cooling data center</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/c0d/31f/071/c0d31f071e4daaeb94bbc5b5e2c03e0f.png"><br>  Up to 35-40% of all energy consumed by the data center is spent on cooling the server racks and engineering systems.  The adiabatic principle of cooling a data center can significantly reduce power consumption compared to traditional systems.  An economical method of cooling the data center will be implemented in the DataPro company data center in Moscow. <br><br><h4>  Weather in the data center </h4><br>  In recent years, the density of equipment in data centers has increased significantly, and with it increased the cost of power supply.  In Russian commercial data centers, one rack consumes on average from 3 to 10 kW - about the same amount of heat has to be removed from it.  At the same time, the most significant "contribution" and the general landscape of energy consumption are made by cooling systems: their share reaches 35-40%. <br><br><a name="habracut"></a><br>  In an effort to optimize the traditional scheme, the experts tried to remove heat by applying more efficient refrigerants and by choosing the optimal parameters of the system.  But these were half measures that did not allow for substantial savings. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The most energy-intensive link in the traditional cooling scheme is the compressor and condensing units.  The abandonment of these components in combination with the use of cold outside air (freecooling - this is what scientifically called the use of natural cooling) was the first revolutionary step towards an optimized cooling system with respect to energy resources.  This approach has been adopted by many data centers around the world.  The principle of free cooling is widely used today in many data centers in Russia - mainly in those regions where for many months a low temperature is maintained outside.  Obviously, the use of such technology is fully justified in Murmansk or Norilsk.  But is it possible to build an energy efficient data center in a hot climate?  For Russian data centers, this issue is also not idle, since in the summer months in middle and even northern latitudes, the air temperature is quite high. <br><br><h4>  Hot cooling </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/3db/d41/f22/3dbd41f229cacada8ad4b28555bc5ba3.jpg"><br>  DC "Mercury" company eBay <br><br>  Paradoxically, many examples of the location of data centers in a hot climate are known all over the world - under conditions that are much more extreme than Russian ones.  For example, eBay built the data center Mercury in Phoenix, Arizona, in the hot desert, where the thermometer reaches 50 degrees C in summer. And this is why the continuity and response time of an application is extremely important for eBay business. at the request of users around the world - every second on the portal of this company is a huge volume of transactions totaling about 2 thousand dollars.  That is, the reliability of all data center systems is in the list of priorities in the first place.  It would seem that to cool such a data center it would be more sensible to locate it in the northern latitudes. <br><br>  And, nevertheless, eBay built its data center in Arizona, and did not burn through.  It would seem that the use of external air and it could not go.  But, after analyzing all the available opportunities to reduce the level of energy consumption, eBay experts came to the conclusion that it is the best way to ensure the required efficiency of the new data center in the desert.  The secret is that in combination with free cooling on this object, adiabatic humidification was applied. <br><br><h4>  Wind was blowing from sea </h4><br>  It has long been noted that the air coming from the sea is cooler than the steppe wind blowing in the direction of the water area.  In ancient Rome, houses were thus cooled: under the open windows there was a pool with a fountain: passing over the water, the air was cooled as a result of its evaporation. <br><br>  Wet cooling towers are based on this principle. This is one of the oldest cooling methods that is widely used in production.  The principle of operation of these systems is based on cooling water with a stream of air blown through its surface. <br>  A more advanced version of this process is used in adiabatic air cooling systems. <br><br><h4>  Economics issue </h4><br>  Adiabatic data center cooling is an inexpensive and reliable system that does not have complex units and does not require redundancy of nodes.  To implement adiabatic humidification, there is practically no need for electricity costs - only water is consumed.  Thus, the cost of cooled air is low, which, if used properly, can significantly improve the energy efficiency of air conditioning systems. <br><br>  In general, the equipment of modern data centers tolerates a higher temperature and an increase in air humidity.  Parameters recommended by ASHRAE (American Society of Heating, Refrigerating and Air Conditioning Engineers) are used as permissible limits.  In the first edition of these recommendations, published in 2004, the upper limit was set at 25 degrees Celsius at a humidity of 40%, in the second (2008) - 27 degrees at a humidity of 60%.  In the recommendations of 2011, two new classes of equipment for data centers appeared - A3 and A4 with a temperature range up to 40 and 45 degrees.  Although such ‚Äúhot‚Äù cooling is not yet widespread, innovation lovers are actively beginning to use it.  This allows you to significantly expand the geography of "green" cooling. <br><img src="https://habrastorage.org/getpro/habr/post_images/b75/a7f/48e/b75a7f48e9fa59b435c5b8273b732f51.png" align="left"><br>  Adiabatic cooling is not always required, only during the hottest months.  In the cold season cooling is carried out with the help of outside air.  Not so long ago, adiabatic cooling systems were mainly used in regions with a dry and hot climate.  But recent developments by manufacturers of climatic equipment have shown a great potential for using adiabatic cooling systems in European regions with a temperate climate. <br><br>  ‚ÄúIt should be noted that neither the initial temperature of the water nor the temperature of the air practically have any effect on the process, unlike humidity,‚Äù explains Mikhail Balkarov, a technical expert at Emerson Network Power.  - So if the data center is located in the desert, but at the same time has a water source, it turns out quite effective system.  But if it rains at an air temperature of plus 25 degrees Celsius, then, alas, no cooling from the system can be removed, because during rain the humidity of the outside air is close to 100%. <br><br>  Michael notes that it is necessary to take into account local anomalies of humidity that occur near large water bodies.  In addition, in the Russian regions with changeable weather, you may have to have two systems at the same time ‚Äî the traditional and the alternative, which will significantly increase the amount of capital investment and may reduce to zero all attempts to save. <br><br>  The disadvantage of the adiabatic cooling method is also an increase in air humidity.  There may be concerns that humidity will become a threat to sensitive electronic equipment in the data center.  One example of such an incident is discussed below (see the Facebook in the Rain section). <br><br>  Among other shortcomings of the adiabatic cooling system, the expert notes the water consumption and the need to prepare this water.  ‚ÄúWater consumes about 2 l / h per 1 kW / h at peak consumption and about 0.3 l / h during the warm season, on average,‚Äù says Balkarov.  ‚ÄúThis is considerable money, and considering the costs of cleaning, is even more visible.‚Äù <br><img src="https://habrastorage.org/getpro/habr/post_images/839/b66/477/839b66477e92fca8a16ea7b7b8d975cf.png" align="right"><br>  It is necessary to purify water, emphasizes Mikhail Balkarov, because during evaporation all minerals are in the air in the form of fine dust.  ‚ÄúAnd if for cooling towers it is a rather cheap process associated with coarse cleaning, cleaning is mainly intended to prevent scale formation, then nozzles in the adiabatic system require microfilters and osmotic filtration,‚Äù the expert explains.  So not only the cost of the system, but also operating costs increase. ‚Äù <br><br>  When using adiabatic cooling, it should be remembered that we will have to solve more water supply, sewerage and water treatment, which, in turn, will flow into the problems of architecture and building structures.  Do not forget about the cost of water.  While its price is incomparable with the cost of electricity, but it is constantly growing. <br><br><h4>  Coefficient wue </h4><br>  The use of adiabatic cooling systems leads to a decrease in PUE and energy consumption, but at the same time water consumption can be very high.  Therefore, in March 2011, the Green Grid organization introduced another parameter that characterizes the useful water consumption in the data center - WUE (Water Usage Effectiveness).  The coefficient is calculated by the formula: <br><br>  <b>WUE</b> = <i>annual water consumption / power of IT equipment</i> <br><br>  The unit of WUE is l / kW / h. <br><br>  Facebook was the first data center operator to share the value of WUE openly.  In the data center located in Prineville in the second half of 2011, this parameter was 0.22 l / kW * h. <br><br>  In general, the use of adiabatic cooling allows achieving high energy efficiency of the data center: the PUE ratio can reach a value of 1.043, due to the fact that the auxiliary equipment, including the cooling system, consumes only about 4% of the electricity of the data center energy even in summer, and even less in winter the PUE period is about 1.018).  The efficiency of condensing systems based on chillers or DX air conditioners is significantly lower, for them PUE = 1.3 is an excellent result. <br><br>  The data center Mercury, mentioned at the beginning of the article, with an area of ‚Äã‚Äã12,600 square meters and a capacity of 4 MW has been operating for over a year.  The use of free-cooling in conjunction with adiabatic evaporative cooling in this data center has proven its effectiveness. <br><br><h4>  Facebook data centers </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/d28/03d/66e/d2803d66e50912d79a98bdbf9ac56be8.jpg"><br>  <i>Adiabatic Cooling System in Facebook Data Center</i> <br><br>  Another striking example of the use of new cooling technologies is Facebook data centers.  Facebook built its first data center in Prinville in 2010.  A year later, a second backup data center was built in Forest City, North Carolina.  The energy efficiency ratios (PUE) of these sites are: 1.07 for data center in Prineville and 1.09 for data center in Forest City.  This was achieved only due to the reduction of losses in the transmission and conversion of electricity, as well as higher operating temperature of the air inside the data center (+35 ¬∞ C allowed in racks in the cold corridor). <br><br>  The data centers installed the traditional cooling system, but it is used only in emergency cases.  The main air conditioning system is direct freecooling with several air preparation chambers through which the outside air passes. <br><br>  Initially, the air from outside is taken in by air intakes on the second tier and enters the preparation chamber, where it is filtered and mixed with hot air.  Further, the air passes through the cooling panels.  They are a humidification chamber with a large number of pipes, spraying distilled water with nozzles under high pressure, thereby increasing the humidity and the temperature of the blown air.  To fine moisture could not conduct electricity, use distilled water.  Next in the path of air are membrane filters that separate large particles of moisture.  Then the air is sent by powerful fans to the engine room.  Waste water is collected in a special tank and cleaned. <br><br><h4>  Facebook in the rain </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/3e8/93e/449/3e893e4492179bbda8bd1a9f274ac4c0.jpg"><br><br>  Once, a cloud of moisture was formed inside the cooled premises of Facebook's data center in Prineville, which literally covered the server rooms along with their (sorry for the pun) ‚Äúcloud‚Äù computing. <br><br>  In 2001, this data center encountered a problem in the operation of the control system, due to which the temperature of the air used to cool the servers reached more than 26 degrees Celsius and the humidity over 95%.  As a result, condensate began to accumulate and a rain cloud formed that filled all the space with computing equipment.  What was happening was impossible to believe.  Calls began to colleagues in the center of the escalation of problems, but for a long time they could not penetrate, what kind of rain cloud are we talking about?  It was easier to convince them that the apple trees bloomed on Mars than in the tale of rain. <br><br>  To save electricity, Facebook used outdoor air to cool its data center instead of the traditional system.  But after the control system failed, the recirculation of the heated air with a low level of moisture began through the cooling system on the basis of a water evaporator. <br><br>  This led to the fact that the air was highly humidified and a cloud was formed, which had done a lot of mischief.  Some servers are completely out of order: those specialists who were in the data center could observe how the servers are sparked and agonized.  It was impossible to imagine anything worse.  However, the incident did not happen again: Facebook experts carefully isolated contacts in the places where the servers were connected to power sources, protecting them from moisture. <br><br><h4>  And what about Russia? </h4><br>  Adiabatic cooling systems in Russia are not yet very popular, but experts believe that in the coming years, the designers of data centers will show increasing interest in them.  The reason for this is the Federal Law FZ-261, which establishes a rigid framework for energy consumption and requires an increase in energy efficiency of 40% by 2020.  The only possible scenario that would allow to meet such requirements is the transition to free cooling in combination with adiabatic cooling.  And the first examples of such implementations are already there.  In particular, this principle of cooling will be used in the new DataPro company data center under construction in Moscow. <br><br>  The project of this site involves the use of an economical in operation solution to ensure the necessary climatic conditions - the modular EcoBreeze system manufactured by Schneider Electric.  DataPro plans to implement Europe‚Äôs largest installation of this system in its own mega-data center in Aviamotornaya Street, a facility with an installed capacity of 20 MW.  The EcoBreeze system is built using the principle of a wet cooling tower (a variety of adiabatic cooling technology) in combination with the free cooling feature described in this article.  In Moscow, where high electricity tariffs are established, the use of this system will make it possible to achieve significant savings in operating costs in the data center. <br><br>  ‚ÄúTechnical solutions using adiabatic cooling cannot be called innovative, since they are successfully used in many data centers abroad,‚Äù explains Alexey Soldatov.  - But the use of this principle in Russian data centers is a rare phenomenon.  The installation of EcoBreeze on our Moscow site is one of the first implementations. ‚Äù <br><br>  But at another facility, in the DataPro company‚Äôs data center in Tver, the traditional principle of using freon routes is used to cool the server rooms and electrical equipment, which is due to low capital costs and low electricity tariffs. <br><br>  At the facility in Tver, another type of adiabatic principle is used - isothermal humidification to maintain the required level of humidity in server rooms, we will tell about it in our next article. <br><br>  <b>Operating principle</b> <br>  <b>Mikhail Balkarov.</b>  <b>An excerpt from the book "Cooling server and data center. Basics.", 2011</b> <br><br>  The principle of operation of the adiabatic cooling system consists in spraying water in the form of tiny droplets that are injected into hot air.  (Water should be free from all sorts of impurities.) Water evaporated in the air can cool it to a temperature close to that of a wet thermometer. <br><br>  <i>Theoretically, the cooling limit in this process is noticeably lower and equals the dew point temperature.</i>  <i>To realize this possibility, it is enough to cool part of the source air to the temperature of a wet thermometer by evaporation of water, and then use it to cool the residue without moistening it.</i>  <i>Further, the cold air is also moistened, acquiring a lower temperature.</i>  <i>The process can be repeated once again with a part of the air, reaching a temperature close to the dew point.</i>  <i>The only obvious technical difficulty in achieving the lowest possible temperature is to increase several times the required volumes of air supplied and the area of ‚Äã‚Äãthe heat exchanger.</i> <br><br>  Such systems are made either according to the principle of wet cooling towers, that is, they use a large surface of plates covered with a thin film of water, or they spray water under pressure of several hundred atmospheres, through micron nozzles, in very small drops directly into the air ducts. <br><br>  Then either the temperature is exchanged so that it needs to be cooled, or the moist air is directly used to cool the equipment.  Water consumption is about 2 Kg per 1 kW / h of exhaust heat.  Since most of the water evaporates, the requirements for its chemical composition increase accordingly, which requires the use of ion exchange filters or reverse osmosis filters. <br><br>  When using nozzles, strict requirements are imposed on mechanical impurities; installation of microfilters is required after the high-pressure pump.  These complications are related to the fact that starting from a certain size of a drop, the evaporation process occurs very quickly, and due to this, the size of the irrigation chamber is significantly reduced. <br><br>  The use of nozzles of larger diameter, medium and low pressure, is easier from the point of view of the operation of the nozzles and the water treatment process.  But at the same time, some of the water does not participate in the process and merges (the drops do not have time to evaporate completely), besides, the dimensions of the humidification chambers become comparable with the rest of the system. </div><p>Source: <a href="https://habr.com/ru/post/200396/">https://habr.com/ru/post/200396/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../200382/index.html">Creating a module for Drupal 7. Part 2</a></li>
<li><a href="../200386/index.html">SSD-VDS and SSD hosting in the Netherlands and the USA</a></li>
<li><a href="../200388/index.html">My Opera closes in March 2014</a></li>
<li><a href="../200390/index.html">How the world's first Bitcoin exchanger works</a></li>
<li><a href="../200394/index.html">How it is done: parsing articles</a></li>
<li><a href="../200398/index.html">Pays.io payment service closes</a></li>
<li><a href="../200400/index.html">BlackBerry 10.2: what's new?</a></li>
<li><a href="../200402/index.html">From 2015, all cars in the Russian Federation must be with GLONASS</a></li>
<li><a href="../200404/index.html">PayPal bans the withdrawal of money from Flattr in Russia</a></li>
<li><a href="../200408/index.html">Favorites: IT Security Links</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>