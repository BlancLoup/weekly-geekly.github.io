<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>As we wrote the application on the NASA Space Apps Challenge hackathon</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="On October 20 - 21, the NASA Space Apps Challenge international hackathon took place in Moscow. It was organized in Russia by guys from the Russian.Ha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>As we wrote the application on the NASA Space Apps Challenge hackathon</h1><div class="post__text post__text-html js-mediator-article">  On October 20 - 21, the <strong>NASA Space Apps Challenge</strong> international hackathon took place in Moscow.  It was organized in Russia by guys from the <a href="https://vk.com/russian_hackers">Russian.Hackers</a> community.  During the event, participants were asked to solve 20 cases on various topics: from shooting a film about the hackathon to developing applications for monitoring and designing autonomous aircraft.  A complete list of topics can be found at the <a href="https://2018.spaceappschallenge.org/challenges/">link</a> or in the <a href="https://habr.com/company/jethackers/blog/426915/">article on Habr√©</a> . <br><img src="https://habrastorage.org/webt/zb/xr/n8/zbxrn8ng1jnvhth73omf4dgorbe.png"><br>  Our team ‚ÄúSpace Monkeys‚Äù, which included Oleg Borodin (Front-end developer at Singularis lab), Vladislav Plotnikov (QA engineer at Singularis lab), Yegor Shvetsov, Dmitry Petrov, Yuri Bederov and Nikolai Denisenko, chose to solve the problem under catchy titled ‚ÄúSpot that fire!‚Äù, which is worded as follows: ‚Äú <em>Apply crowdsourcing so that people can contribute to the detection, confirmation and tracking of forest fires.</em>  <em>The solution can be a mobile or web application.</em>  " <br><br>  Due to the fact that the team gathered 5 developers with development experience for various platforms, it was immediately decided that the prototype of our application would be implemented under the Web and Mobile platform. <br><a name="habracut"></a><br><h2>  What NASA data did we use? </h2><br><p>  Still, the hackathon was conducted under the auspices of the National Aeronautics and Space Administration, so it would be wrong not to use open data from NASA storerooms.  In addition, we immediately found the <a href="https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms/active-fire-data">Active Fire Data data</a> we need.  This dataset contains information about the coordinates of fires around the world (you can download information on a specific continent).  Data is updated every day (you can get data for 24 hours, 48 ‚Äã‚Äãhours, 7 days). </p><br><p>  The file contains information on the following fields: latitude, longitude, brightness, scan, track, acq_date, acq_time, satellite, confidence, version, bright_t31, frp, daynight, of which we used only the coordinates of the fire points (latitude and longitude). </p><br><h2>  The principle of the application </h2><br><p>  Since the application is crowdsourced, then ideally it should be used by a large number of users.  The principle of the application is as follows: </p><br><ol><li><p>  The user, having found a fire, photographs it (with a geotagging) and loads it using the service.  Photos with geotagging and sending coordinates go to the application server.  The photo can be downloaded from the Web or Mobile version of the application. </p></li><li><p>  The resulting photo is processed on the server by a trained neural network to confirm that the photo is really fire.  The result of the script execution is the prediction accuracy, if&gt; 0.7, then the photo is really fire.  Otherwise, we do not fix this information and ask the user to upload another photo. </p></li><li><p>  If the image analysis script gave a positive result, the coordinates from the geo-tag are added to the dataset with all coordinates.  Further, the distances between the <em>i</em> -th point from NASA dataset and the point from the user are calculated.  If the distance between the points is <strong>‚â§</strong> 3 km, then the point from the NASA set is added to the dictionary.  So go through all the points.  After that, on the client side of the application we return json with coordinates that satisfy the condition.  If the coordinates are not found by the given condition, then we return back the single point that we received from the user. </p></li><li><p>  If the server returns an array of points, then the client part of the application draws a fire zone on the map.  In the case when the server returned one point, it is marked on the map with a special label. </p></li></ol><br><h2>  Used technology stack </h2><br><h3>  <em>Front-end part of a web application</em> </h3><br><p>  The web application accessible from the browser was oriented to computer screens and was not adaptive, however, the technologies used easily made it possible to refine this aspect for mobile devices.  We used the following technology stack on the web side: </p><br><ul><li>  Angular 6 framework from Google in TypeScript </li><li>  CSS &amp; JS framework Materialize </li><li>  <a href="https://valor-software.com/ng2-file-upload/">ng2-file-upload file upload</a> module </li><li>  <a href="https://www.openstreetmap.org/">OpenStreetMap</a> maps, <a href="https://leafletjs.com/">Leaflet</a> library </li></ul><br><h4>  Work scenario </h4><br><p>  The user opens the application and sees its location: </p><br><img src="https://habrastorage.org/webt/p2/j1/uk/p2j1ukxxirwd_5ch-rsaje4sflc.jpeg"><br><br><p>  Initialization of user‚Äôs map and geotagging: </p><br><pre><code class="plaintext hljs">this.map = L.map('map').setView([latitude, longitude], 17); L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', { attribution: '&amp; copy; &lt;a href="https://www.openstreetmap.org/copyright"&gt;OpenStreetMap&lt;/a&gt; contributors' }).addTo(this.map); L.circle([latitude, longitude]).addTo(this.map) .bindPopup('You are here') .openPopup();</code> </pre> <br><p>  If there is a fire within a radius of <em>n</em> (adjustable variable) of kilometers, it will be displayed as a polygon with a summary of additional information: </p><br><img src="https://habrastorage.org/webt/6q/1e/k5/6q1ek54slbxacie85pqrdsuwzko.jpeg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>  The user selects the location of the fire on the map: </p><br><img src="https://habrastorage.org/webt/1t/qv/p9/1tqvp9ytbpe3r1kmwogvtviii34.jpeg"><br><br><p>  Setting the fire mark: </p><br><pre> <code class="plaintext hljs">let marker; this.map.on('click', function (e) { if (marker) { self.map.removeLayer(marker); } marker = L.circle([e.latlng.lat, e.latlng.lng], { color: 'red', fillColor: '#f03', fillOpacity: 0.5, radius: 15 }).addTo(self.map) .bindPopup(' ') .openPopup(); self.appService.coordinatesStorage.latitude = e.latlng.lat; self.appService.coordinatesStorage.longitude = e.latlng.lng; console.log('fire', self.appService.coordinatesStorage); });</code> </pre><br><p>  Next, the user uploads a photo of the fire using <a href="https://valor-software.com/ng2-file-upload/">ng2-file-upload</a> . </p><br><p>  As a result of these actions, the following data is transmitted to the server: </p><br><ul><li>  user coordinates </li><li>  coordinates of the specified fire </li><li>  fire photo </li></ul><br><p>  The output of the application is the result of recognition. </p><br><br><h3>  <em>Mobile-app apps</em> </h3><br><h4>  Used technologies </h4><br><ul><li>  React native - framework for developing cross-platform applications for iOS and Android </li><li>  Redux - flow control in applications </li><li>  Redux-saga - a library that uses side effects in Redux </li></ul><br><h4>  Work scenario </h4><br><table><tbody><tr><td><p>  Choosing a photo of fire <br><img src="https://habrastorage.org/webt/m_/n0/ex/m_n0exwfthzn0-yl3so514frun4.jpeg"><br></p><br></td><td><p>  User comment <br><img src="https://habrastorage.org/webt/wg/u5/yd/wgu5ydugmpmcr0j5yaqg52721ia.jpeg"><br></p><br></td><td><p>  Label for fire <br><img src="https://habrastorage.org/webt/4g/hc/et/4ghceta2dtzzj3mwb8ry2ikc5ws.jpeg"><br></p><br></td></tr></tbody></table><br><h3>  <em>Back-end part of the application</em> </h3><br><ul><li><p>  Programming language - JAVA 8 </p></li><li><p>  Cloud Platform - Microsoft Azure </p></li><li><p>  Web application framework - Play Framework </p></li><li><p>  Object-relational mapping - Ebean framework </p></li></ul><br><p>  The server has 2 scripts written in Python: predict.py and getZone.py, the following Python libraries have been installed for their work: </p><br><ul><li>  pandas - for processing and analyzing data </li><li>  geopandas - for work with geodata </li><li>  numpy - for working with multidimensional arrays </li><li>  matplotlib - for visualizing two-dimensional (2D) graphics data (3D graphics are also supported) </li><li>  shapely - for manipulating and analyzing flat geometric objects. </li></ul><br><p>  Server API: <a href="https://fire.iconx.app/api">fire.iconx.app/api</a> </p><br><ul><li>  loading coordinates </li></ul><br><pre> <code class="plaintext hljs">post /pictures {} return { id }</code> </pre><br><ul><li>  loading pictures </li></ul><br><pre> <code class="plaintext hljs">post /pictures/:id</code> </pre><br><p>  <strong>Script predict.py</strong> </p><br><p>  The input script received a picture, a simple preprocessing of the picture took place (more about it in the ‚ÄúModel Training‚Äù block) and based on the saved file with weights, which is also on the server, a prediction was issued.  If the model has given an accuracy of&gt; 0.7, then the fire is fixed, otherwise - no. </p><br><p>  The script runs in the classic way. </p><pre> <code class="plaintext hljs">$ python predict.py image.jpg</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Code Listing:</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">import keras import sys from keras.layers import Dense from keras.models import model_from_json from sklearn.externals import joblib from PIL import Image import numpy as np from keras import models, layers, optimizers from keras.applications import MobileNet from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers import Conv2D, MaxPooling2D def crop_resize(img_path, img_size_square): # Get dimensions mysize = img_size_square image = Image.open(img_path) width, height = image.size # resize if (width and height) &gt;= img_size_square: if width &gt; height: wpercent = (mysize/float(image.size[1])) vsize = int((float(image.size[0])*float(wpercent))) image = image.resize((vsize, mysize), Image.ANTIALIAS) else: wpercent = (mysize/float(image.size[0])) hsize = int((float(image.size[1])*float(wpercent))) image = image.resize((mysize, hsize), Image.ANTIALIAS) # crop width, height = image.size left = (width - mysize)/2 top = (height - mysize)/2 right = (width + mysize)/2 bottom = (height + mysize)/2 image=image.crop((left, top, right, bottom)) return image conv_base = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) def build_model(): model = models.Sequential() model.add(conv_base) model.add(layers.Flatten()) model.add(layers.Dense(256, activation='relu')) model.add(layers.Dense(64, activation='relu')) model.add(layers.Dense(1, activation='sigmoid')) model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc']) return model image=crop_resize(sys.argv[1],224) image = np.reshape(image,[1,224,224,3]) #Loading models and text processing model = build_model() print('building a model') model.load_weights('./models/mobile_weights.h5') print('model loaded') pred_cat=model.predict(image) if pred_cat &gt; 0.7: print('fire {}'.format(pred_cat)) else: print('no fire {}'.format(pred_cat))</code> </pre><br></div></div><br><br><p>  <strong>GetZone.py script</strong> </p><br><p>  The input data of the script are the coordinates of the point that came from the client side of the application.  The script pulls in all coordinates from NASA, adds a new latitude and longitude to this file, overwrites the original file and starts looking for the nearest points.  The distance between the points is calculated according to the formula of haversine (Eng. <a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine formula</a> ). </p><br><p>  For this, the latitude and longitude of the points are converted to radians: </p><br><pre> <code class="plaintext hljs">pt1_lon, pt1_lat, pt2_lon, pt2_lat = map(radians, [pt1_lon, pt1_lat, pt2_lon, pt2_lat])</code> </pre><br><p>  There are differences between latitude and longitude for each of the points: </p><br><pre> <code class="plaintext hljs">d_lon = pt2_lon - pt1_lon d_lat = pt2_lat - pt1_lat</code> </pre><br><p>  All this is substituted into the formula of haversinus: </p><br><pre> <code class="plaintext hljs">a = sin(d_lat/2)**2 + cos(pt1_lat) * cos(pt2_lat) * sin(d_lon/2)**2</code> </pre><br><p>  Take the root of the result of the calculation, calculate the arcsine and multiply the result by 2. </p><br><pre> <code class="plaintext hljs">c = 2 * asin(sqrt(a))</code> </pre><br><p>  The distance will be the product of the radius of the Earth (6371 km) by the result of the previous calculation. </p><br><h2>  Model training </h2><br><p>  To analyze the picture on the subject of a fire, we needed a training set of photos with fires.  The photos were collected by the script from <a href="https://www.flickr.com/">https://www.flickr.com/</a> and manually marked up. </p><br><p>  Downloading was done using FlikerAPI.  In the script, standard preprocessing operations were performed with pictures: framing is square with centering (ratio 1: 1), and resizing to 256 √ó 256 format. </p><br><div class="spoiler">  <b class="spoiler_title">Code Listing:</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">import flickrapi import urllib.request from PIL import Image import pathlib import os from tqdm import tqdm # Flickr api access key flickr=flickrapi.FlickrAPI('your API key', 'your secret key', cache=True) def get_links(): search_term = input("Input keywords for images: ") keyword = search_term max_pics=2000 photos = flickr.walk(text=keyword, tag_mode='all', tags=keyword, extras='url_c', per_page=500, # mb you can try different numbers.. sort='relevance') urls = [] for i, photo in enumerate(photos): url = photo.get('url_c') if url is not None: urls.append(url) if i &gt; max_pics: break num_of_pics=len(urls) print('total urls:',len(urls)) # print number of images available for a keywords return urls, keyword, num_of_pics #resizing and cropping output images will be besquare def crop_resize(img_path, img_size_square): # Get dimensions mysize = img_size_square image = Image.open(img_path) width, height = image.size # resize if (width and height) &gt;= img_size_square: if width &gt; height: wpercent = (mysize/float(image.size[1])) vsize = int((float(image.size[0])*float(wpercent))) image = image.resize((vsize, mysize), Image.ANTIALIAS) else: wpercent = (mysize/float(image.size[0])) hsize = int((float(image.size[1])*float(wpercent))) image = image.resize((mysize, hsize), Image.ANTIALIAS) # crop width, height = image.size left = (width - mysize)/2 top = (height - mysize)/2 right = (width + mysize)/2 bottom = (height + mysize)/2 image=image.crop((left, top, right, bottom)) return image def download_images(urls_,keyword_, num_of_pics_): num_of_pics=num_of_pics_ keyword=keyword_ urls=urls_ i=0 base_path='./flickr_data/' # your base folder to save pics for item in tqdm(urls): name=''.join([keyword,'_',str(i),'.jpg']) i+=1 keyword_=''.join([keyword,'_',str(num_of_pics)]) dir_path= os.path.join(base_path,keyword_) file_path=os.path.join(dir_path,name) pathlib.Path(dir_path).mkdir(parents=True, exist_ok=True) urllib.request.urlretrieve(item, file_path) resized_img=crop_resize(file_path, 256) #set output image size try: resized_img.save(file_path) except: pass urls, keyword, num_of_pics =get_links() continue = input("continue or try other keywords (y,n): ") if continue =='y': download_images(urls, keyword, num_of_pics) elif continue =='n': get_links() else: pass</code> </pre><br></div></div><br><p>  Naturally, for work with pictures, the convolutional architecture of the neural network was used, in which the pre-trained model was used.  The choice fell (expectedly) on <a href="https://habr.com/post/352804/">MobileNet</a> , because: </p><br><ul><li>  Lightweight - it is important that the application response time is minimal. </li><li>  Fast - it is important that the response time of the application is minimal. </li><li>  Accurate - <a href="https://habr.com/post/352804/"><em>MobileNet</em></a> predicts with the necessary accuracy. </li></ul><br><p>  After training, the network gave an accuracy of ~ 0.85. </p><br><p>  To build the model, training and prediction used a bunch of <a href="https://keras.io/">Keras</a> + <a href="https://www.tensorflow.org/">Tensorflow</a> .  Work with data was carried out through <a href="http://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html">Pandas</a> . </p><br><p>  Since NASA DataSet is a geographic data, we wanted to use the <a href="http://geopandas.org/">GeoPandas</a> library.  This library is an extension of the capabilities of Pandas to provide spatial methods and operation on geometric types.  Geometrical operations are implemented through the shapely library, fiona file handling, and matplotlib graphing. </p><br><p>  Having spent almost a day and a half to deal with this library, we abandoned it because we could not find what it could give us a real advantage from working with it.  Our task of calculating the coordinates was very small, so in the end, everyone implemented natively. </p><br><h2>  What's next? </h2><br><p>  Naturally, all that we got as a result is an extremely unstable and raw application that has the right to be finalized. </p><br><p>  We made it: </p><br><ol><li>  Implement prototypes of mobile and Web-based applications that were able to take photos (only for the mobile version), download and send them to the server.  Also send coordinates to the server successfully. </li><li>  The server managed to deploy 2 scripts that implement the main application logic.  The input data to these scripts and the output data were sent and sent to the client part. </li><li>  Implement the real ‚Äúprototype‚Äù of our application. </li></ol><br><p>  We failed to implement, but I would like to solve the following problems and add features (items go according to the priority of the task): </p><br><ol><li>  To organize the recording of all coordinates from the dataset to the database in order to interact directly with the database. </li><li>  To organize automatic uploading of a new file from the NASA site, i.e.  organize automatic daily update of coordinates. </li><li>  Add notification of users located in the zone close to the fire. </li><li>  Add registration (necessary for the implementation of the first paragraph). </li><li>  Rewrite the algorithm for calculating the fire zone. </li><li>  Solve design problems - bring beauty to the mobile and web versions of the application. </li></ol></div><p>Source: <a href="https://habr.com/ru/post/430480/">https://habr.com/ru/post/430480/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../430470/index.html">Why keeping the context on the client's account is fair and profitable</a></li>
<li><a href="../430472/index.html">Seamless DECT-network do it yourself</a></li>
<li><a href="../430474/index.html">CephFS vs GlusterFS</a></li>
<li><a href="../430476/index.html">NCBI Genome Workbench: Scientific Research Under Threat</a></li>
<li><a href="../430478/index.html">Trading bots for cryptographic. Where to begin?</a></li>
<li><a href="../430482/index.html">Theme of armor lifts in the culture of East and West</a></li>
<li><a href="../430484/index.html">Typical NGFW implementation scenarios</a></li>
<li><a href="../430486/index.html">How do freelancers live: from developer to technical copywriter</a></li>
<li><a href="../430488/index.html">Asynchronous data exchange with a remote application via SSH</a></li>
<li><a href="../430490/index.html">To anticipate, train, decide: how and for what EPAM builds the Java Competency Center</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>