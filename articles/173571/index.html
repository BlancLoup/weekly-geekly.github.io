<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Field-level OCR. What is it for?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We have already announced a cool thing called ABBYY Cloud OCR SDK. It is gradually gaining popularity - the other day the service recognized the milli...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Field-level OCR. What is it for?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/969/023/e5b/969023e5b47d0e95c1c976aacda02c8d.jpg" align="right" title="Surprisingly, but a fact (in the sense that you can‚Äôt tell from the picture): under the cut, it‚Äôs not about the clouds, but about OCR">  We <a href="http://habrahabr.ru/company/abbyy/blog/133624/">have already announced a</a> cool thing called ABBYY Cloud OCR SDK.  It is gradually gaining popularity - the other day the service recognized the millionth page.  It seems that this is a good reason to improve the OCR-literacy of current and future users.  So, let's begin. <br><br>  Today we will talk about the existence of two types of recognition - <a href="http://ocrsdk.com/documentation/apireference/processDocument/">Full Page OCR</a> and <a href="http://ocrsdk.com/documentation/apireference/processTextField/">Field-level OCR</a> .  These approaches differ not only in price, there are fundamental differences between them in why they are needed.  Unfortunately, not all new OCR developers understand these differences, and are forced to learn from mistakes.  Moreover, many large and well-known players in the Data Capture market still continue to use a single-pass algorithm where a multi-pass will be good (ie, Full Page OCR instead of Field-level).  The reasons for their behavior are commonplace: the application was written many years ago, and it is too expensive for them to redo the architecture, the UI, to re-train their partners.  And they are forced to pay for it with limitations in the field of quality of recognition. <br><a name="habracut"></a><br>  The need for Field-level OCR arises at the moment when we want to extract some useful data from the document.  Such a processing scenario in the industry is called Data Capture.  For example, we want to extract from Invoice the name of the company-counterparty, the amount that needs to be paid and the date by which the payment must be made.  Moreover, on such documents there are a lot of sums and dates, and here it is important not to miss and choose the right one.  Just imagine the consequences of the fact that, for example, if you pay instead of the invoice amount, your phone number will be used. <br><br>  Usually the processing of such documents looks like this: <br><img src="https://habrastorage.org/storage2/31d/e20/b6e/31de20b6ef91df42b10ca2c875a01750.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Depending on the type of documents being processed, various field search methods may be used.  In the simplest case - machine-readable forms that ‚Äúmatch to the light‚Äù, the coordinates of the fields are known in advance, it remains only to combine the sheet with the template, for which various ‚Äúbenchmarks‚Äù are used, such as these black squares. <br><img src="https://habrastorage.org/storage2/315/87c/62f/31587c62f4efde30f8213f96a54c64d9.png"><br><br>  In the case of invoices, this method no longer passes.  Here, more sophisticated techniques are applied, which are based on searching for keywords like ‚ÄúInvoice #‚Äù, ‚ÄúDue date:‚Äù, and starting from them, zones on the document are defined, in which the required fields are located.  It uses prior knowledge of how the invoice of this company is usually arranged. <br><br><img src="https://habrastorage.org/storage2/b1a/02e/b93/b1a02eb936ce9ee5369a8e6989a8f63b.gif"><br><br>  It was at this moment, when we had already determined the locations of the fields or, as in the most advanced systems like FlexiCapture, several possible hypotheses about the location of the fields ‚Äî it's time to decide how we will extract the text of these fields. <br><br>  Suppose we have determined the location of the fields correctly, and in the Total Amount field we have the amount, not the phone number.  But we still have a great chance to put the wrong point in the amount of ‚Äú$ 1,000.00,‚Äù or simply miss a comma and pay one hundred thousand instead of one thousand dollars.  That is why the extraction of such data is usually taken very seriously, and the question ‚Äúhow many percent of recognition errors‚Äù is already being replaced by the question ‚Äúhow much time is required for manual verification‚Äù.  The quality of technology here is no longer measured in the number of incorrect characters, but in the amount of manual labor required to correct system recognition errors.  Moreover, this is connected not only with the very accuracy of recognition, but also with her ability to correctly say ‚ÄúI‚Äôm not sure about this symbol‚Äù, but this is a topic for a separate article. <br><br>  As I said, there is a class of applications that use only one pass.  Already at the stage of determining the type of document, full recognition of the page occurs.  Its text serves as the basis for deciding on the type of document (for example, by searching for typical keywords for a given type), and then also for searching for reference elements and determining the location of fields.  And the same text is eventually used to extract data from fields. <br><br>  In our opinion, at this very moment it makes sense to once again recognize specific fields, but by already specifying the recognition parameters.  The fact is that by significantly narrowing the possible set of recognized values, we can significantly improve the accuracy of both recognition and definition of uncertainly recognized characters.  As a result, it has a positive effect on the main parameter of the system - the amount of manual labor for entering and processing documents. <br><br>  In particular, knowing which field we will now recognize, we can determine the following parameters: <br><br>  ¬∑ Set a regular expression or special language for dates, amounts, bank details, and so on. <br><br>  ¬∑ Set the dictionary of possible values, in case this field has a limited set of text values ‚Äã‚Äã(company name, nomenclature, etc.) <br><br>  ¬∑ Set text segmentation parameters (one line or several, monospace text or not, etc.) <br><br>  ¬∑ Specify the type of text if the field is printed in a special font like <a href="http://en.wikipedia.org/wiki/OCR-A_font">OCR-A</a> , etc. <br><br>  ¬∑ Apply special image processing settings (for example, if the text itself is printed in a different color, or often an organization stamp or signature is placed on it) <br><br>  In principle, all this setting is to disable various automation, which is in any high-quality OCR, and almost always works correctly.  But as I said, in the DataCapture scenario, the quality level ‚Äúalmost always works correctly‚Äù is not enough.  The presence of this ‚Äúpractically‚Äù leads to the fact that the recognition results are first checked by automatic rules, and then also manually by the operators, and sometimes in several stages, as people, unfortunately, ‚Äúalmost never make mistakes‚Äù. <br><br>  Let's look at this example.  Here, for example, scanned cash voucher. <br><br><img src="https://habrastorage.org/storage2/661/13c/422/66113c4220cd1d2a6c2de096496d021c.png"><br><br>  If you take a closer look, we will see that this is a real nightmare for OCR.  Letters stuck together and not fully printed. <br><br><img src="https://habrastorage.org/storage2/350/75f/74f/35075f74f62fc003ee94310c2cfa0a18.png"><br><br>  And yet, modern OCR technology can handle this.  If you just open it in ABBYY FineReader 11 and recognize the default settings, we will see that even out of this horror you can completely pull out something.  In general, he coped well, although he made a lot of mistakes.  In particular, in the part of particular interest to us - the table with the goods and the price, one of the values ‚Äã‚Äãwas recognized as ‚Äú$ o.ce‚Äù instead of ‚Äú$ 0.00‚Äù. <br><br><img src="https://habrastorage.org/storage2/b50/223/eb6/b50223eb601fabbdfea36e047c656d21.png"><br><br>  But why, you say?  After all, it is obvious that this is exactly "$ 0.00"!  But why is this obvious to you?  Because when you look at the image, you understand that this is a cashier's check, and there is a table in its center, and in the third column of the table are numbers, not abracadabra.  But how could the OCR program know this?  After all, in the left column there can be full abracadabras like ‚Äú5UAMM575‚Äù, why don't they meet in the third one too?  The program does not go shopping, and does not make purchases, and with the default settings, it is equally likely to expect to enter as checks, newspapers, and magazine articles with glamorous layout.  In the case of a two-pass algorithm, we determine that, generally speaking, this is a check, in addition, we can determine its structure, and also remember that for the checks of AJ Auto Detailing Inc. in the third column there are always sums of $ XXX.XX format and no letters there can not be.  Thus, by re-recognizing only these fields, setting the appropriate restrictions (for example, through a regular expression), we are guaranteed to get rid of such errors. <br><br>  In the case of a single-pass algorithm, we have to completely rely on automation, and set the widest possible image processing settings, since we need to recognize not only these fields, but also the rest of the text, as well as for all possible types of documents, and all for one time.  This is a serious limiting factor, which the developers are trying to compensate with more clever rules of post-processing and verification of results, a more efficient manual verification process, etc.  All this, of course, is also important, but if there is an opportunity to significantly reduce the number of errors at once, why not use it? <br><br>  If, in addition to product prices, we are still interested in their nomenclatures, then by connecting the dictionary of available nomenclatures for this supplier, you can also go through these fields too, greatly improving the quality of the data.  But why not connect the dictionary immediately?  But at first, because we don‚Äôt even know the supplier, which means we‚Äôll have to connect all the dictionaries of all the suppliers at once, and this can only worsen the result. <br><br>  By the way, in this dispute, the processing time argument is usually given, as an explanation of why they do not use the second pass.  But the fact is that just this argument is in favor of two-pass recognition, and here's why.  When re-recognition is processed negligibly small part of the area of ‚Äã‚Äãthe original document, and even a good deal of automation is disabled and transferred to manual mode.  If recognition occurs on the local server, then the time of the additional recognition pass is vanishingly short compared with the time of the first pass.  However, in the two-pass scenario, the first pass is used only for extracting the reference text and classification, which are tolerant to recognition errors due to the use of fuzzy comparison algorithms.  The text itself does not go directly to the results, which means that instead of a thorough recognition mode, you can use the fast one, thereby reducing the time by two or more times. <br><br>  In the case of recognition in the cloud, indeed, we will have to make two calls to the server instead of one.  But even in this case, the argument about the possibility of achieving higher quality remains in force. <br><br>  Original article in English <a href="http://blog.ocrsdk.com/field-level-ocr-what-is-it-for/">on the SDK team blog</a> . <br><br>  <i>Andrei Isaev</i> <i><br></i>  <i>director of product development for developers.</i> </div><p>Source: <a href="https://habr.com/ru/post/173571/">https://habr.com/ru/post/173571/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../173557/index.html">HTC Butterfly - beauty at your fingertips</a></li>
<li><a href="../173561/index.html">Runetology (190): Peter Kutis, founder of OneTwoTrip.com</a></li>
<li><a href="../173563/index.html">NASA is organizing the second Space Apps Challenge</a></li>
<li><a href="../173567/index.html">Space Retreat from Flurry</a></li>
<li><a href="../173569/index.html">New security measure for Payoneer cards</a></li>
<li><a href="../173573/index.html">Curiosity is back to active mode.</a></li>
<li><a href="../173575/index.html">Google expands Google Fiber service</a></li>
<li><a href="../173579/index.html">KFC + Imagine Cup = another opportunity to reach the world final</a></li>
<li><a href="../173581/index.html">In Russia, a man was first convicted for Xbox 360 firmware, and then acquitted!</a></li>
<li><a href="../173587/index.html">Graphene and molybdenite based memory</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>