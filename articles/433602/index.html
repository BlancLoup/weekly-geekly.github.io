<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The basis of the rate of evolution may be mathematical simplicity.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Computer scientists are turning to evolutionary biology for inspiration to find optimal solutions in sets of astronomical dimensions 

 Studying the v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The basis of the rate of evolution may be mathematical simplicity.</h1><div class="post__text post__text-html js-mediator-article"><h3>  Computer scientists are turning to evolutionary biology for inspiration to find optimal solutions in sets of astronomical dimensions </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/b3d/603/c84/b3d603c8417f5eb149d538b00ed370a9.jpg"><br>  <i>Studying the vast spaces of possible solutions to the problem, we are faced with the fact that most of the paths will be dead-end.</i>  <i>But evolution may have found ways to increase the chances of success.</i> <br><br>  Creationists love to insist that evolution would have to collect up to 300 amino acids in the correct order, only to create a single human medium-sized protein.  And since each of the positions could contain one of the 20 possible amino acids, it would seem that there are more than <sup>20,300</sup> variants of enumeration, which is many orders of magnitude greater than the number of atoms in the observable Universe.  Even if we find redundancy, due to which some of these options are equivalent, the likelihood that evolution stumbled upon the right combination by chance, conducting random mutations, seems monstrously small, even with billions of years gone by. <br><a name="habracut"></a><br>  The main disadvantage of such arguments is that evolution did not experience these sequences by accident: the process of natural selection eliminated the unnecessary.  In addition, it is likely that nature has found other workarounds, ways to narrow a huge number of probabilities to small, research-able subsets that are more likely to give useful solutions. <br><br>  Informatics specialists have similar problems, which include the search for optimal solutions among the many options of astronomical size.  Some of them are turning to biology for inspiration - despite the fact that biologists themselves are only trying to understand how nature works this way. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Genetic algorithms, optimization methods that have been popular for several decades, use the principles of natural selection to create new designs (for robots, drugs and transport systems, among other things), to train neural networks or to encrypt and decrypt data.  This technology begins with the fact that random solutions to a problem are regarded as certain ‚Äúorganisms‚Äù possessing certain characteristics, or elements, ‚Äúgenetically‚Äù given in their code.  These solutions are not particularly good, but then they undergo various random mutations (and sometimes other changes that replicate the gene shuffling process) and give out the second generation of organisms, which in turn are tested for suitability in solving the problem.  In the end, after many repetitions, this process leads to the appearance of an extremely well adapted individual, or solution. <br><br>  Some experts bring this method to the next level by doing genetic programming in order to get programs that can write programs and produce effective solutions (here, ‚Äúgenes‚Äù can be lines of code).  This goal turned out to be particularly difficult to achieve, since researchers have to take into account certain types of data and structures, as well as many other conditions. <br><br>  Interestingly, these ways of thinking based on evolution (especially genetic programming) conceptually overlap with mathematical theory, which has always been somewhere on the periphery of both biology and computer science.  Recently, some scientists are trying to use it to understand how evolution, natural and artificial, can work efficiently, create something new and learn to learn.  The main thing here was a special concept of complexity, randomness and information, which had no practical applications - until today. <br><br><h2>  Monkeys behind keyboards </h2><br>  This theory, invented in the 1960s, works with what is called algorithmic information.  It builds on the intuitive way of thinking about probability and complexity: the idea that for some input data from a computational point of view, it will be easier to describe how to create something than to create it.  Take the well-known analogy of a monkey, shuffling keys randomly.  The chances of it printing the first 15,000 digits of œÄ are ridiculously small ‚Äî and they decrease exponentially with the number of digits. <br><br>  But if you interpret keystrokes as random text for a computer program that outputs the number œÄ, then the chances of success, or the ‚Äúalgorithmic probability,‚Äù are radically improved.  The code for displaying the first 15,000 digits of the number œÄ in C, for example, can be pressed down to just 133 characters. <br><br>  In other words, the <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2582%25D0%25B5%25D0%25BE%25D1%2580%25D0%25B8%25D1%258F_%25D0%25B8%25D0%25BD%25D1%2584%25D0%25BE%25D1%2580%25D0%25BC%25D0%25B0%25D1%2586%25D0%25B8%25D0%25B8">algorithmic theory of information</a> says that the probability of producing some types of output data is much higher when random processes run at the level of the program describing this data than at the level of the data themselves, since the program will be short.  In this sense, complex structures ‚Äî for example, fractals ‚Äî are much easier to obtain by chance. <br><br>  However, a problem soon arose with such an approach: mathematicians found that algorithmic complexity (also known as <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25BB%25D0%25BC%25D0%25BE%25D0%25B3%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2581%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">Kolmogorov complexity</a> , named after <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25BB%25D0%25BC%25D0%25BE%25D0%25B3%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B2,_%25D0%2590%25D0%25BD%25D0%25B4%25D1%2580%25D0%25B5%25D0%25B9_%25D0%259D%25D0%25B8%25D0%25BA%25D0%25BE%25D0%25BB%25D0%25B0%25D0%25B5%25D0%25B2%25D0%25B8%25D1%2587">Andrei Nikolaevich Kolmogorov</a> , one of the founders of the theory) of the given output ‚Äî the shortest possible program length that will produce them ‚Äî cannot be calculated .  Therefore, computer scientists cannot find an ideal way to compress a string or another object. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ff/c3c/f55/5ffc3cf5551876c10f30ac6d5a13e7a7.jpg"><br>  <i>The algorithmic complexity of the network on the left is high, since for its description it is required to list all the edges connecting the vertices.</i>  <i>In the middle, the complexity is less, since in describing this network, we can write down that vertex A is connected to all the others.</i>  <i>The right network has the smallest complexity, since its description is that all vertices are connected by edges in pairs.</i> <br><br>  As a result, the algorithmic theory of information was developed mainly in the field of pure mathematics, where it is used to study related theorems and determine the concepts of randomness and structure.  Its practical use seemed inaccessible.  ‚ÄúMathematically, this is a simple and beautiful measure of complexity,‚Äù said the famous mathematician Gregory Chaytin, one of the founders of the theory, who worked at the Thomas J. Watson IBM Center and the Federal University of Rio de Janeiro.  ‚ÄúBut in terms of applicability in the real world, she looked impregnable.‚Äù <br><br>  But this did not make him retreat.  He hoped that this theory could be used to formalize the idea that DNA behaves like a program.  In 2012, he published a book where he described how evolution can be presented as a random walk through the program space.  Mutations along this path, he wrote, do not obey the statistically random probability distribution;  they obey a distribution based on Kolmogorov complexity.  But he could not verify it. <br><br>  Now, some scientists hope to revive this theory in this context, and to link it simultaneously with both biology and computer science. <br><br><h2>  Pursuit of simplicity </h2><br>  <a href="https://www.hectorzenil.net/">Hector Zenil</a> , a computer scientist from the Karolinska Institute in Sweden, is one of those who are trying to revive this theory.  He works with other researchers to use Kolmogorov complexity as a metric for analyzing the complexity of biological networks - for example, gene regulatory networks or the interaction of proteins in cells.  The researchers roughly estimate the algorithmic content of the network (the exact value is not computable), then conduct a network mutation and check how much it affected Kolmogorov complexity.  They hope that this method will give them an idea of ‚Äã‚Äãthe relative importance of the various elements of the network, and of its functional response to intentional changes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e3c/09e/cd7/e3c09ecd79b17d996b4857f711a79703.jpg"><br>  <i>Famous mathematician Gregory Chitin, one of the founders of algorithmic information theory</i> <br><br>  In a recent <a href="https://arxiv.org/abs/1709.05429">paper</a> laid out on arxiv.org, they described that if you force the network to move towards an increase in Kolmogorov complexity ‚Äî by introducing mutations that cause the program describing the network to become larger ‚Äî this usually leads to an increase in the number of functions that it can perform network, while making it more sensitive to disturbances.  When they made the network simpler, the functions became smaller, and the stability increased. <br><br>  However, it remains unclear whether the Kolmogorov complexity can play any greater role than a simple tool ‚Äî for example, as Chitin believes, to be the main driver of change.  Despite all the problems, algorithmic information seems an attractive theory for biology.  Traditionally, mathematics has been used to describe evolutionary dynamics in the field of <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D0%25BE%25D0%25BF%25D1%2583%25D0%25BB%25D1%258F%25D1%2586%25D0%25B8%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25B3%25D0%25B5%25D0%25BD%25D0%25B5%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0">population genetics</a> ‚Äî statistical models that describe the frequency of occurrence of genes in a population.  However, population genetics has its limitations: it does not describe the origin of life and other basic biological transition processes, or the appearance of completely new genes.  ‚ÄúIn this beautiful mathematical theory, the idea of ‚Äã‚Äãbiological creativity was somehow lost,‚Äù said Chitin.  But if we take into account algorithmic information, he said, "then creativity is naturally embedded in the overall picture." <br><br>  Like the idea that the evolutionary process improves over time and increases efficiency.  ‚ÄúI‚Äôm convinced that evolution is learning,‚Äù said <a href="http://homepages.herts.ac.uk/~comqdp1/">Daniel Polanyi</a> , a computer scientist and professor of artificial intelligence from the University of Hertfordshire in England.  ‚ÄúI would not be surprised if this can be expressed through the asymptotic reduction of algorithmic complexity.‚Äù <br><br>  Zenil and the team decided to experimentally test the biological and computational consequences of the influence of the platform of algorithmic complexity.  Using the same technique of approximate assessment of complexity, which they used to analyze and perturb networks, they carried out an ‚Äúevolution‚Äù of artificial genetic networks towards certain targets ‚Äî matrices of zeros and ones, indicating gene interactions ‚Äî making a choice in favor of mutations that produced matrices with less algorithmic complexity.  In other words, they made the selection in favor of larger structures. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58d/d2b/8a6/58dd2b8a6edff8df2316750a4f63eeb8.jpg"><br>  <i>Hector Zenil, computer science specialist from the Karolinska Institute</i> <br><br>  They recently published results in the journal Royal Society Open Science, from which it follows that, compared with statistically random mutations, their selection of mutations led to a significant acceleration of the development of networks towards solutions.  Other features appeared, for example, permanent and regular structures - sections of matrices that have already reached a certain degree of simplicity, which new generations could hardly have improved.  ‚ÄúSome regions were more or less mutated simply because they had already reached a certain level of simplicity,‚Äù said Zenil.  ‚ÄúIt was very similar to genes.‚Äù  This genetic memory helped larger structures to emerge faster - researchers believe that this implies that algorithmically probable mutations can lead to outbreaks of diversity and extinction. <br><br>  "This means," said Zenil, "that it will be quite fruitful to consider computational processes when studying evolution."  He hopes to use this understanding of chance and complexity to identify pathways of exchange that may be more susceptible to mutations, or to understand why certain gene interactions can be associated with diseases such as cancer. <br><br><h2>  Evolution of programs </h2><br>  Zenil hopes to understand whether biological evolution works by the same computational rules, but most experts have doubts.  It is not clear which natural mechanism could be responsible for a rough estimate of the algorithmic complexity or make mutations develop purposefully.  Moreover, ‚Äúto assume that life is fully encoded in four letters will be wrong,‚Äù said <a href="https://www.di.ens.fr/users/longo/">Giuseppe Longo</a> , a mathematician from the National Center for Scientific Research in France.  "DNA is extremely important, but it does not make sense outside the cell, the organism, the ecosystem."  Other interactions work, and the use of algorithmic information cannot cover all this complexity. <br><br>  And yet this concept has generated a certain interest - in particular, because such views on evolution and computational processes have something in common, at least a common theme, with the goal of genetic programming - to get a program that can evolve. <br><br>  There were already quite intriguing hints of a potential connection between the ideas of Chaytin and Zenil, associated with Kolmogorov complexity and methods of genetic programming.  For example, in 2001, a team of researchers <a href="https://link.springer.com/chapter/10.1007/3-540-45355-5_28">reported</a> that the complexity of the outputs of the genetic program is limited by the Kolmogorov complexity of the original program. <br><br>  But for the most part, Kolmogorov complexity did not play a role in the attempts of computer scientists to understand these ideas.  They tried other ways to change genetics and mutations.  Some groups changed the rate of mutations, others forced the system to lean toward mutations that replaced large chunks of code.  ‚ÄúPeople came up with dozens, and possibly hundreds of different versions of mutations and genotypes,‚Äù said <a href="http://faculty.hampshire.edu/lspector/">Lee Spector</a> , an information technology specialist from Hampshire College in Massachusetts.  Spector recently led a team that <a href="https://dl.acm.org/citation.cfm%3Fid%3D3205603%26dl%3DACM%26coll%3DDL">demonstrated the advantages of</a> adding and removing mutations across the entire genome of an organism before directly replacing one gene with another.  This new type of genetic operator exponentially increased the number of paths in the genetic search space and eventually led to better solutions. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd7/c52/baa/cd7c52baa648f9bcdf077589680947c4.jpg"><br>  <i>Lee Spector, a computer science specialist from Hampshire College in Massachusetts</i> <br><br>  However, many researchers have gone in the opposite direction, in search of ingenious ways to speed up the process, narrowing the field of search, but not limiting it so much that the search would miss the optimal results.  One idea was to make simplicity a goal: in the 1960s, Eugene Wigner noted "the unreasonable efficiency of mathematics in the natural sciences," and computer scientists found that often simpler and more elegant models are more effective and more often applicable.  ‚ÄúThe question is,‚Äù Spector said, ‚Äúdoes this fact tell us something deep about the structure of the universe, or not?‚Äù  And will it be useful to us? " <br><br>  He also warns that attempts to push evolving programs to simplicity can be destructive: rewarding programs for brevity can lead to cuts in what seems like garbage now, but it can be useful to future generations, which will result in sacrificing optimal solutions.  ‚ÄúAnd we will get stuck,‚Äù he said. <br><br>  However, simplicity remains a seductive goal, which, moreover, has demonstrated its usefulness.  In a paper published last year, Spector and his colleagues found that if programs were reduced in size ‚Äî sometimes by only 25% of the original length ‚Äî after applying genetic programming techniques, programs coped better with new data and could be used on a wider range of common data. problems. <br><br>  In particular, because of this, he is following the work in the field of algorithmic information theory, although he says that there is still to be seen its impact on this area of ‚Äã‚Äãresearch. <br><br><h2>  We learn from life </h2><br>  The Zenil team may have taken the first step in the search for this influence - however, in order to realistically apply their work, they first need to test their method on other types of search problems. <br><br>  And yet, ‚Äúthey convincingly showed the need for constraints based on structure,‚Äù said <a href="https://www.wisc.edu/directories/person.php%3Fname%3DLARISSA%2BALBANTAKIS">Larisa Albantakis</a> , a neuroscientist-theorist from the University of Wisconsin, who also worked to accelerate genetic algorithms by limiting search space.  "Nature is structured, and if we take this as a starting point, it would be foolish to try to check all possible homogeneous mutations."  She added: "Everything that makes sense to us is somehow structured." <br><br>  And while Spector is skeptical about the fact that Zenil's work can be applied to something beyond the solution of a specific problem that he studied, ‚Äúthe information theory underlying their concepts is intriguing and potentially very important,‚Äù he said.  - It seems interesting to me partly because it looks like something alien.  Perhaps there are ideas that comrades from our community are unaware of. ‚Äù  After all, algorithmic information is related to a large assortment of ideas that some genetic programming experts may not include in their work, for example, the unlimited nature of evolution. <br><br>  ‚ÄúI have a strong sense of having something important in this area,‚Äù Spector said.  However, he added, so far "there is a great distance between their work and practical applications." <br><br>  ‚ÄúThe idea of ‚Äã‚Äãimagining life as an evolving program is very fruitful,‚Äù said Chitin, although it is too early to determine its value.  Whether we reason about artificial, or about biological life, ‚Äúwe must see how far we can go.‚Äù </div><p>Source: <a href="https://habr.com/ru/post/433602/">https://habr.com/ru/post/433602/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../433586/index.html">How we didn't win the hackathon</a></li>
<li><a href="../433588/index.html">The amazing performance of parallel C ++ 17 algorithms. Myth or Reality?</a></li>
<li><a href="../433592/index.html">Background: Yandex. Phone</a></li>
<li><a href="../433596/index.html">Magellan error: Buffer overrun or world expedition using SQLite FTS</a></li>
<li><a href="../433600/index.html">Phone Pixel 3 is learning to determine the depth in photos</a></li>
<li><a href="../433604/index.html">Comfortable work with Android Studio</a></li>
<li><a href="../433606/index.html">SIEM depths: out-of-box correlations. Part 3.2. Event Normalization Methodology</a></li>
<li><a href="../433608/index.html">Car of the future. Screens instead of autoglass?</a></li>
<li><a href="../433610/index.html">Notes phytochemist. Persimmon</a></li>
<li><a href="../433612/index.html">FCC: SpaceX satellites in orbit - a source of debris dangerous to Earth‚Äôs inhabitants</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>