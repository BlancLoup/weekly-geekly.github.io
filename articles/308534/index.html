<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>R and Spark</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Spark , an Apache project designed for cluster computing, is a fast and versatile data processing environment, including machine learning. Spark also ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>R and Spark</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/56f/740/9cc/56f7409cc7c64deca38fde935fd45313.png" alt="image" align="left">  <i>Spark</i> , an <i>Apache</i> project designed for cluster computing, is a fast and versatile data processing environment, including machine learning.  <i>Spark</i> also has an <i>API</i> for <i>R</i> ( <i>SparkR</i> package), which is included in the <i>Spark</i> distribution itself.  But, in addition to working with this <i>API</i> , there are two more alternative ways to work with <i>Spark</i> in <i>R.</i>  So we have three different ways to interact with the Spark cluster.  This post provides an overview of the main features of each of the methods, and using one of the options, we will build the simplest model of machine learning on a small amount of text files (3.5 GB, 14 million lines) on the <i>Spark</i> cluster deployed in <i>Azure HDInsight</i> . <br><a name="habracut"></a><br><h3>  Spark Interaction Overview </h3><br>  In addition to the official <i>SparkR</i> package, the capabilities in machine learning of which are weak (in version 1.6.2 there is only one model, in version 2.0.0 there are four of them), there are two more options for access to <i>Spark</i> . <br><br>  The first option is to use a product from <i>Microsoft - Microsoft R Server for Hadoop</i> , which has recently integrated support for <i>Spark</i> .  Using this product, you can perform calculations for the same R functions, in the context of local calculations, <i>Hadoop</i> ( <i>map-reduce</i> ) or <i>Spark</i> .  In addition to the local installation of R and access to the <i>Spark</i> cluster, the <i>Microsoft Azure HDInsight</i> cloud service allows <i>you</i> to deploy ready-made clusters, and, in addition to the usual <i>Spark</i> cluster, you can also deploy the <i>R Server on Spark</i> cluster.  This service is a <i>Spark</i> cluster with a pre-installed <i>R server for Hadoop</i> on an additional, border node that allows you to immediately perform calculations, both locally on this server, and switch to the <i>Spark</i> or <i>Hadoop</i> context.  The use of this product is quite well described in the official documentation for <i>HDInsight</i> on the <i>Microsoft</i> website. <br><br>  The second option is to use the new <i>sparklyr</i> package, which is still under development.  This product is developed under the auspices of <i>RStudio</i> - the company, under the wing of which some of the most useful and necessary packages are <i>released</i> - <i>knitr, ggplot2, tidyr, lubridate, dplyr</i> and others, so this package can become another leader.  So far this package is poorly documented, since it has not yet been officially released. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Based on the documentation and experiments with each of these methods of working with <i>Spark</i> , I prepared the following table (Table 1) with generalized functionality of each of the methods (also added <i>SparkR 2.0.0</i> , in which there were a <i>few</i> more features). <br><br><img src="https://habrastorage.org/files/735/945/918/735945918d48474890743a5f6bf4fe71.png" alt="image"><br>  <i>Table 1. Overview of the possibilities of different ways to interact with <i>Spark</i></i> <br><br>  As can be seen from the table, there are no tools that fully realize the necessary needs out of the box, but the <i>sparklyr</i> package <i>compares</i> favorably with <i>SparkR</i> and <i>R Server</i> .  Its main advantages are reading <i>csv</i> , <i>json</i> , <i>parquet</i> files from <i>hdfs</i> .  Fully <i>dplyr-</i> compatible data manipulation syntax ‚Äî including filtering, column selection, aggregation functions, data merging capabilities, column name modification, and more.  Unlike <i>SparkR</i> or <i>R server for Hadoop</i> , where some of these tasks are either not performed or are very inconvenient (in <i>R server for Hadoop,</i> data merging for objects does not exist at all, it is supported only for the xdf embedded data type).  Another advantage of the package is the ability to write functions for running <i>Java</i> methods directly from R code. <br><br>  <b>Example</b> <br><br><pre><code class="python hljs">count_lines &lt;- function(sc, file) { spark_context(sc) %&gt;% invoke(<span class="hljs-string"><span class="hljs-string">"textFile"</span></span>, file, <span class="hljs-number"><span class="hljs-number">1L</span></span>) %&gt;% invoke(<span class="hljs-string"><span class="hljs-string">"count"</span></span>) } count_lines(sc, <span class="hljs-string"><span class="hljs-string">"/text.csv"</span></span>)</code> </pre> <br>  Because of this, you can implement the missing functionality of the package using the existing <i>java</i> methods in <i>Spark</i> or by implementing them yourself. <br><br>  And, of course, the number of machine learning models is much larger than that of <i>SparkR</i> (even in version 2.0) and <i>R server for Hadoop</i> .  Therefore, we will opt for this package as the most promising and convenient to use.  The <i>Spark</i> cluster was deployed using the <i>Azure HDInsight</i> cloud service offering deployment of 5 cluster types ( <i>HBase</i> , <i>Storm</i> , <i>Hadoop</i> , <i>Spark</i> , <i>R Server on Spark</i> ), in different configurations with minimal effort. <br><br><h3>  Resources used </h3><br><ul><li>  <i>HDInsight Apache Spark 1.6</i> cluster on <i>Linux</i> (cluster deployment is described in detail in the Microsoft Azure documentation) </li><li>  R 3.3.2 installed on the head node </li><li>  RStudio preview edition (additional features for sparklyr), also installed on the head node </li><li>  <i>Putty</i> client to establish a session with the cluster head node and tunnel the <i>RStudio</i> port to the local host port (setting up <i>RStudio</i> and its tunneling is described in the <i>Microsoft Azure</i> documentation) </li></ul><br><h3>  Environment setup </h3><br>  First we deploy the <i>Spark</i> cluster - I chose a configuration with 2 head nodes D12v2 and 4 work nodes D12v2.  (D12v2: 4 cores / 28 GB of RAM, 200 GB disk, this configuration is not entirely optimal, but it is suitable for demonstration of the syntax <i>sparklyr</i> ).  Description of the deployment of different types of cluster and work with them is described in the documentation on <a href="https://azure.microsoft.com/en-us/documentation/services/hdinsight/"><i>HDInsight</i></a> .  After successfully deploying the cluster, using an SSH connection to the working node, install R and RStudio there, with the necessary dependencies.  RStudio it is advisable to use the preview editions, since it has additional features for the sparklyr package - an additional window that displays the original data frames in Spark, and the ability to view their properties or themselves.  After installing R, R Studio, we re-establish the connection using tunneling to <i>localhost: 8787</i> . <br><br>  So, now in the browser at <i>localhost: 8787</i> we connect to RStudio and continue to work. <br><br><h3>  Data preparation </h3><br>  <i>All the code for this task is given at the end of this post.</i> <br><br>  For this test task, we will use the <i>NYC Taxi</i> dataset <i>csv</i> files located at <a href="http://www.andresmh.com/nyctaxitrips/">NYC Taxi Trips</a> .  The data is information about taxi rides and their payment.  For familiarization purposes, we limit ourselves to one month.  Building a model on the same complete dataset, but using <i>R Server for Hadoop</i> (in the context of <i>Hadoop</i> ), is described in the following article: <a href="https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/MicrosoftR/Samples/NYCTaxi/NYC2013_MRS_LinearBinary.html">Exploring NYC Taxi Data with Microsoft R Server and HDInsight</a> .  But there the reading of files, all the preprocessing - filtering the data, merging the tables was done in <i>Hive</i> , and in the R Server they only built the model, here everything is done on a regular R using <i>sparklyr</i> . <br><br>  <i>Having</i> moved both files to the <i>hdfs of the</i> <i>Spark</i> cluster, and using the <i>sparklyr</i> function, we read these files. <br><br><h3>  Data manipulation </h3><br>  Files for trips and tariffs are linked by key - the columns " <i>medallion</i> ", " <i>hack_licence</i> " and " <i>pickup_datetime</i> ", so we will perform the attachment on the left to the <i>data</i> frame, <i>data</i> frame <i>fare</i> .  After combining data and manipulations, we save the data frame in parquet format.  Before building a model, we will look at the data, for this we will create a sample of 2000 random observations and pass them to R using collect.  On this small sample, a standard <i>ggplot2</i> diagram was <i>constructed</i> (the tip depends on the fare, indicating the size of the point ‚Äî the distance of the route and the color of the point by the number of passengers, and divided into a grid by type of payment and taxi operator) (Fig. 1). <br><br><img src="https://habrastorage.org/files/083/aa0/259/083aa0259dd64f54ade9244869216ba3.png" alt="image"><br>  <i>Figure 1 Chart showing the main dependencies</i> <br><br>  It shows that there is a dependence (linear, as ‚Äústandard‚Äù% of the bill) of the tip size on the fare, most of the payments are made using a credit card (CRD panel) and cash (CSH panel), and that when paying cash in tips They are absent (this is probably due to the fact that when paying in cash, tips are already included in the cost of payment, and when paying with a card there is no).  Therefore, in the sample for training we leave only those trips that were paid by credit card.  Using the convenient <i>dplyr</i> syntax and magrittr <i>Piping</i> , we <i>merge the</i> combined <i>dataframe</i> further along the chain: subsequent selection of rows (excluding outliers and illogical values) and columns (leaving only those necessary for building the model), passing the final dataset to the linear regression function.  To train the model, we use 70% of all data, for the test the remaining 30%.  For this problem we use simple linear regression.  The dependency we want to detect is the size of the tip on the parameters of the trip.  The model on these data is quite degenerate and not quite correct (there are a large number of tips equal to 0), but it is simple, it will show the interpretable coefficients of the model and will allow you to demonstrate the basic features of <i>sparklyr</i> .  We will use the following predictors in the model: <i>vendor_id</i> is the identifier of the taxi operator, <i>passenger_count</i> is the number of passengers, <i>trip_time_in_secs</i> is the trip time, <i>trip_distance</i> is the trip distance, <i>payment_type</i> is the type of payment, <i>fare_amount</i> is the price of the trip, <i>surcharg</i> e is the charge.  As a result of training, the model has the following form: <br><br><pre> <code class="python hljs">Call: ml_linear_regression(., response = <span class="hljs-string"><span class="hljs-string">"tip_amount"</span></span>, features = c(<span class="hljs-string"><span class="hljs-string">"vendor_id"</span></span>, <span class="hljs-string"><span class="hljs-string">"passenger_count"</span></span>, <span class="hljs-string"><span class="hljs-string">"trip_time_in_secs"</span></span>, <span class="hljs-string"><span class="hljs-string">"trip_distance"</span></span>, <span class="hljs-string"><span class="hljs-string">"fare_amount"</span></span>, <span class="hljs-string"><span class="hljs-string">"surcharge"</span></span>)) Deviance Residuals: (approximate): Min <span class="hljs-number"><span class="hljs-number">1</span></span>Q Median <span class="hljs-number"><span class="hljs-number">3</span></span>Q Max <span class="hljs-number"><span class="hljs-number">-27.55253</span></span> <span class="hljs-number"><span class="hljs-number">-0.33134</span></span> <span class="hljs-number"><span class="hljs-number">0.09786</span></span> <span class="hljs-number"><span class="hljs-number">0.34497</span></span> <span class="hljs-number"><span class="hljs-number">31.35546</span></span> Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) <span class="hljs-number"><span class="hljs-number">3.2743e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.4119e-03</span></span> <span class="hljs-number"><span class="hljs-number">231.9043</span></span> &lt; <span class="hljs-number"><span class="hljs-number">2e-16</span></span> *** vendor_id_VTS <span class="hljs-number"><span class="hljs-number">-1.0557e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.1408e-03</span></span> <span class="hljs-number"><span class="hljs-number">-92.5423</span></span> &lt; <span class="hljs-number"><span class="hljs-number">2e-16</span></span> *** passenger_count <span class="hljs-number"><span class="hljs-number">-1.0542e-03</span></span> <span class="hljs-number"><span class="hljs-number">4.1838e-04</span></span> <span class="hljs-number"><span class="hljs-number">-2.5197</span></span> <span class="hljs-number"><span class="hljs-number">0.01175</span></span> * trip_time_in_secs <span class="hljs-number"><span class="hljs-number">1.3197e-04</span></span> <span class="hljs-number"><span class="hljs-number">2.0299e-06</span></span> <span class="hljs-number"><span class="hljs-number">65.0140</span></span> &lt; <span class="hljs-number"><span class="hljs-number">2e-16</span></span> *** trip_distance <span class="hljs-number"><span class="hljs-number">1.0787e-01</span></span> <span class="hljs-number"><span class="hljs-number">4.7152e-04</span></span> <span class="hljs-number"><span class="hljs-number">228.7767</span></span> &lt; <span class="hljs-number"><span class="hljs-number">2e-16</span></span> *** fare_amount <span class="hljs-number"><span class="hljs-number">1.3266e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.9204e-04</span></span> <span class="hljs-number"><span class="hljs-number">690.7842</span></span> &lt; <span class="hljs-number"><span class="hljs-number">2e-16</span></span> *** surcharge <span class="hljs-number"><span class="hljs-number">1.4067e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.4705e-03</span></span> <span class="hljs-number"><span class="hljs-number">95.6605</span></span> &lt; <span class="hljs-number"><span class="hljs-number">2e-16</span></span> *** --- Signif. codes: <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-string"><span class="hljs-string">'***'</span></span> <span class="hljs-number"><span class="hljs-number">0.001</span></span> <span class="hljs-string"><span class="hljs-string">'**'</span></span> <span class="hljs-number"><span class="hljs-number">0.01</span></span> <span class="hljs-string"><span class="hljs-string">'*'</span></span> <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-string"><span class="hljs-string">'.'</span></span> <span class="hljs-number"><span class="hljs-number">0.1</span></span> <span class="hljs-string"><span class="hljs-string">' '</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> R-Squared: <span class="hljs-number"><span class="hljs-number">0.6456</span></span> Root Mean Squared Error: <span class="hljs-number"><span class="hljs-number">1.249</span></span></code> </pre> <br>  Using this model, we predict the values ‚Äã‚Äãon the test sample. <br><br><h3>  findings </h3><br>  This article presents the main functionalities of the three ways of interacting with <i>Spark</i> in R and provides an example that implements reading files, their preprocessing, manipulating them and building a simple machine learning model using the <i>sparklyr</i> package. <br><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">devtools::install_github(<span class="hljs-string"><span class="hljs-string">"rstudio/sparklyr"</span></span>) library(sparklyr) library(dplyr) spark_disconnect_all() sc &lt;- spark_connect(master = <span class="hljs-string"><span class="hljs-string">"yarn-client"</span></span>) data_tbl&lt;-spark_read_csv(sc, <span class="hljs-string"><span class="hljs-string">"data"</span></span>, <span class="hljs-string"><span class="hljs-string">"taxi/data"</span></span>) fare_tbl&lt;-spark_read_csv(sc, <span class="hljs-string"><span class="hljs-string">"fare"</span></span>, <span class="hljs-string"><span class="hljs-string">"taxi/fare"</span></span>) fare_tbl &lt;- rename(fare_tbl, medallionF = medallion, hack_licenseF = hack_license, pickup_datetimeF=pickup_datetime) taxi.join&lt;-data_tbl %&gt;% left_join(fare_tbl, by = c(<span class="hljs-string"><span class="hljs-string">"medallion"</span></span>=<span class="hljs-string"><span class="hljs-string">"medallionF"</span></span>, <span class="hljs-string"><span class="hljs-string">"hack_license"</span></span>=<span class="hljs-string"><span class="hljs-string">"hack_licenseF"</span></span>, <span class="hljs-string"><span class="hljs-string">"pickup_datetime"</span></span>=<span class="hljs-string"><span class="hljs-string">"pickup_datetimeF"</span></span>, )) taxi.filtered &lt;- taxi.join %&gt;% filter(passenger_count &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> , passenger_count &lt; <span class="hljs-number"><span class="hljs-number">8</span></span> , trip_distance &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> , trip_distance &lt;= <span class="hljs-number"><span class="hljs-number">100</span></span> , trip_time_in_secs &gt; <span class="hljs-number"><span class="hljs-number">10</span></span> , trip_time_in_secs &lt;= <span class="hljs-number"><span class="hljs-number">7200</span></span> , tip_amount &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span> , tip_amount &lt;= <span class="hljs-number"><span class="hljs-number">40</span></span> , fare_amount &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> , fare_amount &lt;= <span class="hljs-number"><span class="hljs-number">200</span></span>, payment_type==<span class="hljs-string"><span class="hljs-string">"CRD"</span></span> ) %&gt;% select(vendor_id,passenger_count,trip_time_in_secs,trip_distance, fare_amount,surcharge,tip_amount)%&gt;% sdf_partition(training = <span class="hljs-number"><span class="hljs-number">0.7</span></span>, test = <span class="hljs-number"><span class="hljs-number">0.3</span></span>, seed = <span class="hljs-number"><span class="hljs-number">1234</span></span>) spark_write_parquet(taxi.filtered$training, <span class="hljs-string"><span class="hljs-string">"taxi/parquetTrain"</span></span>) spark_write_parquet(taxi.filtered$test, <span class="hljs-string"><span class="hljs-string">"taxi/parquetTest"</span></span>) for_plot&lt;-sample_n(taxi.filtered$training,<span class="hljs-number"><span class="hljs-number">1000</span></span>)%&gt;%collect() ggplot(data=for_plot, aes(x=fare_amount, y=tip_amount, color=passenger_count, size=trip_distance))+ geom_point()+facet_grid(vendor_id~payment_type) model.lm &lt;- taxi.filtered$training %&gt;% ml_linear_regression(response = <span class="hljs-string"><span class="hljs-string">"tip_amount"</span></span>, features = c(<span class="hljs-string"><span class="hljs-string">"vendor_id"</span></span>, <span class="hljs-string"><span class="hljs-string">"passenger_count"</span></span>, <span class="hljs-string"><span class="hljs-string">"trip_time_in_secs"</span></span>, <span class="hljs-string"><span class="hljs-string">"trip_distance"</span></span>, <span class="hljs-string"><span class="hljs-string">"fare_amount"</span></span>, <span class="hljs-string"><span class="hljs-string">"surcharge"</span></span>)) print(model.lm) summary(model.lm) predicted &lt;- predict(model.lm, newdata = taxi.filtered$test) actual &lt;- (taxi.filtered$test %&gt;% select(tip_amount) %&gt;% collect())$tip_amount data &lt;- data.frame(predicted = predicted,actual = actual)</code> </pre><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/308534/">https://habr.com/ru/post/308534/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../308520/index.html">Checking MSBuild source code with PVS-Studio</a></li>
<li><a href="../308522/index.html">What Google is silent on and why you should use Apache HttpComponents in Android</a></li>
<li><a href="../308526/index.html">Math on the fingers: let's count at least one row of Fourier in the mind</a></li>
<li><a href="../308528/index.html">About Legacy code without maximalism: what to do</a></li>
<li><a href="../308532/index.html">Selection of programming podcasts in Russian and English</a></li>
<li><a href="../308536/index.html">Announcement of the conference Linux Piter 2016 - the second international Linux conference in Russia</a></li>
<li><a href="../308538/index.html">Crosswalk Project - replacement of Android WebView. Project development</a></li>
<li><a href="../308540/index.html">Serena releases version 11.1 of its BPM platform.</a></li>
<li><a href="../308546/index.html">Creator of the World Wide Web Tim Berners-Lee changed the world, but he himself remained the same</a></li>
<li><a href="../308548/index.html">Reverse engineering test crackme from Kaspersky Lab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>