<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Small code for big data or Apache Spark in 3 days</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Let the Giraffe was wrong 
 But the Giraffe is not guilty, 
 And the one who shouted from the branches: 
 "Big giraffe - he knows better!" (C) 

 It t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Small code for big data or Apache Spark in 3 days</h1><div class="post__text post__text-html js-mediator-article">  <i>Let the Giraffe was wrong</i> <i><br></i>  <i>But the Giraffe is not guilty,</i> <i><br></i>  <i>And the one who shouted from the branches:</i> <i><br></i>  <i>"Big giraffe - he knows better!" (C)</i> <br><br>  It took to quickly deal with <a href="http://spark.apache.org/">Apache Spark</a> technology sharpened to use Big Data.  In the process of finding out, I actively used habrahabr, so I‚Äôll try to return the information debt by sharing my experience. <br><br>  Namely: installing the system from scratch, setting up and actually programming the code that solves the data processing task to create a model that calculates the probability of bank bankruptcy for a set of features such as loan amount, rate, etc. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It seems like there should be a lot of big data, but for some reason it‚Äôs not easy to find that hot spot where they all feel.  At first I tried the <a href="http://ihorbobak.com/index.php/2015/05/06/installing-hadoop-using-ambari-server">ambari option</a> , but on my Window7, errors occurred on the settings for the network bridge.  As a result, I rolled the option with a pre-configured virtual machine from Cloudera ( <a href="http://www.cloudera.com/downloads/quickstart_vms/5-8.html">CDH</a> ).  Simply install VirtualBox, launch the downloaded file, specify the main parameters (memory, location) and after 5 minutes the honorable <a href="http://hadoop.apache.org/">Apache Hadoop</a> <s>gin is</s> eager for your instructions. <br><br>  A few words why Spark.  As far as I understand, the key differences from the original MapReduce are that the data is kept in memory, instead of being flushed to disk, which gives acceleration many times over.  But perhaps more important are the implementation of a number of statistical functions and a convenient interface for loading / processing data. <br><br>  Next, the actual code for the next task.  There is really big data (for the hand is very tired to scroll these 2000 lines) in the format: <br><br><img src="https://habrastorage.org/files/f7e/f1c/7cf/f7ef1c7cf2b64f928f3db61c85091e44.png"><br><br>  There is an assumption that the default is somehow connected with the other parameters (except for the first one, there are no complaints about the respected Ivanov1 ... N) and it is necessary to build a linear regression model.  Before you begin, it‚Äôs worth mentioning that this is my first Java code, I myself work as an analyst and in general this is my first launch of Eclipse, setting up Maven, etc.  So one should not wait for exquisite miracles, lower the solution of the problem head on in the way that for some reason has earned.  Go: <br><a name="habracut"></a><br>  1. Create a Spark session.  The important point is that it all works only with version 2.0.0, whereas in the CDH delivery comes v1.6.  So you need to make an upgrade, otherwise there will be an exception at startup. <br><br><pre><code class="java hljs">SparkSession ss = SparkSession .builder() .appName(<span class="hljs-string"><span class="hljs-string">"Bankrupticy analyser"</span></span>) .getOrCreate();</code> </pre> <br>  2. Load data into a special type of JavaRDD.  In fact, this is about how List in C #, at least I explained it to myself this way.  The library can read a lot of things, but for a start, a regular csv file will come down. <br><br><pre> <code class="java hljs">JavaRDD&lt;Client&gt; peopleRDD = ss.read() .textFile(filename) .javaRDD() .map(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Function&lt;String, Client&gt;() { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Client </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String line)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ String[] parts = line.split(<span class="hljs-string"><span class="hljs-string">","</span></span>); <span class="hljs-comment"><span class="hljs-comment">//  Client client = new Client(); client.setName(parts[0]); //   (   ) client.setYearOfBirth(Double.parseDouble(parts[1])); client.setAmount(Double.parseDouble(parts[2])); client.setTerm(Double.parseDouble(parts[3])); client.setRate(Double.parseDouble(parts[4])); client.setPaid(Double.parseDouble(parts[5])); client.setStatus(Double.parseDouble(parts[6])); //    (1 - , 0 ‚Äì   ) return client; } });</span></span></code> </pre> <br>  Where Client is a normal class with our attributes (can be found in the project file, following the link at the end of the post). <br><br>  3. Create a dataset that is required for data normalization.  Without normalization, the calculation of the linear regression model by the method of gradient descent does not roll.  At first I tried to fasten StandardScalerModel: fit -&gt; transform but I had problems with data types, it seems because of the difference in versions.  In general, for the time being it has managed a workaround, namely through a select to the data, performing normalization right in it: <br><br><pre> <code class="java hljs">Dataset&lt;Row&gt; clientDF = ss.createDataFrame(peopleRDD, Client.class); clientDF.createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"client"</span></span>); Dataset&lt;Row&gt; scaledData = ss.sql( <span class="hljs-string"><span class="hljs-string">"SELECT name, (minYearOfBirth - yearOfBirth) / (minYearOfBirth - maxYearOfBirth),"</span></span> + <span class="hljs-string"><span class="hljs-string">"(minAmount - amount) / (minAmount - maxAmount),"</span></span> + <span class="hljs-string"><span class="hljs-string">"(minTerm - term) / (minTerm - maxTerm),"</span></span> + <span class="hljs-string"><span class="hljs-string">"(minRate - rate) / (minRate - maxRate),"</span></span> + <span class="hljs-string"><span class="hljs-string">"(minPaid - paid) / (minPaid - maxPaid),"</span></span> + <span class="hljs-string"><span class="hljs-string">"(minStatus - status) / (minStatus - maxStatus) "</span></span> + <span class="hljs-string"><span class="hljs-string">"FROM client CROSS JOIN "</span></span> + <span class="hljs-string"><span class="hljs-string">"(SELECT min(yearOfBirth) AS minYearOfBirth, max(yearOfBirth) AS maxYearOfBirth,"</span></span> + <span class="hljs-string"><span class="hljs-string">"min(amount) AS minAmount, max(amount) AS maxAmount,"</span></span> + <span class="hljs-string"><span class="hljs-string">"min(term) AS minTerm , max(term) AS maxTerm,"</span></span> + <span class="hljs-string"><span class="hljs-string">"min(rate) AS minRate, max(rate) AS maxRate,"</span></span> + <span class="hljs-string"><span class="hljs-string">"min(paid) AS minPaid, max(paid) AS maxPaid,"</span></span> + <span class="hljs-string"><span class="hljs-string">"min(status) AS minStatus, max(status) AS maxStatus "</span></span> + <span class="hljs-string"><span class="hljs-string">"FROM client)"</span></span>).cache();</code> </pre> <br>  4. The model accepts data in the format of JavaRDD in which we stuff the name of the client.  This is the norm for a beautiful display of the test version, in life of course you should not do that, although in general this may be necessary for other purposes. <br><br><pre> <code class="java hljs">JavaRDD&lt;Row&gt; rowData = scaledData.javaRDD(); <span class="hljs-comment"><span class="hljs-comment">// Dataset to JavaRDD JavaRDD&lt;Tuple2&lt;String,LabeledPoint&gt;&gt; parsedData = rowData.map( new Function&lt;Row, Tuple2&lt;String,LabeledPoint&gt;&gt;() { public Tuple2&lt;String,LabeledPoint&gt; call(Row row) { int last = row.length(); String cname = row.getString(0); //   -  double label = row.getDouble(last - 1); //  ‚Äì   double[] v = new double[last]; for (int i = 1; i &lt; last - 1; i++) //    v[i] = row.getDouble(i); v[last - 1] = 1; // +intercept return new Tuple2&lt;String, LabeledPoint&gt; (cname, new LabeledPoint(label, Vectors.dense(v))); } });</span></span></code> </pre> <br>  5. Select the LabeledPoint data for the model: <br><br><pre> <code class="java hljs">JavaRDD&lt;LabeledPoint&gt; parsedDataToTrain = parsedData.map( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Function&lt;Tuple2&lt;String,LabeledPoint&gt;, LabeledPoint&gt;() { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> LabeledPoint </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Tuple2&lt;String,LabeledPoint&gt; namedTuple)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> namedTuple._2(); <span class="hljs-comment"><span class="hljs-comment">// 2      &lt;String,LabeledPoint&gt; } }); parsedData.cache();</span></span></code> </pre> <br>  6. Create the model itself: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> numIterations = <span class="hljs-number"><span class="hljs-number">200</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> stepSize = <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> LinearRegressionModel model = LinearRegressionWithSGD.train(JavaRDD.toRDD(parsedDataToTrain), numIterations, stepSize);</code> </pre> <br>  7. And actually the main work + result: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">final</span></span> NumberFormat nf = NumberFormat.getInstance(); <span class="hljs-comment"><span class="hljs-comment">//     nf.setMaximumFractionDigits(2); JavaRDD&lt;Tuple2&lt;Double, Double&gt;&gt; valuesAndPreds = parsedData.map( new Function&lt;Tuple2&lt;String,LabeledPoint&gt;, Tuple2&lt;Double, Double&gt;&gt;() { public Tuple2&lt;Double, Double&gt; call(Tuple2&lt;String,LabeledPoint&gt; namedTuple) { double prediction = model.predict(namedTuple._2().features()); //         System.out.println(namedTuple._1() + " got the score " + nf.format(prediction) + ". The real status is " + nf.format(namedTuple._2().label())); return new Tuple2&lt;Double, Double&gt;(prediction, namedTuple._2().label()); } });</span></span></code> </pre><br>  8. And we calculate the average squared error (from paragraph 7): <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> MSE = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaDoubleRDD(valuesAndPreds.map( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Function&lt;Tuple2&lt;Double, Double&gt;, Object&gt;() { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Object </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Tuple2&lt;Double, Double&gt; pair)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Math.pow(pair._1() - pair._2(), <span class="hljs-number"><span class="hljs-number">2.0</span></span>); } }).rdd()).mean();</code> </pre><br>  In this case, the output will look like this: <br><br>  Ivanov1983 got the score 0.57.  The real status is 1 <br>  Ivanov1984 got the score 0.54.  The real status is 1 <br>  Ivanov1985 got the score -0.08.  The real status is 0 <br>  Ivanov1986 got the score 0.33.  The real status is 1 <br>  Ivanov1987 got the score 0.78.  The real status is 1 <br>  Ivanov1988 got the score 0.63.  The real status is 1 <br>  Ivanov1989 got the score 0.63.  The real status is 1 <br>  Ivanov1990 got the score 0.03.  The real status is 0 <br>  Ivanov1991 got the score 0.57.  The real status is 1 <br>  Ivanov1992 got the score 0.26.  The real status is 0 <br>  Ivanov1993 got the score 0.07.  The real status is 0 <br>  Ivanov1994 got the score 0.17.  The real status is 0 <br>  Ivanov1995 got the score 0.83.  The real status is 1 <br>  Ivanov1996 got the score 0.31.  The real status is 0 <br>  Ivanov1997 got the score 0.48.  The real status is 0 <br>  Ivanov1998 got the score 0.16.  The real status is 0 <br>  Ivanov1999 got the score 0.36.  The real status is 0 <br>  Ivanov2000 got the score -0.04.  The real status is 0 <br>  16/11/21 21:36:40 INFO Executor: Finished task 0.0 in stage 176.0 (TID 176).  3194 bytes result sent to driver <br>  16/11/21 21:36:40 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 176) in 432 ms on localhost (1/1) <br>  16/11/21 21:36:40 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have completed, from pool <br>  16/11/21 21:36:40 INFO DAGScheduler: ResultStage 176 (mean at App.java:242) finished in 0.433 s <br>  16/11/21 21:36:40 INFO DAGScheduler: Job 175 finished: mean at App.java:242, took 0.452851 s <br>  Training Error = 0.11655428630639536 <br><br>  Now it makes sense to compare it with the analytical solution in Excel: <br><br><img src="https://habrastorage.org/files/4fb/252/702/4fb252702dee4c4a93bf27db2359189c.png"><br><br>  As you can see, the result is very close, the model turned out to be suitable, you can set it on a test sample.  The project code with source data can be downloaded <a href="https://drive.google.com/open%3Fid%3D0ByybUCqM917jSzJMZmd6emstRlE">here</a> . <br><br>  In general, I would like to note that the excitement around big data seems to be quite excessive (much like this).  It seems to me that the more valuable is not the volume, but how exactly to process this data.  Those.  any combination of TF-IDF - neural network - ALS can give an amazing result if it is possible to creatively work on a limited volume.  The problem is probably that managers can beat budgets for the Big Data magic words, and spending resources on research objectives requires a too long-term planning horizon for an ordinary company. <br><br>  To understand this thought, I will clarify that the zoo of the Hadoop ecosystem (Hive, Pig, Impala, etc.) is gorgeous.  I myself have been developing a distributed computing system on neural networks (simultaneous execution of multi-threaded applications on multiple servers with synchronization and aggregation of results) for macroeconomic modeling and I understand approximately how much rake lies on this path.  Yes, there are tasks where there are no alternatives to these technologies - for example, primitive, but streaming online processing of wild data volumes (conditionally speaking, some analysis of the traffic of cellular subscribers in Moscow).  Here <a href="http://storm.apache.org/">Apache Storm</a> or Spark Streaming can create a miracle. <br><br>  But if we have an array of data on a million customers per year, then sampling every 10th (or even 100th) randomly to build a model of some scoring will give almost the same result as the full array.  In other words, instead of the queen of the ball, Data mining has become a stepdaughter, although this is most likely temporary.  The excitement will subside, but the experimental approaches that are now being tested on Hadoop clusters will spread and those who are first aware of the prospects for exploring the ‚Äúsmall‚Äù data will be in the queues. </div><p>Source: <a href="https://habr.com/ru/post/316088/">https://habr.com/ru/post/316088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../316074/index.html">How the telematic service Smartdriving.io was created - 100% Russian technological startup</a></li>
<li><a href="../316076/index.html">Paul Graham's Strategic Essay: Refraction (Part 1)</a></li>
<li><a href="../316080/index.html">UltraVDS: Black Friday with 60% discount</a></li>
<li><a href="../316082/index.html">Development for Sailfish OS: timers and implementation of export to a file using the example of an application for maintaining a to-do list</a></li>
<li><a href="../316086/index.html">Creating and testing a firewall in Linux, Part 2.1. Introduction to the second part. We look at the network and protocols. Wireshark</a></li>
<li><a href="../316090/index.html">Riot.js 3.0 released</a></li>
<li><a href="../316092/index.html">As we came up with and made our first game on Android. Part 2: Levels</a></li>
<li><a href="../316094/index.html">What discounts are hosters on this Black Friday</a></li>
<li><a href="../316098/index.html">Inside NetBeans. Prologue</a></li>
<li><a href="../316100/index.html">Connecting the character LCD to the board from WD MyBook Live on AppliedMicro APM82181. Ending</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>