<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>(Without) painful NGINX Ingress</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="So, you have a Kubernetes cluster, and to forward external traffic to services within the cluster, you have already configured the NGINX Ingress Contr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>(Without) painful NGINX Ingress</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/59/de/04/59de04a16da90950930050.jpeg"><br><br><p>  So, you have a <a href="https://kubernetes.io/">Kubernetes</a> cluster, and to forward external traffic to services within the cluster, you have already configured the <a href="https://github.com/kubernetes/ingress/tree/master/controllers/nginx">NGINX Ingress Controller</a> , well, or for now you are going to do it.  Great! </p><br><p> I also went through this, and at first everything looked very simple: the installed NGINX Ingress controller was at a distance of one <code>helm install</code> .  And then it only remained to tie the DNS to the load balancer and create the necessary <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">Ingress resources</a> . </p><br><p>  After a few months, all external traffic for all environments (dev, staging, production) was sent through the Ingress servers.  And everything was fine.  And then it became bad. </p><br><p>  We all know very well how it happens: first you are interested in this new wonderful thing, you start to use it, and then the trouble begins. </p><a name="habracut"></a><br><h2 id="moy-pervyy-sboy-v-ingress">  My first Ingress crash </h2><br><p>  First, let me warn you: if you are not yet concerned about <a href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html">accept queue overflows</a> , start worrying. </p><br><img src="https://habrastorage.org/webt/59/de/09/59de0900460bf970639567.png"><br><p>  <em>Do not forget about the queues</em> </p><br><p>  What happened was that the application behind NGINX began to respond with long delays, which in turn led to the filling of the <a href="http_core_module.html">NGINX listen backlog</a> .  Because of this, NGINX began to drop connections, including those that tried to install Kubernetes to test the service‚Äôs performance ( <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/">liveness / readiness probes</a> ). </p><br><p>  And what happens when the under does not respond to such requests?  Kubernetes thinks something went wrong and restarts it.  The problem is that this is one of those situations where the restart of the hearth only aggravates the situation: the reception queue continues to overflow, Kubernetes continues to restart the hearth, and eventually draws them into the whirlpool of falls and subsequent restarts. </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a035a16942000232.png"><br><p>  <em>TCP listen queue overflow according netstat</em> </p><br><p>  What lessons can be learned from this situation? </p><br><ul><li>  Examine your NGINX configuration to the last letter.  Find out what should be there and what should not.  Do not blindly trust the default settings. </li><li>  Most Linux distributions out of the box are not configured to work as high-load web servers.  Recheck the appropriate kernel parameters with <code>sysctl -a</code> . </li><li>  Measure the delay of your services and set the appropriate timeouts based on the expected maximum value + margin for small deviations. </li><li>  Customize your applications so that in the event of an overload they begin to reject requests or gently reduce the load.  For example, in NodeJS applications, <a href="https://medium.com/springworks-engineering/node-js-profiling-event-loop-lag-flame-charts-539e04723e84">increasing delays</a> in a message loop may mean that the server is already struggling to handle the current traffic. </li><li>  Use more than one NGINX Ingress Controller. </li></ul><br><h3 id="vazhnost-monitoringa">  The importance of monitoring </h3><br><p>  My advice number 0: <code></code> run a production Kubernetes cluster (or something similar) without setting up quality monitoring of its work.  Monitoring itself will not relieve problems from problems, but collected telemetry makes it much easier to find the root causes of failures, which makes it possible to correct them in the process of further work. </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a0731d6817610377.jpeg"><br><p>  <em>Some useful metrics from `node <em>netstat`</em></em> * </p><br><p>  If you have succumbed to the <a href="https://prometheus.io/">Prometheus</a> craze, you can use <a href="https://github.com/prometheus/node_exporter">node_exporter</a> to collect node-level metrics.  This is a handy tool that allows you to identify including the problems just described. </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a08b167860645462.jpeg"><br><p>  <em>Some metrics derived from the NGINX Ingress Controller</em> </p><br><p>  The NGINX Ingress controller is able to generate metrics for Prometheus itself.  Do not forget to adjust their collection. </p><br><h2 id="znay-svoy-konfig">  Know your config </h2><br><p>  The beauty of the Ingress Controller is that you can rely on this wonderful program to generate and reload the proxy configuration and not worry about it anymore.  You don't even have to be familiar with the underlying technology (NGINX in this case).  True?  <strong>Not!</strong> </p><br><p>  If you have not done this yet, be sure to look at the configuration generated for you.  For the NGINX Ingress Controller, you can get the contents of <code>/etc/nginx/nginx.conf</code> using <code>kubectl</code> . </p><br><pre> <code class="hljs pgsql">$ kubectl -n &lt;namespace&gt; exec &lt;nginx-ingress-controller-pod-<span class="hljs-type"><span class="hljs-type">name</span></span>&gt; <span class="hljs-comment"><span class="hljs-comment">-- cat /etc/nginx/nginx.conf &gt; ./nginx.conf</span></span></code> </pre> <br><pre> <code class="nginx hljs"><span class="hljs-comment"><span class="hljs-comment"># $ cat ./nginx.conf daemon off; worker_processes auto; pid /run/nginx.pid; worker_rlimit_nofile 1047552; worker_shutdown_timeout 10s ; events { multi_accept on; worker_connections 16384; use epoll; } http { real_ip_header X-Forwarded-For; # ... } # ...</span></span></code> </pre> <br><p>  Now try to find something incompatible with your installation.  Want an example?  Let's start with <code>worker_processes auto</code> ; </p><br><blockquote>  The optimal value depends on many factors, including (but not limited to) the number of processor cores, the number of hard drives with data and the load pattern.  If you have difficulty in choosing the right value, you can start by setting it equal to the number of processor cores (the value ‚Äúauto‚Äù tries to determine it automatically). </blockquote><p>  First problem: at the moment (will it ever be fixed?) NGINX knows nothing about <a href="https://ru.wikipedia.org/wiki/Cgroups">cgroups</a> , which means that in the case of <code>auto</code> , the value of the number of <code>  CPU</code> host <code>  CPU</code> and not the number of ‚Äúvirtual‚Äù processors as defined in <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">Kubernetes will be used resource requests / limits</a> . </p><br><p>  Let's do an experiment.  What happens if we try to load the following NGINX configuration file on a dual-core server in a container limited to only one CPU?  How many workflows will be running? </p><br><pre> <code class="nginx hljs"><span class="hljs-comment"><span class="hljs-comment"># $ cat ./minimal-nginx.conf worker_processes auto; events { worker_connections 1024; } http { server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } } }</span></span></code> </pre> <br><pre> <code class="bash hljs">$ docker run --rm --cpus=<span class="hljs-string"><span class="hljs-string">"1"</span></span> -v `<span class="hljs-built_in"><span class="hljs-built_in">pwd</span></span>`/minimal-nginx.conf:/etc/nginx/nginx.conf:ro -d nginx fc7d98c412a9b90a217388a094de4c4810241be62c4f7501e59cc1c968434d4c $ docker <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> fc7 ps -ef | grep nginx root 1 0 0 21:49 pts/0 00:00:00 nginx: master process nginx -g daemon off; nginx 6 1 0 21:49 pts/0 00:00:00 nginx: worker process nginx 7 1 0 21:49 pts/0 00:00:00 nginx: worker process</code> </pre> <br><p>  Thus, if you plan to limit the processor resources that are available to NGINX Ingress, you should not allow nginx to create a large number of workflows in one container.  It is best to explicitly indicate their required number using the <code>worker_processes</code> directive. </p><br><p>  Now consider the <code>listen</code> directive.  The value of the <code>backlog</code> parameter is not explicitly indicated and the default for Linux is <code>511</code> .  If the kernel parameter <code>net.core.somaxconn</code> is equal to, say, <code>1024</code> , then the <code>backlog</code> must be assigned the appropriate value.  In other words, make sure that the nginx configuration is configured according to the kernel parameters. </p><br><p>  But do not stop there.  Such an exercise is necessary for each line of the generated configuration file.  Just look at <a href="">all the parameters</a> that allows you to change the Ingress-controller.  Correct without hesitation everything that is not suitable for your case.  Most NGINX parameters can be <a href="">configured</a> using <code>ConfigMap</code> records and / or annotations. </p><br><h3 id="parametry-yadra">  Kernel options </h3><br><p>  With or without Ingress, always check and tune the parameters of the nodes according to the expected load. </p><br><p>  This is a rather complicated topic, so I do not plan to disclose it in detail here.  Additional materials on this issue can be found in the <a href="http://danielfm.me/posts/painless-nginx-ingress.html">Links</a> section. </p><br><h4 id="kube-proxy-tablica-conntrack">  Kube-Proxy: Conntrack Table </h4><br><p>  Those who use Kubernetes, I think, do not need to explain what the <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Services are</a> and what they are for.  However, it will be useful to consider some features of their work. </p><br><blockquote>  In each node of the Kubernetes cluster, kube-proxy is executed, which is responsible for implementing virtual IP for <strong>Services of a</strong> type other than <strong>ExternalName</strong> .  In Kubernetes v1.0, proxies were run exclusively in user space.  An iptables proxy was added to Kubernetes v1.1, however this was not the default mode.  Starting with Kubernetes v1.2, iptables-proxy is used by default. </blockquote><p>  In other words, packets sent to IP services are sent (directly or through a balancer) to the appropriate <code>Endpoint</code> ( <code>address:port</code> pairs of pods that correspond to the service's <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">selector label</a> ) using iptables rules, controlled by <a href="https://kubernetes.io/docs/admin/kube-proxy/">kube-proxy</a> .  Connections to service IP addresses are tracked by the kernel using the <code>nf_conntrack</code> module, and this information is stored in RAM. </p><br><p>  Since the various conntrack parameters must be consistent with each other (for example, <code>nf_conntrack_maxw</code> and <code>nf_conntrack_buckets</code> ), kube-proxy, when starting a job, sets reasonable default values. </p><br><pre> <code class="bash hljs">$ kubectl -n kube-system logs &lt;some-kube-proxy-pod&gt; I0829 22:23:43.455969 1 server.go:478] Using iptables Proxier. I0829 22:23:43.473356 1 server.go:513] Tearing down userspace rules. I0829 22:23:43.498529 1 conntrack.go:98] Set sysctl <span class="hljs-string"><span class="hljs-string">'net/netfilter/nf_conntrack_max'</span></span> to 524288 I0829 22:23:43.498696 1 conntrack.go:52] Setting nf_conntrack_max to 524288 I0829 22:23:43.499167 1 conntrack.go:83] Setting conntrack hashsize to 131072 I0829 22:23:43.503607 1 conntrack.go:98] Set sysctl <span class="hljs-string"><span class="hljs-string">'net/netfilter/nf_conntrack_tcp_timeout_established'</span></span> to 86400 I0829 22:23:43.503718 1 conntrack.go:98] Set sysctl <span class="hljs-string"><span class="hljs-string">'net/netfilter/nf_conntrack_tcp_timeout_close_wait'</span></span> to 3600 I0829 22:23:43.504052 1 config.go:102] Starting endpoints config controller ...</code> </pre> <br><p>  This is a good option, but you may need to <a href="https://kubernetes.io/docs/admin/kube-proxy/">increase the values ‚Äã‚Äãof these parameters</a> if monitoring shows that you are running out of space allocated for conntrack.  However, it must be remembered that <a href="https://kubernetes.io/docs/admin/kube-proxy/">an increase in the values ‚Äã‚Äãof these parameters</a> leads to an increased memory consumption, so it is more careful there. </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a0aade1753639945.jpeg"><br><p>  <em>Conntrack usage monitoring</em> </p><br><h2 id="delitsya-ne-znachit-zabotitsya">  Sharing (not) is taking care </h2><br><p>  Until recently, we had only one instance of NGINX Ingress, responsible for proxying requests to all applications in all environments (dev, staging, production).  I learned from my own experience that this is a bad idea.  <strong>Do not put all your eggs in one basket.</strong> </p><br><p>  I think the same can be said about the use of one cluster for all environments, however, we found that this approach leads to more efficient use of resources.  We ran the dev / staging pods at the QoS level with non-guaranteed delivery (best-effort QoS tier), thus using the resources left from production-based applications. </p><br><p>  The flip side of the coin here is that we find ourselves limited in the actions that can be performed in relation to the cluster.  For example, if we need to conduct load testing of a staging service, we will have to be very careful not to affect the combat services running in the same cluster. </p><br><p>  Although containers generally provide a good level of isolation, they still <a href="https://sysdig.com/blog/container-isolation-gone-wrong/">depend on shared kernel resources</a> that are subject to abuse. </p><br><h3 id="odna-ustanovka-ingress-na-kazhdoe-okruzhenie">  One setting of Ingress per environment </h3><br><p>  We have already said that there is no reason why you should not use one Ingress-controller for each environment.  This gives an extra level of protection in case problems start to happen with services in dev and / or staging. </p><br><p>  Some advantages of this approach are: </p><br><ul><li>  It is possible to use different settings for different environments. </li><li>  Allows you to test Ingress updates before applying them in production. </li><li>  You can avoid inflating the NGINX configuration with records of many upstream servers and services associated with ephemeral and / or unstable environments. </li><li>  Configuration reloads are accelerating and the number of these events is reduced throughout the day (we will later discuss why we should strive to minimize the number of reloads). </li></ul><br><h4 id="ingress-klassy-v-pomosch">  Ingress classes to help </h4><br><p>  One way to force different <code>ingress</code> controllers to manage different Ingress resources is to use different <strong>ingress class names</strong> for each ingress installation, and then annotate <code>Ingress</code> resources to specify who should manage whom. </p><br><pre> <code class="hljs scala"># <span class="hljs-type"><span class="hljs-type">Ingress</span></span> controller <span class="hljs-number"><span class="hljs-number">1</span></span> apiVersion: extensions/v1beta1 kind: <span class="hljs-type"><span class="hljs-type">Deployment</span></span> spec: template: spec: containers: - args: - /nginx-ingress-controller - --ingress-<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">=class-1</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">-</span></span></span><span class="hljs-class"> ... </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">#</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Ingress</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">controller</span></span></span><span class="hljs-class"> 2 </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">apiVersion</span></span></span></span>: extensions/v1beta1 kind: <span class="hljs-type"><span class="hljs-type">Deployment</span></span> spec: template: spec: containers: - args: - /nginx-ingress-controller - --ingress-<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">=class-2</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">-</span></span></span><span class="hljs-class"> ... </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">#</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">This</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Ingress</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">resource</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">will</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">be</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">managed</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">by</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">controller</span></span></span><span class="hljs-class"> 1 </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">apiVersion</span></span></span></span>: extensions/v1beta1 kind: <span class="hljs-type"><span class="hljs-type">Ingress</span></span> metadata: annotations: kubernetes.io/ingress.<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>: <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">-1</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">spec</span></span></span></span>: rules: ... # <span class="hljs-type"><span class="hljs-type">This</span></span> <span class="hljs-type"><span class="hljs-type">Ingress</span></span> resource will be managed by controller <span class="hljs-number"><span class="hljs-number">2</span></span> apiVersion: extensions/v1beta1 kind: <span class="hljs-type"><span class="hljs-type">Ingress</span></span> metadata: annotations: kubernetes.io/ingress.<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>: <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">-2</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">spec</span></span></span></span>: rules: ...</code> </pre> <br><h2 id="problemy-s-perezagruzkami-ingress">  Ingress reload issues </h2><br><p>  At this point, we had a dedicated ingress controller running for the production environment.  Everything was fine until we decided to transfer one WebSocket application to Kubernetes + ingress. </p><br><p>  Soon, I noticed a strange tendency in the use of memory production ingress. </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a0c13d9063958010.png"><br><p>  <em>What the hell is going on here ?!</em> </p><br><p>  Why is memory usage so high?  With the help of <code>kubectl exec</code> I went into one of the ingress containers and found a group of workflows that hung in <code>shutting down</code> status. </p><br><pre> <code class="bash hljs">root 17755 17739 0 19:47 ? 00:00:00 /usr/bin/dumb-init /nginx-ingress-controller --default-backend-service=kube-system/broken-bronco-nginx-ingress-be --configmap=kube-system/broken-bronco-nginx-ingress-conf --ingress-class=nginx-ingress-prd root 17765 17755 0 19:47 ? 00:00:08 /nginx-ingress-controller --default-backend-service=kube-system/broken-bronco-nginx-ingress-be --configmap=kube-system/broken-bronco-nginx-ingress-conf --ingress-class=nginx-ingress-prd root 17776 17765 0 19:47 ? 00:00:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf nobody 18866 17776 0 19:49 ? 00:00:05 nginx: worker process is shutting down nobody 19466 17776 0 19:51 ? 00:00:01 nginx: worker process is shutting down nobody 19698 17776 0 19:51 ? 00:00:05 nginx: worker process is shutting down nobody 20331 17776 0 19:53 ? 00:00:05 nginx: worker process is shutting down nobody 20947 17776 0 19:54 ? 00:00:03 nginx: worker process is shutting down nobody 21390 17776 1 19:55 ? 00:00:05 nginx: worker process is shutting down nobody 22139 17776 0 19:57 ? 00:00:00 nginx: worker process is shutting down nobody 22251 17776 0 19:57 ? 00:00:01 nginx: worker process is shutting down nobody 22510 17776 0 19:58 ? 00:00:01 nginx: worker process is shutting down nobody 22759 17776 0 19:58 ? 00:00:01 nginx: worker process is shutting down nobody 23038 17776 1 19:59 ? 00:00:03 nginx: worker process is shutting down nobody 23476 17776 1 20:00 ? 00:00:01 nginx: worker process is shutting down nobody 23738 17776 1 20:00 ? 00:00:01 nginx: worker process is shutting down nobody 24026 17776 2 20:01 ? 00:00:02 nginx: worker process is shutting down nobody 24408 17776 4 20:01 ? 00:00:01 nginx: worker process</code> </pre> <br><p>  To understand what happened, you need to take a step back and take a look at how the configuration reload process is implemented in NGINX. </p><br><blockquote>  Having received the signal, the main process checks the correct syntax of the new configuration file and tries to apply the configuration contained in it.  If he succeeds, the main process starts new workflows and sends messages to old workflows with a request to complete.  Otherwise, the main process rolls back the changes and continues to work with the old configuration.  The old workflows, upon receiving the command to complete, stop accepting new requests and <strong>continue to serve current requests until all such requests are serviced.</strong>  <strong>After this, the old workflow is completed.</strong> </blockquote><p>  Let me remind you that we are proxying WebSocket connections, which by their nature are long-lived.  A WebSocket connection can be maintained for hours, or even days, depending on the application.  The NGINX server does not know whether it is possible to terminate the connection during the reboot, we must facilitate this work.  (For example, you can apply a strategy for forcibly terminating connections that are idle for a certain amount of time, both on the client and on the server. Do not leave such things for later.) </p><br><p>  Let's return to our problem.  If we have so many workflows at the completion stage, then the ingress configuration has rebooted many times, and the workflows could not complete the work due to long-lived connections. </p><br><p>  So it really was.  We found out that the NGINX Ingress-controller periodically generated various configuration files due to changing the order of upstream servers and server IP addresses. </p><br><pre> <code class="diff hljs">I0810 23:14:47.866939 5 nginx.go:300] NGINX configuration diff I0810 23:14:47.866963 5 nginx.go:301] --- /tmp/a072836772 2017-08-10 23:14:47.000000000 +0000 +++ /tmp/b304986035 2017-08-10 23:14:47.000000000 +0000 @@ -163,32 +163,26 @@ proxy_ssl_session_reuse on; - upstream production-app-1-80 { + upstream upstream-default-backend { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.71.14:3000 max_fails=0 fail_timeout=0; - server 10.2.32.22:3000 max_fails=0 fail_timeout=0; + server 10.2.157.13:8080 max_fails=0 fail_timeout=0; } - upstream production-app-2-80 { + upstream production-app-3-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.110.13:3000 max_fails=0 fail_timeout=0; - server 10.2.109.195:3000 max_fails=0 fail_timeout=0; + server 10.2.82.66:3000 max_fails=0 fail_timeout=0; + server 10.2.79.124:3000 max_fails=0 fail_timeout=0; + server 10.2.59.21:3000 max_fails=0 fail_timeout=0; + server 10.2.45.219:3000 max_fails=0 fail_timeout=0; } upstream production-app-4-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.109.177:3000 max_fails=0 fail_timeout=0; server 10.2.12.161:3000 max_fails=0 fail_timeout=0; - } - - upstream production-app-5-80 { - # Load balance algorithm; empty for round robin, which is the default - least_conn; - server 10.2.21.37:9292 max_fails=0 fail_timeout=0; - server 10.2.65.105:9292 max_fails=0 fail_timeout=0; + server 10.2.109.177:3000 max_fails=0 fail_timeout=0; } upstream production-app-6-80 { @@ -201,61 +195,67 @@ upstream production-lap-production-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.45.223:8000 max_fails=0 fail_timeout=0; + server 10.2.21.36:8000 max_fails=0 fail_timeout=0; server 10.2.78.36:8000 max_fails=0 fail_timeout=0; + server 10.2.45.223:8000 max_fails=0 fail_timeout=0; server 10.2.99.151:8000 max_fails=0 fail_timeout=0; - server 10.2.21.36:8000 max_fails=0 fail_timeout=0; } - upstream production-app-7-80{ + upstream production-app-1-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.79.126:3000 max_fails=0 fail_timeout=0; - server 10.2.35.105:3000 max_fails=0 fail_timeout=0; - server 10.2.114.143:3000 max_fails=0 fail_timeout=0; - server 10.2.50.44:3000 max_fails=0 fail_timeout=0; - server 10.2.149.135:3000 max_fails=0 fail_timeout=0; - server 10.2.45.155:3000 max_fails=0 fail_timeout=0; + server 10.2.71.14:3000 max_fails=0 fail_timeout=0; + server 10.2.32.22:3000 max_fails=0 fail_timeout=0; } - upstream production-app-8-80 { + upstream production-app-2-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.53.23:5000 max_fails=0 fail_timeout=0; - server 10.2.110.22:5000 max_fails=0 fail_timeout=0; - server 10.2.35.91:5000 max_fails=0 fail_timeout=0; - server 10.2.45.221:5000 max_fails=0 fail_timeout=0; + server 10.2.110.13:3000 max_fails=0 fail_timeout=0; + server 10.2.109.195:3000 max_fails=0 fail_timeout=0; } - upstream upstream-default-backend { + upstream production-app-9-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.157.13:8080 max_fails=0 fail_timeout=0; + server 10.2.78.26:3000 max_fails=0 fail_timeout=0; + server 10.2.59.22:3000 max_fails=0 fail_timeout=0; + server 10.2.96.249:3000 max_fails=0 fail_timeout=0; + server 10.2.32.21:3000 max_fails=0 fail_timeout=0; + server 10.2.114.177:3000 max_fails=0 fail_timeout=0; + server 10.2.83.20:3000 max_fails=0 fail_timeout=0; + server 10.2.118.111:3000 max_fails=0 fail_timeout=0; + server 10.2.26.23:3000 max_fails=0 fail_timeout=0; + server 10.2.35.150:3000 max_fails=0 fail_timeout=0; + server 10.2.79.125:3000 max_fails=0 fail_timeout=0; + server 10.2.157.165:3000 max_fails=0 fail_timeout=0; } - upstream production-app-3-80 { + upstream production-app-5-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.79.124:3000 max_fails=0 fail_timeout=0; - server 10.2.82.66:3000 max_fails=0 fail_timeout=0; - server 10.2.45.219:3000 max_fails=0 fail_timeout=0; - server 10.2.59.21:3000 max_fails=0 fail_timeout=0; + server 10.2.21.37:9292 max_fails=0 fail_timeout=0; + server 10.2.65.105:9292 max_fails=0 fail_timeout=0; } - upstream production-app-9-80 { + upstream production-app-7-80 { # Load balance algorithm; empty for round robin, which is the default least_conn; - server 10.2.96.249:3000 max_fails=0 fail_timeout=0; - server 10.2.157.165:3000 max_fails=0 fail_timeout=0; - server 10.2.114.177:3000 max_fails=0 fail_timeout=0; - server 10.2.118.111:3000 max_fails=0 fail_timeout=0; - server 10.2.79.125:3000 max_fails=0 fail_timeout=0; - server 10.2.78.26:3000 max_fails=0 fail_timeout=0; - server 10.2.59.22:3000 max_fails=0 fail_timeout=0; - server 10.2.35.150:3000 max_fails=0 fail_timeout=0; - server 10.2.32.21:3000 max_fails=0 fail_timeout=0; - server 10.2.83.20:3000 max_fails=0 fail_timeout=0; - server 10.2.26.23:3000 max_fails=0 fail_timeout=0; + server 10.2.114.143:3000 max_fails=0 fail_timeout=0; + server 10.2.79.126:3000 max_fails=0 fail_timeout=0; + server 10.2.45.155:3000 max_fails=0 fail_timeout=0; + server 10.2.35.105:3000 max_fails=0 fail_timeout=0; + server 10.2.50.44:3000 max_fails=0 fail_timeout=0; + server 10.2.149.135:3000 max_fails=0 fail_timeout=0; + } + + upstream production-app-8-80 { + # Load balance algorithm; empty for round robin, which is the default + least_conn; + server 10.2.53.23:5000 max_fails=0 fail_timeout=0; + server 10.2.45.221:5000 max_fails=0 fail_timeout=0; + server 10.2.35.91:5000 max_fails=0 fail_timeout=0; + server 10.2.110.22:5000 max_fails=0 fail_timeout=0; } server {</code> </pre> <br><p>  For this reason, the NGINX Ingress controller rebooted the configuration several times a minute, filling the memory with terminating workflows until it became the victim of the OOM killer. </p><br><p>  After I updated the NGINX Ingress controller for the patched version and indicated the command line parameter <code>--sort-backends=true</code> , things were <code>--sort-backends=true</code> . </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a0ef99e863157834.png"><br><p>  <em>The number of unnecessary reboots after installing the revised version dropped to zero.</em> </p><br><p>  Thank you <a href="https://github.com/aledbf">@aledbf</a> for helping <a href="https://github.com/aledbf">me</a> find and correct this error! </p><br><h3 id="prodolzhaem-minimizirovat-perezagruzki-konfiguracii">  We continue to minimize configuration reloads. </h3><br><p>  It is important to remember that configuration reloads are expensive and should be avoided, especially when working with WebSocket connections.  For this reason, we decided to install a separate Ingress controller specifically for long-lived connections. </p><br><p>      WebSocket-   ,    ,            . </p><br><p>      -  Ingress-,      . </p><br><h4 id="tonkaya-nastroyka-avtomasshtabirovaniya-podov">     </h4><br><p>   NGINX Ingress      IP- ,         Ingress-    .         (autoscaling),    <code>HorizontalPodAutoscalers</code> . </p><br><img src="https://habrastorage.org/webt/59/de/04/59de04a1033d5614416095.png"><br><p> <em>Horizontal pod autoscaler     </em> </p><br><p>   ,     , ‚Äî  ,   horizontal pod autoscaler   ,          . </p><br><pre> <code class="bash hljs">Name: &lt;app&gt; Namespace: production Labels: &lt;none&gt; Annotations: &lt;none&gt; CreationTimestamp: Fri, 23 Jun 2017 11:41:59 -0300 Reference: Deployment/&lt;app&gt; Metrics: ( current / target ) resource cpu on pods (as a percentage of request): 46% (369m) / 60% Min replicas: 8 Max replicas: 20 Conditions: Type Status Reason Message ---- ------ ------ ------- AbleToScale False BackoffBoth the time since the previous scale is still within both the downscale and upscale forbidden windows ScalingActive True ValidMetricFound the HPA was able to succesfully calculate a replica count from cpu resource utilization (percentage of request) ScalingLimited True TooFewReplicas the desired replica count was less than the minimum replica count Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 14d 10m 39 horizontal-pod-autoscaler Normal SuccessfulRescale New size: 10; reason: cpu resource utilization (percentage of request) above target 14d 3m 69 horizontal-pod-autoscaler Normal SuccessfulRescale New size: 8; reason: All metrics below target</code> </pre> <br><p>       <code>--horizontal-pod-autoscaler-upscale-delay</code>  <a href="https://kubernetes.io/docs/admin/kube-controller-manager/">kube-controller-manager</a>        3 . </p><br><p>  ,      <strong></strong>  ,    4  (3   autoscaler +  1    ),   autscaler   ,          . </p><br><h2 id="vashe-mnenie">  Your opinion? </h2><br><p>  - ?  ! </p><br><h2 id="ssylki">  Links </h2><br><ul><li> <a href="https://www.nginx.com/blog/tuning-nginx/">Tuning NGINX for Performance</a> </li><li> <a href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html">How TCP backlog works in Linux</a> </li><li> <a href="https://eklitzke.org/how-tcp-sockets-work">How TCP Sockets Work</a> </li><li> <a href="https://johnleach.co.uk/words/372/netfilter-conntrack-memory-usage">Netfilter Conntrack Memory Usage</a> </li><li> <a href="https://blogs.dropbox.com/tech/2017/09/optimizing-web-servers-for-high-throughput-and-low-latency/">Optimizing web servers for high throuhgput and low latency</a> </li><li> <a href="https://sysdig.com/blog/container-isolation-gone-wrong/">Container isolation gone wrong</a> </li><li> : <a href="http://danielfm.me/posts/painless-nginx-ingress.html">Pain(less) NGINX Ingress</a> . </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/340238/">https://habr.com/ru/post/340238/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../340228/index.html">How to enforce PCI DSS 3.2 requirements</a></li>
<li><a href="../340230/index.html">Serious vulnerability in the popular encryption library undermines the security of millions of crypto keys</a></li>
<li><a href="../340232/index.html">TextView and Spannable: highlighting parts of a word</a></li>
<li><a href="../340234/index.html">Writing a three-dimensional retro shooter engine from scratch</a></li>
<li><a href="../340236/index.html">Analysis of the case of changing the settings for the size of the data block for recording on tape with Veeam Backup & Replication</a></li>
<li><a href="../340242/index.html">Search and fix bugs in PHP source</a></li>
<li><a href="../340246/index.html">PHP page navigation</a></li>
<li><a href="../340248/index.html">Creating distributions for different operating systems in Java 9 and 10</a></li>
<li><a href="../340250/index.html">In simple words: smart contracts, Ethereum, ICO</a></li>
<li><a href="../340252/index.html">China is a digital power. Impressions of Huawei Connect 2017</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>