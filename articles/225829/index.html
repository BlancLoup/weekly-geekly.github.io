<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The method of self-determination of the response time of the LCD monitor screen or TV</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄúWho's stopping us will help us‚Äù 
 k / f "Caucasian Captive" 

 Preamble 
 The response time of the LCD screen is one of the most important characteri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The method of self-determination of the response time of the LCD monitor screen or TV</h1><div class="post__text post__text-html js-mediator-article">  <i>‚ÄúWho's stopping us will help us‚Äù</i> <i><br></i>  <i>k / f "Caucasian Captive"</i> <br><br><h2>  Preamble </h2><br>  <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D1%2580%25D0%25B5%25D0%25BC%25D1%258F_%25D0%25BE%25D1%2582%25D0%25BA%25D0%25BB%25D0%25B8%25D0%25BA%25D0%25B0">The response time of the</a> LCD screen is one of the most important characteristics of the monitor and TV.  It determines how well this monitor is suitable, for example, for computer games or watching videos.  If the response time is too long, then on the screen behind moving high-contrast objects there will be visible artifacts perceived as "ghosts" or "shadows" that interfere with viewing.  But, unlike most other technical specifications, the response time is difficult to measure.  But this could be very useful, for example, when purchasing a new monitor or TV, as well as setting them up. <br><br>  With other technical parameters, everything is more or less clear and obvious.  For example, the screen size, if desired, can be measured with a tape measure or a ruler.  The screen resolution and pixel size can also be ‚Äúfelt‚Äù by looking at the screen at close range.  Many parameters (for example, screen brightness and contrast, black depth, uniformity of light, gradient display, sharpness, viewing angles, gamma and so on) can be checked using special test programs ranging from the simplest utilities like <a href="http://www.ixbt.com/video/testsoft.html">"Nokia Test</a> " to programs for integrated configuration, verification and comparison, for example <a href="http://www.mehanik99.ru/mons/">"LCD Vs_mon</a> ". 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      But, unfortunately, the response time of the LCD screen is so easy to see and "touch" does not work, and it remains to be guided by the values ‚Äã‚Äãspecified by the manufacturer in the passport or advertising leaflet.  But here, too, everything is quite confusing.  There are different notions of response time: GtG (gray to gray, from gray to gray), BtW (black to white, from black to white), BtB or BWB (black-white-black, from black to white and back).  In addition, each manufacturer measures the response time of the monitor using its own method, some of them use Overdrive overclocking technology to reduce response time, and therefore a direct comparison of monitors or TVs of different brands with each other may be incorrect. <br><br>  So I would like to have some kind of tool with which the home (and even better in the store when buying) could be an objective measurement, based on it, to determine how well this TV or monitor is right for you. <br><br>  Is there any way to do this? <br><br>  In principle, of course you can, but ... <a name="habracut"></a><br><br>  Here, for example, is a <a href="http://www.ixbt.com/monitor/methoda/methoda.shtml">brief description of the method for measuring response time</a> adopted at <a href="http://www.ixbt.com/">IXBT.COM</a> : <br><br><blockquote>  <i><b>Theory</b></i> <i><br></i>  <i>The response time for monitors is given in ISO 13406-2.</i>  <i>The response time is the sum of the time required to change the relative brightness of the object from 0.1 to 0.9 (on time) and the time for reverse change (off time).</i>  <i>The relative brightness is defined as the instantaneous difference (at the current time) and the minimum (the monitor is turned on, the video signal corresponding to the black field is supplied to the input) brightness, divided by the maximum difference (the monitor is turned on, the video signal corresponding to the white field is input) and the minimum brightness.</i> <i><br><br><img src="https://habrastorage.org/getpro/habr/post_images/17d/317/dab/17d317dab575e5f186936f9f873936f5.gif" alt="image"><br><br></i>  <i><b>Practice</b></i> <i><br><br></i>  <i>The hardware part of the response time measurement complex consists of a photo sensor that measures the relative brightness on the screen of the monitor under test, and a L-Card E-140 USB ADC (max. 100 kHz, operating at 10 kHz, 14 bits) for digitizing and entering data from the sensor to the computer, as well as the necessary cables ...</i> <i><br><br></i>  <i>The software part of the complex is the GelTreat program, which allows to register and analyze time-response type dependencies modified to obtain response time values.</i> <i><br><br></i>  <i>During the measurements, the GelTreat program launches two processes: the first registers the signal from the sensor, the second, in the DirectDraw mode, displays templates on the screen under test.</i>  <i>Pages in the templates change after 500 ms for 10 seconds ...</i> <i><br><br></i>  <i>On the record we get about 10 pulses.</i>  <i>We process the last 5, where the monitor mode has already been precisely established ... As a result, horizontal red lines appear on the chart, marking 10% and 90% of the maximum response (brightness) ... In total, we define 5 intervals, then we calculate the average on and off times and their sum ...</i> </blockquote>  Can this method be recommended for self-testing? <br><br>  Probably unlikely ... <br><br>  Maybe it can be done somehow simpler, for example, using a regular camera or video camera?  In principle, it is possible, but there are certain difficulties, problems associated both with the principle of image formation on the LCD matrix of a TV or monitor, and with the principles of fixing an image with a camera or video camera. <br><br>  Here we need a little theory. <br><br><h2>  Theory </h2><br>  The image on the <a href="http://ru.wikipedia.org/wiki/%25D0%2596%25D0%25B8%25D0%25B4%25D0%25BA%25D0%25BE%25D0%25BA%25D1%2580%25D0%25B8%25D1%2581%25D1%2582%25D0%25B0%25D0%25BB%25D0%25BB%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B4%25D0%25B8%25D1%2581%25D0%25BF%25D0%25BB%25D0%25B5%25D0%25B9">LCD matrix of a</a> monitor or TV is formed from rows and columns of several million individual points, <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B8%25D0%25BA%25D1%2581%25D0%25B5%25D0%25BB%25D1%258C">pixels</a> , each of which in turn consists of a triad of colored subpixels. <br><br>  For each pixel in accordance with its location, addressing is applied in rows and columns. <br><br>  Information on switching a pixel is transmitted line by line, sequentially to all pixels of each row, and so sequentially row by row for the entire screen.  Then the process starts again, the transfer of the next frame begins.  Typically, in the LCD screens of monitors and televisions during such a cycle, the frame rate is 60 Hertz or more, that is, the frame refresh occurs every 16.7 milliseconds or less. <br><br>  Accordingly, the pixels on the LCD matrix are not switched at a time, but line by line.  Therefore, even within a single frame, at each moment of time, some of the pixels on the screen are already ‚Äúold‚Äù, appeared as much as a few milliseconds ago and already had time to switch and change their brightness, some younger ones are in the process of switching, well, some have just appeared , and only going to switch. <br><br>  Therefore, if we use high-speed shooting to try to fix what is happening on the surface of the whole screen from black to white, then in the photo we will get not a smooth gray tone, but a kind of gradient fill.  Part of the screen has already changed color, and some have not yet. <br><br>  In principle, of course, you can measure in Photoshop the brightness of pixels in different parts of the screenshot, by their position, and also, based on the frame and line frequency, determine the moment of their appearance, and based on this, try to calculate the response time by mathematical calculations, but the solution can hardly be called.  Yes, and such a measurement is unlikely to be.  Well, and for clarity and nothing to say ... <br><br>  And not every camera will allow you to take such a picture. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/272/ac3/306/272ac3306cf9844db6d358a26e5a5472.jpg"><br><br>  And it's not just some special requirements for its speed, but in some features of the shutter and image fixing.  For example, the above picture was taken by an old budget soap box with a central shutter, but in principle it is impossible to make a similar picture even with the most modern ‚ÄúSLR‚Äù with a curtain shutter. <br><br>  Let us dwell on this in more detail. <br><br>  First, a few words about the valves used in photo and video equipment. <br><br><h2>  Photo and video shutters </h2><br>  Of all the variety of construction we will focus on the three most interesting ones for our further consideration. <br><br>  <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25BE%25D1%2582%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9%2520%25D0%25B7%25D0%25B0%25D1%2582%25D0%25B2%25D0%25BE%25D1%2580">The central shutter</a> is located between the lens or right behind the rear lens.  When it is triggered, the entire area of ‚Äã‚Äãthe photosensitive element is displayed immediately.  The shutter speed is controlled by the open time of the shutter.  Such a shutter has a relatively simple design, at any exposure provides a uniform exposure of the entire surface of the photosensitive element, so most of the compact digital cameras are equipped with various versions of such shutters.  But since the central shutter is located inside the lens and makes it difficult to replace it, this design is extremely rare in cameras with interchangeable lenses. <br><br>  <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25BE%25D1%2582%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9%2520%25D0%25B7%25D0%25B0%25D1%2582%25D0%25B2%25D0%25BE%25D1%2580">The shutter</a> is located directly near the film or photosensitive element.  Since the shutter curtains begin to move from one edge to another, the exposure of the frame also occurs sequentially, from edge to edge.  The speed of movement of the shutter curtains is kept strictly constant at any shutter speed, and the shutter speed is controlled by changing the size of the ‚Äúslit‚Äù, the distance between the shutters during their movement (therefore, sometimes such a shutter is called curtain-slit). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a05/6bb/705/a056bb70540487ef35431be5d16bda45.gif" alt="image"><br><br>  Such a shutter is completely open only at shutter speed, more so-called sync shutter speed, X-Sync, which is indicated in the technical characteristics of the camera, and which is used when shooting with a flash.  In this case, we will not shoot anything with the flash, but we still need this parameter. <br><br>  Thus, even if shooting is done with a short flash (for example, 1/1000 seconds), the exposure of the entire frame will take much longer - from 1/30 second in old film mirrors and up to 1/200 second or less in modern digital ones. <br><br>  Such a shutter is structurally much more complicated than the central one, somewhat capricious in operation, problems with uniform illumination may arise, but it allows you to easily replace the lens, and is able to provide very short exposures.  Therefore, the curtain shutter is usually used in <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D0%25B4%25D0%25BD%25D0%25BE%25D0%25BE%25D0%25B1%25D1%258A%25D0%25B5%25D0%25BA%25D1%2582%25D0%25B8%25D0%25B2%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B7%25D0%25B5%25D1%2580%25D0%25BA%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D1%258B%25D0%25B9_%25D1%2584%25D0%25BE%25D1%2582%25D0%25BE%25D0%25B0%25D0%25BF%25D0%25BF%25D0%25B0%25D1%2580%25D0%25B0%25D1%2582">SLR cameras</a> . <br><br>  Finally, the third type of shutter, on which we will stop, is an <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25BE%25D1%2582%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B7%25D0%25B0%25D1%2582%25D0%25B2%25D0%25BE%25D1%2580">electronic shutter</a> .  Strictly speaking, this is not a separate device, but simply the principle of dosing information of the photosensitive matrix.  Directly in the open state, the information on the photosensitive matrix is ‚Äã‚Äãfirst reset, then the matrix is ‚Äã‚Äãexposed during the exposure time, and then the information is read.  Such a shutter is structurally the simplest and, therefore, cheap, and therefore it is often used in the simplest photo and webcams and smartphones, and since it does not have mechanical parts and, consequently, noise and wear, it is often used for video recording with photo and video cameras even with another shutter. <br><br>  The latter type of shutter is most important for our further consideration. <br><br>  Now a few words about the photosensitive matrixes used in photo and video cameras. <br><br><h2>  Photosensitive matrix </h2><br>  Currently, for the shooting are mainly used light-sensitive matrix <a href="http://ru.wikipedia.org/wiki/CCD-%25D0%25BC%25D0%25B0%25D1%2582%25D1%2580%25D0%25B8%25D1%2586%25D0%25B0">CCD</a> and <a href="http://ru.wikipedia.org/wiki/CMOS-%25D0%25BC%25D0%25B0%25D1%2582%25D1%2580%25D0%25B8%25D1%2586%25D0%25B0">CMOS</a> .  Each of these types of matrices has its own characteristics, advantages and disadvantages.  We dwell on only one of the features of each of these matrices, which is important for further understanding. <br><br>  In a modern CCD matrix with column buffering (interline CCD), the captured frame is simultaneously read into a special light-protected frame buffer located in the matrix itself, and then relatively slowly pumped out from there for further processing. <br><br>  In the CMOS matrix, the process of reading cell information occurs line by line, pixel by pixel, drain by line, much like the process of transferring information in the LCD matrix of a monitor or TV, which we discussed above. <br><br>  Some conclusions important for further consideration. <ul><li>  The central shutter in combination with any type of matrix gives a snapshot taken at a single point in time. </li><li>  The curtain shutter in combination with any type of matrix gives a picture, different parts of which were exposed at a slightly different time, determined by the sync delay.  Of course, the time difference is very small, but when shooting fast-moving objects or very fast processes, certain effects may occur.  Usually they are negative (for example, the Rolling Shutter), but sometimes they can also be positive.  But more on that below. </li><li>  The electronic shutter in combination with the CCD matrix gives a picture taken at a single point in time, but the electronic shutter in combination with the CMOS matrix gives a picture, different parts of which were exposed at a slightly different time, as when using the curtain shutter.  Accordingly, the effects of this will be similar to the curtain. <br><img src="https://habrastorage.org/getpro/habr/post_images/5a8/59f/e24/5a859fe24b3e1179942132c14190c000.jpg" alt="image"><br>  Rolling shutter </li></ul><br>  Well, finally, we come to the main issue of the article, and still try to somehow fix, and then somehow measure the response time of the LCD matrix without using a high-speed camera or other special expensive equipment. <br><br><h2>  The author proposes exactly such a very accessible and fairly visual method. </h2><br>  Since the frame change is a very fast process, it would seem that to fix it it would be best to use a camera with a central shutter.  But as we found out, even an ideal camera capable of taking snapshots will not help us; we will need a series of shots taken at a frequency of at least 1000 frames per second.  But we will try to go the other way, and get along with ‚Äúimprovised means‚Äù. <br><br>  Imagine that the screen displays a picture of white and black rectangles that change places at some point in time: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a87/a20/a3b/a87a20a3b423cbe05a8254304e5c5e65.jpg">  -&gt; <img src="https://habrastorage.org/getpro/habr/post_images/1a7/7ad/60a/1a77ad60a8d3206ef93230700f103b1b.jpg"><br><br>  As a result, we will see: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e8b/77d/8ca/e8b77d8cad2ddc735a12a549a6263e7c.gif"><br><br>  On the LCD screen, this happens not instantly, but for a certain period of time.  With a refresh rate of 60 frames per second, this is 16.7 milliseconds. <br><br>  Now imagine that we decided to photograph this process with a camera with a curtain or electronic shutter with a curtain movement from left to right, and in our camera the curtain moves relatively slowly, several times slower than the frame refresh rate on the LCD screen. <br><br>  Consider a chain of events on the screen with the simultaneous imposition of a ‚Äúslot‚Äù position in the camera blind: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a87/a20/a3b/a87a20a3b423cbe05a8254304e5c5e65.jpg">  one) <img src="https://habrastorage.org/getpro/habr/post_images/6d0/034/b9e/6d0034b9e1a1ec082c583975ff76f16a.jpg">  2) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7af/cb2/6f8/7afcb26f8a0dc89ac7d911742a8d7312.jpg">  3) <img src="https://habrastorage.org/getpro/habr/post_images/c38/631/a37/c38631a37cbe006f178101ae0394f734.jpg">  four) <br><br>  Next begins the frame update: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/47c/bee/77f/47cbee77f5679f0ee10452206f52e509.jpg">  five) <img src="https://habrastorage.org/getpro/habr/post_images/655/779/08a/65577908a67b937894365d2d6c53cbe7.jpg">  6) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f38/fa0/979/f38fa0979d46c5453d8f1962eebaa0e4.jpg">  7) <img src="https://habrastorage.org/getpro/habr/post_images/fd0/6d7/92f/fd06d792f69f28d1dbff719668896aa6.jpg">  eight) <br><br>  Frame update ended: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fd0/6d7/92f/fd06d792f69f28d1dbff719668896aa6.jpg">  9) <img src="https://habrastorage.org/getpro/habr/post_images/f26/b5e/9c6/f26b5e9c6b493f5198f6fabfaadee5fe.jpg">  ten <br><br>  And so on ... <br><br>  And now let us remember that in the photo we only recorded what happened, on the screen <b>BEFORE THE MOMENT OF THE PASSAGE ‚Äúgap‚Äù.</b> <br><br>  So: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e51/7f6/562/e517f65626ca1ca8f512f8e348be557c.png"><br><br>  Of course, this is a very simplified picture.  In fact, the screen does not switch instantly, but during the response time (which we just want to determine) <img src="https://habrastorage.org/getpro/habr/post_images/66c/ed6/aa8/66ced6aa815056181cd8f9dc77190403.png">  Yes, and frame scan and movement of the camera curtains are continuous, not steps, and therefore the photo will not be so glamorous. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cda/317/465/cda317465b6a4fb1d54a961aa485dc89.png"><br><br>  Thus, in the photo we had captured the events occurring on the screen at different times during one frame, relatively speaking, a lot of narrow vertical ‚Äúphotos‚Äù taken one after another. <br><br><h2>  So this is exactly what we need! </h2><br>  It remains to understand how to extract the information we need from this. <br>  Suppose that the blind of the camera moves so slowly that during this time on the monitor screen the frame has time to change not two, but three times: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a87/a20/a3b/a87a20a3b423cbe05a8254304e5c5e65.jpg">  -&gt; <img src="https://habrastorage.org/getpro/habr/post_images/1a7/7ad/60a/1a77ad60a8d3206ef93230700f103b1b.jpg">  -&gt; <img src="https://habrastorage.org/getpro/habr/post_images/a87/a20/a3b/a87a20a3b423cbe05a8254304e5c5e65.jpg"><br><br>  In this case, the picture we would have: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad3/b89/000/ad3b89000e08b0fcf2460bf3fcfcc5e2.png"><br><br>  Well, now we have fixed points for which we can attach to determine the time of the relevant events. <br><br>  We know that at some point in time there was a change in the rectangles on the screen, and after another 16.7 milliseconds the opposite change occurred. <br><br>  Thus, on any horizontal line in the picture, the distance between the beginning of the change in brightness of rectangles from black to white and from white to black is exactly 16.7 milliseconds. <br><br>  If the beginning of the change in brightness is difficult to determine, then any other characteristic point can be chosen as a reference point, for example, the point where the brightness of the gradients coincides in the upper and lower bands. <br><br>  Now we know what distance in the photo corresponds to a time interval of 16.7 milliseconds. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8d1/b86/4f5/8d1b864f51149b542e7d70730d7a65e8.png"><br><br>  For simplicity, let us vertically divide our image into conditional time zones of equal width. <br><br>  In the above case, it turned out that the time interval of 16.7 milliseconds takes 13 time zones.  A small error in the definition in this case is not terrible, since it will be a fraction of a millisecond. <br><br>  Consequently, one time zone corresponds to about 1.25 milliseconds. <br><br>  Well, then everything is simple. <br><br>  Let us measure horizontally the length of the front from white to black (BtW) and from black to white (WtB). <br><br>  In this case, they coincided, and have a length of about 4 vertical time zones, that is, about 5 milliseconds. <br><br><h2>  THE TASK SET IN THE HEADING OF THE ARTICLE IS SOLVED! </h2><br>  The truth is only theoretically, on paper.  It remains to create a test material with which we will work, and pick up equipment with which you can take a similar picture. <br><br>  With the first, everything is quite simple. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/520/3df/5bb/5203df5bb62b7e97e9afde16f8d8bd2d.gif"><br><br>  Let's make a <a href="http://yadi.sk/d/f2OC0U3BSqzv5">simple video for offline viewing</a> * with alternating black and white stripes vertically like in the picture above, only at 60 frames per second.  It is easy to see that every 16.7 milliseconds the horizontal bar shifts down by 1 step.  Since in most displays the response time from black to white is much longer than from white to black, the stripes in the test in each horizontal line alternate not through one, but after three (one black and three white).  Accordingly, the horizontals we got not two, but four.  Thus, at each moment of time we have one black and three white stripes on the screen. <br><br>  Well, for convenience, as well as to make it easier to catch defective images, two identical test zones were made one under one. <br><br>  In the picture they should also be exactly the same (well, except perhaps with a slight horizontal displacement due to the frame scan of the monitor). <br><br>  But if the picture is very large, or the length of the strips of the upper and lower test zones do not match, then something went wrong (for example, the photo came at the wrong time of the monitor frame change), and such a picture will have to be rejected. <br><br>  To facilitate subsequent analysis, the video is vertically divided into 50 time zones.  Vertical stripes combined, light / dark gray (10% / 90%).  This should also facilitate further work with photography.  When photographing it is not necessary that all zones fit into the frame.  You can remove and 40, and 30, and even 20 zones.  It‚Äôs not scary if there is not a whole number of time zones in the image, for example, 37.5 - this doesn‚Äôt affect the accuracy, just the conversion factor from the relative width of the time zone to milliseconds will be different. <ul><li>  <b>Small addition</b> <br>  If you have a monitor with a very slow matrix, which does not have time to switch from white to black during one frame, you can try to use <a href="https://yadi.sk/d/V-KvpvL0SyQ7Y">this video</a> .  Here the cycle takes 6 frames.  The top 6 ‚Äúframe-by-frame‚Äù bars can be used to determine the reference points on the frame, and the bottom 2 ‚Äúthree-frame‚Äù bars to measure the response time of monitors with a ‚Äúslow‚Äù LCD matrix.  Of course, there will be a few more defects when shooting (it will be necessary to select images where the entire transition is visible on the lower bars), but you can test monitors with a long response time from white to black. </li></ul><br>  Well, now go to the question <h2>  what are we going to shoot </h2><br>  As we noted above, the duration of the photo frame must be longer than the duration of the frame on the display.  For DSLRs and other cameras with a shutter, the duration of the photo frame is approximately equal to the sync speed. <br><br>  And here the first ambush lurks us: modern cameras have a very short one.  The sync speed is much shorter than 1/60 second. <br><br>  Here the old Soviet ‚ÄúZenith E‚Äù would be perfect, but unfortunately it is not digital. <br><br>  But all is not lost - a similar picture can be taken with a camera with a fast curtain shutter, but there are specific features.  But we'll talk about this in the next article. <br><br>  In addition, modern mirrors usually have the ability to shoot video, so if you have a CMOS matrix, you can use this mode.  The main thing is that the video mode is not very fast - no more than 30 frames per second.  Well, the resolution for the video naturally need to choose the maximum.  Firstly, to get the highest quality freeze frame, and secondly, to slow down the electronic shutter as much as possible. <br><br>  The same requirements for video cameras: in this case, they should be approached with a maximum video mode of no more than 30 frames per second, a CMOS matrix and an electronic shutter.  If the camcorder also uses an electronic shutter when taking photos, then you can try this mode. <br><br>  And finally, digital cameras, smartphones and similar devices, which are usually considered unsuitable for serious work, can be perfect here. <br><br>  The requirements are the same: CMOS matrix, and a rather slow electronic shutter. <br><br>  The truth is, there is one more important requirement that will immediately eliminate half of the digital flashes: THE SHUTTER SHOULD BE SHALL AS SHORTLY AS SHED, at least 1/500 - 1/1000 seconds, and preferably even less.  After all, 1/1000 of a second is 1 millisecond, i.e.  comparable to the response time of the LCD monitor that we want to measure.  Shooting with an exposure of more than 1/500 is the same as shooting an active child with an exposure of more than 1/30.  Of course, we will be able to see something with a longer shutter speed, but it must be borne in mind that in this case, the shorter the shutter speed, the more accurate the result will be. <br><img src="https://habrastorage.org/getpro/habr/post_images/419/76e/772/41976e7729eefad9ae2171d7afa6c723.jpg" alt="image"><br><br>  Such are the conflicting requirements for equipment for shooting. <br><br>  But, nevertheless, suitable for this test photographic equipment can be found.  For example, the camera of the <a href="">Samsung Galaxy S GT-I9000</a> smartphone is quite good for the author of the article. <br><br>  Let's try to determine the response time of the monitor with the TN matrix <a href="">BenQ M2700HD</a> . <br><br>  Before testing, the monitor should be warm and well tuned to the levels of black and white.  This can be done, for example, using the <a href="http://www.mehanik99.ru/mons/">LCD Vs_mon</a> program.  If the black and white levels are inaccurately tuned, then the response time test will give the corresponding error.  Rather, the test result will be correct, but for incorrectly set levels. <br><br>  To get the shortest possible shutter speed, you need to set the maximum sensitivity to light (in this case ISO 800).  With the same purpose, as well as to reduce the effect of PWM backlight lamps, it is advisable to calibrate the monitor during testing at the highest possible brightness. <br><br>  So, we run an endless replay of the video playback in windowed mode, and take several screenshots. <br><br>  Since the electronic shutter usually ‚Äúmoves‚Äù along the short side of the image, we position the camera in front of the screen so that the portrait image is obtained. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/422/ab2/a09/422ab2a0980c1cde31bc530ebaa950d5.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/573/fe5/e93/573fe5e9387ba4f913c8b77126e0fcd0.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Screenshots of the monitor with TN matrix </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BenQ M2700HD</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , taken by the camera of the smartphone </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Samsung Galaxy S GT-I9000</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/650/6d2/f01/6506d2f012f8067938f1ff25c72acbed.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/65c/e6b/d1e/65ce6bd1e976b90e01e2802fcfce808e.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The pictures above clearly show that although they differ in the width of the player‚Äôs window, the character of the lines corresponding to the frames on the LCD screen is exactly the same (well, except for the scale, of course) - in both cases there were four horizontal bars, each which corresponds to the next one by one frame on the monitor screen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the frame rate of the monitor was 60 Hertz (16.7 milliseconds), by the presence of four horizontal bars in the frame, we can conclude that the total response time of the electronic shutter of this camera is about 65 milliseconds, which is a bit too much, but quite acceptable.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Any frame is suitable for further analysis. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But since in the second snapshot we already see the raster of the monitor matrix, we will consider the first snapshot. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For clarity, the picture is blurred in the photo editor, and conditional marks are applied to it, corresponding to the frame time and response time from 10% white to 90% black and from 90% black to 10% white (it‚Äôs clear now why vertical lines are made of exactly these shades). ).</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/654/96c/e57/65496ce57306f9ddb07ac94720c4a329.jpg"><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It can be seen that the length of the frame (16.7 milliseconds) in a picture luring vertical time about 13 </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> x zones.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thus, a one time </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">as</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I zone in the picture turned out 1,285 milliseconds in length</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The response time from white to black takes approximately one temporal </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> th zone, i.e. </font><font style="vertical-align: inherit;">about 1.3 milliseconds.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The response time from black to white is significantly longer, which is typical of TN matrices. </font><font style="vertical-align: inherit;">In this case fall to 10% white (visible on the "disappearance" vertical stripes) took approximately 3 temporal </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e zones, i.e. </font><font style="vertical-align: inherit;">4 milliseconds.</font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If you enable Overdrive in the monitor settings, then the response time from black to white is significantly reduced. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/035/c05/0c4/035c050c42d481e8ecb2645a1503af93.jpg"><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Thus, the task set in the title of the article was solved not only in theory, but also in practice! </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We conducted the previous testing with the monitor brightness close to the maximum, and with optimal adjustment of the black and white levels. However, usually the monitor is operated at a much lower brightness, and the rest of the settings the user usually selects for themselves individually. And from this the result of the test can change significantly. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's try to check the response time of the same </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BenQ M2700HD</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> monitor </font><font style="vertical-align: inherit;">at the operational ‚Äúoffice‚Äù setting (low brightness, black and white levels are calibrated to make all halftones visible in highlights and shadows). </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/400/7e7/886/4007e78866f7f729017900fa0825475f.jpg"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Overdrive is off.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The response time from black to white increased to almost 20 milliseconds, i.e. It became more than one frame. It is here that it becomes clear why the alternation of one black and three white frames is made in the test video. In this case, this is a calibration fee with the distinctiveness of all halftones in highlights. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For ‚Äúoffice‚Äù use, this is not terrible, but for ‚Äúcinema‚Äù and even more ‚Äúgaming‚Äù use, if behind high-contrast objects ‚Äúghosts‚Äù or ‚Äúshadows‚Äù begin to appear, it may be worth sacrificing one or two gradations in highlights (shadows), to get rid of them.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In addition, the picture clearly shows the vertical slightly colored stripes of different rage. </font><font style="vertical-align: inherit;">This flicker backlight with PWM regulation, due to the reduced brightness of the CCFL lamp, operating at incomplete power. </font><font style="vertical-align: inherit;">Alas, this is also a fee for a comfortable brightness. </font><font style="vertical-align: inherit;">Note that the ‚Äúpencil test‚Äù this monitor passes without comment, so in reality, everything is not so scary. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6a2/e13/5df/6a2e135dffd72a04675a82f3bbf9a7f2.jpg"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Overdrive enabled. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The response time from black to white remains almost the same as at maximum brightness, but now after switching the strip becomes whiter than the white background. </font><font style="vertical-align: inherit;">This is an artifact characteristic of the Overdrive display mode, also manifested due to the nature of the calibration.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And a few words in conclusion </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Of course, this method is hardly applicable for professional testing of LCD monitors, and its result is less accurate than according to the method given at the beginning of the article. </font><font style="vertical-align: inherit;">But on the other hand, it makes it quite easy to conduct such testing independently, without the use of special equipment, and the test result is very visual. </font><font style="vertical-align: inherit;">This can be very useful when setting up and calibrating an existing monitor or TV, or when purchasing a new one.</font></font></div><p>Source: <a href="https://habr.com/ru/post/225829/">https://habr.com/ru/post/225829/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../225819/index.html">Curiosity is back on the road after drilling. New panorama of Mount Sharp</a></li>
<li><a href="../225821/index.html">‚ÄúWhere are you, Stepan?‚Äù Or how do Wi-fi bridges help save on the Internet</a></li>
<li><a href="../225823/index.html">Using Pjax in Yii2 (short review)</a></li>
<li><a href="../225825/index.html">Aptly - create your own repository</a></li>
<li><a href="../225827/index.html">Learning to understand the art of programming</a></li>
<li><a href="../225831/index.html">Algorithm for finding the smallest covering capacity of a finite set of its subsets</a></li>
<li><a href="../225837/index.html">Notification during call pickup in Asterisk</a></li>
<li><a href="../225841/index.html">Swift programming language. Russian version</a></li>
<li><a href="../225845/index.html">Hexapod-robot running ROS</a></li>
<li><a href="../225847/index.html">ImEx.js will decorate your code</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>