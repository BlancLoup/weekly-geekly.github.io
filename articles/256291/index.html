<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Similarity search. Search for fuzzy duplicates. Lectures from Yandex</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Today we are publishing the sixth lecture from the course ‚ÄúImage and Video Analysis‚Äù given by Natalia Vasilyeva at the Computer Science Center in St. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Similarity search. Search for fuzzy duplicates. Lectures from Yandex</h1><div class="post__text post__text-html js-mediator-article">  Today we are publishing the sixth lecture from the course ‚ÄúImage and Video Analysis‚Äù given by Natalia Vasilyeva at the Computer Science Center in St. Petersburg, which was created on the joint initiative of the Yandex Data Analysis School, JetBrains and CS-club. <br><br><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://video.yandex.ru/iframe/csc-video/m-28888-15043386e01-a64d328c98037693/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253,15700259&amp;usg=ALkJrhiFlYxSbLBeK4il8RTCtLJ3rzLm_Q" width="450" height="253" frameborder="0" scrolling="no" allowfullscreen="1"></iframe><br><br>  In total, the program has nine lectures, of which have already been published: <br><ol><li>  <a href="http://habrahabr.ru/company/yandex/blog/251161/">Introduction to the course "Image and video analysis"</a> . </li><li>  <a href="http://habrahabr.ru/company/yandex/blog/254249/">Basics of spatial and frequency image processing</a> . </li><li>  <a href="http://habrahabr.ru/company/yandex/blog/254955/">Morphological image processing</a> . </li><li>  <a href="http://habrahabr.ru/company/yandex/blog/255627/">Building signs and comparing images: global signs</a> . </li><li>  <a href="http://habrahabr.ru/company/yandex/blog/255985/">Building signs and comparing images: local signs</a> . </li></ol><br>  Under the cut, you will find a plan for a new lecture, slides and a detailed transcript. <br><a name="habracut"></a><br><div class="slideshow"><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=http://www.slideshare.net/slideshow/embed_code/47285935&amp;xid=25657,15700023,15700186,15700191,15700248,15700253,15700259&amp;usg=ALkJrhhRyRv5DzZAwdZHmNw5qKJxTi96wA" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>Search for visual similarity: description.</b> <br><br>  <b>Fuzzy duplicate search: description.</b> <br><br>  <b>Traditional CBIR system architecture:</b> <br><ul><li>  image indexing; </li><li>  image search; </li><li>  indexing. </li></ul><br><br>  <b>Find your closest neighbors:</b> <br><ul><li>  naive approach; </li><li>  some index structures; </li><li>  KD-Tree Construction; </li><li>  Nearest Neighbor with KD Trees; </li><li>  Spheres vs.  Rectangles. </li></ul><br><br>  <b>Metric trees;</b> <br><ul><li>  vantage point method; </li><li>  how to choose pivot points; </li><li>  Building a VP-tree. </li></ul><br><br>  <b>Reverse Index:</b> <br><ul><li>  "Visual words": the main idea; </li><li>  visual words; </li><li>  reverse image index by visual words; </li><li>  "Bag of visual words." </li></ul><br><br>  <b>How to build a dictionary:</b> <br><ul><li>  selection of fragments; </li><li>  quantization / clustering methods; </li><li>  tree building; </li><li>  indexing; </li><li>  Search; </li><li>  Vocabulary Tree: Performance; </li><li>  Locality Sensitive Hashing (LSH): motivation; </li><li>  LSH: Key idea; </li><li>  LSH (alternative definition); </li><li>  LSH: indexing; </li><li>  LSH: search for the nearest neighbor; </li><li>  use LSH to search for fuzzy duplicates. </li></ul><br><br>  <b>Evaluation of search methods:</b> <br><ul><li>  evaluation issues; </li><li>  Quality control; </li><li>  numerical quality assessment; </li><li>  numerical evaluation; </li><li>  picture tracks; </li><li>  search for visual similarity: observation. </li></ul><br><br><div class="spoiler">  <b class="spoiler_title">Detailed text transcript of the lecture</b> <div class="spoiler_text"> Last time, if you remember, we talked about how to compare images, how they can be represented as feature vectors, as a set of some numbers, and how these same vectors can be compared with each other.  At the same time, we said that, in principle, images can be described using the so-called global features.  That is, when we describe the entire image as a whole, we consider the histogram over the entire image, and, in fact, we considered such signs.  I told you that they are also quite popular, and for a number of tasks it becomes necessary to calculate the so-called local features.  That is, when we have described not the whole picture, but some of its surroundings.  Well, actually, when we have global signs do not work.  Here are some examples here.  For example, when our scale changes significantly, that is, these two fragments, they obviously coincide.  But, nevertheless, if we try to count global signs, so to say, the texture throughout the picture here, throughout the picture here, it will be different.  Histagrams, whatever you like, too.  Forms - too.  That is, in principle, we need to understand that we need to somehow be able to compare this fragment with this fragment.  That is, to count a sign that would describe only a fragment of the image.  The change, in fact, the point from which we look at the object.  That is, the scale here is about the same, but, nevertheless, what we are looking through the window here again has quite a significant change in any global sign that we can build from this picture in comparison with this.  That is, they will not be on each other.  Well, if their threshold is small enough. <br><br>  Changes in lighting.  Here, of course, even more is not the fact that the sign is global or local, but in the invariance to change the lighting, but in fact local signs are almost all invariant.  Well, while those that we are going to discuss today, they are invariant to such a change in lighting.  And overlap.  That is, some kind of interference, again, if we consider a large number of some small fragments and compare them with small fragments from here, we can completely establish that this fragment corresponds to this.  If we look at the signs of this whole square, draw up with it, or even the whole image, they will turn out to be different. <br><br>  What can be proposed in order to overcome all these troubles, try to calculate local signs for some image fragments.  That is, the idea is that, despite the fact that if we try to build some numerical characteristic throughout the picture, it will be different for these two images, you can find some fragments in one and the second picture so that they will be comparable with each other.  That is, we can say that we clearly have this fragment comparable to this and this fragment is comparable to this one.  Two questions arise, in fact: how to choose these very fragments?  And the second question: how to describe the fragments?  Well, actually, an intuitive, such, in the forehead, approach, how to compare fragments, and how to choose them - that is, that is, we take, we completely scan our pair of images.  That is, we choose a window of some size and go on.  On one picture recorded.  We look at the second: matches, does not match.  It does not coincide, it does not coincide, it again does not coincide, here they are.  More less similar.  Hurray, there is a coincidence.  It is clear that, on the one hand, of course, this approach is good, because we are going through all possible options and will not miss anything for sure.  But, on the other hand, it is computationally very complicated, because you need to sort out, it is unclear how large to take the window, it is not clear, in fact, you need to sort out all possible offsets of this window in one picture and in the second picture.  And another problem related to this is that we actually get too many comparable pairs.  Because if we take, let's say, that here we had a window that was originally compared here, this fragment was compared to this.  In fact, a shift here in this image, a window one pissel to the right, one pixel to the left, it will not give a significant change to the vector of signs.  It turns out that we will have a lot of matches.  We will need to bother then search among the overlapping most coincident and so on.  This, in general, do not want to do.  Another option, which in principle would be more pleasant and acceptable, is not to go through all possible options.  The question is, what are the options for us to sort out?  It would be nice if we could find some such singled out special points on the image that are the most informative.  That is, which contain the greatest information about what is presented in this image. <br><br>  Fichers are usually signs, that is, some characteristics.  Here is the point of interest.  That is, this is the position, the point of the image, which is of some interest. <br>  R: That's it, that's why I asked that in some adjacent area, they use the term features to denote those image points that ... <br>  Not.  That is, usually, here, under the "features" understand that's just the description, some characteristics.  That is, around this point you can then build a feature vector or calculate any one ‚Äúfeature‚Äù that will describe a fragment built around this feature.  In Russian literature, they are often called either ‚Äúprecise features‚Äù or ‚Äúspecial points‚Äù, or generally translate who is in that much, tracing from English as ‚Äúkey points‚Äù, ‚Äúpoints of interest‚Äù, ‚Äúpoints of attention‚Äù, in general, all sorts of Different options are possible.  In fact, the idea to try to find such points is also comparable to our psychology.  Surely many have heard about the fact that they are conducting research, for example, tracking your pupil.  If you go to any page on the web, in order to understand which area of ‚Äã‚Äãthe page is most interesting for you, you can hang a webcam that will monitor the movement of your pupil and, in fact, the coordinates of the web page on which you are most of all delayed by your pupil, they are supposed to be more interesting for you.  That is, this is what our vision focuses on when trying to understand the content of a page.  And if you actually look at such a map of the focus and movement of the pupil, it is clear that the pupil is far unevenly moving across the entire screen, we are focusing on some such special points.  We focus on those actions where there is a selection, that is, what attracts our attention. <br><br>  It would be nice to try to find the same points in the pictures.  That is, it is clear: fewer comparisons are significant.  Plus, most likely, we can ensure that these points are more or less isolated from each other, and, accordingly, we will not have the problem of intersecting fragments, as in the previous version.  But, at the same time, we, of course, have no guarantee that we will find absolutely all comparable pairs.  Well, the main question: how to look for these very key points?  Let's try to think about what should be, that is, what requirements can we place on these very special points, special fragments?  On the one hand, we want them to be not very many - substantially smaller than the pixels in the image in order for the properties to be executed ... so that the search is incomplete and so that these same fragments are separated.  So that we do not have the intersection of a large number of pairs.  On the other hand, we want these fragments to be so representative that it is easy to match one fragment in one image and the second fragment in another image.  That is, if, for example, we have a completely homogeneous background, it is clear that we can choose several fragments that are indistinguishable from each other, and if we have exactly the same fragment in the second picture, it is not clear with which of these match it.  That is, they must somehow be unique in some way.  They have to be repeated in the sense that if we have an image of the same object, or the same picture is somehow modified, there is somehow reaped, scaled differently, then we want these fragments and some Some exact features coincided in these two pictures.  That is, the point that we considered special, it is, let's say, if we take a person's face, so his eyes can be special points.  If we find the eyes in one image, we want to find the eyes in another image.  The fact that in one image we considered the features of the eye, in the second image we have a mouth - no, we will not do it, because again we will not be able to compare them.  Well, these fragments themselves, which are built around singular points, should be small in size in order to be resistant to partial overlapping.  That is, if we come back here, then here if we had a large fragment, then again we have a feature vector constructed from this fragment that would be significantly different from what we have here.  That is, it is assumed that, generally speaking, in a small neighborhood of this most particular point, the changes should not be so significant that the feature vectors will differ. <br><br>  How, for example, can we search for these very special points?  What, then, will the comparison of these two images look like with the help of these local features?  First of all, we really need to find the singular points in some way and build the singular fragments, like a neighborhood around this singular point.  In this case, it would be good if our singular points were invariant to a change in lighting, to a change, that is, to different geometric or photometric transformations of a picture.  That is, if we stretch it, compress it, the object moves somewhere in the image, if we change the brightness level - the intensity of the image so that the point is still all the time in the same place.  And in order for the fragment to be also invariant to a turn and to a change in scale.  Next, we build a feature vector based on such a particular fragment and match the sets of local features for different fragments in different pictures.  For example, we have the same cat turned.  We found point features, determined a neighborhood for each point feature, built a feature vector for this neighborhood and want to be able to compare them and further, actually, compare two pictures with each other depending on how many of these feature vectors they more or less match. .  Well, plus it also actually makes sense to look at comparable relative fragments relative to each other.  That is, for example, if we say that this point here corresponds to this point, and this point corresponds to this point, do we still have three, in fact, we had to choose points.  Well, here we still have a feature, and here a feature.  Let's say we compared, found, selected all these pinpoints, built fragments, built vectors of signs around them, realized that here we have this fragment that corresponds to this, this one corresponds to this one, and the knee corresponds to the knee.  And then we can still use the information about the relative location of these very fragments here and here.  That is, we basically, as they are located relative to each other within the same image, it is assumed that it does not change much. <br><br>  Once again about the actual required properties of these singular points.  We want them to be repeatable, because if, for example, in these two images from this side, special points were highlighted in white and from this side in red, then we have no matching points, respectively, there is no possibility match these images. <br><br>  What is important is that, on the one hand, these sets of singular points should intersect, that is, at least some of them should coincide, and, on the other hand, we should be able to find them independently ... that is, look for them in each image independently of the other Images.  That is, we are looking for these singular points on one picture, regardless of that we look for the second picture and we expect that if these two images are modified copies of one another, then the sets of these singular points will intersect. <br><br>  Plus, these fragments are special, they should be informative, this is exactly what I said: if we have an uninformative fragment, but this is actually also uninformative, a special point around which it was built, say, here.  In this picture, here we have three here; we can still build a large number of the same fragments, which, in general, will be comparable to this, it is not clear which one is suitable for us.  Well, I have already spoken about the fact that very invariance to all geometric and photometric transformations is desirable.  Actually, a geometric transformation is either a rotation or a change in scale, or both, or affine transformations, and photometric transformations are affine intensity transformations, that is, when we change the brightness of a picture. <br><br>  Today I will speak again about monochrome pictures, simply because it is easier.  It turns out that in fact quite suitable such a candidate for a particular point is the corner point.  In principle, it ... that is, if we find an angle somewhere, well, such an exact feature is actually not always ... where we have several directions of the gradient, where brightness changes.  Thus, we immediately dismiss here these non-informative fragments, which we build in completely monotonous and monotonous areas, here we obviously have some kind of transition, and, generally speaking, the human eye, too, when looking at the image, it clings for such differences in brightness.  Moreover, it is desirable that the differential was in several directions.  That is, we need a corner.  In principle, these corners can be easily detected using a small window, that is, the requirement that we have a small neighborhood.  How can I find it?  One of these options is from the signs of the angle and the fact that if we take some small window and try to shift it in different directions, then for us for a monochromatic area the offset of this window will not give a change in intensity.  That is, the offset fragment will be similar to the original.  In the case of a unidirectional counter, we will not have a change at least along one direction, along the direction of the edge.  That is, if we move this window up and down, they will look like twin brothers.  If we have a window above the angle, then changing the position of this window in any direction will lead to a change in the brightness ratio of the fragment below it.  Actually, the very first detector of these corner points was based on this property - the Moravik algorithm, which simply considered the difference between the intensity of window displacements and, in fact, took the smallest sum of squares of intensity differences for the angle response force.  That is, we take the window, we consider the sum of the squares of the intensity differences in the next.  If they coincide with us, if this value is minimal for some neighborhood, then there is no angle.  If changes occur in many directions, then most likely there is an angle. <br><br>  Probably the most applicable angle detector, the so-called Harris detector, it looks at the direction of the gradients of each point, and now we will talk about it in more detail.  Consider just such a picture, a wonderful pyramid, and pull out three fragments.  Actually, one fragment is completely homogeneous, the second fragment contains one contour unidirectional, the third fragment contains a clearly defined contour.  That is, we have two distinct gradient directions.  Construct the following visualization.  For each point inside this window, we calculate the gradient in X and in the game.  And then we will try to put them here on such a coordinate grid, that is, here we have horizontal values ‚Äã‚Äã‚Äî this is a gradient along X, and vertical values ‚Äã‚Äã‚Äî a gradient along the game.  In general, it is not difficult to guess for obvious reasons, the gradients of almost all points, they are missing here at zero, because there is no change in brightness.  That is, we have a derivative everywhere - zero.  Of course, it‚Äôs not exactly zero here, because it‚Äôs still an image that doesn‚Äôt have all pixels at all, that is, there is some slight brightness change, so here it runs a little around zero.  If we try to do the same for this fragment, we note that we already have a much more covered region, and we can see that in fact we can trace one such direction as seen on this diagram, in fact, which corresponds to a corner of 450. That is, we have a corner of 450 - this means that both the derivative with respect to x and the game give some non-zero value. ,  ,      450, , , -     , ,    .  ,  ,           ,        ,  ,       ,     ‚Ä¶ - ,     ?   ,     ,       .              .    -    ,  , -,          ,  ,  ,      ,      -  . ,      - .       ,            , ,    . <br><br> :       ,  ,        ,    ,  ,     , , ,     -  ,     ,       ? <br><br>    ,  .  ,        ,  ,      . ,      ,   ‚Ä¶ <br><br> ,   ,             ,    ‚Ä¶     ,   -  ,  ,      .       ,   ,     .       ,     .  Hooray! ,     ?           .  ,      (-),     ,        \[u,v].       ,   ,     ,  ,  -‚Ä¶       ,       ,     ,             ,  .         ( 0:28:50),   ,         ‚Ä¶        ‚Äì  .  ,    ‚Ä¶ <br><br>   ,   .     .   ,     W  X           ‚Äì ,      ,   ,      -  ,     ,   ,     ,        ,  ,  . ,   ,         ,        -    . <br>    ¬´u¬ª  ¬´v¬ª       ,     ¬´-¬ª     ,            ,      .         , ,  ¬´¬ª  -,    , ,   ,      ,   ¬´u¬ª  ¬´v¬ª,   ‚Äì         .   , ,      .  , :     ,           ,         . <br><br>      ‚Äì   .      ‚Äì  .  , ,   ‚Ä¶      ,    ,        ,       ‚Ä¶   ,    .    ,      ,   - .   ,    -   . , ,  ,   ‚Äì   ,      , , , ,    ,    ,   .  ,   ,      ,       R.   ,        ,  ‚Äì ,   ,  ,    .    ,      ,  R    . <br><br> , ,    ,    ,      . ,           ,     ,       ,  ,       ‚Äì       ,      ,      .    ,  ,       ,    .  , ,  ,    -      ,       ,      ,  ,  ,  - ,        , , ,   . , ,        .      ,   , ,   .      ,    ¬´¬ª, ,    ,       ,     ,  ‚Ä¶ ,  ,  ‚Äì ,  ‚Äì  .    , ,      .       .  ,    ,      , ,      ,  ,   , .     ,      ,      -      .       -   .  ,  ,        ,      ,  .    ,     .  ,  ,  -,     ,    ,   , . <br><br>   , ,      ,    ? ,            .  ,     ,      , ,         ,       ,   . <br><br>     ?    ,  ,  ‚Ä¶  ,  ,     ,     , , , .       . , R      ,  ,  -, ,   ,   ,   . ,     ,     , , ,    -  ,      . ,  ,      .              , -, -, , ,       ,        ,          .    ,    ,   .  Not good.  What can be done with this?   ? , ,  ,   :          .  ,    . ,     ,        ,       ,     .  ,        ,   ,     -      ,          . <br><br> ,        ? ,       ,        ,      . ,         ,   -    .  ,    ,     ,       ,  ,       .    ? ,       ,    ,      .  ,     .    ,        ,    . ,                ,    ‚Ä¶  ,            ,      , , ,         ,         ,   ,       ,    , , .  ,         ,    .       . ,       ?       ,       .  ,                 . ,     ,    ,      . ,       - . ,  ,       , ,        ,        ,  ,       .    ,   ,        , ,  ,        .  ,    ,     .  ,          ,        . ,   ,     ,    ,     ,  ,      .  , ,      ,     ,    . <br><br>    ,  ,       , ,   ,    -           .  ,  -   ,    ,  ,  ,       ,  . <br>   <br><br>  ‚Äì ,     ,  ,    ,          . <br><br>   , .           ,   ,  ,      ,       ,       .       ,  ,   ,     , ( -),     ,   , ,          .  ,    ,        ,         .               ?        .  , ,           ,       .        ,   ,  ,   ,   ,  ,  ,    ,    .  ,       , ,       ,       .  ,           ,  ,   ,  ,         -,   ,    ,            .  ,       .          -   .  ,           ,       ,  ‚Äì    .    ,   ,  ,                ,  ,       ,  .           ,       ,       ,   ,        .  ,          ,       ,    ,     .  ,   ,  ,        - ,     ,         ,      .  , - . ,       ,    , ,    ,        ,    ,      ,  (-),  ,  ( 0:45:50)      -,    -  ,  ,     ,    .  ,    ,     ,        ,   , ,     ,               ,  ,   ‚Ä¶    ,  ,  ,     .            ,        . ,     .  ,         , ,  ,  ,    ,           . <br>       ,   , -, ,  -,        ? ,                   -.                    .          ,    ,    , ,  ,  ,   ,  , ,                     .  ,   ,        .             ,   ,  , ,    . ,  ,   ,       ,          ?  ,            ,           ,         .          ,  ,   ,     ,        ,  ,      .  , Space ‚Äì   . ,      , -  SIFT.  ,    . , ,    .    , ,    ?          ,   .       ?   -    , ,  ,           ,             . <br><br> ,  ,  . ,     ,      ,             .   , ,  ,   ,              . ,  ,    ,      . <br><br> ,      ,    ,      ,    ( -),      2004- .   ? ,  ,        ,       . ,         ,   .  ,       , ,  ,   ,  ,            ,  ,       ,  .,     ,   . , ,     ,      .          ,  ,      ,   ,    .      .    ,  -  ,        ,   .  ,         ,         ,  ,        ,   .     ‚Äì  , ,  .   , ,    .  ,    ,              ,   .    ,  ,       ,    ,  ,         ,  ,           .  ,  ,          ,   ,   .      ,     ,    . ,   ,       . , , ,      ,             . ,  ,        ,       . ,       ,         ?     .  ,     ? ,     . , -,           ? ,             ,  . , , -,   ,          ,    ,  ,    .      ,  ,    ,  ,     , ,  ,       -   .      , ,   , , ,   , ,    .         .  ,       ,  ,  ,     .        .  ,    ,  ,      ,      : .    ,       ,   .  ‚Äì . ,      ,    , ,    , ,            ,       ,     .  , ,     ,      ,   ,        ,      ,    -      .  ,      ,  ,  ,          ,    ‚Äì     .    ,  ,   ,      ,     .     ,             ‚Ä¶   ,  ,   ,     , ,     , ,         .  ,   , ,              ,   ,  .        ,  ,       , ,    .      . ,     , ,   ,         ,   ,  , ,   900.  ,            .        ,        .   ,        ,            16 ,    16-       , -,    .  , ,     ,       .  ,  , -   ,    ,      .   , , ,      ,      .       , ,          :      ,   ,   ,   ,  , ,     ,    .     ,             ,   .   ,   ,     ,  ,    .  ,      ,      ,            ,  .          . <br><br>     .   ,   ,    .   , ,    .      . <br>    , ,    , ,      :         :   . ,         ,    ,      .   , ,     ,    , ,      , . ,   ,       ,   ,         ,    ,   .  ,        ,  ‚Äì .  ,  ‚Ä¶ , ‚Ä¶ <br><br>     .  , ..              .     .           ,        .  Those.         .     -      , -     ,     .          500        ,   ,         ,           .      ,      ,  -      ‚Äì      ‚Äì   .        .      ,             ,   .         .  Those.          ,  ,                .      ,      ‚Äì       ,                      .    -   ,                    . <br><br> ,       -.    .      , -,  .     (  ,    ) -             ,    .       ,     .   ,      , ,   ,    ,                  . - . <br></div></div></div><p>Source: <a href="https://habr.com/ru/post/256291/">https://habr.com/ru/post/256291/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../256281/index.html">IBM invites you to the SoftLayer Workshop in Moscow</a></li>
<li><a href="../256283/index.html">Install a free StartSSL SSL certificate on the cloud VPS from Infobox</a></li>
<li><a href="../256285/index.html">DevCon 2015: announcement of the third wave of conference speakers</a></li>
<li><a href="../256287/index.html">Corsair PadLock 2 - flash drive with the ability to instantly destroy data</a></li>
<li><a href="../256289/index.html">Participate in research into the use of software architecture patterns</a></li>
<li><a href="../256293/index.html">The solution of the problem of two sages and numbers from 1 to 100</a></li>
<li><a href="../256295/index.html">Kharkiv Ciklum .NET Saturday</a></li>
<li><a href="../256299/index.html">Treatise on radio paths or some marketing misconceptions about radio communications</a></li>
<li><a href="../256301/index.html">The paradox of birthdays for three people</a></li>
<li><a href="../256303/index.html">How we came up with a text analysis system</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>