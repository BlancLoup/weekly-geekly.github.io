<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Kibana-mother or Why do you need logs at all?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="You can say that ‚Äúsometimes it is necessary ...‚Äù But actually, you want to always see what you have in the logs, through a graphical interface. This a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Kibana-mother or Why do you need logs at all?</h1><div class="post__text post__text-html js-mediator-article">  You can say that ‚Äúsometimes it is necessary ...‚Äù <b>But actually, you want to always</b> see what you have in the logs, through a graphical interface.  This allows: <br><br><ul><li>  To make life easier for developers and system administrators, whose time is just a pity and expensive to write grep-pipelines and parsers for each individual case. <br></li><li>  Provide access to the information contained in the logs, moderately advanced users - managers and technical support. <br></li><li>  And to see the dynamics and tendencies of appearance of pledged events (for example, errors). </li></ul><br>  So today we will talk again about the ELK stack (Elasticsearch + Logstash + Kibana). <br>  <b>But this time - in terms of json-logs</b> ! <br><br>  Such a use case promises to fill your life with completely new colors and make you experience the full range of feelings. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/files/b61/bc4/87a/b61bc487a1c24e039bcf7a91b51807ed.jpg"></div><br><a name="habracut"></a><br><h5>  Prologue: </h5><br><blockquote>  <i>‚ÄúUnderstand, on Habrahabr only talk, what about Kibana and Elasticsearch.</i>  <i>How damn cool it is to see how a huge text log turns into beautiful graphics, and the CPU load is barely visible somewhere in the depths of the top.</i>  <i>And you? .. What will you tell them? "</i> </blockquote><br><br><h4>  <b>Materiel</b> </h4><br>  In the life of every normal boy, a moment arises when he decided to put an ELK bundle on his project. <br><br>  The scheme of the average pipeline looks like this: <br><img src="https://habrastorage.org/files/a5f/f09/7be/a5ff097be6e241ad8032f3fc0ade2741.png"><br><br>  We send 2 kinds of logs to Kibana: <br><br><ol><li>  <b>‚ÄúAlmost normal‚Äù nginx log.</b>  Its only highlight is the request-id.  We will generate them, as is now fashionable, using Lua-in-config ‚Ñ¢. </li><li>  <b>The ‚Äúunusual‚Äù logs of the application itself on node.js.</b>  That is, the error log and the ‚Äúprodlog‚Äù, where ‚Äúnormal‚Äù events are flying - for example, ‚Äúthe user has created a new site‚Äù. <br><br>  The peculiarity of this type of logs is that it: <br><ul><li>  Serialized json (logs events for the bunyan npm module) </li><li>  Formless.  The set of fields for messages is different, besides, in the same fields different messages may have different types of data (this is important!). </li><li>  Very fat.  The length of some messages exceeds 3Mb. </li></ul></li></ol><br>  These are, respectively, the front-and back-end-s of our entire system ... Let's start! <br><br>  <b>filebeat</b> <br><div class="spoiler">  <b class="spoiler_title">filebeat.yml:</b> <div class="spoiler_text">  We describe the paths to the files and add fields to the messages that we need to determine the types of logs at the filtering stage and when sending to ES. <br><br><pre><code class="hljs pgsql">filebeat: prospectors: - paths: - /home/appuser/app/production.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span>.json input_type: <span class="hljs-keyword"><span class="hljs-keyword">log</span></span> document_type: production fields: <span class="hljs-keyword"><span class="hljs-keyword">format</span></span>: <span class="hljs-type"><span class="hljs-type">json</span></span> es_index_name: production es_document_type: production.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span> - paths: - /home/appuser/app/error.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span>.json input_type: <span class="hljs-keyword"><span class="hljs-keyword">log</span></span> document_type: production fields: <span class="hljs-keyword"><span class="hljs-keyword">format</span></span>: <span class="hljs-type"><span class="hljs-type">json</span></span> es_index_name: production es_document_type: production.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span> - paths: - /home/appuser/app/<span class="hljs-keyword"><span class="hljs-keyword">log</span></span>/nginx.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span> input_type: <span class="hljs-keyword"><span class="hljs-keyword">log</span></span> document_type: nginx fields: <span class="hljs-keyword"><span class="hljs-keyword">format</span></span>: nginx es_index_name: nginx es_document_type: nginx.<span class="hljs-keyword"><span class="hljs-keyword">log</span></span> registry_file: /var/lib/filebeat/registry output: logstash: hosts: ["kibana-server:5044"] shipper: <span class="hljs-type"><span class="hljs-type">name</span></span>: ukit tags: ["prod"] logging: files: rotateeverybytes: <span class="hljs-number"><span class="hljs-number">10485760</span></span> # = <span class="hljs-number"><span class="hljs-number">10</span></span>MB</code> </pre> <br></div></div><br><br>  <b>logstash</b> <br><div class="spoiler">  <b class="spoiler_title">logstash-listener / 01-beats-input.conf:</b> <div class="spoiler_text"><pre> <code class="javascript hljs">input { beats { port =&gt; <span class="hljs-number"><span class="hljs-number">5044</span></span> } }</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">logstash-listener / 30-rabbit-output.conf:</b> <div class="spoiler_text"><pre> <code class="javascript hljs">output { rabbitmq { exchange =&gt; <span class="hljs-string"><span class="hljs-string">"logstash-rabbitmq"</span></span> exchange_type =&gt; <span class="hljs-string"><span class="hljs-string">"direct"</span></span> key =&gt; <span class="hljs-string"><span class="hljs-string">"logstash-key"</span></span> host =&gt; <span class="hljs-string"><span class="hljs-string">"localhost"</span></span> port =&gt; <span class="hljs-number"><span class="hljs-number">5672</span></span> workers =&gt; <span class="hljs-number"><span class="hljs-number">4</span></span> durable =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span> persistent =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span> } }</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">logstash-indexer / 01-rabbit-input.conf:</b> <div class="spoiler_text"><pre> <code class="javascript hljs">input { rabbitmq { host =&gt; <span class="hljs-string"><span class="hljs-string">"localhost"</span></span> queue =&gt; <span class="hljs-string"><span class="hljs-string">"logstash-queue"</span></span> durable =&gt; <span class="hljs-literal"><span class="hljs-literal">true</span></span> key =&gt; <span class="hljs-string"><span class="hljs-string">"logstash-key"</span></span> exchange =&gt; <span class="hljs-string"><span class="hljs-string">"logstash-rabbitmq"</span></span> threads =&gt; <span class="hljs-number"><span class="hljs-number">4</span></span> prefetch_count =&gt; <span class="hljs-number"><span class="hljs-number">50</span></span> port =&gt; <span class="hljs-number"><span class="hljs-number">5672</span></span> } }</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">logstash-indexer / 09-filter.conf:</b> <div class="spoiler_text">  Depending on the format, we run it through the appropriate codec. <br><br>  In the case of nginx, these will be such ‚Äúunusual‚Äù regular semi-finished products offered by the ‚Äúgrok‚Äù filter module (left), and the names of the fields into which the matched data will fall (right).  For greater beauty, we also have a geoip filter, which determines the location of the client.  In Kibana, it will be possible to make "geography" of clients.  Base download from here <a href="http://dev.maxmind.com/geoip/legacy/geolite">dev.maxmind.com/geoip/legacy/geolite</a> . <br><br>  And in the case of json, as you see, you don‚Äôt need to do anything at all, which is good news. <br><br><pre> <code class="javascript hljs">filter { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [fields][format] == <span class="hljs-string"><span class="hljs-string">"nginx"</span></span> { grok { match =&gt; [ <span class="hljs-string"><span class="hljs-string">"message"</span></span>, <span class="hljs-string"><span class="hljs-string">"%{IPORHOST:clientip} - \[%{HTTPDATE:timestamp}\] %{IPORHOST:domain} \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:status:int} (?:%{NUMBER:bytes:int}|-) %{QS:referrer} %{QS:agent} %{NUMBER:request_time:float} (?:%{NUMBER:upstream_time:float}|-)( %{UUID:request_id})?"</span></span> ] } date { locale =&gt; <span class="hljs-string"><span class="hljs-string">"en"</span></span> match =&gt; [ <span class="hljs-string"><span class="hljs-string">"timestamp"</span></span> , <span class="hljs-string"><span class="hljs-string">"dd/MMM/YYYY:HH:mm:ss Z"</span></span> ] } geoip { source =&gt; <span class="hljs-string"><span class="hljs-string">"clientip"</span></span> database =&gt; <span class="hljs-string"><span class="hljs-string">"/opt/logstash/geoip/GeoLiteCity.dat"</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [fields][format] == <span class="hljs-string"><span class="hljs-string">"json"</span></span> { json { source =&gt; <span class="hljs-string"><span class="hljs-string">"message"</span></span> } } }</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">logstash-indexer / 30-elasticsearch-output.conf:</b> <div class="spoiler_text">  The index name and document_type for ES are taken from the fields, which at the very beginning of the path were pasted to the messages in the filebeat. <br><br><pre> <code class="javascript hljs">output { elasticsearch { hosts =&gt; [<span class="hljs-string"><span class="hljs-string">"localhost:9200"</span></span>] index =&gt; <span class="hljs-string"><span class="hljs-string">"logstash-%{[fields][es_index_name]}-%{+YYYY.MM.dd}"</span></span> document_type =&gt; <span class="hljs-string"><span class="hljs-string">"%{[fields][es_document_type]}"</span></span> } }</code> </pre><br></div></div><br><br><h4>  <b>Linking events in front and back logs</b> </h4><br><h5>  Outline: </h5><br><blockquote>  <i>‚ÄúWe had 2 types of logs, 5 services in a stack, a half-byte of data in ES, as well as an uncountable set of fields in the application logs.</i>  <i>Not that it was a necessary set for real-time analysis of the state of the service, but when you start thinking more about linking nginx and application events, it becomes difficult to stop.</i> <i><br><br></i>  <i>My only concern was Lua.</i>  <i>There is nothing more helpless, irresponsible and vicious than Lua in Nginx configs.</i>  <i>I knew that sooner or later we will move on to this rubbish. ‚Äù</i> </blockquote><br><img src="https://habrastorage.org/files/211/22a/7fb/21122a7fbd054d51a740c100f6c31c03.png"><br><br>  To generate the request-id on Nginx, we will use a Lua-library that generates uuid-s.  In general, it does its job, but it had to be slightly modified with a file - for in its original form it is (ta-dam!) Duplicate uuid-s. <br><br><pre> <code class="nginx hljs"><span class="hljs-section"><span class="hljs-section">http</span></span> { ... <span class="hljs-comment"><span class="hljs-comment">#      lua_package_path '/etc/nginx/lua/uuid4.lua'; init_worker_by_lua ' uuid4 = require "uuid4" math = require "math" '; ... #   request_id, #   (set $var)      http map $host $request_uuid { default ''; } #    log_format ukit '$remote_addr - [$time_local] $host "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $request_time ' '$upstream_response_time $request_uuid'; #       access_log /home/appuser/app/log/nginx.log ukit; } server { ... #  id  set_by_lua $request_uuid ' if ngx.var.http_x_request_id == nil then return uuid4.getUUID() else return ngx.var.http_x_request_id end '; #       ,       . location @backend { proxy_pass http://127.0.0.1:$app_port; proxy_redirect http://127.0.0.1:$app_port http://$host; proxy_http_version 1.1; proxy_set_header Connection ""; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Nginx-Request-ID $request_uuid; #id  proxy_set_header Host $host; ... } ... }</span></span></code> </pre><br><br>  At the output, we are able to find the request that arrives to Nginx by an event in the application log.  And vice versa. <br><br>  It was quickly discovered that our <a href="https://ru.wikipedia.org/wiki/UUID">‚Äúuniverse-unique‚Äù</a> IDs are not that unique.  The fact is that the randomseed library is taken from the timestamp at the time of the start of the nginx worker.  And we have as many workers as the cores of the processor, and they are launched at the same time ... It doesn't matter!  Let's add the worker's pid there and we will be happy: <br><br><pre> <code class="lua hljs">... <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> M = {} <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> pid = ngx.worker.pid() <span class="hljs-comment"><span class="hljs-comment">----- math.randomseed( pid + os.time() ) math.random() ...</span></span></code> </pre><br>  PS The Debian repository has the nginx-extras package ready.  Immediately there is Lua and a bunch of useful modules.  I recommend, instead of compiling the Lua module with my hands (it is still openresty, but I have not tried it). <br><br><h4>  <b>Grouping errors by frequency of occurrence.</b> </h4><br>  Kibana allows you to group (build ratings) events based on the same field values. <br><br>  In the error log, we have stackracks, they are almost perfect as a grouping key, but the snag is that in Kibana you cannot group by keys longer than 256 characters, and stacks are certainly longer.  Therefore, we make md5 hashes of stackrays in bunyan and group them already.  Beauty! <br><br>  This is what the top 20 errors look like: <br><img src="https://habrastorage.org/files/114/d9f/654/114d9f654f6641d8ae46f5912789ba64.png"><br><br>  And a single type of error on the chart and the list of episodes: <br><img src="https://habrastorage.org/files/39a/2e0/c58/39a2e0c5839b4767ac37352d5d3a9c69.png"><br><br>  Now we know which bug in the system can be fixed sometime later, because  he is too rare.  Agree, such an approach is much more scientific than ‚Äúthere were many similar support tickets for this week‚Äù. <br><br><h4>  <b>And now - the disruption of covers: it works, but bad</b> </h4><br><h5>  The climax: </h5><br><blockquote>  <i>"I understand.</i>  <i>You found paradise in NoSQL: you were developing quickly, because you kept everything in MongoDB, and you didn‚Äôt need friends like me.</i>  <i>And now, you come and say: I need a search.</i>  <i>But you do not ask with respect, you do not even call me the Best Search Engine.</i>  <i>No, you come to my house on <a href="https://en.wikipedia.org/wiki/Elasticsearch">Lucene's</a> birthday and ask me to index unstructured logs for free. ‚Äù</i> </blockquote><br><img src="https://habrastorage.org/files/cb5/420/87e/cb542087eb7d4942b8dd3a98b94010d5.png"><br><br><h5>  <b>Surprises</b> </h5><br><h6>  <b>Do all messages from the log fall into Kibana?</b> </h6><br>  Not.  Not all fall. <br><br>  Mapping remembers the name of the field and its type (number, string, array, object, etc.).  If we send a message to ES, in which there is a field that already exists in the mapping, but the type does not match what was in this field before (for example, in the mapping - an array, but the object came), then such a message will not fall into ES , and in its log there will be a not too obvious message: <br><br>  {"Error": "MappedParcingException [object] mapping for [something] tried <br>  <a href="http://blog.endpoint.com/2013/04/elasticsearch-object-mapping-eof-400.html">A source</a> <br><br><h6>  <b>Field names in json logs</b> </h6><br>  Elasticsearch v2.x does not accept messages in which there are fields whose names contain dots.  In v1.x there was no such restriction, and we cannot switch to the new version without redoing all the logs, since  we have such fields are "historically". <br>  <a href="https://discuss.elastic.co/t/field-name-cannot-contain/33251">A source</a> <br><br>  In addition, Kibana does not support fields whose names begin with an underscore '_'. <br><img src="https://habrastorage.org/files/51d/b18/660/51db18660c944ed7a28b39c1675dad8e.png"><br><br>  <a href="https://github.com/elastic/kibana/issues/2551">Developer Comment</a> <br><br><h6>  <b>Automatic data crawling to neighboring ES instances</b> </h6><br>  By default, the Zen Discovery option is enabled in ES.  Thanks to it, if you run several ES instances on the same network (for example, several docker containers on the same host), they will find each other and share the data among themselves.  A very convenient way to mix productive and test data and deal with it for a long time. <br><br><h6>  <b>It falls and then rises for a long time.</b>  <b>This is even more painful when the docker</b> </h6><br><br>  The stack of demons involved in our criminal scheme is quite numerous.  In addition, some of them like to fall incomprehensibly and go up for a very long time (yes, those in Java).  Most often logstash-indexer hangs, in the logs there is silence or unsuccessful attempts to send data to ES (it can be seen that they were long ago, and not just that).  The process is alive, if you send it a kill - it dies for a very long time.  You have to send kill -9 if you have no time to wait. <br><br>  Less often, but it also happens that Elasticsearch is falling.  He does it ‚Äúin English‚Äù (i.e. silently). <br><br>  In order to understand which of the two of them fell, we make an http-request in ES - if answered, then it‚Äôs not him.  In addition, when you have relatively a lot of data (say, 500G), then your Elasticsearch will start to siphon this data for about half an hour after launch, and at that time it will be unavailable.  The data of Kibana itself is stored there, so it also does not work until its index is picked up.  According to the law of meanness, it usually turns to the very end. <br><br>  It is necessary to monitor by monitoring the queue length in rabbitmq in order to quickly respond to incidents.  Once a week they happen to be stable. <br><br>  And when you have everything in the docker, and the containers are linked together, then you need to restart also all the containers that were linked to the ES container, except for himself. <br><br><h6>  <b>Large memory dumps with OOM</b> </h6><br>  By default, the HeapDumpOnOutOfMemoryError option is enabled in ES.  This can lead to the fact that you have unexpectedly run out of disk space due to one or several ~ 30GB dumps.  Of course, they are dumped into the directory where the binaries are located (and not where the data is).  This happens quickly, monitoring does not even have time to send SMS.  You can disable this behavior in bin / elasticsearch.in.sh. <br><br><h4>  <b>Performance</b> </h4><br>  In Elasticsearch there is a so-called.  ‚ÄúMapping‚Äù indexes.  In essence, this is a table schema in which data is stored in the format ‚Äúfield - type‚Äù.  It is created automatically based on the incoming data.  This means that ES will remember the name and data type of the field, based on what type of data came in this field for the first time. <br><br>  For example, we have 2 very different logs: access-log nginx and production-log nodejs-applications.  In one standard set of fields, it is short, data types never change.  In the other, on the contrary, there are many fields, they are nested, they are different for each line of the log, the names can intersect, the data inside the fields can be of different types, the length of the line reaches 3 or more MB.  As a result, ES auto-mapping does this: <br><br>  <b>Mapping the <s>healthy</s> ‚Äúrectangular‚Äù nginx log:</b> <br>  root @ localhost: /&gt; du -h ./nginx.mapping <br>  16K ./nginx.mapping <br><br>  <b>Mapping the <s>smoker of the</s> ‚Äúshapeless‚Äù json-log of our application:</b> <br>  root @ localhost: /&gt; du -h ./prodlog.mapping <br>  2.1M ./prodlog.mapping <br><br>  In general, it greatly slows down both when indexing data and when searching through Kibana.  In this case, the more accumulated data, the worse. <br><br>  We tried to deal with this closure of old indices with <a href="https://github.com/elastic/curator">curator</a> .  The positive effect is certainly there, but still it is anesthesia, not a treatment. <br><br>  <b>Therefore, we came up with a more radical solution.</b>  All heavy nested-json in the production-log will now be logged as a string in a special <u>single</u> message field.  Those.  here is straight JSON.stringify ().  Due to this, the set of fields in the messages becomes fixed and short, we arrive at a ‚Äúlight‚Äù mapping like that of the nginx log. <br><br>  Of course, this is a kind of ‚Äúamputation with further prosthetics,‚Äù but the option is working.  It will be interesting to see in the comments how else you could have done. <br><br><h4>  <b>Subtotal</b> </h4><br>  Stack ELK is a cool tool.  For us, it has become simply indispensable.  Managers watch the bursts of errors on the front-end after the next release and come to complain to the developers already ‚Äúnot empty-handed‚Äù.  Those, in turn, find correlations with errors in the application, immediately see their stacks and other important data necessary for debag.  It is possible to instantly build various reports from the series ‚Äúhits by site domains‚Äù, etc.  In a word, it is not clear how we lived before.  But in other way‚Ä¶ <br><br>  ‚ÄúRobust, Reliable, Predictable‚Äù - all this is not about ELK.  The system is very capricious and rich in unpleasant surprises.  Very often you have to dig in all this shaky, sorry, Jav-no.  Personally, I can not remember the technology that would so badly follow the principle of "set up and forget." <br><br>  <b>Therefore, over the past 2 months,</b> we completely redid the application logs.  As in terms of format (we get rid of dots in names, in order to switch to ES v.2), so in terms of approach to what is generally logged and what is not.  By itself, this process, IMHO, is absolutely normal and logical for a project such as ours - recently, <a href="https://ukit.com/">uKit</a> celebrated its first birthday. <br><br>  ‚ÄúAt the beginning of the way you dump as much information as possible into the logs, since  it is not known in advance what will be needed, and then, having begun to ‚Äúgrow up,‚Äù gradually remove the excess. ‚Äù  (c. <a href="https://habrahabr.ru/users/pavel_kudinov/" class="user_link">pavel_kudinov</a> ) </div><p>Source: <a href="https://habr.com/ru/post/278729/">https://habr.com/ru/post/278729/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../278705/index.html">AMD fixes microprocessor microcode vulnerability</a></li>
<li><a href="../278709/index.html">Conferences in 3CX Phone System</a></li>
<li><a href="../278711/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ201 (March 1 - 6, 2016)</a></li>
<li><a href="../278713/index.html">Everything you need to know about Unity 5, UWP applications and March 8</a></li>
<li><a href="../278725/index.html">First extortionist discovered for Apple OS X</a></li>
<li><a href="../278731/index.html">Choosing a library to work with WebGL</a></li>
<li><a href="../278735/index.html">Ruby on Rails. Passenger quickstart</a></li>
<li><a href="../278737/index.html">The story about cunning ... Indian, encrypted procedures, DAC and "God mode"</a></li>
<li><a href="../278741/index.html">Gorgeous Six: girls who had a thermonuclear blast counted</a></li>
<li><a href="../278743/index.html">django-controlcenter</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>