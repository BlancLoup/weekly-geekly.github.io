<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Is it possible to teach artificial intelligence to joke?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, the machines have won a series of convincing victories over people: they already play better go, chess, and even Dota 2. Algorithms compose ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Is it possible to teach artificial intelligence to joke?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/rj/0u/gc/rj0ugcktrejtijlijarst0nndk4.jpeg" align="left" width="350" height="370" alt="image">  Recently, the machines have won a series of convincing victories over people: they already play better go, chess, and even Dota 2. Algorithms compose music and write poetry.  Scientists and entrepreneurs around the world make predictions about the future, in which artificial intelligence will far surpass the person.  With a high probability in a few decades, we will live in a world in which robots not only drive cars and work in factories, but also entertain us.  One of the important components of our life is humor.  It is believed that only a person can make jokes.  Despite this, many scientists, engineers, and even ordinary townsfolk wonder: can you teach a computer to joke? <br><br>  The company <a href="http://gentleminds.io/">Gentleminds</a> , the developer of machine learning and computer vision systems, together with FunCorp, tried to create a generator of funny image captions using the iFunny meme database.  Since the application is English-language and is used primarily in the United States, the signatures will be in English.  Details under the cut. <br><a name="habracut"></a><br>  In contrast to the composition of music, in which there are laws of harmony, the nature of what makes us laugh is very difficult to describe.  Sometimes we ourselves can hardly explain what made us laugh.  Many researchers believe that a sense of humor is one of the last frontiers that artificial intelligence must overcome in order to get as close as possible to a person.  <a href="http://elementy.ru/novosti_nauki/430947/Chuvstvo_yumora_i_shchedrost_rezultaty_polovogo_otbora">Studies</a> show that a sense of humor was formed in people for a long time under the influence of sexual selection.  This can be explained by the fact that there is a positive correlation between intelligence and a sense of humor.  Even now, in our understanding, humor is a good marker of human intelligence.  The ability to joke includes such complex elements as skillful language skills and horizons.  After all, language proficiency is important for certain types of humor (for example, British), which are largely based on a play on words.  In general, teaching an algorithm to joke is not an easy task. <br><br>  Researchers from around the world have tried to teach a computer to make jokes.  So, Janelle Shane created a neural network that writes jokes like ‚ÄúKnock, knock!‚Äù  Who is there? ‚Äù(Knock-knock jokes).  For training this network, a data set of 200 knock-knock jokes was used.  On the one hand, this is a fairly simple task for AI, since all the jokes in this set have the same structure.  On the other hand, the neural network simply finds associations between words in a small set of source data and does not give these words any meaning.  The result is a joke, sharpened under the same pattern, which in most cases can hardly be called ridiculous. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In turn, researchers from the University of Edinburgh <a href="http://homepages.inf.ed.ac.uk/s0894589/petrovic13unsupervised.pdf">presented a</a> successful method of teaching computer jokes I like my X like I like my Y, Z. The main contribution of this work is the creation of the first fully unsupervised humor generation system.  The resulting model is significantly superior to the base and generates funny jokes that are considered funny by people in 16% of cases.  The authors use only a large amount of unpartitioned data, and this indicates that generating a joke does not always require deep semantic understanding. <br><br>  Scientists from the University of Washington have created a <a href="http://people.cs.umass.edu/~brun/pubs/pubs/Kiddon11.pdf">system</a> that can come up with vulgar jokes on a pattern that's what she said - TWSS (literally: that's what she said; it can be translated into Russian as ‚Äúif you know what I mean‚Äù).  ‚ÄúThat's what she said.‚Äù This is a well-known group of jokes that has become popular again after the series The Office.  The task of TWSS is a problem with two distinctive characteristics: first, the use of nouns, which are euphemisms for the overtly sexual nature of nouns, and, second, ambiguity.  For the TWSS solution, the system was used Double Entendre via Noun Transfer (DEviaNT).  As a result, in 72% of cases, the DEviaNT system knew when to say ‚Äúthat's what she said ‚Äî a great achievement for this type of natural language program. <br><br>  The authors of the <a href="https://web.stanford.edu/class/cs224n/reports/2760332.pdf">article</a> present a model for generating jokes based on neural networks.  The model can generate a short joke related to a previously specified topic.  An encoder is used to represent the user's theme information and an RNN decoder to generate jokes.  The model is trained in short Conan Christopher O'Brien jokes using the POS Tagger.  Quality was evaluated by five English-speaking people.  On average, this model is superior to the probabilistic, trained writing of jokes of a fixed structure (the approach described above from the University of Edinburgh). <br><br>  Researchers from Microsoft also <a href="http://erichorvitz.com/phumor.pdf">tried to</a> teach the computer to joke.  Using The New Yorker cartoon contest as data for training, they developed an algorithm for choosing from thousands of the funniest inscriptions provided by readers. <br>  As you can see from all the above examples, to teach the car to joke is not an easy task.  Moreover, it does not have a universal quality metric, since everyone can perceive the same joke differently.  And the very wording ‚Äúto invent a funny joke‚Äù does not look concrete. <br><br>  In our experiment, we decided to ease the task a bit and add a context - an image.  The system needed to come up with a funny signature to it.  But, on the other hand, the task became a bit more complicated, as one more space was added and it was required to teach the algorithm to compare text and a picture. <br>  The task of creating a funny picture caption can be reduced to choosing the right one from the existing base or generating a new caption using any method.  In this experiment, we tried both approaches. <br><br>  We relied on a base provided by iFunny.  There were 17,000 memes in it, which we divided into two components: a picture and a signature.  We used only memes, in which the text was located strictly above the picture: <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/31/hj/hb/31hjhbvnwtitmfsxmact9ijnjnw.png" width="350" height="320" alt="image"></div><br>  We tried two approaches: <br><br><ul><li>  signature generation (in one case by a Markov chain, in the other by a recurrent neural network); </li><li>  selection of the most suitable image for the image from the database.  It was carried out on the basis of the visual component.  In the first approach, images were searched for a signature inside the clusters built on the basis of memes.  In the Word2VisualVec approach, which in this paper was called Membedding, we tried to transfer images and text into one vector space, in which the relevant caption would be close to the image. </li></ul><br>  The approaches below are described in more detail. <br><br><h3>  Base analysis </h3><br>  Any study in machine learning always begins with data analysis.  First of all, I wanted to understand what kind of images are contained in the database.  Using a classification network trained at <a href="https://github.com/openimages/dataset">https://github.com/openimages/dataset</a> , for each image we obtained a vector with ratings for each category and made a clustering based on these vectors.  Selected 5 large groups: <br><br><ol><li>  People. </li><li>  Food. </li><li>  Animals </li><li>  Cars. </li><li>  Animation. </li></ol><br>  The results of clustering were later used in the construction of the basic solution. <br><br>  To assess the quality of the experiments, a test base of 50 images was collected that covered the main categories.  Quality was evaluated by ‚Äúexpert‚Äù advice, determining whether it is funny or not. <br><br><h3>  Search by cluster </h3><br>  The approach was based on determining the cluster closest to the picture in which the signature was chosen randomly.  The image descriptor was determined using a categorization neural network.  We used 5 clusters, selected earlier, using the k-means algorithm: people, food, animals, animation, cars. <br>  Examples of the results are shown below.  Since the clusters were quite large, and the contents in them could still differ greatly in meaning, the number of phrases suitable for the picture was approximately 1 to 5 in relation to inappropriate. It may seem that this was due to the fact that the clusters were 5, but in fact, even if the cluster was determined correctly, there are still a large number of unsuitable signatures inside it. <br><table><tbody><tr><td rowspan="4" width="390"><img src="https://habrastorage.org/webt/nj/rv/pn/njrvpn-ygteqzrtcygmp0bt2ctc.jpeg" width="390" height="230"></td><td>  Me buying food vs Me buying textbooks </td></tr><tr><td>  Boss: It says here that you love science <br>  Guy: Ya, I love to experiment <br>  Boss: What do you experiment with? <br>  Guy: Mostly just drugs and alcohol </td></tr><tr><td>  Cop: Did you get a good look at the suspect? <br>  Guy: Yes <br>  Cop: Was it a man or a woman? <br>  Guy: I don‚Äôt know them </td></tr><tr><td>  hillary: why didn't you tell me they were <br>  reopening the investigation? <br>  obama: bitch we emailed you </td></tr></tbody></table><br><table><tbody><tr><td rowspan="4" width="390"><img src="https://habrastorage.org/webt/d_/p0/7p/d_p07phiqnq4wtbo0sbmofpqc1k.jpeg" width="390" height="230"></td><td>  "Ma'am do you have a permit for this <br>  business " <br>  Girl: does it look like I'm selling fucking donuts ?! </td></tr><tr><td>  For a couple of days because their queen was trapped inside the car. </td></tr><tr><td>  I found the guy in those problems with all the watermelons ... </td></tr><tr><td>  So that's what those orange cones were for </td></tr></tbody></table><br><br><h3>  Search by visual similarity </h3><br>  An attempt at clustering suggested that we should try to narrow down the search space.  And if the clusters within themselves remained very diverse, then the search for a picture that most closely resembles the incoming one could bring results.  As part of this experiment, we still used a neural network trained in 7880 categories.  At the first stage, we passed through the network all the images and saved the top 5 rated categories, as well as the values ‚Äã‚Äãfrom the penultimate layer (it stores both visual information and information about categories).  At the stage of searching for the caption for the picture, we received 5 best categories and looked for images with the most similar categories throughout the database.  Of these, we took the 10 nearest, and from this set randomly chose a signature.  Also, an experiment was conducted to search for values ‚Äã‚Äãfrom the last but one layer of the network.  The results of both methods were similar.  On average, 1-2 successful signatures accounted for 5 unsuccessful.  This may be due to the fact that in the caption for visually similar photos of people, a lot of people played emotions in the photo and the situation itself.  Examples are given below. <br><table><tbody><tr><td rowspan="4" width="390"><img src="https://habrastorage.org/webt/nj/rv/pn/njrvpn-ygteqzrtcygmp0bt2ctc.jpeg" width="390" height="230"></td><td>  Me buying food vs Me buying textbooks </td></tr><tr><td>  Don't Act Like You Know <br>  Politics If You Don't <br>  Know Who This Is Q </td></tr><tr><td>  when u tell a joke and no one else laughs </td></tr><tr><td>  When good looking people have no sense of humor <br>  #whatawaste </td></tr></tbody></table><br><table><tbody><tr><td rowspan="5" width="390"><img src="https://habrastorage.org/webt/d_/p0/7p/d_p07phiqnq4wtbo0sbmofpqc1k.jpeg" width="390" height="230"></td><td>  Assholes, meet your king. </td></tr><tr><td>  Free my boy </td></tr><tr><td>  I guess they didn't read the license <br>  plate </td></tr><tr><td>  When someone starts telling you how <br>  to drive from the backseat </td></tr></tbody></table><br><br><h3>  Membedding, or finding the most appropriate signature by casting the image descriptor into the vector space of text descriptors </h3><br>  The purpose of the construction of Membedding is a space in which the vectors of interest to us would be ‚Äúclose‚Äù.  Let's try the approach from the Word2VisualVec <a href="https://arxiv.org/pdf/1604.06838.pdf">article</a> . <br><br>  We have pictures and captions for them.  We want to find text that is ‚Äúclose‚Äù to the image.  In order to solve this problem, we need: <br><br><ol><li>  construct a vector describing the image; </li><li>  construct a vector describing the text; </li><li>  construct a vector space with the desired properties (the text vector is ‚Äúclose‚Äù to the image vector). </li></ol><br>  To build a vector describing the image, we use the neural network pre-trained for 6000+ classes <a href="https://github.com/openimages/dataset">https://github.com/openimages/dataset</a> .  As a vector, we will take the output from the last but one layer of this network of dimension 2048. <br><br>  Two approaches were used to vectorize the text: Bag Of Words and Word2Vec.  Word2Vec was trained in words from all the image captions.  The signature was transformed as follows: each word of the text was translated into a vector using <a href="https://ru.wikipedia.org/wiki/Word2vec">Word2Vec</a> , and then the common vector was found according to the arithmetic mean rule - the average vector.  Thus, an image was fed to the input of the neural network, and the average vector was predicted at the output.  To ‚Äúembed‚Äù text vectors into the vector space of image descriptors, a three-layer fully connected neural network was used. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pj/gw/qk/pjgwqk1eu4ax7p5snkfafxegmaw.png" width="602" height="119" alt="Scheme"></div><br>  With the help of a trained neural network, we calculate the vectors for the base of signatures. <br>  Then, using the convolutional neural network, we obtain a descriptor to search for the image caption and look for the vector of signatures closest in cosine distance.  You can choose the closest, you can randomly from n closest. <br><table><tbody><tr><th>  Good examples </th><th>  Bad examples </th></tr><tr><td>  How do you show up to your ex's funeral <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/d_/p0/7p/d_p07phiqnq4wtbo0sbmofpqc1k.jpeg" width="250"></div></td><td>  Being a teacher in 2018 summed up in one image. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-x/rw/2y/-xrw2ykfl-wkrs04495gik_v4zy.jpeg" width="200" height="250"></div></td></tr><tr><td>  You shall not pass me <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8u/u_/34/8uu_34rc76jn6lux8pq5s4kqq8c.jpeg" width="200" height="250"></div></td><td>  Me: Be careful closing the door Passenger: <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kg/cf/pn/kgcfpnoyi5qs6aloxz_lsti4ud4.jpeg" width="250"></div></td></tr></tbody></table><br><br>  To build a vector using the Bag of Words method that describes the text, we use the following method: calculate the frequency of three-letter combinations in the captions, discard those that occur less than three times, and compose a dictionary of the remaining combinations. <br>  To convert text into a vector, we calculate the number of occurrences of three-letter combinations from the dictionary in the text.  We obtain a vector of dimension 5322. <br>  Result (5 "closest" signatures): <br><table><tbody><tr><td rowspan="4" width="390"><img src="https://habrastorage.org/webt/nj/rv/pn/njrvpn-ygteqzrtcygmp0bt2ctc.jpeg" width="390" height="230"></td><td>  When she sends you </td></tr><tr><td>  when ur enjoying the warm <br>  weather in december but deep <br>  down u know this because of <br>  global warming </td></tr><tr><td>  The stress of not winning an oscar <br>  beginning to take its toll on Leo </td></tr><tr><td>  Dear God, please make our the next <br>  American president as strong as this <br>  yellow button.  Amen. </td></tr></tbody></table><br><table><tbody><tr><td rowspan="4" width="390"><div style="text-align:center;"><img src="https://habrastorage.org/webt/l0/-e/wj/l0-ewju_tsgnr8fds4mogdzakxo.jpeg" width="200" height="300"></div></td><td>  My laptop is set up <br>  incorrect password attempts. </td></tr><tr><td>  My cat isn't thrilled with his new bird saving bib ... </td></tr><tr><td>  jokebud <br>  tell your cat ‚Äúhe‚Äù sa fucking pussy ‚Äù </td></tr><tr><td>  This cat looks just like Kylo Ren from Star Wars </td></tr></tbody></table><br><table><tbody><tr><td rowspan="4" width="390"><div style="text-align:center;"><img src="https://habrastorage.org/webt/3e/vo/vu/3evovufsqe38nvkzemh8zcfmvow.jpeg" width="180" height="260"></div></td><td>  Ugly guys winning bruh QC </td></tr><tr><td>  Single mom dresses as dad so her <br>  son wouldn't miss "Donuts With Dad" <br>  day at school </td></tr><tr><td>  Steak man gotta relax .... </td></tr><tr><td>  My friend went to prom with two dates. <br>  It didn't go as planned ... </td></tr></tbody></table><br>  For similar images, the captions are almost the same: <br><table><tbody><tr><td rowspan="3" width="390"><div style="text-align:center;"><img src="https://habrastorage.org/webt/z0/je/pz/z0jepzyms4qoufdb09okcah0g34.jpeg" width="350" height="260"></div></td><td>  My girlfriend can take beautiful photos <br>  of our cat.  I seemingly can't ... </td></tr><tr><td>  My laptop is set up <br>  incorrect password attempts. </td></tr><tr><td>  This cat looks just like Kylo Ren from Star Wars </td></tr></tbody></table><br><table><tbody><tr><td rowspan="3" width="390"><div style="text-align:center;"><img src="https://habrastorage.org/webt/m8/qd/--/m8qd--dub1qxvgoegsjpnudjm94.jpeg" width="350" height="260"></div></td><td>  Cats constantly look at you like <br>  you just asked them for a ride to <br>  the airport </td></tr><tr><td>  My laptop is set up <br>  incorrect password attempts. </td></tr><tr><td>  Here's my cat, sitting on the best wedding gift we <br>  received a picture of a face on it ... </td></tr></tbody></table><br>  As a result, the ratio of successful examples to bad ones turned out to be approximately 1 to 10. This can most likely be explained by a small number of universal signatures, as well as by the presence in the training sample of a large percentage of memes, whose signature makes sense if the user has some prior knowledge. <br><br><h3>  Signature Generation: WordRNN Approach </h3><br>  The basis of this method is a two-layer recurrent neural network, each layer of which is an <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a> .  The main property of such networks is the ability to extrapolate time series, in which the next value depends on the previous one.  The signature, in turn, is such a temporary series. <br><br>  This network was trained to predict every next word in the text.  For the training sample was taken the entire body of signatures.  It was assumed that such a network would be able to learn to generate in some way meaningful or at least ridiculous because of its absurdity signatures. <br><br>  Only the first word was asked, the rest was generated.  The results were as follows: <br>  <b>The Trump</b> : The <b>Trump</b> <i>Cats</i> <br>  <b>Obama:</b> <i>obama LAUGHING dropping FAVORITE 4rd FAVORITE 4rd fucking long</i> <br>  <b>Asian:</b> <i>Asian RR II</i> <br>  <b>Cat:</b> <i>cat</i> <br>  <b>Car:</b> <i>Car Crispy ‚ÄúEmma: please" BUS 89% Starter be disappointed my pizza penises?</i> <br>  <i>Ppl</i> <br><br>  Contrary to expectations, the signatures obtained were rather a collection of words.  Although in some places the structure of sentences was rather well imitated and some pieces were meaningful. <br><br><h3>  Signature generation using Markov chains </h3><br>  <a href="https://ru.wikipedia.org/wiki/%25D0%25A6%25D0%25B5%25D0%25BF%25D1%258C_%25D0%259C%25D0%25B0%25D1%2580%25D0%25BA%25D0%25BE%25D0%25B2%25D0%25B0">Markov chains</a> are a popular approach to natural language modeling.  To build a Markov chain, the body of the text is divided into tokens, for example, words.  Groups of tokens are assigned as states and probabilities of transitions between them and the next word in the body of the text are calculated.  When generating, the next word is selected by sampling from the probability distribution obtained by analyzing the corpus. <br><br>  <a href="https://github.com/jsvine/markovify/tree/master/markovify">This library was</a> used for implementation, and signatures cleared of dialogues were used as a training base. <br>  New line - new signature. <br><br>  <b>Result (state - 2 words):</b> <br><br>  <i>when your homies told you m 90 to</i> <i><br><br></i>  <i>dwayne johnson &amp; the rock are twins.</i>  <i>it is a patriotic flag tan.</i> <i><br><br></i>  <i>tryna get your joke</i> <i><br><br></i>  <i>If you are not ready to go to work out</i>  <i>please don't be sewing supplies ...</i> <i><br><br></i>  <i>justin hanging with his legos</i> <i><br><br></i>  <i>It is 9h and calling weed</i> <i><br><br></i>  <i>texing a girl that can save meek</i> <br>  <b>Result (state - 3 words):</b> <br><br>  <i>for the answers for the homework</i> <i><br><br></i>  <i>when u ugly so u gotta get creative</i> <i><br><br></i>  <i>my dog ‚Äã‚Äãis gonna die</i> <i><br><br></i>  <i>when you hear a song</i> <i><br><br></i>  <i>your girl goes out and you actually cleaned</i> <i><br><br></i>  <i>chuck voted for prom queen 150 times and you decide to start making healthier choices.</i> <i><br><br></i>  <i>there are more on the stove</i> <i><br><br></i>  <i>when you see your passcode</i> <br><br>  In the state with three words, the text is more meaningful than with two, but it is hardly suitable for direct use.  Probably, it can be used to generate signatures followed by human moderation. <br><br><h3>  Instead of conclusion </h3><br>  Teaching an algorithm to write jokes is an incredibly difficult task, but very interesting.  Her decision will make the intellectual assistants more "human".  As an example, you can imagine a robot from the film ‚ÄúInterstellar‚Äù, whose humor level would be regulated, and jokes would be unpredictable, unlike current versions of helpers. <br><br>  In general, after all the experiments listed above, the following conclusions can be made: <br><br><ol><li>  The approach, consisting in the generation of signatures, requires a very complex and time-consuming work with the body of the text, the method of teaching, the architecture of the model;  Also in this approach it is very difficult to predict the result. </li><li>  More predictable in terms of results is the approach with the selection of the signature from the existing database.  But it is fraught with difficulties: <br><br><ul><li>  memes, the meaning of which can be understood only with a priori information.  Such memes are difficult to separate from the rest, and if they fall into the base, the quality of the jokes will decrease; </li><li>  memes in which you need to understand what is happening in the picture: what action, what situation.  Such memes, again, getting into the base, reduce the quality. </li></ul></li><li>  From an engineering point of view, it seems that at this stage a suitable solution is a careful selection of phrases by the editorial team under the most popular categories.  These are selfies (as people usually check the system on themselves or on photos of friends and acquaintances), photos of celebrities (Trump, Putin, Kim Kardashian, etc.), pets, cars, food, nature.  You can also enter the category ‚Äúthe rest‚Äù and have prepared jokes in case the system did not recognize what is shown in the picture. </li></ol><br>  In general, today, artificial intelligence cannot generate jokes (although not all people cope with this), but it is quite possible to choose the right one.  We will follow the development of events and participate in them! </div><p>Source: <a href="https://habr.com/ru/post/351428/">https://habr.com/ru/post/351428/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../351416/index.html">TECO Editor: EMACS, I am your father</a></li>
<li><a href="../351418/index.html">FastTrack Training. "Network Basics". "Value of Collaboration Products from Cisco." Eddie Martin December 2012</a></li>
<li><a href="../351420/index.html">The digest of interesting materials for the mobile developer # 245 (March 12 - March 18)</a></li>
<li><a href="../351424/index.html">SNAP Issues: Incomplete Object Paradigm and Premature Typing</a></li>
<li><a href="../351426/index.html">Restore Microsoft Money online features. Quotes</a></li>
<li><a href="../351430/index.html">Auto Test Concepts</a></li>
<li><a href="../351432/index.html">Comparison of Material Design CSS frameworks</a></li>
<li><a href="../351434/index.html">Solving big problems with a small semantic analyzer</a></li>
<li><a href="../351436/index.html">Analysis of trends in the cryptocurrency market (for example, Bitcoin)</a></li>
<li><a href="../351438/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ306 (March 12 - 18, 2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>