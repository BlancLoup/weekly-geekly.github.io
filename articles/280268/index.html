<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Russian neural network chatbot</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="About chatbot using neural networks, I already wrote some time ago. Today I will talk about how I tried to make a full-scale Russian version. 



 Lea...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Russian neural network chatbot</h1><div class="post__text post__text-html js-mediator-article"> About chatbot using neural networks, I already wrote some time ago.  Today I will talk about how I tried to make a full-scale Russian version. <br><br><img src="https://habrastorage.org/files/d63/5b0/8a8/d635b08a866a4cb8bbe42e1701284df2.jpg"><br><br>  Learning interactive systems have recently gained unexpected popularity.  Unfortunately, all that has been done in the framework of neural network dialogue systems has been done for the English language.  But today we will fill this gap and teach the model to speak Russian. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><br>  <b>Method</b> <br>  I decided to start by rejecting the generation of the text word for word.  This is cool, but not as useful as it seems and is especially difficult for the Russian language with its large number of different word forms.  Instead, I decided to go by picking the right answer from a large base.  Those.  the task is to create a neural network that determines whether the proposal is the appropriate answer, given the context of the conversation, or not. <br><br>  Why is that: <br>  - You don‚Äôt need a big softmax layer to select words, which means we can allocate more resources to the neural network for the actual text analysis task. <br>  - The resulting matching model is suitable for different purposes, it is theoretically possible to force the chatbot to talk on various special topics, simply by downloading a new database of texts, without a new training.  This is useful in practice. <br>  - You can make a model that works quickly and can actually communicate with many users simultaneously without multiple GPUs on the server. <br><br>  <b>What for</b> <br>  In general, general thematic dialogue systems are useful, for example, in online consultants, so that the consultant can talk on topics unrelated to the main task, in games, and in a number of other tasks. <br><br>  <b>Why neural networks?</b> <br>  Is it possible to approach the task by a more classical method?  Download the answer set in the database and search the full-text index for the previous phrase?  The answer is, you can do it, but the result is not very good.  Here we assume: <br><br>  <i>H: hello!</i> <i><br></i>  <i>K: Greg, Maria, this is Ali ...</i> <i><br></i>  <i>H: how are you?</i> <i><br></i>  <i>To: from the next room received a complaint about the noise, monsieur</i> <i><br></i>  <i>Q: what is your name?</i> <i><br></i>  <i>K: thanks, thank you.</i> <i><br></i>  <i>Q: how old are you?</i> <i><br></i>  <i>K: Do you live somewhere near ...?</i> <br><br>  A search on a large base of answers gives many results, but their relevance is small, so the dialogues are of rather low quality.  This is where the neural network should help us - with its help we will sort out the good answers from the bad ones. <br><br>  <b>Where to get the data for training:</b> <br>  The most painful for many question.  Here and <a href="http://arxiv.org/abs/1510.03055">here,</a> people have taken a base of subtitles for movies.  Such a base is also for the Russian language, though smaller in size.  But the big trouble of this base is that there are a lot of monologues, different garbage in it, and it‚Äôs difficult to separate the dialogues from each other in general. <br><br>  Therefore, I decided to go the other way and, in addition to subtitles, to collect dialogues from publicly available books.  Novice writers and authors of all sorts of fan fiction created just an incredible amount of information, so it's a sin not to use it.  Of course, there is a lot of any nonsense.  In the course of work, I had to inevitably read this, and my head was puffy from the long conversations of some Sergei and Sailor Moon (to whom it had the same idea!).  But in general, this is a better base than subtitles, although gathering it is not so easy, you need to spend time. <br><br>  <b>Architecture</b> <br>  There is plenty of room for imagination.  I started with simple options and moved on to complex ones in order to understand the real benefits of various bells and whistles.  In the articles, people usually try to make cool and attach some new gadget, and due to the fact that the area is new, then the benefits of this are not always obvious. <br><br>  The simplest model takes a mix of a sequence of context and response word vectors and feeds it all onto an ordinary fully connected layer.  Since the answer is of different lengths, we write it in the vector of length fixed, filling the ‚Äúextra‚Äù place with zeros.  It is believed that this is bad.  We'll see. <br><br>  The second option is different in that before the context is ‚Äúmixed‚Äù and answered, they are given ‚Äútheir own‚Äù layer to form the presentation.  Well, then there may be several layers of processing, the figure shows two. <br><br>  The third option encodes a sequence of different lengths using a recurrent LSTM encoder.  It is a lot slower and learns longer.  But it seems like it should work better. <br><br><img src="https://habrastorage.org/files/972/3a0/d6d/9723a0d6d70047f3a936df6df8f05417.jpg"><br>  Fig.1.  Neural Network Architecture <br><br>  <b>results</b> <br>  According to the ability to choose the correct answer from several proposed options (randomly taken answers), the best result was shown by model number 2, with five layers for analyzing data on 700 neurons in each (+1 layer of representation of input data, also from 700 neurons).  To train such a deep network, I had to use Highway (Highway) layers, which allow information to spread from the lower layers to the upper layers easier, and also wait a few days while the model was calculated on the GPU.  Model number 1 was obviously under-educated, but number 3 thought for a long time, and also did not get to the results of model number 2 by a few percent.  Which reminds us that, although the simplest models are not suitable for large amounts of data, you should never multiply entities beyond necessity. <br><br>  The resulting system has a base of 30 million pairs of replicas, and the neural network has about 3 million trained parameters. <br><br>  What kind of dialogues can be obtained as a result? <br><br>  <i>D: Hi</i> <i><br></i>  <i>K: hi.</i> <i><br></i>  <i>W: How are you?</i> <i><br></i>  <i>K: I don't know.</i> <i><br></i>  <i>W: What is your name?</i> <i><br></i>  <i>K: my name is Unis.</i> <i><br></i>  <i>W: How old are you?</i> <i><br></i>  <i>K: Fifteen.</i> <i><br></i>  <i>Q: Where do you live?</i> <i><br></i>  <i>K: At home.</i> <i><br></i>  <i>Q: do you study at school?</i> <i><br></i>  <i>K: No</i> <i><br></i>  <i>W: and where do you study?</i> <i><br></i>  <i>K: in the Bundeswehr.</i> <i><br></i>  <i>Q: Do you like music?</i> <i><br></i>  <i>K: Yes, I love music.</i> <i><br></i>  <i>Q: What kind of music do you like?</i> <i><br></i>  <i>K: I mainly listen to r &amp; b, funk.</i> <i><br></i>  <i>D: Do you believe in god?</i> <i><br></i>  <i>K: I still believe in God, old man</i> <i><br></i>  <i>W: what is moral?</i> <i><br></i>  <i>K: two people together - isn't that moral?</i> <i><br></i>  <i>W: what color is the sea?</i> <i><br></i>  <i>To: the colors of the ocean after the storm.</i> <i><br></i> <br><br>  Good enough in my opinion.  Here is another example: <br><br>  <i>Ch: Where does hippo live?</i> <i><br></i>  <i>K: Lived</i> <i><br></i>  <i>Ch: and what, now does not live?</i> <i><br></i>  <i>K: I don't know.</i> <i><br></i>  <i>H: then where did he live before?</i> <i><br></i>  <i>K: at the park, on the Maple Street.</i> <i><br></i>  <i>Ch: where did he go?</i> <i><br></i>  <i>K: where is he gone?</i> <i><br></i>  <i>Q: I ask you, where is he gone?</i> <i><br></i>  <i>K: I do not understand why I am again in the hospital.</i> <i><br></i>  <i>H: because you are sick</i> <i><br></i>  <i>K: I just want to help people.</i> <i><br></i>  <i>Ch: Then tell me where the hippo is!</i> <i><br></i>  <i>K: why do you want to know this so much?</i> <i><br></i>  <i>H: just answer me</i> <i><br></i>  <i>Q: Do you want me to help you say goodbye to your relatives?</i> <i><br></i>  <i>W: Is it a threat?</i> <i><br></i>  <i>K: Observation</i> <i><br></i>  <i>Ch: So where is the hippo?</i> <i><br></i>  <i>K: he is in Hawaii, but the raj rules from here</i> <i><br></i>  <i>Q: Who is a raj?</i> <i><br></i>  <i>K: not met with him?</i> <i><br></i>  <i>D: No, never</i> <i><br></i>  <i>K: Once there was a husband and a wife, only the husband disappeared every night.</i> <br><br><div class="spoiler">  <b class="spoiler_title">How can you talk to this bot live?</b> <div class="spoiler_text">  I tried to make an android application that communicates with the server where the bot is located.  The application is raw, is in the testing stage, to install it you need to join the group of beta testers: <br>  <a href="https://plus.google.com/u/0/communities/103302070341792486151">plus.google.com/u/0/communities/103302070341792486151</a> <br><br>  After which you can install it with: <br>  <a href="">play.google.com/apps/testing/mindy.bot</a> <br><br>  PS <br>  currently the function of this application is research.  does not take money, does not show advertising.  While the application uses a simplified model, to reduce the load on the server. <br><br>  Pps <br>  If the model tries to communicate in English, just answer it in Russian, and she will correct her mistake. <br><br></div></div><br><br>  <b>Findings:</b> <br>  It turned out funny.  But you can still see the low quality of the training data.  For the development of the model it would be useful to collect more real-world dialogues.  Nevertheless, the results are encouraging, since in order to obtain fairly reasonable answers, it was not necessary to manually create any templates and rules for selecting answers. </div><p>Source: <a href="https://habr.com/ru/post/280268/">https://habr.com/ru/post/280268/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../280256/index.html">Wearable Smart Gateway - wearable device for emergency services</a></li>
<li><a href="../280258/index.html">The digest of interesting materials for the mobile # 146 developer (March 21-27)</a></li>
<li><a href="../280262/index.html">Efficient data structures for PHP 7</a></li>
<li><a href="../280264/index.html">5 tips for preparing your application for multiwindow mode in Android N</a></li>
<li><a href="../280266/index.html">Casual workouts for Swift</a></li>
<li><a href="../280270/index.html">Parsim HTML in C ++ and Gumbo</a></li>
<li><a href="../280272/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ204 (March 21 - 27, 2016)</a></li>
<li><a href="../280274/index.html">Rust and Swift (introduction, first and second parts)</a></li>
<li><a href="../280276/index.html">Development Case on Golang: ITooLabs Virtual PBX Platform</a></li>
<li><a href="../280278/index.html">PHP Digest number 82 - interesting news, materials and tools (March 14 - 27, 2016)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>