<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Configuring Nomad Cluster with Consul and Gitlab Integration</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 

 Recently, the popularity of Kubernetes is growing rapidly - more and more projects are introducing it at home. I wanted to touch such ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Configuring Nomad Cluster with Consul and Gitlab Integration</h1><div class="post__text post__text-html js-mediator-article"><h2>  Introduction </h2><br><br>  Recently, the popularity of Kubernetes is growing rapidly - more and more projects are introducing it at home.  I wanted to touch such an orchestrator as Nomad: it is perfect for projects where other solutions from HashiCorp are already being used, for example, Vault and Consul, and the projects themselves are not complex in terms of infrastructure.  In this material, there will be instructions on installing Nomad, joining two nodes into a cluster, as well as integrating Nomad with Gitlab. <br><br><img src="https://habrastorage.org/webt/bu/yn/4v/buyn4vqshurhgc9kavloja-fzsm.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><br><h2>  Test stand </h2><br><br>  A little bit about the test bench: three virtual servers with the characteristics of 2 CPU, 4 RAM, 50 Gb SSD, connected to a common local area network are used.  Their names and IP addresses: <br><br><ol><li>  <b>nomad-livelinux-01</b> : 172.30.0.5 </li><li>  <b>nomad-livelinux-02</b> : 172.30.0.10 </li><li>  <b>consul-livelinux-01</b> : 172.30.0.15 </li></ol><br><br><h2>  Installing Nomad, Consul.  Creating a Nomad Cluster </h2><br><br>  We proceed to the basic installation.  Despite the ease of installation, I will describe it for the integrity of the article: in fact, it was created from drafts and notes for quick access if necessary. <br><br>  Before starting the practice we will discuss the theoretical part, because at this stage it is important to understand the future structure. <br><br>  We have two Nomad nodes and we want to cluster them, also for the future we will need an automatic scaling cluster - for this we need Consul.  Using this tool, clustering and adding new nodes becomes a very simple task: the created Nomad node connects to the Consul agent, and then makes the connection to the existing Nomad cluster.  Therefore, at the beginning we will install the Consul server, configure the basic http authorization for the web panel (it is by default without authorization and can be accessed at an external address), as well as the Consul agents themselves on Nomad servers, and then proceed to Nomad. <br><br>  Installing HashiCorp tools is very simple: in fact, we simply move the binary file to the bin directory, set up the tool configuration file and create its service file. <br><br>  Load the Consul binary file and unpack it into the user's home directory: <br><br><pre><code class="bash hljs">root@consul-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># wget https://releases.hashicorp.com/consul/1.5.0/consul_1.5.0_linux_amd64.zip root@consul-livelinux-01:~# unzip consul_1.5.0_linux_amd64.zip root@consul-livelinux-01:~# mv consul /usr/local/bin/</span></span></code> </pre> <br><br>  Now we have a ready-made consul binary file for further customization. <br><br>  To work with Consul, we need to create a unique key using the keygen command: <br><br><pre> <code class="bash hljs">root@consul-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># consul keygen</span></span></code> </pre><br><br>  Let's go to the configuration configuration Consul, create a directory /etc/consul.d/ with the following structure: <br><br><pre> <code class="bash hljs">/etc/consul.d/ ‚îú‚îÄ‚îÄ bootstrap ‚îÇ ‚îî‚îÄ‚îÄ config.json</code> </pre> <br><br>  The configuration file config.json will be located in the bootstrap directory - in it we will set the Consul settings.  Its contents are: <br><br><pre> <code class="javascript hljs">{ <span class="hljs-string"><span class="hljs-string">"bootstrap"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-string"><span class="hljs-string">"server"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-string"><span class="hljs-string">"datacenter"</span></span>: <span class="hljs-string"><span class="hljs-string">"dc1"</span></span>, <span class="hljs-string"><span class="hljs-string">"data_dir"</span></span>: <span class="hljs-string"><span class="hljs-string">"/var/consul"</span></span>, <span class="hljs-string"><span class="hljs-string">"encrypt"</span></span>: <span class="hljs-string"><span class="hljs-string">"your-key"</span></span>, <span class="hljs-string"><span class="hljs-string">"log_level"</span></span>: <span class="hljs-string"><span class="hljs-string">"INFO"</span></span>, <span class="hljs-string"><span class="hljs-string">"enable_syslog"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-string"><span class="hljs-string">"start_join"</span></span>: [<span class="hljs-string"><span class="hljs-string">"172.30.0.15"</span></span>] }</code> </pre> <br><br>  Let us analyze separately the main directives and their meanings: <br><br><ul><li>  <b>bootstrap</b> : true.  Turn on the automatic addition of new nodes in the case of their connection.  Note that we do not indicate here the exact number of expected nodes. </li><li>  <b>server</b> : true.  Turn on server mode.  Consul on this virtual machine will be the only server and master at the moment, Nomad VM will be clients. </li><li>  <b>datacenter</b> : dc1.  Specify the name of the data center to create a cluster.  It must be identical on both clients and servers. </li><li>  <b>encrypt</b> : your-key.  A key that must also be unique and match on all clients and servers.  Generated using the consul keygen command. </li><li>  <b>start_join</b> .  In this list we indicate the list of IP addresses to which the connection will be made.  At the moment we leave only our own address. </li></ul><br><br>  At this stage, we can start the consul using the command line: <br><br><pre> <code class="bash hljs">root@consul-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># /usr/local/bin/consul agent -config-dir /etc/consul.d/bootstrap -ui</span></span></code> </pre> <br><br>  This is a good way to debug now, however, on an ongoing basis to use this method will not work for obvious reasons.  Create a file service to manage Consul via systemd: <br><br><pre> <code class="bash hljs">root@consul-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># nano /etc/systemd/system/consul.service</span></span></code> </pre><br><br>  Content of consul.service file: <br><br><pre> <code class="bash hljs">[Unit] Description=Consul Startup process After=network.target [Service] Type=simple ExecStart=/bin/bash -c <span class="hljs-string"><span class="hljs-string">'/usr/local/bin/consul agent -config-dir /etc/consul.d/bootstrap -ui'</span></span> TimeoutStartSec=0 [Install] WantedBy=default.target</code> </pre> <br><br>  Run Consul via systemctl: <br><br><pre> <code class="bash hljs">root@consul-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># systemctl start consul</span></span></code> </pre><br><br>  We check: our service should be started, and having executed the consul members command we should see our server: <br><br><pre> <code class="bash hljs">root@consul-livelinux:/etc/consul.d<span class="hljs-comment"><span class="hljs-comment"># consul members consul-livelinux 172.30.0.15:8301 alive server 1.5.0 2 dc1 &lt;all&gt;</span></span></code> </pre> <br><br>  The next step: installing Nginx and setting up proxying, http authorization.  Install nginx through the package manager and in the / etc / nginx / sites-enabled directory create the configuration file consul.conf with the following contents: <br><br><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> consul-auth { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> localhost:<span class="hljs-number"><span class="hljs-number">8500</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> consul.doman.name; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> http://consul-auth; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> Host <span class="hljs-variable"><span class="hljs-variable">$host</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">auth_basic_user_file</span></span> /etc/nginx/.htpasswd; <span class="hljs-attribute"><span class="hljs-attribute">auth_basic</span></span> <span class="hljs-string"><span class="hljs-string">"Password-protected Area"</span></span>; } }</code> </pre> <br><br>  Do not forget to create .htpasswd file and generate a username and password for it.  This item is required to ensure that the web panel is not accessible to anyone who knows our domain.  However, when setting up Gitlab, we will have to give it up - otherwise, we will not be able to shut down our application in Nomad.  In my project, both Gitlab and Nomad are only in the gray network, so there is no such problem. <br><br>  On the other two servers, install Consul agents using the following instructions.  Repeat actions with binary file: <br><br><pre> <code class="bash hljs">root@nomad-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># wget https://releases.hashicorp.com/consul/1.5.0/consul_1.5.0_linux_amd64.zip root@nomad-livelinux-01:~# unzip consul_1.5.0_linux_amd64.zip root@nomad-livelinux-01:~# mv consul /usr/local/bin/</span></span></code> </pre> <br><br>  By analogy with the previous server, create a directory for the /etc/consul.d configuration files with the following structure: <br><br><pre> <code class="bash hljs">/etc/consul.d/ ‚îú‚îÄ‚îÄ client ‚îÇ ‚îî‚îÄ‚îÄ config.json</code> </pre> <br><br>  Contents of the config.json file: <br><br><pre> <code class="javascript hljs">{ <span class="hljs-string"><span class="hljs-string">"datacenter"</span></span>: <span class="hljs-string"><span class="hljs-string">"dc1"</span></span>, <span class="hljs-string"><span class="hljs-string">"data_dir"</span></span>: <span class="hljs-string"><span class="hljs-string">"/opt/consul"</span></span>, <span class="hljs-string"><span class="hljs-string">"log_level"</span></span>: <span class="hljs-string"><span class="hljs-string">"DEBUG"</span></span>, <span class="hljs-string"><span class="hljs-string">"node_name"</span></span>: <span class="hljs-string"><span class="hljs-string">"nomad-livelinux-01"</span></span>, <span class="hljs-string"><span class="hljs-string">"server"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-string"><span class="hljs-string">"encrypt"</span></span>: <span class="hljs-string"><span class="hljs-string">"your-private-key"</span></span>, <span class="hljs-string"><span class="hljs-string">"domain"</span></span>: <span class="hljs-string"><span class="hljs-string">"livelinux"</span></span>, <span class="hljs-string"><span class="hljs-string">"addresses"</span></span>: { <span class="hljs-string"><span class="hljs-string">"dns"</span></span>: <span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span>, <span class="hljs-string"><span class="hljs-string">"https"</span></span>: <span class="hljs-string"><span class="hljs-string">"0.0.0.0"</span></span>, <span class="hljs-string"><span class="hljs-string">"grpc"</span></span>: <span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span>, <span class="hljs-string"><span class="hljs-string">"http"</span></span>: <span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span> }, <span class="hljs-string"><span class="hljs-string">"bind_addr"</span></span>: <span class="hljs-string"><span class="hljs-string">"172.30.0.5"</span></span>, #    <span class="hljs-string"><span class="hljs-string">"start_join"</span></span>: [<span class="hljs-string"><span class="hljs-string">"172.30.0.15"</span></span>], #     <span class="hljs-string"><span class="hljs-string">"ports"</span></span>: { <span class="hljs-string"><span class="hljs-string">"dns"</span></span>: <span class="hljs-number"><span class="hljs-number">53</span></span> } }</code> </pre><br><br>  Save the changes and proceed to setting up the service file, its contents: <br><br>  /etc/systemd/system/consul.service: <br><br><pre> <code class="bash hljs">[Unit] Description=<span class="hljs-string"><span class="hljs-string">"HashiCorp Consul - A service mesh solution"</span></span> Documentation=https://www.consul.io/ Requires=network-online.target After=network-online.target [Service] User=root Group=root ExecStart=/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin/consul agent -config-dir=/etc/consul.d/client ExecReload=/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin/consul reload KillMode=process Restart=on-failure [Install] WantedBy=multi-user.target</code> </pre> <br><br>  Run consul on the server.  Now, after the launch, we need to see the configured service in the nsul members.  This will mean that he has successfully connected to the cluster as a client.  Repeat the same on the second server and after that we will be able to proceed with the installation and configuration of Nomad. <br><br>  A more detailed installation of Nomad is described in its official documentation.  There are two traditional installation methods: downloading a binary file and compiling from source.  I will choose the first method. <br><br>  <b>Note</b> : the project is developing very quickly, often there are new updates.  Perhaps by the time the article is completed, a new version will be released.  Therefore, I recommend before reading to check the current version of Nomad at the moment and download it. <br><br><pre> <code class="bash hljs">root@nomad-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># wget https://releases.hashicorp.com/nomad/0.9.1/nomad_0.9.1_linux_amd64.zip root@nomad-livelinux-01:~# unzip nomad_0.9.1_linux_amd64.zip root@nomad-livelinux-01:~# mv nomad /usr/local/bin/ root@nomad-livelinux-01:~# nomad -autocomplete-install root@nomad-livelinux-01:~# complete -C /usr/local/bin/nomad nomad root@nomad-livelinux-01:~# mkdir /etc/nomad.d</span></span></code> </pre> <br><br>  After unpacking, we will get a 65 MB Nomad binary file - it needs to be moved to / usr / local / bin. <br><br>  Create a data directory for Nomad and edit its service file (it most likely will not exist at the beginning): <br><br><pre> <code class="bash hljs">root@nomad-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># mkdir --parents /opt/nomad root@nomad-livelinux-01:~# nano /etc/systemd/system/nomad.service</span></span></code> </pre> <br><br>  We insert the following lines there: <br><br><pre> <code class="bash hljs">[Unit] Description=Nomad Documentation=https://nomadproject.io/docs/ Wants=network-online.target After=network-online.target [Service] ExecReload=/bin/<span class="hljs-built_in"><span class="hljs-built_in">kill</span></span> -HUP <span class="hljs-variable"><span class="hljs-variable">$MAINPID</span></span> ExecStart=/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin/nomad agent -config /etc/nomad.d KillMode=process KillSignal=SIGINT LimitNOFILE=infinity LimitNPROC=infinity Restart=on-failure RestartSec=2 StartLimitBurst=3 StartLimitIntervalSec=10 TasksMax=infinity [Install] WantedBy=multi-user.target</code> </pre> <br><br>  However, we are not in a hurry to run nomad - we have not yet created its configuration file: <br><br><pre> <code class="bash hljs">root@nomad-livelinux-01:~<span class="hljs-comment"><span class="hljs-comment"># mkdir --parents /etc/nomad.d root@nomad-livelinux-01:~# chmod 700 /etc/nomad.d root@nomad-livelinux-01:~# nano /etc/nomad.d/nomad.hcl root@nomad-livelinux-01:~# nano /etc/nomad.d/server.hcl</span></span></code> </pre><br><br>  The final directory structure will be as follows: <br><br><pre> <code class="bash hljs">/etc/nomad.d/ ‚îú‚îÄ‚îÄ nomad.hcl ‚îî‚îÄ‚îÄ server.hcl</code> </pre> <br><br>  The nomad.hcl file should contain the following configuration: <br><br><pre> <code class="bash hljs">datacenter = <span class="hljs-string"><span class="hljs-string">"dc1"</span></span> data_dir = <span class="hljs-string"><span class="hljs-string">"/opt/nomad"</span></span></code> </pre> <br><br>  Contents of the server.hcl file: <br><br><pre> <code class="bash hljs">server { enabled = <span class="hljs-literal"><span class="hljs-literal">true</span></span> bootstrap_expect = 1 } consul { address = <span class="hljs-string"><span class="hljs-string">"127.0.0.1:8500"</span></span> server_service_name = <span class="hljs-string"><span class="hljs-string">"nomad"</span></span> client_service_name = <span class="hljs-string"><span class="hljs-string">"nomad-client"</span></span> auto_advertise = <span class="hljs-literal"><span class="hljs-literal">true</span></span> server_auto_join = <span class="hljs-literal"><span class="hljs-literal">true</span></span> client_auto_join = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } bind_addr = <span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span> advertise { http = <span class="hljs-string"><span class="hljs-string">"172.30.0.5"</span></span> } client { enabled = <span class="hljs-literal"><span class="hljs-literal">true</span></span> }</code> </pre> <br><br>  Do not forget to change the configuration file on the second server - there you will need to change the value of the http directive. <br><br>  The last at this stage remains the Nginx configuration for proxying and installing http authorization.  Contents of the nomad.conf file: <br><br><pre> <code class="bash hljs">upstream nomad-auth { server 172.30.0.5:4646; } server { server_name nomad.domain.name; location / { proxy_pass http://nomad-auth; proxy_set_header Host <span class="hljs-variable"><span class="hljs-variable">$host</span></span>; auth_basic_user_file /etc/nginx/.htpasswd; auth_basic <span class="hljs-string"><span class="hljs-string">"Password-protected Area"</span></span>; } }</code> </pre> <br><br>  Now we can access the web panel via an external network.  Connect and go to the servers page: <br><br><img src="https://habrastorage.org/webt/en/uq/ck/enuqck8krqstsbt8b6uwbytoy0e.png"><br>  <b>Figure 1.</b> List of servers in a Nomad cluster <br><br>  Both servers are successfully displayed in the panel, the same thing we will see in the output of the nomad node status command: <br><br><img src="https://habrastorage.org/webt/c1/gv/82/c1gv82tjvwtw0onqxqv3huchv1w.png"><br>  <b>Figure 2.</b> Output of the nomad node status command <br><br>  What about Consul?  Let's get a look.  Go to the Consul control panel, on the nodes page: <br><img src="https://habrastorage.org/webt/m5/6w/tj/m56wtjjgkos9ed5e_jy9lidmutg.png"><br>  <b>Figure 3.</b> List of nodes in the Consul cluster <br><br>  Now we have a prepared Nomad, working in conjunction with Consul.  In the final stage, we will proceed to the most interesting part: we will configure the delivery of Docker containers from Gitlab to Nomad, as well as talk about some of its other distinctive features. <br><br><h2>  Creating Gitlab Runner <br></h2><br><br>  For the deployment of the docker images in Nomad, we will use a separate runner with the Nomad binary file inside (here, by the way, we can note another feature of the Hashicorp applications - individually, they are the only binary file).  Download it to the runner directory.  For it we will create the simplest Dockerfile with the following contents: <br><br><pre> <code class="bash hljs">FROM alpine:3.9 RUN apk add --update --no-cache libc6-compat gettext COPY nomad /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin/nomad</code> </pre><br><br>  In the same project we create .gitlab-ci.yml: <br><br><pre> <code class="bash hljs">variables: DOCKER_IMAGE: nomad/nomad-deploy DOCKER_REGISTRY: registry.domain.name stages: - build build: stage: build image: <span class="hljs-variable"><span class="hljs-variable">${DOCKER_REGISTRY}</span></span>/nomad/alpine:3 script: - tag=<span class="hljs-variable"><span class="hljs-variable">${DOCKER_REGISTRY}</span></span>/<span class="hljs-variable"><span class="hljs-variable">${DOCKER_IMAGE}</span></span>:latest - docker build --pull -t <span class="hljs-variable"><span class="hljs-variable">${tag}</span></span> -f Dockerfile . - docker push <span class="hljs-variable"><span class="hljs-variable">${tag}</span></span></code> </pre> <br><br>  As a result, we will have an available image of the Nomad runner in the Gitlab Registry, now we can go directly to the project repository, create a Pipeline and configure Nomad job Nomad. <br><br><h2>  Project Setup <br></h2><br><br>  Let's start with the job's file for Nomad.  My project in this article will be quite primitive: it will consist of one task.  The contents of .gitlab-ci will be as follows: <br><br><pre> <code class="bash hljs">variables: NOMAD_ADDR: http://nomad.address.service:4646 DOCKER_REGISTRY: registry.domain.name DOCKER_IMAGE: example/project stages: - build - deploy build: stage: build image: <span class="hljs-variable"><span class="hljs-variable">${DOCKER_REGISTRY}</span></span>/nomad-runner/alpine:3 script: - tag=<span class="hljs-variable"><span class="hljs-variable">${DOCKER_REGISTRY}</span></span>/<span class="hljs-variable"><span class="hljs-variable">${DOCKER_IMAGE}</span></span>:<span class="hljs-variable"><span class="hljs-variable">${CI_COMMIT_SHORT_SHA}</span></span> - docker build --pull -t <span class="hljs-variable"><span class="hljs-variable">${tag}</span></span> -f Dockerfile . - docker push <span class="hljs-variable"><span class="hljs-variable">${tag}</span></span> deploy: stage: deploy image: registry.example.com/nomad/nomad-runner:latest script: - envsubst <span class="hljs-string"><span class="hljs-string">'${CI_COMMIT_SHORT_SHA}'</span></span> &lt; project.nomad &gt; job.nomad - cat job.nomad - nomad validate job.nomad - nomad plan job.nomad || <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [ $? -eq 255 ]; <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> 255; <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"success"</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">fi</span></span> - nomad run job.nomad environment: name: production allow_failure: <span class="hljs-literal"><span class="hljs-literal">false</span></span> when: manual</code> </pre> <br><br>  Here the deployment occurs in manual mode, but you can configure it to change the contents of the project directory.  Pipeline consists of two stages: from the assembly of the image and its deployment to the nomad.  At the first stage we collect the docker image and push it to our Registry, at the second we launch our job in Nomad. <br><br><pre> <code class="bash hljs">job <span class="hljs-string"><span class="hljs-string">"monitoring-status"</span></span> { datacenters = [<span class="hljs-string"><span class="hljs-string">"dc1"</span></span>] migrate { max_parallel = 3 health_check = <span class="hljs-string"><span class="hljs-string">"checks"</span></span> min_healthy_time = <span class="hljs-string"><span class="hljs-string">"15s"</span></span> healthy_deadline = <span class="hljs-string"><span class="hljs-string">"5m"</span></span> } group <span class="hljs-string"><span class="hljs-string">"zhadan.ltd"</span></span> { count = 1 update { max_parallel = 1 min_healthy_time = <span class="hljs-string"><span class="hljs-string">"30s"</span></span> healthy_deadline = <span class="hljs-string"><span class="hljs-string">"5m"</span></span> progress_deadline = <span class="hljs-string"><span class="hljs-string">"10m"</span></span> auto_revert = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } task <span class="hljs-string"><span class="hljs-string">"service-monitoring"</span></span> { driver = <span class="hljs-string"><span class="hljs-string">"docker"</span></span> config { image = <span class="hljs-string"><span class="hljs-string">"registry.domain.name/example/project:</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${CI_COMMIT_SHORT_SHA}</span></span></span><span class="hljs-string">"</span></span> force_pull = <span class="hljs-literal"><span class="hljs-literal">true</span></span> auth { username = <span class="hljs-string"><span class="hljs-string">"gitlab_user"</span></span> password = <span class="hljs-string"><span class="hljs-string">"gitlab_password"</span></span> } port_map { http = 8000 } } resources { network { port <span class="hljs-string"><span class="hljs-string">"http"</span></span> {} } } } } }</code> </pre> <br><br>  Please note that I have a closed Registry and for a successful docker-image pull I need to log in to it.  The best solution in this case is to enter the login and password in the Vault, followed by its integration with Nomad.  Nomad natively supports Vault.  But first, in the Vault itself, we will install the necessary policies for Nomad, you can download them: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Download the policy and token role $ curl https://nomadproject.io/data/vault/nomad-server-policy.hcl -O -s -L $ curl https://nomadproject.io/data/vault/nomad-cluster-role.json -O -s -L # Write the policy to Vault $ vault policy write nomad-server nomad-server-policy.hcl # Create the token role with Vault $ vault write /auth/token/roles/nomad-cluster @nomad-cluster-role.json</span></span></code> </pre> <br><br>  Now, having created the necessary policies, we will add integration with the Vault in the task block in the job.nomad file: <br><br><pre> <code class="bash hljs">vault { enabled = <span class="hljs-literal"><span class="hljs-literal">true</span></span> address = <span class="hljs-string"><span class="hljs-string">"https://vault.domain.name:8200"</span></span> token = <span class="hljs-string"><span class="hljs-string">"token"</span></span> }</code> </pre> <br><br>  I use authorization by token and prescribe it directly here, there is also the option of specifying the token as a variable when launching the nomad agent: <br><br><pre> <code class="bash hljs">$ VAULT_TOKEN=&lt;token&gt; nomad agent -config /path/to/config</code> </pre><br><br>  Now we can use keys with a vault.  The principle of operation is simple: we create a file in the Nomad job that will store the values ‚Äã‚Äãof variables, for example: <br><br><pre> <code class="bash hljs">template { data = &lt;&lt;EOH {{with secret <span class="hljs-string"><span class="hljs-string">"secrets/pipeline-keys"</span></span>}} REGISTRY_LOGIN=<span class="hljs-string"><span class="hljs-string">"{{ .Data.REGISTRY_LOGIN }}"</span></span> REGISTRY_PASSWORD=<span class="hljs-string"><span class="hljs-string">"{{ .Data.REGISTRY_LOGIN }}{{ end }}"</span></span> EOH destination = <span class="hljs-string"><span class="hljs-string">"secrets/service-name.env"</span></span> env = <span class="hljs-literal"><span class="hljs-literal">true</span></span> }</code> </pre> <br><br>  With this simple approach, you can customize the delivery of containers to the Nomad cluster and work with it in the future.  I will say that to some extent I sympathize with Nomad - it is more suitable for small projects, where Kubernetes may cause additional difficulties and will not realize its potential to the end.  In addition, Nomad is perfect for beginners - it is just installed and configured.  However, when testing on some projects I encounter the problem of its earlier versions - many basic functions simply do not exist or they work incorrectly.  Nevertheless, I believe that Nomad will continue to develop and in the future will acquire all necessary functions. <br><br>  <i>Author: Ilya Andreev, edited by Alexey Zhadan and the Live Linux team</i> <i><br></i> </div><p>Source: <a href="https://habr.com/ru/post/453322/">https://habr.com/ru/post/453322/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../453310/index.html">Data exchange between React components using the RxJS library</a></li>
<li><a href="../453312/index.html">Generator of business letters in PDF according to data from XML</a></li>
<li><a href="../453314/index.html">Black Mirror with your own hands - we train the bot on the basis of its chat history</a></li>
<li><a href="../453316/index.html">British chip maker ARM ceased cooperation with Huawei</a></li>
<li><a href="../453318/index.html">5 errors in the implementation of push-notifications for mobile applications</a></li>
<li><a href="../453324/index.html">Diode as rectifier</a></li>
<li><a href="../453326/index.html">How to automate IT infrastructure management - we discuss three trends</a></li>
<li><a href="../453328/index.html">Ten years away</a></li>
<li><a href="../45333/index.html">What can a robot feel?</a></li>
<li><a href="../453330/index.html">What to do when RAM fails. Medical history and treatment methods</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>