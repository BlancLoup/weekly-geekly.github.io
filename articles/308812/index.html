<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Mesos. Container Cluster Management System</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Apache Mesos is a centralized, fault-tolerant cluster management system. It is designed for distributed computer environments in order to provide reso...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Mesos. Container Cluster Management System</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/031/d4d/46e/031d4d46ec814f468e6370716e2ed6e5.png"><br><br>  <a href="http://mesos.apache.org/">Apache Mesos</a> is a centralized, fault-tolerant cluster management system.  It is designed for distributed computer environments in order to provide resource isolation and convenient management of clusters of subordinate nodes (mesos slaves).  This is a new effective way to manage the server infrastructure, but, like any technical solution, not a silver bullet. <br><br>  In a sense, the essence of his work is the opposite of traditional virtualization - instead of dividing a physical machine into a bunch of virtual ones, Mesos suggests combining them into one whole, into a single virtual resource. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Mesos allocates CPU and memory resources in a cluster for tasks in a similar manner as the Linux kernel allocates iron resources between local processes. <br><br>  Imagine that there is a need to perform various types of tasks.  To do this, you can select separate virtual machines (separate cluster) for each type.  These virtual machines will probably not be fully loaded and will be idle for some time, that is, they will not work with maximum efficiency.  If all virtual machines for all tasks are merged into a single cluster, we can increase the efficiency of resource use and at the same time increase the speed of their execution (if the tasks are short-term or virtual machines are not fully loaded all the time).  The following picture, I hope, will clarify what was said: <br><br><img src="https://habrastorage.org/files/abe/667/689/abe667689f00418891dc23340ec3b6d3.png"><br><br>  But that's not all.  The Mesos cluster (with the framework for it) is able to recreate individual resources, in case of their fall, scale resources manually or automatically under certain conditions, etc. <br><br>  Let's walk through the components of the Mesos-cluster. <a name="habracut"></a><br><br>  <b>Mesos masters</b> <br><br>  The main controlling servers of the cluster.  Actually they are responsible for the provision of resources, the distribution of tasks between the current Mesos-slaves.  To ensure a high level of availability, there should be several and preferably an odd number, but of course more than 1. This is due to the level of quorum.  Only one server can be an active master (leader) at a time. <br><br>  <b>Mesos slaves</b> <br><br>  Services (nodes) providing the capacity to perform tasks.  Tasks can be executed both in own Mesos-containers, and in Docker. <br><br>  <b>Frameworks</b> <br><br>  Mesos itself is only the "heart" of the cluster, it provides only the environment for the work (execution) of tasks.  All the logic of launching tasks, monitoring their work, scaling, etc.  perform frameworks.  Similar to Linux, this is such an init / upstart system for running processes.  We will consider the work of the Marathon framework, which is designed more to run ongoing tasks (long-term operation of servers, etc.) or short-term ones.  To start the tasks on schedule it is worth using another framework - <b>Chronos</b> (similar to cron). <br><br>  In general, frameworks are quite a large number and here are the most famous among them: <br><br>  <a href="http://aurora.apache.org/">Aurora</a> (can both run tasks on schedule and run long-term tasks).  Developed by Twitter. <br>  <a href="http://hadoop.apache.org/">Hadoop</a> <br>  <a href="http://jenkins.io/">Jenkins</a> <br>  <a href="http://spark.apache.org/">Spark</a> <br>  <a href="http://db.apache.org/torque">Torque</a> <br><br><img src="https://habrastorage.org/files/381/ea2/ee2/381ea2ee28c34d49a776a02ed7a6b300.jpg"><br><br>  <b>ZooKeeper</b> <br><br>  The daemon responsible for coordinating the Mesos Masters nodes.  He holds the election of the master in the presence of a quorum.  Other nodes in the cluster receive the address of the current master by a request to the zookeeper group of nodes of type <b>zk: // master-node1: 2138, master-node2: 2138, master-node3: 2138 / mesos</b> .  Mesos Slaves, in turn, also connect only to the current master using a similar request.  In our tutorial, they will also be installed on nodes with Mesos masters, but they can also live separately. <br><br><img src="https://habrastorage.org/files/6fa/dac/0fa/6fadac0fa8094d4195f435fed9e66c8b.jpg"><br><br>  This article will be more practical: by repeating after me you will also be able to get a working Mesos cluster at the exit. <br><p>  For future sites, I chose the following addresses: <br></p><br><pre><code class="bash hljs">mesos-master1 10.0.3.11 mesos-master2 10.0.3.12 mesos-master3 10.0.3.13 --- mesos-slave1 10.0.3.51 mesos-slave2 10.0.3.52 mesos-slave3 10.0.3.53</code> </pre> <br><br>  Those.  3 masters and 3 slaves.  The wizards will also have a Marathon framework, which, if desired, can be placed on a separate node. <br><br>  At the testing stage, it is better to choose virtual machines running on hardware virtualization platforms (VirtualBox, XEN, KVM), because, say, installing a Docker in an LXC container is not yet very possible or difficult.  We will use Docker to isolate tasks running on Mesos slaves. <br><p>  Thus, having 6 ready servers (virtual machines) with Ubuntu 14.04, we are ready for battle. </p><br><p>  <b>MESOS MASTERS / MARATHON INSTALLATION</b> </p><br><p>  We perform completely similar actions on all 3 Mesos master servers. </p><br><pre> <code class="bash hljs">apt-get install software-properties-common</code> </pre> <br><p>  Add Mesos / Marathon repositories: </p><br><pre> <code class="bash hljs">apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E56151BF DISTRO=$(lsb_release -is | tr <span class="hljs-string"><span class="hljs-string">'[:upper:]'</span></span> <span class="hljs-string"><span class="hljs-string">'[:lower:]'</span></span>) CODENAME=$(lsb_release -cs) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://repos.mesosphere.com/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${DISTRO}</span></span></span><span class="hljs-string"> </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${CODENAME}</span></span></span><span class="hljs-string"> main"</span></span> | \ sudo tee /etc/apt/sources.list.d/mesosphere.list</code> </pre> <br><p>  Mesos and Marathon require a Java machine to work.  Therefore, we install the latest from Oracle: </p><br><pre> <code class="bash hljs">add-apt-repository ppa:webupd8team/java apt-get update apt-get install oracle-java8-installer</code> </pre> <br><p>  Check if Java works: </p><br><pre> <code class="bash hljs">java -version java version <span class="hljs-string"><span class="hljs-string">"1.8.0_91"</span></span> Java(TM) SE Runtime Environment (build 1.8.0_91-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)</code> </pre> <br><p>  Although, it seems, OpenJDK is also suitable. </p><br><p>  For each of the future masters, we will install Mesos and Marathon: </p><br><pre> <code class="bash hljs">apt-get -y install mesos marathon</code> </pre> <br><p>  By the way, the Marathon framework is written in Scala. </p><br><p>  The dependencies will also be installed Zookeeper.  We give him the address of our master node: </p><br><pre> <code class="bash hljs">vim /etc/mesos/zk zk://10.0.3.11:2181,10.0.3.12:2181,10.0.3.13:2181/mesos</code> </pre> <br><p>  <b>2181</b> is the port on which Zookeeper is running. </p><br><p>  For each master node, select a unique ID: </p><br><pre> <code class="bash hljs">vim /etc/zookeeper/conf/myid 1</code> </pre> <br><p>  For the second and third server, I chose <b>2</b> and <b>3,</b> respectively.  Rooms can be selected from 1 to 255. </p><br><p>  Edit <b>/etc/zookeeper/conf/zoo.cfg</b> : </p><br><pre> <code class="bash hljs">vim /etc/zookeeper/conf/zoo.cfg server.1 = 10.0.3.11:2888:3888 server.2 = 10.0.3.12:2888:3888 server.3 = 10.0.3.13:2888:3888</code> </pre> <br><p>  <b>1,2,3</b> - ID that we specified in <b>/ etc / zookeeper / conf / myid of</b> each server. <br>  <b>2888</b> is the port that Zookeeper uses to communicate with the selected master, and <b>3888</b> for new elections, if something happened to the current master. </p><br><p>  Go to the quorum setting.  A quorum is the minimum number of work nodes required to select a new leader.  This option is necessary to prevent the Split-brain cluster.  Imagine that a cluster consists only of 2 servers with a quorum of 1. In this case, only the presence of 1 working server is enough to select a new leader: in fact, each server can choose its own leader.  If one of the servers crashes, this behavior is more than logical.  However, what will happen when only the network connection between them breaks down?  That's right: the probable option is when each of the servers will take turns pulling back the main traffic.  If such a cluster consists of databases, then the loss of reference data is possible in general and it will not even be clear where to recover. </p><br><p>  So, having 3 servers is the minimum to ensure high availability.  The quorum value in this case is 2. If only one server is no longer available, the other 2 will be able to choose someone among themselves.  If the two servers experience breakdowns or the nodes do not see each other on the network, the group, for data integrity, will not elect a new master at all until the required quorum (the appearance of one of the servers on the network) is reached. </p><br><p>  Why doesn't it make much sense to choose 4 (even numbers) servers?  Because in this case, as in the case of 3 servers, only the absence of one server is not critical for the cluster: the fall of the second server will be fatal for the cluster due to the possible Split-brain.  But in the case of 5 servers (and a quorum level of 3), 2 servers are no longer crashing.  Like this.  So it is best to choose clusters with 5 or more nodes, and then who knows what can happen during maintenance at one of them. </p><br><p>  In case Zookeeper will be submitted separately, Mesos-masters can be any, incl.  and fresh, quantity. </p><br><p>  Specify the same quorum level for masters: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"2"</span></span> &gt; /etc/mesos-master/quorum</code> </pre> <br><p>  Specify IP accordingly for each node: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> 10.0.3.11 | tee /etc/mesos-master/ip</code> </pre> <br><p>  If the servers do not have a domain name, then copy the IP address to use it as the host name: </p><br><pre> <code class="bash hljs">cp /etc/mesos-master/ip /etc/mesos-master/hostname</code> </pre> <br><p>  Similarly for <b>10.0.3.12</b> and <b>10.0.3.13</b> . </p><br><p>  Customize the Marathon framework.  Create a directory for configuration files and copy the hostname into it: </p><br><pre> <code class="bash hljs">mkdir -p /etc/marathon/conf cp /etc/mesos-master/hostname /etc/marathon/conf</code> </pre> <br><p>  Copy the Zookeeper settings for Marathon: </p><br><pre> <code class="bash hljs">cp /etc/mesos/zk /etc/marathon/conf/master cp /etc/marathon/conf/master /etc/marathon/conf/zk</code> </pre> <br><p>  Edit the last few: </p><br><pre> <code class="bash hljs">vim /etc/marathon/conf/zk zk://10.0.3.11:2181,10.0.3.12:2181,10.0.3.13:2181/marathon</code> </pre> <br><p>  Finally, we prohibit downloads of the mesos-slave daemon on the wizards: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> manual | sudo tee /etc/init/mesos-slave.override stop mesos-slave</code> </pre> <br><p>  Restart services on all nodes: </p><br><pre> <code class="bash hljs">restart mesos-master restart marathon</code> </pre> <br><p>  Open the Mesos web panel on port 5050: <br></p><br><img src="https://habrastorage.org/files/7b0/671/95d/7b067195d96d475aaa00e4f7901d8a8c.png"><br><br>  In the event that a different server is chosen as a leader, a redirect to another server will take place: <br><br><img src="https://habrastorage.org/files/dfe/074/367/dfe07436704b4251a5726837ad42feff.png"><br><br>  Marathon has a nice dark interface and it works on port 8080: <br><br><img src="https://habrastorage.org/files/02c/cef/b90/02ccefb90d18433f9f5a5082aa10c470.png"><br><br>  <b>MESOS SLAVES INSTALLATION</b> <br><br>  As for the installation of Mesos-masters, we will add repositories and install the necessary packages: <br><br><pre> <code class="bash hljs">apt-get install software-properties-common apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E56151BF DISTRO=$(lsb_release -is | tr <span class="hljs-string"><span class="hljs-string">'[:upper:]'</span></span> <span class="hljs-string"><span class="hljs-string">'[:lower:]'</span></span>) CODENAME=$(lsb_release -cs) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://repos.mesosphere.com/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${DISTRO}</span></span></span><span class="hljs-string"> </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${CODENAME}</span></span></span><span class="hljs-string"> main"</span></span> | \ tee /etc/apt/sources.list.d/mesosphere.list add-apt-repository ppa:webupd8team/java apt-get update apt-get install oracle-java8-installer</code> </pre> <br><p>  Check if Java was installed correctly: </p><br><pre> <code class="bash hljs">java -version java version <span class="hljs-string"><span class="hljs-string">"1.8.0_91"</span></span> Java(TM) SE Runtime Environment (build 1.8.0_91-b14) Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)</code> </pre> <br><p>  It is also necessary to prohibit the launch of the Zookeeper and Mesos-master processes, since  they are not needed here: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> manual | sudo tee /etc/init/zookeeper.override <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> manual | sudo tee /etc/init/mesos-master.override stop zookeeper stop mesos-master</code> </pre> <br><p>  We indicate the domains and IP addresses for the slave: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> 10.0.3.51 | tee /etc/mesos-slave/ip cp /etc/mesos-slave/ip /etc/mesos-slave/hostname</code> </pre> <br><p>  A similar action must also be performed for <b>10.0.3.52</b> and <b>10.0.3.53</b> (of course, with a separate address for each server). </p><br><p>  And describe all the wizards in <b>/ etc / mesos / zk</b> : </p><br><pre> <code class="bash hljs">vim /etc/mesos/zk zk://10.0.3.11:2181,10.0.3.12:2181,10.0.3.13:2181/mesos</code> </pre> <br><p>  The slave will occasionally poll the Zookeeper for the current leader and connect to it, providing its resources. </p><br><p>  During slave startup, the following error may occur: </p><br><pre> <code class="bash hljs">Failed to create a containerizer: Could not create MesosContainerizer: Failed to create launcher: Failed to create Linux launcher: Failed to mount cgroups hierarchy at <span class="hljs-string"><span class="hljs-string">'/sys/fs/cgroup/freezer'</span></span>: <span class="hljs-string"><span class="hljs-string">'freezer'</span></span> is already attached to another hierarchy</code> </pre> <br><p>  In this case, you need to make changes in <b>/ etc / default / mesos-slave</b> : </p><br><pre> <code class="bash hljs">vim /etc/default/mesos-slave ... MESOS_LAUNCHER=posix ...</code> </pre> <br><p>  And run the mesos-slave again: </p><br><pre> <code class="bash hljs">start mesos-slave</code> </pre> <br><p>  If everything is done correctly, the Slaves will connect as resources for the current leader: <br></p><br><img src="https://habrastorage.org/files/9ee/b4a/df7/9eeb4adf7a664651bf21121f784a3c4d.png"><br><br><img src="https://habrastorage.org/files/28b/692/bae/28b692bae34443549f5c726d04195db6.png"><br><br>  The cluster is ready!  Let's run some kind of task in Marathon.  To do this, open Marathon on any master node, click the blue <b>Create Application</b> button and enter everything as shown: <br><br><img src="https://habrastorage.org/files/beb/da8/6ea/bebda86eaad9446f8f7a49995c465ab4.png"><br><br>  The task has started running: <br><br><img src="https://habrastorage.org/files/2ac/d31/541/2acd31541eef434881c9b3c77add2c96.png"><br><br>  The Mesos web panel will immediately show the active task that the framework has set and the history of completed tasks.  The fact is that this task will be completed and begin again, because it is short-term.  That is why in the <b>Completed Tasks</b> will be a complete listing of all old tasks: <br><br><img src="https://habrastorage.org/files/a28/507/e00/a28507e001ff4e158ac890e782cf7603.png"><br><br>  The same task can be performed using the Marathon API, describing it in JSON format: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /tmp vim hello2.json { <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"hello2"</span></span>, <span class="hljs-string"><span class="hljs-string">"cmd"</span></span>: <span class="hljs-string"><span class="hljs-string">"echo hello; sleep 10"</span></span>, <span class="hljs-string"><span class="hljs-string">"mem"</span></span>: 16, <span class="hljs-string"><span class="hljs-string">"cpus"</span></span>: 0.1, <span class="hljs-string"><span class="hljs-string">"instances"</span></span>: 1, <span class="hljs-string"><span class="hljs-string">"disk"</span></span>: 0.0, <span class="hljs-string"><span class="hljs-string">"ports"</span></span>: [0] }</code> </pre> <br><br><pre> <code class="bash hljs">curl -i -H <span class="hljs-string"><span class="hljs-string">'Content-Type: application/json'</span></span> -d@hello2.json 10.0.3.11:8080/v2/apps HTTP/1.1 201 Created Date: Tue, 21 Jun 2016 14:21:31 GMT X-Marathon-Leader: http://10.0.3.11:8080 Cache-Control: no-cache, no-store, must-revalidate Pragma: no-cache Expires: 0 Location: http://10.0.3.11:8080/v2/apps/hello2 Content-Type: application/json; qs=2 Transfer-Encoding: chunked Server: Jetty(9.3.z-SNAPSHOT) {<span class="hljs-string"><span class="hljs-string">"id"</span></span>:<span class="hljs-string"><span class="hljs-string">"/hello2"</span></span>,<span class="hljs-string"><span class="hljs-string">"cmd"</span></span>:<span class="hljs-string"><span class="hljs-string">"echo hello; sleep 10"</span></span>,<span class="hljs-string"><span class="hljs-string">"args"</span></span>:null,<span class="hljs-string"><span class="hljs-string">"user"</span></span>:null,<span class="hljs-string"><span class="hljs-string">"env"</span></span>:{},<span class="hljs-string"><span class="hljs-string">"instances"</span></span>:1,<span class="hljs-string"><span class="hljs-string">"cpus"</span></span>:0.1,<span class="hljs-string"><span class="hljs-string">"mem"</span></span>:16,<span class="hljs-string"><span class="hljs-string">"disk"</span></span>:0,<span class="hljs-string"><span class="hljs-string">"executor"</span></span>:<span class="hljs-string"><span class="hljs-string">""</span></span>,<span class="hljs-string"><span class="hljs-string">"constraints"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"uris"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"fetch"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"storeUrls"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"ports"</span></span>:[0],<span class="hljs-string"><span class="hljs-string">"portDefinitions"</span></span>:[{<span class="hljs-string"><span class="hljs-string">"port"</span></span>:0,<span class="hljs-string"><span class="hljs-string">"protocol"</span></span>:<span class="hljs-string"><span class="hljs-string">"tcp"</span></span>,<span class="hljs-string"><span class="hljs-string">"labels"</span></span>:{}}],<span class="hljs-string"><span class="hljs-string">"requirePorts"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>,<span class="hljs-string"><span class="hljs-string">"backoffSeconds"</span></span>:1,<span class="hljs-string"><span class="hljs-string">"backoffFactor"</span></span>:1.15,<span class="hljs-string"><span class="hljs-string">"maxLaunchDelaySeconds"</span></span>:3600,<span class="hljs-string"><span class="hljs-string">"container"</span></span>:null,<span class="hljs-string"><span class="hljs-string">"healthChecks"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"readinessChecks"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"dependencies"</span></span>:[],<span class="hljs-string"><span class="hljs-string">"upgradeStrategy"</span></span>:{<span class="hljs-string"><span class="hljs-string">"minimumHealthCapacity"</span></span>:1,<span class="hljs-string"><span class="hljs-string">"maximumOverCapacity"</span></span>:1},<span class="hljs-string"><span class="hljs-string">"labels"</span></span>:{},<span class="hljs-string"><span class="hljs-string">"acceptedResourceRoles"</span></span>:null,<span class="hljs-string"><span class="hljs-string">"ipAddress"</span></span>:null,<span class="hljs-string"><span class="hljs-string">"version"</span></span>:<span class="hljs-string"><span class="hljs-string">"2016-06-21T14:21:31.665Z"</span></span>,<span class="hljs-string"><span class="hljs-string">"residency"</span></span>:null,<span class="hljs-string"><span class="hljs-string">"tasksStaged"</span></span>:0,<span class="hljs-string"><span class="hljs-string">"tasksRunning"</span></span>:0,<span class="hljs-string"><span class="hljs-string">"tasksHealthy"</span></span>:0,<span class="hljs-string"><span class="hljs-string">"tasksUnhealthy"</span></span>:0,<span class="hljs-string"><span class="hljs-string">"deployments"</span></span>:[{<span class="hljs-string"><span class="hljs-string">"id"</span></span>:<span class="hljs-string"><span class="hljs-string">"13bea032-9120-45e7-b082-c7d3b7d0ad01"</span></span>}],<span class="hljs-string"><span class="hljs-string">"tasks"</span></span>:[]}%</code> </pre> <br><br>  In this (and previous) example, hello will be displayed, then a delay of 10 seconds and all this in a circle.  The task will be allocated 16MB of memory and 0.1 CPU. <br><br>  The output of running tasks can be observed by clicking on the <b>Sandbox</b> link in the last column of the main panel of the current Mesos wizard: <br><br><img src="https://habrastorage.org/files/000/f81/a8c/000f81a8c3d140af872fdd20a80b5a14.png"><br><br>  <b>DOCKER</b> <br><br>  For better isolation and additional features, Docker support has been integrated into Mesos.  Who does not know him - I advise you to do it beforehand. <br><p>  The activation of Docker in Mesos is also not particularly difficult.  First you need to install Docker itself on all cluster slaves: </p><br><pre> <code class="bash hljs">apt-get install apt-transport-https ca-certificates apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb https://apt.dockerproject.org/repo ubuntu-precise main"</span></span> | tee /etc/apt/sources.list.d/docker.list apt-get update apt-get install docker-engine</code> </pre> <br><p>  To check the installation correctness, run the hello-world test container: </p><br><pre> <code class="bash hljs">docker run hello-world</code> </pre> <br><p>  Specify a new type of containerization for Mesos Slaves: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"docker,mesos"</span></span> | sudo tee /etc/mesos-slave/containerizers</code> </pre> <br><p>  Creating a new container that is not yet in the local cache may take longer.  Therefore, we will raise the timeout value of registering a new container in the framework: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"5mins"</span></span> | sudo tee /etc/mesos-slave/executor_registration_timeout</code> </pre> <br><p>  Well and, as usual, we will overload the service after such changes: </p><br><pre> <code class="bash hljs">service mesos-slave restart</code> </pre> <br><p>  Create a new task in Marathon and run it in the Docker container.  JSON will look like this: </p><br><pre> <code class="bash hljs">vim /tmp/Docker.json { <span class="hljs-string"><span class="hljs-string">"container"</span></span>: { <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"DOCKER"</span></span>, <span class="hljs-string"><span class="hljs-string">"docker"</span></span>: { <span class="hljs-string"><span class="hljs-string">"image"</span></span>: <span class="hljs-string"><span class="hljs-string">"libmesos/ubuntu"</span></span> } }, <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"ubuntu"</span></span>, <span class="hljs-string"><span class="hljs-string">"cpus"</span></span>: 0.5, <span class="hljs-string"><span class="hljs-string">"mem"</span></span>: 128, <span class="hljs-string"><span class="hljs-string">"uris"</span></span>: [], <span class="hljs-string"><span class="hljs-string">"cmd"</span></span>: <span class="hljs-string"><span class="hljs-string">"while sleep 10; do date -u +%T; done"</span></span> }</code> </pre> <br><p>  That is, the container will run an eternal <b>while loop</b> with the output of the current date.  Easy, right? <br>  <b>Docker.json</b> can be directly <b>infused</b> through the Marathon web panel by activating the JSON switch when creating a new task: <br></p><br><img src="https://habrastorage.org/files/2b9/675/10c/2b967510c0e540839fcf338deb1769f1.png"><br><br>  Or, if desired, enter data in separate fields: <br><br><img src="https://habrastorage.org/files/322/8a4/66d/3228a466d50b4382a3b42231c0a7f129.png"><br><br>  After some time, depending on the speed of the Internet connection, the container will be launched.  Its existence can be observed on the Mesos-slave, which received the task to perform: <br><br><pre> <code class="bash hljs">root@mesos-slave1:~<span class="hljs-comment"><span class="hljs-comment"># docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81f39fc7474a libmesos/ubuntu "/bin/sh -c 'while sl" 2 minutes ago Up 2 minutes mesos-4e1e9267-ecf7-4b98-848b-f9a7a30ad209-S2.5c1831a6-f856-48f9-aea2-74e5cb5f067f root@mesos-slave1:~#</span></span></code> </pre> <br><br>  Let's create a slightly more complicated Marathon task, already with healthcheck.  In case of unsatisfactory verification of the container operation, the latter will be recreated by the framework: <br><br><pre> <code class="bash hljs">{ <span class="hljs-string"><span class="hljs-string">"cmd"</span></span>: <span class="hljs-string"><span class="hljs-string">"env &amp;&amp; python3 -m http.server </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$PORT0</span></span></span><span class="hljs-string">"</span></span>, <span class="hljs-string"><span class="hljs-string">"container"</span></span>: { <span class="hljs-string"><span class="hljs-string">"docker"</span></span>: { <span class="hljs-string"><span class="hljs-string">"image"</span></span>: <span class="hljs-string"><span class="hljs-string">"python:3"</span></span> }, <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"DOCKER"</span></span> }, <span class="hljs-string"><span class="hljs-string">"cpus"</span></span>: 0.25, <span class="hljs-string"><span class="hljs-string">"healthChecks"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"gracePeriodSeconds"</span></span>: 3, <span class="hljs-string"><span class="hljs-string">"intervalSeconds"</span></span>: 10, <span class="hljs-string"><span class="hljs-string">"maxConsecutiveFailures"</span></span>: 3, <span class="hljs-string"><span class="hljs-string">"path"</span></span>: <span class="hljs-string"><span class="hljs-string">"/"</span></span>, <span class="hljs-string"><span class="hljs-string">"portIndex"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"HTTP"</span></span>, <span class="hljs-string"><span class="hljs-string">"timeoutSeconds"</span></span>: 5 } ], <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"python-app"</span></span>, <span class="hljs-string"><span class="hljs-string">"instances"</span></span>: 2, <span class="hljs-string"><span class="hljs-string">"mem"</span></span>: 50, <span class="hljs-string"><span class="hljs-string">"ports"</span></span>: [ 0 ], <span class="hljs-string"><span class="hljs-string">"upgradeStrategy"</span></span>: { <span class="hljs-string"><span class="hljs-string">"minimumHealthCapacity"</span></span>: 0.5 } }</code> </pre> <br><br>  Now there will be two full <b>python-app</b> instances running, that is, 2 Python web servers with port flip. <br><br>  Add it also through the Marathon web panel: <br><br><img src="https://habrastorage.org/files/d69/100/0b1/d691000b18d84708bcd2f09df18756a5.png"><br><br>  Now in the Marathon panel we can observe that inspections of the instance work have appeared: <br><br><img src="https://habrastorage.org/files/d4f/7b1/39a/d4f7b139a90549528d16cdd0bfe5d51a.png"><br><br>  At Mesos-master new long-term tasks appeared: <br><br><img src="https://habrastorage.org/files/9ee/b4a/df7/9eeb4adf7a664651bf21121f784a3c4d.png"><br><br>  You can also see which framework has set them to run: <br><br><img src="https://habrastorage.org/files/e88/353/1f1/e883531f1269435ebf5c1be11b113419.png"><br><br>  However, how to find out the port that is assigned to the new Python web servers?  There are several ways and one of them is a request to the Marathon API: <br><br><pre> <code class="bash hljs">curl -X GET -H <span class="hljs-string"><span class="hljs-string">"Content-Type: application/json"</span></span> 10.0.3.12:8080/v2/tasks | python -m json.tool ... { ... { <span class="hljs-string"><span class="hljs-string">"appId"</span></span>: <span class="hljs-string"><span class="hljs-string">"/python-app"</span></span>, <span class="hljs-string"><span class="hljs-string">"healthCheckResults"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"alive"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-string"><span class="hljs-string">"consecutiveFailures"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"firstSuccess"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:20.785Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"lastFailure"</span></span>: null, <span class="hljs-string"><span class="hljs-string">"lastFailureCause"</span></span>: null, <span class="hljs-string"><span class="hljs-string">"lastSuccess"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T12:53:31.372Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"taskId"</span></span>: <span class="hljs-string"><span class="hljs-string">"python-app.53d6ccef-39f7-11e6-a2b6-0800272ca725"</span></span> } ], <span class="hljs-string"><span class="hljs-string">"host"</span></span>: <span class="hljs-string"><span class="hljs-string">"10.0.3.51"</span></span>, <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"python-app.53d6ccef-39f7-11e6-a2b6-0800272ca725"</span></span>, <span class="hljs-string"><span class="hljs-string">"ipAddresses"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"ipAddress"</span></span>: <span class="hljs-string"><span class="hljs-string">"10.0.3.51"</span></span>, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"IPv4"</span></span> } ], <span class="hljs-string"><span class="hljs-string">"ports"</span></span>: [ 31319 ], <span class="hljs-string"><span class="hljs-string">"servicePorts"</span></span>: [ 10001 ], <span class="hljs-string"><span class="hljs-string">"slaveId"</span></span>: <span class="hljs-string"><span class="hljs-string">"4e1e9267-ecf7-4b98-848b-f9a7a30ad209-S2"</span></span>, <span class="hljs-string"><span class="hljs-string">"stagedAt"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:10.767Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"startedAt"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:11.788Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"version"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:10.702Z"</span></span> }, { <span class="hljs-string"><span class="hljs-string">"appId"</span></span>: <span class="hljs-string"><span class="hljs-string">"/python-app"</span></span>, <span class="hljs-string"><span class="hljs-string">"healthCheckResults"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"alive"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-string"><span class="hljs-string">"consecutiveFailures"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"firstSuccess"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:20.789Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"lastFailure"</span></span>: null, <span class="hljs-string"><span class="hljs-string">"lastFailureCause"</span></span>: null, <span class="hljs-string"><span class="hljs-string">"lastSuccess"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T12:53:31.371Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"taskId"</span></span>: <span class="hljs-string"><span class="hljs-string">"python-app.53d6a5de-39f7-11e6-a2b6-0800272ca725"</span></span> } ], <span class="hljs-string"><span class="hljs-string">"host"</span></span>: <span class="hljs-string"><span class="hljs-string">"10.0.3.52"</span></span>, <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"python-app.53d6a5de-39f7-11e6-a2b6-0800272ca725"</span></span>, <span class="hljs-string"><span class="hljs-string">"ipAddresses"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"ipAddress"</span></span>: <span class="hljs-string"><span class="hljs-string">"10.0.3.52"</span></span>, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"IPv4"</span></span> } ], <span class="hljs-string"><span class="hljs-string">"ports"</span></span>: [ 31307 ], <span class="hljs-string"><span class="hljs-string">"servicePorts"</span></span>: [ 10001 ], <span class="hljs-string"><span class="hljs-string">"slaveId"</span></span>: <span class="hljs-string"><span class="hljs-string">"4e1e9267-ecf7-4b98-848b-f9a7a30ad209-S2"</span></span>, <span class="hljs-string"><span class="hljs-string">"stagedAt"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:10.766Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"startedAt"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:11.784Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"version"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-06-24T10:35:10.702Z"</span></span> } ] }</code> </pre> <br><br>  At the addresses <a href="http://10.0.3.52:31307/">http://10.0.3.52:31307</a> and <a href="http://10.0.3.51:31319/">http://10.0.3.51:371319 the</a> new servers will wait for connections: <br><br><img src="https://habrastorage.org/files/7e1/465/e42/7e1465e425d24754b5e16f64fb5a0745.png"><br><br>  Similarly, the port numbers can be found in the Marathon panel. <br><br>  New containers on end hosts: <br><br><pre> <code class="bash hljs">root@mesos-slave1:~<span class="hljs-comment"><span class="hljs-comment"># docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d5e439d61456 python:3 "/bin/sh -c 'env &amp;&amp; p" 2 hours ago Up 2 hours mesos-4e1e9267-ecf7-4b98-848b-f9a7a30ad209-S2.150ac995-bf3c-4ecc-a79c-afc1c617afe2 ... root@mesos-slave2:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1fa55f8cb759 python:3 "/bin/sh -c 'env &amp;&amp; p" 2 hours ago Up 2 hours mesos-4e1e9267-ecf7-4b98-848b-f9a7a30ad209-S2.9392fec2-23c1-4c05-a576-60e9350b9b20 ...</span></span></code> </pre> <br><br>  It is also possible to specify static ports for each new Marathon job.  This is implemented by the <b>Bridget Network Mode</b> .  The correct JSON for creating a task will look like this: <br><br><pre> <code class="bash hljs">{ <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"bridged-webapp"</span></span>, <span class="hljs-string"><span class="hljs-string">"cmd"</span></span>: <span class="hljs-string"><span class="hljs-string">"python3 -m http.server 8080"</span></span>, <span class="hljs-string"><span class="hljs-string">"cpus"</span></span>: 0.5, <span class="hljs-string"><span class="hljs-string">"mem"</span></span>: 64, <span class="hljs-string"><span class="hljs-string">"disk"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"instances"</span></span>: 1, <span class="hljs-string"><span class="hljs-string">"container"</span></span>: { <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"DOCKER"</span></span>, <span class="hljs-string"><span class="hljs-string">"volumes"</span></span>: [], <span class="hljs-string"><span class="hljs-string">"docker"</span></span>: { <span class="hljs-string"><span class="hljs-string">"image"</span></span>: <span class="hljs-string"><span class="hljs-string">"python:3"</span></span>, <span class="hljs-string"><span class="hljs-string">"network"</span></span>: <span class="hljs-string"><span class="hljs-string">"BRIDGE"</span></span>, <span class="hljs-string"><span class="hljs-string">"portMappings"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"containerPort"</span></span>: 8080, <span class="hljs-string"><span class="hljs-string">"hostPort"</span></span>: 31240, <span class="hljs-string"><span class="hljs-string">"servicePort"</span></span>: 9000, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"tcp"</span></span>, <span class="hljs-string"><span class="hljs-string">"labels"</span></span>: {} }, { <span class="hljs-string"><span class="hljs-string">"containerPort"</span></span>: 161, <span class="hljs-string"><span class="hljs-string">"hostPort"</span></span>: 31241, <span class="hljs-string"><span class="hljs-string">"servicePort"</span></span>: 10000, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"udp"</span></span>, <span class="hljs-string"><span class="hljs-string">"labels"</span></span>: {} } ], <span class="hljs-string"><span class="hljs-string">"privileged"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-string"><span class="hljs-string">"parameters"</span></span>: [], <span class="hljs-string"><span class="hljs-string">"forcePullImage"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> } }, <span class="hljs-string"><span class="hljs-string">"healthChecks"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"path"</span></span>: <span class="hljs-string"><span class="hljs-string">"/"</span></span>, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"HTTP"</span></span>, <span class="hljs-string"><span class="hljs-string">"portIndex"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"gracePeriodSeconds"</span></span>: 5, <span class="hljs-string"><span class="hljs-string">"intervalSeconds"</span></span>: 20, <span class="hljs-string"><span class="hljs-string">"timeoutSeconds"</span></span>: 20, <span class="hljs-string"><span class="hljs-string">"maxConsecutiveFailures"</span></span>: 3, <span class="hljs-string"><span class="hljs-string">"ignoreHttp1xx"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> } ], <span class="hljs-string"><span class="hljs-string">"portDefinitions"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"port"</span></span>: 9000, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"tcp"</span></span>, <span class="hljs-string"><span class="hljs-string">"labels"</span></span>: {} }, { <span class="hljs-string"><span class="hljs-string">"port"</span></span>: 10000, <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"tcp"</span></span>, <span class="hljs-string"><span class="hljs-string">"labels"</span></span>: {} } ] }</code> </pre> <br><br>  Therefore, the tcp port of the <b>8080</b> container (containerPort) will be redirected to port <b>31240</b> (hostPort) on the slave machine.  Similarly with udp - <b>161</b> th in <b>31241</b> .  Of course, in this case, there are no reasons to redirect udp at all, and this possibility is given only as an example. <br><br><img src="https://habrastorage.org/files/435/276/d61/435276d611bf4fa299aba647e71f3a2d.png"><br><br>  <b>MESOS-DNS</b> <br><br>  Obviously, access to IP-addresses is not very convenient.  Moreover, the slave on which each next container with a task will be launched will be chosen randomly.  Therefore, it would not be superfluous to be able to automatically bind DNS names to containers. <br><br>  <b>Mesos-DNS</b> can help with this.  This is the DNS server for the Mesos cluster, which uses the Mesos wizard API to retrieve the names of running tasks and the IP addresses of the slaves on which tasks are running. <br><br><img src="https://habrastorage.org/files/990/d2e/45a/990d2e45a21c455da3347b9225ca5745.png"><br><br>  The default domain name will be configured as follows: task name in Mesos + .marathon.mesos.  MESOS-DNS will serve only this zone - all others will be redirected to a standard DNS server. <br><br>  Mesos-DNS is written in the Go language and is distributed as a ready-made compiled binary file.  For which, ideally, you need to write an init or systemd script (depending on the distribution version), but there are ready-made recommendations on the <a href="https://github.com/mesosphere/mesos-dns-pkg/tree/master/common">https://github.com/mesosphere/mesos-dns-pkg/tree/master/common</a> network. <br><br>  To test Mesos-DNS, I created a separate server with the address <b>10.0.3.60</b> , although it could just as well be created in a container using Marathon. <br><br>  Download the latest Mesos-DNS release to the / usr / sbin directory on the new server and rename the binary: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /usr/sbin wget https://github.com/mesosphere/mesos-dns/releases/download/v0.5.2/mesos-dns-v0.5.2-linux-amd64 mv mesos-dns-v0.5.2-linux-amd64 mesos-dns chmod +x mesos-dns</code> </pre> <br><br>  Create a configuration file: <br><br><pre> <code class="bash hljs">vim /etc/mesos-dns/config.json { <span class="hljs-string"><span class="hljs-string">"zk"</span></span>: <span class="hljs-string"><span class="hljs-string">"zk://10.0.3.11:2181,10.0.3.12:2181,10.0.3.13:2181/mesos"</span></span>, <span class="hljs-string"><span class="hljs-string">"masters"</span></span>: [<span class="hljs-string"><span class="hljs-string">"10.0.3.11:5050"</span></span>,<span class="hljs-string"><span class="hljs-string">"10.0.3.12:5050"</span></span>,<span class="hljs-string"><span class="hljs-string">"10.0.3.13:5050"</span></span>], <span class="hljs-string"><span class="hljs-string">"refreshSeconds"</span></span>: 60, <span class="hljs-string"><span class="hljs-string">"ttl"</span></span>: 60, <span class="hljs-string"><span class="hljs-string">"domain"</span></span>: <span class="hljs-string"><span class="hljs-string">"mesos"</span></span>, <span class="hljs-string"><span class="hljs-string">"port"</span></span>: 53, <span class="hljs-string"><span class="hljs-string">"resolvers"</span></span>: [<span class="hljs-string"><span class="hljs-string">"8.8.8.8"</span></span>,<span class="hljs-string"><span class="hljs-string">"8.8.4.4"</span></span>], <span class="hljs-string"><span class="hljs-string">"timeout"</span></span>: 5, <span class="hljs-string"><span class="hljs-string">"email"</span></span>: <span class="hljs-string"><span class="hljs-string">"root.mesos-dns.mesos"</span></span> }</code> </pre> <br><br>  That is, Mesos-DNS will use the request to Zookeeper (zk) to find out information about the current master and poll it once a minute ( <b>refreshSeconds</b> ).  In the case of a request for all other domains except the mesos zone, requests will be redirected to Google‚Äôs DNS servers (the <b>resolvers</b> parameter).  The service will work on the standard port 53, like any other DNS server. <br><br>  The <b>masters option</b> is optional.  First, Mesos-DNS will look for the leader using the request to the Zookeeper server and, if they are not available, it will go through the list of servers specified in the masters. <br><br>  Here is a good article that describes all the possible options <a href="http://mesosphere.github.io/mesos-dns/docs/configuration-parameters.html">http://mesosphere.github.io/mesos-dns/docs/configuration-parameters.html</a> <br><br>  This is enough, so we run Mesos-DNS: <br><br><pre> <code class="bash hljs">/usr/sbin/mesos-dns -config=/etc/mesos-dns/config.json 2016/07/01 11:58:23 Connected to 10.0.3.11:2181 2016/07/01 11:58:23 Authenticated: id=96155239082295306, timeout=40000</code> </pre> <br><p>  Of course, all Mesos cluster nodes (and other nodes from which access to services in containers will be made) should add the Mesos-DNS server address as the main one in <b>/etc/resolv.conf</b> , to the first position: </p><br><pre> <code class="bash hljs">vim /etc/resolv.conf nameserver 10.0.3.60 nameserver 8.8.8.8 nameserver 8.8.4.4</code> </pre> <br><p>  After changing resolv.conf, it‚Äôs worth making sure that all names are re-edited through 10.0.3.60 </p><br><pre> <code class="bash hljs">dig i.ua ; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.8-Ubuntu &lt;&lt;&gt;&gt; i.ua ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 24579 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 512 ;; QUESTION SECTION: ;i.ua. IN A ;; ANSWER SECTION: i.ua. 2403 IN A 91.198.36.14 ;; Query time: 58 msec ;; SERVER: 10.0.3.60<span class="hljs-comment"><span class="hljs-comment">#53(10.0.3.60) ;; WHEN: Mon Jun 27 16:20:12 CEST 2016 ;; MSG SIZE rcvd: 49</span></span></code> </pre> <br><p>  To demonstrate the work of Mesos-DNS, run the following task via Marathon: </p><br><pre> <code class="bash hljs">cat nginx.json { <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx"</span></span>, <span class="hljs-string"><span class="hljs-string">"container"</span></span>: { <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"DOCKER"</span></span>, <span class="hljs-string"><span class="hljs-string">"docker"</span></span>: { <span class="hljs-string"><span class="hljs-string">"image"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx:1.7.7"</span></span>, <span class="hljs-string"><span class="hljs-string">"network"</span></span>: <span class="hljs-string"><span class="hljs-string">"HOST"</span></span> } }, <span class="hljs-string"><span class="hljs-string">"instances"</span></span>: 1, <span class="hljs-string"><span class="hljs-string">"cpus"</span></span>: 0.1, <span class="hljs-string"><span class="hljs-string">"mem"</span></span>: 60, <span class="hljs-string"><span class="hljs-string">"constraints"</span></span>: [ [ <span class="hljs-string"><span class="hljs-string">"hostname"</span></span>, <span class="hljs-string"><span class="hljs-string">"UNIQUE"</span></span> ] ] } curl -X POST -H <span class="hljs-string"><span class="hljs-string">"Content-Type: application/json"</span></span> http://10.0.3.11:8080/v2/apps -d@nginx.json</code> </pre> <br><p>  This task will install the container with Nginx, and Mesos-DNS will register for it the name <b>nginx.marathon.mesos</b> : </p><br><pre> <code class="bash hljs">dig +short nginx.marathon.mesos 10.0.3.53</code> </pre> <br><br><img src="https://habrastorage.org/files/b47/c62/96f/b47c6296fefa42f7836b2f4eba832d83.png"><br><br>  When scaling the nginx task (that is, when creating additional instances), Mesos-DNS recognizes this and creates additional A-records for the same domain: <br><pre> <code class="bash hljs">dig +short nginx.marathon.mesos 10.0.3.53 10.0.3.51</code> </pre> <br><p>  Thus balancing between two nodes at the DNS level will work. </p><br><p>  It is worth noting that Mesos-DNS, in addition to A-records, also creates an SRV-record in DNS for each task (container).  The SRV record links the service name and the hostname-IP port on which it is available.  Check the SRV record for the nginx task, which we launched earlier (not scalable to two instances): </p><br><pre> <code class="bash hljs">dig _nginx._tcp.marathon.mesos SRV ; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.8-Ubuntu &lt;&lt;&gt;&gt; _nginx._tcp.marathon.mesos SRV ;; global options: +cmd ;; Got answer: ;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 11956 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; QUESTION SECTION: ;_nginx._tcp.marathon.mesos. IN SRV ;; ANSWER SECTION: _nginx._tcp.marathon.mesos. 60 IN SRV 0 0 31514 nginx-9g7b9-s0.marathon.mesos. ;; ADDITIONAL SECTION: nginx-9g7b9-s0.marathon.mesos. 60 IN A 10.0.3.51 ;; Query time: 2 msec ;; SERVER: 10.0.3.60<span class="hljs-comment"><span class="hljs-comment">#53(10.0.3.60) ;; WHEN: Fri Jul 01 12:03:37 CEST 2016 ;; MSG SIZE rcvd: 124</span></span></code> </pre> <br><p>  In order not to make changes to the settings of the resolv.conf of each server - you can make changes to the internal DNS infrastructure.  In the case of Bind9, these changes will look like this: </p><br><pre> <code class="bash hljs">vim /etc/<span class="hljs-built_in"><span class="hljs-built_in">bind</span></span>/named.conf.local zone <span class="hljs-string"><span class="hljs-string">"mesos"</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> forward; forward only; forwarders { 192.168.0.100 port 8053; }; };</code> </pre> <br><p>  And in the Mesos-DNS config (imagine that it is now at 192.168.0.100) the following changes should be made: </p><br><pre> <code class="bash hljs">vim /etc/mesos-dns/config.json ... <span class="hljs-string"><span class="hljs-string">"externalon"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-string"><span class="hljs-string">"port"</span></span>: 8053, ...</code> </pre> <br><p>  <b>"externalon": false</b> indicates that Mesos-DNS has the right to refuse service to requests that did not come from mesos domains. </p><br><p>  After the changes are made, you must restart Bind and Mesos-DNS. </p><br><p>  Mesos-DNS also has an API <a href="http-interface/">https://docs.mesosphere.com/1.7/usage/service-discovery/mesos-dns/http-interface/</a> , which can help in solving automation problems. </p><br><p>  Mesos-DNS, in addition to creating records for working tasks, automatically creates records (A and SRV) also for Mesos Slaves, Mesos Masters (and separately for the leader among them), frameworks.  Everything for our convenience. <br></p><br>  <b>MARATHON-LB</b> <br><br>  Despite the advantages, Mesos-DNS also has certain limitations, including: <br><ul><li>  DNS does not bind to the ports on which the services in the containers are running.  They must either be selected statically when setting the task (to monitor their use may not be such a simple task) or to find out a new port every time through Marathon to access the end resources.  Mesos-DNS can also generate SRV records in the DNS (indicating the final hostname and port), but not all programs work out of the box. </li><li>  DNS does not have fast failover (failover function). </li><li>  Records in local DNS caches can be stored for a long time (at least TTL time).  Although the Mesos-DNS itself polls the Mesos Master API quite often. </li><li>  There are no Health-check services in the final containers.  That is, in the case of several instances, the fall of one of them will go unnoticed for Mesos-DNS until it is completely re-created by the Marathon framework. </li><li>  Some programs and libraries do not work correctly with several A-records, which imposes serious restrictions on scaling tasks. </li></ul><br><p>  That is, most problems arise because of the very nature of the DNS. </p><br><p>  To eliminate these shortcomings, the <b>Marathon-lb</b> subproject was launched.  Marathon-lb is a Python script that polls the Marathon API and, based on the data received (the Mesos slave address that physically holds the container and the port of the service), creates the HAproxy configuration file and reloads its process. </p><br><p>  However, it is worth noting that Marathon-lb works only with Marathon, in contrast to Mesos-DNS.  Therefore, in the case of another framework, you will need to look for other software solutions. <br></p><br><img src="https://habrastorage.org/files/d5a/1cf/263/d5a1cf263e9e44e0a3185693874be309.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The figure shows the balancing of requests by two pools of balancers - Internal (for access from the internal network) and External (for access from the Internet). </font><font style="vertical-align: inherit;">The balancer (except ELB) is HAproxy and Marathon-lb. </font><font style="vertical-align: inherit;">ELB is a balancer in the Amazon AWS infrastructure.</font></font><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To configure Marathon-lb, I used a separate virtual machine with the address </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10.0.3.61</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The official documentation also shows the options for running Marathon-lb in a docker container, as a task running from Marathon.</font></font></p><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setting up Marathon-lb and HAproxy is pretty easy. </font><font style="vertical-align: inherit;">We need the latest stable release of HAproxy and for Ubuntu 14.04 this is version 1.6:</font></font></p><br><pre> <code class="bash hljs">apt-get install software-properties-common add-apt-repository ppa:vbernat/haproxy-1.6 apt-get update apt-get install haproxy</code> </pre> <br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Download the Marathon-lb project code: </font></font></p><br><pre> <code class="bash hljs">mkdir /marathon-lb/ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /marathon-lb/ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/mesosphere/marathon-lb .</code> </pre> <br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Install the necessary python packages for work: </font></font></p><br><pre> <code class="bash hljs">apt install python3-pip pip install -r requirements.txt</code> </pre> <br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We generate the keys that marathon-lb requires by default: </font></font></p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /etc/ssl openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes cat key.pem &gt;&gt; mesosphere.com.pem cat cert.pem &gt;&gt; mesosphere.com.pem</code> </pre> <br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We run marathon-lb for the first time: </font></font></p><br><pre> <code class="bash hljs">/marathon-lb/marathon_lb.py --marathon http://my_marathon_ip:8080 --group internal</code> </pre> <br><p>      ‚Äî       Marathon: </p><br><pre> <code class="bash hljs">{ <span class="hljs-string"><span class="hljs-string">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx-internal"</span></span>, <span class="hljs-string"><span class="hljs-string">"container"</span></span>: { <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"DOCKER"</span></span>, <span class="hljs-string"><span class="hljs-string">"docker"</span></span>: { <span class="hljs-string"><span class="hljs-string">"image"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx:1.7.7"</span></span>, <span class="hljs-string"><span class="hljs-string">"network"</span></span>: <span class="hljs-string"><span class="hljs-string">"BRIDGE"</span></span>, <span class="hljs-string"><span class="hljs-string">"portMappings"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"hostPort"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"containerPort"</span></span>: 80, <span class="hljs-string"><span class="hljs-string">"servicePort"</span></span>: 10001 } ], <span class="hljs-string"><span class="hljs-string">"forcePullImage"</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span> } }, <span class="hljs-string"><span class="hljs-string">"instances"</span></span>: 1, <span class="hljs-string"><span class="hljs-string">"cpus"</span></span>: 0.1, <span class="hljs-string"><span class="hljs-string">"mem"</span></span>: 65, <span class="hljs-string"><span class="hljs-string">"healthChecks"</span></span>: [{ <span class="hljs-string"><span class="hljs-string">"protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"HTTP"</span></span>, <span class="hljs-string"><span class="hljs-string">"path"</span></span>: <span class="hljs-string"><span class="hljs-string">"/"</span></span>, <span class="hljs-string"><span class="hljs-string">"portIndex"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"timeoutSeconds"</span></span>: 10, <span class="hljs-string"><span class="hljs-string">"gracePeriodSeconds"</span></span>: 10, <span class="hljs-string"><span class="hljs-string">"intervalSeconds"</span></span>: 2, <span class="hljs-string"><span class="hljs-string">"maxConsecutiveFailures"</span></span>: 10 }], <span class="hljs-string"><span class="hljs-string">"labels"</span></span>:{ <span class="hljs-string"><span class="hljs-string">"HAPROXY_GROUP"</span></span>:<span class="hljs-string"><span class="hljs-string">"internal"</span></span> } }</code> </pre> <br><p>       <b>Running</b> ,  Marathon: </p><br><pre> <code class="bash hljs">/marathon-lb/marathon_lb.py --marathon http://10.0.3.11:8080 --group internal marathon_lb: fetching apps marathon_lb: GET http://10.0.3.11:8080/v2/apps?embed=apps.tasks marathon_lb: got apps [<span class="hljs-string"><span class="hljs-string">'/nginx-internal'</span></span>] marathon_lb: setting default value <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> HAPROXY_BACKEND_REDIRECT_HTTP_TO_HTTPS ... marathon_lb: setting default value <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> HAPROXY_BACKEND_HTTP_HEALTHCHECK_OPTIONS marathon_lb: generating config marathon_lb: HAProxy dir is /etc/haproxy marathon_lb: configuring app /nginx-internal marathon_lb: frontend at *:10001 with backend nginx-internal_10001 marathon_lb: adding virtual host <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> app with id /nginx-internal marathon_lb: backend server 10.0.3.52:31187 on 10.0.3.52 marathon_lb: reading running config from /etc/haproxy/haproxy.cfg marathon_lb: running config is different from generated config - reloading marathon_lb: writing config to temp file /tmp/tmp02nxplxl marathon_lb: checking config with <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>: [<span class="hljs-string"><span class="hljs-string">'haproxy'</span></span>, <span class="hljs-string"><span class="hljs-string">'-f'</span></span>, <span class="hljs-string"><span class="hljs-string">'/tmp/tmp02nxplxl'</span></span>, <span class="hljs-string"><span class="hljs-string">'-c'</span></span>] Configuration file is valid marathon_lb: moving temp file /tmp/tmp02nxplxl to /etc/haproxy/haproxy.cfg marathon_lb: No reload <span class="hljs-built_in"><span class="hljs-built_in">command</span></span> provided, trying to find out how to reload the configuration marathon_lb: we seem to be running on a sysvinit based system marathon_lb: reloading using /etc/init.d/haproxy reload * Reloading haproxy haproxy marathon_lb: reload finished, took 0.02593827247619629 seconds</code> </pre> <br><p>       <b>"HAPROXY_GROUP"</b>   .       ,     . </p><br><p>      haproxy.cfg      <b>10001</b>   <b>10.0.3.52:31187</b> . </p><br><p>  HAproxy    : </p><br><pre> <code class="bash hljs">root@mesos-lb<span class="hljs-comment"><span class="hljs-comment"># netstat -tulpn Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name ... tcp 0 0 0.0.0.0:10001 0.0.0.0:* LISTEN 10285/haproxy ...</span></span></code> </pre> <br><p>  haproxy.cfg   : </p><br><pre> <code class="bash hljs">cat /etc/haproxy/haproxy.cfg ... frontend nginx-internal_10001 <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span> *:10001 mode http use_backend nginx-internal_10001 backend nginx-internal_10001 balance roundrobin mode http option forwardfor http-request <span class="hljs-built_in"><span class="hljs-built_in">set</span></span>-header X-Forwarded-Port %[dst_port] http-request add-header X-Forwarded-Proto https <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> { ssl_fc } option httpchk GET / timeout check 10s server 10_0_3_52_31187 10.0.3.52:31187 check inter 2s fall 11</code> </pre> <br><p> ,   2     Marathon ‚Äî    2    <strong>nginx-internal_10001</strong> . </p><br><img src="https://habrastorage.org/files/eb5/96b/34e/eb596b34eb814db4b6b46f4b6fcb683e.png"><br><p>   ,       ‚Äî    .    ‚Äî   <b>virtual host mapping</b>  HAproxy.     ,        HAproxy,          . </p><br><p>            : </p><br><pre> <code class="bash hljs">{ <span class="hljs-string"><span class="hljs-string">"Id"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx-external"</span></span>, <span class="hljs-string"><span class="hljs-string">"Container"</span></span> { <span class="hljs-string"><span class="hljs-string">"Type"</span></span>: <span class="hljs-string"><span class="hljs-string">"DOCKER"</span></span>, <span class="hljs-string"><span class="hljs-string">"Docker"</span></span> { <span class="hljs-string"><span class="hljs-string">"Image"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx: 1.7.7"</span></span>, <span class="hljs-string"><span class="hljs-string">"Network"</span></span>: <span class="hljs-string"><span class="hljs-string">"BRIDGE"</span></span>, <span class="hljs-string"><span class="hljs-string">"PortMappings"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"HostPort"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"containerPort"</span></span>: 80, <span class="hljs-string"><span class="hljs-string">"servicePort"</span></span> 10000} ], <span class="hljs-string"><span class="hljs-string">"ForcePullImage"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span> } } <span class="hljs-string"><span class="hljs-string">"Instances"</span></span>: 1, <span class="hljs-string"><span class="hljs-string">"Cpus"</span></span>: 0.1, <span class="hljs-string"><span class="hljs-string">"Mem"</span></span>: 65, <span class="hljs-string"><span class="hljs-string">"HealthChecks"</span></span>: [{ <span class="hljs-string"><span class="hljs-string">"Protocol"</span></span>: <span class="hljs-string"><span class="hljs-string">"HTTP"</span></span>, <span class="hljs-string"><span class="hljs-string">"Path"</span></span>: <span class="hljs-string"><span class="hljs-string">"/"</span></span>, <span class="hljs-string"><span class="hljs-string">"PortIndex"</span></span>: 0, <span class="hljs-string"><span class="hljs-string">"TimeoutSeconds"</span></span>: 10 <span class="hljs-string"><span class="hljs-string">"GracePeriodSeconds"</span></span>: 10 <span class="hljs-string"><span class="hljs-string">"IntervalSeconds"</span></span>: 2, <span class="hljs-string"><span class="hljs-string">"MaxConsecutiveFailures"</span></span>: 10 }], <span class="hljs-string"><span class="hljs-string">"Labels"</span></span> { <span class="hljs-string"><span class="hljs-string">"HAPROXY_GROUP"</span></span>: <span class="hljs-string"><span class="hljs-string">"external"</span></span>, <span class="hljs-string"><span class="hljs-string">"HAPROXY_0_VHOST"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx.external.com"</span></span> } }</code> </pre> <br><p> ,     " <b>HAPROXY_0_VHOST</b> "   ,    HAproxy. </p><br><p>  ,  marathon_lb.py: </p><br><pre> <code class="bash hljs">/marathon-lb/marathon_lb.py --marathon Http://10.0.3.11:8080 --group external marathon_lb: fetching apps marathon_lb: GET http://10.0.3.11:8080/v2/apps?embed=apps.tasks marathon_lb: got apps [ <span class="hljs-string"><span class="hljs-string">'/ nginx-internal'</span></span>, <span class="hljs-string"><span class="hljs-string">'/ nginx-external'</span></span>] marathon_lb: setting default value <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> HAPROXY_HTTP_FRONTEND_ACL_WITH_AUTH ... marathon_lb: generating config marathon_lb: HAProxy dir is / etc / haproxy marathon_lb: configuring app / nginx-external marathon_lb: frontend at * 10000 with backend nginx-external_10000 marathon_lb: adding virtual host <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> app with hostname nginx.external.com marathon_lb: adding virtual host <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> app with id / nginx-external marathon_lb: backend server 10.0.3.53:31980 on 10.0.3.53 marathon_lb: reading running config from /etc/haproxy/haproxy.cfg marathon_lb: running config is different from generated config - reloading marathon_lb: writing config to temp file / tmp / tmpcqyorq8x marathon_lb: checking config with <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>: [ <span class="hljs-string"><span class="hljs-string">'haproxy "," -f "," / tmp / tmpcqyorq8x "," -c'</span></span>] Configuration file is valid marathon_lb: moving temp file / tmp / tmpcqyorq8x to /etc/haproxy/haproxy.cfg marathon_lb: No reload <span class="hljs-built_in"><span class="hljs-built_in">command</span></span> provided, trying to find out how to reload the configuration marathon_lb: we seem to be running on a sysvinit based system marathon_lb: reloading using /etc/init.d/haproxy reload * Reloading haproxy haproxy marathon_lb: reload finished, took 0.02756667137145996 seconds</code> </pre> <br><p>     HAproxy: </p><br><pre> <code class="bash hljs">cat /etc/haproxy/haproxy.cfg ... frontend marathon_http_in <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span> * 80 mode http acl host_nginx_external_com_nginx-external hdr (host) -i nginx.external.com use_backend nginx-external_10000 <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> host_nginx_external_com_nginx-external frontend marathon_http_appid_in <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span> *: 9091 mode http acl app__nginx-external hdr (x-marathon-app-id) -i / nginx-external use_backend nginx-external_10000 <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> app__nginx-external frontend marathon_https_in <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span> * 443 ssl crt /etc/ssl/mesosphere.com.pem mode http use_backend nginx-external_10000 <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> {ssl_fc_sni nginx.external.com} frontend nginx-external_10000 <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span> * 10000 mode http use_backend nginx-external_10000 backend nginx-external_10000 balance roundrobin mode http option forwardfor http-request <span class="hljs-built_in"><span class="hljs-built_in">set</span></span>-header X-Forwarded-Port% [dst_port] http-request add-header X-Forwarded-Proto https <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> {ssl_fc} option httpchk GET / timeout check 10s server 10_0_3_53_31980 10.0.3.53:31980 check inter 2s fall 11</code> </pre> <br><p>  ,     nginx.external.com,       HAproxy,          Mesos . </p><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Check the result in the browser: </font></font><br></p><br><img src="https://habrastorage.org/files/53d/57a/cf2/53d57acf285f47619918ac50335628d9.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HAproxy labels are also reflected in Marathon: </font></font><br><br><img src="https://habrastorage.org/files/f47/9a4/763/f479a47636f14e86953b8934404c7313.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In addition, Marathon-lb supports SSL settings for HAproxy, sticky SSL, and data for building haproxy.cfg can be obtained not by an Marathon survey via API, but by subscribing to an Event Bus, etc. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AUTOSCALING</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Anyone who has worked with the Amazon AWS platform knows this excellent opportunity to increase or decrease the number of virtual machines depending on the load. </font><font style="vertical-align: inherit;">Mesos Cluster also has this feature.</font></font><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The first implementation is </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">marathon-autoscale</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The Marathon API script can monitor the CPU / memory usage of the task and raise the number of instances depending on the specified conditions.</font></font></p><br><p> ,  , ‚Äî <b>marathon-lb-autoscale</b> .      Marathon-lb .          ‚Äî        Marathon. </p><br><p>    .       .  ,      ‚Äî        . </p><br><p>       <a href="http://blog.ipeacocks.info/2016/06/mesos-cluster-management.html">http://blog.ipeacocks.info/2016/06/mesos-cluster-management.html</a> </p><br><p>  <b>References:</b> </p><br><p> Getting Stated </p><br><p> <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04">https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04</a> <br> <a href="https://open.mesosphere.com/advanced-course/introduction/">https://open.mesosphere.com/advanced-course/introduction/</a> <br> <a href="https://open.mesosphere.com/getting-started/install/">https://open.mesosphere.com/getting-started/install/</a> <br> <a href="http://iankent.uk/blog/a-quick-introduction-to-apache-mesos/">http://iankent.uk/blog/a-quick-introduction-to-apache-mesos/</a> <br> <a href="http://frankhinek.com/tag/mesos/">http://frankhinek.com/tag/mesos/</a> <br> <a href="https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html">https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html</a> <br> <a href="https://mesosphere.github.io/marathon/">https://mesosphere.github.io/marathon/</a> <br> <a href="https://mesosphere.github.io/marathon/docs/ports.html">https://mesosphere.github.io/marathon/docs/ports.html</a> <br> <a href="https://beingasysadmin.wordpress.com/2014/06/27/managing-docker-clusters-using-mesos-and-marathon/">https://beingasysadmin.wordpress.com/2014/06/27/managing-docker-clusters-using-mesos-and-marathon/</a> <br> <a href="http://mesos.readthedocs.io/en/latest/">http://mesos.readthedocs.io/en/latest/</a> </p><br><p>  Docker </p><br><p> <a href="http://mesos.apache.org/documentation/latest/containerizer/">http://mesos.apache.org/documentation/latest/containerizer/#Composing</a> <br> <a href="http://mesos.apache.org/documentation/latest/docker-containerizer/">http://mesos.apache.org/documentation/latest/docker-containerizer/</a> <br> <a href="https://mesosphere.github.io/marathon/docs/native-docker.html">https://mesosphere.github.io/marathon/docs/native-docker.html</a> </p><br><p> Mesos-DNS </p><br><p> <a href="https://tech.plista.com/devops/mesos-dns/">https://tech.plista.com/devops/mesos-dns/</a> <br> <a href="http://programmableinfrastructure.com/guides/service-discovery/mesos-dns-haproxy-marathon/">http://programmableinfrastructure.com/guides/service-discovery/mesos-dns-haproxy-marathon/</a> <br> <a href="http://mesosphere.github.io/mesos-dns/docs/tutorial-systemd.html">http://mesosphere.github.io/mesos-dns/docs/tutorial-systemd.html</a> <br> <a href="http://mesosphere.github.io/mesos-dns/docs/configuration-parameters.html">http://mesosphere.github.io/mesos-dns/docs/configuration-parameters.html</a> <br> <a href="https://mesosphere.github.io/mesos-dns/docs/tutorial.html">https://mesosphere.github.io/mesos-dns/docs/tutorial.html</a> <br> <a href="https://mesosphere.github.io/mesos-dns/docs/tutorial-forward.html">https://mesosphere.github.io/mesos-dns/docs/tutorial-forward.html</a> <br> <a href="https://github.com/mesosphere/mesos-dns">https://github.com/mesosphere/mesos-dns</a> </p><br><p> Marathon-lb </p><br><p> <a href="https://mesosphere.com/blog/2015/12/04/dcos-marathon-lb/">https://mesosphere.com/blog/2015/12/04/dcos-marathon-lb/</a> <br> <a href="https://mesosphere.com/blog/2015/12/13/service-discovery-and-load-balancing-with-dcos-and-marathon-lb-part-2/">https://mesosphere.com/blog/2015/12/13/service-discovery-and-load-balancing-with-dcos-and-marathon-lb-part-2/</a> <br> <a href="https://docs.mesosphere.com/1.7/usage/service-discovery/marathon-lb/">https://docs.mesosphere.com/1.7/usage/service-discovery/marathon-lb/</a> <br> <a href="https://github.com/mesosphere/marathon-lb">https://github.com/mesosphere/marathon-lb</a> <br> <a href="https://dcos.io/docs/1.7/usage/service-discovery/marathon-lb/usage/">https://dcos.io/docs/1.7/usage/service-discovery/marathon-lb/usage/</a> </p><br><p> Autoscaling </p><br><p> <a href="https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/">https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/</a> <br> <a href="https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/cpu-memory/">https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/cpu-memory/</a> <br> <a href="https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/requests-second/">https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/requests-second/</a> <br> <a href="https://github.com/mesosphere/marathon-autoscale">https://github.com/mesosphere/marathon-autoscale</a> </p><br><p>  Other </p><br><p> <a href="https://clusterhq.com/2016/04/15/resilient-riak-mesos/">https://clusterhq.com/2016/04/15/resilient-riak-mesos/</a> <br> <a href="">https://github.com/CiscoCloud/mesos-consul/blob/master/README.md#comparisons-to-other-discovery-software</a> <br> <a href="http://programmableinfrastructure.com/guides/load-balancing/traefik/">http://programmableinfrastructure.com/guides/load-balancing/traefik/</a> <br> <a href="https://opensource.com/business/14/8/interview-chris-aniszczyk-twitter-apache-mesos">https://opensource.com/business/14/8/interview-chris-aniszczyk-twitter-apache-mesos</a> <br> <a href="http://www.slideshare.net/akirillov/data-processing-platforms-architectures-with-spark-mesos-akka-cassandra-and-kafka">http://www.slideshare.net/akirillov/data-processing-platforms-architectures-with-spark-mesos-akka-cassandra-and-kafka</a> <br> <a href="http://www.slideshare.net/mesosphere/scaling-like-twitter-with-apache-mesos">http://www.slideshare.net/mesosphere/scaling-like-twitter-with-apache-mesos</a> <br> <a href="http://www.slideshare.net/subicura/mesos-on-coreos">http://www.slideshare.net/subicura/mesos-on-coreos</a> <br> <a href="https://www.youtube.com/watch%3Fv%3DRciM1U_zltM">https://www.youtube.com/watch?v=RciM1U_zltM</a> <br> <a href="http://www.slideshare.net/JuliaMateo1/deploying-a-dockerized-distributed-application-in-mesossos-and-marathon/">http://www.slideshare.net/JuliaMateo1/deploying-a-dockerized-distributed-application-in-mesossos-and-marathon/</a> <br> <a href="http://mesos.readthedocs.io/en/latest/">http://mesos.readthedocs.io/en/latest/</a> </p><br><p>  Docker </p><br><p> <a href="http://mesos.apache.org/documentation/latest/containerizer/">http://mesos.apache.org/documentation/latest/containerizer/#Composing</a> <br> <a href="http://mesos.apache.org/documentation/latest/docker-containerizer/">http://mesos.apache.org/documentation/latest/docker-containerizer/</a> <br> <a href="https://mesosphere.github.io/marathon/docs/native-docker.html">https://mesosphere.github.io/marathon/docs/native-docker.html</a> </p><br><p> Mesos-DNS </p><br><p> <a href="https://tech.plista.com/devops/mesos-dns/">https://tech.plista.com/devops/mesos-dns/</a> <br> <a href="http://programmableinfrastructure.com/guides/service-discovery/mesos-dns-haproxy-marathon/">http://programmableinfrastructure.com/guides/service-discovery/mesos-dns-haproxy-marathon/</a> <br> <a href="http://mesosphere.github.io/mesos-dns/docs/tutorial-systemd.html">http://mesosphere.github.io/mesos-dns/docs/tutorial-systemd.html</a> <br> <a href="http://mesosphere.github.io/mesos-dns/docs/configuration-parameters.html">http://mesosphere.github.io/mesos-dns/docs/configuration-parameters.html</a> <br> <a href="https://mesosphere.github.io/mesos-dns/docs/tutorial.html">https://mesosphere.github.io/mesos-dns/docs/tutorial.html</a> <br> <a href="https://mesosphere.github.io/mesos-dns/docs/tutorial-forward.html">https://mesosphere.github.io/mesos-dns/docs/tutorial-forward.html</a> <br> <a href="https://github.com/mesosphere/mesos-dns">https://github.com/mesosphere/mesos-dns</a> </p><br><p> Marathon-lb </p><br><p> <a href="https://mesosphere.com/blog/2015/12/04/dcos-marathon-lb/">https://mesosphere.com/blog/2015/12/04/dcos-marathon-lb/</a> <br> <a href="https://mesosphere.com/blog/2015/12/13/service-discovery-and-load-balancing-with-dcos-and-marathon-lb-part-2/">https://mesosphere.com/blog/2015/12/13/service-discovery-and-load-balancing-with-dcos-and-marathon-lb-part-2/</a> <br> <a href="https://docs.mesosphere.com/1.7/usage/service-discovery/marathon-lb/">https://docs.mesosphere.com/1.7/usage/service-discovery/marathon-lb/</a> <br> <a href="https://github.com/mesosphere/marathon-lb">https://github.com/mesosphere/marathon-lb</a> <br> <a href="https://dcos.io/docs/1.7/usage/service-discovery/marathon-lb/usage/">https://dcos.io/docs/1.7/usage/service-discovery/marathon-lb/usage/</a> </p><br><p> Autoscaling </p><br><p> <a href="https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/">https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/</a> <br> <a href="https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/cpu-memory/">https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/cpu-memory/</a> <br> <a href="https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/requests-second/">https://docs.mesosphere.com/1.7/usage/tutorials/autoscaling/requests-second/</a> <br> <a href="https://github.com/mesosphere/marathon-autoscale">https://github.com/mesosphere/marathon-autoscale</a> </p><br><p>  Other </p><br><p> <a href="https://clusterhq.com/2016/04/15/resilient-riak-mesos/">https://clusterhq.com/2016/04/15/resilient-riak-mesos/</a> <br> <a href="">https://github.com/CiscoCloud/mesos-consul/blob/master/README.md#comparisons-to-other-discovery-software</a> <br> <a href="http://programmableinfrastructure.com/guides/load-balancing/traefik/">http://programmableinfrastructure.com/guides/load-balancing/traefik/</a> <br> <a href="https://opensource.com/business/14/8/interview-chris-aniszczyk-twitter-apache-mesos">https://opensource.com/business/14/8/interview-chris-aniszczyk-twitter-apache-mesos</a> <br> <a href="http://www.slideshare.net/akirillov/data-processing-platforms-architectures-with-spark-mesos-akka-cassandra-and-kafka">http://www.slideshare.net/akirillov/data-processing-platforms-architectures-with-spark-mesos-akka-cassandra-and-kafka</a> <br> <a href="http://www.slideshare.net/mesosphere/scaling-like-twitter-with-apache-mesos">http://www.slideshare.net/mesosphere/scaling-like-twitter-with-apache-mesos</a> <br> <a href="http://www.slideshare.net/subicura/mesos-on-coreos">http://www.slideshare.net/subicura/mesos-on-coreos</a> <br> <a href="https://www.youtube.com/watch%3Fv%3DRciM1U_zltM">https://www.youtube.com/watch?v=RciM1U_zltM</a> <br> <a href="http://www.slideshare.net/JuliaMateo1/deploying-a-dockerized-distributed-application-in-mesos">http://www.slideshare.net/JuliaMateo1/deploying-a-dockerized-distributed-application-in-mesos</a> </p></div><p>Source: <a href="https://habr.com/ru/post/308812/">https://habr.com/ru/post/308812/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../308794/index.html">Why we switched from SharePoint to Bitrix</a></li>
<li><a href="../308796/index.html">On the way to simplicity: how difficult it is for developers</a></li>
<li><a href="../308800/index.html">KPI system in the company: how not to go for three letters</a></li>
<li><a href="../308802/index.html">Empty shelves, a bottle of gasoline and the girl factor: we open a store</a></li>
<li><a href="../308804/index.html">FConsole - debugging tool for PIxi.js (Canvas / WebGL) applications</a></li>
<li><a href="../308814/index.html">Thorny road to sales on Themeforest.net - Part 2</a></li>
<li><a href="../308816/index.html">Virtual User Session vs. VDI: Perspectives and Potential</a></li>
<li><a href="../308818/index.html">When "O" brings a big</a></li>
<li><a href="../308820/index.html">What's new in IntellIJ IDEA 2016.3 EAP</a></li>
<li><a href="../308822/index.html">What is the source of strength and leadership qualities Cheryl Sandberg</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>