<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Normal-oriented Hemisphere SSAO for Dummies</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, username! After a short break, you can again take up three-dimensional graphics. This time we will talk about such a global shading algorithm as t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Normal-oriented Hemisphere SSAO for Dummies</h1><div class="post__text post__text-html js-mediator-article">  Hi, username!  After a short break, you can again take up three-dimensional graphics.  This time we will talk about such a global shading algorithm as the <b>Normal-oriented Hemisphere SSAO</b> .  Interesting?  Under the cat! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c6/724/3f8/3c67243f87a181e10f1f6d6d6cc9948d.jpg" alt="image"><a name="habracut"></a><br><br><h1>  But first a little bit of news. </h1><br>  I refused to use XNA, I began to miss the power of the DX9: of course, in general, nothing has changed, but writing the code has become much less crutch.  All the following examples will be implemented using the <b>SharpDX.Toolkit</b> framework: do not worry, this is the spiritual heir to <b>XNA</b> , also <i>OpenSource</i> and with support for <i>DX11</i> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  Classically - theories </h1><br>  The most important part in the graphics engine of any game (which has claims to be realistic) is lighting.  Now it is impossible to completely simulate the lighting in a real-time game as it happens in our real world.  Relatively speaking, not in real-time applications: the lighting is considered to be ‚Äúlaunching‚Äù photons from a light source in the right directions and registering these photons with a camera (eye).  For real-time processes like this, apromixing is required, for example: we have a certain surface and a light source, and in order to create lighting, we need to calculate the ‚Äúillumination‚Äù of each pixel of the surface, i.e.  only the direct influence of the light source on the texel is taken into account.  This apromix does not take into account indirect lighting, i.e.  in the case of real-time, a photon can be reflected from a surface and affect another Texel.  For single, small light sources this is not particularly critical, but it is worth taking a large light source and an ‚Äúinfinitely distant‚Äù, for example, the sun (the sky acts as a powerful ‚Äúlens‚Äù of light from the sun), then problems arise immediately, something like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d6f/f22/637/d6ff226377bf725c280a25110917df93.gif" alt="image"><br><br>  In the real world, on a similar scene, there would not be such blackness in places of shadows.  Further developing the theme, you can enter a certain ambient value, which will display the overall illumination of the entire scene, a kind of approximation of indirect illumination.  But the fact is that similar lighting throughout the stage is the same everywhere, even in those places where indirect light will have the least impact.  But even here you can cheat and complicate apromixing by shading those areas where the reflected light is the most difficult to reach.  Thus, we come to a concept called ‚Äúglobal shading‚Äù ( <b>ambient occlusion</b> ).  The essence of this approach is that for each fragments of the scene we find some blocking factor, i.e.  the number of non-barred directions of the fall of the "photon" divided by the total number of various directions. <br><br>  Consider the following picture: <br><br><img src="https://habrastorage.org/files/6bb/26f/d1a/6bb26fd1a35c46c28d2447a57a3381b5.png"><br><br>  Here we have two points in question, which form a circle with a radius R around it. And in order to determine the degree of obstruction of the taken fragment, it suffices to find the area of ‚Äã‚Äãthe unlocked space and divide by the total area of ‚Äã‚Äãthe circle.  If we perform a similar operation for all points of the scene, we will get global shading.  It will look something like this (for the three-dimensional case): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b1/789/737/0b178973719142413194138e3787483a.jpg" alt="image"><br><br>  But now you need to think about how to implement a similar algorithm in the pipe-line render of the graphics pipeline.  The difficulty arises in the fact that geometry drawing occurs gradually.  As a result, the first object in the scene will not know about the existence of others.  You can, of course, calculate the AO in advance (at the stage of loading) for the scene, but in this case we will not take into account the dynamically changing geometry: physical objects, characters, etc.  And here comes the work with the geometry in the screen space (Screen Space).  I already <a href="http://habrahabr.ru/post/244367/">mentioned</a> it when talking about the SSLR-algorithm.  This can be used and read AO in screen space.  Here comes the most classic implementation of SSAO, it was invented by cool guys from kortek exactly 8 years ago.  Their algorithm was as follows: after drawing all the geometry, they had a depth buffer, which carries information about all the visible geometry, building spheres for each texel, they counted the number of shading for the scene: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/623/43e/ffc/62343effcfca95803bfebd0023a32475.jpg" alt="image"><br><br>  Here, by the way, there is another difficulty.  The fact is that we cannot take absolutely all directions into account in real-time, firstly, because space is discrete, and secondly, a cross can be put on performance.  We can not even take into account 250 directions (namely, so much is necessary for the minimum imputed image quality).  In order to reduce the number of samples - use some core directions (from 8 to 32), which rotate each time at a random value.  After these operations, AO is available to us in real time: <br><br><img src="https://habrastorage.org/files/4cf/f5d/848/4cff5d8481094f668bcda91c451e53cf.png"><br><br>  The hardest thing in the SSAO algorithm is the definition of a barrier, because it is a reading from a float texture. <br>  A bit later, a modification of the SSAO: <b>Normal-oriented Hemisphere SSAO</b> algorithm was invented.  The essence of the modification is that we can increase the accuracy of the algorithm by taking into account the normals (in fact, we need a <b>GBuffer</b> ).  For the sample space, we will use not a sphere, but a hemisphere that is oriented along the normal of the current texel.  This approach allows you to increase the number of useful samples in two. <br><br><img src="https://habrastorage.org/files/758/8fe/652/7588fe652f54402b832197337d1457b3.png"><br><br>  If you look at the picture, you can understand what I'm saying: <br><br><img src="https://habrastorage.org/files/ab0/426/8ac/ab04268ac1784d84883c03824e0d20d6.png"><br><br>  The final stage of the algorithm will be the blurring of the AO image in order to remove the noise caused by random samples.  Ultimately, the implementation of our algorithm will look like this: <br><br><img src="https://habrastorage.org/files/6c5/ca2/339/6c5ca233965947ae9a544ef23417dc81.png"><br><br>  With theory so far everything is clear, you can go to practice. <br><br><h1>  Theory free zone </h1><br>  I advise you to read <a href="http://habrahabr.ru/post/244367/">this</a> article, there I talked about the essence of the work of <i>Screen Space</i> space.  But, in practice, I will cite very important parts of the code with the necessary comments. <br><br>  The <u>first</u> thing we need is geometry information: <i>GBuffer</i> .  Since  its construction is not included in the topic of the article - I will talk about it in detail some other time. <br><br>  <u>The second</u> is a hemisphere with random directions: <br><br><pre><code class="hljs go">_samplesKernel = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Vector3[<span class="hljs-number"><span class="hljs-number">128</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; _samplesKernel.Length; i++) { _samplesKernel[i].X = random.NextFloat(<span class="hljs-number"><span class="hljs-number">-1f</span></span>, <span class="hljs-number"><span class="hljs-number">1f</span></span>); _samplesKernel[i].Z = random.NextFloat(<span class="hljs-number"><span class="hljs-number">-1f</span></span>, <span class="hljs-number"><span class="hljs-number">1f</span></span>); _samplesKernel[i].Y = random.NextFloat(<span class="hljs-number"><span class="hljs-number">0f</span></span>, <span class="hljs-number"><span class="hljs-number">1f</span></span>); _samplesKernel[i].Normalize(); float scale = (float)i / (float)_samplesKernel.Length; scale = MathUtil.Lerp(<span class="hljs-number"><span class="hljs-number">0.1f</span></span>, <span class="hljs-number"><span class="hljs-number">1.0f</span></span>, scale * scale); _samplesKernel[i] *= scale; }</code> </pre> <br>  It is important to note that in the shader we will not have a trace, since  we are very limited in instructions, instead of this - we will consider the fact of finding the end point in any geometry, therefore it is necessary to take into account more near geometry than far.  To do this, it suffices to take a set of points with a normal distribution in the hemisphere.  This can be obtained by fair normal distribution, you can simply multiply the vector by a random number from 0 to 1, and you can use a small hack: set the length of a function, for example, a quadratic one.  This will give us a better ‚Äúgrade‚Äù of the core. <br><br>  <u>The third</u> is a set of some random vectors, in order to vary the final samples, in my case it is generated in a random way: <br><br><pre> <code class="hljs go">Color[] randomNormal = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Color[_randomNormalTexture.Width * _randomNormalTexture.Height]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; randomNormal.Length; i++) { Vector3 tsRandomNormal = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Vector3(random.NextFloat(<span class="hljs-number"><span class="hljs-number">0f</span></span>, <span class="hljs-number"><span class="hljs-number">1f</span></span>), <span class="hljs-number"><span class="hljs-number">1f</span></span>, random.NextFloat(<span class="hljs-number"><span class="hljs-number">0f</span></span>, <span class="hljs-number"><span class="hljs-number">1f</span></span>)); tsRandomNormal.Normalize(); randomNormal[i] = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Color(tsRandomNormal, <span class="hljs-number"><span class="hljs-number">1f</span></span>); }</code> </pre> <br>  But it looks like this: <br><br><br><br>  You should not use such a texture more than 4x4-8x8, because such a rotation of the core gives a low-frequency noise, which is much easier to blur in the future. <br><br>  Now let's look at the SSAO shader body: <br><br><pre> <code class="hljs matlab">float depth = GetDepth(UV); float3 texelNormal = GetNormal(UV); float3 texelPosition = GetPosition2(UV, depth) + texelNormal * NORMAL_BIAS; float3 random = normalize(RandomTexture.Sample(NoiseSampler, UV * RNTextureSize).xyz); float ssao = <span class="hljs-number"><span class="hljs-number">0</span></span>; [unroll] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(int <span class="hljs-built_in"><span class="hljs-built_in">i</span></span> = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">i</span></span> &lt; MAX_SAMPLE_COUNT; <span class="hljs-built_in"><span class="hljs-built_in">i</span></span>++) { float3 hemisphereRandomNormal = reflect(SamplesKernel[<span class="hljs-built_in"><span class="hljs-built_in">i</span></span>], random); float3 hemisphereNormalOrientated = hemisphereRandomNormal * <span class="hljs-built_in"><span class="hljs-built_in">sign</span></span>( <span class="hljs-built_in"><span class="hljs-built_in">dot</span></span>(hemisphereRandomNormal, texelNormal)); ssao += calculateOcclusion(texelPosition, texelNormal, hemisphereNormalOrientated, RADIUS); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (ssao / MAX_SAMPLE_COUNT);</code> </pre> <br>  Here we get a non-linear depth, we get the world position and the normal, we get a set of random vectors stretched across the screen.  It should immediately say in advance about the two hacks. <br><br>  The first is that we shift the texel position by the normal multiplied by some small value, this is necessary in order to get rid of unnecessary intersections due to the discreteness of the screen space of the space: <br><br>  And the second is that in the algorithm we need to compare the depth values, and the nonlinear depth at medium-long distances is in the vicinity of the unit.  In an amicable way, we should linearize this depth, but since  such values ‚Äã‚Äãare used only for comparison - you can enter a certain estimate of non-linear depth: <br><br><pre> <code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">depthAssessment_invsqrt</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> nonLinearDepth)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - nonLinearDepth); }</code> </pre> <br>  We should also say that it would be good to make a unroll cycle, since  The number of samples is known in advance; such code will work faster. <br><br>  Then the algorithm itself begins: <br>  Rotate the core and orient this core along the normal in the textile: <br><br><pre> <code class="hljs matlab">float3 hemisphereRandomNormal = reflect(SamplesKernel[<span class="hljs-built_in"><span class="hljs-built_in">i</span></span>], random); float3 hemisphereNormalOrientated = hemisphereRandomNormal * <span class="hljs-built_in"><span class="hljs-built_in">sign</span></span>( <span class="hljs-built_in"><span class="hljs-built_in">dot</span></span>(hemisphereRandomNormal, texelNormal));</code> </pre> <br>  And we pass the functions of the calculation of the barrier: <br><br><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">float</span></span> calculateOcclusion(float3 texelPosition, float3 texelNormal, float3 sampleDir, <span class="hljs-type"><span class="hljs-type">float</span></span> radius) { float3 position = texelPosition + sampleDir * radius; float3 sampleProjected = GetUV(position); <span class="hljs-type"><span class="hljs-type">float</span></span> sampleRealDepth = GetDepth(sampleProjected.xy); <span class="hljs-type"><span class="hljs-type">float</span></span> assessProjected = depthAssessment_invsqrt(sampleProjected.z); <span class="hljs-type"><span class="hljs-type">float</span></span> assessReaded = depthAssessment_invsqrt(sampleRealDepth); <span class="hljs-type"><span class="hljs-type">float</span></span> differnce = (assessReaded - assessProjected); <span class="hljs-type"><span class="hljs-type">float</span></span> occlussion = step(differnce, <span class="hljs-number"><span class="hljs-number">0</span></span>); // (x &gt;= y) ? <span class="hljs-number"><span class="hljs-number">1</span></span> : <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-type"><span class="hljs-type">float</span></span> distanceCheck = min(<span class="hljs-number"><span class="hljs-number">1.0</span></span>, radius / abs(assessmentDepth - assessReaded)); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> occlussion * distanceCheck; }</code> </pre> <br>  We take a sample and design it into the screen space (we obtain new UV.xy values ‚Äã‚Äãand non-linear depth): <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">float3</span></span> position = texelPosition + sampleDir * radius; <span class="hljs-attribute"><span class="hljs-attribute">float3</span></span> sampleProjected = GetUV(position);</code> </pre> <br><br>  The projection function is as follows: <br><pre> <code class="hljs go">float3 _innerGetUV(float3 position, float4x4 VP) { float4 pVP = mul(float4(position, <span class="hljs-number"><span class="hljs-number">1.0f</span></span>), VP); pVP.xy = float2(<span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-number"><span class="hljs-number">0.5f</span></span>) + float2(<span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-number"><span class="hljs-number">-0.5f</span></span>) * pVP.xy / pVP.w; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> float3(pVP.xy, pVP.z / pVP.w); } float3 GetUV(float3 position) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> _innerGetUV(position, ViewProjection); }</code> </pre> <br>  <s>Constants 0.5f ask for them to be stitched into a matrix.</s> <br><br>  After that we get a new depth value: <br><pre> <code class="hljs objectivec"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> assessProjected = depthAssessment_invsqrt(sampleProjected.z); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> assessReaded = depthAssessment_invsqrt(sampleRealDepth); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> differnce = (assessReaded - assessProjected); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> occlussion = step(differnce, <span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-comment"><span class="hljs-comment">// (x &gt;= y) ? 1 : 0</span></span></code> </pre> <br>  We define the barrage fact as ‚Äúwhether the point is visible to the observer‚Äù, i.e.  if the point does not lie in any geometry - then <i>assessReaded</i> will always be strictly less <i>assessProjected</i> . <br><br>  Well, given the fact that in the screen space is full of such a phenomenon as information lost, we must adjust the amount of shading depending on the distance ‚Äúpenetration‚Äù into the geometry.  This is necessary so that we do not know anything about geometry beyond the visible part of the screen space: <br><br><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">float</span></span> distanceCheck = min(<span class="hljs-number"><span class="hljs-number">1.0</span></span>, radius / abs(differnce));</code> </pre> <br>  Well, the final stage, this blur.  I will only say that it is impossible to blur the SSAO buffer without taking into account the depth heterogeneity as many do.  Also, it would be good to take into account the normal when blurring, like this: <br><br><pre> <code class="hljs mel">[flatten] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(DepthAnalysis) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> lDepthR = LinearizeDepth(GetDepth(UVR)); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> lDepthL = LinearizeDepth(GetDepth(UVL)); depthFactorR = saturate(<span class="hljs-number"><span class="hljs-number">1.0</span></span>f / (<span class="hljs-keyword"><span class="hljs-keyword">abs</span></span>(lDepthR - lDepthC) / DepthAnalysisFactor)); depthFactorL = saturate(<span class="hljs-number"><span class="hljs-number">1.0</span></span>f / (<span class="hljs-keyword"><span class="hljs-keyword">abs</span></span>(lDepthL - lDepthC) / DepthAnalysisFactor)); } [flatten] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(NormalAnalysis) { float3 normalR = GetNormal(UVR); float3 normalL = GetNormal(UVL); normalFactorL = saturate(<span class="hljs-keyword"><span class="hljs-keyword">max</span></span>(<span class="hljs-number"><span class="hljs-number">0.0</span></span>f, <span class="hljs-keyword"><span class="hljs-keyword">dot</span></span>(normalC, normalL))); normalFactorR = saturate(<span class="hljs-keyword"><span class="hljs-keyword">max</span></span>(<span class="hljs-number"><span class="hljs-number">0.0</span></span>f, <span class="hljs-keyword"><span class="hljs-keyword">dot</span></span>(normalC, normalR))); }</code> </pre> <br>  The <i>depthFactor</i> and <i>normalFactor</i> coefficients are taken into account in the blur coefficients. <br><br><h1>  Instead of the conclusion </h1><br>  For a more detailed study - I will leave the full source code <a href="">here</a> , and for those who like to see with their own eyes the demo <a href="">here</a> . <br>  By the way, in the demo I intend to leave <i>NORMAL_BIAS</i> equal to zero to see the problem, besides, only geometry is drawn in the <i>GBuffer</i> and there is no <i>normal</i> mapping, which is why <i>z-fighting</i> happens at long distances. <br><br>  In future articles I will try to highlight other real-time ao algorithms, such as <i>HBAO, HDAO, HBAO +</i> , if this topic is interesting, of course. <br><br>  <u><i>Have a good job!</i></u> </div><p>Source: <a href="https://habr.com/ru/post/248313/">https://habr.com/ru/post/248313/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../248303/index.html">Publish configuration 1C on GitHub</a></li>
<li><a href="../248305/index.html">The tale of the development of active wireless speakers HiFi. And about. Part 1</a></li>
<li><a href="../248307/index.html">As we now do children's lesson about programmers and programming with broadcast</a></li>
<li><a href="../248309/index.html">Behavioral factors in Yandex. The nuances of the filter, which every webmaster should know</a></li>
<li><a href="../248311/index.html">Guide to the best letters</a></li>
<li><a href="../248319/index.html">3CX Phone System 12.5 Final Release Released</a></li>
<li><a href="../248321/index.html">How to write a good demo</a></li>
<li><a href="../248323/index.html">65% discount on the seminar "Technologies and data storage systems for SMB customers" (Kiev)</a></li>
<li><a href="../248325/index.html">How to carry out an assessment on three points?</a></li>
<li><a href="../248327/index.html">Autonomous security and surveillance system on the Raspberry PI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>