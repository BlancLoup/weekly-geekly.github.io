<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apply machine learning to improve PostgreSQL performance.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Machine learning is engaged in the search for hidden patterns in the data. The growing growth of interest in this topic in the IT community is associa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apply machine learning to improve PostgreSQL performance.</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/c34/846/1fc/c348461fc80f33e3dcd2721b806fe9ec.jpg" alt="image" width="50%" align="right"><br><br>  Machine learning is engaged in the search for hidden patterns in the data.  The growing growth of interest in this topic in the IT community is associated with exceptional results obtained through it.  Speech recognition and scanned documents, search engines - all this is created using machine learning.  In this article I will talk about the current project of our company: how to apply the methods of machine learning to increase the performance of the DBMS. <br>  The first part of this article deals with the existing PostgreSQL scheduler mechanism, the second part describes the possibilities for improving it using machine learning. <br><br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  What is a SQL query execution plan? </h3><br>  Recall that SQL is a declarative language.  This means that the user indicates only what operations should be done with the data.  The DBMS is responsible for selecting the method for performing these operations.  For example, the query <br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> age &gt; <span class="hljs-number"><span class="hljs-number">25</span></span>;</code> </pre> <br>  You can do it in two ways: read all the records from the users table and check each of them for age&gt; 25, or use the index on the age field.  In the second case, we do not view the extra records, but spend more time processing one record due to operations with indices. <br><br><img src="https://habrastorage.org/files/5ab/2fc/de4/5ab2fcde457847cfb30132d660327b31.png"><br><br>  Consider a more complex query. <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> messages.text <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span>, messages <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> users.id = messages.sender_id;</code> </pre><br>  This JOIN can be done in three ways: <br><ul><li>  A nested loop (NestedLoopJoin) scans all possible pairs of records from two tables and checks the condition for each pair. </li><li>  Merging (MergeJoin) sorts both tables by the id and sender_id fields, respectively, and then uses the two-pointer method to find all pairs of records that satisfy the condition.  This method is similar to the merge sort method (MergeSort). </li><li>  Hashing (HashJoin) builds a hash table over the field of the smallest table (in our case, this field is users.id).  The hash table allows for each record from messages to quickly find a record in which users.id = messages.sender_id. </li></ul><br><img src="https://habrastorage.org/files/99e/c77/44e/99ec7744e60e4669b77447cb29384371.png"><br><br>  If the request requires more than one Join operation, then you can also perform them in a different order, for example, in the request <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> u1.name, u2.name, m.text <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> u1, messages <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> m, <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> u2 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> u1.id = m.sender_id <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> u2.id = m.reciever_id;</code> </pre><br><img src="https://habrastorage.org/files/690/a54/47e/690a5447eb7349618e385d223aefa2d3.png"><br><br>  The query execution tree is called the query execution <i>plan</i> . <br><br>  You can view the plan that the DBMS chooses for a particular request using the <code>explain</code> command: <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> u1.name, u2.name, m.text <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> u1, messages <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> m, <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> u2 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> u1.id = m.sender_id <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> u2.id = m.reciever_id;</code> </pre><br><br>  In order to fulfill the request and see the plan chosen for it, you can use the <code>explain analyse</code> command: <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> ANALYSE <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> u1.name, u2.name, m.text <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> u1, messages <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> m, <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> u2 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> u1.id = m.sender_id <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> u2.id = m.reciever_id;</code> </pre><br><br>  The execution time of different plans for the same query may differ by many orders of magnitude.  Therefore, the correct choice of the query execution plan has a serious impact on the performance of the DBMS.  We will understand in more detail how the plan is selected in PostgreSQL now. <br><br><h3>  How does the DBMS search for the optimal query execution plan? </h3><br>  You can divide the process of finding the optimal plan into two parts. <br><br>  First, you need to be able to estimate the <i>cost of</i> any plan - the amount of resources necessary for its implementation.  In the case when the server does not perform other tasks and requests, the estimated time to complete the request is directly proportional to the amount of resources spent on it.  Therefore, we can assume that the cost of the plan is its execution time in some conventional units. <br><br>  Secondly, you want to choose a plan with a minimum estimate of value.  It is easy to show that the number of plans grows exponentially with an increase in the complexity of the query, so you cannot just go through all the plans, estimate the cost of each and choose the cheapest one.  To search for the optimal plan, more complex discrete optimization algorithms are used: dynamic programming over subsets for simple queries and a genetic algorithm for complex ones. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/851/f1f/a62/851f1fa62c064fb5b0fc945b6c96c2bd.png" width="75%"></div><br><br>  In our project, we focused on the first task: according to this plan, we need to predict its cost.  How can this be done without launching a plan for execution? <br><div class="spoiler">  <b class="spoiler_title">In fact</b> <div class="spoiler_text">  In PostgreSQL, two costs are predicted for the plan: start-up cost and total cost.  The start-up cost shows how much resources the plan spends before it issues the first record, and the total cost ‚Äî how many total resources the plan will need to complete.  However, this is not essential for this article.  In the future, the cost of implementation will be understood as the total cost. <br></div></div><br><br>  This task is also divided into two subtasks.  First, for each vertex of the plan (plan node) it is predicted how many tuples will be selected in it.  Then, on the basis of this information, the cost of executing each vertex, and, accordingly, the entire plan, is estimated. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/bf3/909/942/bf3909942861421c88d81146295d1505.png" width="50%"></div><br><br>  We did a little research to establish which of the two subtasks in PostgreSQL is worse. <br>  Each point in the figures below corresponds to one vertex of the plan.  For each vertex, the number of tuples selected in it and the cost of its execution were predicted, and then the actual number of selected tuples and the execution time were measured.  On the right picture, only those vertices are displayed for which the number of tuples is predicted correctly, so it is possible to judge the quality of the cost estimate from it. <br><table><tbody><tr><th align="center"><img src="https://habrastorage.org/files/8ce/4ad/fb2/8ce4adfb268e4c54b3447073ee1c69a6.png" width="100%"></th><th align="center"><img src="https://habrastorage.org/files/107/63e/f75/10763ef757dd4dd6815c208ad4152a35.png" width="100%"></th></tr><tr><td>  Dependence of the true number of tuples on the predicted </td><td align="center">  The dependence of the time of the plan on the cost <br>  if the number of tuples is predicted correctly </td></tr></tbody></table><br>  The first figure shows that the result of solving the first subtask differs from the true one by several orders of magnitude.  The second figure shows that with the right solution to the first subtask, the PostgreSQL model rather adequately estimates the cost of executing one plan or another, since a strong correlation with the execution time is seen.  As a result, it was found that the performance of the DBMS suffers from inaccurate solutions of <i>both</i> subtasks, but it suffers more from the incorrectly established number of tuples at each vertex. <br><br>  Consider the first subtask solution used in PostgreSQL. <br><br><h3>  How does the DBMS estimate the number of tuples at the vertices? </h3><br>  First, let's try to predict the number of tuples selected by a simple query. <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> age &lt; <span class="hljs-number"><span class="hljs-number">25</span></span>;</code> </pre><br><br>  In order to have at least some opportunity to do this, we need some information about the data, statistics on them.  PostgreSQL uses histograms for this data information. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/922/33f/788/92233f7881b74df7988ea63d97f308f7.png"></div><br><br>  Using the histogram, we can easily restore the proportion of those users who are under 25 years old.  For each vertex of the plan, the proportion of all selected tuples in relation to all processed tuples is called <i>selectivity</i> .  In the given example, the selectivity of SeqScan will be approximately 0.3.  To get the number of tuples selected by the vertex, it will be enough to multiply the vertex selectivity by the number of processed tuples (in the case of SeqScan, this will be the number of records in the table). <br><br>  Consider a more complex query. <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">users</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> age &lt; <span class="hljs-number"><span class="hljs-number">25</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> city = <span class="hljs-string"><span class="hljs-string">'Moscow'</span></span>;</code> </pre><br><br>  In this case, using histograms by age and city, we can only get <i>marginal</i> selectivity, that is, the proportion of users under 25 and the proportion of Muscovites among users.  In the PostgreSQL model, all conditions (except pairs of conditions like <code>5 &lt; a AND a &lt; 7</code> , which automatically turn into condition <code>5 &lt; a &lt; 7</code> ) are considered <i>independent</i> .  Mathematicians call two conditions A and B independent if the probability that both conditions are fulfilled simultaneously is equal to the product of their probabilities: P (A and B) = P (A) P (B).  However, in the applied sense, one can understand the independence of two quantities as the fact that the distribution of another quantity does not depend on the value of one quantity. <br><br><h3>  What is the problem? </h3><br><img src="https://habrastorage.org/files/f6d/ae2/108/f6dae2108ad947838420c0f98e65d6be.png"><br><br>  In some cases, the assumption of independence conditions is not satisfied.  In such cases, the PostgreSQL model does not work very well.  There are two ways to deal with this problem. <br><br>  The first way is to build multi-dimensional histograms.  The problem with this method is that as the dimension increases, a multidimensional histogram requires an exponentially growing amount of resources to maintain the same accuracy.  Therefore it is necessary to be limited to histograms of small dimension (2-8 measurements).  From here follows the second problem of this method: it is necessary to somehow understand for which pairs (or triples, or quadruples ...) of columns it makes sense to build multidimensional histograms, and for which it is not necessary. <br>  To solve this problem, you need either a good administrator who will study the plans of resource-intensive queries, determine correlations between the columns and manually specify which histograms you need to complete, or a software tool that will try to find columns dependent on each other using statistical tests.  However, it does not make sense to build histograms for all dependent columns, therefore the software should also analyze the coexistence of columns in queries.  Currently, there are patches that allow using multidimensional histograms in PostgreSQL, but the administrator needs to manually specify in which columns these multidimensional histograms should be built. <br><br><h3>  We use machine learning to evaluate selectivity. </h3><br>  However, this article focuses on an alternative approach.  An alternative approach is the use of machine learning to find the joint selectivity of several conditions.  As mentioned above, machine learning is engaged in finding patterns in the data.  Data is a collection of objects.  In our case, the object is a set of conditions in one vertex of the plan.  According to these conditions and their marginal choices, we need to predict joint selectivity. <br><br>  The observed signs of the top of the plan will be the marginal selectivity of all its conditions.  We assume that all conditions that differ only in constants are equivalent to each other.  You can consider this assumption as a typical method of machine learning - hashing trick - used to reduce the dimension of space.  However, a more powerful motivation is behind this: we assume that all the information necessary for a prediction about the constants of a condition is contained in its marginal selectivity.  This can be shown strictly for simple conditions of the form a &lt;const: here, by the conditional selectivity, we can restore the value of a constant, that is, there is no loss of information. <br><br>  The resulting machine learning task will look like the one shown in the figure. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/05b/b04/2c7/05bb042c75bd4d6592d72ab5ecb28d07.png" width="70%"></div><br>  We must predict the leftmost column from the known values ‚Äã‚Äãin all other columns.  Such a task, in which it is necessary to predict a real number, in machine learning is called a regression problem.  The method that solves it is called the regressor, respectively. <br><br>  Let us turn to logarithms in all columns.  Note that if we now use linear regression, then we will get the current PostgreSQL model as a special case. <br><br>  Linear regression: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/18d/a2b/fc6/18da2bfc657249898fb8a804a531c74a.png" width="50%"></div><br><br>  In the case when all the adjustable parameters are 1, we get the standard PostgreSQL selectivity model: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/6ef/fd2/eb0/6effd2eb0eaf4848a5e2f55ce38f68f5.png" width="40%"></div><br><br>  The standard ridge regression method suggests looking for parameters by minimizing the following functional: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/8a7/290/5c7/8a72905c72c24ec6ad6a505b01a09025.png"></div><br><br>  To test different approaches, we used the TPC-H benchmark. <br><br>  The following methods were used as simple regressors: <br><ul><li>  Ridge linear regression + stochastic gradient descent.  This method is good because it allows the use of dynamic learning (online learning), so it does not require to store any observable objects. </li><li>  Many linear ridge regression + stochastic gradient descent.  Here it is assumed that for each set of conditions a separate row-wise linear regressor is created.  This method, like the previous one, is good because it allows the use of dynamic learning, so it does not require to store any observable objects, but it works somewhat more precisely than the previous one, because it contains significantly more configurable parameters. </li><li>  Many linear ridge regression + analytical solution by Gauss method.  This method requires storing all monitored objects, but at the same time, unlike the two previous ones, it is much faster to configure data. <br>  However, this is also his minus: he behaves rather unstable. <br></li></ul><br>  Let us explain the nature of the instability arising from the analytical solution.  Our regressor responses are input to the optimizer, which is looking for the optimal plan.  The objects we observe (executable plans) are the output values ‚Äã‚Äãof the optimizer.  Therefore, the objects we observe depend on the responses of the regressor.  Such feedback systems are much more difficult to study than systems in which the regressor does not affect the environment.  It is in these terms that the analytical solution by the Gauss method is unstable - it learns quickly, but offers more risky solutions, so the system as a whole works worse. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/378/eae/378/378eae37884a45668f091a313ced7e5b.png" width="50%"></div><br><br>  After a detailed study of the linear model, we found that it does not fully describe the data.  Therefore, the best results from the methods we tested showed kNN. <br><ul><li>  kNN.  A significant disadvantage of this method is the need to store in memory all objects, followed by the organization of a quick search for them.  This situation can be significantly improved using the object selection algorithm.  The idea of ‚Äã‚Äãa naive object selection algorithm: if the prediction on an object is good enough, then it is not necessary to memorize this object. </li></ul><br><br>  This method is also more stable than linear regression: convergence on the TPC-H benchmark requires only 2 training cycles shown in the figure above. <br><br><h3>  What causes the use of machine learning </h3><br>  We present the results obtained for the kNN algorithm. <br><br><table><tbody><tr><td><img src="https://habrastorage.org/files/079/79e/86e/07979e86e1174b1caf76c24a2d888999.png" width="100%"></td><td><img src="https://habrastorage.org/files/395/be8/81d/395be881d319474d902f6f2958a68233.png" width="100%"></td></tr><tr><td align="center">  Before machine learning </td><td align="center">  After machine learning </td></tr></tbody></table><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b1c/f78/bdc/b1cf78bdc87b4b0895c453d84762ed22.png"></div><br><br>  You can see that the proposed approach really speeds up the time for the DBMS.  On one of the benchmark request types, the acceleration is 30-45%, on the other - 2-4 times. <br><br><h3>  What are the ways of development? </h3><br>  There are still many areas for further improvement of the existing prototype. <br><br><ol><li>  The problem of finding plans.  The current algorithm ensures that in those plans to which the algorithm converges, the selectivity predictions will be correct.  However, this does not guarantee the global optimality of the selected plans.  The search for globally optimal plans or at least the best local optimum is a separate task. </li><li>  Interrupt mode to stop the execution of an unsuccessful plan.  In the standard PostgreSQL model, it does not make sense for us to interrupt the execution of the plan, since we have only one best plan and it does not change.  With the introduction of machine learning, we can interrupt the implementation of the plan, in which serious mistakes were made in the prediction of selectivity, take into account the information received and choose a new best plan for implementation.  In most cases, the new plan will differ significantly from the previous one. </li><li>  Modes of obsolescence of information.  During the operation of the DBMS, the data and typical queries change.  Therefore, data that was obtained in the past may be irrelevant.  Now our company is working on a good system for determining the relevance of information, and, accordingly, "forgetting" outdated information. </li></ol><br><br><h3>  What was it? </h3><br>  In this article we: <br><ul><li>  dismantled the mechanism of the PostgreSQL scheduler; </li><li>  noted problems in the current selectivity estimation algorithm; </li><li>  showed how machine learning methods can be used to evaluate selectivity; </li><li>  It was established experimentally that the use of machine learning leads to an improvement in the work of the scheduler and, accordingly, to an acceleration of the work of the DBMS. </li></ul><br><br>  Thanks for attention! <br><br><img src="http://luxetravel.wpengine.netdna-cdn.com/wp-content/uploads/2012/09/Elephant-Painting3.jpg" width="50%" alt="image" align="right"><br><br><h3>  Literature </h3><br><ul><li>  Pro PostgreSQL Scheduler <br><ul><li>  <a href="https://momjian.us/main/writings/pgsql/optimizer.pdf">Explaining the Postgres Query Optimizer, Bruce Momjian</a> </li><li>  <a href="http://www.postgresql.org/developer/coding/">PostgreSQL Developer Materials</a> </li><li>  <a href="http://www.neilconway.org/talks/hacking/">Reports about the internal device PostgreSQL, Neil Conway</a> </li></ul><br></li><li>  About machine learning (from the lecture course of K. V. Vorontsov) <br><ul><li>  <a href="http://www.machinelearning.ru/wiki/images/f/fc/Voron-ML-Intro-slides.pdf">Introduction to machine learning</a> </li><li>  <a href="http://www.machinelearning.ru/wiki/images/c/c3/Voron-ML-Metric-slides.pdf">Metric methods</a> </li><li>  <a href="http://www.machinelearning.ru/wiki/images/5/53/Voron-ML-Lin-SG.pdf">Linear models and stochastic gradient</a> </li></ul><br></li></ul></div><p>Source: <a href="https://habr.com/ru/post/273199/">https://habr.com/ru/post/273199/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../273185/index.html">A bit about Facebook data center</a></li>
<li><a href="../273189/index.html">XML, XQuery and Triple Grief with Performance</a></li>
<li><a href="../273191/index.html">Test the theory of six handshakes</a></li>
<li><a href="../273193/index.html">Introducing Kerio Control 9</a></li>
<li><a href="../273197/index.html">Give the youth</a></li>
<li><a href="../273201/index.html">Installing the VNC server, and setting it up over SSH</a></li>
<li><a href="../273205/index.html">3 business projects that improve the data center industry</a></li>
<li><a href="../273209/index.html">Update Windows 10 SDK - build 10586</a></li>
<li><a href="../273213/index.html">Critical 0-day vulnerability detected in CMS Joomla</a></li>
<li><a href="../273217/index.html">HTML5 Mastery: Fragments</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>