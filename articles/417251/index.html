<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using the Fish eye camera on a Raspberry Pi 3 with ROS - part 1</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, dear readers of Habr. A few years ago I wrote about using the Raspberry Pi Camera Board camera on the Raspberry Pi in conjunction with...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using the Fish eye camera on a Raspberry Pi 3 with ROS - part 1</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, dear readers of Habr.  A few years ago I <a href="https://habr.com/post/388927/">wrote</a> about using the Raspberry Pi Camera Board camera on the Raspberry Pi in conjunction with ROS.  In this and the next article I would like to talk about the use of a wide-angle fish eye camera on the Raspberry Pi 3 with Ubuntu 16.04 installed.  Who cares please under the cat. <br><a name="habracut"></a><br>  For a start, why exactly fish eye camera?  I have seen many articles on the use of wide-angle cameras for visual odometry and SLAM.  Due to the greater viewing angle fish eye camera improves the accuracy of visual odometry.  Therefore, I wanted to try one such camera with Raspberry Pi with ROS support.  I bought a camera with a 160 degree angle on <a href="http://www.dx.com/p/adjustable-focus-160-degreeviewing-angle-fisheye-lens-raspberry-pi-camera-w-2-ir-lights-board-423129">dx.com</a> for $ 28.  Two IR night vision lamps are also included with the camera: <br><br><img src="https://habrastorage.org/webt/gl/wv/z4/glwvz4wepa70om2eyr5vviaerso.jpeg" alt="image"><br><br>  In the first article I will talk about installing the necessary drivers, OpenCV 3 and packages to support the Raspberry Pi Camera Board camera in ROS. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Installing a fish eye camera driver on Raspberry Pi 3 </h2><br>  So, let's begin.  Connect to RPi 3 via SSH: <br><br><pre><code class="bash hljs">ssh -Y &lt;user&gt;@&lt;ip&gt;</code> </pre> <br>  The -Y parameter allows you to solve the problem with getting the error ‚ÄúCould not connect to display‚Äù when running some GUI applications (Qt, window with an image from the OpenCV program).  More details can be found <a href="https://unix.stackexchange.com/questions/83949/with-ssh-x11-forwarding-ssh-x-get-cant-open-display-trying-to-run-x-app">here</a> . <br><br>  First we need to enable the camera driver support in the Raspberry Pi raspi-config settings.  This service is already included in Raspbian, it must be installed in Ubuntu: <br><br><pre> <code class="bash hljs">sudo apt-get install raspi-config</code> </pre><br>  Run the raspi-config: <br><br><pre> <code class="bash hljs">sudo raspi-config</code> </pre><br>  Select the Interfacing option, then Pi Camera and click Yes.  And finally Finish. <br>  Verify that camera support is enabled using the raspistill utility: <br><br><pre> <code class="bash hljs">raspistill -o mypicture.jpg</code> </pre><br>  If you get the error ‚ÄúCamera is not detected.  Please check carefully the camera module is installed ‚Äúcorrectly‚Äù and check if you have connected the camera to the Raspberry Pi correctly.  You can also reboot the system (it helped me). <br><br>  Let's try to record a video: <br><br><pre> <code class="bash hljs">raspivid -o myvideo.h264</code> </pre><br>  I got an image on a monitor connected to a Raspberry Pi.  I was unable to get a pop-up window on my computer when connected via ssh. <br><br><img src="https://habrastorage.org/webt/in/tj/8q/intj8q2llng2w0ves6izieqtrtc.jpeg" alt="image"><br><br><h2>  Using OpenCV 3 with a fish eye camera on the Raspberry Pi </h2><br>  Install the picamera [array] library: <br><br><pre> <code class="bash hljs">pip install <span class="hljs-string"><span class="hljs-string">"picamera[array]"</span></span></code> </pre><br>  Install the necessary dependencies for OpenCV.  To begin, update the apt package manager and upgrade the pre-installed packages: <br><br><pre> <code class="bash hljs">sudo apt-get update sudo apt-get upgrade</code> </pre><br>  Install some libraries: <br><br><pre> <code class="bash hljs">sudo apt-get install build-essential cmake pkg-config sudo apt-get install libjpeg8-dev libtiff5-dev libjasper-dev libpng12-dev sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev sudo apt-get install libxvidcore-dev libx264-dev sudo apt-get install libgtk-3-dev sudo apt-get install libatlas-base-dev gfortran sudo apt-get install python2.7-dev python3.5-dev</code> </pre><br>  We will install OpenCV 3 from source. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~ wget -O opencv.zip https://github.com/Itseez/opencv/archive/3.1.0.zip unzip opencv.zip</code> </pre><br>  We also need to load the opencv_contrib repository: <br><br><pre> <code class="bash hljs">wget -O opencv_contrib.zip https://github.com/Itseez/opencv_contrib/archive/3.1.0.zip unzip opencv_contrib.zip</code> </pre><br>  The fact is that in OpenCV 3, packages with feature descriptors (such as SIFT and SURF) were transferred to a separate contrib repository.  Now, to use feature descriptors, we need to download the contrib repository separately. <br><br>  Now we are finally ready to install OpenCV.  We can perform cmake to compile OpenCV with the necessary parameters: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/opencv-3.1.0/ mkdir build <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> build cmake -D CMAKE_BUILD_TYPE=RELEASE \ -D CMAKE_INSTALL_PREFIX=/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span> \ -D INSTALL_PYTHON_EXAMPLES=ON \ -D INSTALL_C_EXAMPLES=OFF \ -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib-3.1.0/modules \ -D PYTHON_EXECUTABLE=~/.virtualenvs/cv/bin/python \ -D BUILD_EXAMPLES=ON ..</code> </pre><br>  If cmake runs without errors, run make: <br><br><pre> <code class="bash hljs">make -j4</code> </pre><br>  When compiling, I received an ‚ÄúSegmentation fault‚Äù error.  If you get the same error, run make clean to remove the compilation results and run make with one kernel: <br><br><pre> <code class="bash hljs">make clean make</code> </pre><br>  My compilation procedure took 3 hours.  Finally, complete the installation of OpenCV 3: <br><br><pre> <code class="bash hljs">sudo make install sudo ldconfig</code> </pre><br>  There is an interesting nuance associated with ROS Kinetic.  If you install Kinetic ROS, then ROS adds the path to the Python libraries (/opt/ros/kinetic/lib/python2.7/dist-packages) to the system path when executing the source /opt/ros/kinetic/setup.bash command.  This leads to some problems with the subsequent installation of OpenCV from source (for more details, see <a href="https://stackoverflow.com/questions/43019951/after-install-ros-kinetic-cannot-import-opencv">here</a> ).  To solve the problem, you need to remove the line 'source /opt/ros/kinetic/setup.bash' from the .bashrc file.  Do not forget to run: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">source</span></span> ~/.bashrc</code> </pre><br>  Let's check that OpenCV is now correctly linked from Python. <br>  Create a folder for the project and a simple test script: <br><br><pre> <code class="bash hljs">mkdir PiCamera &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> PiCamera vim test_cam.py</code> </pre><br>  Add the following code to the file: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> picamera.array <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PiRGBArray <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> picamera <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PiCamera <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-comment"><span class="hljs-comment"># initialize the camera and reference the raw camera capture camera = PiCamera() rawCapture = PiRGBArray(camera) # allow camera to warmup time.sleep(0.1) # grab an image camera.capture(rawCapture, format="bgr") image = rawCapture.array cv2.imshow("Capture", image) cv2.waitKey(0)</span></span></code> </pre><br>  Run the script: <br><br><pre> <code class="bash hljs">python test_cam.py</code> </pre><br>  If successful, we will get something like this: <br><br><img src="https://habrastorage.org/webt/hl/kl/dg/hlkldgvxsd8jvyufl_joq6dkqpa.png" alt="image"><br><br>  Let's now try to record video from the camera. <br><br><pre> <code class="bash hljs">vim test_videom.py</code> </pre><br>  Add the following code to the file: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># import the necessary packages from picamera.array import PiRGBArray from picamera import PiCamera import time import cv2 # initialize the camera and grab a reference to the raw camera capture camera = PiCamera() camera.resolution = (640, 480) camera.framerate = 32 rawCapture = PiRGBArray(camera, size=(640, 480)) # allow the camera to warmup time.sleep(0.1) # capture frames from the camera for frame in camera.capture_continuous(rawCapture, format="bgr", use_video_port=True): # grab the raw NumPy array representing the image, then initialize the timestamp # and occupied/unoccupied text image = frame.array # show the frame cv2.imshow("Frame", image) key = cv2.waitKey(1) &amp; 0xFF # clear the stream in preparation for the next frame rawCapture.truncate(0) # if the `q` key was pressed, break from the loop if key == ord("q"): break</span></span></code> </pre><br>  Let's try something more interesting, for example, add edge detection.  I am using Kenny's detector here (the code is taken <a href="https://pythonprogramming.net/canny-edge-detection-gradients-python-opencv-tutorial/">from here</a> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> picamera.array <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PiRGBArray <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> picamera <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PiCamera <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># initialize the camera and grab a reference to the raw camera capture camera = PiCamera() camera.resolution = (640, 480) camera.framerate = 32 rawCapture = PiRGBArray(camera, size=(640, 480)) # allow the camera to warmup time.sleep(0.1) # capture frames from the camera for frame in camera.capture_continuous(rawCapture, format="bgr", use_video_port=True): # grab the raw NumPy array representing the image, then initialize the timestamp # and occupied/unoccupied text image = frame.array hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) lower_red = np.array([30,150,50]) upper_red = np.array([255,255,180]) mask = cv2.inRange(hsv, lower_red, upper_red) res = cv2.bitwise_and(image,image, mask= mask) edges = cv2.Canny(res,100,200) # show the frame cv2.imshow("Frame", image) cv2.imshow("Edges", edges) key = cv2.waitKey(1) &amp; 0xFF # clear the stream in preparation for the next frame rawCapture.truncate(0) # if the `q` key was pressed, break from the loop if key == ord("q"): break</span></span></code> </pre><br>  Here is the result of running the program: <br><br><img src="https://habrastorage.org/webt/kr/tc/ld/krtcldbsjfjrrlg8oz9b0lhlf0i.png" alt="image"><br><br><h2>  Adding Raspberry Pi Camera Camera Support to ROS </h2><br>  Now let's add the ability to work with a fish eye camera for the Raspberry Pi from ROS.  First, install the necessary V4L2 driver for the Raspberry Pi camera (you can read more <a href="https://www.raspberrypi.org/forums/viewtopic.php%3Ft%3D68247">here</a> ).  Run the command: <br><br><pre> <code class="bash hljs">sudo rpi-update</code> </pre><br>  and reboot the system.  Now add the driver: <br><br><pre> <code class="bash hljs">sudo modprobe bcm2835-v4l2</code> </pre><br>  Check that the device / dev / video0 is available: <br><br><pre> <code class="bash hljs">ll /dev/video0</code> </pre><br>  The output will be: <br><br><pre> <code class="bash hljs">crw-rw----+ 1 root video 81, 0 Mar 17 15:47 /dev/video0</code> </pre><br>  Download the usb_cam package: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-kinetic-usb-cam <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash</code> </pre><br>  Run the ROS master and rqt_image_view: <br><br><pre> <code class="bash hljs">roscore roslaunch usb_cam usb_cam-test.launch rosrun rqt_image_view rqt_image_view</code> </pre><br>  Select the topic / usb_cam / image_raw.  We will get this picture: <br><br><img src="https://habrastorage.org/webt/j1/yo/ab/j1yoabxr0g8o5xxy5zeswfrr1oi.png" alt="image"><br><br>  Now fish eye camera can be used with any packages of computer vision in ROS.  Next time we will try object detection.  Good luck in your experiments and see you soon! </div><p>Source: <a href="https://habr.com/ru/post/417251/">https://habr.com/ru/post/417251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../417241/index.html">S3 metadata in PostgreSQL. Yandex lecture</a></li>
<li><a href="../417243/index.html">Install the 3CX SBC Session Border Controller on Windows, Raspberry Pi or Debian 9</a></li>
<li><a href="../417245/index.html">Erlang for IoT</a></li>
<li><a href="../417247/index.html">VSCE # 1: a podcast about media entrepreneurs</a></li>
<li><a href="../417249/index.html">The US Accounts Chamber warns: SpaceX and Boeing are waiting for new delays, it is possible that the United States will have a break in flights to the ISS</a></li>
<li><a href="../417255/index.html">Lego Mindstorms cuckoo clock</a></li>
<li><a href="../417257/index.html">C pointers as a linguistic paradox</a></li>
<li><a href="../417259/index.html">Digital events in Moscow from July 16 to July 22</a></li>
<li><a href="../417261/index.html">Uber after the accident with the participation of his mobile phone decided to reduce the staff of operators of smart machines in Pittsburgh</a></li>
<li><a href="../417263/index.html">Javascript as the embodiment of evil</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>