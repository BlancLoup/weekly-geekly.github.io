<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apache Spark or the return of the prodigal user</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We continue the series of articles about DMP and the technological stack of Targetix . 

 This time it will be a question of using Apache Spark in our...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apache Spark or the return of the prodigal user</h1><div class="post__text post__text-html js-mediator-article">  We continue the series of articles about DMP and the technological stack of <a href="http://targetix.net/">Targetix</a> . <br><br>  This time it will be a question of using <b><a href="http://spark.apache.org/">Apache Spark</a></b> in our practice and a tool that allows you to create remarketing audiences. <br><br>  It is thanks to this tool, once you see a jigsaw, you will see it in all corners of the Internet until the end of your life. <br>  This is where we stuffed the first bumps in Apache Spark. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Architecture and Spark-code under the cut. <br><br><img src="https://habrastorage.org/files/833/c23/2aa/833c232aaea64f228ad5ee8075dc1601.jpg"><br><a name="habracut"></a><br><h4>  <b>Introduction</b> </h4><br>  For understanding of the purposes we will explain terminology and the initial data. <br><br>  <b>What is remarketing?</b>  You will find the answer to this question on the <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D1%2582%25D0%25B0%25D1%2580%25D0%25B3%25D0%25B5%25D1%2582%25D0%25B8%25D0%25BD%25D0%25B3">wiki</a> ), and in short, remarketing (also known as retargeting) is an advertising mechanism that allows you to return the user to the advertiser's site to perform a targeted action. <br><br>  To do this, we need data from the advertiser himself, the so-called <b>first party data</b> , which we collect automatically from sites that set up our code - <b>SmartPixel</b> .  This is information about the user agent, the pages visited and the actions taken.  We then process this data using Apache Spark and get audiences to show ads. <br><br><h4>  <b>Decision</b> </h4><br><h5>  A bit of history </h5><br>  It was originally planned to write on pure Hadoop using MapReduce tasks and we even succeeded.  However, writing this type of application required a large amount of code, which is very difficult to understand and debug. <br><br>  <i>For an example of three different approaches, we present the audience_id grouping code by visitor_id.</i> <br><div class="spoiler">  <b class="spoiler_title">Sample MapReduce code:</b> <div class="spoiler_text"><pre><code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Map</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Mapper</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LongWritable</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">map</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(LongWritable key, Text value, Context context)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException, InterruptedException </span></span>{ String s = value.toString(); String[] split = s.split(<span class="hljs-string"><span class="hljs-string">" "</span></span>); context.write(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(split[<span class="hljs-number"><span class="hljs-number">0</span></span>]), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text(split[<span class="hljs-number"><span class="hljs-number">1</span></span>])); } } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Reduce</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Reducer</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Text</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ArrayWritable</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">reduce</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException, InterruptedException </span></span>{ HashSet&lt;Text&gt; set = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashSet&lt;&gt;(); values.forEach(t -&gt; set.add(t)); ArrayWritable array = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayWritable(Text.class); array.set(set.toArray(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Text[set.size()])); context.write(key, array); } } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Run</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException, ClassNotFoundException, InterruptedException </span></span>{ Job job = Job.getInstance(); job.setJarByClass(Run.class); job.setMapperClass(Map.class); job.setReducerClass(Reduce.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(ArrayWritable.class); FileInputFormat.addInputPath(job, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Path(args[<span class="hljs-number"><span class="hljs-number">0</span></span>])); FileOutputFormat.setOutputPath(job, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Path(args[<span class="hljs-number"><span class="hljs-number">1</span></span>])); System.exit(job.waitForCompletion(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>) ? <span class="hljs-number"><span class="hljs-number">0</span></span> : <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br></div></div><br>  Then Pig caught sight of us.  A language based on Pig Latin, which interpreted the code in the MapReduce task.  Now it took much less code to write, and from an aesthetic point of view it was much better. <br><br><div class="spoiler">  <b class="spoiler_title">Pig code example:</b> <div class="spoiler_text"><pre> <code class="java hljs">A = LOAD <span class="hljs-string"><span class="hljs-string">'/data/input'</span></span> <span class="hljs-function"><span class="hljs-function">USING </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">PigStorage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">' '</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">AS</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(visitor_id:chararray, audience_id:chararray)</span></span></span></span>; B = DISTINCT A; C = GROUP B BY visitor_id; D = FOREACH C GENERATE group AS visitor_id, B.audience_id AS audience_id; STORE D INTO <span class="hljs-string"><span class="hljs-string">'/data/output'</span></span> <span class="hljs-function"><span class="hljs-function">USING </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">PigStorage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>;</code> </pre><br></div></div><br>  That was just a problem with saving.  I had to write my own modules to save, because  most database developers did not support Pig. <br><br>  Here Spark came to the rescue. <br><br><div class="spoiler">  <b class="spoiler_title">Spark code example:</b> <div class="spoiler_text"><pre> <code class="java hljs">SparkConf sparkConf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SparkConf().setAppName(<span class="hljs-string"><span class="hljs-string">"Test"</span></span>); JavaSparkContext jsc = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaSparkContext(sparkConf); jsc.textFile(args[<span class="hljs-number"><span class="hljs-number">0</span></span>]) .mapToPair(str -&gt; { String[] split = str.split(<span class="hljs-string"><span class="hljs-string">" "</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple2&lt;&gt;(split[<span class="hljs-number"><span class="hljs-number">0</span></span>], split[<span class="hljs-number"><span class="hljs-number">1</span></span>]); }) .distinct() .groupByKey() .saveAsTextFile(args[<span class="hljs-number"><span class="hljs-number">1</span></span>]);</code> </pre><br></div></div><br>  Here, both brevity and convenience, as well as the presence of many <b>OutputFormat</b> , which make it easier to write to the database.  In addition, in this tool we were interested in the possibility of stream processing. <br><br><h5>  <b>Current implementation</b> </h5><br>  The process as a whole is as follows: <br><br><img src="https://habrastorage.org/files/b34/990/02f/b3499002fcb94c3ab2b6550833f590f8.jpg"><br><br>  The data comes to us with SmartPixel'e, installed on the sites.  We will not give the code, it is very simple and similar to any external metric.  From here, data comes in the form of <b>{Visitor_Id: Action}</b> .  Here Action can be understood as any target action: viewing a page / product, adding to the cart, buying, or any custom action set by the advertiser. <br><br>  Remarketing processing consists of 2 main modules: <br><ul><li>  Stream processing. </li><li>  Batch processing ( <b>batching</b> ). </li></ul><br><br><h5>  <b>Stream processing</b> </h5><br>  Allows you to add users to the audience in real time.  We use Spark Streaming with a processing interval of 10 seconds.  The user is added to the audience almost immediately after the committed action (within those 10 seconds).  It is important to note that in streaming mode, data can be lost in small quantities due to pinging to databases or for any other reason. <br><br>  The main thing is the balance between response time and throughput.  The less <b>batchInterval</b> , the faster the data will be processed, but a lot of time will be spent on connection initialization and other overhead costs, so not so much can be processed at once.  On the other hand, a large interval allows you to process more data at a time, but then more precious time is spent from the moment of the action to the addition to the right audience. <br><br><div class="spoiler">  <b class="spoiler_title">Selection of events from Kafka:</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">StreamUtil</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> Function&lt;JavaPairRDD&lt;String, <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[]&gt;, JavaRDD&lt;Event&gt;&gt; eventTransformFunction = rdd -&gt; rdd.map(t -&gt; Event.parseFromMsgPack(t._2())).filter(e -&gt; e != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> JavaPairReceiverInputDStream&lt;String, <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[]&gt; createStream(JavaStreamingContext jsc, String groupId, Map&lt;String, Integer&gt; topics) { HashMap prop = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashMap() {{ put(<span class="hljs-string"><span class="hljs-string">"zookeeper.connect"</span></span>, BaseUtil.KAFKA_ZK_QUORUM); put(<span class="hljs-string"><span class="hljs-string">"group.id"</span></span>, groupId); }}; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> KafkaUtils.createStream(jsc, String.class, <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[].class, StringDecoder.class, DefaultDecoder.class, prop, topics, StorageLevel.MEMORY_ONLY_SER()); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> JavaDStream&lt;Event&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEventsStream</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaStreamingContext jssc, String groupName, Map&lt;String, Integer&gt; map, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> getStream(jssc, groupName, map, count, eventTransformFunction); } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> &lt;T&gt; <span class="hljs-function"><span class="hljs-function">JavaDStream&lt;T&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getStream</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaStreamingContext jssc, String groupName, Map&lt;String, Integer&gt; map, Function&lt;JavaPairRDD&lt;String, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[]&gt;, JavaRDD&lt;T&gt;&gt; transformFunction)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> createStream(jssc, groupName, map).transform(transformFunction); } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> &lt;T&gt; <span class="hljs-function"><span class="hljs-function">JavaDStream&lt;T&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getStream</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaStreamingContext jssc, String groupName, Map&lt;String, Integer&gt; map, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count, Function&lt;JavaPairRDD&lt;String, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[]&gt;, JavaRDD&lt;T&gt;&gt; transformFunction)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (count &lt; <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> getStream(jssc, groupName, map, transformFunction); ArrayList&lt;JavaDStream&lt;T&gt;&gt; list = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; count; i++) { list.add(getStream(jssc, groupName, map, transformFunction)); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> jssc.union(list.get(<span class="hljs-number"><span class="hljs-number">0</span></span>), list.subList(<span class="hljs-number"><span class="hljs-number">1</span></span>, count)); } }</code> </pre><br>  To create a message flow, you need to pass the context, the necessary topics and the name of the group of recipients (jssc, topics and groupId, respectively).  For each group its own message queue shift is formed for each topic.  You can also create multiple recipients for load balancing between servers.  All transformations on the data are specified in the transformFunction and are performed in the same stream as the recipients. <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Event handling:</b> <div class="spoiler_text">  Creating context <br><pre> <code class="java hljs"> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> JavaPairRDD&lt;String, Condition&gt; conditions; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> JavaStreamingContext jssc; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Map&lt;Object, HyperLogLog&gt; hlls; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> JavaStreamingContext </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ sparkConf.setAppName(<span class="hljs-string"><span class="hljs-string">"UniversalStreamingBuilder"</span></span>); sparkConf.set(<span class="hljs-string"><span class="hljs-string">"spark.serializer"</span></span>, <span class="hljs-string"><span class="hljs-string">"org.apache.spark.serializer.KryoSerializer"</span></span>); sparkConf.set(<span class="hljs-string"><span class="hljs-string">"spark.storage.memoryFraction"</span></span>, <span class="hljs-string"><span class="hljs-string">"0.125"</span></span>); jssc = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaStreamingContext(sparkConf, batchInterval); HashMap map = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashMap(); map.put(topicName, <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-comment"><span class="hljs-comment">// Kafka topic name and number partitions JavaDStream&lt;Event&gt; events = StreamUtil.getEventsStream(jssc, groupName, map, numReceivers).repartition(numWorkCores); updateConditions(); events.foreachRDD(ev -&gt; { // Compute audiences JavaPairRDD&lt;String, Object&gt; rawva = conditions.join(ev.keyBy(t -&gt; t.pixelId)) .mapToPair(t -&gt; t._2()) .filter(t -&gt; EventActionUtil.checkEvent(t._2(), t._1().condition)) .mapToPair(t -&gt; new Tuple2&lt;&gt;(t._2().visitorId, t._1().id)) .distinct() .persist(StorageLevel.MEMORY_ONLY_SER()) .setName("RawVisitorAudience"); // Update HyperLogLog`s rawva.mapToPair(t -&gt; t.swap()).groupByKey() .mapToPair(t -&gt; { HyperLogLog hll = new HyperLogLog(); t._2().forEach(v -&gt; hll.offer(v)); return new Tuple2&lt;&gt;(t._1(), hll); }).collectAsMap().forEach((k, v) -&gt; hlls.merge(k, v, (h1, h2) -&gt; HyperLogLog.merge(h1, h2))); // Save to Aerospike and HBase save(rawva); return null; }); return jssc; }</span></span></code> </pre><br>  Here, to join two (events and conditions) RDD (Resilient Distributed Dataset), use join by pixel_id.  The save method is fake.  This is done in order to unload the submitted code.  In its place should be several transformations and saves. <br><br>  Launch <br><pre> <code class="java hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ create(); jssc.start(); <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> millis = TimeUnit.MINUTES.toMillis(CONDITION_UPDATE_PERIOD_MINUTES); <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Timer(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>).schedule(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> TimerTask() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ updateConditions(); } }, millis, millis); <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Timer(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>).scheduleAtFixedRate(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> TimerTask() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ flushHlls(); } }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Date(saveHllsStartTime), TimeUnit.MINUTES.toMillis(HLLS_UPDATE_PERIOD_MINUTES)); jssc.awaitTermination(); }</code> </pre><br>  First, the context is created and launched.  Parallel to this, 2 timers are started to update the conditions and save the HyperLogLog.  It is mandatory that awaitTermination () is specified at the end, otherwise the processing will end without starting. <br></div></div><br><h5>  <b>Batch processing</b> </h5><br>  Once a day, it rebuilds all audiences, which solves the problems of obsolete and lost data.  Remarketing has one unpleasant feature for the user - advertising hype.  Here comes the <b>lookback window</b> .  For each user, the date of his addition to the audience is stored, so we can control the relevance of information to the user. <br><br>  It takes 1.5-2 hours - it all depends on the load on the network.  And most of the time it is saving across databases: loading, processing and recording in Aerospike 75 minutes (performed in one pipeline), the rest of the time is saving in HBase and Mongo (35 minutes). <br><br><div class="spoiler">  <b class="spoiler_title">Batch processing code:</b> <div class="spoiler_text"><pre> <code class="java hljs">JavaRDD&lt;Tuple3&lt;Object, String, Long&gt;&gt; av = HbaseUtil.getEventsHbaseScanRdd(jsc, hbaseConf, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Scan()) .mapPartitions(it -&gt; { ArrayList&lt;Tuple3&lt;Object, String, Long&gt;&gt; list = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(); it.forEachRemaining(e -&gt; { String pixelId = e.pixelId; String vid = e.visitorId; <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> dt = e.date.getTime(); List&lt;Condition&gt; cond = conditions.get(pixelId); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (cond != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { cond.stream() .filter(condition -&gt; e.date.getTime() &gt; beginTime - TimeUnit.DAYS.toMillis(condition.daysInterval) &amp;&amp; EventActionUtil.checkEvent(e, condition.condition)) .forEach(condition -&gt; list.add(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple3&lt;&gt;(condition.id, vid, dt))); } }); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list; }).persist(StorageLevel.DISK_ONLY()).setName(<span class="hljs-string"><span class="hljs-string">"RawVisitorAudience"</span></span>);</code> </pre><br>  Here is almost the same as in stream processing, but join is not used.  Instead, it uses event check against the condition list with the same pixel_id.  As it turned out, this design requires less memory and runs faster. <br></div></div><br><h5>  <b>Save to base</b> </h5><br>  Saving from Kafka to HBase was originally sewn into a streaming service, but due to possible failures and failures, it was decided to put it into a separate application.  To implement fault tolerance, <b>Kafka Reliable Receiver was used</b> , which allows not to lose data.  Uses Checkpoint to save meta information and current data. <br><br>  The number of entries in HBase is currently about 400 million.  All events are stored in the database for 180 days and are deleted by TTL. <br><br><div class="spoiler">  <b class="spoiler_title">Using Reliable Receiver:</b> <div class="spoiler_text">  First you need to implement the create () method of the JavaStreamingContextFactory interface and add the following lines when creating the context <br><pre> <code class="java hljs">sparkConf.set(<span class="hljs-string"><span class="hljs-string">"spark.streaming.receiver.writeAheadLog.enable"</span></span>, <span class="hljs-string"><span class="hljs-string">"true"</span></span>); jssc.checkpoint(checkpointDir);</code> </pre><br>  Now instead of <br><pre> <code class="java hljs">JavaStreamingContext jssc = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaStreamingContext(sparkConf, batchInterval);</code> </pre><br>  use <br><pre> <code class="java hljs">JavaStreamingContext jssc = JavaStreamingContext.getOrCreate(checkpointDir, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ());</code> </pre><br></div></div><br>  Saving to Aerospike takes place using a self-written OutputFormat and a Lua script.  To use an asynchronous client, I had to add two classes to the official connector ( <a href="https://github.com/v-lukashin/aerospike-hadoop">fork</a> ). <br><div class="spoiler">  <b class="spoiler_title">Running a Lua script:</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">UpdateListOutputFormat</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">com</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">aerospike</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">hadoop</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mapreduce</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AerospikeOutputFormat</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">String</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Bin</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> Log LOG = LogFactory.getLog(UpdateListOutputFormat.class); <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LuaUdfRecordWriter</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AsyncRecordWriter</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">String</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Bin</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LuaUdfRecordWriter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Configuration cfg, Progressable progressable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>(cfg, progressable); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">writeAerospike</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String key, Bin bin, AsyncClient client, WritePolicy policy, String ns, String sn)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { policy.sendKey = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; Key k = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Key(ns, sn, key); Value name = Value.get(bin.name); Value value = bin.value; Value[] args = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Value[]{name, value, Value.get(System.currentTimeMillis() / <span class="hljs-number"><span class="hljs-number">1000</span></span>)}; String packName = AeroUtil.getPackage(cfg); String funcName = AeroUtil.getFunction(cfg); <span class="hljs-comment"><span class="hljs-comment">// Execute lua script client.execute(policy, null, k, packName, funcName, args); } catch (Exception e) { LOG.error("Wrong put operation: \n" + e); } } } @Override public RecordWriter&lt;String, Bin&gt; getAerospikeRecordWriter(Configuration entries, Progressable progressable) { return new LuaUdfRecordWriter(entries, progressable); } }</span></span></code> </pre><br>  Asynchronously executes a function from the specified package. <br></div></div><br>  As an example, the function of adding new values ‚Äã‚Äãto the list is presented. <br><div class="spoiler">  <b class="spoiler_title">Lua script:</b> <div class="spoiler_text"><pre> <code class="lua hljs"><span class="hljs-keyword"><span class="hljs-keyword">local</span></span> split = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(str)</span></span></span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> tbl = list() <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> start, fin = <span class="hljs-built_in"><span class="hljs-built_in">string</span></span>.<span class="hljs-built_in"><span class="hljs-built_in">find</span></span>(str, <span class="hljs-string"><span class="hljs-string">",[^,]+$"</span></span>) list.append(tbl, <span class="hljs-built_in"><span class="hljs-built_in">string</span></span>.<span class="hljs-built_in"><span class="hljs-built_in">sub</span></span>(str, <span class="hljs-number"><span class="hljs-number">1</span></span>, start - <span class="hljs-number"><span class="hljs-number">1</span></span>)) list.append(tbl, <span class="hljs-built_in"><span class="hljs-built_in">string</span></span>.<span class="hljs-built_in"><span class="hljs-built_in">sub</span></span>(str, start + <span class="hljs-number"><span class="hljs-number">1</span></span>, fin)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tbl <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> save_record = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(rec, name, mp)</span></span></span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> res = list() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k,v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> map.<span class="hljs-built_in"><span class="hljs-built_in">pairs</span></span>(mp) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> list.append(res, k..<span class="hljs-string"><span class="hljs-string">","</span></span>..v) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> rec[name] = res <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> aerospike:exists(rec) <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> aerospike:update(rec) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> aerospike:<span class="hljs-built_in"><span class="hljs-built_in">create</span></span>(rec) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">put_in_list_first_ts</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(rec, name, value, timestamp)</span></span></span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> lst = rec[name] <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> mp = map() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> value ~= <span class="hljs-literal"><span class="hljs-literal">nil</span></span> <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> list.size(value) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> list.iterator(value) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> mp[i] = timestamp <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> lst ~= <span class="hljs-literal"><span class="hljs-literal">nil</span></span> <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> list.size(lst) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> list.iterator(lst) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> sp = split(i) mp[sp[<span class="hljs-number"><span class="hljs-number">1</span></span>]] = sp[<span class="hljs-number"><span class="hljs-number">2</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> save_record(rec, name, mp) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span></code> </pre><br></div></div><br>  This script adds new entries in the audience list like ‚Äúaudience_id, timestamp‚Äù.  If the entry exists, then the timestamp remains the same. <br><br>  Characteristics of servers running applications: <br>  Intel Xeon E5-1650 6-core 3.50 GHz (HT), 64GB DDR3 1600; <br>  CentOS 6 operating system; <br>  CDH version 5.4.0. <br><br>  Application Configuration: <br><br><img src="https://habrastorage.org/files/211/7a0/cb4/2117a0cb4d44422695a4179c4583aaab.jpg"><br><br><h4>  <b>In custody</b> </h4><br>  On the way to this implementation, we tried several options (C #, Hadoop MapReduce and Spark) and got a tool that performs equally well with the tasks of stream processing and recalculation of huge data arrays.  Due to the partial introduction of lambda architecture, the reuse of the code has increased.  The time for complete restructuring of the classroom channels has decreased from ten hours to ten minutes.  And horizontal scalability has never been easier. <br><br>  You can always try our technologies on our <a href="http://hybrid.ru/">Hybrid</a> platform. <br><br><h4>  <b>PS</b> </h4><br>  Special thanks are expressed to <a href="https://habrahabr.ru/users/danilaperepechin/" class="user_link">DanilaPerepechin</a> for their invaluable assistance in writing the article. </div><p>Source: <a href="https://habr.com/ru/post/266009/">https://habr.com/ru/post/266009/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../265993/index.html">Compiled data bindings in Windows 10 applications</a></li>
<li><a href="../265997/index.html">Grokay RxJava, part four: Jet Android</a></li>
<li><a href="../266003/index.html">Sell ‚Äã‚Äãin 60 seconds. Call center in the cloud and a special SIM card</a></li>
<li><a href="../266005/index.html">Tyuni memory and network stack in Linux: the history of the transfer of high-loaded servers to a fresh distribution</a></li>
<li><a href="../266007/index.html">Industrial control system: how we created a system for the exact calculation of the machine tool life of a large plant</a></li>
<li><a href="../266011/index.html">Takari: Maven on steroids</a></li>
<li><a href="../266013/index.html">Digest of grocery design, August 2015</a></li>
<li><a href="../266015/index.html">IBM Watson cognitive system: principles of working with natural language</a></li>
<li><a href="../266017/index.html">Centrifuge + Go = Centrifugo - harder, better, faster, stronger</a></li>
<li><a href="../266019/index.html">The first book of the young programmer. Learning to write programs on Scratch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>