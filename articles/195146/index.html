<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Evaluation of linear regression results</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 Today, everyone who is even slightly interested in mining is probably heard about a simple linear regression . About it already wrote o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Evaluation of linear regression results</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  Today, everyone who is even slightly interested in mining is probably heard about a simple <a href="http://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">linear regression</a> .  About it already <a href="http://habrahabr.ru/post/148782/">wrote</a> on Habr√©, as well as told in detail about Andrew Ng in his famous machine learning course.  Linear regression is one of the basic and simplest methods of machine learning, however, methods for assessing the quality of the constructed model are rarely mentioned.  In this article I will try to correct this annoying omission a little by examining the results of the function summary.lm () in the R language. At the same time, I will try to provide the necessary formulas so that all calculations can be easily programmed in any other language.  This article is intended for those who have heard that it is possible to construct a linear regression, but have not encountered statistical procedures to assess its quality. <br><a name="habracut"></a><br><h4>  Linear regression model </h4><br>  So, let there be several independent random variables X1, X2, ..., Xn (predictors) and the quantity Y depending on them (it is assumed that all the necessary predictor transformations have already been made).  Moreover, we assume that the dependence is linear, and the errors are normally distributed, that is, <br><img src="https://habrastorage.org/storage3/f5e/0ee/10d/f5e0ee10d11f605692f0fcfcbfd3dc81.png"><br>  where I is the unit square matrix of size nx n. <br><br>  So, we have data consisting of k observations of Y and Xi values ‚Äã‚Äãand we want to estimate the coefficients.  The standard method for finding estimates of coefficients is the <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BD%25D0%25B0%25D0%25B8%25D0%25BC%25D0%25B5%25D0%25BD%25D1%258C%25D1%2588%25D0%25B8%25D1%2585_%25D0%25BA%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D0%25BE%25D0%25B2">method of least squares</a> .  And the analytical solution that can be obtained by applying this method looks like this: <br><img src="https://habrastorage.org/storage3/131/96b/0e0/13196b0e02aecf15b8bbf11cfa934208.png"><br>  where <b>b</b> with a lid is an estimate of the coefficient vector, <b>y</b> is a vector of values ‚Äã‚Äãof the dependent variable, and X is a matrix of size kx n + 1 (n is the number of predictors, k is the number of observations), in which the first column consists of ones, the second is the value of the first predictor , the third - the second and so on, and the lines correspond to the available observations. <br><br><h4>  Function summary.lm () and evaluation of the results </h4><br>  Now consider an example of building a linear regression model in the language R: <br><pre><code class="bash hljs">&gt; library(faraway) &gt; lm1&lt;-lm(Species~Area+Elevation+Nearest+Scruz+Adjacent, data=gala) &gt; summary(lm1) Call: lm(formula = Species ~ Area + Elevation + Nearest + Scruz + Adjacent, data = gala) Residuals: Min 1Q Median 3Q Max -111.679 -34.898 -7.862 33.460 182.584 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.068221 19.154198 0.369 0.715351 Area -0.023938 0.022422 -1.068 0.296318 Elevation 0.319465 0.053663 5.953 3.82e-06 *** Nearest 0.009144 1.054136 0.009 0.993151 Scruz -0.240524 0.215402 -1.117 0.275208 Adjacent -0.074805 0.017700 -4.226 0.000297 *** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1 Residual standard error: 60.98 on 24 degrees of freedom Multiple R-squared: 0.7658, Adjusted R-squared: 0.7171 F-statistic: 15.7 on 5 and 24 DF, p-value: 6.838e-07</code> </pre> <br>  The gala table contains some data on 30 Galapagos Islands.  We will consider a model where Species - the number of different plant species on the island linearly depends on several other variables. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Consider the output of the function summary.lm (). <br>  First comes the string that recalls how the model was built. <br>  Then there is information about the distribution of residuals: minimum, first quartile, median, third quartile, maximum.  In this place it would be useful not only to look at some quantile residues, but also to check their normality, for example, with the Shapiro-Wilk test. <br>  Next - the most interesting - information about the coefficients.  It takes a bit of theory. <br>  We first write the following result: <br><img src="https://habrastorage.org/storage3/b01/d11/091/b01d110914b98b3403e3cfdd44bd2390.png"><br>  while the sigma squared with a lid is an unbiased estimate for the real sigma squared.  Here <b>b</b> is the real vector of coefficients, and epsilon with a lid is the vector of residuals, if we take the least-squares estimates as coefficients.  That is, assuming that errors are distributed normally, the vector of coefficients will also be distributed normally around the real value, and its dispersion can be unbiasedly estimated.  This means that it is possible to test the hypothesis for the equality of the coefficients to zero, and therefore to check the significance of the predictors, that is, whether the value of Xi really influences the quality of the constructed model. <br>  To test this hypothesis, we need the following statistics, which has <a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D0%25B5%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A1%25D1%2582%25D1%258C%25D1%258E%25D0%25B4%25D0%25B5%25D0%25BD%25D1%2582%25D0%25B0">a Student's distribution</a> if the real value of the coefficient bi is 0: <br><img src="https://habrastorage.org/storage3/19a/222/439/19a222439b28b88398b6607082a4d3d7.png"><br>  Where <br><img src="https://habrastorage.org/storage3/cbd/09e/73a/cbd09e73adabf1bd1472b0066550d439.png">  - standard error of the coefficient estimate, and t (kn-1) - Student's distribution with kn-1 degrees of freedom. <br><br>  Now everything is ready to continue parsing the output of the function summary.lm (). <br>  So, next are the estimates of the coefficients obtained by the method of least squares, their standard errors, the values ‚Äã‚Äãof t-statistics and <a href="http://en.wikipedia.org/wiki/P-value">p-values</a> for it.  Usually, a p-value is compared with some sufficiently small pre-selected threshold, for example, 0.05 or 0.01.  And if the value of p-statistics turns out to be less than the threshold, then the hypothesis is rejected; if more, nothing concrete, unfortunately, cannot be said.  I recall that in this case, since the Student‚Äôs distribution is symmetrical with respect to 0, the p-value will be 1-F (| t |) + F (- | t |), where F is the Student‚Äôs distribution function with kn-1 degrees of freedom .  Also, R kindly denotes asterisks significant coefficients for which the p-value is sufficiently small.  That is, those coefficients that are with a very low probability are equal to 0. In the Signif line.  codes just contain the decoding of asterisks: if there are three, then the p-value is from 0 to 0.001, if there are two, then it is from 0.001 to 0.01, and so on.  If there are no icons, then the p-value is greater than 0.1. <br><br>  In our example, it can be said with great confidence that the predictors of Elevation and Adjacent do affect the Species value with a high probability, but nothing definite can be said about the other predictors.  Usually, in such cases, the predictors remove one by one and see how much other indicators of the model change, for example, <a href="http://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC</a> or Adjusted R-squared, which will be analyzed further. <br><br>  The value of the Residual standart error corresponds simply to a sigma estimate with a lid, and the degrees of freedom are calculated as kn-1. <br><br>  And now the most important statistics that you should look at first are: R-squared and Adjusted R-squared: <br><img src="https://habrastorage.org/storage3/9a1/07a/46e/9a107a46e2631177d3d71a6e274bab7b.png"><br>  where Yi is the real Y values ‚Äã‚Äãin each observation, Yi with a lid are the values ‚Äã‚Äãpredicted by the model, Y with the bar is the average for all real Yi values. <br><img src="https://habrastorage.org/storage3/f5e/586/2e8/f5e5862e80b293ffdb74f578bddf6e8d.png"><br><br>  We begin with the statistics of the R-square or, as it is sometimes called, the coefficient of determination.  It shows how the conditional dispersion of the model differs from the dispersion of real values ‚Äã‚Äãof Y. If this coefficient is close to 1, then the conditional dispersion of the model is quite small and it is very likely that the model describes the data quite well.  If the R-squared coefficient is much less, for example, less than 0.5, then, with a large degree of confidence, the model does not reflect the real state of affairs. <br><br>  However, the R-square statistic has one serious drawback: with an increase in the number of predictors, this statistic can only increase.  Therefore, it may seem that a model with a large number of predictors is better than a model with a smaller one, even if all new predictors do not affect the dependent variable in any way.  Here you can recall the principle of <a href="http://ru.wikipedia.org/wiki/%25D0%2591%25D1%2580%25D0%25B8%25D1%2582%25D0%25B2%25D0%25B0_%25D0%259E%25D0%25BA%25D0%25BA%25D0%25B0%25D0%25BC%25D0%25B0">Occam's razor</a> .  Following it, if possible, it is worth getting rid of the extra predictors in the model, as it becomes simpler and more understandable.  For these purposes, a corrected R-square statistic was invented.  It is a regular R-square, but with a penalty for a large number of predictors.  The basic idea: if the new independent variables make a large contribution to the quality of the model, the value of these statistics increases, if not, then vice versa decreases. <br><br>  For example, consider the same model as before, but now instead of five predictors, we‚Äôll leave two: <br><pre> <code class="bash hljs">&gt; lm2&lt;-lm(Species~Elevation+Adjacent, data=gala) &gt; summary(lm2) Call: lm(formula = Species ~ Elevation + Adjacent, data = gala) Residuals: Min 1Q Median 3Q Max -103.41 -34.33 -11.43 22.57 203.65 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.43287 15.02469 0.095 0.924727 Elevation 0.27657 0.03176 8.707 2.53e-09 *** Adjacent -0.06889 0.01549 -4.447 0.000134 *** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1 Residual standard error: 60.86 on 27 degrees of freedom Multiple R-squared: 0.7376, Adjusted R-squared: 0.7181 F-statistic: 37.94 on 2 and 27 DF, p-value: 1.434e-08</code> </pre><br>  As you can see, the value of the R-squared statistics has decreased, but the value of the adjusted R-squared has even slightly increased. <br><br>  Now we check the hypothesis that all coefficients are equal to zero under predictors.  That is, the hypothesis about whether the value of Y generally depends on the values ‚Äã‚Äãof Xi linearly.  To do this, you can use the following statistics, which, if the hypothesis that all coefficients are equal to zero, has <a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D0%25B5%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D0%25B8%25D1%2588%25D0%25B5%25D1%2580%25D0%25B0">the Fisher distribution</a> cn and kn-1 degrees of freedom: <br><img src="https://habrastorage.org/storage3/d7a/1a3/ab1/d7a1a3ab17f6a5fd25b36a16f7bbac8a.gif"><br>  The value of F-statistics and p-value for it are in the last line of the output of the function summary.lm (). <br><br><h4>  Conclusion </h4><br><br>  In this article, standard methods for assessing the significance of coefficients and some criteria for assessing the quality of the constructed linear model were described.  Unfortunately, I did not touch upon the question of considering the distribution of residuals and checking it for normality, since this would have doubled the article, although this is a rather important element of checking the adequacy of the model. <br>  I really hope that I managed to slightly expand the standard idea of ‚Äã‚Äãlinear regression, as an algorithm that just evaluates some kind of dependency, and to show how to evaluate its results. </div><p>Source: <a href="https://habr.com/ru/post/195146/">https://habr.com/ru/post/195146/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../195134/index.html">How to measure content relevance</a></li>
<li><a href="../195136/index.html">Integration of web services into popular cms</a></li>
<li><a href="../195138/index.html">C ++ test case, sorting functor</a></li>
<li><a href="../195140/index.html">Adding Admob to Unity3d and withdrawing money from PayPal to a bank account in Russia</a></li>
<li><a href="../195142/index.html">Random Cat Generator in 8 Steps</a></li>
<li><a href="../195148/index.html">GCC and Variable-Length Arrays</a></li>
<li><a href="../195150/index.html">Debian: create packages for a narrow range of systems</a></li>
<li><a href="../195152/index.html">Linux pipes tips & tricks</a></li>
<li><a href="../195154/index.html">Primitive game design. Turn-based card game development</a></li>
<li><a href="../195158/index.html">Pirates vs. copyright holders: insider view</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>