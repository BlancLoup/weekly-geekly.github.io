<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The architecture of artificial intelligence needs to be changed.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Using von Neumann architecture for applications with artificial intelligence is inefficient. What will replace her? 
 Using existing architectures to ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The architecture of artificial intelligence needs to be changed.</h1><div class="post__text post__text-html js-mediator-article"><h3>  Using <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D1%2580%25D1%2585%25D0%25B8%25D1%2582%25D0%25B5%25D0%25BA%25D1%2582%25D1%2583%25D1%2580%25D0%25B0_%25D1%2584%25D0%25BE%25D0%25BD_%25D0%259D%25D0%25B5%25D0%25B9%25D0%25BC%25D0%25B0%25D0%25BD%25D0%25B0">von Neumann architecture</a> for applications with artificial intelligence is inefficient.  What will replace her? </h3><br>  Using existing architectures to solve machine learning (MO) and artificial intelligence (AI) problems has become impractical.  The power consumed by the AI ‚Äã‚Äãhas increased significantly, and the CPU along with the GPU seems to be increasingly inappropriate tools for this job. <br><br>  Participants at several symposia agreed that the best opportunities for significant change arise in the absence of inherited features that have to be dragged along.  Most of the systems evolved gradually over time - and, let it provide a safe way forward, such a scheme does not provide optimal solutions.  When something new appears, it is possible to take a fresh look at things and choose a better direction than what the conventional technologies offer.  That was what was discussed at a recent conference, where the question was studied whether the complementary metal-oxide-semiconductor ( <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%259C%25D0%259E%25D0%259F">CMOS</a> ) structure is the best basic technology on which to build an AI application. <br><a name="habracut"></a><br>  An Chan, appointed by IBM as executive director of the Nanoelectronics Research Initiative (NRI), formulated a discussion framework.  ‚ÄúFor many years we have been researching new, modern technologies, including the search for an alternative to CMOS, especially because of its problems associated with power consumption and scaling.  After all these years, the opinion was developed that we did not find anything better as a basis for creating logical circuits.  Today, many researchers are concentrating on AI, and it does offer new ways of thinking and new schemes, and they have new technological products.  Will new AI devices have the ability to replace CMOS? ‚Äù <br><br><h2>  AI today </h2><br>  Most applications for MO and AI use von Neumann architecture.  ‚ÄúIt uses memory to store arrays of data, and the CPU performs all the calculations,‚Äù explains Marvin Chen, a professor of electrical engineering at Xinhua National University.  ‚ÄúLarge amounts of data are moving along the bus.  Today, GPUs are also often used for in-depth training, including convolutional [neural networks].  One of the main problems is the appearance of intermediate data necessary for drawing up a conclusion.  Moving data, especially off-chip, leads to energy losses and delays.  This is a bottleneck of technology. ‚Äù 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/7cd/968/73a/7cd96873afab685ee739ee78db59a7a8.png"><br>  <i>Architecture used for AI</i> <br><br>  What you need today is to combine data processing and memory.  ‚ÄúThe concept of memory computing has been offered by computer architecture experts for many years,‚Äù says Chen.  - There are several schemes for SRAM and non-volatile memory, with which they tried to use and implement such a concept.  Ideally, if this works out, you can save a huge amount of energy by eliminating the movement of data between the CPU and memory.  But this is the ideal. ‚Äù <br><br>  But today we have no memory calculations.  ‚ÄúWe still have AI 1.0, using the von Neumann architecture, because silicon devices that implement memory processing haven't appeared yet,‚Äù complains.  Chen.  - The only way to somehow use 3D TSV is to use high-speed memory along with the GPU to solve the bandwidth problem.  But it still remains a bottleneck for energy and time. ‚Äù <br><br>  Is there enough data processing in memory to solve the problem of energy loss?  "There are a hundred billion neurons and 10 <sup>15</sup> synapses in the human brain," said Sean Lee, assistant director at Taiwan Semiconductor Manufacturing Company.  "Now look at the IBM TrueNorth."  TrueNorth is a multi-core processor developed by IBM in 2014. It has 4096 cores, and each has 256 programmable artificial neurons.  ‚ÄúSuppose we want to scale it and reproduce the size of the brain.  The difference is 5 orders of magnitude.  But if we just directly increase the numbers and multiply TrueNorth, which consumes 65 mW, then we will have a machine with a consumption of 65 kW against a human brain that consumes 25 watts.  Consumption must be reduced by several orders of magnitude. " <br><br>  Lee offers another way to imagine this opportunity.  ‚ÄúThe most efficient supercomputer for today is the Green500 from Japan, issuing 17 Gflops per Watt, or 1 <a href="https://ru.wikipedia.org/wiki/FLOPS">flop</a> per 59 pJ‚Äù.  The Green500 website says that the ZettaScaler-2.2 system installed at the Advanced Computing and Communications Center (RIKEN) in Japan measured 18.4 Gflops / W during the Linpack test run, which required 858 teraflops.  ‚ÄúCompare this with <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25B8%25D0%25BD%25D1%2586%25D0%25B8%25D0%25BF_%25D0%259B%25D0%25B0%25D0%25BD%25D0%25B4%25D0%25B0%25D1%2583%25D1%258D%25D1%2580%25D0%25B0">the Landauer principle</a> , according to which at room temperature the minimum switching energy of the transistor is about 2.75 zJ [10-21 J].  Again, the difference is several orders of magnitude.  59 pJ is about <sup>10-11</sup> against a theoretical minimum of about <sup>10-21</sup> .  We have a huge field for research. " <br><br>  Is it fair to compare such computers with the brain?  ‚ÄúAfter examining the latest successes of in-depth training, we will see that in most cases the latter have won seven years in a row at the competition of people and machines,‚Äù says Kaushik Roy, honorary professor of electrical engineering and computer science at Purdue University.  ‚ÄúIn 1997 Deep Blue defeated Kasparov, in 2011 IBM Watson won the game Jeopardy !, and in 2016 Alpha Go defeated Lee Sedol.  This is the greatest achievement.  But at what cost?  These machines consumed 200 to 300 kW.  The human brain consumes about 20 watts.  Huge break.  Where does innovation come from? <br><br>  At the heart of most applications of MO and AI are the simplest calculations performed on a huge scale.  ‚ÄúIf you take the simplest neural network, it performs a weighted summation followed by a threshold operation,‚Äù Roy explains.  - This can be done in matrices of various types.  This may be a device from spintronics or resistive memory.  In this case, the input voltage and total conductivity will be associated with each intersection point.  At the output, you get the sum of the voltages multiplied by the conductivity.  This is current.  Then you can take similar devices that perform the threshold operation.  The architecture can be imagined as a bunch of these nodes, connected together so as to carry out calculations. " <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b45/191/123/b45191123cc0afe303fe51cf0ae114e6.png"><br>  <i>The main components of the neural network</i> <br><br><h2>  New types of memory </h2><br>  Most potential architectures are associated with emerging types of non-volatile memory.  ‚ÄúWhat are the most important characteristics?‚Äù Asks Jeffrey Barr, a researcher at IBM Research.  ‚ÄúI would put it on nonvolatile analog resistive memory, such as phase state memory, memristors, and so on.  The idea is that these devices are capable of doing all the multiplications for fully connected layers of neural networks in a single clock cycle.  On a set of processors, this can take a million clock cycles, and in an analog device this can be done with the help of physics, working at the location of the data.  There are enough very interesting aspects in terms of time and energy for this idea to evolve into something more. ‚Äù <br><br><img src="https://habrastorage.org/getpro/habr/post_images/68c/6e0/60b/68c6e060bf517fd1ac76b8ad79fdad3c.png"><br>  <i>New memory technologies</i> <br><br>  Chen agrees with this.  ‚ÄúPCM, STT has serious applications for victory.  These three types of memory are good candidates for implementing in-memory computing.  They are capable of basic logical operations.  Some species have problems with reliability, and they can not be used for training, but it is possible to get a conclusion. " <br><br>  But it may turn out that it is not necessary to switch to this memory.  ‚ÄúPeople talk about using SRAM for exactly the same purpose,‚Äù adds Lee.  ‚ÄúThey do analog computing with SRAM.‚Äù  The only negative is that SRAM is too big - 6 or 8 transistors per bit.  Therefore, it‚Äôs not a fact that we will use these new technologies in analog computing. ‚Äù <br><br>  The transition to analog computing also implies that the accuracy of the calculations will no longer be a matter of prime necessity.  ‚ÄúAI is specializing, classifying and predicting,‚Äù he says.  - It makes decisions that can be rude.  From the point of view of accuracy, we can sacrifice something.  We need to determine which calculations are error tolerant.  Then some technology can be applied to reduce power consumption or speed up calculations.  Over probabilistic CMOS work since 2003.  This includes reducing the voltage up to the appearance of several errors, the number of which remains tolerable.  Today, people are already using approximate computing techniques, for example, quantization.  Instead of a 32-bit floating point number, you will have 8-bit integers.  Analog computers are another feature already mentioned. ‚Äù <br><br><h2>  Get out of the lab </h2><br>  Moving technology from the lab to shared use can be challenging.  ‚ÄúSometimes you have to look for alternatives,‚Äù says Barr.  ‚ÄúWhen the two-dimensional flash memory didn‚Äôt take off, the three-dimensional flash memory seemed no longer so difficult.  If we continue to improve existing technologies, getting a doubling of the characteristics here, doubling there, then analog computing inside the memory will be abandoned.  But if the following improvements are minor, analog memory will look more attractive.  We, as researchers, must be ready for new opportunities. ‚Äù <br><br>  The economy often hinders development, especially in the field of memory, but Barr says that in this case this will not happen.  ‚ÄúOne of our advantages is that this product will not be related to memory.  It will not be something with small improvements.  This is not a consumer product.  This thing is competing with the GPU.  They are sold at a price 70 times higher than the cost of the DRAM placed on them, so this is clearly a non-memory product.  And the cost of the product will not be much different from the memory.  It sounds good, but when you make decisions worth billions of dollars, all the costs and the product development plan should be crystal clear.  To overcome this barrier, we need to produce impressive prototypes. ‚Äù <br><br><h2>  CMOS Replacement </h2><br>  Processing data in memory can provide impressive benefits, but more is needed to implement the technology.  Can any material other than CMOS help in this?  ‚ÄúConsidering the transition from CMOS low consumption to tunnel FET, we are talking about reducing consumption by 1-2 orders of magnitude,‚Äù says Lee.  - Another possibility is three-dimensional integrated circuits.  They reduce the length of wiring using TSV.  This reduces power consumption and delays.  Look at the data centers, they all remove the metal wiring and connect the optical one. ‚Äù <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a95/b57/b95/a95b57b955aa7f86e612623ba201d926.jpg"><br>  <i>Vertically - power consumption, horizontally - delays in the operation of devices</i> <br><br>  Although it is possible to achieve certain advantages when switching to another technology, they may not be worth it.  ‚ÄúIt will be very difficult to replace CMOS, but some of the devices under discussion can complement CMOS technology so that it performs computations in memory,‚Äù says Roy.  - CMOS can support in-memory computations in analog form, possibly in cell 8T.  Is it possible to create an architecture with a clear advantage over CMOS?  If everything is done correctly, then CMOS will give me energy efficiency increases thousands of times.  But it takes time. ‚Äù <br><br>  It is clear that CMOS will not replace.  ‚ÄúNew technologies will not reject the old ones, and they will not be made on any other substrates other than CMOS,‚Äù Barr concludes. </div><p>Source: <a href="https://habr.com/ru/post/420943/">https://habr.com/ru/post/420943/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../420931/index.html">How to test nuclear power plants</a></li>
<li><a href="../420935/index.html">Everything you need to know about alignment in Flexbox</a></li>
<li><a href="../420937/index.html">About wear SSD on real examples</a></li>
<li><a href="../420939/index.html">One story about career growth or why I consider myself a good manager</a></li>
<li><a href="../420941/index.html">P2P disputes on the blockchain</a></li>
<li><a href="../420945/index.html">We study new worlds with the help of an open-source ATV project from NASA</a></li>
<li><a href="../420947/index.html">On the issue of pulsations, interesting people and inductances</a></li>
<li><a href="../420951/index.html">How Yandex prepares front-end vendors. From the Coursera program to university courses</a></li>
<li><a href="../420955/index.html">A pair of skyrmion-antiskirmion as a possible future of data storage</a></li>
<li><a href="../420957/index.html">Review of the updated 3D-printer Sinterit Lisa and the new Sinterit Lisa 2 Pro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>