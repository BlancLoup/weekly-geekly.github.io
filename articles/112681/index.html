<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using Rebar and GProc</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Using rebar 

 This tutorial may contain outdated information, since Rebar is very actively developed without preserving compatibility with previous v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using Rebar and GProc</h1><div class="post__text post__text-html js-mediator-article"><h2>  Using rebar </h2><br><br>  <strong>This tutorial may contain outdated information, since Rebar is very actively developed without preserving compatibility with previous versions.</strong> <br><br>  When developing on Erlang, it is often necessary to collect dependencies from different sources, monitor their desired versions, create OTP releases for distributing projects.  Things are quite routine and unpleasant.  In order to develop less unpleasant moments, Basho created a very convenient tool - Rebar.  In this article I will try to reveal the benefits of using it on a real-world example using third-party dependencies and creating configurable OTP releases. <br><a name="habracut"></a><br>  Download Rebar at <a href="http://hg.basho.com/rebar/downloads/rebar">hg.basho.com/rebar/downloads/rebar</a> .  This is one single file containing several beam modules.  It should be placed in any convenient place included in the search path for executable PATH files, for example, <code>~/bin/</code> or <code>/usr/local/bin/</code> . <br>  Let's start the project. <br>  First, create a directory in which our project will be located ( <code>gpt</code> ) and go into it: <br><pre> $ mkdir gpt &amp;&amp; cd gpt
</pre>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In it, we will create a subdirectory where we will save the source files of our application directly: <br><pre> $ mkdir -p apps / gpt &amp;&amp; cd apps / gpt
</pre><br><br>  Making an application skeleton: <br><pre> $ rebar create-app appid = gpt
</pre><br><br>  The appid parameter specifies the name of our application and, accordingly, the prefix of the source files. <br><pre> $ ls -1 src
 gpt_app.erl
 gpt.app.src
 gpt_sup.erl
</pre><br><br>  Add to the preset for the .app file ( <code>src/gpt.app.src</code> ) the application description and the dependency on gproc: <br><pre>   {description, "GProc tutorial"},
   ...
   {applications,
    [
     kernel,
     stdlib
     gproc% &lt;--- Application depends on gproc
    ]},
   ...
</pre><br><br>  Go back to the top level directory where our project is stored, create a <code>rel</code> subdirectory in it and go there: <br><pre> $ cd ../../
 $ mkdir rel &amp;&amp; cd rel
</pre><br><br>  Rel will contain the files needed to create a release - all that is required to run a project, all its runtime dependencies. <br>  Using <code>rebar</code> create a stub for the node by passing its name in the <code>nodeid</code> parameter: <br><pre> $ rebar create-node nodeid = gptnode
</pre><br><br>  Edit the file <code>reltool.config</code> : <br><pre>   ...
   {lib_dirs, ["../deps", "../apps"]},% &lt;--- In these directories, reltool will look for dependencies and our application
   {rel, "gptnode", "1",
    [
     kernel,
     stdlib
     sasl
     gproc,% &lt;--- gproc application
     gpt% &lt;--- Our application
    ]},
   ...
</pre><br><br>  Then you can edit the <code>files/vm.args</code> file by changing, say, the node name: <br><pre> -name gptnode@127.0.0.1
</pre><br><br>  on <br><pre> -sname gptnode @ localhost
</pre><br><br>  Back in the top-level directory: <br><pre> $ cd ../
</pre><br><br>  and create a file <code>rebar.config</code> with the following content: <br><pre> %% There will be dependencies here.
 {deps_dir, ["deps"]}.

 %% Subdirectories that rebar should look at
 {sub_dirs, ["rel", "apps / gpt"]}.

 %% Compiler Options
 {erl_opts, [debug_info, fail_on_warning]}.

 %% List of Dependencies
 %% In the gproc directory the master branch of the corresponding git repository will be cloned.
 {deps,
  [
   {gproc, ". *", {git, "http://github.com/esl/gproc.git", "master"}}
  ]}.
</pre><br><br>  Now we are ready to create a release.  Run several <code>rebar</code> commands (command output omitted): <br><pre> $ rebar get-deps
 $ rebar compile
 $ rebar generate
</pre><br><br>  The <code>get-deps</code> command downloads dependencies.  In our case, this is gproc application.  The <code>compile</code> command obviously compiles all the source files, and <code>generate</code> creates a release. <br>  The <code>rel/gptnode</code> can be safely moved to other hosts (of course, subject to binary compatibility, since the release includes the Erlang virtual machine).  After creating the release, run what we got: <br><pre> (cd rel / gptnode &amp;&amp; sh bin / gptnode console)
</pre><br><br>  Make sure that all the necessary applications are running: <br><pre> (gptnode @ localhost) 1&gt; application: which_applications ().
 [{sasl, "SASL CXC 138 11", "2.1.9.2"},
  {gpt, "GProc tutorial", "1"},
  {gproc, "GPROC", "0.01"},
  {stdlib, "ERTS CXC 138 10", "1.17.2"},
  {kernel, "ERTS CXC 138 10", "2.14.2"}]
</pre><br><br>  We are interested in gpt and gproc.  As you can see, they are on this list. <br><h2>  Using gproc </h2><br>  So, with <code>rebar</code> figured out, learned how to create a simple project and work with it.  Proceed to gproc. <br>  As you know, applications in Erlang, as a rule, consist of many processes that exchange messages. <br>  In order for the processes to know whom to send which message, it is necessary to have a registrar converting some coordinates into a process identifier.  By default, Erlang / OTP provides process registration under the atom name.  This is wasteful, since atoms are not collected by the garbage collector, and once created, they live to complete the work of the entire node, which will necessarily lead to the exhaustion of all memory, if necessary, to register processes under unique names.  Moreover, such an approach is inconvenient, since it would be necessary to convert different terms into an atom, write some rules for this, besides, the process can be registered only under one name.  Registration of processes under the atom name using the <code>erlang:register/2</code> function is allowed only for a small number of long-lived processes, whose name should not change, the analogue is global variables in imperative programming languages. <br>  To circumvent these limitations, the following scheme is often used: <br><ol><li>  the registrar process is started, which creates the ets-table and is its owner; </li><li>  when starting processes that require registration, they send a message to the registrar containing the coordinates for registration (any erlang-term) and their identifier; </li><li>  the registrar writes this mapping to the ets-table and includes monitoring the process using <code>erlang:monitor/2</code> ; </li><li>  the registered process, upon completion, either explicitly sends a message about its deregistration, or the registrar receives a <code>'DOWN'</code> message when this process crashes, and then deletes its entry from the ets-table; </li></ol><br>  This scheme is very often used, almost every application has its own implementation, with its own features and bugs.  Of course, there is a natural desire to replace this recorder with something unique.  And the solution came in the form of the developer Ulf Wiger and its gproc applications (https://github.com/esl/gproc). <br>  The application API is available at <a href="">github.com/esl/gproc/blob/master/doc/gproc.md</a> . <br><h3>  Local registration </h3><br>  Consider the simplest case - local (at the current node) registration of a process with an arbitrary term. <br>  The source code for the examples can be found here: <a href="">github.com/Zert/gproc-tutorial.git</a> <br>  The code for the processes that we will register via gproc is in the <code>gpt_proc.erl</code> file.  The <code>gpt_sup.erl</code> contains the code for the supervisor of this process group.  When the <code>gpt_sup:start_worker/1</code> function is called, our process will be launched and registered under the name that is passed to the function as the only argument.  In this case, it is a number. <br>  We started the node using the above command, and executed a series of processes with different identifiers in it: <br><pre> (gptnode @ localhost) 1&gt; [gpt_sup: start_worker (Id) ||  Id &lt;- lists: seq (1,3)].
 (gpt_proc: 29) Start process: 1
 (gpt_proc: 29) Start process: 2
 (gpt_proc: 29) Start process: 3
 [{ok, &lt;0.61.0&gt;}, {ok, &lt;0.62.0&gt;}, {ok, &lt;0.63.0&gt;}]
</pre><br><br>  The function call <code>gproc:add_local_name(Name)</code> registers the process that calls it, under the name <code>Name</code> (this function is simply a wrapper over <code>gproc:reg({n,l,Name})</code> , where <code>n</code> is the <code>name</code> , <code>l</code> is <code>local</code> ).  After that, the <code>gproc:lookup_local_name(Name)</code> function will return the process ID. <br>  Now we will tell one of the processes to start waiting for the process to start and register with the name 4. The code responsible for this is: <br><pre> handle_info ({await, Id},
             #state {id = MyId} = State) -&gt;
     gproc: await ({n, l, Id}),
     ? DBG ("MyId: ~ p. ~ NNewId: ~ p.", [MyId, Id]),
     {noreply, State};
</pre><br><br>  Here, the <code>gproc:await/1</code> function is called with an argument that has the following form: <code>{n, l, Id}</code> .  For some reason, it does not have a wrapper, but oh well. <br><pre> (gptnode @ localhost) 2&gt; gproc: lookup_local_name (1)!  {await, 4}.
 {await, 4}
</pre><br><br>  Having started the process with identifier 4, we will first see a message from it, and then from the first waiting process: <br><pre> (gptnode @ localhost) 3&gt; gpt_sup: start_worker (4).
 (gpt_proc: 29) Start process: 4
 (gpt_proc: 45) MyId: 1.
 NewId: 4.
 {ok, &lt;0.66.0&gt;}
</pre><br><br>  Let us stop the process of receiving the <code>stop</code> message: <br><pre> handle_info (stop, State) -&gt;
     {stop, normal, State};
</pre><br><br>  and stop it: <br><pre> (gptnode @ localhost) 4&gt; gproc: lookup_local_name (1)!  stop
 stop
</pre><br><br>  After this, the process is automatically deleted from the registrar database: <br><pre> (gptnode @ localhost) 5&gt; gproc: lookup_local_name (1).
 undefined
</pre><br><br><h3>  Global registration </h3><br>  It is well known that Erlang is wildly distributed.  This implies a transparent exchange of messages between nodes, in other words, having a process identifier, you can send a message to it without knowing which node it is on.  Local registration of a process using gproc allows you to map an arbitrary term to a process identifier within one erlang node, while the other node cannot get an identifier value using this term. <br>  In order for any node in the cluster to be able to register its processes so that they are available from other nodes, there is global registration.  GProc implements the <code>gproc:add_global_name/1</code> call to allow this action.  Consider an example. <br>  First, we will build two nodes combined in a cluster, and <code>rebar</code> will help us with this, since it has the ability to create configuration files using a predetermined pattern.  When creating a cluster, consider the following details: <br><ul><li>  Set same cookie values ‚Äã‚Äãon nodes </li><li>  Ask them different names </li><li>  Pass the appropriate parameters to the mandatory <code>kernel</code> application on each node </li><li>  When using GProc, transfer the desired node roles to it. </li></ul><br>  The first two items are set in the <code>files/vm.args</code> : <br><pre> ## Name of the node
 -sname {{node}}

 ## Cookie for distributed erlang
 -setcookie gptnode
</pre><br><br>  Here <code>{{node}}</code> is a placeholder, which will be filled when creating a release.  The <code>-setcookie</code> virtual machine <code>-setcookie</code> sets the cookie value for this node; in a cluster, all the nodes should have the same values. <br>  The second two items are set in the <code>files/app.config</code> .  Here, placeholders will also be used: <br><pre>  %% gproc
  {gproc, {{gproc_params}}},

 %% Kernel
  {kernel, {{kernel_params}}},
</pre><br><br>  To fill the placeholders, specify in the file <code>reltool.config</code> that the previous two files should be treated as templates: <br><pre>   {template, "files / app.config", "etc / app.config"},
   {template, "files / vm.args", "etc / vm.args"}
</pre><br><br>  Create two configuration files, one for each node: <code>vars/dev1_vars.config</code> and <code>vars/dev2_vars.config</code> .  The <code>dev1_vars.config</code> file will contain the following placeholder values: <br><pre> %% etc / app.config
 {gproc_params,
 "[
   {gproc_dist, {['gpt1 @ localhost'],
                 [{workers, ['gpt2 @ localhost']}]}}
  ] "}.

 {kernel_params,
 "[
   {sync_nodes_mandatory, ['gpt2 @ localhost']},
   {sync_nodes_timeout, 15000}
  ] "}.

 %% etc / vm.args
 {node, "gpt1 @ localhost"}.
</pre><br><br>  For the <code>dev2_vars.config</code> file <code>dev2_vars.config</code> the <code>sync_nodes_mandatory</code> and <code>node</code> parameters <code>sync_nodes_mandatory</code> swapped.  We analyze them in more detail. <br>  The <code>gproc_dist</code> parameter refers to the gproc application, it is a tuple of two lists.  The first list is the nodes that are able to become the leader (master), the second list contains key-value tuples, for now we only need one key - <code>workers</code> , which defines a list of nodes that are simple cluster members (slave). <br>  The kernel application includes two parameters.  The first, <code>sync_nodes_mandatory</code> is a list of nodes that are required to be present in the cluster.  The second, <code>sync_nodes_timeout</code> is the time in milliseconds that each node will wait for the nodes from the previous list to appear.  If the nodes do not appear during this time, the node will stop.  Let's make its value 15 seconds in order to have time to run them both by hand. <br>  The <code>node</code> value will be written to the startup parameters of the virtual machine, this is its name. <br>  Now create two releases using the following rule from the Makefile: <br><pre> dev1 dev2:
     mkdir -p dev
     (cd rel &amp;&amp; rebar generate target_dir = .. / dev / $ @ overlay_vars=vars/$@_vars.config)
</pre><br><br>  Go to the <code>dev/dev1</code> , launch the second terminal window (or create a new window in the screen <code>),   </code> dev / dev2 directory <code>.    </code>  <code>.    </code> ./bin/gptnode console`.  Let's see the list of available nodes in the first Erlang shell: <br><pre> (gpt1 @ localhost) 1&gt; nodes ().
 [gpt2 @ localhost]
</pre><br>  We see that the second node started up normally and connected to the cluster.  In order not to be wise for a long time, we‚Äôll globally register the current shell process under some term: <br><pre> (gpt1 @ localhost) 2&gt; gproc: add_global_name ({shell, 1}).
 true
</pre><br><br>  In another window, let's try to request a process identifier for this term: <br><pre> (gpt2 @ localhost) 2&gt; gproc: lookup_global_name ({shell, 1}).
 &lt;3358.70.0&gt;
</pre><br><br>  As you can see, successfully.  By sending a message to this process, we can get it at the first node: <br><pre> (gpt2 @ localhost) 3&gt; gproc: lookup_global_name ({shell, 1})!  {the, message}.
 message
</pre><br><br>  We read it on the first node with the <code>flush()</code> command: <br><pre> (gpt1 @ localhost) 3&gt; flush ().
 Shell got {the, message}
 ok
</pre><br><br><h3>  Conclusion </h3><br>  That's all.  I started writing the article for myself, since the documentation on rebar is very scarce and is constantly forgotten after another use.  Along the way, I started using gproc, and in order not to get up twice, I put everything in one article. </div><p>Source: <a href="https://habr.com/ru/post/112681/">https://habr.com/ru/post/112681/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../112674/index.html">Do you know JAVA,% username%? Part two</a></li>
<li><a href="../112676/index.html">Garbage Collection clearly</a></li>
<li><a href="../112678/index.html">Twitter added social functionality</a></li>
<li><a href="../112679/index.html">HTTPS support has been added to Facebook</a></li>
<li><a href="../112680/index.html">British policemen catch Anonymus</a></li>
<li><a href="../112682/index.html">Upgrade</a></li>
<li><a href="../112685/index.html">"I do not write unit tests, because ..." - excuses</a></li>
<li><a href="../112686/index.html">Effective team</a></li>
<li><a href="../112687/index.html">Microsoft reported for the quarter: revenue from the Xbox grew by 55%, from Windows fell by 29%</a></li>
<li><a href="../112688/index.html">The near future: copyright holders and users</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>