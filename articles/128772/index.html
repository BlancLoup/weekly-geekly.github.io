<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What is an â€œasynchronous event modelâ€, and why is it now â€œin fashionâ€</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Now on the subject the Internet is fashionable the word "Node.js" . In this small article we will try to understand (â€œon the fingersâ€), where did all ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">ğŸ”</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">ğŸ“œ</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">â¬†ï¸</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">â¬‡ï¸</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What is an â€œasynchronous event modelâ€, and why is it now â€œin fashionâ€</h1><div class="post__text post__text-html js-mediator-article">  Now on the subject the Internet is fashionable the word <a href="http://ru.wikipedia.org/wiki/Nodejs">"Node.js"</a> .  In this small article we will try to understand (â€œon the fingersâ€), where did all this come from, and how does this architecture differ from the usual architecture with â€œsynchronousâ€ and â€œblockingâ€ input / output in the application code (a typical <a href="http://ru.wikipedia.org/wiki/PHP">PHP</a> + <a href="http://ru.wikipedia.org/wiki/MySQL">MySQL</a> site) running on <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B5%25D1%2580%25D0%25B2%25D0%25B5%25D1%2580_%25D0%25BF%25D1%2580%25D0%25B8%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B9">an application server</a> that uses a "flow (or process) to request" scheme (classic <a href="http://ru.wikipedia.org/wiki/Apache">Apache Web Server</a> ). <br><a name="habracut"></a><br><h4>  About the readability of the article </h4><br>  This article, since its appearance here, has undergone many revisions (including conceptual) and additions, thanks to feedback from readers mentioned at the end of the article.  If you have a piece for understanding here, describe it in the comments, and we will write it in an article in a more understandable language. <br><br><h4>  About performance </h4><br>  Modern high- <a href="http://www.insight-it.ru/masshtabiruemost/arkhitektura-twitter-dva-goda-spustya/">powered</a> sites like <a href="http://www.insight-it.ru/masshtabiruemost/arkhitektura-twitter-dva-goda-spustya/">twitter</a> , <a href="http://www.insight-it.ru/masshtabiruemost/arkhitektura-twitter-dva-goda-spustya/">VKontakte</a> and <a href="http://www.insight-it.ru/masshtabiruemost/arkhitektura-facebook/">facebook</a> work on bundles of the form PHP + Apache + NoSQL or <a href="http://ru.wikipedia.org/wiki/Ruby_on_Rails">Ruby on Rails</a> + <a href="http://unicorn.bogomips.org/">Unicorn</a> + NoSQL, and do not slow down at all.  First, they use <a href="http://ru.wikipedia.org/wiki/NoSQL">NoSQL</a> instead of SQL.  Second, they distribute requests ( <a href="http://ru.wikipedia.org/wiki/%25D0%2591%25D0%25B0%25D0%25BB%25D0%25B0%25D0%25BD%25D1%2581%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25BA%25D0%25B0_%25D0%25BD%25D0%25B0%25D0%25B3%25D1%2580%25D1%2583%25D0%25B7%25D0%25BA%25D0%25B8">â€œbalanceâ€</a> ) across many of the same working servers (this is called <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B0%25D1%2581%25D1%2588%25D1%2582%25D0%25B0%25D0%25B1%25D0%25B8%25D1%2580%25D1%2583%25D0%25B5%25D0%25BC%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">â€œhorizontal scalingâ€</a> ).  Third, they <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B5%25D1%2588%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5">cache</a> everything they can: whole pages, pieces of pages, data in Json format for <a href="http://ru.wikipedia.org/wiki/Ajax">Ajax requests</a> , and so on ... Cached data is <a href="http://www.ylsoftware.com/news/599">â€œstaticâ€</a> , and immediately <a href="http://ru.wikipedia.org/wiki/Nginx">sent to</a> servers like <a href="http://ru.wikipedia.org/wiki/Nginx">NginX</a> , bypassing attachment. <br><br>  I personally do not know whether the site will be faster if it is rewritten from Apache + PHP to Node.js.  In the thematic Internet can be found as those who consider the system flows slower "asynchronous event model", and those who defend the opposite point of view. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Thinking about what to write the next project, you should proceed from its tasks, and choose the architecture that is well superimposed on the objectives of the project. <br><br>  For example, if your program supports multiple simultaneous connections, and constantly writes to them, and reads from them, then in this case you should definitely look in the direction of an â€œasynchronous event modelâ€ (for example, in the direction of Node.js).  Node.js is perfect if you want to translate any subsystem to the <a href="http://ru.wikipedia.org/wiki/WebSocket">WebSocket</a> protocol. <br><br>  Examples of systems that are well suited to the â€œasynchronous event modelâ€: <br><ul><li>  the system in the dispatching taxi that monitors the movement of each car, distributes the flow of passengers, calculates the best way, etc. </li><li>  a life support system that constantly collects data from a variety of scattered sensors, and controls chemical composition, temperature, humidity, etc. </li><li>  the human body ( <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25BE%25D0%25B7%25D0%25B3">brain</a> - control logic, <a href="http://ru.wikipedia.org/wiki/%25D0%259D%25D0%25B5%25D1%2580%25D0%25B2%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B8%25D1%2581%25D1%2582%25D0%25B5%25D0%25BC%25D0%25B0">nervous system</a> - data transmission channel) </li><li>  chat </li><li>  <a href="http://ru.wikipedia.org/wiki/MMORPG">MMORPG</a> </li></ul><br><h4>  What is â€œblockingâ€ and â€œnon-blockingâ€ I / O </h4><br>  Let us understand the types of input / output using the example of a <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BE%25D0%25BA%25D0%25B5%25D1%2582_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B8%25D0%25BD%25D1%2582%25D0%25B5%25D1%2580%25D1%2584%25D0%25B5%25D0%25B9%25D1%2581)">network socket</a> (â€œsocketâ€ - literally â€œplace of connectionâ€), through which the Internet user connected to our website, and uploads a picture for the avatar.  In this article, we will compare the â€œasynchronous event modelâ€ with the â€œfamiliarâ€ architecture, where all the I / O in the application code is â€œsynchronousâ€ and â€œblockingâ€.  â€œHabitualâ€ - simply because before that no one bothered with all sorts of â€œlocksâ€, and everyone wrote like that, and it was enough for everyone.  What is â€œsynchronousâ€ and â€œblockingâ€ I / O?  This is the simplest and most common I / O on which most of the sites are written: <br><ul><li>  open file </li><li>  start reading it </li><li>  wait until it counts </li><li>  file was considered </li><li>  close file </li><li>  display the read content on the screen </li></ul><br>  In the case of our socket, this will be: <ul><li>  start listening to the socket </li><li>  read from it the first piece of image data </li><li>  wait until the second data portion of the image comes to it </li><li>  read from it the second piece of image data </li><li>  wait for the next batch of image data </li><li>  ... </li><li>  picture was considered </li><li>  we put the picture on the avatar to the user </li></ul><br>  In this case, a â€œblockingâ€ occurs in the code of our program, during which the thread is idle, although it could do something useful.  To solve this problem, â€œsynchronousâ€ and â€œnon-blockingâ€ input / output was coined: <ul><li>  start listening to the socket </li><li>  if there is no new data on it, stop listening to the socket </li><li>  if it has already received some portion of the image data - read this data </li><li>  stop listening to the socket </li></ul><br>  If these steps are performed in a loop until the last portion of the image data has been read, then we will also get the whole picture as a result.  With the only difference that in this cycle, in addition to reading data from the socket, we can do something else useful, and not stand idle under the "lock".  For example, one could also read data from another socket.  Such a cycle of "non-blocking" I / O pops up again closer to the middle of the article. <br><br>  There is also "asynchronous" I / O.  In our article, we will not consider it, but in general it is when we hang the <a href="http://ru.wikipedia.org/wiki/Callback_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5)">â€œcallback functionâ€ (callback)</a> from our code, which will be called by the operating system every time the next piece of image data comes to this socket.  And then we forget about listening to this socket in general, going to do other things.  "Asynchronous" I / O, as well as "synchronous", is divided into "blocking" and "non-blocking".  But in this article, under the words â€œblockingâ€ and â€œnon-blockingâ€, we will mean precisely â€œsynchronousâ€ input / output. <br><br>  And yet, in this article we will consider only the â€œfamiliarâ€ architecture, where the application is running directly on the operating system, with its system threads, and not on any â€œvirtual machineâ€ with its â€œgreen threadsâ€.  Because inside a â€œvirtual machineâ€ with â€œgreen streamsâ€ you can perform various miracles, such as turning the supposedly â€œsynchronousâ€ I / O into â€œasynchronousâ€, which will be discussed closer to the end of the article, in the section â€œAlternative wayâ€. <br><br><h4>  Prerequisites </h4><br>  The whole avalanche of experiments with new application architectures was caused by the fact that traditional architecture was solving the needs of the Internet at the dawn of its development, and, of course, was not designed to meet the evolving needs of the â€œweb two-nolâ€ Internet, in which everything buzzes and moves. <br><br>  The PHP + MySQL + <a href="http://ru.wikipedia.org/wiki/Apache">Apache</a> combination proven over the years coped well with â€œInternet 1.0â€.  The server launched a new thread (or process, <a href="http://stackoverflow.com/questions/807506/threads-vs-processes-in-linux">which is almost the same from the point of view of the operating system</a> ) for each user request.  This thread went to <a href="http://ru.wikipedia.org/wiki/PHP">PHP</a> , from there to the database, chose something there, and returned with an answer that was sent to the user via <a href="http://ru.wikipedia.org/wiki/HTTP">HTTP</a> , after which it self-contained. <br><br>  However, for real-time applications, it was missed.  Suppose we have the task of â€œsimultaneously maintaining 10,000 connections with users.â€  One could create 10,000 threads for this.  How will they get along with each other?  They will get along with each other system <a href="http://en.wikipedia.org/wiki/Scheduling_(computing)">"scheduler"</a> , whose task is to give each thread its share of processor time, and at the same time not deprive anyone.  He acts like that.  When one thread has worked a little, the scheduler starts, temporarily stops the thread, and â€œprepares the siteâ€ to start the next thread (which is already waiting in the queue). <br><br>  Such a â€œsite preparationâ€ is called a <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B5%25D1%2580%25D0%25B5%25D0%25BA%25D0%25BB%25D1%258E%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25BA%25D0%25BE%25D0%25BD%25D1%2582%25D0%25B5%25D0%25BA%25D1%2581%25D1%2582%25D0%25B0">â€œcontext switchâ€</a> , and it includes the preservation of the â€œcontextâ€ of the suspended flow, and the restoration of the context of the flow that will be launched next.  The "context" includes the processor registers and process data in the operating system itself (id's, access rights, resources and locks, allocated memory, etc.). <br><br>  How often the scheduler runs is decided by the operating system.  For example, in Linux, the default scheduler runs about <a href="http://en.wikipedia.org/wiki/Scheduling_(computing)">once every hundredth of a second</a> .  The scheduler is also called when the process is â€œblockedâ€ manually (for example, by the sleep function) or while waiting for â€œsynchronousâ€ and â€œblockingâ€ (that is, the simplest and most common) input / output (for example, a user request in the PHP stream waits until data will give him a monthly sales report). <br><br>  <a href="http://stackoverflow.com/questions/304752/how-to-estimate-the-thread-context-switching-overhead">In general, it is believed</a> that â€œcontext switchingâ€ between system threads is not so expensive, and is in the order of a microsecond. <br><br>  If threads actively read different areas of RAM (and write to different areas of RAM), then, with an increase in the number of such threads, they will miss <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D1%258D%25D1%2588_%25D0%25BF%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581%25D0%25BE%25D1%2580%25D0%25B0">the second-level cache (L2) of the</a> processor, which is of the order of a megabyte.  In this case, they will have to wait each time for the delivery of data on the <a href="http://ru.wikipedia.org/wiki/%25D0%25A8%25D0%25B8%25D0%25BD%25D0%25B0_(%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BF%25D1%258C%25D1%258E%25D1%2582%25D0%25B5%25D1%2580)">system bus</a> from the RAM to the processor, and for writing data on the system bus from the processor to the RAM.  Such access to RAM is <a href="http://www.karbosguide.com/books/pcarchitecture/chapter11.htm">orders of magnitude slower than</a> accessing the processor's cache: for this, this cache was invented.  In these cases, the â€œcontext switchâ€ time can <a href="http://www.cs.rochester.edu/u/cli/research/switch.pdf">go up to 50 microseconds</a> . <br><br>  On the Internet, you can find the opinion that the constant â€œcontext switchingâ€ of a large number of simultaneous streams can significantly slow down the entire system.  However, I did not find unambiguous and detailed numerical evidence for this hypothesis. <br><br>  Let us consider what imprint imposes a multi-threaded model on the application's consumption of RAM.  A <a href="http://en.wikipedia.org/wiki/Data_segment">â€œstackâ€</a> is associated with each system thread.  If the thread calls a certain function with arguments, then the arguments of this function <a href="http://en.wikipedia.org/wiki/Call_stack">are put</a> on the â€œstackâ€, and the current address in the code, called the â€œreturn addressâ€ (because we will return back here when the called function ends).  If this function calls some other function inside itself, then the corresponding data is again written to the â€œstackâ€, on top of those that have already been written there, thus creating a semblance of a coil. <br><br>  When creating a system thread, the â€œstackâ€ is allocated by the operating system in RAM not all at once, but in pieces, as it is used.  This is called <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B8%25D1%2580%25D1%2582%25D1%2583%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BF%25D0%25B0%25D0%25BC%25D1%258F%25D1%2582%25D1%258C">â€œvirtual memory</a> . <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B8%25D1%2580%25D1%2582%25D1%2583%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BF%25D0%25B0%25D0%25BC%25D1%258F%25D1%2582%25D1%258C">â€</a>  That is, each thread is immediately allocated a large piece of â€œvirtual memoryâ€ under the â€œstackâ€, but in fact, all this â€œvirtual memoryâ€ is split into â€œpiecesâ€ called â€œmemory pagesâ€, and these â€œmemory pagesâ€ are already allocated to â€œreal Â»RAM only when necessary.  When a thread touches a â€œmemory pageâ€ that has not yet been allocated in â€œrealâ€ RAM (for example, it tries to command the processor to write something there), the processorâ€™s <a href="http://ru.wikipedia.org/wiki/%25D0%2591%25D0%25BB%25D0%25BE%25D0%25BA_%25D1%2583%25D0%25BF%25D1%2580%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F_%25D0%25BF%25D0%25B0%25D0%25BC%25D1%258F%25D1%2582%25D1%258C%25D1%258E">â€œmemory control unitâ€</a> intercepts this action and causes an â€œ <a href="http://en.wikipedia.org/wiki/Fault_(computing)">exception</a> â€ in the operating system " <a href="http://en.wikipedia.org/wiki/Page_fault">Page fault</a> ", to which it responds by allocating this "memory page" in the "real" RAM. <br><br>  In Linux, the default stack size <a href="http://www.linuxquestions.org/questions/programming-9/why-the-stack-size-limit-878108/">is 8 megabytes</a> , and the size of the â€œmemory pageâ€ is <a href="http://www.cyberciti.biz/faq/linux-check-the-size-of-pagesize/">4 kilobytes</a> (one or two â€œmemory pagesâ€ are immediately allocated to the â€œstackâ€).  In terms of 10,000 simultaneously running threads, we get a requirement of about 80 megabytes of â€œrealâ€ RAM.  It seems like a bit, and there seems to be no cause for concern.  But the size of the required memory in this case grows as <a href="http://ru.wikipedia.org/wiki/%25D0%259E-%25D0%25B1%25D0%25BE%25D0%25BB%25D1%258C%25D1%2588%25D0%25BE%25D0%25B5">O (n)</a> , which means that with a further increase in load, difficulties with <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B0%25D1%2581%25D1%2588%25D1%2582%25D0%25B0%25D0%25B1%25D0%25B8%25D1%2580%25D1%2583%25D0%25B5%25D0%25BC%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">â€œscalabilityâ€</a> may arise: what if tomorrow your site will already serve 100,000 simultaneous users, and will require maintaining 100 000 simultaneous connections?  And the day after tomorrow - 1,000,000?  And after the day after tomorrow - it is still unknown how much ... <br><br>  Single-threaded application servers lack such a drawback and do not require new memory as the number of simultaneous connections grows (this is called O (1)).  Take a look at this graph comparing the memory consumption of Apache Web Server and <a href="http://ru.wikipedia.org/wiki/Nginx">NginX</a> : <br><br><img src="http://thefoley.net/node/nginx-apache-memory.png" alt="image"><br><br>  Modern web servers (including modern Apache) are not built entirely on a stream-to-query architecture, but on a more <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D0%25BF%25D1%2582%25D0%25B8%25D0%25BC%25D0%25B8%25D0%25B7%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F_(%25D0%25B8%25D0%25BD%25D1%2584%25D0%25BE%25D1%2580%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0)">optimized one</a> : there is a <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D0%25B1%25D1%258A%25D0%25B5%25D0%25BA%25D1%2582%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25BF%25D1%2583%25D0%25BB">pool of</a> pre-prepared <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D0%25BE%25D1%2582%25D0%25BE%25D0%25BA_%25D0%25B2%25D1%258B%25D0%25BF%25D0%25BE%25D0%25BB%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F">threads</a> that serve all requests as they arrive.  This can be compared with an attraction in which there are 10 horses, and 100 riders who want to ride: a queue forms, and while the first 10 riders do not roll back and forth, the next 10 riders will stand and wait in line.  In this case, an attraction is an application server, horses are streams from a pool, and riders are site users. <br><br>  If we use such a â€œpoolâ€ of system threads, then at the same time we will be able to serve only the number of users, how many threads we will have â€œin the poolâ€, that is, not 10,000. <br><br>  The difficulties described in this section, which constantly raise the question of the suitability of a multi-threaded architecture for servicing a very large number of simultaneous connections, have received the collective name <a href="http://en.wikipedia.org/wiki/C10k_problem">â€œThe C10K problemâ€</a> . <br><br><h4>  Asynchronous event model </h4><br>  Needed a new architecture for this class of applications.  And in such a situation, the â€œasynchronous event modelâ€ came in handy.  It is based on the <a href="http://en.wikipedia.org/wiki/Event_loop">â€œevent loopâ€</a> and the <a href="http://en.wikipedia.org/wiki/Reactor_pattern">â€œreactorâ€</a> pattern (from the word â€œreactâ€ to respond). <br><br>  An â€œevent loopâ€ is an endless loop that polls â€œevent sourcesâ€ (descriptors) for any â€œeventsâ€ to appear in them.  The survey is performed using the library of <a href="">â€œsynchronousâ€</a> I / O, which, in this case, will be <a href="http://publib.boulder.ibm.com/infocenter/iseries/v5r3/index.jsp%3Ftopic%3D%252Frzab6%252Frzab6cmultiplex.htm">â€œnon-blockingâ€</a> (the O_NONBLOCK flag is passed to the system I / O function). <br><br>  That is, during the next turn of the â€œevent cycleâ€, our system passes through all the descriptors sequentially, and tries to count â€œeventsâ€ from them: if there are any, they are returned as a read function to our system;  if the descriptor does not have any new events, then it will not â€œblockâ€ and wait for the â€œeventâ€ to appear, but will immediately return the answer: â€œthere are no new eventsâ€. <br><br>  An â€œeventâ€ can be the arrival of a regular portion of data on a <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BE%25D0%25BA%25D0%25B5%25D1%2582_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B8%25D0%25BD%25D1%2582%25D0%25B5%25D1%2580%25D1%2584%25D0%25B5%25D0%25B9%25D1%2581)">network socket</a> (â€œsocketâ€ - literally â€œjunctionâ€), or the reading of a new portion of data from a hard disk: in general, any input / output.  For example, when you upload a picture to the hosting, the data comes in chunks, each time causing the event "a new piece of picture data is received." <br><br>  The â€œevent sourceâ€ in this case will be the <a href="http://www.daniweb.com/software-development/c/threads/117802">â€œdescriptorâ€</a> (pointer to the data stream) of the <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BE%25D0%25BA%25D0%25B5%25D1%2582%25D1%258B_%25D0%2591%25D0%25B5%25D1%2580%25D0%25BA%25D0%25BB%25D0%25B8">TCP socket</a> through which you connected to the site via the network. <br><br>  The second component of the new architecture, as already mentioned, is the â€œreactorâ€ pattern.  And, for the Russian people, this is not the same reactor, which is at the nuclear power plant.  The essence of this pattern is that the server code is not written in one large piece, which is executed sequentially, but in small blocks, each of which is called (â€œreactsâ€) when the event associated with it occurs.  Thus, the code is a set of multiple blocks whose task is to "react" to some events. <br><br>  Such a new architecture became â€œmainstreamâ€ after the appearance of Node.js.  Node.js is written in <a href="http://ru.wikipedia.org/wiki/C%2B%2B">C ++</a> , and bases its event loop on the <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B8_(%25D1%258F%25D0%25B7%25D1%258B%25D0%25BA_%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D1%258F)">Sibish</a> library <a href="http://libev.schmorp.de/bench.html">"libev"</a> .  However, Javascript is not a favorite language here: if the language of the library has â€œnon-blockingâ€ I / O, you can also write similar <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D1%2580%25D0%25B5%25D0%25B9%25D0%25BC%25D0%25B2%25D0%25BE%25D1%2580%25D0%25BA">frameworks</a> for it: Python has <a href="http://en.wikipedia.org/wiki/Twisted_(software)">Twisted</a> and <a href="http://www.tornadoweb.org/">Tornado</a> , <a href="http://en.wikipedia.org/wiki/Perl_Object_Environment">Perl has Perl Object Environment</a> , Ruby has <a href="http://rubyeventmachine.com/">EventMachine</a> (which is already five years old).  On these "frameworks" you can write your own servers, like Node.js.  For example, for Java (based on java.nio), <a href="http://www.jboss.org/netty">Netty</a> and <a href="http://stackoverflow.com/questions/1637752/netty-vs-apache-mina">MINA</a> are written, and for Ruby (based on EventMachine), <a href="http://www.igvita.com/2011/03/08/goliath-non-blocking-ruby-19-web-server/">Goliath</a> (which also benefits from <a href="http://en.wikipedia.org/wiki/Coroutine">Fibers</a> ). <br><br><h4>  Advantages and disadvantages </h4><br>  "Asynchronous event model" is well suited where many, many users simultaneously perform some actions that do not load the processor.  For example: they receive temperature from the sensors in the â€œ <a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25B2%25D1%2580%25D0%25B5%25D0%25BC%25D1%258F">current time</a> â€ mode, receive images from video cameras, transmit the temperature taken from the thermometers attached to them to the server, write new messages in the chat, receive new messages from the chat, etc. <br><br>  The requirement of actions that do not load the processor becomes clear when we remember that this entire infinite cycle is running in one single thread, and if you insert some heavy computation into this cycle (let's say, start solving a differential equation), then all the rest users will wait in the queue until this calculation is completed. <br><br>  Therefore, servers like Node.js are suitable only for tasks that do not load the processor, or as a â€œfrontendâ€ for a heavyweight <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D1%2580%25D0%25BE%25D0%25BD%25D1%2582%25D0%25B5%25D0%25BD%25D0%25B4">backend</a> .  And also they are suitable as servers for servicing â€œslowâ€ requests (narrow communication channel, slow data return / sending, long response time somewhere inside, ...).  I would take servers like Node.js to take the place of the â€œinput-outputâ€ intermediary.  For example, the place of the intermediary between the â€œclientâ€ and the â€œserverâ€: the entire visual representation is created and drawn directly in the browser of the Internet user, all the necessary data is stored on the server in the repository, and Node.js performs the intermediary task, issuing the â€œclientâ€ the required data on request and writing new data to the storage when it comes from a â€œclientâ€. <br><br>  The fact that the servers on the "asynchronous event model" are running in the same system thread in practice creates two more obstacles.  The first is memory leaks.  If Apache creates a system thread for each new request, then, after sending the response to the user, this system thread self-destructs, and all the memory allocated to it is simply released.  In the case of, say, Node.js, the developer should be careful <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B1%25D0%25BE%25D1%2580%25D1%2589%25D0%25B8%25D0%25BA_%25D0%25BC%25D1%2583%25D1%2581%25D0%25BE%25D1%2580%25D0%25B0">not to leave a trace</a> when processing the next user request (to remove all the evidence from the memory that such a request came at all), otherwise the process will devour more and more memory with each new request.  The second is the handling of program errors.  If, again, normal Apache creates a separate system thread to process the incoming request, and the processing code in PHP throws some â€œexceptionâ€, then this system thread will just silently â€œdieâ€, and the user will receive in response a page like â€œ500.  Internal Server Error.  In the case of the same Node.js, the only error that occurred during the processing of a single request would â€œputâ€ the entire server entirely, due to which it would have to be <a href="http://kuroikaze85.wordpress.com/2010/04/27/using-nodejs-with-init-and-monit/">monitored and restarted manually</a> . <br><br>  Another possible drawback of the â€œasynchronous event modelâ€ is sometimes (not always, but it happens, especially when using the â€œasynchronous event modelâ€ for what it is not intended for) the application code <a href="http://news.ycombinator.com/item%3Fid%3D2266124">can become difficult</a> to understand because of the intertwining of <a href="http://ru.wikipedia.org/wiki/Callback_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5)">â€œcallbacksâ€</a> .  This is called the problem of <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BF%25D0%25B0%25D0%25B3%25D0%25B5%25D1%2582%25D1%2582%25D0%25B8-%25D0%25BA%25D0%25BE%25D0%25B4">â€œspaghetti codeâ€</a> , and is described as: â€œa callback on a callback, a callback on driveâ€.  They are trying to fight this, and, for example, the library <a href="http://substack.net/posts/e0741f/Seq-Chainable-Asynchronous-Flow-Control-in-Node-js">Seq is</a> written for Node.js. <br><br>  Another way to eliminate â€œcallbacksâ€ in general is the so-called <a href="http://ru.wikipedia.org/wiki/Continuation">continuations</a> ( <a href="http://en.wikipedia.org/wiki/Coroutine">coroutines</a> ).  They are introduced, for example, in <a href="http://ru.wikipedia.org/wiki/Scala_(%25D1%258F%25D0%25B7%25D1%258B%25D0%25BA_%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D1%258F)">Scala</a> , starting with version 2.8 ( <a href="http://jim-mcbeath.blogspot.com/2011/04/java-nio-and-scala-coroutines.html">coroutines</a> ), and in Ruby, starting with version 1.9 ( <a href="http://www.rubyinside.com/ruby-fibers-8-useful-reads-on-rubys-new-concurrency-feature-1769.html">Fibers</a> ).  Here's an example of how using Fibers in Ruby, you can completely eliminate callbacks, and write code <a href="http://www.igvita.com/2010/03/22/untangling-evented-code-with-ruby-fibers/">as if everything happens synchronously</a> . <br><br>  For Node.js, a similar <a href="https://github.com/laverdet/node-fibers">node-fibers</a> library was written.  In terms of performance (in artificial tests, not in real applications), node-fibers still work <a href="https://github.com/laverdet/node-fibers/issues/23">about three to four times slower than the</a> usual style with â€œcallbacksâ€.  The author of the library <a href="http://groups.google.com/group/nodejs/browse_thread/thread/ddd6e2756f1f4d8c">states</a> that this performance difference arises where Javascript fits into the C ++ code of <a href="http://ru.wikipedia.org/wiki/V8_(%25D0%25B4%25D0%25B2%25D0%25B8%25D0%25B6%25D0%25BE%25D0%25BA_JavaScript)">the V8 engine</a> (on which Node.js itself is based), and that performance measurements should not be interpreted as â€œnode-fibers three to four times slowerâ€ callbacks â€, but asâ€œ compared to the other low-level actions in your code (working with byte arrays, connecting to a database or to a service on the Internet), the node-fibers performance imprint will not be noticed at all â€. <br><br>  In addition to the usual programming style, node-fibers gives us a familiar and convenient <a href="http://ru.wikipedia.org/wiki/%25D0%2598%25D1%2581%25D0%25BA%25D0%25BB%25D1%258E%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5)">way to handle try / catch errors</a> .  However, this library <a href="http://markmail.org/message/4kpqyrpghfdjfkao">will not be implemented into the core of Node.js</a> , since <a href="http://tinyclouds.org/">Ryan Dahl</a> sees the purpose of his creation in being low-level and not hiding anything from the developer. <br><br>  This concludes the main part of this article, and finally we will briefly consider an alternative way, and how the â€œevent loopâ€ polls the â€œsources of eventsâ€ for new data in them. <br><br><h4>  Alternative way </h4><br>  In this article, we explained why an application that uses â€œsynchronousâ€ and â€œblockingâ€ I / O does not support a large number of simultaneous connections.  As one of the solutions, we proposed to transfer this application to an â€œasynchronous event modelâ€ (that is, to rewrite the application, say, on Node.js).  In this way, we will solve the problem by actually (backstage) switching from â€œsynchronousâ€ and â€œblockingâ€ input / output to â€œsynchronousâ€ and â€œnon-blockingâ€ input / output.  But this is not the only solution: we can also resort to "asynchronous" I / O. <br><br>  Namely, we can use the good old "pool" of system flows (described earlier in this article), which evolved to a new stage of development.  This stage of development is called <a href="http://en.wikipedia.org/wiki/Green_threads">â€œgreen processesâ€</a> (respectively, there are also â€œgreen streamsâ€).  These are processes, but not system ones, but created by a <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B8%25D1%2580%25D1%2582%25D1%2583%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D1%2588%25D0%25B8%25D0%25BD%25D0%25B0">virtual machine of</a> the language in which our code is written.  A virtual machine runs inside itself the usual â€œpoolâ€ of system threads (say, by the number of cores in the processor), and already on these system threads displays its internal â€œgreen processesâ€ (completely hiding it from the developer). <br><br>  â€œGreen processesâ€ are precisely â€œprocessesâ€ and not â€œflowsâ€, since they do not have any common variables with each other, and communicate only by sending control â€œmessagesâ€ to each other.  Such a model provides protection against various <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B7%25D0%25B0%25D0%25B8%25D0%25BC%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25B1%25D0%25BB%25D0%25BE%25D0%25BA%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25BA%25D0%25B0">â€œdeadlocksâ€</a> and avoids problems with <a href="http://www.vr-online.ru/%3Fq%3Dcontent/sovmestnyj-dostup-k-dannym-1140">data sharing</a> , because everything that has a â€œgreen processâ€ is its internal state and â€œmessageâ€. <br><br>  Each "object" has its own turn of "messages" (for this, a "green process" is created).  And any call to the â€œobjectâ€ code is sending a â€œmessageâ€ to it.  Sending â€œmessagesâ€ from one â€œobjectâ€ to another â€œobjectâ€ occurs asynchronously. <br><br>  In addition to this, the virtual machine creates its I / O subsystem, which is mapped to non-blocking system I / O (and again the developer is unaware of anything). <br><br>  And, of course, the virtual machine also contains its internal scheduler. <br><br>  As a result, the developer thinks that he is writing the usual code, with the usual I / O, but in fact there is a very high-performance system.  Examples: <a href="http://ru.wikipedia.org/wiki/Erlang">Erlang</a> , <a href="http://en.wikipedia.org/wiki/Actor_model">Actors</a> in <a href="http://ru.wikipedia.org/wiki/Scala_(%25D1%258F%25D0%25B7%25D1%258B%25D0%25BA_%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D1%258F)">Scala</a> . <br><br><h4>  How the â€œevent loopâ€ polls the â€œevent sourcesâ€ for new data </h4><br>  The simplest solution you can think of is to poll all the â€œdescriptorsâ€ (open network sockets, read or write files, ...) for new data.  This algorithm is called <a href="http://en.wikipedia.org/wiki/Polling_(computer_science)">â€œpollâ€</a> .  It looks like this: <ul><li>  you have two open sockets </li><li>  you create an array of two structures that describe these sockets </li><li>  to each element of this array, you put down what and what socket to write to it </li><li>  then you pass this array to the system function poll, which writes there a description of the current state of these sockets </li><li>  after that you walk through this array again, figuring out whether there is new data for these sockets </li><li>  if there is, read them and do something with them </li><li>        Â« Â» </li></ul>         ,   ,   ,      Â« Â»  Â« Â»,        (   ). <br><br>         ,         ,    ,     -     ( ,    <a href="http://ru.wikipedia.org/wiki/%25D0%25A8%25D0%25B8%25D0%25BD%25D0%25B0_(%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BF%25D1%258C%25D1%258E%25D1%2582%25D0%25B5%25D1%2580)"> </a>        ). <br><br>    ( <a href="http://people.freebsd.org/~jlemon/papers/kqueue.pdf"> 95%</a> )   (  10 000  )  ,        . <br><br>         ,  ,      ,    .  ,       ,   Â« Â»  .    : Â«   O(n)Â». <br><br>      ? ,         : <a href="http://en.wikipedia.org/wiki/Epoll">epoll</a>  Linux'  <a href="http://en.wikipedia.org/wiki/Kqueue">kqueue</a>  FreeBSD.  Windows'   <a href="http://en.wikipedia.org/wiki/Input/output_completion_port">IO Completion Ports</a> ,       <i>epoll</i> ',    <a href="http://joyent.com/"> Node.js'</a>     Windows,       <a href="https://github.com/joyent/libuv">libuv</a> ,      libev,    IO Completion Ports. <br><br>  <i>epoll</i> .     <i>poll</i> '   . <br><ul><li>       (   ),       (  ),   . </li><li>             <i>/dev/epoll</i> (    Â«Â»,      Linux' Â«  Â»).      (   )    <a href="http://en.wikipedia.org/wiki/Mmap">mmap</a>  -  .         <a href="http://en.wikipedia.org/wiki/Ioctl">ioctl</a> </li></ul><br>       O(n) ,      O(1) ,            . <br><br><h4> ,      </h4><br>    ,  : <a href="https://habrahabr.ru/users/akzhan/" class="user_link">akzhan</a> , <a href="https://habrahabr.ru/users/erlyvideo/" class="user_link">erlyvideo</a> , <a href="https://habrahabr.ru/users/eyeofhell/" class="user_link">eyeofhell</a> , <a href="https://habrahabr.ru/users/magasoft/" class="user_link">MagaSoft</a> , <a href="https://habrahabr.ru/users/mox/" class="user_link">Mox</a> , <a href="https://habrahabr.ru/users/nuit/" class="user_link">nuit</a> , <a href="https://habrahabr.ru/users/olegich/" class="user_link">olegich</a> , <a href="https://habrahabr.ru/users/reddot/" class="user_link">reddot</a> , <a href="https://habrahabr.ru/users/splav_asv/" class="user_link">splav_asv</a> , <a href="https://habrahabr.ru/users/tanenn/" class="user_link">tanenn</a> , <a href="https://habrahabr.ru/users/throwable/" class="user_link">Throwable</a> . <br>      ,  : <a href="https://habrahabr.ru/users/goder/" class="user_link">Goder</a> , @theelephant. <br><br><h4>  Related Links </h4><br> <a href="http://habrahabr.ru/blogs/webdev/108241/">  ,  ,   Node.js â€”    -</a> <br> <a href="http://confreaks.net/videos/555-scotlandruby2011-introduction-to-eventmachine-and-evented-programming">  EventMachine</a> <br> <a href="http://bulk.fefe.de/scalable-networking.pdf">Scalable network programming</a> <br> <a href="http://people.freebsd.org/~jlemon/papers/kqueue.pdf">Kqueue</a> <br> <a href="http://habrahabr.ru/blogs/python/107237/">Stackless Python  Concurrence</a> <br> <a href="http%253A%252F%252Fdocs.google.com%252Fviewer%253Fa%253Dv%2526q%253Dcache%253AJU6Hg3DUj0oJ%253Aube.ege.edu.tr%252F~erciyes%252FCENG322%252Fnotes%252F510_socket5.ppt%252Bi%252Fo%252Bmultiplexing%252Bsite%253Aube.ege.edu.tr%2526hl%253Dru%2526gl%253Dru%2526pid%253Dbl%2526srcid%253DADGEESjbF5FlSvwsbdHH8UVCKVUmgtOXnzsnE-xyHqlmqhiMwfWsyxqpB3FUpwVW39BR-Nm-2SPqFCVp5Puf3l-EDHSulJW_k7KEi1ZRyoMrVryGrCd1w0hXPSFjsT6lRa_aNvI1antj%2526sig%253DAHIEtbRkA7xfi9gm6hrTHYVF_ETiv6OwtQ%26ei%3DWK54TpngHa_Y4QSjmsmJDA%26usg%3DAFQjCNFPZh-v2n4PV3OFKy3uGWJ_T4j51Q%26sig2%3De4Cnk-QIbUKNEnhiSWYy-w">     / (  ,  )</a> <br>  <a href="http://habrahabr.ru/blogs/nodejs/116124/">node-sync - pseudo-synchronous programming on nodejs using fibers</a> <br> <a href="http://computere.mybb.ru/viewtopic.php%3Fid%3D5">   </a> <br> <a href="http://citeseer.ist.psu.edu/viewdoc/download%3Bjsessionid%3DBF94ABE409DD15D886DE5F747C21F7BB%3Fdoi%3D10.1.1.91.957%26rep%3Drep1%26type%3Dpdf">What every programmer should know about memory</a> <br> <a href="http://www.mulix.org/lectures/kernel_workshop_mar_2004/things.pdf">10 things every Linux programmer should know</a> <br> <a href="http://jsconf.eu/2009/video_nodejs_by_ryan_dahl.html">Video: Node.js by Ryan Dahl</a> <br> <a href="http://blog.envylabs.com/2010/07/no-callbacks-no-threads-ruby-1-9/">No Callbacks, No Threads &amp; Ruby 1.9</a> </div><p>Source: <a href="https://habr.com/ru/post/128772/">https://habr.com/ru/post/128772/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../128765/index.html">Opera Software bought Handster</a></li>
<li><a href="../128766/index.html">Modder was able to combine PSP and GameCube</a></li>
<li><a href="../128768/index.html">Image segmentation</a></li>
<li><a href="../128769/index.html">Stored procedures. Who is faster</a></li>
<li><a href="../128770/index.html">VRRP in Linux</a></li>
<li><a href="../128773/index.html">Alpha-blending per one-pixel multiplication on Windows Mobile</a></li>
<li><a href="../128774/index.html">Modding the USB-to-SATA converter for your own needs</a></li>
<li><a href="../128775/index.html">Samsung Galaxy Tab 10.1 - how to disassemble the tablet and what it consists of</a></li>
<li><a href="../128776/index.html">Over 270 video reports from BUILD conference are available.</a></li>
<li><a href="../128777/index.html">Is your ICQ UIN running on another computer? Keep communicating on this!</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>