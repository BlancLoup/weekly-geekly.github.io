<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Kinect for Windows SDK. Part 2. Data Flows</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="- Kinect for Windows SDK. Part 1. Sensor 
- [Kinect for Windows SDK. Part 2. Data Flows] 
- Kinect for Windows SDK. Part 3. Functionalities 
- Playing...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Kinect for Windows SDK. Part 2. Data Flows</h1><div class="post__text post__text-html js-mediator-article"><ul><li>  <a href="http://habrahabr.ru/post/150955">Kinect for Windows SDK.</a>  <a href="http://habrahabr.ru/post/150955">Part 1. Sensor</a> </li><li>  [Kinect for Windows SDK.  Part 2. Data Flows] </li><li>  <a href="http://habrahabr.ru/post/151296/">Kinect for Windows SDK.</a>  <a href="http://habrahabr.ru/post/151296/">Part 3. Functionalities</a> </li><li>  <a href="http://habrahabr.ru/post/142236/">Playing cubes with Kinect</a> </li><li>  <a href="http://habrahabr.ru/post/142677/">Program, aport!</a> </li></ul><br>  Continue to get acquainted with the possibilities of Kinect.  <a href="http://habrahabr.ru/post/150955">Last time</a> I outlined several features of Kinect, each of which undoubtedly deserves a separate article, and did not mention the workers at all, by whose efforts both speech recognition and tracking of the human figure are provided.  Have you ever thought in what form the sensor transmits data?  What is this stream or data streams?  And if once a moonless night, in a dark alley, a maniac sneaks up on you and asks: ‚ÄúHow many data streams does Kinect have at the exit?‚Äù, Without hesitation, answer: ‚ÄúThree!‚Äù.  Video <i>Stream (Color Stream)</i> , <i>Audio Stream (Audio Stream)</i> and rangefinder data <i>(Depth Stream)</i> .  The SDK builds on these threads.  Let's start with them. <br><img src="https://habrastorage.org/getpro/habr/post_images/07a/18b/a39/07a18ba39d10a7544a7b9fa1f4ebdc34.png" alt="image"><br><a name="habracut"></a><br>  Setting a goal to use the Kinect features, the first thing to do is to select the desired sensor and initialize the required data streams.  Remember that up to 4 sensors can be connected to the computer at the same time?  With the help of the <a href="http://msdn.microsoft.com/en-us/library/microsoft.kinect.kinectsensor">KinectSensor</a> class it is not too difficult to sort them all.  In the documentation you will find this way to select and enable the first connected sensor: <br><br><pre><code class="cs hljs">KinectSensor kinect = KinectSensor.KinectSensors.Where(s =&gt; s.Status == KinectStatus.Connected).FirstOrDefault(); kinect.Start();</code> </pre> <br><br>  After that, for the selected sensor, you can configure and enable the necessary threads.  And it is on the three data streams received from the sensor, we will stop a little. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  Sensor Stream </h5><br>  Carefully reading MSDN, you can see, it seems, useful information about this stream.  For example, the developer is free to set the quality level and format of the picture when initializing the video stream.  The quantity and speed of data transmitted from the sensor, which, in turn, is limited by USB 2.0 bandwidth, directly depends on the quality level.  So for a picture with a resolution of 1280x960, the number of frames per second is 12, and for a picture with a resolution of 640x480 - 30. The image format is determined by the color model and can be either RGB or YUV. <br><br>  The combinations of quality level and image format are represented by the <a href="http://msdn.microsoft.com/en-us/library/microsoft.kinect.colorimageformat">ColorImageFormat</a> listing.  Three of its values ‚Äã‚Äãdetermine the 32-bit encoding of each pixel of the image: <i>RgbResolution1280x960Fps12</i> , <i>RgbResolution640x480Fps30</i> and <i>YuvResolution640x480Fps15</i> , and the fourth - 16-bit <i>RawYuvResolution640x480Fps15</i> .  <i>YuvResolution 640x480Fps15</i> causes a <i>lot of confusion</i> .  The MSDN clearly states ( <a href="http://msdn.microsoft.com/en-us/library/nuiimagecamera.nui_image_type">here</a> and <a href="http://msdn.microsoft.com/en-us/library/jj131027">here</a> ) that this is a YUV converted to RGB32 ... but, nevertheless, continues to be YUV ... <br><br>  To start receiving a video stream from the sensor, this same stream must be initialized: <br><br><pre> <code class="cs hljs"><span class="hljs-comment"><span class="hljs-comment">//      RGB   640x480(30fps) kinect.ColorStream.Enable(ColorImageFormat.RgbResolution640x480Fps30); //      ,         kinect.ColorFrameReady +=SensorColorFrameReady;</span></span></code> </pre><br><br>  A slightly more detailed <a href="http://msdn.microsoft.com/en-us/library/hh973069">example</a> can be found in MSDN. <br><br><h5>  Sensor audio stream </h5><br>  You already know that Kinect has a built-in set of four microphones using a 24-bit analog-to-digital converter, and the built-in audio signal handler includes echo cancellation and noise reduction.  Each microphone is set to have a small focus.  Whether to use echo or noise reduction depends on the developer, i.e.  These options are set at the initialization stage of the audio stream.  The optimal distance between the speaker and the sensor is 1-3 meters. <br><br>  Kinect audio capabilities can be used in a variety of ways, for example, for high-quality audio capture, audio positioning, or speech recognition.  We will discuss speech recognition further, but now I would like to dwell on one feature of Kinect, the description of which I did not find in the documentation (I was looking bad?).  Initialization of the audio stream takes a little less than four seconds.  This must be taken into account, and, say, after calling the Start () sensor method, a delay of four seconds is made before adjusting the parameters of the audio stream - <a href="http://msdn.microsoft.com/en-us/library/microsoft.kinect.kinectsensor.audiosource">KinectSensor.AudioSource</a> .  <a href="http://msdn.microsoft.com/en-us/library/hh855349">An example of</a> determining the direction of sound can be found in MSDN. <br><br><h5>  Rangefinder data flow from sensor </h5><br>  Must be the most interesting thread.  And it is primarily interesting to those who want to know more about tracking a human figure <i>(skeletal tracking)</i> . <br><br>  This stream is formed from frames in which each pixel contains the distance (in millimeters) from the sensor plane to the nearest object in certain coordinates of the camera's field of view.  As in the case of a video stream, the resolution of a single frame can be set for the rangefinder data stream, which is defined by the <a href="http://msdn.microsoft.com/en-us/library/microsoft.kinect.depthimageformat">DepthImageFormat</a> enumeration.  With a frame rate of 30 per second, the developer is free to choose resolutions of 80x60 ( <i>Resolution80x60Fps30</i> ), 320x240 ( <i>Resolution320x240Fps30</i> ) and 640x480 ( <i>Resolution640x480Fps30</i> ).  And as already mentioned in the previous part, there are two ranges of ‚Äúworking‚Äù distances: Default Range and Near Range, defined by the <a href="http://msdn.microsoft.com/en-us/library/microsoft.kinect.depthrange.aspx">DepthRange</a> enumeration. <br><br><pre> <code class="cs hljs"><span class="hljs-comment"><span class="hljs-comment">//    kinect.DepthStream.Range = DepthRange.Near; //       640x480(30fps) kinect.DepthStream.Enable(DepthImageFormat.Resolution640x480Fps30);</span></span></code> </pre><br><br>  But that's not all.  The fact is that the distance value in each pixel is encoded only by 13 bits, and 3 bits are designed to identify the person.  If the distance to the object is outside the operating range (remember the Default and Near? Ranges), a zero or a specific constant will return in 13 bits.  If during the sensor initialization, enable tracking of a human figure, in 3 bits the sequence number (1 or 2) of the detected person will be returned (if a person is found at this point, otherwise 0 will return): <br><br><pre> <code class="cs hljs">kinect.SkeletonStream.Enable();</code> </pre><br><br>  So, we have come close to the first opportunity of Kinect, which we will consider, namely the tracking of the human figure <i>(skeletal tracking)</i> . </div><p>Source: <a href="https://habr.com/ru/post/151131/">https://habr.com/ru/post/151131/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../151126/index.html">802.11 Network Security - Top Threats</a></li>
<li><a href="../151127/index.html">Does the Internet dumb us?</a></li>
<li><a href="../151128/index.html">Unix as IDE: Working with Text</a></li>
<li><a href="../151129/index.html">We make a textbook or documentation for an hour on the Sphinx</a></li>
<li><a href="../151130/index.html">Happy Testers Day!</a></li>
<li><a href="../151132/index.html">Leaked information about the unusual camera from Sony</a></li>
<li><a href="../151133/index.html">ReactOS hires and pays in Euro</a></li>
<li><a href="../151134/index.html">The first chip to measure the strength of Casimir</a></li>
<li><a href="../151135/index.html">How to watch videos with two subtitle streams</a></li>
<li><a href="../151137/index.html">WebStorm 5 Released - Become More Productive</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>