<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Data engineer climb</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I joined the Facebook team in 2011 as a business analyst engineer. By the time I left the team in 2013, I was already a data engineer. 

 I was not pr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Data engineer climb</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/1cf/412/a1f/1cf412a1f9bbe136abfaa788dca2b41c.png" alt="image"><br><br>  I joined the Facebook team in 2011 as a business analyst engineer.  By the time I left the team in 2013, I was already a data engineer. <br><br>  I was not promoted or assigned to this new position.  In fact, Facebook has come to the conclusion that the work we do is a classic business intelligence.  The role that we ultimately created for ourselves was a completely new discipline, and my team and I were at the forefront of this transformation.  We developed new approaches, ways to solve problems and tools.  In this case, most often, we ignored the traditional methods.  We were pioneers.  We were data engineers! 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  Date-engineering? </h3><br>  The science of data as an independent discipline is experiencing a period of adolescent self-assertion and self-determination.  At the same time, data engineering could be called its ‚Äúyounger brother‚Äù, who also went through something similar.  Data-engineering received signals from its ‚Äúsenior relative‚Äù, searched for its place and its own identity.  Like data scientists, data engineers also write code.  It is highly analytic, with a large share of visualization. <br><br>  But unlike scientists working with data and inspired by a more mature progenitor of the sphere - programming - data engineers create their own tools, infrastructure, frameworks and services.  In fact, we are much closer to programming than to the science of data. <br><a name="habracut"></a><br>  In connection with the previously established roles, data engineering could be considered as a superset of business intelligence and databases that brings in more programming elements.  This discipline includes the specialization of working with distributed Big Data systems, an extended Hadoop ecosystem, streaming data processing and working with Scale. <br><br>  In small companies, where there is still no definitive infrastructure for data storage, engineers are assigned the role of its creation and support within the organization.  This includes platform support tasks on Hadoop / Hive / HBase, Spark or something similar. <br><br>  In small ecosystems, people tend to use hosting services, such as Amazon or Databricks, or get support from companies like Cloudera or Hortonworks, which essentially play the role of intermediaries between other companies. <br><br>  In large ecosystems, there is a tendency towards specialization and the creation of a formal position to manage this area, as the team's need for data infrastructure is constantly growing.  This unites the team to solve higher level tasks.  As the engineering aspect of the data engineer position grows, aspects of its original business role become secondary.  For example, the emphasis is reduced from creating and maintaining report portfolios and informational tables. <br><br>  Now we have an excellent set of self-service tools, where analysts, scientists and the spherical "information worker" work more intelligently and can operate on data offline. <br><br><h3>  ETL is changing </h3><br>  We observed a massive departure from the practice of drag-and-drop ETL (Extract Transform and Load) to the program approach.  Products based on know-how platforms like Informatica, IBM DataStage, Cognos, AbInitio or Microsoft SSIS are not common among modern data engineers and are being replaced by more general software and programming skills, along with an understanding of software platforms or configurable Airflow, Oozie, Azkabhan platforms or Luigi.  This is a fairly common practice among data engineers who manage their workflow through, for example, a scheduler. <br><br>  There are many reasons why complex software elements are not developed on the principle of "drag and drop" tools: ultimately, self-written code is the best solution for software.  Although the reasoning on this topic is beyond the scope of this publication, it is easy to conclude that all of the above applies to the writing of the ETL, as it applies to any other software. <br><br>  Own code allows the use of arbitrary levels of abstraction, allows you to describe logical operations in the usual way, suitable for collaboration and interacts well with the source of version control.  The fact that ETL tools have evolved to extrude graphical interfaces seems like a full circle of data processing history. <br><br>  It must be emphasized that abstractions influenced by traditional ETL tools deviated from their original purpose.  There is no doubt the need for the abstract complexity of data processing exists, as in the calculation and storage.  But I will note that these solutions should not be simplified by means of ETL (for example, a source / target bundle, filtering, etc.) because of the fashion, use the drag-and-drop approach.  Abstractions must have a higher level.  For example, a necessary abstraction of a modern data environment is a configuration for experimenting with A / B testing frameworks. <br><br>  What kind of experiments?  How will they go?  What are the related procedures?  What percentage of users should take part in the test?  When are the results expected?  What will we measure?  In this case, we have a specific framework with which we can determine the input data with high accuracy, upload statistics and get final calculations.  We expect that adding new data will simply lead to additional calculations and the data will be updated.  It is important to understand that in this example the parameters of the abstraction are not determined by the traditional ETL tools and that the task of such an abstraction did not occur with the help of drug-and-drop'a. <br><br>  For a modern data engineer, traditional tools in the form of ETL are obsolete, because their logic cannot be expressed in the form of code.  As a result, the necessary abstractions created using these tools cannot be understood intuitively. <br><br>  Now, knowing that ETL is not enough, one can argue about the creation of this direction from scratch.  A new stack, new tools, a new set of rules and, in many cases, a new generation of specialists are needed. <br><br><h3>  Data modeling is changing </h3><br>  Typical modeling techniques ‚Äî like the star schema ‚Äî they define our data modeling approach for analyzing workloads associated with the data warehouse, but are less and less significant for us.  The best traditional practices in data warehousing lose ground when it comes to changing stacks.  At the same time, it is cheaper to store and process data than ever before, and the emergence of distributed bases and linear scaling saves such a scarce resource as ‚Äúengineer time‚Äù.  Here are some changes that are observed in data modeling techniques: <br><br><ul><li>  Additional denormalization (support of surrogate keys can be used as a trick, but this makes tables less readable), using real (human) readable keys and table change attributes is becoming more common, reducing the need for expensive connections that may be too heavy for distributed databases.  Also note that code support and compression in a serialization format, such as Parquet or ORC, or within a DBMS using Vertica, leads to a serious loss of performance, which is usually associated with denormalization.  These systems were created to normalize data, and storage is optional. <br><br></li><li>  BLOBs: modern databases were created with the support of "Blobs" through their own types and functions.  This opens up new possibilities in data processing modeling and can allow several functional granules to be stored in the table at once when a dynamic scheme is required. <br><br></li><li>  Dynamic schemes: since the advent of map reduce and with the increasing popularity of documentation for supporting blobs and databases, it has become much easier to develop database schemas without executing DML.  This simplifies an iterative approach to data storage and eliminates the need to achieve a complete consensus between sales and development. <br><br></li><li>  Systematic snapshuting of the dimension (saving a full copy of the table size for each ETL cycle graph, usually done in different sections of the table) is used as a simple way to cope with the SCD (slow changing dimension).  However, it requires little effort and, unlike the classical approach, it is easy to understand when writing ETL and queries.  It also makes it easy and relatively cheap to denormalize the dimension attribute and the table in order to track its readings when the operation is completed.  In retrospect, complex SCD modeling techniques are not intuitive and reduce accessibility. <br><br></li><li>  Accordingly, the consistency of measurements and metrics is still extremely important in the environment of modern databases, but besides this we also need the speed of interaction with a large team, which includes many experts who also contribute to the work, and a certain compromise is needed here. </li></ul><br><h2>  Roles and responsibilities </h2><br><h3>  Data store </h3><br>  ‚ÄúThe data warehouse is a copy of all the transferred data, which is specially structured for querying and analyzing,‚Äù - Ralph Kimball. <br><br>  ‚ÄúThe data warehouse is a domain-specific, integrated, time-varying and non-volatile data collection method and a guide to decision-making,‚Äù Bill Inmon. <br><br>  Data storage is more relevant than ever, and data engineers are responsible for many aspects of its formation and operation.  The data storage is the coordinate center of the data engineer and everything revolves around it. <br><br>  Modern data storage is now more open than it used to be.  Now scientists, analysts and software engineers are taking part in its creation and operation at the same time.  Data has become too important a center of activity for any company to restrict access to it and more and more types of specialists can manage it.  Although this allows scaling for the organization of workflows within an organization and meeting its information needs, as a result, this approach leads to a chaotic and imperfect infrastructure element. <br><br>  Data engineers of companies often undergo internal certification to improve their skills in working with data warehouses.  In Airbnb, for example, there is a set of ‚Äúcore‚Äù schemes that are managed by a data engineers team as part of a service agreement (SLA), where the parameters are clearly defined and are strictly followed.  We are talking about business metadata and documentation of the highest level, for which maintenance requires a clear set of best practices. <br><br>  Often, such a data warehouse becomes for the engineering team a ‚Äúcenter of advanced development‚Äù, which defines standards and applies the best solutions and processes for certifying database objects.  Such a team can take part in the education of other specialists by sharing their best decisions.  All this is done to ensure that other engineers are improved in the field of working with data warehouses.  For example, Facebook has its own Data Camp education program, and Airbmb has a Data University.  There, engineers are trained to work with the database. <br><br>  Data engineers are ‚Äúlibrarians‚Äù of data warehousing, people who catalog and organize metadata that defines workflows.  In the fast-growing and partly chaotic world of data, metadata and tool management is becoming a vital component of any modern platform. <br><br><h3>  Performance and Optimization </h3><br>  Data is becoming more and more strategic when companies grow and their infrastructure budgets are impressive.  This makes it more and more rational for data engineers to increase productivity and optimize data processing and storage.  Since budgets are rarely reduced (in this area), optimization consists in more efficient use of resources or ‚Äústraightening‚Äù the exponential growth of workload and costs to a linear form. <br><br>  Knowing the enormous complexity of the engineering stack of working with databases, we can assume that optimizing such a stack is also not an easy task.  As a rule, decisions are made that require a minimum of costs while bringing great benefits. <br><br>  Of course, in the interests of the engineer to create a scalable infrastructure.  This allows the company to save resources at all stages. <br><br><h3>  Data integration </h3><br>  The integration of data and the practice of business integration systems by sharing data are more important than ever.  Software and SaaS are becoming the new standard for companies.  At the same time the need to synchronize data between these systems is becoming more and more critical.  Moreover, SaaS needs new management standards from the company if we want to bring in the data obtained on the side to our repository so that they are related to the data we already have.  Of course, SaaS has its own analytical solutions, but from time to time they lack the prospects for working with the rest of the proposed data set.  Often, these SaaS models offer to accept relational data without integration and exchange of primary keys, which ultimately leads to a catastrophe that should be avoided at all costs.  No one wants to manually maintain two repositories and a client for two lists on different systems or worse. <br><br>  The head of the company often signs a contract with SaaS suppliers without taking into account the problem of data integration.  The integration load is systematically minimized by solution providers for the sake of higher sales, which ultimately falls on the shoulders of data engineers who have to perform unplanned work.  Not to mention the fact that typical SaaS APIs are often lousy and do not have clear documentation and sufficient flexibility.  All this means that you can expect anything, for example, changes in the solution without prior notice from the supplier. <br><br><h3>  Services </h3><br>  Data engineers work with higher levels of abstraction.  In some cases, this means that these same engineers, scientists, or analysts can provide manual services and tools to automate the work. <br><br>  Here are some examples of services that data engineers and database infrastructure maintenance engineers can create that can be exploited. <br><br><ul><li>  Data uptake: services and tools built around ‚Äúscraping‚Äù the database, loading logs, extracting data from external sources or an API ... <br><br></li><li>  Calculation of metrics: frameworks for calculating and summarizing participation, growth, or segmentation-related indicators. <br><br></li><li>  Anomaly detection: automating data consumption and warning the right people about anomalous events or the emergence of trends to significant changes. <br><br></li><li>  Metadata management: tools built around the generation and consumption of metadata, making it easy to find information both inside and outside the repository. <br><br></li><li>  Experimentation: Writing experimental A / B tests and frameworks is often an important component of a company's analytics with a significant amount of engineering data. <br><br></li><li>  Toolkit: analytics begins with recording the events and attributes associated with these events.  Data engineers are selfishly interested in high-quality data going up. <br><br></li><li>  Professionalization: the creation of sources of information that specialize in building actions in chronology, which allows analysts to understand the behavior of the user. <br></li></ul><br>  As well as software developers, data engineers must be constantly looking for ways to automate their work and set abstractions that allow them to grow.  The level of need for process automation may vary depending on the situation, but it should be carried out in all directions. <br><br><h3>  Skills Required </h3><br>  <b>Knowledge of SQL:</b> if English is the language of world business, then SQL is the language of data.  How successful do you want to be a businessman if you don‚Äôt speak good English?  Technology and generation are changing, but SQL stands firmly on its feet, like <a href="https://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B3%25D0%25B2%25D0%25B0_%25D1%2584%25D1%2580%25D0%25B0%25D0%25BD%25D0%25BA%25D0%25B0">Lingua Franca of the</a> data world.  The data engineer should be able to use SQL to express such things as ‚Äúsubquery correlation‚Äù and window functions of any complexity.  SQL / DML / DDL are primitive and simple enough to have no secrets from the data engineer.  In addition to the declarative nature of SQL, the engineer must be able to read and understand the execution plans of the database, as well as have an idea of ‚Äã‚Äãhow all the stages, indices, and various join and distributed measurement algorithms work within the framework of this plan. <br><br>  <b>Methods of data modeling:</b> for a data engineer, the ‚Äúentity-relationship‚Äù modeling should become a reflex, along with a clear understanding of normalization and an intuitive sense of the line between denormalization and the need to make concessions. -              . <br><br> <b> ETL:</b>   ,   ¬´¬ª ETL   .          . <br><br> <b> :</b>       , -       , ,    ,    .    , -,     ,  ,  ,     .              ,      ,      . <br><br><h3>  Finally </h3><br>           FAcebook, Airbnb  Yahoo!,      -  Google, Netflix, Amazon, Uber, LYFT       ,     -  ,      .  ,           .  ,       ,   ,    ! </div><p>Source: <a href="https://habr.com/ru/post/321030/">https://habr.com/ru/post/321030/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../321020/index.html">How IT professionals work. SearchInform development manager Dmitry Gatsura</a></li>
<li><a href="../321022/index.html">YouTube Video Text Search</a></li>
<li><a href="../321024/index.html">Class'y Class'y</a></li>
<li><a href="../321026/index.html">How we got smarter and learned how to open quests twice as fast</a></li>
<li><a href="../321028/index.html">A script that writes another script and configures routers</a></li>
<li><a href="../321032/index.html">Using Sketchode 2 in Development: An Overview</a></li>
<li><a href="../321034/index.html">Managing complexity in ruby ‚Äã‚Äãon rails projects. Part 3</a></li>
<li><a href="../321036/index.html">How it all began: developers remember the first games they created</a></li>
<li><a href="../321038/index.html">The history of the creation of the first game on Unity - from idea to release</a></li>
<li><a href="../321040/index.html">Russian 4Gap: distribution of 4G networks in Russia and in the world</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>