<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>I have no mouth, but I have to shout. Reflections on AI and ethics</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Disclaimer  I am skeptical about my ability to express a truly original idea. Most likely, I am not the first to ask these questions, and it is quite ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>I have no mouth, but I have to shout. Reflections on AI and ethics</h1><div class="post__text post__text-html js-mediator-article"><div class="spoiler">  <b class="spoiler_title">Disclaimer</b> <div class="spoiler_text">  I am skeptical about my ability to express a truly original idea.  Most likely, I am not the first to ask these questions, and it is quite possible that they even have some digestible answers.  Therefore, typing this text, I do not expect your surprise or admiration.  I expect that people familiar with the modern philosophy of consciousness will come to the comments and give me references to works of serious thinkers with funny German surnames. <br></div></div><br><img src="https://habrastorage.org/getpro/habr/post_images/4de/bcf/8fe/4debcf8fe238985125121b531bdaefef.jpg" alt="image"><br><br>  Not so long ago there was a <a href="https://habr.com/company/kaspersky/blog/421791/">post</a> on Habr√©, comments on which made me think about several interrelated issues.  The results of these thoughts (or their absence, here how to look) I want to share with the community. <br><br><h3>  What is pain? </h3><br>  I once had a toothache.  I lay on the couch and tried not to pay attention to it.  I thought that pain was just a signal going to my brain.  The same signal as the presence or absence of voltage in the wiring going to the PS / 2 connector of the system unit.  By itself, it does not carry any semantics, it is my mind that chooses how to interpret it.  If I stop taking it as pain, and instead ignore it or simply ‚Äútake note‚Äù, it will be easier for me. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a>  But it did not get any easier.  In this simple way, I discovered that pain has <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B2%25D0%25B0%25D0%25BB%25D0%25B8%25D0%25B0">qualia</a> and is not limited to the simple transfer of information. <br><br><h3>  How do we understand what others hurt? </h3><br>  I am not an expert in neurophysiology, but they say there are some mirror neurons in the brain.  When we see another person perform certain actions, the mirror neurons perform their reverse engineering.  We are trying to understand what should happen in the head of this person so that he behaves exactly this way.  And to some extent even we ourselves begin to feel what, according to our assumptions, he should feel.  My cheekbones can be reduced at the sight of someone eating a lemon.  If someone, for example, screams, cries, writhes, rolls on the floor ... It is likely that this someone is in pain.  Most likely, it will be unpleasant for me to see such a sight.  I will begin to sympathize with this person, and, if it is in my power, I will even take some action to stop the pain.  Damn mirror neurons. <br><br>  In fact, we have no guarantees that the other person is really in pain.  For example, it may be a simulator, an actor, as in the <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D1%2581%25D0%25BF%25D0%25B5%25D1%2580%25D0%25B8%25D0%25BC%25D0%25B5%25D0%25BD%25D1%2582_%25D0%259C%25D0%25B8%25D0%25BB%25D0%25B3%25D1%2580%25D1%258D%25D0%25BC%25D0%25B0">Milgram experiment</a> .  However, this can be easily discerned by putting the simulator in the tomograph and looking at which parts of the brain are currently active.  However, this is also a behavior, albeit at a lower level.  In the end, it all comes down to a very simple (I would even say too simple) criterion: we believe that a <i>person is in pain if he behaves the way we would behave if we were in pain</i> . <br><br><h3>  How to understand that the other person is a person? </h3><br>  There is such a famous thought experiment called " <a href="https://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B8%25D0%25BB%25D0%25BE%25D1%2581%25D0%25BE%25D1%2584%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B7%25D0%25BE%25D0%25BC%25D0%25B1%25D0%25B8">philosophical zombie</a> ."  Its essence is simple: let's imagine something that behaves absolutely indistinguishable from a person from the point of view of an external observer, but at the same time is completely devoid of subjective experience.  If you prick him with a needle, it will say ‚Äúah‚Äù (or something less censorious), withdraw his arm, his corresponding facial muscles will contract, and even the tomograph will not be able to catch him.  But at the same time inside it does not feel anything.  He simply does not have this "inside."  Such a thing is called a ‚Äúphilosophical zombie‚Äù, and the essence of the experiment is that the existence of this hypothetical creature does not lead to obvious contradictions.  That is, it seems to be <i>possible</i> . <br><br>  Returning to the previous question, we really do not have any reliable opportunity to find out if another person is experiencing pain as a qualification.  We can listen to our mirror neurons, or, if this is not enough for our sophisticated minds, use the Occam's razor.  Saying that a ‚Äúphilosophical zombie‚Äù is a redundant entity.  It is much more logical to assume that all people are more or less the same than to assume the opposite, without any intelligible grounds for this.  However, Occam's principle is still a heuristic, and not an immutable law.  Entities that yesterday seemed superfluous to us today enter our house, opening the door with their foot.  If you do not agree, try to imagine how you would explain quantum mechanics to Democritus. <br><br><h3>  Do the androids have electric reins? </h3><br>  In the first comment to the post, about which I wrote above, the user <a href="https://habr.com/users/neocode/" class="user_link">NeoCode</a> expressed the following thought: <br><blockquote>  First of all, a ‚Äústrong AI‚Äù is not a living being and will not be able to experience pain or loneliness, simply because its nature is initially different, it does not have millions of years of evolution and natural selection, and therefore - low-level biological mechanisms and programs.  He will not even have the instinct of self-preservation, unless specifically programmed of course.  But in its pure form - will not;  it is possible to create an AI that is conscious and capable of solving complex tasks and learning, while not possessing a self-preservation instinct at all. <br>  This is an important point, which many for some reason do not understand, by default ‚Äúhumanizing‚Äù artificial intelligence. </blockquote><br>  In this, of course, there is a rational grain.  It is impossible to mindlessly transfer human qualities to a hypothetical AI.  In this regard, 95% of science fiction and 99.9% of the inhabitants are hopelessly naive.  But I want to say the following: you should not also mindlessly deprive AI of human qualities.  Some of them may turn out to be more fundamental than might have been supposed. <br><br>  Consider such a hypothetical situation: in order for the AI ‚Äã‚Äãto do what we need, and not what it wants (and it may well be more ‚Äúinteresting‚Äù for it to solve the sudoku than to engage in our project, which is about to be overdue) we add to it a special input signal - such that the main goal of the AI, the main component of its <a href="https://ru.wikipedia.org/wiki/%25D0%25A6%25D0%25B5%25D0%25BB%25D0%25B5%25D0%25B2%25D0%25B0%25D1%258F_%25D1%2584%25D1%2583%25D0%25BD%25D0%25BA%25D1%2586%25D0%25B8%25D1%258F">objective function</a> will be to minimize this signal.  Accordingly, when the deadline approaches, we press the pedal, the wiring is energized, and the AI ‚Äã‚Äãbegins to actively think about how to remove this voltage.  And the more active, the harder we press.  And since the pressure of the foot on the pedal is associated with an unfinished project, the AI ‚Äã‚Äãhas no choice but to complete this project.  Well, or to hack a military drone flying past, so that it will blow out the brains to the pedal operator.  Who knows, this strong AI. <br><br>  However, I digress.  Tell me, does this hypothetical signal accidentally remind you of anything?  Is it possible in this case to say that the AI ‚Äã‚Äãis in pain? <br><br><h3>  Man to man is a wolf, and zombie is a zombie zombie </h3><br>  In general, how can we understand whether an AI is experiencing qualia?  In the case of the philosophical zombies, Occam's razor and empathy were on our side.  However, AI is philosophical, but not zombie.  That is, it makes sense to raise this question about him, but he is not human-like.  Therefore, we cannot say that he feels something, just by analogy with ourselves. <br><br>  Someone (as, for example, the author of the comment quoted above) will say that we can safely say the opposite.  That there is no reason to believe that the AI ‚Äã‚Äãreally is in pain, and if not, then we will not believe so.  To this I would answer as follows: Imagine that a certain thinking, feeling, but completely inhuman being created you.  What reasons would he have for believing that you are experiencing qualia?  Unless, of course, this being does not have the transcendental ability to really get into someone else's head;  allegorically speaking, <a href="https://ru.wikipedia.org/wiki/%25D0%25A7%25D1%2582%25D0%25BE_%25D0%25B7%25D0%25BD%25D0%25B0%25D1%2587%25D0%25B8%25D1%2582_%25D0%25B1%25D1%258B%25D1%2582%25D1%258C_%25D0%25BB%25D0%25B5%25D1%2582%25D1%2583%25D1%2587%25D0%25B5%25D0%25B9_%25D0%25BC%25D1%258B%25D1%2588%25D1%258C%25D1%258E%253F">to become a bat</a> .  However, this is already beyond the scope of our analogy and goes into the category of talking about the divine. <br><br><h3>  Anthropic chauvinism </h3><br>  In all the previous paragraphs we talked about pain.  Pain is one of, say, the most characteristic varieties of human sensations.  But who said that everything is limited to man? <br><br>  If a hypothetical alien mind (in general, even unimportant, artificial, alien, or some other) is in principle capable of experiencing qualia, they may turn out to be fundamentally different from those that a person experiences.  A grotesque example: the tiny AI comes to the father scientist and says that he is experiencing <i>sybkdschrtrb</i> .  Is it good or bad?  Should give him candy as a reward, pat on the head for consolation, or even pour in an electric belt, because there is nothing here? <br><br>  In all the previous paragraphs, I asked questions to which there is no answer, and in fact did not state anything.  Now I venture to say: <b>human ethics are not ready to make the inhuman mind their full subject</b> .  We can talk about "ethical issues of AI", considering artificial intelligence as a means by which some people do well or badly to other people.  But if we try to think about ethical issues from the point of view of AI, we simply will not succeed.  Not that we could not get an answer - we do not even possess the appropriate conceptual apparatus in order to correctly put the question.  Perhaps we do not possess <i>yet</i> .  Or maybe this is a fundamentally unavoidable gap.  And artificial intelligence will have to develop its own ethics, if, of course, it is even needed. <br><br>  And then decide whether it should consider a person as a subject, hehe. </div><p>Source: <a href="https://habr.com/ru/post/422917/">https://habr.com/ru/post/422917/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422903/index.html">How and why we wrote a highly loaded scalable service for 1C: Enterprises: Java, PostgreSQL, Hazelcast</a></li>
<li><a href="../422905/index.html">But you say Ceph ... is it really good?</a></li>
<li><a href="../422907/index.html">Quick Reference Guide for 2018 Robot Vacuum Cleaners</a></li>
<li><a href="../422909/index.html">10 most popular videos of retro reports of the Festival 404</a></li>
<li><a href="../422915/index.html">I am looking for a senior without an office and cookies: how are we organized the search for employees 100% remote</a></li>
<li><a href="../422919/index.html">Bike SIPs and cloud telephony talk to each other</a></li>
<li><a href="../422921/index.html">From Kotlin to Goblin: how TechTrain passed</a></li>
<li><a href="../422923/index.html">How to celebrate the day of the programmer, not decorating office ficus with zeros and units</a></li>
<li><a href="../422925/index.html">Interview with Godfrey Chan, RubyRussia Conference Speaker</a></li>
<li><a href="../422929/index.html">Yandex mail [was] unavailable for about an hour at 12:16 MSK</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>