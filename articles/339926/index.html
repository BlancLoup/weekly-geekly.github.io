<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A practical guide to analyzing application performance</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="You probably already know that several months after the conferences we post videos of all the reports . And for the very best, as in the case of Sasha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A practical guide to analyzing application performance</h1><div class="post__text post__text-html js-mediator-article">  You probably already know that several months after the conferences we post <a href="https://www.youtube.com/channel/UCNPwMPudMEw-gnAT4zh_UZg/playlists">videos of all the reports</a> .  And for the very best, as in the case of Sasha's <a href="https://habrahabr.ru/users/goldshtn/" class="user_link">goldshtn</a> Goldstein <a href="https://habrahabr.ru/users/goldshtn/" class="user_link">keynout</a> , we are also preparing transcripts - so that those who do not like the video format can also join. <br><br>  Sasha talks about the methods and tools for analyzing the performance of applications, including those developed by him. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/xg4xcv76OsY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The article is based on Sasha‚Äôs speech at the DotNext 2017 Piter conference.  Sasha works as the technical director of the Israeli training and consulting company Sela and knows firsthand how to conduct a performance analysis.  How to start it better than complete it, what tools should be used, and what to avoid, read under the cut. <br><a name="habracut"></a><br><h2>  Performance Analysis: Step by Step </h2><br>  Let's start with the performance analysis framework.  The following plan is used by developers, system administrators, any technical specialists: <br><br><ol><li>  Getting a description of the problem.  It sounds simpler than it actually is, because clients often describe problems very poorly. </li><li>  Building a system diagram.  This makes it possible to realize what parts the problem consists of. </li><li>  Quick performance check.  This allows you to understand what works in the system, what is overloaded, etc. </li><li>  Understanding which component is causing the problem.  At this stage, we still do not know what the problem is, but we already understand where it is, so there is already progress. </li><li>  Detailed analysis.  This stage takes the most time. </li><li>  Search for the root of the problem. </li><li>  Elimination of the problem. </li><li>  Check.  At this stage, you need to check whether the problem is fixed and whether the system is now working correctly. </li><li>  Documenting the entire analysis process.  This is necessary in order to know exactly what you have done, which tools worked for you, and which tools did not.  This makes it possible not to repeat the same mistakes in the future. </li></ol><br><h2>  Problem Description: Why is it sometimes so hard to get? </h2><br>  It is much more difficult to get an exact description of the problem from the client than it seems at first glance. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/25a/2b7/ac7/25a2b7ac763e7a7ec4b24c806b4eeef3.jpg"><br><br>  A client can deal with a problem like: <br><br>  <i>‚ÄúThe application is working too SLOWLY.</i>  <i>Users can not say exactly when this happens, but this is bad.</i>  <i>Can you see it? ‚Äù</i> <br><br>  Or <br><br>  <i>‚ÄúWe have a budget for productivity work, will you be able to look at our work environment for two days and find a problem?‚Äù</i> <br><br>  Of course, you can try, but it is unlikely to be a very good use of the allocated budget.  The problem, formulated more precisely, may look like this: <br><br>  <i>‚ÄúStarting from 4:25 in the morning, when accessing the ASP.NET site in 95% of cases, there is a delay of 1,400 ms (the normal response time is 60 ms).</i>  <i>The delay is observed regardless of geographic location and does not decrease.</i>  <i>We turned on automatic scaling, but that didn't help. ‚Äù</i> <br><br>  Such a description of the problem is much more accurate, because I see the symptoms and understand where to look, and I know what can be considered a solution to the problem (reducing the delay to 60 ms). <br><br>  Sometimes it is much more difficult to find out what exactly is required by the client than it seems at first glance. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b7/a56/359/5b7a5635979988b2be2bf6f190f7bafe.jpg"><br><br>  Each company has its own performance requirements, which, unfortunately, are not always formulated.  For example, they may be: <br><br><ul><li>  90% of all full-text queries should be completed no later than 200 ms; <br></li><li>  99% of all full-text queries should be completed no later than 600 ms; <br></li><li>  100% of all full-text queries should be completed no later than 2000 ms. <br></li></ul><br>  When there are such requirements, it remains only to test the system for compliance with them and understand how to solve the problem.  But it is important to understand that the requirements are not taken from nowhere, they must always be consistent with business goals.  With well-defined requirements, you can always track the statistics in the APM-solution or in other ways and receive notifications when something goes wrong. <br><br><h2>  Anti-patterns: how not to perform analysis </h2><br>  Before diving into the analysis methods that give results, I want to talk a little about how not to analyze the problem.  So you definitely shouldn't: <br><br><ul><li>  Make assumptions; <br></li><li>  Trust "instincts" and absurd beliefs; <br></li><li>  Find a solution to a problem only where it is easiest to find (this behavior is also called the ‚Äústreet lamp effect.‚Äù He was shown by a drunkard from a famous anecdote who was looking for keys not where he lost them, but where it was light); <br></li><li>  Use random tools; <br></li><li>  Shift responsibility on tools. <br></li></ul><br>  I will give an example of one unsuccessful analysis, which was never completed.  My task was to understand why sometimes customers encounter significant delays when saving and loading documents in the project management system.  The system was connected to NetApp via SMB on the local network, and my task was to find out the network latency and latency that could have occurred when working with the data warehouse. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8dc/c57/785/8dcc577853ab9a0f518e80c833792743.jpg"><br><br>  I had tools for monitoring WCF and application server performance, I had a sniffer for network traffic, but I did not have access to NetApp storage.  After a series of tests, I found out that the average response speed was 11 ms, but within 24 hours some cases of a 1200 ms delay were observed.  I lacked information about what was happening on the part of NetApp, and it was necessary to obtain performance testing data. <br><br>  From the client, I was able to get only the information that the response speed of the data storage system could not be less than 5 ms.  To my question about what this figure is: the average or peak delay, I received the answer: <i>this is the maximum average value for 60 seconds.</i>  I still do not know what this value is, and I believe that you also do not know.  He could take the average value every second and then the maximum value from all averages, or perhaps take the maximum value every second and then the average from the maximum ... <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4e/7df/ac6/c4e7dfac68ab91ace88d568f40c4129c.jpg"><br><br>  After that, I found in the documentation for NetApp performance counters that are considered valid for this storage system.  These are average data per second, not per minute.  I asked the client to provide me with this data, but I was refused.  This attempt analysis ended. <br><br>  For me, this is a classic case of how performance analysis cannot be done.  I did my best to get as much information as possible and <i>not to rely on assumptions</i> , but I did not succeed because of the lack of mutual understanding with the client.  And this is a good example of why you can not rely on assumptions and absurd beliefs. <br><br>  Now about the unsuccessful use of tools. <br><br>  Sometimes experts think that if they bought an expensive instrument, then they are simply obliged to use it for all analysis options.  I will give a classic example of using the wrong tool for analysis. <br><br>  Let's run the Visual Studio profiling tools in CPU sampling mode to test the performance of the crawler.  A robot can do some things that do not burden the processor, and if we do this test, we can get something like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/721/123/8e6/7211238e61475b0fbe48c85d13a0db85.jpg"><br><br>  From this it follows that it is necessary to improve the performance of System.Console.WriteLine, since this method slows down the application.  However, the search robot can simply wait for the receipt of network data, it has nothing to do with the processor.  Therefore, you can never choose a tool for analysis on the principle "simply because we bought it, and we need to recapture its cost." <br><br><h2>  Finding the source of the problem: USE method </h2><br>  Sometimes you just don‚Äôt know what to look for, in which case I suggest a methodology that is often used by engineers all over the world.  This is the USE (Utilization, Saturation, Errors) method, which is handled in several steps: <br><br><ol><li>  At the first stage, it is necessary to construct a system diagram, including all the hardware and software resources and the connections between them; </li><li>  Then, for each resource and each link, you need to define three parameters: Utilization ‚Äî use (how much the resource is loaded), Saturation ‚Äî saturation (whether there is a queue to use this resource), and Errors ‚Äî whether errors occur. </li><li>  If there are problems with any parameter, they need to be solved. </li></ol><br>  Here is what the USE method might look like for hardware and software resources: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb8/1e7/ea7/bb81e7ea7f80f39badb8a3301240fde2.jpg"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/0fe/adc/114/0feadc11478a1d73c1367e9c4d7704ca.jpg"><br><br>  You must have a checklist, according to which you systematically test each of the components to get the big picture. <br><br>  Here is the checklist for Windows systems: <br><br><table><tbody><tr><td>  <b>Component</b> <br></td><td>  <b>Type of</b> <br></td><td>  <b>Analysis Tools or Tracked Parameters</b> <br></td></tr><tr><td>  <nobr>CPU</nobr> <br></td><td>  <nobr>Loading</nobr> <br></td><td>  Processor (_Total) \% ProcessorTime,% User Time Process (My App) \% ProcessorTime <br></td></tr><tr><td>  <nobr>CPU</nobr> <br></td><td>  <nobr>Saturation</nobr> <br></td><td>  System \ Processor Queue Length <br></td></tr><tr><td>  <nobr>CPU</nobr> <br></td><td>  <nobr>Errors</nobr> <br></td><td>  Intel Processor Diagnostic Tool (and others) <br></td></tr><tr><td>  <nobr>Memory</nobr> <br></td><td>  <nobr>Loading</nobr> <br></td><td>  Memory \ Available Mbytes <br>  Process \ Virtual Size, Private Bytes, Working Set <br>  .NET CLR Memory \ #Bytes in all Heaps <br>  VMMap, RAMMap <br></td></tr><tr><td>  <nobr>Memory</nobr> <br></td><td>  <nobr>Saturation</nobr> <br></td><td>  Memory \ Pages / sec <br></td></tr><tr><td>  <nobr>Memory</nobr> <br></td><td>  <nobr>Errors</nobr> <br></td><td>  Windows Memory Diagnostic Utility (and others) <br></td></tr><tr><td>  <nobr>Network</nobr> <br></td><td>  <nobr>Loading</nobr> <br></td><td>  Network Interface \ Bytes Received / sec, Bytes Sent / sec <br></td></tr><tr><td>  <nobr>Network</nobr> <br></td><td>  <nobr>Saturation</nobr> <br></td><td>  Network Interface \ Output Queue Length, Packets Outbound Discarded, Packets Received Discarded <br></td></tr><tr><td>  <nobr>Network</nobr> <br></td><td>  <nobr>Errors</nobr> <br></td><td>  Network Interface \ Packets Outbound Errors, Packets Received Errors <br></td></tr><tr><td> <nobr>Disk</nobr> <br></td><td>  <nobr>Loading</nobr> <br></td><td>  Physical Disc Disc Discs, Disc Ids, Disc Writes / sec <br></td></tr><tr><td>  <nobr>Disk</nobr> <br></td><td>  <nobr>Saturation</nobr> <br></td><td>  Physical Disc \ Current Disk Queue Length <br></td></tr><tr><td>  <nobr>Disk</nobr> <br></td><td>  <nobr>Errors</nobr> <br></td><td>  Chkdisk (and other tools) <br></td></tr><tr><td>  <nobr>application</nobr> <br></td><td>  <nobr>Errors</nobr> <br></td><td>  .NET CLR Exceptions \ # of Excepts Thrown / sec <br>  ASP.Net \ Error Events Raised <br></td></tr></tbody></table><br>  Most of this data can be obtained using the built-in Windows performance counters.  This check can be done very quickly, but it allows you to save a lot of time to focus on analyzing the problems found. <br><br>  To automate this process, you can use a variety of solutions: <br><br><ul><li>  Windows system monitor (Perfmon) - can collect logs of performance counters continuously or only when certain conditions are met. <br></li><li>  Typeperf - is able to generate a CSV file every second with performance counter values ‚Äã‚Äãthat are specified by the user. <br></li><li>  Third Party Solutions.  For example, if you are working with a cloud solution, then the provider will most likely provide access to a tool for monitoring processor, disk, network activity, etc. <br></li></ul><br><h2>  Performance analysis: what tools to use </h2><br>  Performance analysis tools can be divided into three categories: <br><br><ul><li>  Those that help determine how often this happens (counting).  For example, how many requests per second we get <br></li></ul><br><ul><li>  Those that help determine how long it takes (waiting time).  For example, how long does my ASP.NET requests take, how long does it take to switch between windows, etc. <br></li></ul><br><ul><li>  Those that help determine why this happens (stacks).  For example, where a certain condition occurs in the application source code <br></li></ul><br>  As a rule, the tools of the first category give a small overhead, when using tools to determine the waiting time, it is longer, and the tools of the third category lead to a significant overhead.  This is not surprising, since the latter provide much more information. <br><br>  When choosing tools, it is important to pay attention to five points: <br><br><ul><li>  Small overhead <br></li><li>  Accuracy (how much can you trust the results) <br></li><li>  Fast results (when you do not need to wait hours for data analysis) <br></li><li>  Invasiveness (Ability to run on operating systems) <br></li><li>  The ability to focus on a specific area (class, function, etc.) <br></li></ul><br><h2>  Remember the overhead! </h2><br>  Any observation can affect the state of the system, but some tools are stronger than others.  Therefore, before using any tool it is best to refer to the documentation.  As a rule, it indicates what can be expected from the use of the tool (for example, increasing the processor load by 5-10% under certain circumstances). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1d9/ac5/b53/1d9ac5b534a7937cb1f42fc98d22684b.jpg"><br><br>  If the documentation for the tool you are going to use does not say anything about the overhead, then you will have to test it yourself.  This should be done on a test system, measuring how much the performance drops. <br><br><h2>  Accuracy: a story with safe conditions </h2><br>  Perhaps, for those who do not work with Java, this will be news, but most CPU Java profilers that are used by developers give out incorrect data (VisualVM, jstack, YourKit, JProfiler ...).  They use the GetAllStackTraces documented by the JVMTI API.  It gives a sample of what each thread in the system does when you call the GetAllStackTraces function. <br><br>  The advantage of using it is cross-platform, but there is a significant drawback.  You only get the sample stream when all the threads are in safe conditions.  That is, if you request a stack trace, you do not receive it from the current moment, but from some point later, when the thread decides that it wants to transfer its stack trace.  As a result, you get results that have no relation to the real state of affairs. <br><br>  In the screenshot below, you can see the data from a scientific report on the accuracy of Java profilers. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/afe/c44/fc4/afec44fc4991960869d6531f893f8323.jpg"><br><br>  On the graph, you can see the data of four profilers on which of the methods on a particular benchmark was the hottest.  Two of the four profilers (right and left) determined that this was the jj_scan_token method, the third profiler determined that it was the getPositionFromParent method, and the fourth was the DefaultNameStep.evaluate.  That is, four profilers gave completely different readings and completely different methods.  And here it‚Äôs not the profilers, but the API that they use to get the results from the target process. <br><br>  That is why, if you use a new tool, you must test it in different conditions (when the processor is actively working, at rest or reading data from the disk).  And you need to make sure that the profiler provides the correct data, and then look at the overhead.  If the data is incorrect, then this profiler, of course, should not be used. <br><br><h2>  Results: how fast will you get them? </h2><br>  Here I want to give an example of instructions for profiling. NET Core on Linux. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e0/256/33c/0e025633c6f1f5518c7c933d7c370249.jpg"><br><br>  We will not consider it in detail, we will address only some points.  It begins with the need to set up an environment variable, which I, for example, have problems with.  Well, let's say you did it.  The instruction ends with the need to take a zip file generated as a result of all these steps, copy it to a Windows machine and open it using PerfView.  And only then can you analyze the data.  It sounds ridiculous, is not it?  Perform an analysis on Linux, and then open it on Windows ... <br><br>  Here is an alternative solution to the same problem.  These scripts do not work very well, but at least they provide an opportunity to get results on Linux. <br><br>  <i>$ ./dotnet-mapgen.py generate 4118</i> <i><br></i>  <i>$ ./dotnet-mapgen.py merge 4118</i> <i><br></i>  <i># perf record -p 4118 -F 97 -g</i> <i><br></i>  <i># perf script |</i>  <i>./stackcollapse-perf.pl&gt; stacks</i> <i><br></i>  <i>$ ./flamegraph.pl stacks&gt; stacks.svg</i> <br><br>  As a result, you get a visualization called a flame graph.  I will focus on it in more detail, since many Windows and .NET developers are not yet familiar with it. <br><br>  This method allows you to visualize different stack traces, for example, where an application often accesses a disk, when there is a heavy processor load, etc.  When you have many different stacks, a flame graph is a good way to visualize them instead of reading a lot of text.  Flame graph turns thousands of stack trace pages into one interactive graph. <br><br>  Each rectangle in the graph is a function.  Colors are selected in a random order, so they can be ignored.  The Y axis is the depth of the stack, that is, if one function called another, it will be located above it, and will be shown above in the graph.  The X axis is sorted stacks (not time).  Having such a schedule, it is very easy to bring exactly the area that you are interested. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/071/511/9bf/0715119bf095b7eeaa63669daa7371e6.jpg"><br><br><h2>  Invasiveness: how to do no harm </h2><br>  Invasive profilers can have a bad effect on performance, reliability, and system response because they are too ‚Äúheavy‚Äù.  For example, when using the Visual Studio profiler in instrumentation mode and IntelliTrace, the application is recompiled and launched with additional markers.  Such a tool cannot be used in a working environment. <br><br>  Another example is the CLR Profiling API, which is still used in some tools.  It is based on the implementation of the DLL in the target process.  This may be acceptable when developing, but in a production environment it can be problematic to embed a library in a running process. <br><br>  The Linux extreme example is the Linux SystemTap, LTTng, and SysDig trace frameworks that require the installation of a custom kernel module in the system.  Yes, you can trust these guys, but it's still a bit suspicious that you need to load something new into the kernel to run the performance measurement tool. <br><br>  Fortunately, Windows has a fairly lightweight Event Tracing framework (Windows), which you may have heard about.  With this framework, you can profile the processor, determine where the garbage collections are, which files the application gets access to, where it accesses the disk, etc. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55a/b66/1f4/55ab661f4c7692a470be0682a3049a92.jpg"><br><br>  But despite the fact that ETW is not too invasive, the speed of getting results from it can sometimes be a problem.  Below I give an example from a log file generated using PerfView: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/60a/eae/e84/60aeaee84a0ff58834c5f09f774661cb.jpg"><br><br>  As you can see, I collected information about the use of the processor for 10 seconds, and a total of 15 MB of data.  Therefore, it is unlikely that you will be able to test the system using Event Tracing for hours - the amount of data will be too large.  In addition, the CLR Rundown took 12.7 seconds to complete, then it took some time to convert and open the data (I highlighted the time in red).  That is, to get the data collected within 10 seconds, you need to spend half a minute to process and open them. <br><br>  Despite the fact that this is considered a fairly good result, I do not really like it.  Therefore, I would rather tell you about the tools that I wrote myself and without which I simply cannot live. <br><br>  Etrace (https://github.com/goldshtn/etrace) is the open source command line interface for ETW.  You can tell him what events you want to see, and he will give information about them in real time.  As soon as an event occurs, it can be seen on the command line. <br><br> <i><br></i>  <i>&gt; etrace --help</i> <i><br></i>  <i>...</i> <i><br></i>  <i>Examples:</i> <i><br></i>  <i>etrace --clr GC --event GC / AllocationTick</i> <i><br></i>  <i>etrace --kernel Process, Thread, FileIO, FileIOInit --event File / Create</i> <i><br></i>  <i>etrace --file trace.etl --stats</i> <i><br></i>  <i>etrace --clr GC --event GC / Start --field PID, TID, Reason [12], Type</i> <i><br></i>  <i>etrace --kernel Process --event Process / start --where ImageFileName = myapp</i> <i><br></i>  <i>etrace --clr GC --event GC / Start --duration 60</i> <i><br></i>  <i>etrace --other Microsoft-Windows-Win32k --event QueuePostMessage</i> <i><br></i>  <i>etrace --list CLR, Kernel</i> <br><br>  For example, you run etrace and say: I want GC events.  As soon as such an event starts, I want to see its type, reason, process, etc. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad0/3f0/068/ad03f00687cb44372509afa5dcae5fb6.jpg"><br><br>  Another tool that I wrote myself and I want to present to you is <a href="https://github.com/goldshtn/livestacks">LiveStacks</a> .  He is also related to ETW.  LiveStacks collects stack traces for interesting events (where are garbage collections, where there is a load on the processor, which files the application gets access to, where it accesses the disk, etc.).  The main difference between LiveStacks and other similar tools is to display information in real time.  You do not need to wait until data processing is complete to find out what processes are taking place. <br><br>  Here is an example of the processor profiling mode that is used by default.  LiveStacks looks at the process in Visual Studio and shows the call stack in a process that requires the most CPU time. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb5/ef5/229/bb5ef5229079c4c56d00ec110851e39d.jpg"><br><br>  Another example: when asked, ‚Äú <i>show me where garbage collection starts, which call stack caused the garbage collection to run in a specific process or across the entire system</i> ‚Äù LiveStacks gives you a call stack in real time with information about where garbage collection takes place: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4c/fe2/518/c4cfe251843d97c53e08b7a0582e91b2.jpg"><br><br>  From the results, LiveStacks can generate flame graphs by visualizing the call stacks that were displayed in the console. <br><br>  <i>&gt; LiveStacks -P JackCompiler -f&gt; stacks.txt</i> <i><br></i>  <i>ÀÜC</i> <i><br></i>  <i>&gt; perl flamegraph.pl stacks.txt&gt; stacks.svg</i> <br><br>  I use these tools because they give me the opportunity to get results quickly, without waiting for data processing. <br><br><h2>  How to build systems for effective instrumentation </h2><br>  When you build a system, library, architecture for your new project, you should think in advance about some things that in the future will simplify the performance analysis: <br><br><ol><li>  Make sure that the call stack for interesting events (disk access, garbage collection, etc.) is easy to get; <br></li><li>  Implement static code instrumentation (tracepoints) so that people can get real-time information about the processes; <br></li><li>  Take care that important processes can be enabled without an overhead projector, without the need to restart the system, but simply by setting up at the log level; <br></li><li>  Add debug points (probes) for dynamic instrumentation; <br></li><li>  Create examples and a documentation file so that people performing performance analysis do not need to spend too much time understanding how your system works. <br></li></ol><br>  An example of a project with very good instrumentation tools is .NET on Windows, which has been used by many people for more than 10 years.  There are ETW events that I mentioned above, there is an opportunity to capture the call stacks of interesting events and convert them into function names.  And all this is included by default! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7df/670/92e/7df67092ecae0fd97a95f0f6328b206d.jpg"><br><br>  Making a project with such instrumentation tools is not easy.  Say, if you look at .NET Core 2.0 for Linux, everything is not so rosy.  And not at all because there are no good tools for performance analysis in Linux, but because it is rather difficult to build a platform that would be easy to profile and debug. <br><br>  Do you want to know what is wrong with .NET Core 1.0 for Linux?  The platform has events, but it is impossible to receive call stacks, you can only find out that an event has occurred (which is much less informative).  Another example: to convert call stacks to get the names of functions, you need to do a lot of preliminary actions.  That is why the documentation proposes to take a ZIP file and open it in Windows (I gave this example above). <br><br>  It's all about priorities.  If you think that the possibility of performing a performance analysis is an important requirement for the system you are developing, you will not release something like this.  Although, of course, this is just my point of view. <br><br><h2>  Be careful with the statistics! </h2><br>  Statistics and tools often deceive us.  This is what you should always remember in this regard: <br><br><ol><li>  Average values ‚Äã‚Äãare meaningless. <br></li><li>  Medians are meaningless. <br></li><li>  Percentiles and distributions are useful only if you know exactly what you are doing. <br></li><li>  Use good visualization for your data. <br></li><li>  Beware of the phenomenon of coordinated omission. <br></li></ol><br>  For example, someone tells you that "the average response time of the system is 29 ms."  What can this mean?  For example, the fact that, with an average response time of 29 ms, the worst value is 50 ms or 60 ms, and the best is close to zero.  Or it may mean that for most cases the response time is 10 ms, but there is a mode in which the system is much slower (with a response time of up to 250 ms), and the average value is also 29 ms. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed7/29a/ac9/ed729aac98e73fa1dc787fcd810e9ca9.png"><br><br>  You can see that the two graphs showing these two cases with the same average response time are completely different.  In order to understand the real picture of what is happening, it is not enough to look at the numbers, you need to look at the real distribution. <br><br>  There is a great <a href="https://www.autodeskresearch.com/publications/samestats">study</a> I found on the web.  It demonstrates why you can never trust only summary statistics and always need to visualize the data. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/40d/d68/505/40dd68505301bd97fd0fc91122ac9017.png"><br><br>  The authors visualized 13 data sets with the same summary statistics (the same mean x / y, one standard deviation x / y, and the same cross-correlation).  However, these datasets look completely different.  That is, when you look only at numbers, it means nothing.  You do not see the "form" of your data when you look only at the numbers. <br><br>  <a href="https://github.com/dotnet/BenchmarkDotNet">BenchmarkDotNet</a> is the library that many of you use.  It is simply gorgeous, but does not show the ‚Äúform‚Äù of your data (at least, by default).  When you run it in the console, it gives out a lot of numbers: averages, standard deviations, confidence intervals, quartiles, but not the "form" of the data.  And this is very important.  For some types of analysis, the inability to see the "form" of the data means that you miss important things. <br><br>  Here is an example of what you can skip by relying on averages.  This graph shows the delay time.  In 99% of cases, the response time is just under 200 ms, but periodic stuttering can be observed ‚Äî too long delays (even up to 10 ms) occurring over a short period of time. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/61f/81a/60a/61f81a60ae1a0a4903560dccdaf6efe5.jpg"><br><br>  And in most cases, when performing performance analysis, they are asked to pay attention to stuttering - to the fact that they are above average values, to problems that users sometimes face.  In order to identify them, it is necessary to visualize all the data points, as in the graph above, or to build the distribution, as in the graph below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/205/605/9c4/2056059c4544f48dde20599817facd07.jpg"><br><br>  Another common mistake people make with percentiles is to perform mathematical operations with them.  For example, it is impossible to average percentile, as my client did, whose letter you can read below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dfa/eb5/9f6/dfaeb59f62433dd4133ee364e8658982.jpg"><br><br>  Imagine that you have two servers.  For server A, the delay time is 90 ms for 90% of the time; for Server B, the delay time is 90 ms for 90% of the time. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/651/0a2/3e6/6510a23e68d430e093892e673f22bc64.jpg"><br><br>  It is important to understand that you cannot average these values.  It is not true that 90% of requests respond in less than 57 ms.  In fact, 90% of requests respond in less than 68 ms. <br><br>  Therefore, interest, quartiles, etc. can never be averaged.  We must always look at the data and their distribution. <br><br>  Sometimes you can hear something like: ‚ÄúWho cares about the 99th percentile?  None of my users can even see this! ‚ÄùI will explain why this is important on the example page of Amazon.com.  She made 328 requests.  Assuming that all requests are independent, what is the probability that at least one of them was in the 99th percentile? <br><br>  <i>P = 1 - 0.99 <sup>328</sup> ~ 96%</i> <br><br>  The answer is 96%.  Therefore, it is very likely that when you go to the Amazon.com page, you will receive at least one request in the 99th percentile.  And if your users get access to a system that is relatively complex, then the likelihood that the worst scenario will happen to them is very high. <br><br><h2>  Use serious tools for large systems! </h2><br>  The last thing I would like to mention in this article is the need to use special tools for systems consisting of a large number of machines.  This is what these tools should be able to do: <br><ul><li>        ; <br></li><li>       ID ; <br></li><li>     ; <br></li><li>      , ,    . <br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are a lot of such tools. </font><font style="vertical-align: inherit;">One example of an application performance monitoring tool is </font></font><a href="https://github.com/Netflix/vector"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vector</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from Netflix. </font><font style="vertical-align: inherit;">On the information panel you can see the summary statistics, but at the same time, at any time, you can click on a specific instance and, say, view the processor flame graph for this instance or the use of disk resources. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/17b/dd9/f41/17bdd9f413f6bf67a49098ab5ed3c16a.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another example is the </font></font><a href="https://newrelic.com/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">New Relic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> AMP solution </font><font style="vertical-align: inherit;">, which also works with .NET. </font><font style="vertical-align: inherit;">It shows you requests in the system and where you spend time servicing these requests. </font><font style="vertical-align: inherit;">And if you want, you can switch to a specific request, to a specific user session.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> When the work is completed: do not forget to document! </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">After the performance review is complete, do not neglect the opportunity to sit down and document what has been done. </font><font style="vertical-align: inherit;">What exactly is worth doing?</font></font><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Document the steps that were taken to find, diagnose, solve, and verify the problem. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What tools did you use? </font><font style="vertical-align: inherit;">How can they be improved? </font><font style="vertical-align: inherit;">What didn't work?</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> What prevented you from doing research? </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Can you add monitoring tools for system administrators? </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Can you add tools for those who will analyze the system after you? </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If this problem occurs again, how can you automate its solution? </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Documenting the process will help you and the entire team avoid the same mistakes in the future, as well as possibly automate repetitive tasks. </font></font></li></ol><br><hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sasha Goldstein is a .NET expert, a performance guru and a constant speaker at our conferences. </font><font style="vertical-align: inherit;">On the two-day DotNext, which will be held November 12-13 in Moscow, he will give a hardcore report </font></font><a href="https://dotnext-moscow.ru/2017/msk/talks/2dfoltply8kscqeoa6444g/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Debugging and Profiling. NET Core Apps on Linux</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">And on the eve of the conference, he </font></font><a href="https://dotnext-moscow.ru/2017/msk/trainings/m4aetwwkioiwk4yaaouaq/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">will hold a separate training on</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Production Performance and Troubleshooting of .NET Applications. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Of the other reports, these three will probably also seem interesting to you:</font></font><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">another hardcore performance from Karel Zikmund from Microsoft ( </font></font><a href="https://dotnext-moscow.ru/2017/msk/talks/3hcuoycrw4egcs0mkewoio/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">High performance Networking in .NET Core</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">typical performance testing problems and possible approaches to solving them in the speech of Andrey Akinshin from JetBrains ( </font></font><a href="https://dotnext-moscow.ru/2017/msk/talks/6a4afxs2sqmwws0yuoc06s/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's talk about performance testing)</font></font></a> <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">serious talk about high-performance code in the report by Federico Lois from Corvalius ( </font></font><a href="https://dotnext-moscow.ru/2017/msk/talks/3dzbwqxenm6eqkai4giygw/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Patterns for high-performance C #: from algorithm to low-level techniques)</font></font></a> <br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You can view the entire conference program, get virtually acquainted with the speakers and purchase tickets on </font></font><a href="https://dotnext-moscow.ru/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the event website</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></div><p>Source: <a href="https://habr.com/ru/post/339926/">https://habr.com/ru/post/339926/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../339914/index.html">Jupyter Widgets for implementing the Turing UI machine</a></li>
<li><a href="../339916/index.html">SLA philosophy: what is escalation and why is it needed?</a></li>
<li><a href="../339918/index.html">How to gather a chat chat bot from scrap materials in a day and a half</a></li>
<li><a href="../339920/index.html">Zabbix conference 2017: how was the second day</a></li>
<li><a href="../339924/index.html">Check Point R80.10 API. Management through CLI, scripts and not only</a></li>
<li><a href="../339928/index.html">How to maintain a Telegram channel with 20,000 subscribers? Interview with the creator of All-in-One Person</a></li>
<li><a href="../339930/index.html">Development for Sailfish OS: displaying graphs using D3.js and QML Canvas</a></li>
<li><a href="../339932/index.html">Development for Sailfish OS: working with maps and geolocation</a></li>
<li><a href="../339936/index.html">We are looking for treasures in the source code Aladdin</a></li>
<li><a href="../339938/index.html">We play APK golf. Reduce the size of Android APK files by 99.9%</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>