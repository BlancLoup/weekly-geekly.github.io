<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Top 10 universities in the field of speech technology and artificial intelligence</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Over the past few years, interest in speech interfaces has revived in Russia. The western scientific tradition, unlike the Russian one, has a continuo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Top 10 universities in the field of speech technology and artificial intelligence</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage/a02170d2/d5a6f1de/33608a5d/acd5ca1e.png"><br><br>  Over the past few years, interest in speech interfaces has revived in Russia.  The western scientific tradition, unlike the Russian one, has a <i>continuous</i> experience of more than half a century in this direction. <br>  Our review is devoted to leading universities that provide education in the field of speech technologies - automatic speech processing, voice interfaces, biophysics, artificial intelligence, neural networks, etc. <br><a name="habracut"></a><br><h6>  At the end of the list, a few words describe the situation with the educational market of Russia in the field of speech technologies and two specialized departments at MIPT and ITMO. </h6><br><br><h4>  Harvard University - Massachusetts Institute of Technology <br>  Speech and Hearing Bioscience and Technology (SHBT) </h4><br> <a href="http://web.mit.edu/shbt/index.html"><img src="https://habrastorage.org/storage/918b7f05/e6a2aaaa/a3d4cf4d/cc5d6733.png"></a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>‚ÄúA strange but generally accepted fact - an idea, an emotion, a signal, a song can travel from the head of one person to the head of another, and this movement depends on an eerily complex, extremely exciting chain reaction known as human communication.</i>  <i>In the program of our university, we study every link in this chain, at every level of knowledge, from biochemistry to understanding. ‚Äù</i> <br><br>  Since 1992, about 50 students from 60 different departments at Harvard University, Massachusetts Institute of Technology, Boston University, and Harvard Training Hospitals are enrolled at SHBT each year. <br><br>  The main research interests of SHBT: <br><ul><li>  Fundamental studies of speech apparatus and speech functions. </li><li>  Clinical studies of human voice and speech abnormalities. </li><li>  Mechanics, biophysics, physiology and / or molecular biology of the middle and inner ear. </li><li>  Acquired or congenital abnormalities of the mechanisms of hearing. </li><li>  Neurophysiological or modeling approaches in the study of nerve cells and schemes that are the basis of auditory processing. </li><li>  Neurovisual studies of the mechanisms of tinnitus. </li><li>  Cognitive neurobiology of language signal processing. </li><li>  Design, development and improvement of hardware and software systems for hearing aids, ear implants, vestibular prostheses or automatic speech recognition algorithms. </li></ul><br>  Candidates for SHBT must have a bachelor's degree in physics, biology, psychology, linguistics, communication sciences, engineering and computer science, and have extensive analytical skills. <br><br><h5>  reference </h5><br>  <b>Institution</b> : Harvard-MIT Division of Health Sciences and Technology <br>  <b>Direction</b> : Program in Speech and Hearing Bioscience and Technology <br>  <b>Faculty</b> : Speech and Hearing Bioscience and Technology <br>  <b>Website</b> : <a href="http://web.mit.edu/shbt">web.mit.edu/shbt</a> <br>  <b>Disciplines</b> : Acoustical Signal Processing, Engineering Acoustics, Medical / Bioacoustics, Musical Acoustics, Physical Acoustics, Psychological Acoustics, Speech, Animal Bioacoustics <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/Harvard">www.youtube.com/Harvard</a> , <a href="http://www.youtube.com/MIT">www.youtube.com/MIT</a> <br>  <b>Address</b> : E25-518, 77 Massachusetts Avenue, Cambridge, MA 02139, USA [ <a href="http://goo.gl/gXObU">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/fOuAX">goo.gl/fOuAX</a> <br>  <b>Contacts</b> : 617-2537498 (fax), shbt-admissions@mit.edu <br><br><br><h4>  Stanford School of Engineering <br>  Mechanical engineering </h4><br> <a href="http://soe.stanford.edu/"><img src="https://habrastorage.org/storage/052b7b4a/23034462/b922b885/45a7d874.png"></a> <br><br>  <i>"The future is limited only by our imagination, and the possibilities are endless."</i> <br><br>  The Stanford School of Engineering, founded in 1925 and located in the heart of Silicon Valley, annually accommodates 9 different departments, about 200 teachers and 4 thousand students.  65 laboratories, many of which are interdisciplinary, operate in the fields of medicine, business, linguistics, and physics. <br><br>  Main research interests and areas of SOE: <br><ul><li>  Aeronautics and astronautics. </li><li>  Bioengineering. </li><li>  Chemical technology. </li><li>  Civil and environmental engineering. </li><li>  Computer science. </li><li>  Electrical engineering. </li><li>  Management in the field of science and technology. </li><li>  Materials Science. </li><li>  Machine design. </li></ul><br><h5>  reference </h5><br>  <b>Institution</b> : Stanford School of Engineering <br>  <b>Direction</b> : Mechanical Engineering;  ME &amp; Aero.  &amp; Astro. <br>  <b>Website</b> : <a href="http://soe.stanford.edu/">soe.stanford.edu</a> <br>  Courses: Medical / Bioacoustics, Physiological Acoustics, Structural Acoustics and Vibration, Engineering Acoustics, Noise and Noise Control, Nonlinear / Aeroacoustics <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/StanfordUniversity">www.youtube.com/StanfordUniversity</a> <br>  <b>Address</b> : Stanford, CA 94305, USA [ <a href="http://goo.gl/sQxNJ">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/PuYOY">goo.gl/PuYOY</a> <br>  <b>Contact</b> : chasst@stanford.edu ( <a href="http://soe.stanford.edu/research/layout.php%3Fsunetid%3Dchasst">Charles R. Steele</a> ), lele@stanford.edu ( <a href="http://soe.stanford.edu/research/layout.php%3Fsunetid%3Dlele">Sanjiva K. Lele</a> ), pinsky@stanford.edu ( <a href="http://soe.stanford.edu/research/layout.php%3Fsunetid%3Dpinsky">Peter Pinsky</a> ) <br><br><br><h4>  Cambridge University Engineering Department <br>  The Machine Intelligence Laboratory </h4><br> <a href="http://mi.eng.cam.ac.uk/mi/"><img src="https://habrastorage.org/storage/f574690b/7fb6d03e/a6c079af/5dc7003f.png"></a> <br><br>  <i>‚ÄúSpeech Research Group is part of the Machine Intelligence Laboratory.</i>  <i>SRG's mission is to advance the knowledge of machine processing of spoken language and the development of efficient algorithms for implementing applications.</i>  <i>The main specification of SRG is working with large speech dictionaries and related technologies.</i>  <i>Research interests also extend to conversational conversational systems, pattern recognition, speech synthesis, and machine learning. ‚Äù</i> <br><br>  SRG main research interests and areas: <br><ul><li>  Acoustic modeling (statistical models). </li><li>  Basic research in machine learning. </li><li>  Optimizing dialogue using reinforcing learning. </li><li>  Recognition in large dictionaries. </li><li>  Pattern recognition. </li><li>  Speech recognition on mobile devices. </li><li>  Speech and noise cancellation. </li><li>  Interactive systems and VoiceXML. </li><li>  Statistical language modeling. </li><li>  Statistical machine translation. </li><li>  Processing and transcribing recognized speech. </li></ul><br>  Speech Research Group accepts applications from potential graduate students and doctoral candidates.  It is also possible 1 or 2-year magistracy. <br><br><h5>  reference </h5><br>  <b>Institution</b> : Cambridge University, Speech Research Group <br>  <b>Direction</b> : The Machine Intelligence Laboratory <br>  <b>Faculty</b> : Cambridge University Engineering Department. <br>  <b>Website</b> : <a href="http://mi.eng.cam.ac.uk/mi/Main/Speech/">mi.eng.cam.ac.uk/mi/Main/Speech</a> <br>  <b>Disciplines</b> : vocational vocabulary speech transcription, spoken dialogue systems, multimedia document retrieval, speech synthesis, machine learning. <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/CambridgeUniversity">www.youtube.com/CambridgeUniversity</a> <br>  <b>Address</b> : Trumpington Street, CB2 1PZ, UK [ <a href="http://goo.gl/2PsJv">on map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/VbucH">goo.gl/VbucH</a> <br>  <b>Contact</b> : 01223 332752 (tel.), 01223 332662 (fax), jrm16@eng.cam.ac.uk (Janet Milne) <br><br><br><h4>  University of oxford <br>  Speech &amp; Brain Research Group </h4><br> <a href="http://www.fmrib.ox.ac.uk/speech-and-brain"><img src="https://habrastorage.org/storage/edbb5ec1/13dd63d9/16f03154/af080d9f.png"></a> <br><br>  <i>‚ÄúWe are interested in how the sensory and motor areas of the brain interact with speech communication.</i>  <i>We use various methods of imaging brain activity to study the brain during speech and speech perception. ‚Äù</i> <br><br>  Speech &amp; Brain Research Group recruits potential masters and doctors who can choose any of the courses in the Department of Experimental Psychology. <br><br>  Main research interests and areas of FMRIB: <br><ul><li>  Analysis of functional and structural data of brain images. </li><li>  Physiological neuroimaging. </li><li>  Brain disorders. </li><li>  Diffusion image. </li><li>  Speech and brain. </li><li>  Visualization. </li><li>  Neurodegeneration. </li><li>  Cognition </li><li>  Psychiatry. </li><li>  Epilepsy. </li></ul><br><h5>  reference </h5><br>  <b>Foundation</b> : University of Oxford <br>  <b>Direction</b> : Center for Functional Magnetic Resonance Imaging of the Brain (FMRIB);  Speech &amp; Brain Research Group <br>  <b>Faculty</b> : Department of Experimental Psychology, Oxford Center for Developmental Science. <br>  <b>Website</b> : <a href="http://www.fmrib.ox.ac.uk/speech-and-brain">www.fmrib.ox.ac.uk/speech-and-brain</a> <br>  <b>Disciplines</b> : brain structure, neural activity, emotional processing, non-speech stimuli. <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/Oxford">www.youtube.com/Oxford</a> <br>  <b>Address</b> : Wellington Square, OX1 9FB Oxford, UK [ <a href="http://goo.gl/YXvw2">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/HDMcO">goo.gl/HDMcO</a> <br>  <b>Contact</b> : kate.watkins@psy.ox.ac.uk, +44 (0) 1865 280459 (tel.), +44 (0) 1865 280300 (fax) <br><br><br><h4>  University of California, Los Angeles (UCLA) <br>  Department Of Linguistics </h4><br> <a href="http://www.linguistics.ucla.edu/"><img src="https://habrastorage.org/storage/a3fc3d15/ed1750d3/143674c5/3fb42b6b.png"></a> <br><br>  <i>‚ÄúUCLA Linguistics Department is one of the world's leading centers for scientific language learning.‚Äù</i> <br><br>  The main scientific interests and areas of UCLA LD: <br><ul><li>  Phonetics. </li><li>  Phonology. </li><li>  Syntax. </li><li>  Semantics. </li><li>  Psycholinguistics. </li><li>  Matlingvistics. </li><li>  Historical linguistics. </li><li>  African, Indian languages. </li></ul><br>  There are laboratories of phonetics, psycholinguistics, language learning.  <a href="http://goo.gl/kznZE">List of linguistic disciplines</a> . <br><br><h5>  reference </h5><br>  <b>Foundation</b> : University of California, Los Angeles <br>  <b>Direction</b> : Department Of Linguistics <br>  <b>Website</b> : <a href="http://www.linguistics.ucla.edu/">www.linguistics.ucla.edu</a> <br>  <b>Disciplines</b> : phonetics, phonology, syntax, semantics, psycholinguistics, language acquisition, historical linguistics, mathematical linguistics. <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/UCLA">www.youtube.com/UCLA</a> <br>  <b>Address</b> : 3125 Campbell Hall, UCLA, Los Angeles, USA [ <a href="http://goo.gl/9Ieau">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/cdvYF">goo.gl/cdvYF</a> <br>  <b>Contacts</b> : (310) 825-0634 (tel.), + (310) 206-5743 (fax), linguist@humnet.ucla.edu <br><br><br><h4>  Johns hopkins university <br>  The Center for Language and Speech Processing </h4><br> <a href="http://www.clsp.jhu.edu/"><img src="https://habrastorage.org/storage/54855511/757469c3/0bfcda8e/47b2f53d.png"></a> <br><br>  <i>‚ÄúAutomated systems that interact with people through conversation or writing will soon increase their convenience, ease of use, and hence our productivity.</i>  <i>These systems will accompany us wherever information is found, and everyone, including people with disabilities, will be able to access large and unstructured databases, such as the Internet, for example. ‚Äù</i> <br><br>  The Center for Language and Speech Processing (CLSP) was organized in 1992 with the support of the US government (NSF, DARPA, DoD).  Studies are conducted by teachers, researchers and graduate students affiliated with six related faculties: bioengineering, cognitive science, computer science, electrical engineering and computer science, mathematical science and psychology. <br><br>  The main research interests and areas of CLSP: <br><ul><li>  Language modeling. </li><li>  Natural language processing. </li><li>  Neural processing. </li><li>  Acoustic treatment. </li><li>  Optimization theory. </li><li>  Language entry </li></ul><br>  CLSP accepts undergraduate and graduate students.  Applications must be submitted through any of the following departments: Biomedical Engineering, Cognitive Science, Computer Science, Electrical and Computer Engineering, Applied Mathematics &amp; Statistics, Psychological and Brain Sciences. <br><br><h5>  reference </h5><br>  <b>Foundation</b> : Johns Hopkins University <br>  <b>Direction</b> : The Center for Language and Speech Processing <br>  <b>Website</b> : <a href="http://www.clsp.jhu.edu/">www.clsp.jhu.edu</a> <br>  <b>Disciplines</b> : language modeling, natural language processing, neural auditory processing, acoustic processing, optimality theory, and language acquisition. <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/JohnsHopkins">www.youtube.com/JohnsHopkins</a> <br>  <b>Address</b> : 3400 North Charles Street, Baltimore, MD, USA [ <a href="http://goo.gl/DKwrD">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/mQuyY">goo.gl/mQuyY</a> <br>  <b>Contact</b> : clsp@clsp.jhu.edu, +1 443-997-6688 (tel.) <br><br><br><h4>  Carnegie mellon university <br>  The Human-Computer Interaction Institute (HCII) </h4><br> <a href="http://www.hcii.cmu.edu/"><img src="https://habrastorage.org/storage/41366bd3/a6913850/e42b55b1/101a728c.png"></a> <br><br>  <i>‚ÄúThe mission of HCII is to understand and create a harmonious technology that enhances the capabilities of a person, his intentions and improve his social space through interdisciplinary research and education in the field of design, computer and social sciences.‚Äù</i> <br><br>  Since 1985, HCII has been offering research and educational programs covering the full cycle of knowledge acquisition.  It includes studies of social activity (work, play, communication) and social structures;  design, creation and evaluation of technologies and tools to support social activities. <br><br>  Main scientific interests and directions of HCII: <br><ul><li>  User interface software. </li><li>  Cognitive models. </li><li>  Speech recognition. </li><li>  Understanding of natural language. </li><li>  Computer graphics. </li><li>  Gesture recognition. </li><li>  Data visualization, visual design, multimedia. </li><li>  Computer support teamwork. </li><li>  Computer music and theatrical skills. </li><li>  Social technology. </li></ul><br>  HCII is recruiting for training at the degree of <a href="http://www.hcii.cmu.edu/applying-undergraduate-major">bachelor</a> , <a href="http://www.hcii.cmu.edu/masters-program-application">graduate students</a> and <a href="http://www.hcii.cmu.edu/phd-program-application">candidates of science</a> . <br><br><h5>  reference </h5><br>  <b>Foundation</b> : Carnegie Mellon University <br>  <b>Direction</b> : The Human-Computer Interaction Institute (HCII) <br>  <b>Website</b> : <a href="http://www.hcii.cmu.edu/">www.hcii.cmu.edu</a> <br>  <b>Courses</b> : user-interface software, cognitive models, speech recognition, natural language, language, understanding, computer graphics, gesture, data, visualization, intelligent, tangible, technical writing, technical and social impact of technology. <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/CarnegieMellonU">www.youtube.com/CarnegieMellonU</a> <br>  <b>Address</b> : 5000 Forbes Avenue, Pittsburgh PA 15213-3891, USA [ <a href="http://goo.gl/EABhv">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/AqW92">goo.gl/AqW92</a> <br>  <b>Contact</b> : <a href="http://www.hcii.cmu.edu/contact-us">www.hcii.cmu.edu/contact-us</a> , hcii@cs.cmu.edu <br><br><br><h4>  Educational market of speech technologies in Russia </h4><br>  The history of speech technologies (namely, technologies, and not just scientific linguistics) originates from the vicissitudes associated with the organization in 1959 of the Institute of Cybernetics in the USSR, whose success story dramatically turned out to be the beginning of the failure and loss of world primacy in this direction.  The creation of the Institute of Cybernetics was partly due to Western successes, in particular, the demonstration on January 7, 1954 in the New York office of the IBM machine translation system (IBM-701). <br>  Technology of machine translation, text decoding, pattern recognition in the 50-60s.  in the USSR they were brought to the level of the space program and the defense industry and had to prove the leading positions of the Soviet Union in the field of modeling artificial intelligence and computer-aided design.  The heyday of scientific thought at this time is associated with such names as N. D.  Andreev, Yu.D.  Apresyan, I.A.  Melchuk, A.K.  Zholkovsky, O.S.  Kulagina, A.I.  Berg, A.A.  Lyapunov, M.L.  Tsetlin, V. A. Uspensky, S. K. Shahumyan, and others. <br>  In the 70s, the outlined approach to new frontiers in the field of artificial intelligence, speech recognition and synthesis, was for various reasons finally decentralized and, one can say, suspended in the 80s, when scientists were forced to switch from state funding to a grant basis. <br>  By the end of the 80s and the beginning of the 90s.  These include the first attempts at independent survival of individual linguistic schools and traditions, subsequently translating their knowledge into commercially successful products and implementing their educational ambitions at a new stage in the development of speech technologies.  About two of them - in our short review. <br><br><h4>  Moscow Institute of Physics and Technology, ABBYY <br>  Image Recognition and Text Processing </h4><br> <a href="http://www.abbyy.ru/kafedra/"><img src="https://habrastorage.org/storage/91bcd6c9/be69a6ba/de3090d4/6e13758f.png"></a> <br><br>  <i>‚ÄúOur goal is to make at FIVTe (Faculty of Innovations and High Technologies) the best teaching of Computer Science in Russia.‚Äù</i> <br><br>  Since 2006, about fifty people have entered the department.  After graduation, work is offered at ABBYY, but graduates are not bound by any obligations towards the company. <br><br>  The main scientific interests and directions of RIOT ABBYY: <br><ul><li>  Software Engineering. </li><li>  Basics of creating graphical user interfaces. </li><li>  The architecture of modern computers and operating systems. </li><li>  Development of distributed and client-server applications. </li><li>  Algorithms and data structures. </li><li>  Intellectual systems. </li><li>  Artificial Intelligence. </li><li>  Designing user interaction. </li><li>  Compilation theory. </li><li>  Logic and modeling reasoning. </li><li>  Design and analysis of algorithms. </li><li>  Linguistic basics of automatic text processing. </li></ul><br>  Students are accepted to the department starting from the third year of study (bachelor, master). <br><br><h5>  reference </h5><br>  <b>Establishment</b> : Moscow Institute of Physics and Technology, ABBYY <br>  <b>Faculty</b> : Faculty of Innovation and High Technologies <br>  <b>Department</b> : Image Recognition and Text Processing <br>  <b>Website</b> : <a href="http://www.abbyy.ru/kafedra/">www.abbyy.ru/kafedra</a> <br>  <b>Disciplines</b> : design and analysis of algorithms, automatic text processing, applied lattice theory, graphical user interface development, intelligent systems, image recognition and processing, behavior modeling, perception and thinking, architecture development, client-server applications. <br>  <b>YouTube channel</b> : <a href="http://www.youtube.com/ABBYYVIDEOS">www.youtube.com/ABBYYVIDEOS</a> <br>  <b>Address</b> : Moscow, Klimentovsky lane., 1, p. 18 [ <a href="http://goo.gl/kSmnN">on the map</a> ] <br>  <b>Information for applicants</b> : <a href="http://goo.gl/pA7x9">goo.gl/pA7x9</a> <br>  <b>Contacts</b> : (495) 408-4318, (495) 408-4633;  <a href="">fivt.fizteh.ru;</a>  upr@mail.mipt.ru, krivtsov@mail.mipt.ru. <br><br><br><br><h4>  St. Petersburg State University of Information Technologies, Mechanics and Optics (ITMO), Speech Technology Center <br><br>  Speech Information Systems (RIS) </h4><br> <a href="http://www.speechpro.ru/career/learn-itmo"><img src="https://habrastorage.org/storage/8e0d1f81/7c2942fe/5649cc2f/1632aaa4.png"></a> <br><br>  <i>"We create products and technologies that help people understand others and be understood, making life in the global information community more efficient and safer."</i> <br><br>  Opened in 2011, the Department of Speech Information Systems (RIS), became part of the faculty of Information Technology and Programming ITMO.  The department trains specialists who are able to participate in research and design work in the field of speech information technologies with a specialization in the areas of speech recognition and synthesis, voice recognition, multimodal biometrics, in the design and development of information systems and software. <br><br>  Main scientific interests and RIS directions: <br><ul><li>  Digital processing of speech signals </li><li>  Speech recognition and synthesis </li><li>  Speaker Recognition </li><li>  Artificial Intelligence </li><li>  Multimodal biometrics </li><li>  Organization of software design and development </li><li>  Multithreaded programming </li><li>  Flexible software development models </li><li>  Information Systems Design </li><li>  System analysis and modeling of information processes and systems </li></ul><br>  The department accepts students with a bachelor's degree or specialist (preferably in the areas of information technology and programming) with general mathematical training. <br><br><h5>  reference </h5><br>  <b>Institution</b> : St. Petersburg State University of Information Technologies, Mechanics and Optics (ITMO), Center for Speech Technologies <br>  <b>Faculty</b> : Faculty of Information Technology and Programming <br>  <b>Department</b> : Speech Information Systems (RIS) <br>  <b>Website</b> : <a href="http://www.speechpro.ru/career/learn-itmo">www.speechpro.ru/career/learn-itmo</a> <br>  <b>Disciplines</b> : speech recognition and synthesis, voice recognition, multimodal biometrics. <br>  <b>Address</b> : St. Petersburg, st.  Krasutsky, 4 [ <a href="http://goo.gl/fUWdI">on the map</a> ] <br>  <b>Information for applicants</b> : May 17, 2011 - open day (registration ris@speechpro.com). <br>  <b>Contacts</b> : +7 911 2643973;  (812) 325-88-48;  ris@speechpro.com <br><br></div><p>Source: <a href="https://habr.com/ru/post/119061/">https://habr.com/ru/post/119061/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../119054/index.html">MSSql: Using the APPLY operator in TSql</a></li>
<li><a href="../119055/index.html">Programming network applications in C ++</a></li>
<li><a href="../119056/index.html">Pyaterochka in Google-Maps</a></li>
<li><a href="../119058/index.html">We learn system of paging addressing and interrupt handling</a></li>
<li><a href="../119059/index.html">About replacements in Vim using regular expressions</a></li>
<li><a href="../119063/index.html">Open Electoral Statistics of Russia</a></li>
<li><a href="../119064/index.html">VimpelCom Announces Reaching Final Agreements on the Purchase of NTK</a></li>
<li><a href="../119065/index.html">GreenfieldFeedback: Internet users and e-government officials</a></li>
<li><a href="../119066/index.html">Symantec experts have discovered and helped to correct a serious mistake in the system for protecting the personal data of Facebook users.</a></li>
<li><a href="../119067/index.html">Virtual Republic of Alter Russia: Results of the Technical Launch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>