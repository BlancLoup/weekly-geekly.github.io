<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What's inside XGBoost, and where does Go</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the world of machine learning, one of the most popular types of models is a decisive tree and ensembles based on them. The advantages of trees are:...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What's inside XGBoost, and where does Go</h1><div class="post__text post__text-html js-mediator-article"> In the world of machine learning, one of the most popular types of models is a decisive tree and ensembles based on them.  The advantages of trees are: simplicity of interpretation, no restrictions on the type of initial dependence, soft requirements for the sample size.  Trees have a major drawback - a tendency to retrain.  Therefore, almost always trees are combined into ensembles: a random forest, gradient boosting, etc. The complex theoretical and practical tasks are the compilation of trees and their unification into ensembles. <br><br>  In this article, we will consider the procedure for the formation of predictions on the already trained model of an ensemble of trees, the features of implementations in the popular libraries of gradient boosting <a href="https://github.com/dmlc/xgboost"><code>XGBoost</code></a> and <a href="https://github.com/Microsoft/LightGBM"><code>LightGBM</code></a> .  As well as the reader will get acquainted with the <a href="https://github.com/dmitryikh/leaves"><code>leaves</code></a> library for Go, which allows you to make predictions for tree ensembles, without using the original libraries C API. <br><a name="habracut"></a><br><h2>  Where do trees grow from? </h2><br>  Consider first the general provisions.  Usually work with trees, where: <br><br><ol><li>  splitting in a node occurs by one attribute </li><li>  tree is binary - each node has a left and right descendant </li><li>  in the case of a real attribute, the decision rule consists of comparing the characteristic value with a threshold value </li></ol><br>  I took this illustration from the <a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">XGBoost documentation</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/is/kk/wt/iskkwtpwjobce6ix23itjf0l48i.png" width="400"><br><br>  In this tree we have 2 nodes, 2 decision rules and 3 leaves.  Below the circles are the values ‚Äã‚Äã- the result of applying the tree to an object.  Usually, a transformation function is applied to the result of computing a tree or ensemble of trees.  For example, <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B8%25D0%25B3%25D0%25BC%25D0%25BE%25D0%25B8%25D0%25B4%25D0%25B0">sigmoid</a> for a binary classification problem. <br><br>  To obtain predictions from an ensemble of trees obtained by the gradient boosting method, you need to add up the results of the predictions of all the trees: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> pred = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">auto</span></span>&amp; tree: trees) pred += tree-&gt;Predict(feature_values);</code> </pre><br>  Hereinafter there will be <code>C++</code> , since  <code>XGBoost</code> and <code>LightGBM</code> are written in this language.  I will omit irrelevant details and try to give the most concise code. <br><br>  Next, consider what is hidden in <code>Predict</code> , and how the tree data structure is organized. <br><br><h2>  XGBoost trees </h2><br>  In <code>XGBoost</code> there are several classes (in the sense of OOP) of trees.  We will talk about <code>RegTree</code> (see <code>include/xgboost/tree_model.h</code> ), which is the main word from the documentation.  If you leave only the details that are important for predictions, the members of the class look as simple as possible: <br><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegTree</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-comment"><span class="hljs-comment">// vector of nodes std::vector&lt;Node&gt; nodes_; };</span></span></code> </pre><br>  The <code>GetNext</code> rule is implemented in the <code>GetNext</code> function.  The code is slightly modified, without affecting the result of the calculations: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// get next position of the tree given current pid int RegTree::GetNext(int pid, float fvalue, bool is_unknown) const { const auto&amp; node = nodes_[pid] float split_value = node.info_.split_cond; if (is_unknown) { return node.DefaultLeft() ? node.cleft_ : node.cright_; } else { if (fvalue &lt; split_value) { return node.cleft_; } else { return node.cright_; } } }</span></span></code> </pre><br>  Two things follow from here: <br><br><ol><li>  <code>RegTree</code> works only with real signs (type <code>float</code> ) </li><li>  missing attribute values ‚Äã‚Äãsupported </li></ol><br>  The centerpiece is the <code>Node</code> class.  It contains the local tree structure, the decision rule and the leaf value: <br><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Node</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: <span class="hljs-comment"><span class="hljs-comment">// feature index of split condition unsigned SplitIndex() const { return sindex_ &amp; ((1U &lt;&lt; 31) - 1U); } // when feature is unknown, whether goes to left child bool DefaultLeft() const { return (sindex_ &gt;&gt; 31) != 0; } // whether current node is leaf node bool IsLeaf() const { return cleft_ == -1; } private: // in leaf node, we have weights, in non-leaf nodes, we have split condition union Info { float leaf_value; float split_cond; } info_; // pointer to left, right int cleft_, cright_; // split feature index, left split or right split depends on the highest bit unsigned sindex_{0}; };</span></span></code> </pre><br>  The following features can be distinguished: <br><br><ol><li>  sheets are represented as nodes whose <code>cleft_ = -1</code> </li><li>  The <code>info_</code> field <code>info_</code> represented as a <code>union</code> , i.e.  two data types (in this case, the same) divide one section of memory depending on the type of node </li><li>  the high bit in <code>sindex_</code> is responsible for where the object goes, for which the attribute value is omitted </li></ol><br>  In order to be able to trace the path from calling the <code>RegTree::Predict</code> method to getting an answer, I‚Äôll provide the missing two functions: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> RegTree::Predict(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> RegTree::FVec&amp; feat, <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> root_id) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pid = <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>-&gt;GetLeafIndex(feat, root_id); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nodes_[pid].leaf_value; } <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> RegTree::GetLeafIndex(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> RegTree::FVec&amp; feat, <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> root_id) <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> pid = <span class="hljs-keyword"><span class="hljs-keyword">static_cast</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(root_id); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (!nodes_[pid].IsLeaf()) { <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> split_index = nodes_[pid].SplitIndex(); pid = <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>-&gt;GetNext(pid, feat.Fvalue(split_index), feat.IsMissing(split_index)); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pid; }</code> </pre><br>  In the <code>GetLeafIndex</code> function <code>GetLeafIndex</code> we loop down through the nodes of the tree until we get to the leaf. <br><br><h2>  LightGBM trees </h2><br>  LightGBM has no node data structure.  Instead, the tree data structure (file <code>include/LightGBM/tree.h</code> ) contains arrays of values, where the node number is used as the index.  The values ‚Äã‚Äãin the leaves are also stored in separate arrays. <br><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Tree</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-comment"><span class="hljs-comment">// Number of current leaves int num_leaves_; // A non-leaf node's left child std::vector&lt;int&gt; left_child_; // A non-leaf node's right child std::vector&lt;int&gt; right_child_; // A non-leaf node's split feature, the original index std::vector&lt;int&gt; split_feature_; //A non-leaf node's split threshold in feature value std::vector&lt;double&gt; threshold_; std::vector&lt;int&gt; cat_boundaries_; std::vector&lt;uint32_t&gt; cat_threshold_; // Store the information for categorical feature handle and mising value handle. std::vector&lt;int8_t&gt; decision_type_; // Output of leaves std::vector&lt;double&gt; leaf_value_; };</span></span></code> </pre><br>  <code>LightGBM</code> supports categorical features.  Support is provided using a <code>cat_threshold_</code> stored in <code>cat_threshold_</code> for all nodes.  The <code>cat_boundaries_</code> stores to which node which part of the bit field corresponds to.  The <code>threshold_</code> field for the categorical case is converted to an <code>int</code> and corresponds to the index in <code>cat_boundaries_</code> to search for the beginning of the bit field. <br><br>  Consider the decision rule for a categorical trait: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">CategoricalDecision</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params"> fval, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> node)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">const</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">uint8_t</span></span> missing_type = GetMissingType(decision_type_[node]); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> int_fval = <span class="hljs-keyword"><span class="hljs-keyword">static_cast</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(fval); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (int_fval &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> right_child_[node];; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::isnan(fval)) { <span class="hljs-comment"><span class="hljs-comment">// NaN is always in the right if (missing_type == 2) { return right_child_[node]; } int_fval = 0; } int cat_idx = static_cast&lt;int&gt;(threshold_[node]); if (FindInBitset(cat_threshold_.data() + cat_boundaries_[cat_idx], cat_boundaries_[cat_idx + 1] - cat_boundaries_[cat_idx], int_fval)) { return left_child_[node]; } return right_child_[node]; }</span></span></code> </pre><br>  It can be seen that, depending on the <code>missing_type</code> value <code>NaN</code> automatically lowers the solution along the right branch of the tree.  Otherwise, <code>NaN</code> is replaced with 0. Finding a value in a bit field is quite simple: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">FindInBitset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">uint32_t</span></span></span></span><span class="hljs-function"><span class="hljs-params">* bits, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> n, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> pos)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i1 = pos / <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (i1 &gt;= n) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i2 = pos % <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (bits[i1] &gt;&gt; i2) &amp; <span class="hljs-number"><span class="hljs-number">1</span></span>; }</code> </pre><br>  i.e., for example, for the categorical feature <code>int_fval=42</code> checked whether the 41st (numbering with 0) bits are set in the array. <br><br>  This approach has one major drawback: if the categorical feature can take large values, for example 100,500, then a bit field of up to 12,564 bytes in size will be created for each decision rule! <br><br>  <b>Therefore, it is advisable to renumber the values ‚Äã‚Äãof the categorical attributes so that they go continuously from 0 to the maximum value</b> . <br><br>  For my part, I made <code>LightGBM</code> to the <code>LightGBM</code> and <a href="https://github.com/Microsoft/LightGBM/pull/1636">accepted them</a> . <br><br>  Working with real signs is not much different from <code>XGBoost</code> , and I‚Äôll skip this for short. <br><br><h2>  leaves - Go library for predictions </h2><br>  <code>XGBoost</code> and <code>LightGBM</code> very powerful libraries for building gradient <code>LightGBM</code> models on decision trees.  To use them in the backend service, where machine learning algorithms are necessary, it is necessary to solve the following tasks: <br><br><ol><li>  Periodic training of models in offline </li><li>  Delivery models in the backend service </li><li>  Online Model Survey </li></ol><br>  For writing a loaded backend service, <code>Go</code> is a popular language.  <code>XGBoost</code> or <code>LightGBM</code> through C API and cgo is not the easiest solution - the program builds up, due to careless handling you can catch <code>SIGTERM</code> , problems with the number of system streams (OpenMP inside libraries vs go runtime). <br><br>  So I decided to write a library on pure <code>Go</code> for predictions using models built in <code>XGBoost</code> or <code>LightGBM</code> .  It is called <a href="https://github.com/dmitryikh/leaves"><code>leaves</code></a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c31/ac7/577/c31ac7577425653a4902dcff8a3b9456.png" alt="leaves"><br><br>  The main features of the library: <br><br><ul><li>  For <code>LightGBM</code> models <br><ul><li>  Reading models from a standard format (text) </li><li>  Support for real and categorical features </li><li>  Missing Value Support </li><li>  Optimization of work with categorical variables </li><li>  Optimizing predictions with predictive-only data structures </li></ul><br></li><li>  For <code>XGBoost</code> models <br><ul><li>  Reading models from a standard format (binary) </li><li>  Missing Value Support </li><li>  Prediction optimization </li></ul><br></li></ul><br>  I will give here a minimal program on <code>Go</code> that loads the model from disk and displays the prediction on the screen: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">package main </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">import</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"bufio"</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"fmt"</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"os"</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"github.com/dmitryikh/leaves"</span></span></span></span><span class="hljs-function"><span class="hljs-params"> )</span></span></span><span class="hljs-function"> func </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// 1.     path := "lightgbm_model.txt" reader, err := os.Open(path) if err != nil { panic(err) } defer reader.Close() // 2.   LightGBM model, err := leaves.LGEnsembleFromReader(bufio.NewReader(reader)) if err != nil { panic(err) } // 3.  ! fvals := []float64{1.0, 2.0, 3.0} p := model.Predict(fvals, 0) fmt.Printf("Prediction for %v: %f\n", fvals, p) }</span></span></code> </pre><br>  The library API is minimalistic.  To use the <code>XGBoost</code> model <code>XGBoost</code> simply call the <code>leaves.XGEnsembleFromReader</code> method instead of the one above.  Predictions can be made in batches by calling the <code>PredictDense</code> or <code>model.PredictCSR</code> .  More usage scenarios can be found in the <a href="">tests for leaves</a> . <br><br>  Despite the fact that the <code>Go</code> language is slower than <code>C++</code> (mainly due to the heavier runtime and runtime checks), a number of optimizations have resulted in prediction speeds comparable to the C API call of the original libraries. <br><img src="https://habrastorage.org/webt/xl/rw/bi/xlrwbiikgtfpor6luj5_n0gm4c8.png" width="600"><br><br>  More details about the results and the way of comparisons are in the <a href="https://github.com/dmitryikh/leaves">repository on github</a> . <br><br><h2>  Behold the root </h2><br>  I hope this article I opened the door in the implementation of trees in the libraries <code>XGBoost</code> and <code>LightGBM</code> .  As you can see, the basic constructs are quite simple, and I encourage readers to take advantage of open source ‚Äî to study the code when there are questions about how it works. <br><br>  For those who are interested in the topic of using gradient boosting models in their services in the Go language, I recommend you to get acquainted with the <a href="https://github.com/dmitryikh/leaves">leaves</a> library.  With the help of <code>leaves</code> you can quite simply use the leading edge solutions in machine learning in your production environment, practically not losing in speed compared to the original C ++ implementations. <br><br>  Successes! </div><p>Source: <a href="https://habr.com/ru/post/423495/">https://habr.com/ru/post/423495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../423485/index.html">Lazy loading images using IntersectionObserver</a></li>
<li><a href="../423487/index.html">Node.js without node_modules</a></li>
<li><a href="../423489/index.html">I'm an emergency doctor, and I want to talk about the new Apple Watch electrocardiogram</a></li>
<li><a href="../423491/index.html">PHP Digest number 139 (September 3 - 17, 2018)</a></li>
<li><a href="../423493/index.html">Android Go is the next billion devices and 50 MB limit. Yandex lecture</a></li>
<li><a href="../423497/index.html">Let's try to talk about hierarchical finite automata in general and their support in SObjectizer-5 in particular</a></li>
<li><a href="../423499/index.html">DevBoy - how I created a project with an open source device and launched a project on Kickstarter</a></li>
<li><a href="../423501/index.html">Search and create a visual style design project</a></li>
<li><a href="../423503/index.html">My experience of moving, living and studying in Germany</a></li>
<li><a href="../423505/index.html">Zuckerberg sells Facebook shares for $ 13 billion so that ‚Äúour children never have to be sick‚Äù</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>