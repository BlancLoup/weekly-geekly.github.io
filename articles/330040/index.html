<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Flashcache - cheap and angry or alternative to HW RAID 10 SAS</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Until 2014, on the FirstVDS servers we used industrial HDDs with 
 SAS-interface and hardware controllers, assembled in RAID 10. This solution complet...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Flashcache - cheap and angry or alternative to HW RAID 10 SAS</h1><div class="post__text post__text-html js-mediator-article">  Until 2014, on the <a href="https://firstvds.ru/%3Futm_source%3Dhabrahabr.ru%26utm_medium%3Dreferral%26utm_campaign%3DFlashcache%2520%25E2%2580%2594%2520%25D0%25B4%25D0%25B5%25D1%2588%25D0%25B5%25D0%25B2%25D0%25BE%2520%25D0%25B8%2520%25D1%2581%25D0%25B5%25D1%2580%25D0%25B4%25D0%25B8%25D1%2582%25D0%25BE">FirstVDS servers</a> we used industrial HDDs with <br>  SAS-interface and hardware controllers, assembled in RAID 10. This solution completely satisfied us in terms of reliability and performance. <a name="habracut"></a>  Problems with partial loss of customer data were 3 times in 12 years of use.  Twice burned hardware controllers.  Once the battery failed and during an emergency power off, the raid‚Äôs built-in cache memory was cleared. <br><br>  However, SAS HDD is expensive.  For one server, we took a set of 4 disks of 600 GB each, a hardware RAID controller with a battery.  The entire solution cost 44,806 rubles.  for 1 TB.  We did not want to raise prices for VDS.  It was necessary to find a cheaper solution, while not losing in speed and reliability.  And ideally, increase the space provided for VDS. <br><br>  Only SSD is even more expensive.  At that time, drives of 240 GB cost from 8000 rubles.  It was cheaper to stay on Raid 10 SAS than to use SSD with a total volume of 1 TB.  And to increase the storage and even more expensive.  Therefore, we reviewed several software solutions and included SSD in tests to compare speed.  Table with the results below. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Alternative solutions </h2><br>  <b>zfs</b> is a file system and logical partition manager with an <a href="https://ru.wikipedia.org/wiki/ZFS">adaptive replacement cache</a> developed by Sun Microsystems.  Zfs cannot be included in the original version of the Linux kernel due to license incompatibility (CDDL vs GPL).  The system can be screwed with DKMS modules, but the effort is not worth it - judging by the public tests, the write / read speed was low.  Test themselves did not. <br><br>  <b>bcache</b> - the development of Google, in 2013 was still raw - was not used in production.  It worked only with CentOS 7, and we used CentOS 6. Bcache was also not tested. <br><br>  <b>lvm cache</b> - Linux community technology.  It also worked only with CentOS 7, but at that time there were no public tests - we decided to do it ourselves.  The numbers did not like. <br><br>  <b>flashcache</b> is developed by Facebook: the company inspires confidence, and the technology has already been tested in production. <br><br>  Flashcache works in 3 modes: <br><br><ul><li>  <b>Write through</b> - data is first written to disk, and then flushed to the cache.  Record is cached only. </li><li>  <b>Write back</b> - data is first written to the cache, then flushed to disk.  Cached write and read. </li><li>  <b>Write around</b> - the data is written to the disk, and the cache gets after the first read.  Caching is read only. </li></ul><br>  Since <b>write back</b> is the fastest mode, we chose it for tests. <br><br>  <b>MD</b> - software raid.  Flashcache works in conjunction with MD and Raid 1. We included MD without Flashcache in testing to test how it works separately. <br><br><h3>  Test results </h3><br>  In order to bring the study conditions as close as possible to the real ones, they started random writing and reading a 32 GB file (mounted file system). <br><table><tbody><tr><th>  Parameter </th><th>  raid10 sas </th><th>  SSD </th><th>  MD </th><th>  flashcache write back </th></tr><tr><td>  queue depth </td><td>  32 </td><td>  32 </td><td>  32 </td><td>  32 </td></tr><tr><td>  IOPSread </td><td>  1,401 </td><td>  51 460 </td><td>  598 </td><td>  6,124 </td></tr><tr><td>  Iopswrite </td><td>  999 </td><td>  23,082 </td><td>  230 </td><td>  3 205 </td></tr><tr><td>  reading speed </td><td>  5 607 Kb / s </td><td>  205 842 Kb / s </td><td>  2 393 Kb / s </td><td>  24 496 Kb / s </td></tr><tr><td>  write speed </td><td>  3 998 Kb / s </td><td>  92 329 Kb / s </td><td>  922 Kb / s </td><td>  12 823 Kb / s </td></tr></tbody></table><br>  Flashcache in writeback mode bypassed lvmcache and overtook the software raid.  He lost a lot of expensive SSD, but most importantly, flashcache surpassed our solution on SAS HDD. <br><br><h2>  New solution with flashcache </h2><br>  According to a study in January 2014, we implemented flashcache on SSD + SATA HDD.  Since then, on the same server is 1 SSD and 2 SATA HDD on 4TB in the mirror.  The technology works in writeback mode: it quickly writes data to the cache and slowly drops it onto the main carrier. <br><br>  In the implementation and maintenance of flashcache, we are faced with some features of the technology. <br><br><h3>  Flashcache features </h3><br>  <b>1) SSD wears out</b> <br><br>  Due to the exceeded number of entries / overwrites, SSD stops recording new data.  To prevent this, we monitor SMART attributes: <br><br><ul><li>  <b>Media_Wearout_Indicator</b> is the disc lifetime or wear: the value for a new disc is 100, with time it decreases.  The minimum allowable is 10, when this value is reached, the disk becomes read only. </li><li>  <b>Reallocated_Sector_Count</b> - the number of reassigned sectors - must be less than 100. </li></ul><br>  The monitoring program monitors these values ‚Äã‚Äãautomatically and notifies employees about problem disks.  We can only change them in time. <br><br>  We used to use 240 GB disks, they worked less than a year.  Now <a href="http://www.nix.ru/computer_hardware_news/hardware_news_viewer.html%3Fid%3D178629">over-provisioning</a> technology allows us to increase the backup disk area and due to this, extend the lifetime of the SSD.  We cut the 1 TB disk to 240 GB, this is the working area, the remaining 760 GB is a reserve for wear.  Now SSD is on average 1 year. <br><br>  <b>2) Crashes when SSD burns and unsynchronized (dirty) data is lost</b> <br><br>  In writeback mode, the data first gets into the SSD cache and only then into the SATA HDD memory.  Data that did not have time to fold on the SATA HDD, called dirty.  In case of failure, they are irrevocably burned out along with the SSD.  In case of emergency power failure, SSD can also fail with data loss. <br><br>  Fortunately, failures do not occur as often.  For 2.5 years, we had two cases with the loss of client data that did not have time to register in the repository. <br><br>  There are two ways to reduce the number of failures: <br><br><ul><li>  Use high-quality server SSD.  What we are doing is buying disks from Intel, Hitachi, Toshiba, and others. </li><li>  Configure cache replication (mirror raid).  The solution provides for the installation of a second SSD, but due to rare failures, we squeezed the money for it. </li></ul><br>  <b>3) Long clean the cache</b> <br><br>  Change SSD and configure flashcache - 5 minutes.  But before that, you need to clear the cache - throw all the dirty data on the disks. <br><br>  On average, we have 30% of dirty data on the SSD, the maximum is 70%.  Clearing the cache takes up to 4 hours. <br><br>  At this time, the system is slower because it refers to slow media.  We always warn customers about speed drops, but we cannot force the process.  The speed of writing to SATA HDD depends on how intensively the clients use the disk.  The more intensively they use, the greater the load and the slower the recording speed. <br><br>  <b>4) Cache can overflow</b> <br><br>  Frequently used data is in cache and is called hot.  On our servers, they are about 13%, maximum 62%.  This amount is enough for a quick read / write of all VDS on the server.  But overflowing the cache and reducing productivity can be a distrust of the entire customer. <br><br>  Suppose a client wants to test a disk subsystem.  Run a random file writer.  If the client's disk is larger in cache, everything is bad.  The cache will overflow and everything will fall into poor performance.  All VDS on the server will be affected. <br><br>  If you decide to conduct such a test, do not expect actual results.  We programmatically limit the violator of the number of hits on the disk, it reduces the speed. <br><br>  <b>5) Flashcache does not work on Centos 7</b> <br><br>  After updating the kernel, flashcache became incompatible with Centos 7. Since this version of the distribution kit costs 50% of our servers, the problem is acute.  Now Centos 7 is used with sw raid1 with SSD.  On three clusters, we are testing enhanceio ‚Äî another caching technology ‚Äî but we are not yet ready to voice the results. <br><br><h3>  Flashcache deployment results </h3><br>  We calculate how flashcache on SSD + SATA HDD is more profitable than RAID 10 SAS.  To do this, we calculate the cost of each solution. <br><table><tbody><tr><th width="330">  RAID 10 SAS </th><td>  approximate prices for March 2013 </td></tr><tr><td>  SAS 600 GB, 4 pcs. </td><td>  7714 rub.  x 4 </td></tr><tr><td>  hardware controller + battery </td><td>  8600 rub.  + 4500 rub. </td></tr><tr><td>  cable </td><td>  850 rub. </td></tr><tr><td></td><td>  = 44806 rub.  or $ 1493 (at the rate of $ 1 = 30 rubles.) </td></tr><tr><td></td><td>  - cost of 1 TB of space on the parent server </td></tr></tbody></table><br><table><tbody><tr><th width="330">  SATA HDD + SSD </th><td>  prices in May 2017 </td></tr><tr><td>  SATA HDD 4 TB, 2 pcs. </td><td>  12 000 rub.  x 2 </td></tr><tr><td>  SSD </td><td>  17 100 rub. </td></tr><tr><td></td><td>  = 41 100 rub.  or $ 685 (at the rate of $ 1 = 60 rubles.) </td></tr></tbody></table><br><br>  Since 2013, the dollar has risen by 2 times.  Therefore, a solution with a flashcache in rubles costs almost as much as RAID 10 SAS, and in dollars is 2 times cheaper. <br><br>  Increasing the storage capacity by 4 times, we reduced the price of 1 TB.  Now it is cheaper by 4 times in rubles and 8 times in dollars. <br><br><h2>  Conclusion </h2><br>  In 2014, we implemented flashcache - we increased the space provided for VDS 4 times, and increased the speed of interaction with the disk subsystem.  This solution came out cheaper than the previous one, allowing us to reduce costs and not raise prices for VDS. <br><br>  Reliability remained a question, but there were fewer failures with the HW RAID 10 SAS.  In May 2015 for people for whom reliability and speed are crucial, we introduced <a href="https://firstvds.ru/%3Futm_source%3Dhabrahabr.ru%26utm_medium%3Dreferral%26utm_campaign%3DFlashcache%2520%25E2%2580%2594%2520%25D0%25B4%25D0%25B5%25D1%2588%25D0%25B5%25D0%25B2%25D0%25BE%2520%25D0%25B8%2520%25D1%2581%25D0%25B5%25D1%2580%25D0%25B4%25D0%25B8%25D1%2582%25D0%25BE">tariffs with SSD</a> as the main carrier. </div><p>Source: <a href="https://habr.com/ru/post/330040/">https://habr.com/ru/post/330040/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../330030/index.html">Dynamic Angular or manipulate correctly</a></li>
<li><a href="../330032/index.html">OpenTl.Server - server implementation of the messenger</a></li>
<li><a href="../330034/index.html">Named tuples. Writing Python Code Cleaner</a></li>
<li><a href="../330036/index.html">GitLab 9.2 released: Multiple task executors, pipelines on schedule, localization, disaster recovery alpha</a></li>
<li><a href="../330038/index.html">Cisco CSR 1000v: Reliability - the key to success. Part 2</a></li>
<li><a href="../330044/index.html">Chat with your own hands</a></li>
<li><a href="../330046/index.html">1 more non-recursive algorithm for generating all partitions of an integer</a></li>
<li><a href="../330048/index.html">Understanding the event architecture of Node.js</a></li>
<li><a href="../330052/index.html">Software Defined Radio by the hands of a sixteen year old</a></li>
<li><a href="../330056/index.html">The history of the creation of the Virtual File System Git (GVFS, Git Virtual File System)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>