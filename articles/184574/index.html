<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>SMS filtering of spam using a naive Bayes classifier (R code)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hey. In this post, we will look at a simple spam filtering model using a naive Bayes classifier with blur according to Laplace , write a few lines of ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>SMS filtering of spam using a naive Bayes classifier (R code)</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/adf/b34/133/adfb34133e0ac6a80ead91ed2d2c834e.jpg" align="right">  Hey.  In this post, we will look at a simple spam filtering model <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">using a naive Bayes classifier</a> with <a href="http://en.wikipedia.org/wiki/Additive_smoothing">blur according to Laplace</a> , write a few lines of code <a href="http://www.r-project.org/">in R</a> , and finally test it on an English-language <a href="http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/">sms spam database</a> .  Generally, on Habr√©, I found two articles on this topic, but none of them had a vivid example, so that you could download the code and see the result.  There was also no mention of blur, which significantly increases the quality of the model, without much effort, unlike, say, a complex text preprocessing.  But in general, the next post about naive bayes made me feel that I was writing a training manual for students with R code examples, so I decided to share the info. <br><br><a name="habracut"></a><br><br><h4>  Naive Bayes Classifier </h4>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Consider the set of some objects <i>D = {dq, d2, ..., dm}</i> , each of which has a certain set of features from the set of all features <i>F = {f1, f2, ..., fq}</i> , as well as one label from the set of tags <i>C = {c1, c2, ..., cr}</i> .  Our task is to calculate the most probable class / label of an incoming object d, based on the set of its attributes <i>Fd = {fd1, fd2, ..., fdn}</i> .  In other words, we need to calculate such a value of the random variable <i>C</i> , at which the a posteriori maximum (MAP) is reached. <br><br><img src="https://habrastorage.org/storage2/1c3/833/d73/1c3833d737bea12e0f5cc92a64f7494e.png"><br><br><ul><li>  2.1 - in fact, this is our goal </li><li>  2.2 - decomposed by <a href="http://en.wikipedia.org/wiki/Bayes%2527_theorem">the Bayes theorem</a> </li><li>  2.3 - given that we are looking for an argument that maximizes the likelihood function, and the fact that the denominator does not depend on this argument and is a constant in this case, we can safely delete the value of the total probability <i>P (d)</i> </li><li>  2.4 - since the logarithm monotonously increases for any <i>x&gt; 0</i> , the maximum of any function <i>f (x)</i> will be identical to the maximum <i>ln (f (x))</i> ;  this is necessary so that in the future, during programming, not to operate with numbers close to zero </li></ul><br><br>  The model of the naive Bayes classifier makes two assumptions, from which it is so naive: <br><ol><li>  the order of the signs of the object does not matter; </li><li>  probabilities of attributes are independent of each other for a given class: <img src="https://habrastorage.org/storage2/a4e/ea1/0c3/a4eea10c344e99a0a46660717c43a8b9.png">  . </li></ol><br><br>  Given the above assumptions, we continue to derive formulas. <br><br><img src="https://habrastorage.org/storage2/8f6/071/8ef/8f60718ef65e625404a1ce76a79dfe5c.png"><br><br><ul><li>  2.6-2.7 - this is just a consequence of the application of assumptions. </li><li>  2.8 - here, just, the remarkable logarithm property is used, which allows us to avoid loss of accuracy when operating with very small values </li></ul><br><br>  We can depict a <a href="http://en.wikipedia.org/wiki/Graphical_model">graphical model of a</a> naive Bayes classifier as follows: <br><br><img src="https://habrastorage.org/storage2/05f/a2e/78b/05fa2e78bde5f3f44bbffb85cba087b7.png"><br><br><h4>  Spam classifier </h4><br>  Now, from the more general classification task, we dive into the specific task of classifying spam.  So, the coupon <i>D</i> consists of SMS messages.  Each message is marked with a label from the set <i>C = {ham, spam}</i> .  In order to formulate the concept of signs, we will use the model of representation <a href="http://en.wikipedia.org/wiki/Bag-of-words_model">bag of words</a> , we illustrate this with an example.  Suppose we have only two ham sms messages in the database <br><br> <code>hi how are you</code> <br> <code>how old are you</code> <br> <br>  Then we can build a table <br><br><table><tbody><tr><th>  Word </th><th>  Frequency </th></tr><tr><td>  hi </td><td>  one </td></tr><tr><td>  how </td><td>  2 </td></tr><tr><td>  are </td><td>  2 </td></tr><tr><td>  you </td><td>  2 </td></tr><tr><td>  old </td><td>  one </td></tr></tbody></table><br><br>  There are only 8 words in the body of non-spam messages, then after rationing we get the a posteriori probability of the word using <a href="https://en.wikipedia.org/wiki/Maximum_likelihood">maximum likelihood estimation</a> .  For example, the probability of the word "how", provided that the message is not spam, will be: <br><br>  <i>P (fi = "how" | C = ham) = 2/8 = 1/4</i> <br><br>  Or we can write this method in general: <br><br><img src="https://habrastorage.org/storage2/2f4/da1/b6f/2f4da1b6f675045e9634a659808230a0.gif">  where q is the total number of unique words in the dictionary. <br><br><h4>  Laplace Blur </h4><br>  At this point, it's time to pay attention to the following problem.  Recall our base of two ham messages, and, let's say, a message came to us for classification: " <i>hi bro</i> ", and, let's say, the a priori probability of non-spam <i>P (ham) = 1/2</i> .  Calculate the probabilities of words: <br><br><ol><li>  <i>P ("hi" | ham) = 1/8</i> </li><li>  <i>P ("bro" | ham) = 0/8 = 0</i> </li></ol><br><br>  Recall formula 2.8 and calculate the expression under <b>argmax</b> with <i>c = ham</i> : <br><img src="https://habrastorage.org/storage2/49f/ee3/e2f/49fee3e2fcccfee4647d389c99ed2838.gif"><br><br>  Obviously, we get either an error or a negative infinity, because  the logarithm at zero does not exist.  If we did not use logarithmization, then we would simply get 0, i.e.  the probability of this message would be zero, which in principle gives us great benefit. <br><br>  This can be <a href="http://en.wikipedia.org/wiki/Additive_smoothing">avoided by Laplace blur or k-additive smoothing</a> - this method allows you to blur when calculating the probabilities of categorical data.  In our case, it will look like this: <br><br><img src="https://habrastorage.org/storage2/406/f6e/b4f/406f6eb4feb0b5e5ec169083d4e4d689.gif">  , where z&gt; = 0 is the blur coefficient, and q is the number of values ‚Äã‚Äãthat a random variable can take, in our case it is the number of words in the class;  and q is the total number of words that were used in teaching the model. <br><br>  For example, when reading ham and spam messages, we found 10 unique words, then <i>P ("hi" | ham) = (1 + 1) / (8 + 1 * 10) = 2/18 = 1/9</i> with a blur factor z = 1. And the zero probability ceases to be such: <i>P ("bro" | ham) = (0 + 1) / (8 + 1 * 10) = 1/18</i> . <br><br>  From the Bayesian point of view, this method corresponds to the mathematical expectation of the a posteriori distribution, using the <a href="http://en.wikipedia.org/wiki/Dirichlet_distribution">Dirichlet distribution</a> parameterized by the parameter z as the prior distribution. <br><br><h4>  Experiment and code </h4><br>  I use a database downloaded from the <a href="http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/">University of Campinas</a> website, which contains 4827 normal SMS messages (ham) and 747 spam messages. <br><br>  I did not do any serious preprocessing of the text, such as <a href="http://en.wikipedia.org/wiki/Stemming">stemming</a> , only a few simple operations: <br><ul><li>  reduced the text to lower case letters </li><li>  removed all punctuation marks </li><li>  all numeric sequences replaced by one </li></ul><br><br><div class="spoiler">  <b class="spoiler_title">Pretreatment code</b> <div class="spoiler_text"><pre> <code class="java hljs">PreprocessSentence &lt;- function(s) { # Cut and make some preprocessing with input sentence words &lt;- strsplit(gsub(pattern=<span class="hljs-string"><span class="hljs-string">"[[:digit:]]+"</span></span>, replacement=<span class="hljs-string"><span class="hljs-string">"1"</span></span>, x=tolower(s)), <span class="hljs-string"><span class="hljs-string">'[[:punct:][:blank:]]+'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(words) } LoadData &lt;- function(fileName = <span class="hljs-string"><span class="hljs-string">"./Data/Spam/SMSSpamCollection"</span></span>) { # Read data from text file and makes simple preprocessing: # to lower <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> -&gt; replace all digit strings with <span class="hljs-number"><span class="hljs-number">1</span></span> -&gt; split with punctuation and blank characters con &lt;- file(fileName,<span class="hljs-string"><span class="hljs-string">"rt"</span></span>) lines &lt;- readLines(con) close(con) df &lt;- data.frame(lab = rep(NA, length(lines)), data = rep(NA, length(lines))) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i in <span class="hljs-number"><span class="hljs-number">1</span></span>:length(lines)) { tmp &lt;- unlist(strsplit(lines[i], <span class="hljs-string"><span class="hljs-string">'\t'</span></span>, fixed = T)) df$lab[i] &lt;- tmp[<span class="hljs-number"><span class="hljs-number">1</span></span>] df$data[i] &lt;- PreprocessSentence(tmp[<span class="hljs-number"><span class="hljs-number">2</span></span>]) } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(df) }</code> </pre><br></div></div><br><br>  The following function creates a partition of an array of data in appropriate proportions, thereby generating indices of the training, validation, and test data sets: <br><br><div class="spoiler">  <b class="spoiler_title">Separation date set</b> <div class="spoiler_text"><pre> <code class="java hljs">CreateDataSet &lt;- function(dataSet, proportions = c(<span class="hljs-number"><span class="hljs-number">0.6</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>)) { # Creates a list with indices of train, validation and test sets proportions &lt;- proportions/sum(proportions) hamIdx &lt;- which(df$lab == <span class="hljs-string"><span class="hljs-string">"ham"</span></span>) nham &lt;- length(hamIdx) spamIdx &lt;- which(df$lab == <span class="hljs-string"><span class="hljs-string">"spam"</span></span>) nspam &lt;- length(spamIdx) hamTrainIdx &lt;- sample(hamIdx, floor(proportions[<span class="hljs-number"><span class="hljs-number">1</span></span>]*nham)) hamIdx &lt;- setdiff(hamIdx, hamTrainIdx) spamTrainIdx &lt;- sample(spamIdx, floor(proportions[<span class="hljs-number"><span class="hljs-number">1</span></span>]*nspam)) spamIdx &lt;- setdiff(spamIdx, spamTrainIdx) hamValidationIdx &lt;- sample(hamIdx, floor(proportions[<span class="hljs-number"><span class="hljs-number">2</span></span>]*nham)) hamIdx &lt;- setdiff(hamIdx, hamValidationIdx) spamValidationIdx &lt;- sample(spamIdx, floor(proportions[<span class="hljs-number"><span class="hljs-number">2</span></span>]*nspam)) spamIdx &lt;- setdiff(spamIdx, spamValidationIdx) ds &lt;- list( train = sample(union(hamTrainIdx, spamTrainIdx)), validation = sample(union(hamValidationIdx, spamValidationIdx)), test = sample(union(hamIdx, spamIdx)) ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(ds) }</code> </pre><br></div></div><br><br>  Then a model is created based on the input data array: <br><br><div class="spoiler">  <b class="spoiler_title">Creating a model</b> <div class="spoiler_text"><pre> <code class="java hljs">CreateModel &lt;- function(data, laplaceFactor = <span class="hljs-number"><span class="hljs-number">0</span></span>) { # creates naive bayes spam classifier based on data m &lt;- list(laplaceFactor = laplaceFactor) m[[<span class="hljs-string"><span class="hljs-string">"total"</span></span>]] &lt;- length(data$lab) m[[<span class="hljs-string"><span class="hljs-string">"ham"</span></span>]] &lt;- list() m[[<span class="hljs-string"><span class="hljs-string">"spam"</span></span>]] &lt;- list() m[[<span class="hljs-string"><span class="hljs-string">"hamLabelCount"</span></span>]] &lt;- sum(data$lab == <span class="hljs-string"><span class="hljs-string">"ham"</span></span>) m[[<span class="hljs-string"><span class="hljs-string">"spamLabelCount"</span></span>]] &lt;- sum(data$lab == <span class="hljs-string"><span class="hljs-string">"spam"</span></span>) m[[<span class="hljs-string"><span class="hljs-string">"hamWordCount"</span></span>]] &lt;- <span class="hljs-number"><span class="hljs-number">0</span></span> m[[<span class="hljs-string"><span class="hljs-string">"spamWordCount"</span></span>]] &lt;- <span class="hljs-number"><span class="hljs-number">0</span></span> uniqueWordSet &lt;- c() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i in <span class="hljs-number"><span class="hljs-number">1</span></span>:length(data$lab)) { sentence &lt;- unlist(data$data[i]) uniqueWordSet &lt;- union(uniqueWordSet, sentence) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(j in <span class="hljs-number"><span class="hljs-number">1</span></span>:length(sentence)) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data$lab[i] == <span class="hljs-string"><span class="hljs-string">"ham"</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(is.<span class="hljs-keyword"><span class="hljs-keyword">null</span></span>(m$ham[[sentence[j]]])) { m$ham[[sentence[j]]] &lt;- <span class="hljs-number"><span class="hljs-number">1</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { m$ham[[sentence[j]]] &lt;- m$ham[[sentence[j]]] + <span class="hljs-number"><span class="hljs-number">1</span></span> } m[[<span class="hljs-string"><span class="hljs-string">"hamWordCount"</span></span>]] &lt;- m[[<span class="hljs-string"><span class="hljs-string">"hamWordCount"</span></span>]] + <span class="hljs-number"><span class="hljs-number">1</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data$lab[i] == <span class="hljs-string"><span class="hljs-string">"spam"</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(is.<span class="hljs-keyword"><span class="hljs-keyword">null</span></span>(m$spam[[sentence[j]]])) { m$spam[[sentence[j]]] &lt;- <span class="hljs-number"><span class="hljs-number">1</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { m$spam[[sentence[j]]] &lt;- m$spam[[sentence[j]]] + <span class="hljs-number"><span class="hljs-number">1</span></span> } m[[<span class="hljs-string"><span class="hljs-string">"spamWordCount"</span></span>]] &lt;- m[[<span class="hljs-string"><span class="hljs-string">"spamWordCount"</span></span>]] + <span class="hljs-number"><span class="hljs-number">1</span></span> } } } m[[<span class="hljs-string"><span class="hljs-string">"uniqueWordCount"</span></span>]] &lt;- length(uniqueWordSet) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(m) }</code> </pre><br></div></div><br><br>  The last function for the model classifies the incoming message using the trained model: <br><br><div class="spoiler">  <b class="spoiler_title">Message classification</b> <div class="spoiler_text"><pre> <code class="java hljs">ClassifySentense &lt;- function(s, model, preprocess = T) { # calculate <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">the</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">input</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sentence</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">based</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">on</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">the</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">model</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GetCount</span></span></span><span class="hljs-class"> &lt;- </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">function</span></span></span><span class="hljs-class">(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">w</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ls</span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(is.<span class="hljs-keyword"><span class="hljs-keyword">null</span></span>(ls[[w]])) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(<span class="hljs-number"><span class="hljs-number">0</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(ls[[w]]) } words &lt;- unlist(s) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(preprocess) { words &lt;- unlist(PreprocessSentence(s)) } ham &lt;- log(model$hamLabelCount/(model$hamLabelCount + model$spamLabelCount)) spam &lt;- log(model$spamLabelCount/(model$hamLabelCount + model$spamLabelCount)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i in <span class="hljs-number"><span class="hljs-number">1</span></span>:length(words)) { ham &lt;- ham + log((GetCount(words[i], model$ham) + model$laplaceFactor) /(model$hamWordCount + model$laplaceFactor*model$uniqueWordCount)) spam &lt;- spam + log((GetCount(words[i], model$spam) + model$laplaceFactor) /(model$spamWordCount + model$laplaceFactor*model$uniqueWordCount)) } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(ham &gt;= spam) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(<span class="hljs-string"><span class="hljs-string">"ham"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(<span class="hljs-string"><span class="hljs-string">"spam"</span></span>) }</code> </pre><br></div></div><br><br>  To test the model on the set, use the following function: <br><br><div class="spoiler">  <b class="spoiler_title">Model testing</b> <div class="spoiler_text"><pre> <code class="java hljs">TestModel &lt;- function(data, model) { # calculate percentage of errors errors &lt;- <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i in <span class="hljs-number"><span class="hljs-number">1</span></span>:length(data$lab)) { predictedLabel &lt;- ClassifySentense(data$data[i], model, preprocess = F) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(predictedLabel != data$lab[i]) { errors &lt;- errors + <span class="hljs-number"><span class="hljs-number">1</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(errors/length(data$lab)) }</code> </pre><br></div></div><br><br>  To find the optimal blur ratio, <a href="http://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-qualification</a> on the corresponding set is used: <br><br><div class="spoiler">  <b class="spoiler_title">Cross-qualification model</b> <div class="spoiler_text"><pre> <code class="java hljs">CrossValidation &lt;- function(trainData, validationData, laplaceFactorValues, showLog = F) { cvErrors &lt;- rep(NA, length(laplaceFactorValues)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i in <span class="hljs-number"><span class="hljs-number">1</span></span>:length(laplaceFactorValues)) { model &lt;- CreateModel(trainData, laplaceFactorValues[i]) cvErrors[i] &lt;- TestModel(validationData, model) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(showLog) { print(paste(laplaceFactorValues[i], <span class="hljs-string"><span class="hljs-string">": error is "</span></span>, cvErrors[i], sep=<span class="hljs-string"><span class="hljs-string">""</span></span>)) } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(cvErrors) }</code> </pre><br></div></div><br><br>  The following code reads the data, creates models for the blur parameter values ‚Äã‚Äãfrom 0 to 10, selects the best result, tests the model on the previously unused test set, and then builds a graph of the error change on the cross-validation set from the blur parameter and the final error level on the test set: <br><br><pre> <code class="java hljs">rm(list = ls()) source(<span class="hljs-string"><span class="hljs-string">"./Spam/spam.R"</span></span>) set.seed(<span class="hljs-number"><span class="hljs-number">14880</span></span>) fileName &lt;- <span class="hljs-string"><span class="hljs-string">"./Data/Spam/SMSSpamCollection"</span></span> df &lt;- LoadData() ds &lt;- CreateDataSet(df, proportions = c(<span class="hljs-number"><span class="hljs-number">0.7</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>)) laplaceFactorValues &lt;- <span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span> cvErrors &lt;- CrossValidation(df[ds$train, ], df[ds$validation, ], <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span>, showLog = T) bestLaplaceFactor &lt;- laplaceFactorValues[which(cvErrors == min(cvErrors))] model &lt;- CreateModel(data=df[ds$train, ], laplaceFactor=bestLaplaceFactor) testResult &lt;- TestModel(df[ds$test, ], model) plot(cvErrors, type=<span class="hljs-string"><span class="hljs-string">"l"</span></span>, col=<span class="hljs-string"><span class="hljs-string">"blue"</span></span>, xlab=<span class="hljs-string"><span class="hljs-string">"Laplace Factor"</span></span>, ylab=<span class="hljs-string"><span class="hljs-string">"Error Value"</span></span>, ylim=c(<span class="hljs-number"><span class="hljs-number">0</span></span>, max(cvErrors))) title(<span class="hljs-string"><span class="hljs-string">"Cross validation and test error value"</span></span>) abline(h=testResult, col=<span class="hljs-string"><span class="hljs-string">"red"</span></span>) legend(bestLaplaceFactor, max(cvErrors), c(<span class="hljs-string"><span class="hljs-string">"cross validation values"</span></span>, <span class="hljs-string"><span class="hljs-string">"test value level"</span></span>), cex=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, col=c(<span class="hljs-string"><span class="hljs-string">"blue"</span></span>, <span class="hljs-string"><span class="hljs-string">"red"</span></span>), lty=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><br><img src="http://habrastorage.org/storage2/a06/cf2/5b1/a06cf25b175bc868f2af2fbddf6a665e.png"><br><br>  All code can be <a href="https://github.com/mephistopheies/ml-r">downloaded from github</a> . <br><br><h4>  Conclusion </h4><br>  As you can see, this method is very effective even with simple preprocessing, the error rate on the test set (the ratio of incorrectly classified messages to the total number of messages) is only <b>2.32%</b> .  Where can you use this method?  For example, there are a lot of comments on your site, you have recently entered a rating of comments from 1 to 5, and you have only a small part of it with the rating placed by people;  then you can automatically arrange more or less relevant ratings for the remaining comments. </div><p>Source: <a href="https://habr.com/ru/post/184574/">https://habr.com/ru/post/184574/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../184560/index.html">VKontakte iOS SDK</a></li>
<li><a href="../184562/index.html">Thread concurrency C ++ 11, your bike technology (Apple) GCD</a></li>
<li><a href="../184566/index.html">LinkMeUp. Release 4</a></li>
<li><a href="../184570/index.html">Digest of new MSDN materials in Russian for May and June</a></li>
<li><a href="../184572/index.html">Port "Age of Empires" for smartphones will be released before the end of the year</a></li>
<li><a href="../184576/index.html">Carberp source leaks are a big hit to user security.</a></li>
<li><a href="../184578/index.html">Automate the deployment of Play! Framework applications on the platform OpenShift</a></li>
<li><a href="../184580/index.html">Scientists have created the most detailed 3D model of the human brain</a></li>
<li><a href="../184584/index.html">The quadcopter on the radio has received sufficient funding on Kickstarter</a></li>
<li><a href="../184590/index.html">The influence of buns on the choice of the company: Student Edition</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>