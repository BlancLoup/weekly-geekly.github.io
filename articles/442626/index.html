<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Habrarating: building a cloud of Russian-language words on the example of Habr's headlines</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr. 

 In the last part of Habraraiting, a method of constructing a word cloud for English terms was published. Of course, the task of parsing R...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Habrarating: building a cloud of Russian-language words on the example of Habr's headlines</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr. <br><br>  In the last part of Habraraiting, a method of constructing a word cloud for English terms was published.  Of course, the task of parsing Russian words is much more complicated, but as suggested in the comments, there are ready-made libraries for this. <br><br>  We will understand how to build such a picture: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/8c/ct/a6/8ccta6jikwu2sfopuhf7fdpetgu.png"><br><br>  Also look at the cloud of Habr's articles for all the years. <br><br>  Who cares what happened, please under the cat. <br><a name="habracut"></a><br><h2>  Parsing </h2><br>  The original dataset, as in the previous case, is a csv with titles of Habr's articles from 2006 to 2019.  If anyone is interested to try it yourself, download it <a href="https://cloud.mail.ru/public/GgYT/KEXDzixsS">here</a> . <br><br>  First, load the data into the Pandas Dataframe and sample the headings for the required year. <br><br><pre><code class="python hljs">df = pd.read_csv(log_path, sep=<span class="hljs-string"><span class="hljs-string">','</span></span>, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>, error_bad_lines=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, quotechar=<span class="hljs-string"><span class="hljs-string">'"'</span></span>, comment=<span class="hljs-string"><span class="hljs-string">'#'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> year != <span class="hljs-number"><span class="hljs-number">0</span></span>: dates = pd.to_datetime(df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>], format=<span class="hljs-string"><span class="hljs-string">'%Y-%m-%dT%H:%MZ'</span></span>) df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] = dates df = df[(df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] &gt;= pd.Timestamp(datetime.date(year, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))) &amp; ( df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] &lt; pd.Timestamp(datetime.date(year + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)))] <span class="hljs-comment"><span class="hljs-comment"># Remove some unicode symbols def unicode2str(s): try: return s.replace(u'\u2014', u'-').replace(u'\u2013', u'-').replace(u'\u2026', u'...').replace(u'\xab', u"'").replace(u'\xbb', u"'") except: return s titles = df["title"].map(unicode2str, na_action=None)</span></span></code> </pre> <br>  The unicode2str function is needed to remove various cunning Unicode characters from the console output, such as nonstandard quotes - under OSX this worked the same way, and when outputting to Windows Powershell, the error ‚ÄúUnicodeEncodeError: 'charmap' codec can't encode character‚Äù was generated.  It was too lazy to deal with Powershell settings, so this was the easiest way. <br><br>  The next step is to separate the Russian words from all the others.  It's quite simple - we translate characters into ascii encoding, and see what remains.  If there are more than 2 characters left, then we consider the word ‚Äúfull-fledged‚Äù (the only exception that comes to mind is the Go language, however, those who wish can add it themselves). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_ascii</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: s = s.replace(<span class="hljs-string"><span class="hljs-string">"'"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>).replace(<span class="hljs-string"><span class="hljs-string">"-"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>).replace(<span class="hljs-string"><span class="hljs-string">"|"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>).encode(<span class="hljs-string"><span class="hljs-string">"ascii"</span></span>, errors=<span class="hljs-string"><span class="hljs-string">"ignore"</span></span>).decode() <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">is_asciiword</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> ascii_word = to_ascii(s) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(ascii_word) &gt; <span class="hljs-number"><span class="hljs-number">2</span></span></code> </pre><br>  The next task is the normalization of the word - to display a word cloud, each word must be output in one case and declination.  For the English language, we simply remove the "'s" at the end, also remove other unreadable characters such as parentheses.  I'm not sure that this method is scientifically correct (and I am not a linguist), but for this task it is quite enough. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normal_eng</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> sym <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (<span class="hljs-string"><span class="hljs-string">"'s"</span></span>, <span class="hljs-string"><span class="hljs-string">'{'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>, <span class="hljs-string"><span class="hljs-string">"'"</span></span>, <span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>, <span class="hljs-string"><span class="hljs-string">';'</span></span>, <span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">'['</span></span>, <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'('</span></span>, <span class="hljs-string"><span class="hljs-string">')'</span></span>, <span class="hljs-string"><span class="hljs-string">'-'</span></span>, <span class="hljs-string"><span class="hljs-string">'/'</span></span>, <span class="hljs-string"><span class="hljs-string">'\\'</span></span>): s = s.replace(sym, <span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s.lower().strip()</code> </pre><br>  Now the most important thing for the sake of which everything actually was started is the parsing of Russian words.  As advised in the comments to the previous part, for Python this can be done using the library pymorphy2.  Let's see how it works. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pymorphy2 morph = pymorphy2.MorphAnalyzer() res = morph.parse(<span class="hljs-string"><span class="hljs-string">u""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> r.normal_form, r.tag.case</code> </pre> <br>  For this example, we have the following results: <br><br><pre> <code class="python hljs"> NOUN,inan,masc sing,datv datv  NOUN,inan,masc sing,loc2 loc2  NOUN,inan,neut sing,datv datv  NOUN,inan,masc sing,gen2 gen2</code> </pre><br>  For the word ‚Äúworld‚Äù, MorphAnalyzer defined ‚Äúnormal form‚Äù as a noun ‚Äúpeace‚Äù (or ‚Äúmiro‚Äù, however, I don‚Äôt know what it is), a single number (sing), and possible cases like dativ, genitiv or locative. <br><br>  With the use of MorphAnalyzer, the parsing is quite simple - we make sure that the word is a noun, and we derive its normal form. <br><br><pre> <code class="python hljs">morph = pymorphy2.MorphAnalyzer() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normal_rus</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(w)</span></span></span><span class="hljs-function">:</span></span> res = morph.parse(w) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'NOUN'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> r.tag: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> r.normal_form <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span></code> </pre><br>  It remains to put everything together, and see what happened.  The code looks like this (non-essential fragments removed): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Counter c_dict = Counter() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> titles.values: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> s.split(): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> is_asciiword(w): <span class="hljs-comment"><span class="hljs-comment"># English word or digit n = normal_eng(w) c_dict[n] += 1 else: # Russian word n = normal_rus(w) if n is not None: c_dict[n] += 1</span></span></code> </pre><br>  At the output we have a dictionary of words and their numbers of occurrences.  Let's output the first 100 and form a word popularity cloud from them: <br><br><pre> <code class="python hljs">common = c_dict.most_common(<span class="hljs-number"><span class="hljs-number">100</span></span>) wc = WordCloud(width=<span class="hljs-number"><span class="hljs-number">2600</span></span>, height=<span class="hljs-number"><span class="hljs-number">2200</span></span>, background_color=<span class="hljs-string"><span class="hljs-string">"white"</span></span>, relative_scaling=<span class="hljs-number"><span class="hljs-number">1.0</span></span>, collocations=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, min_font_size=<span class="hljs-number"><span class="hljs-number">10</span></span>).generate_from_frequencies(dict(common)) plt.axis(<span class="hljs-string"><span class="hljs-string">"off"</span></span>) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>)) plt.imshow(wc, interpolation=<span class="hljs-string"><span class="hljs-string">"bilinear"</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"%d"</span></span> % year) plt.xticks([]) plt.yticks([]) plt.tight_layout() file_name = <span class="hljs-string"><span class="hljs-string">'habr-words-%d.png'</span></span> % year plt.show()</code> </pre><br>  The result, however, turned out to be very strange: <br><br><img src="https://habrastorage.org/webt/eo/3e/is/eo3eisf-_suvjfhpempv5m4juhk.png"><br><br>  In text form, it looked like this: <br><br><pre> <code class="python hljs">  <span class="hljs-number"><span class="hljs-number">3958</span></span>  <span class="hljs-number"><span class="hljs-number">3619</span></span>  <span class="hljs-number"><span class="hljs-number">1828</span></span>  <span class="hljs-number"><span class="hljs-number">840</span></span> <span class="hljs-number"><span class="hljs-number">2018</span></span> <span class="hljs-number"><span class="hljs-number">496</span></span>  <span class="hljs-number"><span class="hljs-number">389</span></span>  <span class="hljs-number"><span class="hljs-number">375</span></span>  <span class="hljs-number"><span class="hljs-number">375</span></span></code> </pre><br>  The words "performing", "second" and "century" were leading by a wide margin.  And although this is possible in principle (you can imagine a title like ‚ÄúPassing passwords at a speed of 1000 times per second will take a century‚Äù), but it was still suspicious that there are so many of these words.  And not in vain - as debugging showed, MorphAnalyzer defined the word "c" as "second", and the word "c" as "century".  Those.  in the heading "With the help of technology ..." MorphAnalyzer singled out 3 words - "second", "help", "technology", which is obviously wrong.  The following incomprehensible words were ‚Äúwhen‚Äù (‚ÄúWhen used ...‚Äù) and ‚Äúalready‚Äù, which were defined as the noun ‚Äústraight‚Äù and ‚Äúalready‚Äù, respectively.  The solution was simple - take into account when parsing only words longer than 2 characters, and enter a list of Russian-language exception words that would be excluded from the analysis.  Again, maybe this is not entirely scientific (for example, an article about ‚Äúobserving changes in coloring already‚Äù would fall out of the analysis), but for this task already :) is enough. <br><br>  The final result is more or less similar to the truth (with the exception of Go and possible articles about the tips).  It remains to save all this in gif (the gif generation code is in the <a href="https://habr.com/ru/post/442168/">previous part</a> ), and we get the animated result in the form of the popularity of keywords in the Habr headlines from 2006 to 2019. <br><br><img src="https://habrastorage.org/webt/gw/pq/ef/gwpqeflpg6h6wd8f30xiwr_irnk.gif"><br><br><h2>  Conclusion </h2><br>  As you can see, the analysis of the Russian text with the help of ready-made libraries turned out to be quite simple.  Of course, with some reservations - the spoken language is a flexible system with many exceptions and the dependence of the meaning on the context, and 100% authenticity here is probably impossible to get at all.  But for the task, the above code is enough. <br><br>  The work with Cyrillic texts in Python, by the way, is far from perfect - minor problems with character output to the console, idle print output for print, the need to add u "" lines for Python 2.7, etc. It is strange that in the 21st century, when like all atavisms like KOI8-R or CP-1252 died out, the problems of encoding strings are still relevant. <br><br>  Finally, it is interesting to note that the addition of Russian words to the text cloud practically did not increase the informativeness of the picture compared to the <a href="">English version</a> - almost all IT terms are English-speaking, so the list of Russian words changed much less in 10 years.  Probably, to see the changes in the Russian language, you have to wait 50-100 years - after a specified time, there will be an occasion to update the article again;) </div><p>Source: <a href="https://habr.com/ru/post/442626/">https://habr.com/ru/post/442626/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../442616/index.html">Overclock event handling up to 1.6 million per second</a></li>
<li><a href="../442618/index.html">Not for Selfies: Digital ELISA with a new chip embedded in a smartphone</a></li>
<li><a href="../442620/index.html">Machine learning in IT monitoring</a></li>
<li><a href="../442622/index.html">How to make Korutin in Unity a little more convenient</a></li>
<li><a href="../442624/index.html">The book "The perfect algorithm. Basics</a></li>
<li><a href="../442628/index.html">Methods for effective transformation of information based on the modified Bailey-Borwein-Plaff formula</a></li>
<li><a href="../442630/index.html">The durability of LED lamps and reduced luminous flux</a></li>
<li><a href="../442632/index.html">Geothermal energy: how the heat of the Earth turned into an effective energy resource</a></li>
<li><a href="../442636/index.html">Do you bring bad news to management?</a></li>
<li><a href="../442638/index.html">App-based Kubernetes metrics scaling from Prometheus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>