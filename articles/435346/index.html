<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Subscribe to Kafka via HTTP or how to simplify your own web-hooks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="There are many ways to handle messages from Pub-Sub systems: using a separate service, isolating an isolated process, orchestrating a process / thread...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Subscribe to Kafka via HTTP or how to simplify your own web-hooks</h1><div class="post__text post__text-html js-mediator-article">  There are many ways to handle messages from Pub-Sub systems: using a separate service, isolating an isolated process, orchestrating a process / thread pool, complex IPCs, Poll-over-Http, and many others.  Today I want to talk about how to use Pub-Sub over HTTP and about my service, written specifically for this. <br><br>  Using a ready-made HTTP service backend in some cases is an ideal solution for processing message queues: <br><br><ol><li>  Balancing out of the box.  Usually, the backend is already behind the balancer and has an infrastructure ready for loads, which greatly simplifies the work with messages. </li><li>  Use a regular REST controller (any HTTP resource).  Consumption of messages via HTTP minimizes the costs of implementing users for different languages, if the backend is motley. </li><li>  Simplify the use of other services web hooks.  Now almost every service (Jira, Gitlab, Mattermost, Slack ...) somehow supports Web hooks to interact with the outside world.  You can make life easier if you teach the queue to perform the functions of the HTTP dispatcher. </li></ol><br>  This approach has disadvantages: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  You can forget about the lightness of the solution.  HTTP is a heavy protocol, and the use of frameworks on the side of the consumer will instantly lead to an increase in latency and load. </li><li>  We lose the strengths of the Poll approach by getting Push weaknesses. </li><li>  Processing messages by the same service instances that process clients can affect responsiveness.  This is irrelevant, as it is treated by balancing and isolation. </li></ol><br>  I implemented the idea as a Queue-Over-Http service, which will be discussed later.  The project is written in Kotlin using Spring Boot 2.1.  As a broker, now only Apache Kafka is available. <br><a name="habracut"></a><br>  <i>Further in the article it is assumed that the reader is familiar with Kafka and knows about commits (commit) and offsets (offset) of messages, principles of groups (group) and consumers (consumer), and also understands how the partition (partition) differs from the topic (topic) .</i>  <i>If there are gaps, I advise you to read <a href="https://kafka.apache.org/documentation/">this</a> section of the Kafka documentation before continuing reading.</i> <br><br><h1>  Content </h1><br><ul><li>  <a href="https://habr.com/ru/post/435346/">Overview</a> </li><li>  <a href="https://habr.com/ru/post/435346/">Commits</a> </li><li>  <a href="https://habr.com/ru/post/435346/">Error processing</a> </li><li>  <a href="https://habr.com/ru/post/435346/">Messages</a> </li><li>  <a href="https://habr.com/ru/post/435346/">Performance</a> </li><li>  <a href="https://habr.com/ru/post/435346/">Demonstration</a> </li><li>  <a href="https://habr.com/ru/post/435346/">Conclusion</a> </li></ul><br><a name="overview"></a><h1>  Overview </h1><br>  Queue-Over-Http is a service that acts as an intermediary between the message broker and the final HTTP provider (the service makes it easy to implement support for sending messages to conservators in any other way, for example, various * RPCs).  At the moment, only subscription, unsubscribe, and browsing the list of consumer designers are available. Sending messages to the broker (produce) via HTTP has not yet been implemented because it is impossible to guarantee the order of messages without special support from the producer. <br><br>  The key figure of the service is the consumer manager, who can subscribe to specific partitions or simply to topics (the topic pattern is supported).  In the first case, the auto balance of the partitions is turned off.  After subscribing, the specified HTTP resource starts to receive messages from the assigned Kafka partitions.  Architecturally, each subscriber is associated with the Kafka native Java client. <br><br><div class="spoiler">  <b class="spoiler_title">an entertaining story about KafkaConsumer</b> <div class="spoiler_text">  Kafka has a great Java client that can do a lot.  I use it in the queue adapter to receive messages from the broker and then send it to the local service queues.  It is worth mentioning that the client works exclusively in the context of a single thread. <br><br>  The idea of ‚Äã‚Äãthe adapter is simple.  We start in one thread, we write the simplest scheduler of native clients, with an emphasis on reducing latency.  That is, we write something similar: <br><br><pre><code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (!Thread.interrupted()) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> hasWork = <span class="hljs-literal"><span class="hljs-literal">false</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (consumer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> kafkaConsumers) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> queueGroup = consumers[consumer] ?: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> invalidateSubscription(consumer, queueGroup) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> records = consumer.poll(Duration.ZERO) <span class="hljs-comment"><span class="hljs-comment">/*      */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!records.isEmpty) { hasWork = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> committed = doCommit() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!hasWork &amp;&amp; committed == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// ,    Thread.sleep(1) } }</span></span></code> </pre> <br>  It would seem that everything is fine, latency is minimal even if there are dozens of consultants.  In practice, it turned out that <code>KafkaConsumer</code> for such a mode of operation and gives the allocation rate about 1.5 MB / s to idle.  With 100 conservatives, the allocation rate reaches 150 MB / s and makes the GC more often recall the application.  Of course, all this garbage is in the young area, GC copes with it, but still, the solution is not perfect. <br><br>  Obviously, you need to go in a typical way for <code>KafkaConsumer</code> , and each subscriber is now placed in his stream.  This gives an overhead of memory and dispatch, but there is no other way out. <br><br>  I rewrite the code from above, removing the inner loop and changing <code>Duration.ZERO</code> to <code>Duration.ofMillis(100)</code> .  It turns out well, the allocation rate drops to an acceptable 80-150 KB / s per binsmith.  However, the Poll with a 100ms timeout delays the entire commit queue for these same 100ms, and this is unacceptable a lot. <br><br>  In the process of finding solutions to the problem, I remember about <code>KafkaConsumer::wakeup</code> , which throws a <code>WakeupException</code> and interrupts any blocking operation on the consumer store.  With this method, the path to low-latency is simple: when a new request for a commit arrives, we put it in the queue, and on the native bureaucrater we call <code>wakeup</code> .  In the working cycle we catch <code>WakeupException</code> and go to commit what has accumulated.  For the transfer of control with the help of exceptions, you need to immediately give hands, but since there is no other way ... <br><br>  It turns out that this option is far from perfect, since any operation on the native bureaucrater is now throwing out a <code>WakeupException</code> , including the commit itself.  Handling this situation will charge the code that allows <code>wakeup</code> . <br><br>  I come to the conclusion that it would be a good idea to modify the <code>KafkaConsumer::poll</code> method so that it can be interrupted in a regular manner, using an additional flag.  As a result, <a href="https://github.com/viirtus/queue-over-">Frankenstein</a> was born from reflection, which exactly copies the original poll method, adding a loop out of the flag.  This flag is set by a separate interruptPoll method, which, moreover, on the client's selector causes a wakeup to unlock the thread on an I / O operation. <br><br>  Having implemented a client in this way, I get a reaction rate from the moment a request is received for a commit before it is processed up to 100 microseconds, and an excellent latency on a selection of messages from a broker, which is fine. <br></div></div><br>  Each partition is represented by a separate local queue where the adapter writes messages from the broker.  A worker collects messages from it and sends them to execution, that is, to send via HTTP. <br><br>  The service supports batch processing of messages to increase throughput.  When subscribing, you can specify the <code>concurrencyFactor</code> each topic (applies to each assigned partition independently).  For example, <code>concurrencyFactor=1000</code> means that 1000 messages can be sent to the consumer at the same time as HTTP requests.  As soon as all messages from the pack have been unequivocally worked out by the consultant, the service decides on the next commit of the last set in the order of the message to Kafka.  Hence the second value of <code>concurrencyFactor</code> is the maximum number of re-processed messages by the consumer in the event of a Kafka or Queue-Over-Http crash. <br><br>  To reduce delays, the queue has <code>loadFactor = concurrencyFactor * 2</code> , which allows you to read twice as many messages from a broker than can be sent.  Since the autocommit on the native client is disabled, such a scheme does not violate At-Least-Once warranties. <br>  A high value of <code>concurrencyFactor</code> increases the throughput of the queue (throughput) by reducing the number of commits that take up to 10 ms in the worst case.  At the same time, the load on the consumer increases. <br><br>  The sequence of sending messages within a packet is not guaranteed, but it can be achieved if you set <code>concurrencyFactor=1</code> . <br><br><a name="commits"></a><h1>  Commits </h1><br>  Commits are an important part of the service.  When the next data packet is ready, the offset of the last message from the packet is immediately committed to Kafka, and only after a successful commit does the next packet become available for processing.  Often this is not enough and autocommit is required.  To do this, there is the <code>autoCommitPeriodMs</code> parameter, which has little to do with the classic autocommit period for native clients who commit the last message read from the partition.  Imagine that <code>concurrencyFactor=10</code> .  The service sent all 10 messages and waits for each of them to be ready.  The processing of message 3 is completed first, then message 1, and then message 10. At this point, the time of autocommit occurs.  It is important not to break the At-Least-Once semantics.  Therefore, you can commit only the first message, that is, offset 2, since only it has been successfully processed at this moment.  Further, until the next auto-commit, messages 2, 5, 6, 4, and 8 are processed. Now you need to commit only offset 7, and so on.  Autocommit has almost no effect on throughput. <br><br><a name="errors"></a><h1>  Error processing </h1><br>  In the normal mode of operation, the service sends a message to the master once.  If for some reason it caused a 4xx or 5xx error, the service will re-send the message, waiting for successful processing.  The time between attempts can be configured as a separate parameter. <br><br>  It is also possible to set the number of attempts after which the message will be marked as processed, which will stop the re-sending regardless of the response status.  I do not advise using it for sensitive data, situations of failure of consumers should always be corrected manually.  Sticking messages can be monitored by the service logs and monitoring the status of the response of the consumerizer. <br><br><div class="spoiler">  <b class="spoiler_title">about sticking</b> <div class="spoiler_text">  Usually, the HTTP server, giving the 4xx or 5xx status of the response, also sends a <code>Connection: close</code> header.  A TCP connection thus closed remains in the <code>TIME_WAITED</code> status until it is cleared by the operating system after some time.  The problem is that such connections occupy a whole port that cannot be reused until it is released.  This can result in the absence of free ports on the machine to establish a TCP connection and the service will be strewn with exceptions in the logs for each send.  In practice, on Windows 10 ports end after 10‚Äì20 thousand dispatch of erroneous messages within 1-2 minutes.  In standard operation, this is not a problem. <br></div></div><br><a name="messages"></a><h1>  Messages </h1><br>  Each message retrieved from the broker is sent to HTTP to the resource specified by the subscriber during the subscription.  By default, the message is sent by a POST request in the body.  This behavior can be changed by specifying any other method.  If the method does not support sending data in the body, you can specify the name of the string parameter in which the message will be sent.  In addition, when subscribing, you can specify additional headers that will be added to each message, which is convenient for basic authorization using tokens.  Headers are added to each message with the identifier of the consumer‚Äôs designer, the topic and the partition from which the message was read, the message number, the partition key, if applicable, and the name of the broker itself. <br><br><a name="performance"></a><h1>  Performance </h1><br>  To evaluate the performance, I used a PC (Windows 10, OpenJDK-11 (G1 without tuning), i7-6700K, 16GB), on which the service and laptop (Windows 10, i5-8250U, 8GB) are running, on which the message producer was spinning, HTTP -resource konsyumera and Kafka with default settings.  The PC is connected to the router via a 1Gb / s wired connection, a laptop using 802.11ac.  The producer records messages, 110 bytes long, every 100 ms within 1000 seconds, into assigned topics subscribed to by consumer designers ( <code>concurrencyFactor=500</code> , autocommit is off) from different groups.  The stand is far from ideal, but you can get some picture. <br><br>  The key measured parameter is the effect of the service on latency. <br><br>  Let be: <br>  - t <sub>q</sub> - timestamp of the service receiving the message from the native client <br>  - d <sub>t0</sub> - time between t <sub>q</sub> and the time of sending the message from the local queue to the pool of executors <br>  - d <sub>t</sub> - time between t <sub>q</sub> and the time of sending the HTTP request.  D <sub>t</sub> is the influence of the service on the latency of the message. <br><br>  During the measurements, the following results were obtained (C - Consumer, T - Topics, M - Messages): <br><br><img src="https://habrastorage.org/webt/p4/r7/pq/p4r7pqavkke1d3glzc7u8o6a5gu.png"><br><br>  In the standard mode of operation, the service itself has almost no effect on latency, and memory consumption is minimal.  The maximum values ‚Äã‚Äãof d <sub>t</sub> (about 60 ms) are not specifically indicated, as they depend on the operation of the GC, and not on the service itself.  Smoothing the spread of maximum values ‚Äã‚Äãcan help special tuning GC or replacing the G1 on Shenandoah. <br><br>  Everything changes dramatically when the consumer does not cope with the flow of messages from the queue and the service turns on the trotting mode.  In this mode, memory consumption increases, as the response time to queries grows dramatically, which prevents timely cleaning of resources.  The effect on latency here remains at the level with previous results, and high dt values ‚Äã‚Äãare caused by preloading messages into the local queue. <br><br>  Unfortunately, it is not possible to test at a higher load, since the laptop is already bent at 1300 RPS.  If someone can help with the organization of measurements at high loads, I will be happy to provide an assembly for the tests. <br><br><a name="demo"></a><h1>  Demonstration </h1><br>  We now turn to the demonstration.  For this we need: <br><br><ul><li>  Kafka broker, ready to go.  I will take raised on 192.168.99.100:9092 from Bitnami. </li><li>  An HTTP resource that will receive messages.  For clarity, I took the Web-hooks from Slack. </li></ul><br>  First of all, you need to raise the Queue-Over-Http service itself.  To do this, create in the empty <code>application.yml</code> directory as follows: <br><br><pre> <code class="plaintext hljs">spring: profiles: default logging: level: com: viirrtus: queueOverHttp: DEBUG app: persistence: file: storageDirectory: "persist" brokers: - name: "Kafka" origin: "kafka" config: bootstrap.servers: "192.168.99.100:9092"</code> </pre><br>  Here we indicate to the service the connection parameters of a specific broker, as well as where to store subscribers, so that between launches they are not lost.  In `app.brokers []. Config`, you can specify any connection parameters supported by the native Kafka client, the full list can be found <a href="">here</a> . <br><br>  Since the configuration file is processed by Spring, you can write a lot of interesting things there.  Including, customize logging. <br><br>  Now we start the service itself.  We use the easiest way - <code>docker-compose.yml</code> : <br><br><pre> <code class="plaintext hljs">version: "2" services: app: image: viirrtus/queue-over-http:0.1.3 restart: unless-stopped command: --debug ports: - "8080:8080" volumes: - ./application.yml:/application.yml - ./persist:/persist</code> </pre><br>  <i>If this option does not suit you, you can build the service from source.</i>  <i>Assembly instructions in the project's Readme, a link to which is given at the end of the article.</i> <br><br>  The next step is to register the first subscriber.  To do this, you must perform an HTTP request to the service with a description of the Consumer: <br><br><pre> <code class="plaintext hljs">POST localhost:8080/broker/subscription Content-Type: application/json { "id": "my-first-consumer", "group": { "id": "consumers" }, "broker": "Kafka", "topics": [ { "name": "slack.test", "config": { "concurrencyFactor": 10, "autoCommitPeriodMs": 100 } } ], "subscriptionMethod": { "type": "http", "delayOnErrorMs": 1000, "retryBeforeCommit": 10, "uri": "&lt;slack-wh-uri&gt;", "additionalHeaders": { "Content-Type": "application/json" } } }</code> </pre><br>  If everything went well, the response will be almost the same content sent. <br><br>  Let's go over each parameter: <br><br><ul><li>  <code>Consumer.id</code> - our subscriber ID </li><li>  <code>Consumer.group.id</code> - group id </li><li>  <code>Consumer.broker</code> - we indicate which service broker to subscribe to </li><li>  <code>Consumer.topics[0].name</code> - the name of the topic from which we want to receive messages </li><li> <code>Consumer.topics[0].config. concurrencyFactor</code>  <code>Consumer.topics[0].config. concurrencyFactor</code> - the maximum number of simultaneously sent messages </li><li> <code>Consumer.topics[0].config. autoCommitPeriodMs</code>  <code>Consumer.topics[0].config. autoCommitPeriodMs</code> - period of forced commit of ready messages </li><li>  <code>Consumer.subscriptionMethod.type</code> is a subscription type.  Currently only HTTP is available. </li><li>  <code>Consumer.subscriptionMethod.delayOnErrorMs</code> - time before re-sending the message, which ended in error </li><li>  <code>Consumer.subscriptionMethod.retryBeforeCommit</code> - the number of attempts to resubmit an error message.  If 0 - the message will spin until successful processing.  In our case, the guarantee of full delivery is not as important as the constancy of flow. </li><li>  <code>Consumer.subscriptionMethod.uri</code> - a resource to which messages will be sent </li><li>  <code>Consumer.subscriptionMethod.additionalHeader</code> - additional headers that will be sent with each message.  Note that there will be JSON in the body of each message so that Slack can correctly interpret the request. </li></ul><br>  <i>In this request, the indication of the HTTP method is omitted, as the default, POST, Slack is fine.</i> <br><br>  From this point on, the service keeps track of the assigned partitions of the slack.test topic for new messages. <br><br>  To write messages to the topic, I will use the utilities built into Kafka, which are located in <code>/opt/bitnami/kafka/bin</code> of the Kafka running image (the location of the utilities in other Kafka instances may differ): <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list localhost:9092 --topic slack.test &gt; {‚Äútext‚Äù: ‚ÄúHello!‚Äù}</code> </pre><br>  At the same time, Slack will inform about the new message: <br><br><img src="https://habrastorage.org/webt/kl/eh/z7/klehz7ev6x1y2eaqpf_ylpnjic4.png"><br><br>  <i>To unsubscribe a consumer, it is enough to make a POST request for `broker / unsubscribe` with the same content as it was with the subscription.</i> <br><br><a name="the-end"></a><h1>  Conclusion </h1><br>  Currently only basic functionality is implemented.  Next, we plan to improve batching, try to implement Exactly-once semantics, add the ability to send messages to the broker via HTTP and, most importantly, add support for other popular Pub-Sub. <br><br>  The Queue-Over-Http service is currently under active development.  Version 0.1.3 is fairly stable for testing on dev and stage stands.  Performance has been tested on Windows 10, Debian 9 and Ubuntu 18.04.  Use in prod at your own risk.  If you want to help with the development or give any feedback on the service - welcome to the <a href="http">Github</a> project. </div><p>Source: <a href="https://habr.com/ru/post/435346/">https://habr.com/ru/post/435346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../435336/index.html">Something found: reports from Elasticsearch Moscow meetup in OZON</a></li>
<li><a href="../435338/index.html">Create an electronic timekeeping races</a></li>
<li><a href="../435340/index.html">Researcher posted an example of a working worm code for Facebook</a></li>
<li><a href="../435342/index.html">Homemade BadUSB on Arduino Pro Micro or Leonardo</a></li>
<li><a href="../435344/index.html">Amazon unveiled Showroom, or why we will soon be buying all the furniture online.</a></li>
<li><a href="../435348/index.html">Simple MCerver - a small shell for Minecraft server</a></li>
<li><a href="../435352/index.html">Conference DEFCON 18. Practical espionage using a mobile phone. Part 2</a></li>
<li><a href="../435354/index.html">Conference DEFCON 18. Practical espionage using a mobile phone. Part 1</a></li>
<li><a href="../435358/index.html">Antiquities: Minidisk in the Age of Ipod</a></li>
<li><a href="../435360/index.html">Snippet vs Clover - we beat the most popular quiz in real time</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>