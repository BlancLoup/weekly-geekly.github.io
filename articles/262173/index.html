<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Build-Deploy-Test. Continuous integration</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continuous Integration (eng. Continuous Integration, hereinafter CI) is the practice of software development, which is to perform frequent automated p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Build-Deploy-Test. Continuous integration</h1><div class="post__text post__text-html js-mediator-article">  <b>Continuous Integration</b> (eng. Continuous Integration, hereinafter CI) is the practice of software development, which is to perform frequent automated project builds to quickly identify and solve the problems of integrating the results of several developers. <br><br>  I emphasize that this is not a technique and not a standard, it is PRACTICE, and it implies the ongoing work and involvement of all team members.  What for?  Yes, in order not to wait for the end of the project for integration and a sudden global collapse.  In addition, the task of CI is to protect against destructive changes as a result of refactoring, adding new functionality, changes in architecture and a heap of other unforeseen or known problems. <br><br>  With the help of integration assemblies, you can get rid of the syndrome "I do not know, everything works on my machine."  We also defend ourselves from ‚Äúbad code‚Äù, often repeated bugs, ‚Äúmerge curves‚Äù.  CI increases the possibility of feedback because it allows you to monitor the status of the project throughout the day. <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>How do we come to continuity</b> <br><br>  Our company has launched a new large-scale retail project on .NET using various new-fangled technologies, SOA.  Development was carried out completely from scratch, with gradual integration between the components.  The development and <a href="http://icl-services.com/services/nezavisimoe-testirovanie/">testing of</a> components took place on different continents. <br><br>  We developed core service components.  In addition, it was necessary to test the performance and installation-removal of components.  And also there was a requirement for development - 100% code coverage with unit tests.  As a result, we have: autotests, unit tests, 4 test environments, partially implemented components, ‚Äúfalling‚Äù builds and bugs (where to without them?) And one tester for 14 developers.  And I want everything to be collected, installed, tested and deleted.  And, of course, I really want to give the most stable and high-quality result to the main testing team. <br><br>  It‚Äôs difficult to test one on 4 systems, when we have only 15 people in the team - to put it mildly.  Therefore, we decided to try the <b>Microsoft approach - Build-Deploy-Test</b> .  The following tools helped to keep up with the development of the tester: TFS 2012, MSTest Manager 2012, Visual Studio 2012 Ultimate.  Over time, moved to 2013. <br><br>  We decided to make 2 CI servers: <b>Jenkins and TFS server</b> .  At first, we had everything going once an hour in debug mode (debug mode).  Then there was installation on the server, running smoke tests (tests that the application is running), and after that the uninstallation began.  Sonar ran all the modular and integration tests once a day, at night.  This solved the problem with the instability of the assembly and the early notification of developers about the problems.  On the second CI server (TFS build server), we also had the build in debug mode.  Then the installation was carried out on a test machine and the launch of functional autotests.  After all the tests were completed (no matter whether it was successful or not), the uninstallation took place. <br><br>  We decided to make 2 CI servers in order to separate the developers 'tests (modular and integration) from the testers' functional tests.  Builds on Jenkins were done significantly more often to respond to falling tests immediately.  And assemblies on TFS were carried out by the tester, if necessary, and daily at night, since the full cycle of functional testing takes a lot of time.  In addition, so that everything was built in the Release configuration and the code, as a minimum, was always compiled, we introduced the Gated Check-in assembly.  When programmers or testers upload changes to TFS, the entire system is first assembled in the Release configuration and changes are made to TFS only if it is successful.  If there is a problem, the changes are not applied and the build in TFS remains working. <br><br>  We began automating functional tests with a selection of their types.  Microsoft offers the following: <br><br><ul><li>  <b>Unit tests</b> that programmers write. </li><li>  <b>Coded Ui Test</b> is a type of test designed to automate functional tests and test the user interface. </li><li>  <b>Web Performance Test</b> - functional testing of web applications within the framework of the organization of load tests (Load Test). </li><li>  <b>Load Test</b> - tests for load testing web applications. </li><li>  <b>Generic Test</b> is a special kind of test that allows you to run external testing applications. </li><li>  <b>Ordered Test</b> - allows you to organize the execution of all written automatic tests in a specific order. </li></ul><br>  As a result, having thought it over, we decided that <b>generic</b> and <b>ordered tests</b> would be more suitable for us. <br><br>  Generic test need to specify the * .exe file and the parameters that he needs to feed.  Each test case in TFS was associated with a generic test.  For autotests, we had one project for each component and when we run the autotest from TM, a generic test is called, which passes the current autotest number to the required * .exe file, and then the required method is executed. <br><br>  <b>The Build-Deploy-Test process</b> as a whole looks like this: developers make changes, before uploading changes, the Build Server collects everything in the Release configuration and if the build passes, the changes are uploaded to the server. <br><br><img src="https://habrastorage.org/files/e3f/5b2/84a/e3f5b284ae714150882926b7173db3a7.jpg" alt="image"><br><br>  Next in functional testing. <br><br>  According to the Build-Deploy-Test approach, there are 3 roles - <b>Build Controller (BC)</b> , <b>Test Controller (TC)</b> and <b>Test Agent (TA)</b> .  Our Build Controller is the same as our Build Server and Test Controller. <br><br>  Build Controller monitors the builds of the project, it collects the binaries in the build folder (Gated Check In is not suitable here, there were separate build configurations for testing).  Test Controller is needed for launch management, storage of test results.  And the Test Agent receives a command from the TS on the launch of a test suite, a deployment team and all launch parameters, including a generic test suite. <br><br>  The tester opens Microsoft Test Manager, selects there a test plan that he needs, a configuration for running, an assembly to be used, and a test environment.  And that's it!  The rest is done by Test Controller.  It receives a set of parameters for a test run (including the location of the folder with binaries) and starts the installation on the test environment.  After the installation script runs, the Test Agent launches all the selected tests one by one.  After all the tests have been completed, a cleanup script is launched that removes the application and, after clearing the test system, returns it to the initial state.  Then Test Agent transfers control to Test Controller, informing it of its readiness.  Test ontroller takes away all the temporary folders of the test run, puts the results in TFS (you can see them later through TM) and displays the result of tests in TM - successfully completed tests and not very successful ones. <br><br>  <b>Test environment settings</b> <br><br>  All our builds are stored on the Build Server.  There are also generic tests.  After running autotests in Microsoft Test Manager (TM), Test Controller creates a temporary folder on the test machine where it copies generic tests and creates its own deploy.bat and clean.bat files.  These scripts consist of 2 parts.  The first is the definition of all startup variables, including the name of the build directory, and the second part is the contents of our deploy file, which we specified for these test settings. <br><br>  Thus, it turns out that TC creates a wrapper for the script, which we indicated to it as the deploy script (let's call it the Call Deploy script). <br><br><img src="https://habrastorage.org/files/4b6/54f/f40/4b654ff4002645d28a3535cd4d349003.png" alt="image"><br><br>  In our case, this script copies the entire build directory to the test machine, then it calls another install script - the Deploy script that was in this build.  We need this in order for the deployment script to have versioning so that it can be updated along with the build. <br><br>  This script already performs all the preparations for the installation, since all the scripts are implemented in the same environment, they have access to the variables that the TC passed to them.  Using them, the script updates the configuration and installs the application.  After the deployment is complete, the Test Controller starts work, which instructs the Test Agent to perform the tests (the same generic tests that it copied into the temporary folder).  These generic tests call the * .exe file at the path specified by it and pass the number of the test case as a parameter to the program.  Autotest causes a specific method depending on the parameter passed to it. <br><br>  After all auto tests are completed, Test Controller begins the cleaning process.  To do this, it calls the wrapper script that it created at the beginning.  It determines the parameters and calls the Call Clean script, which lies on all test systems.  Call Clean runs the Clean script, which uninstalls the application, then collects all the logs, archives them and moves to the temporary launch folder created by Test Controller, so that after the completion of the cleanup, all the logs are loaded into TFS and picked up to run the tests. <br><br>  We have builds that run the Build-Deploy-Test approach on a scheduled basis.  To do this, a special process template is specified in the assembly definition.  Once a week such assembly is launched.  Its configuration indicates which tests need to be performed, with which settings and on which test environment the selected tests should be run. <br><br>  The whole process starts with the launch on the Build Controller, which provides the build parameters for the Build Agent (which projects to build, in what configuration - we have this Release / Debug). After the Build Agent collects everything, the Build Controller transfers control to the Test Controller along with The parameters for running auto tests are a set of auto tests, a test environment and test settings. <br><br>  <i>Our <a href="http://ow.ly/PPHT3">company</a> uses its own test settings and its own build for each test environment.</i> <br><br>  After launching the Test Controller, it starts the deployment process, then passes testing to the Test Agent, and after that the Test Controller runs the system cleanup script. <br><br>  If the test environment consists of 2 machines, then this should be specified in the Test Manager, for them a single test environment is created, in which there will be 2 machines.  Each machine has its own Test Agent connected to TFS so that these machines can be seen in TM.  Each machine is assigned a separate role, for example, the Database Server and the Client. <br><br><img src="https://habrastorage.org/files/a92/572/f9d/a92572f9ddb74d2f9ce295bc8f49a63e.png" alt="image"><br><br>  In this case, the same will happen at startup, but the test environment will consist of 2 machines and the tests will run on only one machine, and the logs can also be assembled different depending on the role. <br><br>  <b>Problems Configuring the Build-Test-Deploy Process</b> <br><br>  As it turned out, powershell scripts are not suitable for deploy / clean scripts, only cmd or bat are suitable for them.  And, moreover, if you ask him to use the batch file and call the powershell script from the batch file, Test Manager ignores this call.  Similarly, it ignores all sleep, wait, and even ping of a nonexistent host with a timer (we needed sleep after stopping / starting the services).  It was necessary even for such simple things to write separate crutches that were launched from a batch file. <br><br>  As the project evolved, the tests evolved.  At first it was a set of libraries, so it was possible in the deployment script to simply copy them and run tests, and then delete them.  And everyone was happy.  Then our gallant developers wrapped everything in msi-packages that had to be run with a lot of parameters.  And delete accordingly.  Here, the task has already become complicated with changes in the parameters that need to be submitted.  For this, we used the parameters that Test ontroller transmits Test Agent.  That was enough. <br><br>  Then a lot of msi installation packages appeared, which should be installed in a certain sequence and with a lot of parameters and configuration files.  In order for the configuration to take place depending on the test system, we replaced all the connection strings from the default string to the required one, replaced all paths, parameters, and so on (all this was also taken from the auto-test launch parameters).  Still it was necessary to make removal of MSMQ (Microsoft Message Queuing) of queues.  Simple batch files do not solve this problem, so I wrote such a script on PS.  But then another surprise was waiting for - well, MicroSoft Test Manager does not want to work with its illustrious powershell.  Inexplicably.  As a result, this was again solved in the autotests themselves. <br><br>  The final (at the moment) stage of the installation was a single program with a user interface, in which the necessary components and parameters are selected and it launches all the necessary installer files with parameters.  Similarly, the removal.  We automated the installation without having to set values ‚Äã‚Äãin the user interface.  The installer is fed to the input a configured xml file with the necessary parameters (some of which were used that can be transferred from the Test Controller) were used for installation and removal.  Everything else is the same. <br><br>  So, we have automated and set the whole process.  Of course, the means of achieving continuous integration may differ significantly from the project, from the preferences, traditions and policies of the company.  And we can help decide what is needed for your company. <br><br>  By <a href="http://habrahabr.ru/users/rsarvarova/" class="user_link">rsarvarova</a> </div><p>Source: <a href="https://habr.com/ru/post/262173/">https://habr.com/ru/post/262173/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../262151/index.html">Compact installation of FreeBSD 10 for a certification authority</a></li>
<li><a href="../262155/index.html">Top 10 data mining algorithms in simple language</a></li>
<li><a href="../262163/index.html">Reliable storage and update of data in flash memory of STM32 and MSP430 microcontrollers</a></li>
<li><a href="../262167/index.html">Android WebView: actual problems and their solutions</a></li>
<li><a href="../262169/index.html">Consulo: Running Java code on the .NET platform using IKVM.NET</a></li>
<li><a href="../262175/index.html">Real-time data processing in AWS Cloud. Part 1</a></li>
<li><a href="../262177/index.html">Web file manager with integrated chickenpox</a></li>
<li><a href="../262179/index.html">How to beat Excluded Constraints with RubyGem</a></li>
<li><a href="../262181/index.html">Using potential fields in real-time strategy scenarios</a></li>
<li><a href="../262183/index.html">React on ES6 +</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>