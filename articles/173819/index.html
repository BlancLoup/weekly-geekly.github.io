<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Data mining: Toolkit - Theano</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the previous materials of this cycle, we considered methods of preprocessing data using a DBMS. This can be useful for very large volumes of inform...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Data mining: Toolkit - Theano</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/86b/268/e94/86b268e9471d961b06851d924e386a0e.png"><br>  In the previous materials of this cycle, we considered methods of preprocessing data using a DBMS.  This can be useful for very large volumes of information processed.  In this article I will continue to describe the tools for intelligent processing of large amounts of data, focusing on the use of Python and Theano. <br><a name="habracut"></a><br>  Consider the tasks that we will solve, and what tools for this we use.  Read the previous parts [ <a href="http://habrahabr.ru/post/165001/">1</a> , <a href="http://habrahabr.ru/post/165281/">2</a> , <a href="http://habrahabr.ru/post/165283/">3</a> ] is desirable, but not necessary.  The initial data that was obtained as a result of the implementation of the previous parts of the cycle of articles can be taken here <br><br><h5>  Tasks </h5><br>  If among the data there are hidden relationships, correlation between features, structural relationships, then the problem arises of reducing the dimension of the input data.  This problem manifests itself especially brightly in a situation where a large number of sparse data is being processed. <br>  To compare data dimension reduction methods, we are going to consider the neural network compression method (Autoencoder) and the principal component method (PCA). <br>  The classic way to solve this problem is the principal component analysis method (PCA).  Wikipedia is well described [ <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25B3%25D0%25BB%25D0%25B0%25D0%25B2%25D0%25BD%25D1%258B%25D1%2585_%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BF%25D0%25BE%25D0%25BD%25D0%25B5%25D0%25BD%25D1%2582">4</a> ], there is also a link [ <a href="http://www.chemometrics.ru/materials/textbooks/pca.htm">5</a> ] to the site with examples in Excel, and a detailed and fairly clear description.  Here are more links to articles on Habr√© [ <a href="http://habrahabr.ru/post/146236/">6</a> , <a href="http://habrahabr.ru/post/176257/">7</a> ]. <br>  As a rule, the results of reducing the dimension of input data are primarily compared with the results of applying this method. <br>  The article [ <a href="http://habrahabr.ru/post/134950/">8</a> ] describes what an auto-encoder is and how it works; therefore, the main material will be devoted to the implementation and application of this approach. <br>  Banguio and Joshua wrote a good and clear review of the use of neural network compression, if suddenly someone needs a bibliography and references to works in this direction to compare their results with the existing ones, in [ <a href="http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/239">9</a> ], section 4.6, pp. 48-50. <br>  As a toolkit, I decided to use Python and Theano [ <a href="http://deeplearning.net/software/theano/">10</a> ].  I found this package after listening to the <a href="https://www.coursera.org/course/neuralnets">Neural Networks for Machine Learning</a> courses, studying the links provided by the teacher J. Hinton.  With the help of this package neural networks of ‚Äúdeep learning‚Äù (deep learning neural networks) are implemented.  Such networks, as described in the lectures and the article [ <a href="http://bgr.com/2013/03/13/google-speech-recognition-dnnresearch-373125/">11</a> , <a href="http://research.google.com/pubs/SpeechProcessing.html">12</a> ], formed the basis of the voice recognition system used by Google on Android. <br>  This approach to the construction of neural networks in the opinion of some scientists is quite promising, and already shows good results.  Because it became interesting to me to use it for solving problems on Kaggle. <br>  Also, on the site <a href="http://deeplearning.net/">deeplearning.net there</a> are a lot of examples of building machine learning systems using this particular package. <br><br><h5>  Instruments </h5><br>  In the documentation of developers, given the definition: <br>  Theano is a Python library and optimizing compiler that allows you to define, optimize, and calculate mathematical expressions efficiently using multidimensional arrays. <br>  Library features: <br><ul><li>  tight integration with NumPy; </li><li>  transparent use of the GPU; </li><li>  effective differentiation of variables; </li><li>  fast and stable optimization; </li><li>  dynamic code generation in C; </li><li>  advanced features of unit testing and self-testing; </li></ul><br>  Theano has been used in high-intensity computational research since 2007. <br>  In fact, programming with Theano is not programming in the full sense of the word, since a Python program is written that creates an expression for Theano. <br>  On the other hand, this is programming, since we declare variables, create an expression that says what to do with these variables, and compile these expressions into functions that are used in the calculation. <br>  In short, here is a list of what exactly Theano can do, unlike NumPy. <br><ul><li>  execution speed optimization: Theano can use g ++ or nvcc to compile parts of your expression in a GPU or CPU instruction that runs much faster than pure Python; </li><li>  variable differentiation: Theano can automatically build expressions to calculate the gradient; </li><li>  stability of optimization: Theano can recognize some numerically inaccurately calculated expressions and calculate them using more reliable algorithms </li></ul><br>  The package closest to Theano is sympy.  The sympy package can be compared to Mathematica, while the NumPy is more similar to the MATLAB package.  Theano is a hybrid whose developers have tried to take the best sides of both these packages. <br>  Most likely, in the continuation of the cycle, a separate article will be written on how to configure theano, connect the use of the CUDA GPU to the training of neural networks and solve problems arising during installation. <br>  In the meantime, on my Linux operating system Slackware 13.37, python-2.6, setuptools-0.6c9-py2.6, g ++, python-dev, NumPy, SciPy, BLAS is installed.  Detailed installation manual for common OS in English: [ <a href="http://deeplearning.net/software/theano/install.html">12</a> ]. <br>  Before we begin to reduce the data dimension, we will try to implement a simple example of using Theano to write a function that will allow us to solve our problem of splitting a group into two parts. <br>  As a method for splitting data into two classes, we use logistic regression [ <a href="http://ru.wikipedia.org/wiki/%25D0%259B%25D0%25BE%25D0%25B3%25D0%25B8%25D1%2581%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">13</a> ]. <br>  The example code is based on [ <a href="http://deeplearning.net/software/theano/tutorial/examples.html">14</a> ] with some changes: <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> theano <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> theano.tensor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> T <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> csv <span class="hljs-comment"><span class="hljs-comment">#   csv  csv_file_object = csv.reader(open('./titanik_train_final.csv', 'rb'), delimiter='\t') data=[] # - for row in csv_file_object: #   data.append(row) #    data data = numpy.array(data) #      numpy.array data = data.astype('float') #    float Y = data[:,1] #       Y X = data[:,2:] #           X #   ,   Y csv_file_object = csv.reader(open('./titanik_test_final.csv', 'rb'), delimiter='\t') data_test=[] for row in csv_file_object: data_test.append(row) Tx = numpy.array(data_test) Tx = Tx.astype('float') Tx = Tx[:,1:] #      rng = numpy.random #  N = 891 #  feats = 56 #   training_steps = 10000 #    Theano x = T.matrix("x") y = T.vector("y") w = theano.shared(rng.randn(feats), name="w") b = theano.shared(0., name="b") #  ¬´¬ª Theano p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b)) #  ,    1 prediction = p_1 &gt; 0.5 #    xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) #      cost = xent.mean() + 0.01 * (w ** 2).sum() #   gw,gb = T.grad(cost, [w, b]) #    #  ¬´¬ª Theano train = theano.function( inputs=[x,y], outputs=[prediction, xent], updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb))) predict = theano.function(inputs=[x], outputs=prediction) #   for i in range(training_steps): pred, err = train(X, Y) # P = predict(Tx) #   numpy.savetxt('./autoencoder.csv',P,'%i')</span></span></code> </pre> <br>  The most interesting lines in this code are: <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  ¬´¬ª Theano p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b)) #  ,    1 prediction = p_1 &gt; 0.5 #    xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) #      cost = xent.mean() + 0.01 * (w ** 2).sum() #   gw,gb = T.grad(cost, [w, b]) #    #  ¬´¬ª Theano train = theano.function( inputs=[x,y], outputs=[prediction, xent], updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb))) predict = theano.function(inputs=[x], outputs=prediction)</span></span></code> </pre><br>  Here the following happens (we <i>analyze it from the end!</i> ): We have two ‚Äúexpressions‚Äù <b>train</b> and <b>predict</b> .  They are ‚Äúcompiled‚Äù (this is not only a compilation, but at the beginning of the study it will be better to simplify) with the help of <b>theano.function</b> into a form that can be later called and executed. <br>  Our input parameters for prediction are x, and the output is the <b>prediction</b> expression, which is equal to <b>p_1&gt; 0.5</b> ‚Äî that is, the threshold that returns a yes / no value, that is, a value of 0 or 1. In turn, the expression <i>p_1</i> contains information about what exactly needs to be done with the variable <i>x</i> , namely: <br><pre> <code class="python hljs">p_1 = <span class="hljs-number"><span class="hljs-number">1</span></span> / (<span class="hljs-number"><span class="hljs-number">1</span></span> + T.exp(-T.dot(x, w) - b))</code> </pre>  where <i>x, w, b</i> are variables, while <i>w</i> and <i>b</i> we define using the expression <b>train</b> . <br>  For train, the input will be <i>x, y</i> , and the output <i>prediction</i> and <i>xent</i> .  At the same time, we will update (search for optimal values) for <i>w</i> and <i>b</i> , updating them using the formulas <br><pre> <code class="python hljs">w<span class="hljs-number"><span class="hljs-number">-0.1</span></span>*gw, b<span class="hljs-number"><span class="hljs-number">-0.1</span></span>*gb</code> </pre>  where <i>gw</i> and <i>gb</i> are gradients associated with the error <i>xent</i> through the expression <i>cost</i> . <br>  And the <b>error</b> calculated by the formula is obtained from the following expression: <br><pre> <code class="python hljs">xent = -y * T.log(p_1) - (<span class="hljs-number"><span class="hljs-number">1</span></span>-y) * T.log(<span class="hljs-number"><span class="hljs-number">1</span></span>-p_1)</code> </pre>  And when we ‚Äúcompile‚Äù the expressions predict and train, Theano takes all the necessary expressions, creates C code for the CPU / GPU for them and executes them accordingly.  This gives a significant increase in performance, while not depriving us of the convenience of using the Python environment. <br>  The result of the implementation of this code will be the quality of the forecast, equal to 0.765555 about the Kaggle evaluation rules for the Titanik competition. <br>  In the next articles of the cycle, we will try to reduce the dimension of the problem using different algorithms, and compare the results. </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/173819/">https://habr.com/ru/post/173819/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../173795/index.html">Sudoku solution methods</a></li>
<li><a href="../173797/index.html">Developing Blueprints plugins in Atlassian Confluence</a></li>
<li><a href="../173799/index.html">Human revolution</a></li>
<li><a href="../173811/index.html">Russian has become the second most popular language of the Internet</a></li>
<li><a href="../173815/index.html">Don Jones "Creating a unified IT monitoring system in your environment." Chapter 2. Elimination of management practices for individual sites in IT management</a></li>
<li><a href="../173821/index.html">Evaluation of algorithms complexity</a></li>
<li><a href="../173823/index.html">Install the second hard drive in the Samsung 300V laptop</a></li>
<li><a href="../173825/index.html">Bortnik Fund - "easy money" for the benefit or harm</a></li>
<li><a href="../173827/index.html">Apple introduced two-factor verification for Apple ID and iCloud accounts</a></li>
<li><a href="../173833/index.html">Oscillograph cartoon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>