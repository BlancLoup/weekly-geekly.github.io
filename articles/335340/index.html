<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>In a section: the news aggregator on Android with backend. Java Crawl Library (crawler4j)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction (with links to all articles) 

 An integral part of the news gathering system is a robot for crawling sites (crawler, kruler, “spider”). ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">🔎</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">📜</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">⬆️</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">⬇️</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>In a section: the news aggregator on Android with backend. Java Crawl Library (crawler4j)</h1><div class="post__text post__text-html js-mediator-article">  <a href="https://habrahabr.ru/post/334510/">Introduction (with links to all articles)</a> <br><br>  An integral part of the news gathering system is a robot for crawling sites (crawler, kruler, “spider”).  Its functions include tracking changes on specified sites and entering new data into the database (DB) of the system. <br><br>  There was no fully ready and suitable solution - therefore, it was necessary to choose something from the existing projects that would satisfy the following criteria: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  ease of setup; </li><li>  ability to customize to crawl multiple sites; </li><li>  undemanding of resources; </li><li>  the absence of additional infrastructural things (coordinators of work, databases for the "spider", additional services, etc.). </li></ul><a name="habracut"></a><br>  The solution chosen was a fairly popular robot for crawling sites - <a href="https://github.com/yasserg/crawler4j">crawler4j</a> .  Of course, he pulls a lot of libraries to analyze the received content, but this does not affect the speed of his work or the resources consumed.  As a database of references uses Berkley DB, created in a custom directory for each analyzed site. <br><br>  As a method of customization, the developer chose a hybrid of behavioral patterns “ <a href="https://en.wikipedia.org/wiki/Strategy_pattern">Strategy</a> ” (the right to make a decision about which links and sections of the site should be analyzed by the client) and “ <a href="https://en.wikipedia.org/wiki/Observer_pattern">Observer</a> ” (when crawling the site, data about the page (address, format, content, meta data) ) transferred to the client, who is free to decide how to deal with them). <br><br>  In fact, for a developer, a “spider” looks like a library that connects to a project and into which the necessary implementations of interfaces for customizing behavior are transferred.  The developer extends the library class <code>«edu.uci.ics.crawler4j.crawler.WebCrawler»</code> (with the methods of <code>«shouldVisit»</code> and <code>«visit»</code> ), which is subsequently passed to the library.  The interaction in the process of work looks like this: <br><br><img src="https://habrastorage.org/web/ffd/463/fc9/ffd463fc99e94131aef6200ba31d892a.png" alt="image"><br><br>  where <code>edu.uci.ics.crawler4j.crawler.CrawlController</code> is the main library class through which interaction takes place (bypass setting, control code transfer, status information, start / stop). <br><br>  There was no need to deal with the implementation of site parsing before - so I immediately had to face a series of problems and in the process of eliminating them, it was necessary to make several decisions on the implementation and methods of processing the obtained crawl data: <br><br><ul><li>  The code for analyzing the received content and the implementation of the “Strategy” template is presented in the form of a separate project, the versioning of which is separate from the versions of the “spider” itself; <br><br></li><li>  The actual analysis code of the received content and link analysis is implemented on <a href="http://groovy-lang.org/">groovy</a> , which allows you to change the operation logic without restarting the spiders (the <code>«recompileGroovySource»</code> option is activated in <code>«org.codehaus.groovy.control.CompilerConfiguration»</code> ) (with the corresponding implementation code <code>«edu.uci.ics.crawler4j.crawler.WebCrawler»</code> actually contains only the groovy interpreter, which processes the transmitted data in itself); <br><br></li><li>  data extraction from each page encountered in the “spider” is not complete - comments, “cap” and “basement” are removed, i.e.  the fact that it makes no sense to spend 50% of the volume of each page - everything else is stored in the MongoDB database for further analysis (this allows you to restart the analysis of pages without re-traversing sites); <br><br></li><li>  key fields for each news (“date”, “title”, “topic”, “author”, etc.) are retrieved already from the database in MongoDB, while their fullness is controlled - when a certain number of errors is reached - a notification of the need to adjust the scripts (a sure sign of a change in the structure of the site). </li></ul><br><h3>  Change in library code </h3><br>  The main problem for me was some architectural solution developer cralwer4j that the pages of the site do not change, i.e.  The logic of his work is: <br><br><img src="https://habrastorage.org/web/dce/b72/1f7/dceb721f744e474f9900cd7cb620c451.png" alt="image"><br><br>  Having studied the source texts of the library, I realized that with no settings this logic could be changed and it was decided to create a fork of the main project.  In the specified branch, before the action “Add extracted links to the link database”, an additional check is performed on the need to add links to the link database: the start pages of the site are never entered into this database and, as a result, when they get into the main processing cycle, they are reused and redefined , while giving links to the latest news. <br><br>  However, this refinement required a change in the work with the library, in which the launch of the main methods should be carried out on a periodic basis, which was easily implemented using the <a href="http://www.quartz-scheduler.org/">quartz</a> library.  In the absence of fresh news on the start pages, the method completed its work in a couple of seconds (after receiving the start pages, analyzing them and receiving the already passed links) or writing the latest news in the database. <br><br>  Thanks for attention! </div><p>Source: <a href="https://habr.com/ru/post/335340/">https://habr.com/ru/post/335340/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../335328/index.html">IOS UI tests: why you need to believe in QA friendship and development, but don't flatter yourself</a></li>
<li><a href="../335330/index.html">How to start young mobile game developers from Russia in the current reality [Part 2]</a></li>
<li><a href="../335332/index.html">Learning to program for Android</a></li>
<li><a href="../335336/index.html">CRM-system: full implementation algorithm</a></li>
<li><a href="../335338/index.html">Expand Emercoin testnet and get a lot of free coins</a></li>
<li><a href="../335342/index.html">How artificial intelligence can save email</a></li>
<li><a href="../335344/index.html">How does participation in professional IT communities affect career?</a></li>
<li><a href="../335346/index.html">Integration of Intel Threading Building Blocks in your CMake project</a></li>
<li><a href="../335350/index.html">Do not think about the minutes down</a></li>
<li><a href="../335352/index.html">Basic accessibility errors when developing a site</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>