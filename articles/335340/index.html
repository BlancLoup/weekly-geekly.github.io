<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>In a section: the news aggregator on Android with backend. Java Crawl Library (crawler4j)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction (with links to all articles) 

 An integral part of the news gathering system is a robot for crawling sites (crawler, kruler, â€œspiderâ€). ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">ğŸ”</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">ğŸ“œ</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">â¬†ï¸</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">â¬‡ï¸</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>In a section: the news aggregator on Android with backend. Java Crawl Library (crawler4j)</h1><div class="post__text post__text-html js-mediator-article">  <a href="https://habrahabr.ru/post/334510/">Introduction (with links to all articles)</a> <br><br>  An integral part of the news gathering system is a robot for crawling sites (crawler, kruler, â€œspiderâ€).  Its functions include tracking changes on specified sites and entering new data into the database (DB) of the system. <br><br>  There was no fully ready and suitable solution - therefore, it was necessary to choose something from the existing projects that would satisfy the following criteria: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  ease of setup; </li><li>  ability to customize to crawl multiple sites; </li><li>  undemanding of resources; </li><li>  the absence of additional infrastructural things (coordinators of work, databases for the "spider", additional services, etc.). </li></ul><a name="habracut"></a><br>  The solution chosen was a fairly popular robot for crawling sites - <a href="https://github.com/yasserg/crawler4j">crawler4j</a> .  Of course, he pulls a lot of libraries to analyze the received content, but this does not affect the speed of his work or the resources consumed.  As a database of references uses Berkley DB, created in a custom directory for each analyzed site. <br><br>  As a method of customization, the developer chose a hybrid of behavioral patterns â€œ <a href="https://en.wikipedia.org/wiki/Strategy_pattern">Strategy</a> â€ (the right to make a decision about which links and sections of the site should be analyzed by the client) and â€œ <a href="https://en.wikipedia.org/wiki/Observer_pattern">Observer</a> â€ (when crawling the site, data about the page (address, format, content, meta data) ) transferred to the client, who is free to decide how to deal with them). <br><br>  In fact, for a developer, a â€œspiderâ€ looks like a library that connects to a project and into which the necessary implementations of interfaces for customizing behavior are transferred.  The developer extends the library class <code>Â«edu.uci.ics.crawler4j.crawler.WebCrawlerÂ»</code> (with the methods of <code>Â«shouldVisitÂ»</code> and <code>Â«visitÂ»</code> ), which is subsequently passed to the library.  The interaction in the process of work looks like this: <br><br><img src="https://habrastorage.org/web/ffd/463/fc9/ffd463fc99e94131aef6200ba31d892a.png" alt="image"><br><br>  where <code>edu.uci.ics.crawler4j.crawler.CrawlController</code> is the main library class through which interaction takes place (bypass setting, control code transfer, status information, start / stop). <br><br>  There was no need to deal with the implementation of site parsing before - so I immediately had to face a series of problems and in the process of eliminating them, it was necessary to make several decisions on the implementation and methods of processing the obtained crawl data: <br><br><ul><li>  The code for analyzing the received content and the implementation of the â€œStrategyâ€ template is presented in the form of a separate project, the versioning of which is separate from the versions of the â€œspiderâ€ itself; <br><br></li><li>  The actual analysis code of the received content and link analysis is implemented on <a href="http://groovy-lang.org/">groovy</a> , which allows you to change the operation logic without restarting the spiders (the <code>Â«recompileGroovySourceÂ»</code> option is activated in <code>Â«org.codehaus.groovy.control.CompilerConfigurationÂ»</code> ) (with the corresponding implementation code <code>Â«edu.uci.ics.crawler4j.crawler.WebCrawlerÂ»</code> actually contains only the groovy interpreter, which processes the transmitted data in itself); <br><br></li><li>  data extraction from each page encountered in the â€œspiderâ€ is not complete - comments, â€œcapâ€ and â€œbasementâ€ are removed, i.e.  the fact that it makes no sense to spend 50% of the volume of each page - everything else is stored in the MongoDB database for further analysis (this allows you to restart the analysis of pages without re-traversing sites); <br><br></li><li>  key fields for each news (â€œdateâ€, â€œtitleâ€, â€œtopicâ€, â€œauthorâ€, etc.) are retrieved already from the database in MongoDB, while their fullness is controlled - when a certain number of errors is reached - a notification of the need to adjust the scripts (a sure sign of a change in the structure of the site). </li></ul><br><h3>  Change in library code </h3><br>  The main problem for me was some architectural solution developer cralwer4j that the pages of the site do not change, i.e.  The logic of his work is: <br><br><img src="https://habrastorage.org/web/dce/b72/1f7/dceb721f744e474f9900cd7cb620c451.png" alt="image"><br><br>  Having studied the source texts of the library, I realized that with no settings this logic could be changed and it was decided to create a fork of the main project.  In the specified branch, before the action â€œAdd extracted links to the link databaseâ€, an additional check is performed on the need to add links to the link database: the start pages of the site are never entered into this database and, as a result, when they get into the main processing cycle, they are reused and redefined , while giving links to the latest news. <br><br>  However, this refinement required a change in the work with the library, in which the launch of the main methods should be carried out on a periodic basis, which was easily implemented using the <a href="http://www.quartz-scheduler.org/">quartz</a> library.  In the absence of fresh news on the start pages, the method completed its work in a couple of seconds (after receiving the start pages, analyzing them and receiving the already passed links) or writing the latest news in the database. <br><br>  Thanks for attention! </div><p>Source: <a href="https://habr.com/ru/post/335340/">https://habr.com/ru/post/335340/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../335328/index.html">IOS UI tests: why you need to believe in QA friendship and development, but don't flatter yourself</a></li>
<li><a href="../335330/index.html">How to start young mobile game developers from Russia in the current reality [Part 2]</a></li>
<li><a href="../335332/index.html">Learning to program for Android</a></li>
<li><a href="../335336/index.html">CRM-system: full implementation algorithm</a></li>
<li><a href="../335338/index.html">Expand Emercoin testnet and get a lot of free coins</a></li>
<li><a href="../335342/index.html">How artificial intelligence can save email</a></li>
<li><a href="../335344/index.html">How does participation in professional IT communities affect career?</a></li>
<li><a href="../335346/index.html">Integration of Intel Threading Building Blocks in your CMake project</a></li>
<li><a href="../335350/index.html">Do not think about the minutes down</a></li>
<li><a href="../335352/index.html">Basic accessibility errors when developing a site</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>