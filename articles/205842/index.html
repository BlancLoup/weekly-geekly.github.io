<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Image Classifier</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Given a bit matrix containing a filled-in image of a circle, square, or triangle. 
 The image may be slightly distorted and may contain noise. 
 It is...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Image Classifier</h1><div class="post__text post__text-html js-mediator-article">  Given a bit matrix containing a filled-in image of a circle, square, or triangle. <br>  The image may be slightly distorted and may contain noise. <br>  It is necessary to write an algorithm to determine the type of the drawn figure on the matrix. <br><img src="https://habrastorage.org/getpro/habr/post_images/b3b/8fb/0ad/b3b8fb0ad2416306df879938cb9e0717.png"><br>  This simple task at first glance met me at the entrance exam at DM Labs. <br>  At the first lesson we discussed the solution, and the teacher (Alexander Shlemov; he supervised and further implementation) showed why it is better to use machine learning for the solution. <br><br>  During the discussion, we found that our decision was made in two stages.  The first stage is noise filtering, the second stage is the calculation of the metric by which the classification will take place.  Here the problem of defining boundaries arises: it is necessary to know what values ‚Äã‚Äãthe metric can take for each shape.  It is possible to pave these boundaries manually ‚Äúby the eye‚Äù, but it is better to entrust this matter to a mathematically sound algorithm. <br>  This learning task was an introduction to Machine Learning for me, and I would like to share this experience with you. <br><a name="habracut"></a><br><h4>  main idea </h4><br>  First, we create a variety of random images of circles, triangles and quadrangles.  Next, we pass the pictures through the filters to eliminate noise and calculate the set of metrics that will be used to classify the figures.  We define the boundary values ‚Äã‚Äãfor metrics using a decision tree (Decision tree), or rather, with the help of its CART variety (for more details see <a href="http://themainstreamseer.blogspot.ru/2013/01/introduction-to-classification.html">here</a> ).  The implementation of the algorithm is simple and better interpreted in terms of boundaries. <br>  By passing an unknown image through the filters and calculating the metrics, we can tell by the decision tree which class the figure in the picture belongs to. <br><br><h4>  Generation </h4><br>  The generator must not only create pictures, but also be able to interfere with them.  When generating, we must discard figures with sides less than a certain size (for example, 15 pixels) and with obtuse angles (more than 150 degrees) - even for a person it is difficult to classify them. <br>  The script is carefully provided by Victor Evstratov. <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/picture_generator.py">bitbucket.org/rampeer/image-classifier/src/HEAD/picture_generator.py</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Filters </h4><br>  During the discussion with colleagues, we found good ideas for filters.  Let us take black pixels surrounded by pixels of the opposite color for interference (this idea formed the basis of the median filter), and take a large amount of black pixels as the desired circuit, that is, we use a bicomponent filter. <br><br>  <b>Median filter</b> : for each black pixel we determine the number of ‚Äúblack‚Äù neighbors in the vicinity of the radius R. If this number is less than a certain <b>T</b> , then discard this pixel, that is, paint it white.  In the ‚Äúoriginal‚Äù median filter, we drop the pixel if it has less than half of the black neighbors, and we have defined our threshold <b>T</b> , so in fact it is a quantile filter. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7f6/345/ec6/7f6345ec67797e52654b3d56fea0047a.png"><br><br>  I wrote a median filter honestly and head-on, so it works for <code>O(WHR2)</code> , where W and H are the size of the image.  The teacher said that the algorithm can be accelerated using the Fourier transform.  Indeed, the median filter can be expressed through convolution, and convolution can be quickly calculated using the fast Fourier transform. <br>  It turns out that you can calculate the matrix with the number of neighbors as <br> <code>result = FFT-1 (FFT(data) FFT(window))</code> <br>  This algorithm works for <code>O(WHlog(W+H))</code> , that is, much faster than a naive implementation, and does not depend on the window size.  Due to the cyclical nature of convolution, an artifact occurs at the boundaries: when processing the leftmost pixels, the neighbors will be considered the rightmost ones.  This can be corrected by adding a frame of pure pixels along the edges of the image, and you can leave it so that I did - anyway, this effect does not damage the performance. <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/filter_median.py">bitbucket.org/rampeer/image-classifier/src/HEAD/filter_median.py</a> <br>  However, I found this property a bad property: it rounds the acute angles of the triangles.  Because of this, it is necessary to take the radius of the window R rather small and pass through the image with a filter only a few (N) times.  Although at first it seemed that you can apply a median filter as long as it removes some pixels. <br><br>  <b>Bicomponent filter</b> : take an arbitrary black pixel, assign it some Q number. Assign the same number to ‚Äúblack‚Äù neighbors of this pixel in a neighborhood with radius R and repeat for neighbors neighbors.  We will repeat until we reach the border of the image (this is reminiscent of the effect of the Paint Fill tool in Paint, but we paint it in Q color).  Then we increase the number Q by one, select the next ‚Äúuncolored‚Äù pixel and repeat the process. <br>  After executing this algorithm, we get a set of non-contiguous islands.  We can say with high confidence that the largest island is the figure, and the rest of the islands are interferences. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/333/cdd/6fe/333cdd6fe36c85c37e4fe5af8e8de352.png"><br>  &lt;filter_bicomp.py&gt; <br>  Unlike the previous one, this filter does not spoil the image.  It can cause damage only if the line is crossed by a line of interference with a width greater than <b>T</b> , which is unlikely. <br>  In the median filter, I found another property, this time positive.  It breaks the space filled with noise into ‚Äúislands‚Äù.  So, then applying a bicomponent filter, we get a loop with sticky noise.  After processing with a bicomponent filter, you should once again go through the median to remove the remaining irregularities.  Then you need to build a convex contour around the remaining points, fill it in and calculate the metrics already for the new image. <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/process.py">bitbucket.org/rampeer/image-classifier/src/HEAD/process.py</a> <br>  Filters work: <br><table><tbody><tr><td>  Source image </td><td>  Median filter </td><td>  Median, bicomponent </td><td>  Median, bicomponent, <br>  median, fill </td></tr><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/63b/439/c3a/63b439c3a52fb8bf8e2c6ac6a738f62c.png"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/41a/148/1b3/41a1481b3919c777965179168cb704f4.png"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/868/f25/80a/868f2580ac156a43f135a712b47ff343.png"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/cf3/493/d3e/cf3493d3e48fbec30d74108816e90e61.png"></td></tr></tbody></table><br>  Filter parameters are selected based on the size of the images in the sample and their noise.  For the clever quad shown above: <br><pre> <code class="python hljs"> median.filter(img, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) bicomp.filter(img, <span class="hljs-number"><span class="hljs-number">2</span></span>) median.filter(img, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre><br>  In our sample, images will be less noisy, and the settings will be more benign. <br><br><h4>  Metrics </h4><br>  In the course of the same discussion with colleagues, we came up with many more interesting metrics. <br><br>  <b>Counting angles</b> .  This is the very first thing that comes to mind after reading the task.  But due to interference, additional angles may appear, close to 0 degrees.  I tried unsuccessfully to deal with this by sticking together almost collinear vectors and setting thresholds.  Such methods are hard to set up, and they can still give an incorrect result, since the figure is smoothed when filtering.  It is better to sum the squares of the sines of the corners, and if the angles are greater than a certain threshold T, round the square up to one.  This gives a fairly good result: acute angles add one to the counter, while angles close to 0 add almost nothing.  By the way, it seemed to me amusing that in such a case the number of angles at the triangle can vary from 2.5 to 4. <br><img src="https://habrastorage.org/getpro/habr/post_images/233/e40/221/233e40221b334c5d7204e065ad97fecb.png"><br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/feature_edges.py">bitbucket.org/rampeer/image-classifier/src/HEAD/feature_edges.py</a> <br><br>  <b>Mirroring</b> .  The meaning of this metric is to calculate how much the figure will coincide with an inverted copy of itself when reflected horizontally / vertically / along both axes.  That is, this metric is a kind of measure of symmetry.  A circle, whatever one may say, will always completely coincide with itself.  Also, I intuitively assumed that the square will coincide more with itself than the triangle. <br><img src="https://habrastorage.org/getpro/habr/post_images/074/042/8f8/0740428f859e3f5a74cb802a2f54ded1.png"><br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/feature_mirror.py">bitbucket.org/rampeer/image-classifier/src/HEAD/feature_mirror.py</a> <br><br>  <b>The ratio of the area to the square of the perimeter</b> .  The perimeter must be squared so that the metric does not have dimensions and does not depend on the size of the image.  The perimeter and area will be taken from the convex contour.  The circle has the largest metric value among the figures: <code>s/p^2 =(œÄr^2)/(4œÄ^2 r^2 )=1/4œÄ</code> .  For an equilateral triangle (it has the largest ratio among the triangles): <code>s/p^2 =(4‚àö3 a^2)/(3*9a^2 )=(4‚àö3)/27</code> .  For the square: <code>s/p^2 =(a^2)/(16*a^2 )=1/16</code> . <br><img src="https://habrastorage.org/getpro/habr/post_images/df9/07b/d78/df907bd7849875c105ea37b3b5c4ea3b.png"><br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/feature_perimeter.py">bitbucket.org/rampeer/image-classifier/src/HEAD/feature_perimeter.py</a> <br><br>  <b>Metrics on the describing rectangle</b> .  The previous metrics did not divide the four and the triangle very well, and I decided to come up with a new metric.  Construct a bounding box around the shape.  For each side of the rectangle we find the first (‚Äúminimal‚Äù) and last (‚Äúmaximal‚Äù) intersection with the figure.  We will have an ‚Äúoctagon‚Äù for which we can calculate different metrics. <br><img src="https://habrastorage.org/getpro/habr/post_images/404/376/abd/404376abd7b987236d9245558828bccc.png"><br>  For example, the ratio of the area of ‚Äã‚Äãa figure to the area of ‚Äã‚Äãa describing square (sbound). <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/feature_sbound.py">bitbucket.org/rampeer/image-classifier/src/HEAD/feature_sbound.py</a> <br>  Also a promising metric is the ratio of the area of ‚Äã‚Äãa figure to the area of ‚Äã‚Äãthis octagon (sbound2): <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/feature_sbound2.py">bitbucket.org/rampeer/image-classifier/src/HEAD/feature_sbound2.py</a> <br><br><h4>  Data collection </h4><br>  Applying the knowledge gained, I generated images and collected statistics.  In this set of images, I added shapes representing potential ‚Äúbad incidents‚Äù for metrics: <br><ul><li>  equilateral triangle </li><li>  right triangle with two sides parallel to the axes </li><li>  square with sides parallel to the axes. </li></ul><br>  These cases, I gave a lot of weight when building a tree.  The fact is that the probability of random generation of such images is small, and these cases are boundary for some metrics.  Therefore, for correct classification, you need to add them to the sample with a large weight. <br>  The procedure for filtering images and collecting metrics I rendered to a separate file, it will be needed for analysis.  By the way, in the decision tree our metrics are called ‚Äúinput parameters‚Äù or ‚Äúfeatures‚Äù (feature). <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/process.py">bitbucket.org/rampeer/image-classifier/src/HEAD/process.py</a> <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/stats.py">bitbucket.org/rampeer/image-classifier/src/HEAD/stats.py</a> <br>  Then I plotted to make sure the metrics distinguish the figures well enough.  For this, a ‚Äúbox with mustache‚Äù type of chart is suitable: <br><img src="https://habrastorage.org/getpro/habr/post_images/1b7/8c5/e54/1b78c5e549555701016557f147bf8fdc.png"><br>  ‚ÄúAntennae‚Äù overlap, which means that inaccuracies in the analysis are possible.  As it was written above, precisely for accuracy we need several metrics, and not one.  Then I tried to make sure that the ‚Äúbad cases‚Äù of the metrics do not overlap.  For this, I built the dependence of one metric on another.  If it turns out that they are monotonously dependent on each other, then their ‚Äúbad incidents‚Äù will also coincide. <br><img src="https://habrastorage.org/getpro/habr/post_images/24c/a99/aa2/24ca99aa29a749a512b9de301402b4ec.png"><br>  * As we can see from the graphs, the ‚Äúclouds‚Äù of points intersect strongly.  Therefore, the classification may be a big mistake.  In addition, metrics are not monotonously dependent on each other. <br><br><h4>  Analysis </h4><br>  According to the collected data, you can build a decision tree: <br>  <a href="https://bitbucket.org/rampeer/image-classifier/src/HEAD/analyze.py">bitbucket.org/rampeer/image-classifier/src/HEAD/analyze.py</a> <br>  I tried to visualize the tree.  It turned out this scheme: <br><img src="https://habrastorage.org/getpro/habr/post_images/eb8/7d0/818/eb87d08187a26a7649c40830da22631c.png"><br>  It follows from it that some metrics remained unused.  From the very beginning, we could not predict which metrics would turn out to be ‚Äúbetter‚Äù than others. <br>  The prediction accuracy is about 91 percent, which is not bad considering the square distortions and interference in the sample: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae2/db5/f28/ae2db5f2890dae1734c76f5656021d31.png"><br><br>  Let's try to draw the images yourself and analyze them: <br><table><tbody><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/0e3/40e/c10/0e340ec10acaae279b73eb2e21168c16.png"><br>  Circle </td><td><img src="https://habrastorage.org/getpro/habr/post_images/dc3/689/5d2/dc36895d23bee57aedd49abc14251ee6.png"><br>  Rectangle </td><td><img src="https://habrastorage.org/getpro/habr/post_images/6f8/9b0/f1e/6f89b0f1e61157d79eab1400e1f10bf8.png"><br>  Triangle </td></tr></tbody></table><br>  Let's try to increase the voltage. <br>  We will distort the figures until they become incorrectly determined. <br><table><tbody><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/e9f/a7e/8f1/e9fa7e8f1f932132b442970bfb777db8.png"><br>  Rectangle </td><td><img src="https://habrastorage.org/getpro/habr/post_images/630/aa2/933/630aa29336dc517115015007fbd98aec.png"><br>  Rectangle </td><td><img src="https://habrastorage.org/getpro/habr/post_images/118/bed/6ee/118bed6ee5f07b444d4035daa63a839a.png"><br>  Triangle </td><td><img src="https://habrastorage.org/getpro/habr/post_images/1c0/496/3c5/1c04963c5463bfae4fcd89221f7ca6cb.png"><br>  Rectangle </td></tr></tbody></table><br>  That's all. <br>  In the last image, the corners of the triangle are strongly rounded, edges cannot work correctly, and perimeter gives too large an error.  The triangle is unsuccessfully rotated: when constructing a bounding rectangle, only two vertices will touch it, and sbound and sbound2 will not yield anything reasonable.  Only mirror could give the correct result, but it is not included in the tree.  And if out of 5 metrics only one points to a triangle, then this conclusion can be interpreted as erroneous. <br><br><h4>  Conclusion </h4><br>  Methods of machine learning allowed to build a system that copes well with the task - it recognizes the figures in the image quite well. <br>  Graphs were built in R: <br>  <a href="">bitbucket.org/rampeer/image-classifier/src/HEAD/charts.R</a> </div><p>Source: <a href="https://habr.com/ru/post/205842/">https://habr.com/ru/post/205842/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../205832/index.html">Interview with Bobuk aka Grigory Bakunov, director of technology distribution at Yandex and radio host T</a></li>
<li><a href="../205836/index.html">Servers free until the end of the year</a></li>
<li><a href="../205838/index.html">Fallout 1, 2 and Tactics for free</a></li>
<li><a href="../20584/index.html">Witcher: Improved Edition</a></li>
<li><a href="../205840/index.html">ZeroNights'2013 - Conference Report</a></li>
<li><a href="../205844/index.html">Language K: Displaying a graphical interface from data</a></li>
<li><a href="../205846/index.html">FastVPS.ru - company office in St. Petersburg</a></li>
<li><a href="../205848/index.html">Secrets of the ternary operator</a></li>
<li><a href="../20585/index.html">Famous people about Habr√©</a></li>
<li><a href="../205850/index.html">New heart of CoolRF: ATmega128RFA1 chip</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>