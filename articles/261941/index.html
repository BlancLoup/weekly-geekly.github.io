<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Beginner site optimization guide. Part 2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Part 1 

 Optimization process 
 Establishing a well-defined and formal optimization process in an organization is a very useful practice since it: 

...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Beginner site optimization guide. Part 2</h1><div class="post__text post__text-html js-mediator-article">  <a href="http://habrahabr.ru/post/260803/"><i>Part 1</i></a> <br><br><h4>  Optimization process </h4><br>  Establishing a well-defined and formal optimization process in an organization is a very useful practice since it: <br><br><ol><li>  organizes workflow and sets real deadlines </li><li>  sets quality control standards and reduces errors </li><li>  adds weight to the whole operation - the logic of the process can be explained to the owners of the company </li></ol>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      At the general planning level, I would recommend arranging optimization planning meetings 1-2 times a week, at which it is necessary: <br><br><ol><li>  View current tests to see if you need to stop them or recognize them as ‚Äúcompleted‚Äù (see below).  For completed tests there are two possibilities: <br><ol><li>  there is a clear winner.  In this case, it is necessary to develop its output in production. </li><li>  There is no clear winner in the current control group.  In this case, you need to determine whether additional study of the issue is required, or whether you just need to stop the experiment. </li></ol><br></li><li>  Review data sources and think about new test ideas. </li><li>  Discuss and assign priority to any new ideas. </li></ol><br><br><h4>  How to understand when the test is completed? </h4><br>  Completion criteria are complex and even are commercial secrets.  I will define the minimum necessary conditions for declaring the test ‚Äúcompleted‚Äù.  There are no generally accepted standards, and the criteria depend mainly on the views of your team.  We have developed the following criteria for ourselves: <br><a name="habracut"></a><br><ol><li>  Time.  Tests must go at least two weeks to smooth out fluctuations associated with the days of the week. </li><li>  Statistical confidence.  We used a confidence interval of 90-95% </li><li>  Stability in time.  Options should be at least a week in place. </li><li>  Total number of conversions.  At least 200 pcs. </li></ol><br><br>  Creating a new optimization test can follow the same pattern as product development.  I recommend the following basic structure: <br><br><ol><li>  data analysis </li><li>  search for ideas for improvement </li><li>  development of test options </li><li>  writing a test plan </li><li>  development </li><li>  quality control </li><li>  test run </li><li>  analysis of results and reporting </li></ol><br><br><h4>  Step 1: Data Analysis </h4><br>  First you need to decide on what to concentrate efforts.  We used the following list: <br><br><ol><li>  Recent product releases, or pages that are not yet optimized. </li><li>  Especially valuable pages: <br><ol><li>  Highly profitable (basket, description of expensive products, etc.) </li><li>  Highly visited (home page) </li><li>  Special strategic places that are important for some other reason. </li></ol></li><li>  Pages with bad stats: <br><ol><li>  Low conversion </li><li>  High percentage of care </li></ol></li></ol><br><br><h4>  Step 2: Search for ideas for improvement </h4><br>  The question of improving the page is as big as the question of the user interface, and is beyond the scope of this article.  You can improve the texts, design forms, display media data, render pages, appearance, accessibility ... <br><br>  I advise you only to collect ideas together - use the power of the whole team to look for new ideas.  Include not only designers, but also developers, copywriters, business analysts, marketers, testers ... A good idea can come anywhere. <br><br><h4>  Step 3: Writing a test plan </h4><br>  The plan is the basis of any test.  At the top level, it is used for planning, communicating and documenting the experiment, and moreover, it teaches the team to correctly and clearly formulate goals and analyze the results. <br><br>  A good plan should be the following items: <br><br><ol><li>  Test name </li><li>  Description </li><li>  Goals </li><li>  Opportunities (what we get in case of success) </li><li>  Methodology <br><ol><li>  Expected test dates </li><li>  Resources (who will work on it) </li><li>  Metrics to track </li><li>  Completion criteria </li><li>  Options (screenshots of different designs that visitors will see) </li></ol></li></ol><br><br>  Here is a <a href="https://docs.google.com/document/d/1NFOWFDHU2RBpwBvo8fojrfQpn8AGRB2xOCWR8-3wNGw/edit">sample test plan</a> . <br><br><h4>  Step 4: Test Design and Development </h4><br>  Usually they follow the path of product development - but since the test is simpler than a full-fledged product, I use the light version of the path. <br><br>  But to lower for speed should be minor things - you can not do the documentation, but do not need to save on the quality of design.  Do not forget to make basic checks on usability options. <br><br><h4>  Step 5: Quality Control </h4><br>  Check the quality of tests as carefully as any other code.  I recommend at least functional, visual and analytical tests. <br><br>  Plus optimization tests in that you can arrange any targeting.  You can target different options to specific browsers, platforms, audiences, etc.  Suppose your team checked the work of only one A / B test - for desktop browsers, but not for mobile browsers.  Then you can test its results exclusively for desktop users.  If you still have any problems with the display in mobile browsers, they will not affect the test results. <br><br><h4>  Step 6: Launch </h4><br>  At the end of quality checks and decision making on targeting, tests should be run.  There are a few things to keep in mind. <br><br><h5>  Options need to be shown simultaneously </h5><br>  The first principle is so obvious that it is not spoken of.  But I very often heard statements like ‚Äúafter the launch of a new design, our sales / conversions increased - it means that the new design is better‚Äù. <br><br>  The problem is that you do not know what other factors could affect the work of the project before and after the launch of a new design.  Perhaps the conversion would have increased, thanks to the promotion of the brand, seasonal fluctuations, or simply on the occasion.  Therefore, all options must be checked in parallel.  Only in this way can we eliminate extraneous influence. <br><br><h5>  Track multiple conversion metrics </h5><br>  One of the A / B tests that we conducted was used on the film description page on the Latin American website DIRECTV.  We increased the size and visibility of the ‚ÄúVer adelanto‚Äù button (viewing the trailer), deciding that if people watched the trailer, it would encourage them to buy movies from the site. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f86/cac/da4/f86cacda4c0c2272520e68be69367a91.png" alt="image"><br><br>  And so it happened - in a few weeks we saw an increase in the number of purchases by 4.8%.  In a year, such an increase would result in an increase of $ 18,000 in profits.  Fortunately, since we also monitored other parameters of the site, we saw that this option reduced purchases of channel packages (HBO, Showtime) by as much as 25%.  It would be much more reduced profits.  Therefore, we did not introduce this option in production. <br><br>  It is important to remember that changes can affect your site unpredictably.  Always keep track of different metrics. <br><br>  Tests must reach an acceptable level of statistical significance. <br><br>  In one of the presentations, the consultant reported that the preliminary tests of e-mail segmentation showed promising results. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58b/228/e56/58b228e568bcddd1e8a5550002a644c5.png" alt="image"><br><br>  On the graph, the last segment of users (logged in more than 4 times per year) had a conversion of 0.00139% (0.139 upgrades per 1000 emails).  And although this conversion is very small, according to the consultant, it shows a 142% increase, which is a good result. <br><br>  Without even mentioning the questionable benefits of this statistics (is it proposed to send emails only to users who have logged in more than four times?), There is another problem in the test.  If you look at the ‚ÄúUpgrades‚Äù column, you will see that the results were derived from only five cases of the upgrade order.  Five out of forty eight thousand sent letters.  It turns out that plus / minus one order would radically change all the statistics. <br><br>  Although this is not an example of an optimization test, but simply a study of email segmentation, it contains an important lesson: do not announce the winner without typing an acceptable amount of statistics. <br><br>  What is ‚Äúacceptable‚Äù?  The concepts ‚Äúsignificant‚Äù (95% confidence) and ‚Äúhighly significant‚Äù (99% confidence) in the results are accepted in science.  And the fact that they, respectively, have a 5% and 1% chance that your conclusions are wrong.  In addition, the more statistics you need to collect, the more time it will take.  I would recommend to focus on results in the region of 90-95% confidence, depending on the importance of the situation. <br><br><h5>  The duration of the tests should take into account natural variations (working days, weekends, etc.) and be stable over time. </h5><br>  <a href="http://www.blog.analyticsinspector.com/ab-test-pitfall-consequences-of-ending-your-test-too-soon/">In an article on the site AnalyticsInspector.com,</a> Yan Petrovich describes the problem of premature termination of tests.  The test was conducted on a popular site for only one day, and at the end it was announced that the winning option increased the conversion rate by 87% with 100% confidence. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c5c/d55/808/c5cd55808df9ba542f5dc143bb97f02a.png" alt="image"><br><br>  Jan writes: ‚ÄúIf we stopped the test right then and tapped each other on the shoulder, we would make a mistake.  We didn‚Äôt test our test on Friday or Monday traffic.  But since we didn‚Äôt stop the test, the real result was completely different. ‚Äù <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e6d/416/15f/e6d41615f2a870927112ac69e59a91ec.png" alt="image"><br><br>  After four weeks it became clear that the new design, although it worked better than the control one, showed an improvement of only 10.49%. <br><br>  Do not forget about the short-term fluctuations in the behavior of site visitors, take into account the difference between working days and weekends and seasonal traffic. <br><br><h5>  Step 7: Analysis and Reports </h5><br>  At the end of the test, when you press the stop button, you need to collect the results into a report.  The report may be a continuation of the plan from step 2, but with the following additional sections: <br><br><ol><li>  results </li><li>  Discussion </li><li>  Further steps </li></ol><br><br>  It is very good to include graphs and various details in the ‚Äúresults‚Äù section so that those who are familiar with the report can themselves follow the trends and analyze the data.  This will add credibility to your research and will attract people to the optimization program. <br><br>  The discussion is useful for explaining the details and describing the reasons for the results.  It should make the team think about user behavior and develop further product improvements. </div><p>Source: <a href="https://habr.com/ru/post/261941/">https://habr.com/ru/post/261941/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../261927/index.html">DirectX rendering in WPF window</a></li>
<li><a href="../261931/index.html">Lines and probability theory</a></li>
<li><a href="../261935/index.html">Qihoo 360 and Go</a></li>
<li><a href="../261937/index.html">Network media server for PS3</a></li>
<li><a href="../261939/index.html">New PhpStorm 9: constant advance. Postfix code completion for PHP, Inline Debugger, and more.</a></li>
<li><a href="../261943/index.html">We pononet a bit: it became clearer what will happen to personal data after September 1, 2015</a></li>
<li><a href="../261945/index.html">Comparative test of popular antivirus software from the developer of cyber weapons Hacking Team</a></li>
<li><a href="../261951/index.html">We are pumping JavaScript using TurboFan</a></li>
<li><a href="../261953/index.html">Vundervaflya with one button</a></li>
<li><a href="../261955/index.html">Qt Framework: streams, hierarchical finite state machine, work with USB devices = QThread + QStateMachine + libUSB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>