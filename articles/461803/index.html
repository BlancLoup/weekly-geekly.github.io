<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Data Version Control (DVC): data versioning and experiment reproducibility</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article is a kind of master class ‚ÄúDVC for automating ML experiments and data versioning‚Äù, which took place on June 18 at the ML REPA (Machine Le...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Data Version Control (DVC): data versioning and experiment reproducibility</h1><div class="post__text post__text-html js-mediator-article">  This article is a kind of master class ‚ÄúDVC for automating ML experiments and data versioning‚Äù, which took place on June 18 at the ML REPA (Machine Learning REPA: <br>  Reproducibility, Experiments and Pipelines Automation) at our bank site. <br><br>  Here I will talk about the features of the internal work of DVC and how to use it in projects. <br><br>  The code examples used in the article are available <a href="https://github.com/mlrepa">here</a> .  The code was tested on MacOS and Linux (Ubuntu). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/webt/ol/je/jq/oljejq9wphbrkaudwspehuivhss.gif"></div><a name="habracut"></a><br><h3>  Content </h3><br>  Part 1 <br><br><ul><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">DVC setup</a> </li><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">DVC Features</a> <br><ul><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">Versioning Models and Data</a> </li><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">Automation of ML pipelines</a> </li><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">Metrics tracking</a> </li><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">Pipeline reproducibility</a> </li><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">Saving data to a remote repository</a> </li></ul></li></ul><br>  Part 2 <br><br><ul><li>  <a href="https://habr.com/ru/company/raiffeisenbank/blog/461803/">How to implement DVC in your projects?</a> </li></ul><br><a name="1"></a><h3>  DVC setup </h3><br>  Data Version Control is a tool that is designed to manage model and data versions in ML projects.  It is useful both at the experimental stage and for deploying your models into operation. <br><br><img src="https://habrastorage.org/webt/i6/l_/r0/i6l_r01fthd6lptmezat_znzwdo.png"><br><br>  DVC allows you to version models, data and pipelines in DS projects. <br>  The source is <a href="https://dvc.org/doc/tutorial">here</a> . <br><br>  Let's look at the DVC operation using the example of the iris color classification problem.  To do this, I will use the well-known dataset <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris Data Set</a> .  Other <a href="https://github.com/mlrepa/dvc-1-get-started/blob/master/tutorial.ipynb">examples of</a> working with DVC are shown by Jupyter Notebook. <br><br>  <b>What should be done:</b> <br><br><ul><li>  <a href="https://github.com/mlrepa/dvc-1-get-started">clone the repository;</a> </li><li>  create a virtual environment; </li><li>  install the necessary python packages; </li><li>  initialize DVC. </li></ul><br>  So, we clone the repository, create a virtual environment and install the necessary packages.  Installation and launch instructions are in the README repository. <br><blockquote>  1. Clone this repository <br><br><pre><code class="plaintext hljs">git clone https://gitlab.com/7labs.ru/tutorials-dvc/dvc-1-get-started.git cd dvc-1-get-started</code> </pre> <br>  2. Create and activate virtual environment <br><br><pre> <code class="plaintext hljs">pip install virtualenv virtualenv venv source venv/bin/activate</code> </pre> <br>  3. Install python libraries (including dvc) <br><br><pre> <code class="plaintext hljs">pip install -r requirements.txt</code> </pre> </blockquote><br>  To install DVC, use the <code>pip install dvc</code> command.  After installation, it is necessary to initialize the DVC in the <code>dvc init</code> project folder, which will generate a set of folders for further work of the DVC. <br><blockquote>  4. checkout new branch in demo repository (to not wipe content of master branch) <br><br><pre> <code class="plaintext hljs">git checkout -b dvc-tutorial</code> </pre> <br>  5. Initialize DVC <br><br><pre> <code class="plaintext hljs">dvc init commit dvc init git commit -m "Initialize DVC"</code> </pre> </blockquote><br>  DVC runs on top of Git, uses its infrastructure, and has similar syntax. <br>  In the process, DVC creates meta files to describe pipelines and versioned files that need to be saved in Git the history of your project.  Therefore, after executing <code>dvc init</code> you need to run <code>git commit</code> to commit all the settings made. <br><br>  The <code>.dvc</code> folder will appear in your repository, in which <code>cache</code> and <code>config</code> will lie. <br><br>  The contents of <code>.dvc</code> will look like this: <br><br><pre> <code class="python hljs">./ ../ .gitignore cache/ config</code> </pre> <br>  Config is the DVC configuration, and cache is the system folder into which DVC will store all the data and models that you will version. <br><br>  DVC will also create a <code>.gitignore</code> file, in which it will write those files and folders that do not need to be committed to the repository.  When you transfer a file to DVC for versioning in Git, versions and metadata will be saved, and the file itself will be stored in cache. <br><br>  Now you need to install all the dependencies, and then make a <code>checkout</code> in the new <code>dvc-tutorial</code> branch, in which we will work.  And download the Iris dataset. <br><blockquote>  Get data <br><br><pre> <code class="plaintext hljs">wget -P data/ https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv</code> </pre> </blockquote><br><a name="2"></a><h3>  <b>DVC Features</b> </h3><br><a name="3"></a>  <u>Versioning Models and Data</u> <br><img src="https://habrastorage.org/webt/iz/sp/lc/izsplcjf4il5fou5ermm-vmc3i4.png"><br>  The source is <a href="https://dvc.org/doc/use-cases/data-and-model-files-versioning">here</a> . <br><br>  Let me remind you that if you transfer some data under the control of DVC, then it will begin to track all changes.  And we can work with this data in the same way as with Git: save the version, send it to the remote repository, get the right version of the data, change and switch between versions.  The interface at DVC is very simple. <br><br>  Enter the <code>dvc add</code> command and specify the path to the file that we need to version.  DVC will create the iris.csv metafile with the extension .dvc, and write information about it to the cache folder.  Let's commit these changes so that information about the beginning of versioning appears in the Git history. <br><br><pre> <code class="python hljs">dvc add data/iris.csv</code> </pre> <br>  Inside the generated dvc file, its hash with standard parameters is stored. <br><br>  <code>Output</code> - the path to the file in the dvc folder, which we added under the control of DVC.  The system takes the data, puts it in the cache and creates a link to the cache in the working directory.  This file can be added to the Git history and thus versioned.  DVC takes over the management of the data itself.  The first two characters of the hash are used as the folder inside the cache, and the remaining characters are used as the name of the created file. <br><br><img src="https://habrastorage.org/webt/2d/8h/h1/2d8hh1p69aw2gu8j2f3lykygv_g.png"><br><br><a name="4"></a>  <u>Automation of ML Pipelines</u> <br><br>  In addition to data version control, we can create pipelines (pipelines) - chains of calculations between which dependencies are defined.  Here is the standard pipeline for classifier training and assessment: <br><br><img src="https://habrastorage.org/webt/qd/th/xb/qdthxbdo4-he5hswnlagqebeqo0.png"><br><br>  At the input, we have data that must be pre-processed, divided into train and test, calculate the characteristics and only then train the model and evaluate it.  This pipeline can be broken into separate pieces.  For example, to distinguish the stage of loading and preprocessing data, splitting data, evaluating, etc., and connecting these chains together. <br><br>  To do this, the DVC has a wonderful <code>dvc run</code> command, in which we pass certain parameters and specify the Python module that we need to run. <br><br>  Now - for example, the launch phase of the calculation of signs.  First, let's look at the contents of the featureization.py module: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataset)</span></span></span><span class="hljs-function">:</span></span> features = dataset.copy() <span class="hljs-comment"><span class="hljs-comment"># uncomment for step 5.2 Add features # features['sepal_length_to_sepal_width'] = features['sepal_length'] / features['sepal_width'] # features['petal_length_to_petal_width'] = features['petal_length'] / features['petal_width'] return features if __name__ == '__main__': dataset = pd.read_csv('data/iris.csv') features = get_features(dataset) features.to_csv('data/iris_featurized.csv', index=False)</span></span></code> </pre> <br>  This code takes the dataset, calculates the characteristics and saves them in iris_featurized.csv.  We left the calculation of additional signs to the next stage. <br><br>  To create a pipeline, it is necessary to execute the command for each stage of calculations <br>  <code>dvc run</code> . <br><br><img src="https://habrastorage.org/webt/0u/mr/na/0umrna10h7yubpqn0muenf1j3ky.png"><br><br>  First, in the <code>dvc run</code> command, specify the name of the stage_feature_extraction.dvc metafile, in which the DVC will write the necessary metadata about the calculation stage.  Through the <code>-d</code> argument, we specify the necessary dependencies: the featureization.py module and the iris.csv data file.  We also specify the iris_featurized.csv file, in which the signs are saved, and the python src / featurization.py launch command itself. <br><br><pre> <code class="python hljs">dvc run -f stage_feature_extraction.dvc \ -d src/featurization.py \ -d data/iris.csv \ -o data/iris_featurized.csv \ python src/featurization.py</code> </pre> <br>  DVC will create a metafile and will track changes in the Python module and the iris.csv file. <br>  If changes occur in them, the DVC will restart this calculation step in the pipeline. <br><br>  The resulting stage_feature_extraction.dvc file will contain its hash, start command, dependencies and output (there are additional parameters for them that can be found in the metadata). <br><br>  Now you need to save this file in the history of Git commits.  Thus, we can create a new branch and push it into the Git repository.  You can commit to a Git story either by creating each stage individually, or all stages at once. <br><br>  When we build such a chain for our entire experiment, DVC builds a computation graph (DAG), by which it can start either recalculation of the entire pipeline or some part.  The hashes of the output from one stage go to the inputs of another.  According to them, DVC tracks dependencies and builds a graph of calculations.  If you changed the code somewhere in split_dataset.py, the DVC will not load the data and possibly recalculate the signs, but will restart this stage and the subsequent training and evaluation stages. <br><br><img src="https://habrastorage.org/webt/7c/_u/6t/7c_u6txcw7wv7c68gvu6_wdmnpo.png"><br><br><a name="5"></a>  <u>Metrics tracking</u> <br><br>  Using the <code>dvc metrics show</code> command, you can display the metrics of the current launch, the branch in which we are located.  And if we pass the <code>-a</code> option, the DVC will show all the metrics that are in the Git history.  In order for DVC to start tracking metrics, when creating the evaluate step, we pass the <code>-m</code> parameter through data / eval.txt.  The evaluate.py module writes metrics to this file, in this case <code>f1</code> and <code>confusion metrics</code> .  In the output folder in the dvc file of this step, <code>cache</code> and <code>metrics</code> set to true.  That is, the dvc metrics show command will output the contents of the eval.txt file to the console.  Also, with the arguments of this command, you can show only <code>f1_score</code> or only <code>confusion_matrix</code> . <br><br><img src="https://habrastorage.org/webt/wg/xq/jn/wgxqjnhy8yzuxlnsdnxixbhswks.png"><br><br>  In this example, we got these results: <br><br><img src="https://habrastorage.org/webt/tz/cf/-r/tzcf-r9pym3mm8c9ptkywohn4wo.png"><br><br><a name="6"></a>  <u>Pipeline reproducibility</u> <br><br>  Those who have worked with this dataset know that it is very difficult to build a good model on it. <br><br>  Now we have a pipeline created using DVC.  The system tracks the history of data and the model, can restart itself in whole or in part, and can display metrics.  We have completed all the necessary automation. <br><br>  We had a model with f1 = 0.78.  We want to improve it by changing some parameters.  To do this, restart the entire pipeline, ideally, with just one command.  In addition, if you are working in a team, you may want to pass on the model and code to colleagues so that they can continue to work on them. <br><br>  The <code>dvc repro</code> allows <code>dvc repro</code> to restart pipelines or individual stages (in this case, you need to specify the reproduced stage after the command). <br><br>  <code>dvc repro stage_evaluate</code> , the stage will try to restart the entire pipeline.  But if we do this in the current state, the DVC will not see any changes and will not restart.  And if we change something, he will find the change and restart the pipeline from this point on. <br><br><pre> <code class="python hljs">$ dvc repro stage_evaluate.dvc Stage <span class="hljs-string"><span class="hljs-string">'data/iris.csv.dvc'</span></span> didn<span class="hljs-string"><span class="hljs-string">'t change. Stage '</span></span>stage_feature_extraction.dvc<span class="hljs-string"><span class="hljs-string">' didn'</span></span>t change. Stage <span class="hljs-string"><span class="hljs-string">'stage_split_dataset.dvc'</span></span> didn<span class="hljs-string"><span class="hljs-string">'t change. Stage '</span></span>stage_train.dvc<span class="hljs-string"><span class="hljs-string">' didn'</span></span>t change. Stage <span class="hljs-string"><span class="hljs-string">'stage_evaluate.dvc'</span></span> didn<span class="hljs-string"><span class="hljs-string">'t change. Pipeline is up to date. Nothing to reproduce.</span></span></code> </pre> <br>  In this case, the DVC did not see any changes in the stage_evaluate stage dependencies and refused to restart.  And if we specify the <code>-f</code> option, then it will restart all the preliminary steps and show a warning that it deletes previous versions of the data that it was tracking.  Each time the DVC restarts the stage, it deletes the previous cache, actually overwrites it so as not to duplicate data.  At the moment the DVC file is launched, its hash will be checked, and if it has changed, the pipeline will restart and overwrite all the output that this pipeline has.  If you want to avoid this, you must first run a specific version of the data in some remote repository. <br><br>  The ability to restart pipelines and track the dependencies of each stage allows you to experiment with models faster. <br><br>  For example, you can change the characteristics ('uncomment' the lines for calculating the characteristics in <code>featurization.py</code> ).  DVC will see these changes and restart the entire pipeline. <br><br><a name="7"></a>  <u>Saving data to a remote repository</u> <br><img src="https://habrastorage.org/webt/6r/oz/ts/6roztsbchi1rii7avixi08pq4ws.png"><br><br>  DVC can work not only with local version storage.  If you execute the <code>dvc push</code> command, the DVC will send the current version of the model and data to a pre-configured remote repository repository.  If then your colleague makes the <code>git clone</code> your repository and performs <code>dvc pull</code> , he will receive the version of the data and models that is intended for this branch.  The main thing is that everyone has access to this repository. <br><br><img src="https://habrastorage.org/webt/zu/kt/a_/zukta_xkhshrdsoiiqdfrors8iy.png"><br><br>  In this case, we simulate the ‚Äúremote‚Äù storage in the temp / dvc folder.  In approximately the same way, remote storage is created in the cloud.  Commit this change so that it remains in the Git story.  Now we can perform <code>dvc push</code> to send data to this storage, and your colleague simply <code>dvc pull</code> to receive them. <br><br>  <b>So</b> , we examined three situations in which DVC and basic functionality are useful: <br><br><ul><li>  <b>Versioning data and models</b> .  If you do not need pipes and remote repositories, you can version the data for a specific project, working on the local machine.  DVC allows you to quickly work with data in tens of gigabytes. </li><li>  <b>Exchange of data and models between teams</b> .  You can use cloud solutions to store data.  This is a convenient option if you have a distributed team or there are restrictions on the size of files sent by mail.  Also, this technique can be used in situations when you send each other a Notebook, but they do not start. </li><li>  <b>Organization of team work inside a large server</b> .  The team can work with the local version of big data, for example, several tens or hundreds of gigabytes, so that you do not copy them back and forth, but use one remote storage that will send and save only critical versions of models or data. </li></ul><br><h3>  <b>Part 2</b> </h3><br><a name="8"></a>  <u>How to implement DVC in your projects?</u> <br><br>  To ensure reproducibility of the project, certain requirements must be observed. <br>  Here are the main ones: <br><br><ul><li>  all pipelines are automated; </li><li>  control of launch parameters of each stage of calculations; </li><li>  version control of code, data and models; </li><li>  environmental control; </li><li>  documentation. </li></ul><br>  If all this is done, then the project is more likely to be reproducible.  DVC allows you to fulfill the 3 first requirements in this list. <br><br>  When trying to implement DVC in your company, you may encounter reluctance: ‚ÄúWhy do we need this?  We have a Jupyter Notebook. ‚Äù  Perhaps some of your colleagues only work with Jupyter Notebook, and it is much more difficult for them to write such pipelines and code in the IDE.  In this case, you can go through a step-by-step implementation. <br><br><ol><li>  The easiest way to start is by versioning the code and models. <br>  And then move on to automating the pipelines. </li><li>  First automate the steps that often restart and change, <br>  and then the whole pipeline. </li></ol><br>  If you have a new project and a couple of enthusiasts in a team, then it is better to use DVC right away.  So, for example, it turned out in our team!  When starting a new project, my colleagues supported me, and we started using DVC on our own.  Then they began to share with other colleagues and teams.  Someone picked up our undertaking.  Today, DVC is not yet a generally accepted tool in our bank, but it is used in several projects. </div><p>Source: <a href="https://habr.com/ru/post/461803/">https://habr.com/ru/post/461803/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../461793/index.html">Ivan Ponomarev about Kafka Streams API at jug.msk.ru meeting</a></li>
<li><a href="../461797/index.html">Tales of service. A frivolous post about serious work</a></li>
<li><a href="../4618/index.html">J & P: You can make good money on smartphones</a></li>
<li><a href="../46180/index.html">Party in honor of the new premises! (Moscow, December 9, 18:00)</a></li>
<li><a href="../461801/index.html">DisplayPort-LVDS</a></li>
<li><a href="../461805/index.html">Monte Carlo Integration Application in Rendering</a></li>
<li><a href="../461807/index.html">How pod priorities at Kubernetes caused downtime at Grafana Labs</a></li>
<li><a href="../461815/index.html">A revolution in the design of computer power supplies half a century ago</a></li>
<li><a href="../461817/index.html">CMake and C ++ - brothers forever</a></li>
<li><a href="../461819/index.html">Why simple website design is better scientifically</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>