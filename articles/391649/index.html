<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Do robots need their own wikipedia?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Welcome to the pages of the blog iCover ! Despite the skepticism of a certain part of intellectuals to such resources as Wikipedia, which in some case...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Do robots need their own wikipedia?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/d31/9d1/d04/d319d1d046e94964a78fbb57492c3d6c.png"><br><a name="habracut"></a><br>  Welcome to the pages of the blog <a href="http://www.icover.ru/">iCover</a> !  Despite the skepticism of a certain part of intellectuals to such resources as Wikipedia, which in some cases has sufficiently strong reasons, in general, the value of this informational source accessible to all should nevertheless be considered positive.  Of course, it would be rash to link a visit to Wikipedia or YouTube with some kind of scientific revelation, it‚Äôs more about access to information about quite trivial things that help us respond to current challenges and questions of our time.  So, for example, a video on how to cook an omelet using the original recipe viewed on YouTube will allow us to quickly and effectively improve our culinary literacy without resorting to the need of tedious learning recipes from the cookbook.  Why are we, actually? <br><br>  The question is of interest: everything is fairly simple, clear and familiar to us, and how can we most effectively adapt the knowledge accumulated by mankind to the learning process of robots?  It is clear that the value of the information provided by the PS to the robot in response to its ‚Äúsearch query‚Äù: what is the algorithm for transferring a cup of tea from the kitchen to the living room?  ... will be reduced to zero.  In order to assimilate information, the machine needs a detailed answer, step-by-step instructions with specific actions and an understanding of the language.  So in our example with a cup of tea you will need to provide information about the coordinates of the tea container, the method of capture, the place where it should be transported, etc. Of course, the example is intended to be simplified - in real life with a randomly changing environment, information acquires many different vector parameters and introductory.  And here we see a certain problem: the specifics of many existing methods of teaching robotic complexes imposes some limitations on the effectiveness of such training. <br><br>  Finding ways to create uniform algorithms and information sources for productive learning of robots becomes a powerful incentive to search for and develop new directions and ways of communicating special knowledge and gaining the required experience.  Today we will touch upon two promising areas, working on which researchers have already managed to achieve certain positive results. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  <font color="¬´#6aa400¬ª">Learning Robots with YouTube</font> </h2><br>  So, as we found out, those things that seem simple and natural to us (simple body movements, processing vegetables, working with a vacuum cleaner, cooking according to the usual recipes, etc.) for a robot that has not undergone special training are an unsolvable problem.  The fact is that at this stage, robots, unlike humans, are not yet able to learn empirically, independently explore the world and relate the surrounding objects with certain qualities.  Thus, today, at the dawn of robotics development, the robot still needs to be taught each elementary movement separately - how to open a refrigerator, how to take a container, how to open it, how to extract the contents. <br><br>  The absence of such a valuable human quality as intuition and any skills of associative thinking and the learning process of robots, which is delaying in this regard, forced specialists to search and develop alternative techniques.  Experts from the Institute of Advanced Computer Technologies (Maryland, USA) offered their answer to the question, using YouTube videos to speed up and improve the quality of education. <br><br>  In this case, an increase in the effectiveness of the learning process is observed due to the simultaneous use of two channels of information identification ‚Äî the recognition by artificial intelligence of actions performed by a person in a training video and the recognition of speech information by parsing the language.  The learning process allows at any given time to associate specific words and phrases with the corresponding meanings and actions performed on the monitor screen. <br><br>  According to the participants of the experiment, the use of the ‚Äútwo-channel‚Äù training method has already allowed us to demonstrate the level of accuracy of the tasks at 77%, with the material memorization rate of 76%.  At the same time, the module recognizes objects with an accuracy of 93% and in the future will be able to identify more complex verbal commands with a high degree of accuracy. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/xRwhsFtUnpc%3Ffeature%3Doembed&amp;xid=17259,1500004,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhi0ICs8HzBRQBihfbXfQJjvZOl_0w" frameborder="0" allowfullscreen=""></iframe><br><br><h2>  <font color="¬´#6aa400¬ª">Cloud learning</font> </h2><br>  Robotics are familiar with the problems that their mechanical wards experience when developing algorithms for capturing objects of various shapes, weights, and sizes.  Obvious problems robots have in cases where it is necessary to pick up or use objects for which they are unfamiliar.  And here cloud technologies are indispensable.  A team at Brown University, USA, led by Stephanie Tellex (Stefanie Tellex), is conducting an experiment to train the Baxter collaborative robot to capture objects and transfer their experience to fellow robots of the same model. <br><br>  A robot that first encounters an object scans the latter with infrared sensors, which allows it to identify the shape of the object.  And the next step is the choice of the approach that will be optimal when lifting an object of this shape.  Such an algorithm works in most cases and turns out to be 75% more successful than capture attempts made under the standard protocol.  But this is only the first step.  At the next stage, the resulting positive ‚Äúexperience‚Äù is loaded into the cloud, which is essentially a database of already studied objects for all robots connected to it and a kind of analogue to the aforementioned Wikipedia. <br><br>  Today, about 300 Baxter robots work in laboratories around the world.  Experts estimate that if they all took part in the replenishment of the common cloud database, then every 11 days with a full load of the robotic community, the library could be supplemented with information about one million of the objects under study.  Due to the fact that the basic platform can be improved, such an approach in the future can be a powerful incentive for the development of the whole community.  So, for example, relatively recently, Baxter received a ‚Äúsoft grip‚Äù, allowing him to lift many objects without compromising their integrity. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/Y5kZO8SSxVw%3Ffeature%3Doembed&amp;xid=17259,1500004,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhQi0yvn0r-F_ngciTEan2C9qw-yw" frameborder="0" allowfullscreen=""></iframe><br><br>  The possibility of raising a variety of items without the risk of dropping and damaging them will in the long run allow us to consider new areas of application of such robots not only on assembly lines, but also in the infrastructure of warehouse complexes of various specificities.  And this is only the beginning, and in the long term the possibilities of collective self-learning, which the cloud environment ‚ÄúRobopedia‚Äù (author‚Äôs term) will reveal, will most likely be used in practically any area of ‚Äã‚Äãrobotics, from <a href="http://www.zdnet.com/article/robot-operates-from-inside-patient-for-first-time/">medicine</a> to the <a href="http://fortune.com/2016/03/09/hilton-robot-ibm-watson/">service sector</a> and <a href="http://ooo-its.ru/">fire fighting</a> . <br><br>  Positive examples that reveal the potential of the concept of cloud learning, today allow us to look optimistically at the future of this approach.  Among such examples are the simplest ways of learning the recognition of photo libraries that help in identifying objects and whole sets of algorithms that allow you to transfer individual skills of a higher order.  And to create an intelligent learning cloud today, experts at Brown, Stanford and Cornell University are actively working.  At the present stage of research, the robotic system allows you to save and transfer information on symbols, syntax elements, shapes, tactile properties, and motor skills to a common information cloud. <br><br>  The approach to learning using cloudy Robopedia appeared relatively recently.  Until recently, the overwhelming majority of researchers viewed the learning process as isolated.  The revision of the concept of training will allow specialists to focus on improving the algorithms of robots, while having free access to the full and relevant library of knowledge accumulated in the field at the moment. <br><hr><br>  Dear readers, we are always happy to meet and wait for you on the pages of our blog.  We are ready to continue to share with you the latest news, review materials and other publications, and we will try to do everything possible so that the time spent with us will be useful for you.  And, of course, do not forget to subscribe to <a href="http://geektimes.ru/company/icover/profile/">our headings</a> . <br>  Our other articles and events <br><br><ul><li>  <a href="http://www.icover.ru/promo/gator-caref-watch-zabota-o-vashem-rebenke/">Gator Caref Watch.</a>  <a href="http://www.icover.ru/promo/gator-caref-watch-zabota-o-vashem-rebenke/">Caring for your child</a> </li><li>  <a href="http://www.icover.ru/promo/skidki-ot-kitchenaid/">Spring discounts from KitchenAid</a> </li><li>  <a href="http://www.icover.ru/sale/">Sale of useful gadgets and interesting pieces</a> </li><li>  <a href="http://www.icover.ru/blog/article/logitech-rasshiryaet-lineyku-mekhanicheskikh-igrovykh-klaviatur-s-tsvetnoy-podsvetkoy/">Logitech Expands Color-Illuminated Mechanical Gaming Keyboards</a> </li><li>  <a href="http://www.icover.ru/blog/article/vybor-umnykh-chasov-segodnya-chto-izmenilos/">A selection of smart watches today.</a>  <a href="http://www.icover.ru/blog/article/vybor-umnykh-chasov-segodnya-chto-izmenilos/">What changed?</a> </li><li>  <a href="http://www.icover.ru/blog/article/idealnyy-gadzhetoryukzak-dlya-ottsa-semeystva/">Perfect gadget backpack for father family</a> </li><li>  <a href="http://www.icover.ru/blog/article/kak-chekhol-ne-spas-moy-iphone-vybiray-pravilno/">How the case did not save my iPhone.</a>  <a href="http://www.icover.ru/blog/article/kak-chekhol-ne-spas-moy-iphone-vybiray-pravilno/">Choose right</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/391649/">https://habr.com/ru/post/391649/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../391637/index.html">ASUS ZenPad 10 Tablet Review</a></li>
<li><a href="../391639/index.html">Top 10 torrent trackers over the hill</a></li>
<li><a href="../391641/index.html">Diablo game] [got the first patch in 6 years</a></li>
<li><a href="../391645/index.html">Lenovo Yoga: a brief history and mini-review of the Yoga 900</a></li>
<li><a href="../391647/index.html">Mission "ExoMars" contacted the Earth</a></li>
<li><a href="../391651/index.html">Media magnate Dmitry Itskov plans to live forever, uploading his identity to the robot</a></li>
<li><a href="../391657/index.html">Flight Anchorage-Honolulu was delayed by 25 minutes to please Umbrafilov on board</a></li>
<li><a href="../391659/index.html">Lee Sedol won the fourth game with AlphaGo</a></li>
<li><a href="../391661/index.html">15 interesting and useful services from Google</a></li>
<li><a href="../391663/index.html">World Drone Prix 2016</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>