<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Installing PROXMOX 4.3 on Soft-RAID 10 GPT</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon friends. Today I would like to share my personal experience in setting up Proxmox on soft-Raid 10. 

 What we have: 


- HP ProLiant DL...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Installing PROXMOX 4.3 on Soft-RAID 10 GPT</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon friends.  Today I would like to share my personal experience in setting up Proxmox on soft-Raid 10. <br><br>  <b>What we have:</b> <br><ul><li>  HP ProLiant DL120 G6 Server (10 GB RAM) </li><li>  4x1000Gb SATA HDD - no physical RAID controller on board </li><li>  USB flash drive with PROXMOX 4.3 (more on this below) </li></ul><br>  <b>What we want:</b> <br><ul><li>  Get the installation of PROXMOX 4.3 installed completely on the S-RAID 10 GPT, so that if any disk fails, the system will continue to work. </li><li>  Get a notification about the failure of a failed disk in the mail. </li></ul><br>  <b>What we do - the general plan of action:</b> <br><ul><li>  Install PROXMOX 4.3 </li><li>  Raise and test RAID10 </li><li>  Set up email notifications </li></ul><br>  Under the cut stage of the quest. <br><a name="habracut"></a><br>  And now in stages. <br><br>  <b>First moment:</b> <br>  I connected the USB flash drive - if in brief - the installation disk was not found.  I can not mount. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/950/f99/242/950f992425418e9b2b9b91f0db74551e.png" alt="image"><br><br>  I did not understand what yes how, yes why.  I recorded the image on a CD and connected a USB CDROM (since it was near) <br><br>  <b>The second point:</b> <br>  I connected the CDROM and the keyboard to the front ports of the server (there are two of them) to the server - the first thing I saw, on the first welcome screen of the proxmox, you cannot press anything without a mouse.  That is, tab overlapping control buttons does not occur.  Since  the server was in a rack and it was problematic to climb behind it, began to stick in turns with the keyboard and mouse.  I click ‚Äúfurther‚Äù with the mouse, with the keyboard - I enter the data. <br><br>  <b>The installation consists of several steps:</b> <br><br><ul><li>  Agree with their requirements </li><li>  Select the hard drive where the system is installed. </li><li>  Select a country and time zone </li><li>  Specify server name, addressing </li><li>  And actually wait a bit to scan the image on the server. </li></ul><br>  PROXMOX is installed on the first disk, which he called as / dev / sda.  I connect from my laptop to the address I specified during installation: <br><br><pre><code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#ssh root@192.168.1.3</span></span></code> </pre> <br>  I update the system: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#apt-get update</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">I see at the exit</b> <div class="spoiler_text"><pre> <code class="hljs sql">Ign http://ftp.debian.org jessie InRelease Get:1 http://ftp.debian.org jessie Release.gpg [<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">373</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://security.debian.org jessie/updates InRelease [<span class="hljs-number"><span class="hljs-number">63.1</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://ftp.debian.org jessie <span class="hljs-keyword"><span class="hljs-keyword">Release</span></span> [<span class="hljs-number"><span class="hljs-number">148</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span> https://enterprise.proxmox.com jessie InRelease [<span class="hljs-number"><span class="hljs-number">401</span></span> B] Ign https://enterprise.proxmox.com jessie InRelease <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">5</span></span> https://enterprise.proxmox.com jessie Release.gpg [<span class="hljs-number"><span class="hljs-number">401</span></span> B] Ign https://enterprise.proxmox.com jessie Release.gpg <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">6</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://ftp.debian.org jessie/<span class="hljs-keyword"><span class="hljs-keyword">main</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">787</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span> https://enterprise.proxmox.com jessie <span class="hljs-keyword"><span class="hljs-keyword">Release</span></span> [<span class="hljs-number"><span class="hljs-number">401</span></span> B] Ign https://enterprise.proxmox.com jessie <span class="hljs-keyword"><span class="hljs-keyword">Release</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://security.debian.org jessie/updates/<span class="hljs-keyword"><span class="hljs-keyword">main</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">313</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">9</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en_US [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">11</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">12</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">13</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en_US [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">14</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">15</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">16</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en_US [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">17</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">18</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">19</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en_US [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">20</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://security.debian.org jessie/updates/contrib amd64 Packages [<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">506</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">21</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">22</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> amd64 Packages [<span class="hljs-number"><span class="hljs-number">401</span></span> B] Err https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> amd64 Packages HttpError401 <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">23</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en_US [<span class="hljs-number"><span class="hljs-number">401</span></span> B] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">24</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://security.debian.org jessie/updates/contrib <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">211</span></span> B] Ign https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en_US <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">25</span></span> https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">401</span></span> B] Ign https://enterprise.proxmox.com jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://security.debian.org jessie/updates/<span class="hljs-keyword"><span class="hljs-keyword">main</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">169</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">27</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://ftp.debian.org jessie/contrib amd64 Packages [<span class="hljs-number"><span class="hljs-number">50.2</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://ftp.debian.org jessie/contrib <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">38.5</span></span> kB] <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span>:<span class="hljs-number"><span class="hljs-number">29</span></span> <span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://ftp.debian.org jessie/<span class="hljs-keyword"><span class="hljs-keyword">main</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Translation</span></span>-en [<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">583</span></span> kB] Fetched <span class="hljs-number"><span class="hljs-number">12.2</span></span> MB <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>s (<span class="hljs-number"><span class="hljs-number">778</span></span> kB/s) W: <span class="hljs-keyword"><span class="hljs-keyword">Failed</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">fetch</span></span> https://enterprise.proxmox.com/debian/dists/jessie/pve-<span class="hljs-keyword"><span class="hljs-keyword">enterprise</span></span>/<span class="hljs-built_in"><span class="hljs-built_in">binary</span></span>-amd64/Packages HttpError401 E: <span class="hljs-keyword"><span class="hljs-keyword">Some</span></span> <span class="hljs-keyword"><span class="hljs-keyword">index</span></span> files <span class="hljs-keyword"><span class="hljs-keyword">failed</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> download. They have been ignored, <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-keyword"><span class="hljs-keyword">old</span></span> ones used instead.</code> </pre> <br></div></div><br>  This is not the case.  I do not plan to buy a license for support yet.  I am changing the official subscription to their ‚Äúfree‚Äù repository. <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#nano /etc/apt/sources.list.d/pve-enterprise.list</span></span></code> </pre> <br>  I see there: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">deb</span></span> https://enterprise.proxmox.com/debian jessie pve-enterprise</code> </pre> <br>  Change to: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">deb</span></span> http://download.proxmox.com/debian jessie pve-<span class="hljs-literal"><span class="hljs-literal">no</span></span>-subscription</code> </pre> <br>  And again updated and put the new system: <br><br><pre> <code class="hljs pgsql">root@pve1:~#apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> &amp;&amp; apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> upgrade</code> </pre> <br>  Now everything has been updated without hesitation and the system is in the new state.  I put the packages to work with the raid: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#apt-get install -y mdadm initramfs-tools parted</span></span></code> </pre> <br>  Now we determine the exact size of the first disk, it will be useful to us in the following: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda print</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Model: ATA MB1000EBNCF (scsi) Disk /dev/sda: <span class="hljs-number"><span class="hljs-number">1000</span></span>GB Sector size (logical/physical): <span class="hljs-number"><span class="hljs-number">512</span></span>B/<span class="hljs-number"><span class="hljs-number">512</span></span>B <span class="hljs-keyword"><span class="hljs-keyword">Partition</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Table</span></span>: gpt Disk Flags: Number <span class="hljs-keyword"><span class="hljs-keyword">Start</span></span> <span class="hljs-keyword"><span class="hljs-keyword">End</span></span> Size File <span class="hljs-keyword"><span class="hljs-keyword">system</span></span> <span class="hljs-type"><span class="hljs-type">Name</span></span> Flags <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">1049</span></span>kB <span class="hljs-number"><span class="hljs-number">10.5</span></span>MB <span class="hljs-number"><span class="hljs-number">9437</span></span>kB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span> bios_grub <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">10.5</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>MB <span class="hljs-number"><span class="hljs-number">990</span></span>MB ext4 <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">1000</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>GB <span class="hljs-number"><span class="hljs-number">999</span></span>GB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span></code> </pre> <br>  We see that exactly 1000GB - remember.  Mark up the rest of the sections under our array.  First, clear the partition table on three empty disks and mark up the disks under GPT: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#dd if=/dev/zero of=/dev/sb[bcd] bs=512 count=1</span></span></code> </pre> <br><pre> <code class="hljs objectivec"><span class="hljs-number"><span class="hljs-number">1</span></span>+<span class="hljs-number"><span class="hljs-number">0</span></span> records <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>+<span class="hljs-number"><span class="hljs-number">0</span></span> records <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-number"><span class="hljs-number">512</span></span> bytes (<span class="hljs-number"><span class="hljs-number">512</span></span> B) copied, <span class="hljs-number"><span class="hljs-number">7.8537e-05</span></span> s, <span class="hljs-number"><span class="hljs-number">6.5</span></span> MB/s</code> </pre> <br>  <b>Mark up:</b> <br><br>  Second: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb mklabel gpt</span></span></code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-built_in"><span class="hljs-built_in">Warning</span></span>: The existing disk label <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> /dev/sdb will be destroyed <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> this disk will be lost. <span class="hljs-keyword"><span class="hljs-keyword">Do</span></span> you want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>? Yes/<span class="hljs-keyword"><span class="hljs-keyword">No</span></span>? yes Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  Third: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdc mklabel gpt</span></span></code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-built_in"><span class="hljs-built_in">Warning</span></span>: The existing disk label <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> /dev/sdc will be destroyed <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> this disk will be lost. <span class="hljs-keyword"><span class="hljs-keyword">Do</span></span> you want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>? Yes/<span class="hljs-keyword"><span class="hljs-keyword">No</span></span>? yes Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  Fourth: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdd mklabel gpt</span></span></code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-built_in"><span class="hljs-built_in">Warning</span></span>: The existing disk label <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> /dev/sdd will be destroyed <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> this disk will be lost. <span class="hljs-keyword"><span class="hljs-keyword">Do</span></span> you want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>? Yes/<span class="hljs-keyword"><span class="hljs-keyword">No</span></span>? yes Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  Now we recreate the partitions in the same way as on the original first disk: <br><br>  one. <pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb mkpart primary 1M 10M</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  2 <pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb set 1 bios_grub on</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  3 <pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb mkpart primary 10 1G</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  Here we will need to know the size of the original first disc. <br><br>  four. <pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb mkpart primary 1G 1000GB</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  We perform all these four steps for all our disks: sdb, sdc, sdd.  Here's what I got: <br><br>  This is the original: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda print</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Model: ATA MB1000EBNCF (scsi) Disk /dev/sda: <span class="hljs-number"><span class="hljs-number">1000</span></span>GB Sector size (logical/physical): <span class="hljs-number"><span class="hljs-number">512</span></span>B/<span class="hljs-number"><span class="hljs-number">512</span></span>B <span class="hljs-keyword"><span class="hljs-keyword">Partition</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Table</span></span>: gpt Disk Flags: Number <span class="hljs-keyword"><span class="hljs-keyword">Start</span></span> <span class="hljs-keyword"><span class="hljs-keyword">End</span></span> Size File <span class="hljs-keyword"><span class="hljs-keyword">system</span></span> <span class="hljs-type"><span class="hljs-type">Name</span></span> Flags <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">17.4</span></span>kB <span class="hljs-number"><span class="hljs-number">1049</span></span>kB <span class="hljs-number"><span class="hljs-number">1031</span></span>kB bios_grub <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">1049</span></span>kB <span class="hljs-number"><span class="hljs-number">134</span></span>MB <span class="hljs-number"><span class="hljs-number">133</span></span>MB fat32 boot, esp <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">134</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>GB <span class="hljs-number"><span class="hljs-number">1000</span></span>GB lvm</code> </pre> <br>  And this is the second, third and fourth (with a difference in the drive letter). <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb print</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Model: ATA MB1000EBNCF (scsi) Disk /dev/sdd: <span class="hljs-number"><span class="hljs-number">1000</span></span>GB Sector size (logical/physical): <span class="hljs-number"><span class="hljs-number">512</span></span>B/<span class="hljs-number"><span class="hljs-number">512</span></span>B <span class="hljs-keyword"><span class="hljs-keyword">Partition</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Table</span></span>: gpt Disk Flags: Number <span class="hljs-keyword"><span class="hljs-keyword">Start</span></span> <span class="hljs-keyword"><span class="hljs-keyword">End</span></span> Size File <span class="hljs-keyword"><span class="hljs-keyword">system</span></span> <span class="hljs-type"><span class="hljs-type">Name</span></span> Flags <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">1049</span></span>kB <span class="hljs-number"><span class="hljs-number">10.5</span></span>MB <span class="hljs-number"><span class="hljs-number">9437</span></span>kB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span> bios_grub <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">10.5</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>MB <span class="hljs-number"><span class="hljs-number">990</span></span>MB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">1000</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>GB <span class="hljs-number"><span class="hljs-number">999</span></span>GB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span></code> </pre> <br>  Next, you need to clarify - if you are playing with this case for the first time and before that there was not even a RAID concept on the server, and most importantly on the hard drives, you can skip this point.  If something didn‚Äôt work out, then RAID was probably already installed and there are superblocks on the hard drives that need to be removed. <br><br>  Check out so: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --misc --examine /dev/sda</span></span></code> </pre> <br><pre> <code class="hljs pgsql">/dev/sda: MBR Magic : aa55 <span class="hljs-keyword"><span class="hljs-keyword">Partition</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>] : <span class="hljs-number"><span class="hljs-number">1953525167</span></span> sectors at <span class="hljs-number"><span class="hljs-number">1</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">type</span></span> ee)</code> </pre> <br>  You need to check all four disks. <br><br>  <b>Now configure mdadm</b> <br><br>  Create a config based on the example: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#cp /etc/mdadm/mdadm.conf /etc/mdadm/mdadm.conf.orig</span></span></code> </pre> <br>  We empty: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#echo "" &gt; /etc/mdadm/mdadm.conf</span></span></code> </pre> <br>  Open: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#nano /etc/mdadm/mdadm.conf</span></span></code> </pre> <br>  Enter and save: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> owner=root <span class="hljs-keyword"><span class="hljs-keyword">group</span></span>=disk mode=<span class="hljs-number"><span class="hljs-number">0660</span></span> auto=yes MAILADDR <span class="hljs-keyword"><span class="hljs-keyword">user</span></span>@mail.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span></code> </pre> <br>  For now, we will leave the mail as it is, then we will return to it. <br><br>  Now we are raising our RAID in degradation mode (skipping the first working hard drive). <br><br><ul><li>  In / dev / md0 - I will have / boot </li><li>  In / dev / md1 - VML partition with system </li></ul><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --create /dev/md0 --metadata=0.90 --level=10 --chunk=2048 --raid-devices=4 missing /dev/sd[bcd]2</span></span></code> </pre> <br><pre> <code class="hljs pgsql">mdadm: <span class="hljs-keyword"><span class="hljs-keyword">array</span></span> /dev/md0 started.</code> </pre> <br>  And the second: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --create /dev/md1 --metadata=0.90 --level=10 --chunk=2048 --raid-devices=4 missing /dev/sd[bcd]3</span></span></code> </pre> <br><pre> <code class="hljs pgsql">mdadm: <span class="hljs-keyword"><span class="hljs-keyword">array</span></span> /dev/md1 started.</code> </pre> <br>  Here it is necessary to clarify the keys: <br><br><ul><li>  --level = 10 - says that our RAID will be exactly 10 </li><li>  --chunk = 2048 - cluster size on partition </li><li>  --raid-devices = 4 - four devices will take part in the raid </li><li>  missing / dev / sd [bcd] 2 - while we mark the first working section as missing, add the other three to the raid </li></ul><br>  UDP  After a mass of comments, I came out at one important point. <br>  In the process of creating, I deliberately set the chunk size to 2048, instead of skipping this flag and leaving it by default.  This flag significantly reduces performance.  This is especially visually noticeable on Windows virtual machines. <br><br>  That is, the right team to create should look like this: <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --create /dev/md0 --metadata=0.90 --level=10 --raid-devices=4 missing /dev/sd[bcd]2</span></span></code> </pre> <br>  and <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --create /dev/md1 --metadata=0.90 --level=10 --raid-devices=4 missing /dev/sd[bcd]3</span></span></code> </pre> <br><br>  Save the configuration: <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --detail --scan &gt;&gt; /etc/mdadm/mdadm.conf</span></span></code> </pre> <br><br>  Check the content: <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment"># cat /etc/mdadm/mdadm.conf</span></span></code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> owner=root <span class="hljs-keyword"><span class="hljs-keyword">group</span></span>=disk mode=<span class="hljs-number"><span class="hljs-number">0660</span></span> auto=yes MAILADDR <span class="hljs-keyword"><span class="hljs-keyword">user</span></span>@mail.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ARRAY</span></span> /dev/md0 metadata=<span class="hljs-number"><span class="hljs-number">0.90</span></span> <span class="hljs-type"><span class="hljs-type">UUID</span></span>=<span class="hljs-number"><span class="hljs-number">4</span></span>df20dfa:<span class="hljs-number"><span class="hljs-number">4480524</span></span>a:f7703943:<span class="hljs-number"><span class="hljs-number">85</span></span>f444d5 <span class="hljs-keyword"><span class="hljs-keyword">ARRAY</span></span> /dev/md1 metadata=<span class="hljs-number"><span class="hljs-number">0.90</span></span> <span class="hljs-type"><span class="hljs-type">UUID</span></span>=<span class="hljs-number"><span class="hljs-number">432e3654</span></span>:e288eae2:f7703943:<span class="hljs-number"><span class="hljs-number">85</span></span>f444d5</code> </pre> <br>  Now we need to transfer the valid LVM array to three empty disks.  To begin, create in the raid md1 - LVM-section: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#pvcreate /dev/md1 -ff</span></span></code> </pre> <br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Physical</span></span> volume <span class="hljs-string"><span class="hljs-string">"/dev/md1"</span></span> successfully created</code> </pre> <br>  And add it to the pve group: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#vgextend pve /dev/md1</span></span></code> </pre> <br><pre> <code class="hljs cs">Volume <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-string"><span class="hljs-string">"pve"</span></span> successfully extended</code> </pre> <br>  Now we transfer the data from the original LVM to the newly created one: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#pvmove /dev/sda3 /dev/md1</span></span></code> </pre> <br><pre> <code class="hljs matlab">/dev/sda3: Moved: <span class="hljs-number"><span class="hljs-number">0.0</span></span><span class="hljs-comment"><span class="hljs-comment">%</span></span></code> </pre> <br>  The process is long.  It took me about 10 hours.  Interestingly, I launched it out of habit while being connected via SSH and by 1.3% realized that it‚Äôs not convenient to sit so much time with a laptop at work.  I canceled the operation via CTRL + C, went to the physical server and tried to start the transfer command there, but the smart piece unsubscribed that the process was already underway and the command would not be executed a second time, and started drawing transfer percentages on a real screen.  At least thanks :) <br><br>  The process ended twice writing 100%.  Remove the first disk from LVM: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#vgreduce pve /dev/sda3</span></span></code> </pre> <br><pre> <code class="hljs cs"> Removed <span class="hljs-string"><span class="hljs-string">"/dev/sda3"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> volume <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-string"><span class="hljs-string">"pve"</span></span></code> </pre> <br>  We transfer the boot / boot to our new raid / md0, but first we format and mount the raid itself. <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mkfs.ext4 /dev/md0</span></span></code> </pre> <br><pre> <code class="hljs sql">mke2fs 1.42.12 (29-Aug-2014) Creating filesystem <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-number"><span class="hljs-number">482304</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span>k blocks <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-number"><span class="hljs-number">120720</span></span> inodes Filesystem <span class="hljs-keyword"><span class="hljs-keyword">UUID</span></span>: <span class="hljs-number"><span class="hljs-number">6</span></span>b75c86a<span class="hljs-number"><span class="hljs-number">-0501</span></span><span class="hljs-number"><span class="hljs-number">-447</span></span>c<span class="hljs-number"><span class="hljs-number">-8</span></span>ef5<span class="hljs-number"><span class="hljs-number">-386224e48538</span></span> Superblock backups <span class="hljs-keyword"><span class="hljs-keyword">stored</span></span> <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> blocks: <span class="hljs-number"><span class="hljs-number">32768</span></span>, <span class="hljs-number"><span class="hljs-number">98304</span></span>, <span class="hljs-number"><span class="hljs-number">163840</span></span>, <span class="hljs-number"><span class="hljs-number">229376</span></span>, <span class="hljs-number"><span class="hljs-number">294912</span></span> Allocating <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">tables</span></span>: done Writing inode <span class="hljs-keyword"><span class="hljs-keyword">tables</span></span>: done Creating journal (<span class="hljs-number"><span class="hljs-number">8192</span></span> blocks): done Writing superblocks <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> filesystem accounting information: done</code> </pre> <br>  Create a directory and mount the raid there: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mkdir /mnt/md0</span></span></code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mount /dev/md0 /mnt/md0</span></span></code> </pre> <br>  Copy the contents of live / boot: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#cp -ax /boot/* /mnt/md0</span></span></code> </pre> <br>  Unmount the raid and delete the temporary directory: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#umount /mnt/md0</span></span></code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#rmdir /mnt/md0</span></span></code> </pre> <br>  Determine the UUID of the raid partition where the / boot is stored ‚Äî this is needed in order to correctly write it to the / etc / fstab table: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#blkid |grep md0</span></span></code> </pre> <br>  / dev / md0: UUID = "6b75c86a-0501-447c-8ef5-386224e48538" TYPE = "ext4" <br>  Open the table and write the boot data at its end: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#nano /etc/fstab</span></span></code> </pre> <br>  Register and save: <br><br><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">UUID</span></span>="6b75c86a-0501-447c-8ef5-386224e48538" /boot ext4 defaults <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br>  Now mount / boot: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mount /boot</span></span></code> </pre> <br>  Let the OS boot, even if the state is BOOT_DEGRADED (that is, the raid is degraded due to disk failure): <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#echo "BOOT_DEGRADED=true" &gt; /etc/initramfs-tools/conf.d/mdadm</span></span></code> </pre> <br>  Register the ramfs download: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mkinitramfs -o /boot/initrd.img-`uname -r`</span></span></code> </pre> <br>  The bootloader's graphic mode is disabled: <br><br><pre> <code class="hljs scala">root<span class="hljs-meta"><span class="hljs-meta">@pve</span></span>1:~#echo <span class="hljs-string"><span class="hljs-string">"GRUB_TERMINAL=console"</span></span> &gt;&gt; /etc/<span class="hljs-keyword"><span class="hljs-keyword">default</span></span>/grub</code> </pre> <br>  Install the bootloader on all three disks: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#grub-install /dev/sdb</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Installing <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i386-pc platform. Installation finished. <span class="hljs-keyword"><span class="hljs-keyword">No</span></span> error reported.</code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#grub-install /dev/sdc&gt;</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Installing <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i386-pc platform. Installation finished. <span class="hljs-keyword"><span class="hljs-keyword">No</span></span> error reported.</code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#grub-install /dev/sdd</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Installing <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i386-pc platform. Installation finished. <span class="hljs-keyword"><span class="hljs-keyword">No</span></span> error reported.</code> </pre> <br>  Now a very important point.  We take as a basis the second disk / dev / sd <b>b</b> , on which the system, bootloader and grub and transfer all this to the first disk / dev / sd <b>a</b> , which would later make it also part of our raid.  To do this, consider the first disc as clean and mark it just like the others at the beginning of this article. <br><br>  Zanulim and mark as GPT: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#dd if=/dev/zero of=/dev/sda bs=512 count=1</span></span></code> </pre> <br><pre> <code class="hljs objectivec"><span class="hljs-number"><span class="hljs-number">1</span></span>+<span class="hljs-number"><span class="hljs-number">0</span></span> records <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>+<span class="hljs-number"><span class="hljs-number">0</span></span> records <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-number"><span class="hljs-number">512</span></span> bytes (<span class="hljs-number"><span class="hljs-number">512</span></span> B) copied, <span class="hljs-number"><span class="hljs-number">0.0157829</span></span> s, <span class="hljs-number"><span class="hljs-number">32.4</span></span> kB/s</code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda mklabel gpt</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  We break it into sections exactly like the other three: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda mkpart primary 1M 10M</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda set 1 bios_grub on</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda mkpart primary 10 1G</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  Here we again need accurate knowledge of the size of the disk.  Let me remind you, we received it with the command, which in this case should be applied to the / dev / sdb disk: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sdb print</span></span></code> </pre> <br>  Since we have the same disks, the size has not changed - <b>1000Gb</b> .  Mark up the main section: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda mkpart primary 1G 1000Gb</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Information: You may need <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> /etc/fstab.</code> </pre> <br>  It should work like this: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#parted /dev/sda print</span></span></code> </pre> <br><pre> <code class="hljs pgsql">Model: ATA MB1000EBNCF (scsi) Disk /dev/sda: <span class="hljs-number"><span class="hljs-number">1000</span></span>GB Sector size (logical/physical): <span class="hljs-number"><span class="hljs-number">512</span></span>B/<span class="hljs-number"><span class="hljs-number">512</span></span>B <span class="hljs-keyword"><span class="hljs-keyword">Partition</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Table</span></span>: gpt Disk Flags: Number <span class="hljs-keyword"><span class="hljs-keyword">Start</span></span> <span class="hljs-keyword"><span class="hljs-keyword">End</span></span> Size File <span class="hljs-keyword"><span class="hljs-keyword">system</span></span> <span class="hljs-type"><span class="hljs-type">Name</span></span> Flags <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">1049</span></span>kB <span class="hljs-number"><span class="hljs-number">10.5</span></span>MB <span class="hljs-number"><span class="hljs-number">9437</span></span>kB fat32 <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span> bios_grub <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">10.5</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>MB <span class="hljs-number"><span class="hljs-number">990</span></span>MB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">1000</span></span>MB <span class="hljs-number"><span class="hljs-number">1000</span></span>GB <span class="hljs-number"><span class="hljs-number">999</span></span>GB <span class="hljs-keyword"><span class="hljs-keyword">primary</span></span></code> </pre> <br>  It remains to add this disk to the common array.  The second section is respectively in / md0, and the third is in / md1: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --add /dev/md0 /dev/sda2</span></span></code> </pre> <br><pre> <code class="hljs">mdadm: added /dev/sda2</code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --add /dev/md1 /dev/sda3</span></span></code> </pre> <br><pre> <code class="hljs">mdadm: added /dev/sda3</code> </pre> <br>  We are waiting for synchronization ... <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#watch cat /proc/mdstat</span></span></code> </pre> <br>  This command shows the synchronization process in real time: <br><br><pre> <code class="hljs mel">Every <span class="hljs-number"><span class="hljs-number">2.0</span></span>s: cat /<span class="hljs-keyword"><span class="hljs-keyword">proc</span></span>/mdstat Fri Nov <span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">09</span></span>:<span class="hljs-number"><span class="hljs-number">18</span></span> <span class="hljs-number"><span class="hljs-number">2016</span></span> Personalities : [raid10] md1 : active raid10 sda3[<span class="hljs-number"><span class="hljs-number">4</span></span>] sdd3[<span class="hljs-number"><span class="hljs-number">3</span></span>] sdc3[<span class="hljs-number"><span class="hljs-number">2</span></span>] sdb3[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">1951567872</span></span> blocks <span class="hljs-number"><span class="hljs-number">2048</span></span>K chunks <span class="hljs-number"><span class="hljs-number">2</span></span> near-copies [<span class="hljs-number"><span class="hljs-number">4</span></span>/<span class="hljs-number"><span class="hljs-number">3</span></span>] [_UUU] [&gt;....................] recovery = <span class="hljs-number"><span class="hljs-number">0.5</span></span>% (<span class="hljs-number"><span class="hljs-number">5080064</span></span>/<span class="hljs-number"><span class="hljs-number">975783936</span></span>) finish=<span class="hljs-number"><span class="hljs-number">284.8</span></span><span class="hljs-keyword"><span class="hljs-keyword">min</span></span> speed=<span class="hljs-number"><span class="hljs-number">56796</span></span>K/sec bitmap: <span class="hljs-number"><span class="hljs-number">15</span></span>/<span class="hljs-number"><span class="hljs-number">15</span></span> pages [<span class="hljs-number"><span class="hljs-number">60</span></span>KB], <span class="hljs-number"><span class="hljs-number">65536</span></span>KB chunk md0 : active raid10 sda2[<span class="hljs-number"><span class="hljs-number">0</span></span>] sdd2[<span class="hljs-number"><span class="hljs-number">3</span></span>] sdc2[<span class="hljs-number"><span class="hljs-number">2</span></span>] sdb2[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">1929216</span></span> blocks <span class="hljs-number"><span class="hljs-number">2048</span></span>K chunks <span class="hljs-number"><span class="hljs-number">2</span></span> near-copies [<span class="hljs-number"><span class="hljs-number">4</span></span>/<span class="hljs-number"><span class="hljs-number">4</span></span>] [UUUU]</code> </pre> <br>  And if the first raid with / boot was synchronized immediately, then it took patience to synchronize the second (around 5 hours). <br><br>  It remains to install the bootloader on the added disk (here you need to understand that you <u>only</u> need <u>to</u> do this <u>after the</u> disks have been <u>fully</u> synchronized). <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#dpkg-reconfigure grub-pc</span></span></code> </pre> <br>  Press Enter a couple of times without changing anything and at the last step we check all 4 disks. <br>  <u>md0 / md1 do not touch!</u> <br><br>  It remains to reboot the system and check that everything is in order: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#shutdown ‚Äìr now</span></span></code> </pre> <br>  The system booted normally (I even changed the BIOS loading order of the screws in the BIOS several times - it loads the same way). <br><br>  Check arrays: <br><br><pre> <code class="hljs mel">&lt;<span class="hljs-keyword"><span class="hljs-keyword">source</span></span> lang=<span class="hljs-string"><span class="hljs-string">"vim"</span></span>&gt;root@pve1:~#cat /<span class="hljs-keyword"><span class="hljs-keyword">proc</span></span>/mdstat</code> </pre> <br><pre> <code class="hljs delphi">Personalities : [raid10] md1 : active raid10 sda3[<span class="hljs-number"><span class="hljs-number">0</span></span>] sdd3[<span class="hljs-number"><span class="hljs-number">3</span></span>] sdc3[<span class="hljs-number"><span class="hljs-number">2</span></span>] sdb3[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">1951567872</span></span> blocks <span class="hljs-number"><span class="hljs-number">2048</span></span>K chunks <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">near</span></span>-copies [<span class="hljs-number"><span class="hljs-number">4</span></span>/<span class="hljs-number"><span class="hljs-number">4</span></span>] [UUUU] bitmap: <span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">15</span></span> pages [<span class="hljs-number"><span class="hljs-number">8</span></span>KB], <span class="hljs-number"><span class="hljs-number">65536</span></span>KB chunk md0 : active raid10 sda2[<span class="hljs-number"><span class="hljs-number">0</span></span>] sdd2[<span class="hljs-number"><span class="hljs-number">3</span></span>] sdc2[<span class="hljs-number"><span class="hljs-number">2</span></span>] sdb2[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">1929216</span></span> blocks <span class="hljs-number"><span class="hljs-number">2048</span></span>K chunks <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">near</span></span>-copies [<span class="hljs-number"><span class="hljs-number">4</span></span>/<span class="hljs-number"><span class="hljs-number">4</span></span>] [UUUU]</code> </pre> <br>  Four horseshoes in each raid indicate that all four discs are in operation.  We look at the information on arrays (on the example of the first, more precisely zero). <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --detail /dev/md0</span></span></code> </pre> <br><pre> <code class="hljs sql">/dev/md0: Version : 0.90 Creation Time : Thu Nov 10 15:12:21 2016 Raid Level : raid10 Array Size : 1929216 (1884.32 MiB 1975.52 MB) Used Dev Size : 964608 (942.16 MiB 987.76 MB) Raid Devices : 4 Total Devices : 4 Preferred Minor : 0 Persistence : Superblock is persistent <span class="hljs-keyword"><span class="hljs-keyword">Update</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Time</span></span> : Fri Nov <span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">07</span></span>:<span class="hljs-number"><span class="hljs-number">47</span></span> <span class="hljs-number"><span class="hljs-number">2016</span></span> State : active Active Devices : <span class="hljs-number"><span class="hljs-number">4</span></span> Working Devices : <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Failed</span></span> Devices : <span class="hljs-number"><span class="hljs-number">0</span></span> Spare Devices : <span class="hljs-number"><span class="hljs-number">0</span></span> Layout : near=<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Chunk</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Size</span></span> : <span class="hljs-number"><span class="hljs-number">2048</span></span>K <span class="hljs-keyword"><span class="hljs-keyword">UUID</span></span> : <span class="hljs-number"><span class="hljs-number">4</span></span>df20dfa:<span class="hljs-number"><span class="hljs-number">4480524</span></span>a:f7703943:<span class="hljs-number"><span class="hljs-number">85</span></span>f444d5 (<span class="hljs-keyword"><span class="hljs-keyword">local</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> host pve1) <span class="hljs-keyword"><span class="hljs-keyword">Events</span></span> : <span class="hljs-number"><span class="hljs-number">0.27</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Number</span></span> Major Minor RaidDevice State <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> active <span class="hljs-keyword"><span class="hljs-keyword">sync</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>-A /dev/sda2 <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> active <span class="hljs-keyword"><span class="hljs-keyword">sync</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>-B /dev/sdb2 <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-number"><span class="hljs-number">34</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> active <span class="hljs-keyword"><span class="hljs-keyword">sync</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>-A /dev/sdc2 <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> active <span class="hljs-keyword"><span class="hljs-keyword">sync</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>-B /dev/sdd2</code> </pre> <br>  We see that the array type is RAID10, all disks are in place, active and synchronized. <br><br>  Now, it would be possible to play around with disabling the disks, changing the boot disk in the BIOS, but before that let us set up an administrator notification when the disks fail, and therefore the raid itself.  Without notice, the raid will die slowly and painfully, and no one will know about it. <br><br>  In Proxmox, postfix is ‚Äã‚Äãalready installed by default, I did not delete it, although I consciously understand that it would be easier to configure other MTAs. <br><br>  We put the SASL library (I need it to work with our external mail server): <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:/etc</span></span><span class="hljs-comment"><span class="hljs-comment">#apt-get install libsasl2-modules</span></span></code> </pre> <br>  Create a file with data from which we will authenticate on our remote mail server: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#touch /etc/postfix/sasl_passwd</span></span></code> </pre> <br>  There we write the line: <br><br><pre> <code class="hljs pgsql">[mail.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru] pve1@<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru:<span class="hljs-keyword"><span class="hljs-keyword">password</span></span></code> </pre> <br>  Now we create the transport file: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#touch /etc/postfix/transport</span></span></code> </pre> <br>  There we write: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru smtp:[mail.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru]</code> </pre> <br>  Create a generic_map: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#touch /etc/postfix/generic</span></span></code> </pre> <br>  Here we write (we denote from whom the mail will be sent): <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">root</span></span> pve1<span class="hljs-variable"><span class="hljs-variable">@domain</span></span>.ru</code> </pre> <br>  Create sender_relay (in fact, the route to the external server): <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#touch /etc/postfix/sender_relay</span></span></code> </pre> <br>  And we write there: <br><br><pre> <code class="hljs pgsql">pve1@<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru smtp.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru</code> </pre> <br>  Hash files: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#postmap transport</span></span></code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#postmap sasl_passwd</span></span></code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#postmap geniric</span></span></code> </pre> <br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#postmap sender_relay</span></span></code> </pre> <br>  In the /etc/postfix/main.cf file, I got this working configuration: <br><br><div class="spoiler">  <b class="spoiler_title">main.cf</b> <div class="spoiler_text">  # See /usr/share/postfix/main.cf.dist for a commented, more complete version <br><br>  myhostname = domain.ru <br><br>  smtpd_banner = $ myhostname ESMTP $ mail_name (Debian / GNU) <br>  biff = no <br>  # appending .domain is the MUA's job. <br>  append_dot_mydomain = no <br>  # Uncomment the next line to generate "delayed mail" warnings <br>  #delay_warning_time = 4h <br><br>  alias_maps = hash: / etc / aliases <br>  alias_database = hash: / etc / aliases <br>  mydestination = $ myhostname, localhost. $ mydomain, localhost <br>  mynetworks = 127.0.0.0/8,192.168.1.0/24 <br>  inet_interfaces = loopback-only <br>  recipient_delimiter = + <br><br>  smtp_tls_loglevel = 1 <br>  smtp_tls_session_cache_database = btree: / var / lib / postfix / smtp_tls_session_cache <br>  smtp_use_tls = no <br>  tls_random_source = dev: / dev / urandom <br><br>  ## SASL Settings <br>  smtpd_sasl_auth_enable = no <br>  smtp_sasl_auth_enable = yes <br>  smtpd_use_pw_server = yes <br>  enable_server_options = yes <br>  smtpd_pw_server_security_options = plain, login <br>  smtp_sasl_password_maps = hash: / etc / postfix / sasl_passwd <br>  smtp_sender_dependent_authentification = yes <br>  sender_dependent_relayhost_maps = hash: / etc / postfix / sender_relay <br>  smtpd_sasl_local_domain = $ myhostname <br>  smtp_sasl_security_options = noanonymous <br>  smtp_sasl_tls_security_options = noanonymous <br>  smtpd_sasl_application_name = smtpd <br>  smtp_always_send_ehlo = yes <br>  relayhost = <br>  transport_maps = hash: / etc / postfix / transport <br>  smtp_generic_maps = hash: / etc / postfix / generic <br>  disable_dns_lookups = yes <br></div></div><br>  Reboot postfix: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#/etc/init.d/postfix restart</span></span></code> </pre> <br>  Now we need to return to the raid settings file and correct it a bit.  We indicate to whom to receive letters of happiness and from whom they will come. <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#nano /etc/dmadm/mdadm.conf</span></span></code> </pre> <br>  I have this: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> owner=root <span class="hljs-keyword"><span class="hljs-keyword">group</span></span>=disk mode=<span class="hljs-number"><span class="hljs-number">0660</span></span> auto=yes MAILADDR <span class="hljs-keyword"><span class="hljs-keyword">info</span></span>@<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span>.ru MAILFROM pve1@dpmain.ru <span class="hljs-keyword"><span class="hljs-keyword">ARRAY</span></span> /dev/md0 metadata=<span class="hljs-number"><span class="hljs-number">0.90</span></span> <span class="hljs-type"><span class="hljs-type">UUID</span></span>=<span class="hljs-number"><span class="hljs-number">4</span></span>df20dfa:<span class="hljs-number"><span class="hljs-number">4480524</span></span>a:f7703943:<span class="hljs-number"><span class="hljs-number">85</span></span>f444d5 <span class="hljs-keyword"><span class="hljs-keyword">ARRAY</span></span> /dev/md1 metadata=<span class="hljs-number"><span class="hljs-number">0.90</span></span> <span class="hljs-type"><span class="hljs-type">UUID</span></span>=<span class="hljs-number"><span class="hljs-number">432e3654</span></span>:e288eae2:f7703943:<span class="hljs-number"><span class="hljs-number">85</span></span>f444d5</code> </pre> <br>  Restart mdadm to re-read the settings: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#/etc/init.d/mdadm restart</span></span></code> </pre> <br>  Check through the console testing the raid and sending a letter: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#mdadm --monitor --scan -1 --test --oneshot</span></span></code> </pre> <br>  I received two letters with information on both of the raids I created.  It remains to add the test task to cron and remove the ‚Äìtest key.  To send letters only when something happened: <br><br><pre> <code class="hljs ruby">root@pve1<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span><span class="hljs-comment"><span class="hljs-comment">#crontab -e</span></span></code> </pre> <br>  Add a task (do not forget to click on Enter after the line and move the cursor down, so that an empty line would appear): <br><br><pre> <code class="hljs pgsql"><span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span> * * * mdadm <span class="hljs-comment"><span class="hljs-comment">--monitor --scan -1 ‚Äìoneshot</span></span></code> </pre> <br>  Testing will be done every morning at 5 am and if problems arise, mail will be sent. <br><br>  That's all.  Perhaps I was too smart with the postfix config - while trying to achieve a normal send via our external server, I added a lot of things.  I would be grateful if you correct (simplify). <br><br>  In the next article, I want to share the experience of moving virtual machines from our Esxi-6 hypervisor to this new Proxmox.  I think it will be interesting. <br><br>  UPD. <br>  It is necessary to separately cancel the moment with a physical place on the / dev / data partition - this is the main partition created as LVM-Thin <br>  When Proxmox was installed, it automatically marked / dev / sda, taking into account that it allocated 10% of the capacity of the partition, namely 100Gb, to the / root partition where the system, ISO, dumps and containers are stored.  In the remaining space, he created the LVM-Thin partition, which is essentially not mounted anywhere (this is another subtlety of version&gt; 4.2, after transferring the disks to GPT).  And as you understand this section has become the size of 900Gb.  When we picked up RAID10 from 4x 1Tb drives, we got the capacity (including the RAID1 + 0 reserve) - 2Tb <br>  But when they copied LVM into a raid, they copied it as a container, with its size of 900Gb. <br><br>  When you first enter the Proxmox admin panel, the attentive viewer may notice that poking to the local-lvm (pve1) section - we see these with 800Gb dimes <br><br>  So in order to expand LVM-Thin to the full size of 1.9TB, we need to execute all one command: <br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">lvextend</span></span> /dev/pve/<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class"> -l +100%</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">FREE</span></span></span></span></code> </pre> <br>  After that, the system does not even need to restart. <br>  You do not need to do resize2fs - and this is probably even impossible, because the system will start swearing at <br><pre> <code class="hljs kotlin"><span class="hljs-symbol"><span class="hljs-symbol">root@</span></span>pve1:~# resize2fs /dev/mapper/pve-<span class="hljs-keyword"><span class="hljs-keyword">data</span></span> resize2fs <span class="hljs-number"><span class="hljs-number">1.42</span></span>.12 (<span class="hljs-number"><span class="hljs-number">29</span></span>-Aug-<span class="hljs-number"><span class="hljs-number">2014</span></span>) resize2fs: MMP: invalid magic number <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> trying to <span class="hljs-keyword"><span class="hljs-keyword">open</span></span> /dev/mapper/pve-<span class="hljs-keyword"><span class="hljs-keyword">data</span></span> Couldn<span class="hljs-string"><span class="hljs-string">'t find valid filesystem superblock.</span></span></code> </pre> <br>  And it will start correctly - this section is not mounted via fstab <br><br>  In general, while I was trying to figure out how to expand the disk and read the Proxmox forum - in the meantime, the system was already showing a new size, both in the table and on the scale. <br><img src="http://yegorov.kz/resize2fs.jpg" alt="image"></div><p>Source: <a href="https://habr.com/ru/post/315086/">https://habr.com/ru/post/315086/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../315074/index.html">You are not superheroes: please stop setting yourself tasks that you are not yet able to cope with.</a></li>
<li><a href="../315076/index.html">We forward USB ‚Äì key to the cloud (Linux client - Linux server)</a></li>
<li><a href="../315078/index.html">"Browser War" Google Chrome continues - news from the fields</a></li>
<li><a href="../315080/index.html">Lectures Tehnotreka. Basics of web development (spring 2016)</a></li>
<li><a href="../315084/index.html">Console in the robot on Arduin</a></li>
<li><a href="../315098/index.html">Nginx build: CentOS 6.8, documents and rake</a></li>
<li><a href="../315100/index.html">The malicious program Retefe is used to compromise online banking users.</a></li>
<li><a href="../315102/index.html">Setting up a FullMesh network on Mikrotik via EoIP tunnels</a></li>
<li><a href="../315106/index.html">From zero to one. How I went from freelance to chief designer for the year</a></li>
<li><a href="../315108/index.html">Representing SAP R / 3 data in Oracle Database using the SAP Java Connector</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>