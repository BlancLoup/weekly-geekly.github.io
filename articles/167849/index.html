<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A little philosophical post about how we looked into the eyes</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the article I will tell a small story about a small technical puzzle and how it was solved by various people around. Perhaps this story will help t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A little philosophical post about how we looked into the eyes</h1><div class="post__text post__text-html js-mediator-article">  In the article I will tell a small story about a small technical puzzle and how it was solved by various people around.  Perhaps this story will help the reader to learn a few lessons about what mistakes sometimes occur. <br>  A little bit of matan incl. <br><img src="https://habrastorage.org/getpro/habr/post_images/348/583/dc4/348583dc406de5a7f032fab3251ed836.jpg" alt="Three colours"><br>  The idea to recognize people by the iris appeared in distant 1987 with Dr. <a href="http://www.cl.cam.ac.uk/~jgd1000/">John Dougman</a> and was patented in 1989. At about the same time, a prototype appeared.  At that time, it was the pinnacle of technology.  A couple of years before the first commercial digital camera + image processing algorithm on computers of the i386 / i486 level.  Until now, I have no idea how to get a stable result on such equipment. <br>  The task about which I want to tell came into the world somewhere in 2006-2009.  By this time, the processors were somewhat accelerated, good cameras appeared, the 1989 patent had expired, and eye recognition systems were now granted the right to make everyone.  People who decided to make a clone of the system wanted to use modern technology and improve the algorithm.  The very first thing that caught the eye - the old eye comparison algorithm used an image of the eye in the near IR range.  The fact that the eyes are colored is not taken into account. <br><a name="habracut"></a><br><h4>  Little theory </h4><br>  The iris of the eye is a unique characteristic of a person.  The drawing of the iris is formed in the eighth month of intrauterine development, finally stabilizes at the age of about two years and practically does not change during life, except as a result of severe injuries or abrupt pathologies.  The method is one of the most accurate among biometric methods. <br>  The classic recognition algorithm for black and white eyes, consists of two parts - <b>segmentation</b> and <b>comparison</b> . <br>  <b>Segmentation</b> is the selection of the eye itself in a photograph or in a video stream.  The segmentation algorithm is highly dependent on the equipment used and the optical configuration.  Unlike comparison, which is a mathematically rigorous problem, segmentation is a problem with too many variables.  You always have to invent and customize something.  Dougman in his patent proposed to look for the eye during segmentation as a circle for which the maximum gradient: <br><img src="https://habrastorage.org/getpro/habr/post_images/9d4/7cf/876/9d47cf87613cade96ca61757953048ff.png" alt="Circle search"><br>  Here G is the operator of Gaussian image blur, and I (x, y) is the image itself.  The number of hypotheses that need to be iterated is approximately equal to W ‚àô H ‚àô (R <sub>max</sub> -R <sub>min</sub> ), where W is the image width, H is its height, R <sub>max</sub> and R <sub>min are the</sub> maximum and minimum radii, respectively.  The Dougman algorithm is an inside-out <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A5%25D0%25B0%25D1%2584%25D0%25B0">Hough transformation</a> for circles.  In its pure form, it is not applicable.  The conversion of Hough itself is unstable, moreover, on modern Intel i7 processors, this operation for a 1.3 megapixel image without prior optimization is of the order of several seconds.  There are many tricks and tricks to achieve work in real time. <br>  One of the most beautiful is to use the lighting that gives a characteristic highlight on the pupil and look for this highlight.  Such highlights are clearly visible here: <br><img src="https://habrastorage.org/getpro/habr/post_images/bd5/5bc/f1b/bd55bcf1b5ac30e27a8f58e7211008f0.jpg" alt="highlight"><br>  The task of searching for a highlight is computationally much simpler than the task of searching for an eye.  And then the eye is searched for in the vicinity of the flare. <br>  As a result of segmentation, the pupil and iris are detected.  On the iris there are areas of interest for further use.  The segmented area is obtained: <br><img src="https://habrastorage.org/getpro/habr/post_images/72e/6b2/fbf/72e6b2fbf23020fbc7773859d9e424f8.jpg" alt="Segmentation 1"><br>  The second is often a <b>comparison</b> .  After isolating the iris, it should be normalized for easy comparison with other irises.  The iris unfolds from the polar coordinates into a rectangle and is filtered.  As a filter, Dougman suggested using <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B8%25D0%25BB%25D1%258C%25D1%2582%25D1%2580_%25D0%2593%25D0%25B0%25D0%25B1%25D0%25BE%25D1%2580%25D0%25B0">the Gabor filter</a> , which allows emphasizing characteristic regions and reducing high-frequency noise: <br><img src="https://habrastorage.org/getpro/habr/post_images/a26/470/8e2/a264708e2c88d0d75dcd82861259548b.png" alt="image"><br>  Although, of course, the filter used is customized depending on the equipment.  Transformed iris is called <i>Iris Code</i> .  These irises look something like this: <br><img src="https://habrastorage.org/getpro/habr/post_images/0da/812/073/0da812073242656e471d57b620463a4b.png" alt="image">  -An unfolded colored iris. <br>  __________________________________________________________________________ <br><img src="https://habrastorage.org/getpro/habr/post_images/5d0/37a/761/5d037a761da20ba3b64da88bf5c00c87.png" alt="image">  -An open black and white iris with a mask on top. <br>  __________________________________________________________________________ <br><img src="https://habrastorage.org/getpro/habr/post_images/4ba/313/621/4ba313621849d91bc4b62bf4ef6938fc.png" alt="image">  - Pure <i>Iris Code</i> . <br><br>  In order to compare two irises, for the received <i>Iris Code, the</i> Hamming distance is constructed, which in this case is a measure of the correlation of objects.  The smaller the Hamming distance between the two codes, the closer they are to each other.  If we compare a fairly large database of images with each other, calculate the <a href="http://en.wikipedia.org/wiki/Hamming_distance">Hamming</a> distance for it, and construct the resulting histogram, we get the following distribution: <br><img src="https://habrastorage.org/getpro/habr/post_images/0f0/67b/286/0f067b2867002695a6b793367241d754.png" alt="image"><br>  A left hump painted white will form a comparison of identical eyes with identical ones.  The right hump drawn by black will form the comparison of different eyes between themselves.  From this graph, a number is taken that separates the two humps well.  Usually he is chosen closer to the left hump: to prevent a person is better than to miss a spy.  For this chart it is something like 0.32. <br>  Further, the system decides that a person can be skipped if the code of his eye has a distance of less than 0.32 with some other code from the database. <br><br><h4>  Prehistory </h4><br>  I and two other friends (one - <a href="http://habrahabr.ru/users/vasyutka/" class="user_link">Vasyutka</a> , the second - <a href="http://habrahabr.ru/users/strepetarh/" class="user_link">Strepetarh</a> ) started the <a href="http://habrahabr.ru/users/strepetarh/" class="user_link">topic of</a> recognition in the eyes at the 4th year of MIPT.  We needed to make a course project on information security.  Then we made a simple eye recognition system using a webcam, a column case, a key fob and a clothes peg.  Seeing how well it works (we <a href="http://drec.mipt.ru/radioDay/2008/soft/01.html">won the institute competition</a> and got a lot of positive feedback), we decided to finish it in a full system.  Over the next year of unhurried programming, we brought the system to a completely working product.  That's when investors came.  But they wanted a strange one. <br>  At the same time, when we looked into the eyes of our future investors, we came across the fact that the idea of ‚Äã‚Äãrecognizing eyes not from a black and white picture, but from a color one, was never patented anywhere.  And being people who are technically savvy and possessing a commercial spirit they decided to get a patent.  True, they did not know how to program, and even more so they did not understand the inherent mathematics. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  The first call to the problem </h4><br>  Let's return to our sheep.  At first, investors did not come to us, but to the only company that in Russia was engaged in eye recognition and had a finished product (ready-made scanner + algorithms).  Investors have ordered a study on how color image recognition will improve statistics.  The approach to the task of the company was terribly technical.  They built the <i>Iris Code</i> for each RGB channel separately and compared three elements for the same person.  In fact, we took the existing technology and invested new data into it. <br>  Let's see what they did in reality.  Lay the image into channels: <br> <a href="http://img-fotki.yandex.ru/get/5643/6107910.14/0_68ca8_3ceaf2d9_orig"><img src="https://habrastorage.org/getpro/habr/post_images/15f/f39/073/15ff3907324fc55c026e89291000b770.jpg" alt="image"></a> <br>  As mentioned above, to underline the image texture, it is customary to use a Gabor filter or some other mid-range filter that emphasizes the boundaries.  He turns these pictures into: <br> <a href="http://img-fotki.yandex.ru/get/6440/6107910.14/0_68caa_a85eb84d_orig"><img src="https://habrastorage.org/getpro/habr/post_images/ddb/bb5/bed/ddbbb5bedc0b6340b0225d8c0a249a92.png" alt="image"></a> <br>  As you can see, the structure for all colors is almost identical.  The results of comparing eyes in different colors will almost always coincide.  In a report written by that firm, this conclusion was brilliantly confirmed.  Moreover, statistics with this recognition significantly deteriorates.  After all, the color camera uses <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B8%25D0%25BB%25D1%258C%25D1%2582%25D1%2580_%25D0%2591%25D0%25B0%25D0%25B9%25D0%25B5%25D1%2580%25D0%25B0">Bayer filter</a> : <br><img src="https://habrastorage.org/getpro/habr/post_images/ba3/dbd/f14/ba3dbdf14448de8623e541b89333f08d.png" alt="image"><br>  So, in order to have a color image of the same resolution as a black and white one needs to use four times smaller pixels, which, because of the filter, will collect three times less light.  Which significantly reduces the signal-to-noise ratio. <br>  The second problem with this approach is black eyes.  In order to see something in them under white light, everything must be burned out. <br><img src="https://habrastorage.org/getpro/habr/post_images/0a9/f3e/477/0a9f3e477cbe1801d4d271281d10df6e.jpg" alt="image"><br>  In general, based on the above, the guys said that recognition by color eyes is impossible. <br>  <b>Thought 1.</b> <i>Well-proven methods will not always work in new conditions.</i>  <i>If you are faced with a research task and known methods did not work - this does not mean that the problem is not solved.</i> <br><br><h4>  Research approach, aka approach of British scientists </h4><br>  If you follow the plot, then there would have to be a section on how we came and quickly resolved everything.  I do not like linear narration.  I'll tell you better first about how the rest of the world approached this problem in various institutions.  We came across these studies after we had made a working algorithm for color recognition.  And they looked with interest at the jungle of people that their scientific approach was able to bring. <br>  The fact that when using color as RGB information is duplicated in each layer - it occurred to many.  It would be logical to use a color space where the brightness information would be independent of the color.  This is possible if the color of each pixel is considered as a kind of one-dimensional characteristic, so that two pixels can be compared.  I think that almost all readers are familiar with the <a href="http://ru.wikipedia.org/wiki/HSL">HSL</a> ( <a href="http://ru.wikipedia.org/wiki/HSV_(%25D1%2586%25D0%25B2%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B2%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C)">HSV</a> ) color space.  In it, the color coordinates are specified in terms of brightness, saturation and hue (an analogue of wavelength). <br><img src="https://habrastorage.org/getpro/habr/post_images/012/4c6/cfb/0124c6cfbbbea04090ffee3e536bb675.png" alt="image"><br>  The first work on this topic, I think, was <a href="http://csee.wvu.edu/IIAS/docs/thesis/monaco-thesis.pdf">this one</a> .  After it was a series of studies conducted at the <a href="http://www.di.ubi.pt/~hugomcp/investigacao.htm">Portuguese Institute</a> .  The researchers experimented with translating into different color spaces and comparing the images in them.  They honestly checked all the standard color spaces: <a href="http://ru.wikipedia.org/wiki/LAB">Lab</a> , <a href="http://ru.wikipedia.org/wiki/CMYK">CMYK</a> , <a href="http://ru.wikipedia.org/wiki/HSV_(%25D1%2586%25D0%25B2%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B2%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C)">HSV,</a> etc. ... They isolated the irises and correlated them with each other.  We constructed the <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8_%25D0%25BF%25D0%25B5%25D1%2580%25D0%25B2%25D0%25BE%25D0%25B3%25D0%25BE_%25D0%25B8_%25D0%25B2%25D1%2582%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25BE%25D0%25B4%25D0%25B0">distribution of FAR and FRR</a> for all colors, as well as their statistical dependence on each other.  Drew many beautiful plates.  Painted the advantages and disadvantages of different color spaces.  And it turned out that the wave is too unstable sign.  Too much noise in it compared to the rest.  And it's true!  If you look at how the above eye looks in HSL space, you will notice that there are horrible noises in the H channel. <br> <a href="http://img-fotki.yandex.ru/get/6425/6107910.14/0_68cab_7103be57_orig"><img src="https://habrastorage.org/getpro/habr/post_images/ca1/237/bfa/ca1237bfa68d99bad3baa402f737318f.png" alt="image"></a> <br>  If you try to compare two images of the eye, the correlation will be much worse than in other channels.  As a result, studies have shown that the only statistically independent brightness characteristic is eye color.  After that, they happily dismounted it, as too noisy and unreliable. <br>  <b>Thought 2</b> .  <i>If the new research task is similar to the old one, then when solving it, first of all it is worth focusing on the differences.</i>  <i>If the differences are insignificant, then does the new task make sense?</i> <br>  It must be admitted that they still received good statistics with their approach.  For example, here in <a href="http://144.206.159.178/ft/CONF/16432192/16432238.pdf">this</a> article.  True to reality, it no longer has any relation.  In contrast to the previous study, it was not the real base of the eyes that was used, but the base obtained approximately as follows: <br><img src="https://habrastorage.org/getpro/habr/post_images/856/a48/2bf/856a482bf5358b7ae7f499d53101d10c.jpg" alt="image"><br>  When shooting such a base, the head is fixed and a strong flash hits in the eye.  The resolution is several times better than in any of the existing normal scanners. <br>  In reality, the resolutions of the used eye scanners allow you to capture the eyes with an iris radius of 70-100 pixels.  This is due to the strength of the permissible illumination and the depth of field of the system. <br>  <b>Thought 3</b> .  <i>Solving the real problem should be repelled primarily on the characteristics of the equipment used, and not on a beautiful mathematical model.</i> <br><br><h4>  Our appearance </h4><br>  After the developers from the first company, where the investor had addressed, explained that color recognition is worse than recognition by B &amp; W, the investor got worried.  The patent is not cheap and required additional infusions of funds for its maintenance.  The investor found us three days before they had to make a decision whether to leave the project or merge it.  And already during these three days we have found the first solution, which allows us to improve the statistics.  As always, an approach is implemented in such situations: ‚ÄúWhat would be faster to come up with in order for it to work.‚Äù  Need to compare colored eyes?  So let's compare BW and add a comparison for the average color of the eye.  It turned out that the probability that the color of your eye coincides with a randomly taken eye is about 10% with 90% coincidence with yourself. <br>  This was enough to improve the statistics by 3 times, which was not achieved by any of the above studies. <br>  Satisfying the investor and pushing him to the fact that he remained in the subject and entered into an agreement with us, we began a real study.  And already from the first step we went a different way than all the above works.  Instead of solving the mathematical problem of comparing colored eyes, we began by solving a purely technical problem: ‚ÄúHow do color cameras shoot eyes and how much light is required.  Already after the first Asian with a practically black iris, we realized that we could not abandon the infrared spectrum.  To do this, we had to use a color camera with an IR filter removed and with two backlight systems: infrared and color.  The infrared part was supposed to provide a classic comparison, and the color part was to add an additional component that would make the system ‚Äústronger‚Äù than all the existing ones. <br>  Having received a sufficient base of images of the eyes, we began to try to draw out additional information from the colored eyes.  Of course, we tried the comparison in the RGB spectrum, making sure almost immediately that it does not give anything.  And right after that, we came to a comparison in the HSL spectrum.  By the way, an eye decomposed into HSL space above was obtained by a ‚Äúgood‚Äù method of photographing.  The real eyes received by the camera look like this: <br><img src="https://habrastorage.org/getpro/habr/post_images/ed2/e6d/9e0/ed2e6d9e05834fff5e78923149de51b7.jpg" alt="image"><br>  Over similar pictures we stupid a few days.  Indeed, on the one hand, in the H and S channel contains new information.  But on the other hand, it is very noisy, and slightly spatially correlated with BW eyes.  The solution was simple and elegant.  If we need information only about color, then we need to score on spatial information.  Construct a histogram of color distribution for the eye.  Such a histogram aligns the noise, averaging over them.  According to such histograms, you can quickly compare, and most importantly, the result of recognition by such histograms for the H and S channels does not correlate with each other and does not correlate with the classical method of recognition of the black-and-white eyes: <br><img src="https://habrastorage.org/getpro/habr/post_images/fe2/6a2/d50/fe26a2d5005d00a4ffdf2441b57e4feb.png" alt="image"><br>  Only twenty points of the histogram H give the intersection of the <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8_%25D0%25BF%25D0%25B5%25D1%2580%25D0%25B2%25D0%25BE%25D0%25B3%25D0%25BE_%25D0%25B8_%25D0%25B2%25D1%2582%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25BE%25D0%25B4%25D0%25B0">false tolerance</a> curve <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8_%25D0%25BF%25D0%25B5%25D1%2580%25D0%25B2%25D0%25BE%25D0%25B3%25D0%25BE_%25D0%25B8_%25D0%25B2%25D1%2582%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25BE%25D0%25B4%25D0%25B0">and the false non-admission</a> at the level of 6 percent.  Approximately 10% gives S histogram.  Of course, such percentages do not add up, they must be taken into account in a more cunning way.  For example <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BE%25D0%25BF%25D0%25BE%25D1%2580%25D0%25BD%25D1%258B%25D1%2585_%25D0%25B2%25D0%25B5%25D0%25BA%25D1%2582%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B2">SVM</a> . <br>  All this research took us about 15 days and a half people.  What is very funny to compare with scientific activities, which for several years have been around this subject in the articles above. <br><br><h4>  Afterword </h4><br>  This story had two goals.  The first is to tell a story with a small amount of matane, and kill your ten minutes to read it.  The second is to pay attention to several problems in the development of algorithms that are often found around and which I myself regularly get into. <br>  The first problem is overreliance on existing patterns.  Often, when solving a new task, they try to reduce it to the existing algorithms.  And you cannot say that it is bad.  But the desire to go on the beaten track often devalues ‚Äã‚Äãthe entire work.  The most enchanting example is the phrase I once met in some report: ‚ÄúThis problem cannot be solved using OpenCV methods, which means it is insoluble.‚Äù <br>  The second problem is excessive perfectionism.  When a task is a little bit scientific, it gives rise to a whole tree of branching possibilities for its development.  Far from every peak is something useful.  It is often difficult, almost impossible, to focus on the goal that lies at the core of the task.  Endless explorations of empty spaces begin.  And the worst thing is that the modern scientific community encourages such an approach.  And if in mathematics or theoretical physics it makes even a little sense, then in technical sciences it generates more and more ‚ÄúBritish scientists‚Äù.  Index Hirsch witness.  The feeling that this is already some kind of simulacrum, where even Popper with his tambourine is powerless ... <br>  This is how you go between Scylla and Charybdis, solving the next task.  And you can not repeat and dig.  And what do you do in such cases? <br><br><h4>  A pair of small additions </h4><br><ul><li>  Someday, I hope, I will fill in an article on the subject of iris scanners and the process of their development.  There will be a lot of funny monstrous pictures. </li><li>  The devices with the algorithms that we developed for the investor were never released to the market for a variety of reasons.  And we keep the algorithms for BW in a more or less alive state. </li><li>  The developers, to whom the investor came first, must be said, although they tried to solve the problem to be extremely drastic, but they took out very valuable material from the work.  Ever since their scanners have a white light, which causes the pupil to shrink, increasing the working field. </li></ul></div><p>Source: <a href="https://habr.com/ru/post/167849/">https://habr.com/ru/post/167849/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../167835/index.html">Google patented a smartphone with 8 flashes</a></li>
<li><a href="../167837/index.html">Profiling already running programs</a></li>
<li><a href="../167839/index.html">Delivery - or the ‚Äúquickest way to go bankrupt on Kickstarter‚Äù</a></li>
<li><a href="../167843/index.html">Flight - a new js-framework from Twitter</a></li>
<li><a href="../167847/index.html">Why do we continue to break deadlines</a></li>
<li><a href="../167851/index.html">The end of another era: Philips is leaving the consumer electronics market</a></li>
<li><a href="../167853/index.html">Hosting for smart. Results of the competition</a></li>
<li><a href="../167855/index.html">How to motivate the salary?</a></li>
<li><a href="../167857/index.html">CodeIgniter Application Development Standard</a></li>
<li><a href="../167859/index.html">Lebedev Studio layout chosen as a new map of the Moscow metro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>