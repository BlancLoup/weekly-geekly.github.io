<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>In-depth training on the features of the title and content of the article to overcome clickbate</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Click cloud word cloud 

 TL; DR: I achieved a clickbate recognition accuracy of 99.2% on the test data for features of the header and content. The co...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>In-depth training on the features of the title and content of the article to overcome clickbate</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/06f/e33/dbf/06fe33dbfece2b73856a992675adb1f9.png"><br>  <i>Click cloud word cloud</i> <br><br>  <b>TL; DR:</b> I achieved a clickbate recognition accuracy of 99.2% on the test data for features of the header and content.  The code is available in <a href="http://github.com/abhishekkrthakur/clickbaits_revisited">the GitHub repository</a> . <br><br>  Sometime in the past, I wrote <a href="http://www.linkedin.com/pulse/identifying-clickbaits-using-machine-learning-abhishek-thakur">an article</a> on clickbate detection.  That article received good feedback as well as a lot of criticism.  Some said that they needed to take into account the contents of the site, others asked for more examples from different sources, and some suggested trying in-depth training methods. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In this article I will try to resolve these issues and bring the clickback to a new level. <br><a name="habracut"></a><br><h1>  There is no free <s>food</s> information. </h1><br>  Looking through my own Facebook feed, I found that clickbate cannot be categorized simply by title.  It also depends on the content.  If the content of the site is well matched to the title, it should not be classified as clickback.  However, it is very difficult to determine what a real clickback is. <br><br>  See some real-life examples on Facebook. <br><br><table width="700"><tbody><tr><td width="200">  one. </td><td><img src="https://habrastorage.org/getpro/habr/post_images/118/de7/43c/118de743c49be0cbb2b9950a28f86959.png"></td></tr><tr><td width="200">  2 </td><td><img src="https://habrastorage.org/getpro/habr/post_images/aa4/6bb/9e1/aa46bb9e16625de13d5f8b031d7c242e.png"></td></tr><tr><td width="200">  3 </td><td><img src="https://habrastorage.org/getpro/habr/post_images/61b/4c9/bc8/61b4c9bc8a650ac29b87e0982118d6fb.png"></td></tr><tr><td width="200">  four. </td><td><img src="https://habrastorage.org/getpro/habr/post_images/8e6/87b/c82/8e687bc82a4b97371f88f7a2cc84e084.png"></td></tr></tbody></table><br>  What do you think now?  Which of them would you classify as clickbate and which ones not?  Has it become more difficult after deleting source information? <br><br>  My previous models based on TF-IDF and Word2Vec classify the first three as clickbacks, and maybe the fourth too.  However, among these examples there are only two clickbates: the second and the third.  The first example is the article that CNN distributes, and the fourth from The New York Times.  These are two reputable news sources, no matter what Trump says!  :) <br><br>  If Facebook / Google takes into account only the headlines, they will block all the above examples in the news feed or search results. <br><br>  So I decided to classify not only by the title, but also by the content of the site, which is opened by reference, and by some of the main features that are noticeable on this site. <br><br>  Let's start with the data collection. <br><br><h1>  Data collection </h1><br>  This time, I retrieved data from publicly accessible Facebook pages.  Max Woolf wrote an excellent <a href="http://minimaxir.com/2015/07/facebook-scraper/">article</a> on how to do it.  Python scripts are available <a href="http://github.com/minimaxir/facebook-page-post-scraper">here</a> .  This scraper allows you to extract data from public Facebook pages that are available for viewing without authorization on the site. <br><br>  I extracted data from the following pages: <br><br><ul><li>  Buzzfeed </li><li>  CNN </li><li>  The new york times </li><li>  Clickhole </li><li>  StopClickBaitOfficial </li><li>  Upworthy </li><li>  Wikinews </li></ul><br>  Let's see what data Max Wolfe's scraper has learned from the Clickhole page. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/20c/b2c/d2f/20cb2cd2f317e55a40c270785c3ba221.png"><br><br>  The following fields are interesting here: <br><br><ul><li>  link_name (title of the published URL) </li><li>  status_type (is there a link, photo or video) </li><li>  status_link (real URL) </li></ul><br>  I filtered <b>status_type == link</b> because I‚Äôm interested only in published URLs with some textual content. <br><br>  Then combined the collected data into two CSV files: Buzzfeed, Clickhole, Upworthy, and Stopclickbaitofficial fell into clickbaits.csv, and the rest into non_clickbaits.csv. <br><br><h1>  Data processing and feature generation </h1><br>  When data is collected and saved in two different files, it's time to collect html documents for all links and save all data as pickle files.  To do this, I created a very simple Python script: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/076/564/f50/076564f506515fe0fe7949ec61e75b51.png"><br><br>  I approached html extraction very strictly, and in the case of any failure, the answer was ‚Äúno html‚Äù.  To save my time and speed up data collection I used Parallel in <a href="http://pythonhosted.org/joblib/">Joblib</a> .  Please note that you need to enable cookie support for cracking sites like The New York Times. <br><br>  Since on my computer 64 GB of RAM, I did everything in memory.  You can easily modify the code to save the results line by line in CSV and free up a lot of memory. <br><br>  The next step was to generate the tags from this HTML data. <br><br>  I used <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup4</a> and <a href="http://github.com/grangier/python-goose">goose-extractor</a> to generate features. <br><br>  The generated signs included: <br><br><ul><li>  HTML size (in bytes) </li><li>  HTML length </li><li>  Total number of links </li><li>  Total number of buttons </li><li>  Total number of input fields </li><li>  Total number of unordered lists </li><li>  Total number of numbered lists </li><li>  Total number of H1 tags </li><li>  Total number of tags H2 </li><li>  Text length in all found H1 tags </li><li>  Text length in all found H2 tags </li><li>  Total number of images </li><li>  Total number of html tags </li><li>  The number of unique tags html </li></ul><br>  Let's look at some of these signs: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/749/097/2e6/7490972e6af99ff2804f1d2c878cd57a.png"><br><br>  It seems that the average number of lists is more on sites without clickbate than on sites with clickbate.  I thought it would be the opposite, but the data convince otherwise.  It also turns out that clickable sites have more links: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43b/372/72a/43b37272a9481db1b803dd437f570140.png"><br><br>  At first, I suggested that there would be more images on clickbate sites.  And yes, I was right: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c7/477/200/5c7477200f9c408253f952aa54cf261f.png"><br><br>  That's how they attract people.  Pictures in articles are like worms for fish :) <br><br>  The number of interactive elements, for example, buttons, is almost the same: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d2/24d/21b/9d224d21b2314f3c87faf5f4880d0d91.png"><br><br>  When working with text data, it is customary to compose word clouds :), so here they are. <br><br><table><tbody><tr><td>  Word cloud headlines for clickbate </td><td><img src="https://habrastorage.org/getpro/habr/post_images/c96/c86/a85/c96c86a85daf17844b8f91c4eff595ff.png"></td></tr><tr><td>  Word cloud headlines without clickbate </td><td><img src="https://habrastorage.org/getpro/habr/post_images/e05/26a/e36/e0526ae36e327beebb26c3b89f9fe212.png"></td></tr></tbody></table><br>  In the end, textual signs include: <br><br><ul><li>  Full text H1 </li><li>  Full text H2 </li><li>  Meta description </li></ul><br>  Of course, you can extract more text and non-text features from web pages, but I limited myself to the list above.  At this stage of extracting text data from web pages, I also deleted domain names from the text data of the corresponding web pages to avoid any retraining. <br><br>  I noticed that the text with Buzzfeed often contains the words "Report a problem, thanks," so I deleted them too.  Also created a special list of stop words for web pages: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/491/ee7/763/491ee77638797d7b020d6f25f82f769d.png"><br><br>  At a certain moment, the data began to satisfy me and there appeared a confidence that the model would not retrain on this data.  Then I began to construct some cool models of deep learning.  But first, look at the final data: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f4e/7d6/c1e/f4e7d6c1ec1dd7b17242ac8afb8f6cf6.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/34a/06c/c42/34a06cc42ace8de61024b1bd3a34c3ac.png"><br><br>  I ended up with about 50,000 samples.  Approximately 25,000 for clickback sites, about the same for the rest. <br><br>  Let's start building models! <br><br><h1>  Depth learning models </h1><br>  Before starting the construction of depth learning models, I divided the data into two parts, using a bundle on the label (1 = clickbate, 0 = not_clickbate).  Let's call this test data, they consist of about 2500 examples from each sample.  Test data were left intact, they were used only to evaluate the model.  This model was built and tested on the remaining 90% of the data - data for training. <br><br>  First, I tried a simple LSTM model with an embedded layer that converts positive indices into fixed-size density vectors.  It was followed by two dense layers (Dense) with dropout and packet normalization (Batch Normalization): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e9/176/89e/9e917689ef8f6a735ec816ddd4be5a01.png"><br><br>  A simple network shows an accuracy of 0.904 on a validation set after several periods, as well as an accuracy of 0.884 on a test set.  I regarded it as a benchmark and tried to improve performance.  We still have signs of content to add!  Perhaps this will improve accuracy both on the validation set and on the test set. <br><br>  In the following model, without changing the dense layers, followed by the LSTM layers, I added features of textual content and merged them before going through the dense layers: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2f5/30d/504/2f530d5045866a0287d4961698cd56ed.png"><br><br>  This model immediately improved the performance by 7% on benchmarks!  The validation accuracy has increased to 0.975, and the accuracy on the test set to 0.963.  The disadvantage of these models is that it takes a lot of time to learn, because you need to learn how to embed it.  To overcome this, I made the following models with GloVe embedding as initialization for embedded layers.  840 billion GloVe 300-dimensional inserts were used, trained on Common Crawl data.  These inserts can be downloaded <a href="http://nlp.stanford.edu/projects/glove/">here</a> . <br><br>  Previous timed dense models, as described in my article about duplicate posts in Quora.  Inserts were initialized by GloVe: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b00/afe/066/b00afe066538c8a458a8f6645d4db686.png"><br><br>  The model shows the accuracy of validation 0.977, and the accuracy on the test set - 0.971.  The advantage of using this model is that the learning time per period is less than 10 seconds, while the previous model required 120-150 seconds per period. <br><br>  So if you need a fast trained neural network model for determining clickbate, choose one of the above.  If you need a more accurate model, see below :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cef/e74/dee/cefe74deec1daced82bb49501fe6e878.png"><br><br>  This network gives a good increase in validation accuracy: 0.983, but test accuracy increased very slightly to 0.975. <br><br>  If you remember, I also created some numerical attributes based on what we do not see when we go by the URL.  My next and final model includes these attributes too, along with LSTM for the header and text data content: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d1/2f6/f82/6d12f6f8270916435495cae6adc29747.png"><br><br>  As it turned out, this is the best model with a validation accuracy of 0.996 and 0.991 on the test set.  Each period takes approximately 60 seconds on this particular model. <br><br>  The table summarizes the accuracy indicators obtained by different models: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fe2/4e1/9d0/fe24e19d090ef5e0e65345070870e323.png"><br><br>  Summarizing, I was able to build a model for determining clickback, which takes into account the title, text content and some functions of the website and demonstrates accuracy above 99% both during validation and on the test set. <br><br>  The code for everything I‚Äôm talking about is <a href="http://github.com/abhishekkrthakur/clickbaits_revisited">available on GitHub</a> . <br><br>  All models were trained on NVIDIA TitanX, Ubuntu 16.04 system with 64 GB of memory. <br><br>  Join forces and stop clickbate #StopClickBaits! <br><br>  Feel free to comment or email at abhishek4 [at] gmail [dot] com if you have any questions. </div><p>Source: <a href="https://habr.com/ru/post/324960/">https://habr.com/ru/post/324960/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../324948/index.html">Thunderbird and Kontact instead of MS Outlook</a></li>
<li><a href="../324950/index.html">Startup of the day, start (February 2017)</a></li>
<li><a href="../324952/index.html">Is FLIF the ideal format for images?</a></li>
<li><a href="../324956/index.html">Preview portal with early access to new Azure functionality</a></li>
<li><a href="../324958/index.html">Instructions for publishing iOS applications on the App Store</a></li>
<li><a href="../324962/index.html">Dumbbell as an instrument of the mind</a></li>
<li><a href="../324964/index.html">Are there stacking in Cisco Nexus switches?</a></li>
<li><a href="../324966/index.html">SAP Business One ERP Solution Features on SAP HANA Platform</a></li>
<li><a href="../324968/index.html">learnopengl. Lesson 1.8 - Coordinate Systems</a></li>
<li><a href="../324970/index.html">Adaptive Email Guide</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>