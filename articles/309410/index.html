<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>GrabDuck: How we make bookmarked articles</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We welcome you reader. Not so long ago, a new parser / article extractor appeared on our GrabDuck service. Between ourselves, we call it GrabDuck Arti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>GrabDuck: How we make bookmarked articles</h1><div class="post__text post__text-html js-mediator-article">  We welcome you reader.  Not so long ago, a new parser / article extractor appeared on our <a href="https://grabduck.com/">GrabDuck</a> service.  Between ourselves, we call it GrabDuck Article Extractor 2.0, or abbreviated as GAE 2.0.  Why so loud?  The fact is, changes and improvements have accumulated so much that we had to completely throw out the old one, with which we have lived for the last year and a half and create a new parser of articles from scratch.  And yes, for us this is a big and important change.  What we did not like and what we did as a result is described under the cut. <br><br><img src="https://habrastorage.org/files/230/62f/38b/23062f38bf3e4e6e8e405d7e14b6fddb.jpeg"><br><a name="habracut"></a><br>  So, we lived for a long time with the old parser, taken from the side in the form of a fork from some open source project.  Yes, he was good and tried to do his job for all 100 (somewhere in one of the first articles we gave a link to it - if you are interested, look).  And for those whose requirements do not exceed the average, we still recommend it to use - it will precisely handle. <br><br><img src="https://habrastorage.org/files/ad2/1f6/1a3/ad21f61a3a8840dc948d431b8c65c62a.jpg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      But over time, they increasingly began to encounter various restrictions.  As we know, our websites retain all sorts of things, we still come across a terrible legacy of the 2000s, when there were no special standards.  In general, here our library was failing and we had to climb more and more into someone else's code and edit it for ourselves.  Over time, perhaps the main complaint was that the library was like a Swiss knife, good, but I did everything myself: I loaded the document by url, tracked redirects, knew how to decipher various reference abbreviations, tried to determine the encoding, even if it was not explicitly specified, Parsil the document, identified the images and even tried to understand the date when the article was published.  In general, not a library, but a fairy tale ... True, until something needed to be corrected or slightly changed.  And we often had a choice: either to edit the code directly, or, after processing the document, to carry out another, our own, naturally duplicating in some places some logic from our original parser.  And this decision was not easy - the creator of this open source library was clearly not a fan of testing and therefore everything worked smoothly until it was touched and did not make significant changes to the code. <br><br>  And considering that the process of parsing and retrieving articles, for those who have never come across it, relies entirely on statistics rather than clear criteria, it was enough to slightly change the weights of the applied statistical model, and we immediately risked that once , some classes of sites simply cease to be processed correctly.  After all, there is no general format - the whole article is just a big piece of html, in which somewhere inside there are several paragraphs of the text we need so much.  So over time, we have our parallel world, when an already processed and seemingly already prepared article was once again banished, but through our own under-parser. <br><br>  How this open source library worked in a multi-threaded mode was a separate and very sad song.  And initially, on large imports, when the bill went to tens of thousands of bookmarks standing in line at the same time for processing, everything in our kingdom just stopped. <br><br>  And it was lesson number 1 for us: <b>when building your system, use independent components - bricks.</b>  <b>And from them collect what is necessary for you.</b>  If something goes wrong, or there is a new interesting project that does the job better, you can always turn off the old and try new, without breaking the system and not risking that everything crumble at some stage.  And then, believe our experience, if something in the world of numbers can go wrong, it will definitely go wrong almost immediately. <br><br>  So at the end we decided - that's enough, it's time to take control in our own hands and write something ours, under our requirements and with a quality that satisfies us.  And so a new component, GAE 2.0, appeared on our architectural diagram. <br>  First of all, I wanted to build it in the form of a collection of independent components.  For some steps, we needed parallel processing according to the principle: the more, the better, somewhere it was possible to do with one thread, and somewhere we wanted to speed up parallelizing work, but there were serious limitations on the number of simultaneously processed elements. <br><br>  As a result, a sort of pipeline or pipeline emerged, where each bookmark turns into a full-fledged article, filled with meaningful data for the user with each step. <br><br><img src="https://habrastorage.org/files/bf5/028/96b/bf502896b73241ec9876c6420aae50d1.jpg"><br><br>  So, what steps do we need to take in order to make a full-fledged article from the link, which can already be shown to the user? <br><br>  After deliberation, the areas of responsibility turned out to be the following: Actually Url Fetcher.  Responsible for the direct download of the article provided by Url.  Must understand all sorts of redirects, be able to work through SSL and with abbreviations of links.  And it also needs to be parallelized, because the very wait for a response from the server takes years of computer time and something needs to be done about it.  But the more the strategy, the better, here also does not fit: we will bombard the same site with requests and we will simply be banned.  So we need some kind of optimum, which is called both ours and yours. <br><br>  The result obtained should be checked for errors, and it can also be a duplicate of an article already existing on GrabDuck, and then it is enough just to link a new user to this existing article. <br><br>  And only after that it is time to extract the data and prepare the final article, which we will show to our users.  What is included here?  Obtaining meta-information, and these are headings, images, calculation of tags and language of the document  Of course, we need the content itself for full-text search, we also need to generate a text snippet briefly representing the document itself. <br><br>  After that, the document is ready for use and available for search on GrabDuck. <br><br>  So, the new parser is ready and cheers, all new bookmarks will already go through it and we will finally get what we wanted!  But the big question that may arise from the reader is: what will happen to existing bookmarks?  After all, they were ALREADY processed and ALREADY saved in the system!  Do they remain untouched?  And our answer is no!  First of all, the user always has the opportunity to select a bookmark and forcibly update it.  To do this, simply select the appropriate item from the context menu.  It looks something like this. <br><br><img src="https://habrastorage.org/files/6a0/919/931/6a0919931c3f4a94a13bd957cb652373.png"><br><br>  Well, or just wait a bit.  One of the great features of <a href="https://grabduck.com/">GrabDuck</a> is that we periodically check all the bookmarks: is everything OK, are the websites still alive, have new comments appeared on the page, etc.  So sooner or later, your bookmarks will be updated and passed through GAE 2.0. <br><br>  Today this is all we wanted to tell you.  Leave your comments and see you soon. </div><p>Source: <a href="https://habr.com/ru/post/309410/">https://habr.com/ru/post/309410/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../309400/index.html">The book ‚ÄúHTML5 and CSS3. Website development for any browsers and devices. 2nd ed. "</a></li>
<li><a href="../309402/index.html">Microsoft StorSimple virtual array. Part 2</a></li>
<li><a href="../309404/index.html">Why the 35-year-old SoftBank company again spoils its reputation because of the ‚Äúcrazy‚Äù deal with ARM Holdings</a></li>
<li><a href="../309406/index.html">Anniversary Edition Intercepter-NG 1.0</a></li>
<li><a href="../309408/index.html">Manual Start Timer</a></li>
<li><a href="../309412/index.html">GoTech.vc: Last week</a></li>
<li><a href="../309414/index.html">Reverse engineering of visual stories (part 2)</a></li>
<li><a href="../309416/index.html">New security features Android 7</a></li>
<li><a href="../309420/index.html">Gentleman's set of R packages for automating business tasks</a></li>
<li><a href="../309422/index.html">React patterns</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>