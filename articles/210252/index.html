<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What does a robot need to build a card?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Once again, Tod's blog is with you, and today we will continue our acquaintance with the navigation stack of the operating system for ROS robots. Reca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What does a robot need to build a card?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/776/b87/602/776b87602467336445e3431651ce8007.gif"><br>  Once again, Tod's blog is with you, and today we will continue our acquaintance with the navigation stack of the operating system for ROS robots.  Recall that in the <a href="http://habrahabr.ru/company/tod/blog/204250/">previous article</a> a general description of the navigation stack was given, the necessary requirements for its use on the robot were outlined, the tasks of controlling the movement of the robot, and obtaining sensory odometer and sonar data were considered.  In this article we will talk about the most "tasty" possibilities of the navigation stack: building a map and planning a trajectory of movement, taking into account the obstacles encountered on the way of the robot.  Under the cut, among other things, you will find a video with navigation of the robot Tod in the apartment. <br><a name="habracut"></a><br><h4>  Kinect </h4><br>  To build a map with a robot, you can use both a professional laser rangefinder and a less expensive depth camera: Kinect or ASUS Xtion.  Perhaps each of you knows about Kinect as a game controller for the Xbox 360 console, expanding its interactive capabilities, but not everyone knows that it is thanks to Kinect that professional robotics has become much more accessible.  While the price of an initial level laser rangefinder is about $ 1000, buying a Kinect will cost you $ 150-200. <br><img src="https://habrastorage.org/getpro/habr/post_images/c41/1a6/d47/c411a6d476aff2e103a1dc8b1afcb9c3.png"><br>  As can be seen from the picture above, Kinect is equipped with several types of sensors, which are useful for solving several tasks in the field of robotics at once: <br><ul><li>  A VGA camera with a resolution of up to 1280x1024 can be used in the system of telepresence, indoor navigation and video calls. </li><li>  Based on the data obtained from the depth sensor, 2-D and 3-D maps are built and other tasks of autonomous navigation are performed, and if the robot has a manipulator, it searches for and captures objects. </li><li>  An array of 4 microphones - for localizing sound sources (this is an interesting topic for a separate article). </li></ul><br>  In ROS, Kinect communicates through the openni_launch package node by posting several types of messages to the appropriate topics.  First of all, you should pay attention to the following topics: <br><ul><li>  / camera / rgb / image_color ‚Äî RGB camera data as an image; </li><li>  / camera / depth / image ‚Äî depth sensor data as an image; </li><li>  / camera / depth / points - depth sensor data in the form of a three-dimensional point cloud. </li></ul><br>  Using Kinect in the navigation stack requires converting the point cloud data into a fake laser 2-D rangefinder data, which means getting a horizontal cut of the original point cloud.  To solve this problem, we used the pointcloud_to_laserscan package from the stack of the Turtlebot robot.  This is what the Kinect sensor data slice looks like in the message format sensor_msgs / LaserScan. <br><img src="https://habrastorage.org/getpro/habr/post_images/3b6/ae8/4c8/3b6ae84c85f55f5066e9d8e0e79022ca.png"><br>  Kinect compared to expensive laser range finders, however, has certain disadvantages.  They should be considered, first of all, when deciding on the location of Kinect on the robot.  One of the main drawbacks is the large blind area (about 50 cm).  After the ambikontur user comment in the previous article about this problem and some discussions, we decided to place Kinect closer to the back of the robot.  This allowed us to ‚Äúhide‚Äù most of the dead zone inside the case. <br><img src="https://habrastorage.org/getpro/habr/post_images/89d/df1/a9f/89ddf1a9fad971ffcbf7b1a822c15430.jpg"><br>  Thus, at this stage, the Tod robot can already perform the following tasks related to navigation: <br><ul><li>  obtain odometry data to track the trajectory of movement; </li><li>  receive commands to move the robot in the format of linear and angular velocity; </li><li>  receive sensory sonar data in a point cloud format; </li><li>  Receive Kinect sensory data in a 2-D laser rangefinder format. </li></ul><br>  On the basis of such a system, it is possible to solve navigation problems of a higher level.  First of all, these tasks include SLAM (Simultaneous localization and mapping).  SLAM solves the ‚Äúchicken and egg‚Äù problem: on the one hand, a reliable estimate of the location of the robot in space requires an accurately constructed map, on the other hand, the process of building a map requires a more accurate assessment of the location of the robot.  Another equally important navigation task is the planning of the trajectory of movement. <br>  The ROS navigation stack provides 3 basic packages designed to solve high-level navigation tasks: <br><ul><li>  gmapping creates a room map based on the SLAM algorithm, laser rangefinder and odometer data; </li><li>  amcl locates the robot already on the existing map; </li><li>  move_base allows you to move the robot to any point on the map, taking into account obstacles. </li></ul><br>  Now let's take a closer look at the capabilities of each package. <br><br><h5>  gmapping </h5><br>  First, it should be said that the map in ROS is a regular image file in PGM format, where each pixel can be: <br><ul><li>  white space is free; </li><li>  black space is occupied by an obstacle; </li><li>  gray - the space has not yet been investigated by the robot. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/119/719/df2/119719df2d8f6b07ecf488b52f6f259f.jpg"><br>  The slam_gmapping node in the gmapping package is intended for building a map.  The SLAM algorithm used in the package, based on the collected sensory data, forms a grid map in which each cell is defined by a certain probability of finding an obstacle in it.  The probability of each cell is adjusted as new sensory data is received, and as a result we get the most reliable representation of the map.  As a sensory data, gmapping uses data from a laser rangefinder, the source of which in the Tod robot is Kinect, and odometer data. <br>  To create a map, you need to control the robot from the keyboard or the joystick, go around the room and save the resulting map to a file.  It is better not to go around the premises very quickly, while taking into account the particularities of the rangefinder used.  For example, Kinect has a blind zone in front, so when building a map you should not drive too close to the walls. <br>  We experienced the gmapping package and the robot Tod at home combat, and this is what came of it. <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/zopNwP5snE0%3Ffeature%3Doembed&amp;xid=25657,15700021,15700186,15700190,15700253&amp;usg=ALkJrhho3rYdrbg2n21eW2w_zv9ReIE3Lw" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  amcl </h4><br>  The amcl (Adaptive Monte Carlo Localization) node algorithm works with a ready-made map, for example, created using the gmapping package.  This algorithm is designed for probabilistic determination of the location of the robot based on the Monte Carlo method and the particle filter. <br>  Tod's robot as the source data in the amcl node uses sensory data from a laser rangefinder and odometry.  After the start, the node waits for setting the initial position of the robot.  This is convenient, for example, when the robot starts from the docking station.  However, if the initial position is not specified, then it is assigned a point at the beginning of the coordinate system of the map. <br>  As can be seen in the picture below, the map displays the current data of the laser range finder as red dots on the walls and obstacles, and the robot itself is in a cloud of green arrows.  These arrows indicate the array of possible positions of the robot at the current time, formed by the amcl node.  As the robot moves around the map and new sensory data is received, the uncertainty of the robot's position decreases, and this cloud becomes smaller. <br><img src="https://habrastorage.org/getpro/habr/post_images/860/57a/01b/86057a01bfbe4d0d62c8fe77529178e0.jpg"><br>  In the amcl node, you can set many parameters of the algorithm.  For example, increasing the maximum number of particles (particle) improves the accuracy of determining the position of the robot, but it also increases the load on the CPU. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  move_base </h4><br>  You can move the robot around the map, controlling it from the keyboard, but the move_base package in the ROS navigation stack also allows its autonomous movement.  It is enough to set a point on the map, and the robot will independently create the best route to the target.  During the assignment, the robot will report its current location, and if the target is unavailable for some reason, it will cancel it without disrupting the operation of the system. <br>  The global route is built immediately after setting the target, taking into account the currently known obstacles.  During the movement to the target, the global route is divided into segments - local routes.  Each local route is constructed taking into account the incoming sensory data by setting the appropriate linear and angular velocity of the robot. <br>  The nature of the route of movement of the robot to the target is determined by two components: <br><ul><li>  global cost map (global cost map) - to build a global route; </li><li>  local cost map (local cost map) - to build the nearest local traffic route. </li></ul><br>  Cost maps provide the navigation information needed to successfully complete the current route.  In the configuration files of the cost cards, the robot sizes, its speed along the route, the length of the segments, the frequency of the route update, and much more are set. <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/jiLDcdB3sbA%3Ffeature%3Doembed&amp;xid=25657,15700021,15700186,15700190,15700253&amp;usg=ALkJrhhhT9JoAYKMrYRBav5IiX4iendQvA" frameborder="0" allowfullscreen=""></iframe><br><br>  And this is where we end up with the ROS navigation stack.  In the <a href="http://habrahabr.ru/company/tod/blog/214849/">next post,</a> we will teach Tod to understand Russian.  Subscribe to our blog - stay up to date. </div><p>Source: <a href="https://habr.com/ru/post/210252/">https://habr.com/ru/post/210252/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../210234/index.html">We consider likes in real life or how to properly evaluate an employee (concept)</a></li>
<li><a href="../210236/index.html">Pavel Durov sold his stake in VK. Now officially</a></li>
<li><a href="../210238/index.html">Four methods for downloading images from a website using Python</a></li>
<li><a href="../210240/index.html">How statistics help make Yandex.Probki better</a></li>
<li><a href="../210248/index.html">Neurosystem: a revolution of consciousness</a></li>
<li><a href="../210254/index.html">The lessons of space catastrophes</a></li>
<li><a href="../210256/index.html">The subtleties of analyzing C / C ++ source code using cppcheck</a></li>
<li><a href="../210258/index.html">Opportunity has been on Mars for 10 years.</a></li>
<li><a href="../210262/index.html">What should look like a manual for a female phone</a></li>
<li><a href="../210264/index.html">CMS development practice</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>