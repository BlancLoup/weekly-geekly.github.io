<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Flying snowflakes</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="1. Introduction 


 In heavily loaded portals or APIs, there may be a need to use machine learning algorithms, for example, to classify users. In the ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Flying snowflakes</h1><div class="post__text post__text-html js-mediator-article"><h2 id="1-vstuplenie">  1. Introduction </h2><br><p>  In heavily loaded portals or APIs, there may be a need to use machine learning algorithms, for example, to classify users.  In the framework of this note, the process of implementation of some high-performance linear models will be shown, and explanations of the basic theoretical principles will be given. </p><a name="habracut"></a><br><h2 id="2-parnaya-lineynaya-zavisimost">  2. Paired linear dependence </h2><br><p>  I will begin my story with the most frequently used and simple models.  Suppose that there is a pair of metrics with a pronounced linear dependence.  Visually display the data: the value of the first metric is the position of the point on the abscissa, and the value of the second metric is the position of the point on the ordinate.  The figure shows that with an increase in the explanatory variable (it is also called a predictor, a regressor or an independent variable), an increase in the dependent variable occurs.  For clarity, theoretical examples will be shown in R: </p><br><pre><code class="hljs lisp">a &lt;- c(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">18</span></span>, <span class="hljs-number"><span class="hljs-number">22</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">29</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>) b &lt;- c(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">17</span></span>, <span class="hljs-number"><span class="hljs-number">19</span></span>, <span class="hljs-number"><span class="hljs-number">22</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>) plot(<span class="hljs-name"><span class="hljs-name">a</span></span>, b) abline(<span class="hljs-name"><span class="hljs-name">lm</span></span>(<span class="hljs-name"><span class="hljs-name">b</span></span> ~ a), col = <span class="hljs-string"><span class="hljs-string">"blue"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/9i/bt/d6/9ibtd6i-yw-fvu3lng86xg_dmok.png"></p><br><p>  Let it be necessary to write such an algorithm, which should reveal the fact of the existence of a linear relationship, as well as measure its degree of expression.  Formally speaking, it is necessary to calculate the linear correlation coefficient of Karl Pearson.  I propose to recall the theoretical foundations and deal in more detail with the calculation formulas: </p><br><p><img src="https://habrastorage.org/webt/om/vj/fz/omvjfzu2bo6rbdhgkywwtr1scaq.png"></p><br><p>  First of all, we are interested in such a characteristic of sets, which is called the variance of a random variable.  If we take the average value from each element of the set and square the result, we get a new set, the average value of which is called the variance of the random variable for the general population.  As you understand, if all the elements of the original set were the same, then the variance is zero, and the more the elements deviate from the average value, the greater will be the variance.  And it can not be a negative number. </p><br><pre> <code class="hljs lisp">var_a &lt;- sum((<span class="hljs-name"><span class="hljs-name">a</span></span> - mean(<span class="hljs-name"><span class="hljs-name">a</span></span>)) ^ <span class="hljs-number"><span class="hljs-number">2</span></span>) / (<span class="hljs-name"><span class="hljs-name">length</span></span>(<span class="hljs-name"><span class="hljs-name">a</span></span>) - <span class="hljs-number"><span class="hljs-number">1</span></span>) c(<span class="hljs-name"><span class="hljs-name">var</span></span>(<span class="hljs-name"><span class="hljs-name">a</span></span>), var_a) # <span class="hljs-number"><span class="hljs-number">127.2625</span></span> <span class="hljs-number"><span class="hljs-number">127.2625</span></span> c(<span class="hljs-name"><span class="hljs-name">sd</span></span>(<span class="hljs-name"><span class="hljs-name">a</span></span>), sqrt(<span class="hljs-name"><span class="hljs-name">var_a</span></span>)) # <span class="hljs-number"><span class="hljs-number">11.28107</span></span> <span class="hljs-number"><span class="hljs-number">11.28107</span></span></code> </pre> <br><p>  Note that in the example shown above, we divided not by the power of the set, but by one less than it.  In other words, we calculated the variance for the sample, not for the general population.  And since the difference between the average and the element was squared, it now makes sense to extract the square root of the variance, thereby obtaining the standard deviation.  To search for relationships, you need to know the standard deviation of the second set: </p><br><pre> <code class="hljs lisp">var_b &lt;- sum((<span class="hljs-name"><span class="hljs-name">b</span></span> - mean(<span class="hljs-name"><span class="hljs-name">b</span></span>)) ^ <span class="hljs-number"><span class="hljs-number">2</span></span>) / (<span class="hljs-name"><span class="hljs-name">length</span></span>(<span class="hljs-name"><span class="hljs-name">b</span></span>) - <span class="hljs-number"><span class="hljs-number">1</span></span>) c(<span class="hljs-name"><span class="hljs-name">var_b</span></span>, var(<span class="hljs-name"><span class="hljs-name">b</span></span>)) # <span class="hljs-number"><span class="hljs-number">122.7833</span></span> <span class="hljs-number"><span class="hljs-number">122.7833</span></span> c(<span class="hljs-name"><span class="hljs-name">sd</span></span>(<span class="hljs-name"><span class="hljs-name">b</span></span>), sqrt(<span class="hljs-name"><span class="hljs-name">var_b</span></span>)) # <span class="hljs-number"><span class="hljs-number">11.08076</span></span> <span class="hljs-number"><span class="hljs-number">11.08076</span></span></code> </pre> <br><p>  Now it is necessary to calculate such a measure of linear dependence of two quantities as covariance.  The formula is very similar to variance, moreover, if the sets are identical, then we really get the variance of the random variable.  The order of the arguments can be arbitrary (it is possible to interchange sets), since symmetry is visible by the formula - the covariance of A and B is equal to the covariance of B and A. </p><br><pre> <code class="hljs lisp">cov_ab &lt;- sum((<span class="hljs-name"><span class="hljs-name">a</span></span> - mean(<span class="hljs-name"><span class="hljs-name">a</span></span>)) * (b - mean(b))) / (length(a) - 1) c(cov(a, b), cov_ab) # 124.525 124.525</code> </pre> <br><p>  Actually, the linear correlation coefficient of Karl Pearson is simply the ratio of the covariance and the product of the standard deviations of the sets.  Unlike covariance, it is very convenient to interpret it: it is always in the range from -1 to 1. The closer it is to one, the higher the linear correlation.  And proximity to -1 shows a negative correlation (in other words, the more one variable, the less the other).  If it does not deviate strongly from zero, then this indicates a weak dependence.  It is very important to emphasize that we are talking only about linear dependence without sharply pronounced outliers, otherwise the use of this coefficient will not make sense. </p><br><pre> <code class="hljs perl">cov_ab / (<span class="hljs-keyword"><span class="hljs-keyword">sqrt</span></span>(var_a) * <span class="hljs-keyword"><span class="hljs-keyword">sqrt</span></span>(var_b)) <span class="hljs-comment"><span class="hljs-comment"># 0.9961772 cor(a, b) # 0.9961772</span></span></code> </pre> <br><p>  The linear correlation coefficient can be calculated after normalization or standardization of data, since the dependence will be preserved.  Consider both the above mentioned modifications of the initial data - standardization and normalization.  In the first case, the average value of each element of the set was subtracted (we got the force of deviation of this value from the average), and then we divided it by the standard deviation.  As a result, we obtained a new set, in which the average value is 0, and the variance is 1. In the second case, we subtracted the minimum value from each element and divided it into a variational span (the data will be in the range from 0 to 1). </p><br><pre> <code class="hljs delphi">#  nm &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(a)</span></span></span><span class="hljs-function"> </span><span class="hljs-comment"><span class="hljs-function"><span class="hljs-comment">{ (a - mean(a)) / sd(a) }</span></span></span><span class="hljs-function"> #  </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">snt</span></span></span><span class="hljs-function"> &lt;- </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(a)</span></span></span><span class="hljs-function"> </span><span class="hljs-comment"><span class="hljs-function"><span class="hljs-comment">{ (a - min(a)) / (max(a) - min(a)) }</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(a, b)</span></span></span><span class="hljs-function"> # 0.9961772 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(nm(a)</span></span></span><span class="hljs-function">, </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">nm</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(b)</span></span></span><span class="hljs-function">) # 0.9961772 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(snt(a)</span></span></span><span class="hljs-function">, </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">snt</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(b)</span></span></span><span class="hljs-function">) # 0.9961772</span></span></code> </pre> <br><p>  Observing a pairwise linear dependence, we approximate it by a straight line.  This will make it possible to predict the value of one metric, if only the second is known.  Since we are examining exactly the pairwise linear dependence, we should calculate only two parameters: a constant (intersection, offset, intercept) and the coefficient of the only predictor, i.e.  slope of a straight line (slope).  To calculate the predictor coefficient, it is enough to multiply the correlation by the result of dividing the standard deviation of the predictor and the dependent variable.  The intersection can be found even easier: subtract from the average value of the predictor the result of the product of the coefficient and the average value of the dependent variable. </p><br><pre> <code class="hljs lisp">slope &lt;- cor(<span class="hljs-name"><span class="hljs-name">a</span></span>, b) * (<span class="hljs-name"><span class="hljs-name">sd</span></span>(<span class="hljs-name"><span class="hljs-name">b</span></span>) / sd(<span class="hljs-name"><span class="hljs-name">a</span></span>)) intercept &lt;- mean(<span class="hljs-name"><span class="hljs-name">b</span></span>) - (<span class="hljs-name"><span class="hljs-name">slope</span></span> * mean(a)) c(intercept, slope) # 0.2803261 0.9784893</code> </pre> <br><p>  If the dependency is not functional, but stochastic, then some error will appear.  Consider an example.  Let us try to predict the value of the dependent variable using linear regression if only the predictor is known.  In red, I display the predicted values ‚Äã‚Äãthat are strictly on the straight line, and the black ones - the actual value: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">y</span></span> &lt;- (<span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">2803261</span></span> + (<span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">9784893</span></span> * a)) plot(a, b) points(a, y, col = <span class="hljs-string"><span class="hljs-string">"red"</span></span>) abline(lm(b <span class="hljs-regexp"><span class="hljs-regexp">~ a),</span></span> col = <span class="hljs-string"><span class="hljs-string">"blue"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/7y/xn/vm/7yxnvmqfcpske2gqu_jjd5rxi8e.png"></p><br><p>  Error is the difference between the actual and predicted value.  For example, in the R programming language, descriptive error statistics are displayed in the Residuals clause.  Robust (resistant to interference) measurement results are shown.  The middle of the sorted set (median) is resistant to outliers (interference), as well as the lower or upper quartile.  The average value is not used here because it is not resistant to emissions.  It is not difficult to guess that the maximum and minimum are peculiar records (the most powerful mistake). </p><br><pre> <code class="hljs smalltalk">summary(lm(b ~ a)) # <span class="hljs-type"><span class="hljs-type">Residuals</span></span>: # <span class="hljs-type"><span class="hljs-type">Min</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>Q <span class="hljs-type"><span class="hljs-type">Median</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span>Q <span class="hljs-type"><span class="hljs-type">Max</span></span> # <span class="hljs-number"><span class="hljs-number">-2.15126</span></span> <span class="hljs-number"><span class="hljs-number">-0.61350</span></span> <span class="hljs-number"><span class="hljs-number">-0.09749</span></span> <span class="hljs-number"><span class="hljs-number">0.50744</span></span> <span class="hljs-number"><span class="hljs-number">2.04233</span></span> # # <span class="hljs-type"><span class="hljs-type">Coefficients</span></span>: # <span class="hljs-type"><span class="hljs-type">Estimate</span></span> <span class="hljs-type"><span class="hljs-type">Std</span></span>. <span class="hljs-type"><span class="hljs-type">Error</span></span> t value <span class="hljs-type"><span class="hljs-type">Pr</span></span>(&gt;|t|) # (<span class="hljs-type"><span class="hljs-type">Intercept</span></span>) <span class="hljs-number"><span class="hljs-number">0.28033</span></span> <span class="hljs-number"><span class="hljs-number">0.44308</span></span> <span class="hljs-number"><span class="hljs-number">0.633</span></span> <span class="hljs-number"><span class="hljs-number">0.537</span></span> # a <span class="hljs-number"><span class="hljs-number">0.97849</span></span> <span class="hljs-number"><span class="hljs-number">0.02293</span></span> <span class="hljs-number"><span class="hljs-number">42.669</span></span> <span class="hljs-number"><span class="hljs-number">3.17e-16</span></span> *** # --- # <span class="hljs-type"><span class="hljs-type">Signif</span></span>. codes: <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-string"><span class="hljs-string">'***'</span></span> <span class="hljs-number"><span class="hljs-number">0.001</span></span> <span class="hljs-string"><span class="hljs-string">'**'</span></span> <span class="hljs-number"><span class="hljs-number">0.01</span></span> <span class="hljs-string"><span class="hljs-string">'*'</span></span> <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-string"><span class="hljs-string">'.'</span></span> <span class="hljs-number"><span class="hljs-number">0.1</span></span> <span class="hljs-string"><span class="hljs-string">' '</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> #</code> </pre> <br><p>  In addition, the intercept and predictor coefficients that we calculated earlier are shown.  Neighbor column is a standard error.  The t-statistic is shown next to it, which tests the null hypothesis that the coefficient is zero (since there is no sense in subtracting zero from the coefficient, we simply divide the coefficient by the standard error).  The level of significance is quite large, which allows you to reject the null hypothesis.  For clarity, we calculate manually obtained indicators: </p><br><pre> <code class="hljs pgsql">e &lt;- (b - y) # Residuals: c(min(e), quantile(e, <span class="hljs-number"><span class="hljs-number">.25</span></span>), median(e), quantile(e, <span class="hljs-number"><span class="hljs-number">.75</span></span>), max(e)) # <span class="hljs-number"><span class="hljs-number">-2.15126190</span></span> <span class="hljs-number"><span class="hljs-number">-0.61349440</span></span> <span class="hljs-number"><span class="hljs-number">-0.09748515</span></span> <span class="hljs-number"><span class="hljs-number">0.50744140</span></span> <span class="hljs-number"><span class="hljs-number">2.04233440</span></span> # Std. Error (a) sqrt(sum(e ^ <span class="hljs-number"><span class="hljs-number">2</span></span>) / ((length(e) - <span class="hljs-number"><span class="hljs-number">2</span></span>) * sum((a - mean(a)) ^ <span class="hljs-number"><span class="hljs-number">2</span></span>))) # <span class="hljs-number"><span class="hljs-number">0.02293208</span></span> # t <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> (a) <span class="hljs-number"><span class="hljs-number">0.9784893</span></span> / <span class="hljs-number"><span class="hljs-number">0.02293208</span></span> # <span class="hljs-number"><span class="hljs-number">42.66902</span></span> # Pr(&gt;|t|) (a) round((pt(<span class="hljs-number"><span class="hljs-number">42.66902</span></span>, df = <span class="hljs-number"><span class="hljs-number">14</span></span>, lower.tail = <span class="hljs-keyword"><span class="hljs-keyword">FALSE</span></span>) * <span class="hljs-number"><span class="hljs-number">2</span></span>), digits = <span class="hljs-number"><span class="hljs-number">18</span></span>) # <span class="hljs-number"><span class="hljs-number">3.17e-16</span></span></code> </pre> <br><p>  Now we estimate the accuracy of the model using the following metrics: MSE, MAE and RMSE.  The name MSE comes from the English Mean Square Error.  This is the average square error.  And the MAE (Mean Absolute Error) metric is the average absolute value of the error.  In other words, in the first case we get the average value of the square of the error, and in the second - the average of the error modulus.  The RMSE (Root Mean Square Error) metric is simply the square root of MSE. </p><br><pre> <code class="hljs lisp">mae &lt;- mean(<span class="hljs-name"><span class="hljs-name">abs</span></span>(<span class="hljs-name"><span class="hljs-name">e</span></span>)) mse &lt;- mean(<span class="hljs-name"><span class="hljs-name">e</span></span> ^ <span class="hljs-number"><span class="hljs-number">2</span></span>) rmse &lt;- sqrt(<span class="hljs-name"><span class="hljs-name">mse</span></span>) c(<span class="hljs-name"><span class="hljs-name">mae</span></span>, mse, rmse) # <span class="hljs-number"><span class="hljs-number">0.7131298</span></span> <span class="hljs-number"><span class="hljs-number">0.8783887</span></span> <span class="hljs-number"><span class="hljs-number">0.9372239</span></span> hist(<span class="hljs-name"><span class="hljs-name">e</span></span>, breaks = <span class="hljs-number"><span class="hljs-number">10</span></span>, col = <span class="hljs-string"><span class="hljs-string">"blue"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/yw/bp/rr/ywbprr8wh1xphgydxtjpctogkbk.png"></p><br><h2 id="3-perenos-suschestvuyuschih-modeley">  3. Transferring existing models </h2><br><p>  Let us turn to a more practical aspect.  Suppose that there is a very high-loaded API, in which you need to add functionality to detect the value of the dependent variable according to the value of the only predictor.  In fact, we are talking about the problem of approximation (regression).  The implementation of the linear function will differ in a very compact and high-performance code. </p><br><p>  We assume that the API is written in PHP7.  Let me remind you that the external system should not know anything about the principles of the model.  All work logic will be encapsulated in one class.  Only input requirements and return value are known.  As the design strategy strategy suggests, the client will use any class that implements the interface.  This interface will require the implementation of one method that takes a single argument (predictor), and returns a different scalar value - the dependent variable. </p><br><pre> <code class="php hljs"><span class="hljs-meta"><span class="hljs-meta">&lt;?php</span></span> <span class="hljs-keyword"><span class="hljs-keyword">declare</span></span>(strict_types = <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">IModel</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $x * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $x)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span></span>; } <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Example</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">IModel</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@var</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> SLOPE = <span class="hljs-number"><span class="hljs-number">0.9784893</span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@var</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> INTERCEPT = <span class="hljs-number"><span class="hljs-number">0.2803261</span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $x * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $x)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::INTERCEPT + (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::SLOPE * $x)); } } <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Client</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@var</span></span></span><span class="hljs-comment"> IModel */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> $_model; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> IModel $model */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(IModel $model)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;_model = $model; } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $x * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $x)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;_model-&gt;predict($x); } } $client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Client(); $client-&gt;setModel(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Example()); <span class="hljs-keyword"><span class="hljs-keyword">echo</span></span> $client-&gt;run(<span class="hljs-number"><span class="hljs-number">17</span></span>);</code> </pre> <br><p>  For comparison, you can write a complete code for a pairwise linear relationship: </p><br><pre> <code class="php hljs"><span class="hljs-meta"><span class="hljs-meta">&lt;?php</span></span> <span class="hljs-keyword"><span class="hljs-keyword">declare</span></span>(strict_types = <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Model</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@var</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> $slope = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@var</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> $intercept = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $x * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $y */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $x, array $y)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;slope = Stat::cor($x, $y) * (Stat::sd($y) / Stat::sd($x)); <span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;intercept = Stat::mean($y) - (<span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;slope * Stat::mean($x)); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> float $x * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float $x)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;intercept + (<span class="hljs-keyword"><span class="hljs-keyword">$this</span></span>-&gt;slope * $x)); } }</code> </pre> <br><p>  I implemented descriptive statistics methods in a separate class: </p><br><pre> <code class="php hljs"><span class="hljs-meta"><span class="hljs-meta">&lt;?php</span></span> <span class="hljs-keyword"><span class="hljs-keyword">declare</span></span>(strict_types = <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Stat</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $values * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">max</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $values)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> max($values); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $values * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">min</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $values)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> min($values); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $values * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sum</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $values)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> array_sum($values); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $values * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $values)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::sum($values) / count($values); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $values * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">variance</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $values)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ $mean = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::mean($values); $pow = array_map(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">($v)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">use</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">($mean)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pow($v - $mean, <span class="hljs-number"><span class="hljs-number">2</span></span>); }, $values); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::sum($pow) / (count($pow) - <span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $values * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sd</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $values)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sqrt(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::variance($values)); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $a * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $b * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cov</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $a, array $b)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ $meanA = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::mean($a); $meanB = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::mean($b); $diff = []; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>($i = <span class="hljs-number"><span class="hljs-number">0</span></span>; $i &lt; count($a); $i++) { $diff[] = ($a[$i] - $meanA) * ($b[$i] - $meanB); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::sum($diff) / (count($diff) - <span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-comment"><span class="hljs-comment">/** * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $a * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@param</span></span></span><span class="hljs-comment"> array $b * </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@return</span></span></span><span class="hljs-comment"> float */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(array $a, array $b)</span></span></span><span class="hljs-function">: </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">float</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::cov($a, $b) / (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::sd($a) * <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>::sd($b)); } }</code> </pre> <br><p>  Let's complicate the task.  Let the number of predictors be arbitrary.  This is not a straight line, but a hyperplane in multidimensional space.  And we change the type of the problem from approximation to classification.  For example, the problem of binary classification was solved using logistic regression.  We want to use this statistical model in our incredibly heavily loaded service, for example, to classify users.  To solve the problem, we do not need the model learning algorithm itself, but only the parameters of the separating hyperplane. </p><br><p>  In this situation, the principle of the model will remain the same.  In the same way, the results of multiplying the predictors by their corresponding coefficients should be summed up.  Then intercept is added to the amount received.  Sometimes, instead of bias, an artificial constant predictor is added, then the whole formula will be reduced only to the sum of the predictor products with their coefficients (the scalar product of the weight vector and the feature vector). </p><br><p>  For the classification problem, we simply compare the calculation result with a predetermined threshold.  If the value is greater, then it is assigned the first class, otherwise - zero.  The transfer of such a model will be identical.  This is the two most important advantages of such linear models - compact code and very high performance.  This allows literally on the fly to identify the class of observation on the vector of signs. </p><br><pre> <code class="hljs mel">#   dataset &lt;- read.csv(<span class="hljs-string"><span class="hljs-string">'dataset.csv'</span></span>) #      pairs(dataset, col = factor(dataset$class)) #     model &lt;- glm(formula = class ~ ., data = dataset, family = binomial) #    b &lt;- model$coefficients #    ,    nc &lt;- (b[<span class="hljs-number"><span class="hljs-number">1</span></span>] + (dataset$alpha * b[<span class="hljs-number"><span class="hljs-number">2</span></span>]) + (dataset$beta * b[<span class="hljs-number"><span class="hljs-number">3</span></span>])) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> plot(dataset$alpha, dataset$beta, col = factor(nc))</code> </pre> <br><p><img src="https://habrastorage.org/webt/3b/uf/qu/3bufquaeyimoziblnlgs72x6t8i.png"></p><br><p>  The image shows that a similar linear function divided the points into two classes.  Actually, its parameters and need to be exported to the code in another programming language.  As we have seen, this is an easy task.  This process is very well automated.  The main thing is to be sure that such a hyperplane will correctly classify, and all predictors are really necessary. </p><br><p>  Train the model and check its accuracy should be on different data sets.  There are a number of classification accuracy metrics, the main ones we will definitely consider.  First of all, I propose to recall the probability metric of an exact answer.  It is calculated as the number of correct answers divided by the number of all answers. </p><br><pre> <code class="hljs lisp">test &lt;- factor(<span class="hljs-name"><span class="hljs-name">as</span></span>.logical(<span class="hljs-name"><span class="hljs-name">dataset</span></span>$class)) length(<span class="hljs-name"><span class="hljs-name">nc</span></span>) # <span class="hljs-number"><span class="hljs-number">345</span></span> table(<span class="hljs-name"><span class="hljs-name">test</span></span> == nc) # FALSE TRUE # <span class="hljs-number"><span class="hljs-number">17</span></span> <span class="hljs-number"><span class="hljs-number">328</span></span> <span class="hljs-number"><span class="hljs-number">328</span></span> / <span class="hljs-number"><span class="hljs-number">345</span></span> # <span class="hljs-number"><span class="hljs-number">0.9507246</span></span></code> </pre> <br><p>  And what if the proportion of observations of one of the classes is only one thousandth of a percent?  Here, even the constant issuing classifier will show a remarkable result.  It makes sense to display the confusion matrix.  In a binary classification, there can be only four outcomes of the prediction of a class label.  A true positive result is the correct guessing of a positive class (TRUE is predicted to be TRUE).  True negative - correct guessing of the negative class (FALSE predicted as FALSE).  It is logical to assume that a false positive is FALSE predicted as TRUE, and a false negative is TRUE predicted as FALSE.  Let's look at a specific example: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">table</span></span>(nc, test) # test # nc <span class="hljs-keyword"><span class="hljs-keyword">FALSE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TRUE</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">FALSE</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">TRUE</span></span> <span class="hljs-number"><span class="hljs-number">9</span></span> <span class="hljs-number"><span class="hljs-number">208</span></span></code> </pre> <br><p>  Where "nc" is the response of the classifier, and "test" is the true answer.  Determine the proportion of positive responses of the classifier, which were really positive (accuracy, precision).  As well as recall, i.e.  what proportion of these positive ones could be identified by this model.  The meaning of these indicators is the following: accuracy shows the degree of confidence in the classifier, if he gave a positive answer.  In other words, as far as we can be sure that this is a really positive class.  But the fullness shows the coverage of the detecting ability, i.e.  share of positives identified.  If we are afraid to mistakenly call a class positive, then accuracy is more important.  When you need to find as many positive ones as possible, completeness is more important. </p><br><pre> <code class="hljs pgsql">library(caret) <span class="hljs-type"><span class="hljs-type">precision</span></span> &lt;- posPredValue(factor(nc), test, positive = T) # <span class="hljs-number"><span class="hljs-number">0.9585253</span></span> recall &lt;- sensitivity(factor(nc), test, positive = T) # <span class="hljs-number"><span class="hljs-number">0.962963</span></span> #  F1       f1 &lt;- (<span class="hljs-number"><span class="hljs-number">2</span></span> * <span class="hljs-type"><span class="hljs-type">precision</span></span> * recall) / (<span class="hljs-type"><span class="hljs-type">precision</span></span> + recall) # <span class="hljs-number"><span class="hljs-number">0.960739</span></span></code> </pre> <br><p>  Calculate manually the accuracy and completeness.  It is enough to substitute values ‚Äã‚Äãfrom the confusion matrix: </p><br><pre> <code class="hljs lisp"># precision ( /  + ) <span class="hljs-number"><span class="hljs-number">208</span></span> / (<span class="hljs-number"><span class="hljs-number">208</span></span> + <span class="hljs-number"><span class="hljs-number">9</span></span>) # <span class="hljs-number"><span class="hljs-number">0.9585253</span></span> # recall ( /  + ) <span class="hljs-number"><span class="hljs-number">208</span></span> / (<span class="hljs-number"><span class="hljs-number">208</span></span> + <span class="hljs-number"><span class="hljs-number">8</span></span>) # <span class="hljs-number"><span class="hljs-number">0.962963</span></span></code> </pre> <br><h2 id="4-ocenka-vazhnosti-prediktorov">  4. Assessing the importance of predictors </h2><br><p>  For example, a complex psychological study of people was carried out.  One half of the subjects suffer from neurosis, while the other is doing well.  What are the differences?  Or another example: measured the performance of the equipment - some devices work well, but with others the problem.  What influences it?  Intuitively, we can assume that we should try to look for a correlation between the dependent variable and each of the predictors.  Suddenly it turns out that, for example, the metric of fuel quality correlates strongly with durability (the better the fuel, the more durable the operation of the device).  Or see the differences in the mean values ‚Äã‚Äãof predictors for observations of different classes. </p><br><p>  However, let's try to visually display our data set.  Some conditional border is visible, after which the dots change color.  It passes in the region of 0.5 according to the alpha predictor.  This can be seen in the histogram of its distribution (shown in different colors).  And according to the ‚Äúbeta‚Äù predictor, there are no obvious differences. </p><br><p><img src="https://habrastorage.org/webt/to/nv/s4/tonvs40kxnnxfr82ue-lg4cpnei.png"></p><br><p>  It is intuitively clear that, despite the error (some points will be incorrectly classified), such a criterion will more effectively solve the problem than any possible separation according to the ‚Äúbeta‚Äù predictor.  Therefore, the importance of "alpha" will be quite high.  After separation, the probability to meet the point of the desired class increases significantly.  To identify the difference, we first calculate the probability without separation. </p><br><pre> <code class="hljs lisp">table(<span class="hljs-name"><span class="hljs-name">dataset</span></span>$class) # <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> # <span class="hljs-number"><span class="hljs-number">129</span></span> <span class="hljs-number"><span class="hljs-number">216</span></span> length(<span class="hljs-name"><span class="hljs-name">dataset</span></span>$class) # <span class="hljs-number"><span class="hljs-number">345</span></span> c(<span class="hljs-number"><span class="hljs-number">129</span></span> / <span class="hljs-number"><span class="hljs-number">345</span></span>, <span class="hljs-number"><span class="hljs-number">216</span></span> / <span class="hljs-number"><span class="hljs-number">345</span></span>) # <span class="hljs-number"><span class="hljs-number">0.373913</span></span> <span class="hljs-number"><span class="hljs-number">0.626087</span></span></code> </pre> <br><p>  Knowing the probabilities, we calculate the data homogeneity metric (if only representatives of one class, then the Gini impurity index will be equal to 0).  Gini impurity is calculated as the sum of the squares of probabilities, which was taken from the unit. </p><br><pre> <code class="hljs lua"># Gini impurity gini &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(p)</span></span></span></span> { (<span class="hljs-number"><span class="hljs-number">1</span></span> - sum(p ^ <span class="hljs-number"><span class="hljs-number">2</span></span>)) } gini(c(<span class="hljs-number"><span class="hljs-number">0.373913</span></span>, <span class="hljs-number"><span class="hljs-number">0.626087</span></span>)) # <span class="hljs-number"><span class="hljs-number">0.4682041</span></span></code> </pre> <br><p>  Divide all points by the condition mentioned earlier.  The essence boils down to an intuitive logic: we want to choose the most effective separation according to the most informative predictor. </p><br><pre> <code class="hljs pgsql">node_1 &lt;- subset(dataset, alpha &gt; <span class="hljs-number"><span class="hljs-number">.5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">table</span></span>(node_1$<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>) # <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> # <span class="hljs-number"><span class="hljs-number">25</span></span> <span class="hljs-number"><span class="hljs-number">197</span></span> length(node_1$<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>) # <span class="hljs-number"><span class="hljs-number">222</span></span> #   gini(c(<span class="hljs-number"><span class="hljs-number">25</span></span>/<span class="hljs-number"><span class="hljs-number">222</span></span>, <span class="hljs-number"><span class="hljs-number">197</span></span>/<span class="hljs-number"><span class="hljs-number">222</span></span>)) # <span class="hljs-number"><span class="hljs-number">0.199862</span></span></code> </pre> <br><p>  Repeat the procedure recursively with each new subset obtained.  This will occur until a certain stopping condition, for example, until only observations of one class remain.  This is well described by the decision tree, where in the nodes the corresponding test conditions (comparing the predictor with a constant) and in the terminal nodes (leaves) are observations of one class.  Since the tree will try first of all to take the most effective predictors, the conditions of separation according to them will accumulate in the nodes close to the root.  It turns out that the level (depth) of separation according to the predictor reflects its importance. </p><br><pre> <code class="hljs pgsql">node_2 &lt;- subset(node_1, beta &lt; <span class="hljs-number"><span class="hljs-number">.29</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">table</span></span>(node_2$<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>) # <span class="hljs-number"><span class="hljs-number">1</span></span> # <span class="hljs-number"><span class="hljs-number">34</span></span> length(node_2$<span class="hljs-keyword"><span class="hljs-keyword">class</span></span>) # <span class="hljs-number"><span class="hljs-number">34</span></span> #      gini(c(<span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">34</span></span>, <span class="hljs-number"><span class="hljs-number">34</span></span>/<span class="hljs-number"><span class="hljs-number">34</span></span>)) # <span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre> <br><p>  Agree that doing it manually is not the most comfortable task.  This is where machine learning algorithms come to the rescue.  Unfortunately, decision tree ensembles do not know how to explain (or rather, it is difficult to interpret a huge number of decision trees) the difference between classes, but they can calculate the importance of predictors.  This also applies to approximation tasks, where the principle of operation is similar, only the separation criterion will be different. </p><br><p>  On this dataset it was as clear as possible that one of the predictors has a very high significance.  Let's see how it correlates with the class label: </p><br><p><img src="https://habrastorage.org/webt/l7/js/dr/l7jsdrrbxi7q7magkwtg6wgqucc.png"></p><br><p>  There are differences in the mean values ‚Äã‚Äãof different classes.  I propose to look at descriptive statistics (examples in Python and R): </p><br><p><img src="https://habrastorage.org/webt/jq/y5/pk/jqy5pkpvaexadvcfewiuhpi8fai.png"></p><br><p>  Assessing the importance of predictors through Random Forest: </p><br><p><img src="https://habrastorage.org/webt/kn/n-/pv/knn-pvbger2amcgqyr2y1ree8iw.png"></p><br><h2 id="5-vyvody">  5. Conclusions </h2><br><p>  The linear models described in the note have two main advantages that make it quite easy to transfer them to different projects.  First, it is a compact code (only a few mathematical operations).  Secondly, very high performance.  However, everything has flaws.  Unfortunately, if the points are poorly separated by a hyperplane or the dependence is poorly approximated by it, then the efficiency will be at an unacceptably low level. </p><br><h2 id="6-prilozhenie">  6. Application </h2><br><p>  Used source code snippets (Python) to identify the degree of predictor importance: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd dataset = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'dataset.csv'</span></span>) dataset.info() dataset.sample(<span class="hljs-number"><span class="hljs-number">5</span></span>) dataset.describe() dataset.corr() dataset.groupby(<span class="hljs-string"><span class="hljs-string">'class'</span></span>).mean()</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt dataset.hist(bins = <span class="hljs-number"><span class="hljs-number">20</span></span>, figsize = (<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>)) plt.show() sns.heatmap(dataset.corr(), square = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.show() sns.pairplot( data = dataset, hue = <span class="hljs-string"><span class="hljs-string">'class'</span></span>, size = <span class="hljs-number"><span class="hljs-number">2</span></span>, palette = <span class="hljs-string"><span class="hljs-string">'seismic'</span></span> ) plt.show()</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> classification_report <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier dataset = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'dataset.csv'</span></span>) X_train, X_test, y_train, y_test = train_test_split( dataset, dataset.pop(<span class="hljs-string"><span class="hljs-string">'class'</span></span>), test_size = <span class="hljs-number"><span class="hljs-number">.5</span></span> ) model = RandomForestClassifier( n_estimators = <span class="hljs-number"><span class="hljs-number">1000</span></span>, max_depth = <span class="hljs-number"><span class="hljs-number">100</span></span>, max_features = <span class="hljs-number"><span class="hljs-number">2</span></span> ).fit(X_train, y_train) print(classification_report(y_test, model.predict(X_test))) pd.Series(model.feature_importances_, index = X_train.columns)</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> catboost <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CatBoostClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KFold <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> confusion_matrix, f1_score kf = KFold(n_splits = <span class="hljs-number"><span class="hljs-number">3</span></span>, shuffle = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) dataset = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'dataset.csv'</span></span>) y = dataset.pop(<span class="hljs-string"><span class="hljs-string">'class'</span></span>).values X = dataset.values columns = dataset.columns <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> train_index, test_index <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> kf.split(X): X_train, X_test = X[train_index], X[test_index] y_train, y_test = y[train_index], y[test_index] model = CatBoostClassifier( calc_feature_importance = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ).fit(X_train, y_train) y_pred = model.predict(X_test) print(confusion_matrix(y_test, y_pred)) print(f1_score(y_test, y_pred)) print(list(zip(columns, model.feature_importances_)))</code> </pre> </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/343700/">https://habr.com/ru/post/343700/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../343688/index.html">Implementation of the simplest investment strategy based on API MOEX (Moscow Exchange)</a></li>
<li><a href="../343690/index.html">How to get on the road to OS development</a></li>
<li><a href="../343692/index.html">Open the CrackMe winter contest: break-rover</a></li>
<li><a href="../343694/index.html">Arduino and segment LCD indicator</a></li>
<li><a href="../343696/index.html">Latent parasites</a></li>
<li><a href="../343702/index.html">tldr - alternative man with self-titled name</a></li>
<li><a href="../343704/index.html">Learning a computer to write like Tolstoy, Volume I</a></li>
<li><a href="../343706/index.html">I created an application that makes learning algorithms and data structures much more interesting.</a></li>
<li><a href="../343708/index.html">Code Textures</a></li>
<li><a href="../343714/index.html">Local automation of builds (Crashlytics + Slack + FastLane)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>