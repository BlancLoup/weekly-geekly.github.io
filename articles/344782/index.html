<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The study of eye movements: eytreking without a video camera and other solutions</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Is it possible to collect data on the movements of the eyes of all visitors to the planetarium, without having at the disposal of special equipment? H...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The study of eye movements: eytreking without a video camera and other solutions</h1><div class="post__text post__text-html js-mediator-article">  Is it possible to collect data on the movements of the eyes of all visitors to the planetarium, without having at the disposal of special equipment?  How to study visual attention during the active actions of several people without constructing a complex system with eytrekler-glasses?  How to achieve exceptional accuracy and record eye movements with a frequency of 8000 Hz?  In our article we will try to answer these questions. <br><br><img src="https://habrastorage.org/webt/ct/p7/u-/ctp7u-mdonhnhwihcnk9odreyqs.jpeg" alt="image"><br><a name="habracut"></a><br>  Nowadays, well-known eytreker, based on the method of video recording eye movements: these are trackers of famous brands like <a href="http://www.sr-research.com/">EyeLink</a> , <a href="https://www.tobii.com/">Tobii</a> , as well as various hand-made solutions and webcam-based solutions (we wrote about this in a previous <a href="https://habrahabr.ru/company/neurodatalab/blog/339424/">article</a> on eytracking) .  However, there are still many interesting and unusual approaches to the study of human visual attention. <br><br><h2>  Thermal IT </h2><br>  In 2016, Wang et al. Published a new eye tracking system based on infrared thermography.  Efron et al., (1989) showed that the edge of the cornea is 0.45 ¬∞ warmer than its center, a similar discovery formed the basis for the development of thermal eytriking. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Wang et al., 2016, in order to validate their system, they simultaneously registered eye movements using the methods of videooculography (Eye Link, 500 Hz) and thermography (60 Hz) in ten subjects.  The median verification error was 1.4 ¬∞ compared with EyeLink, which shows the good potential of this method for its further use. <br>  It is curious that thermography is also successfully used to recognize the emotional state of a person (for example, see Park et al., 2013) and respiratory rate (for example, see Al-Khalidi et al., 2011).  Thus, thermal eytracking is becoming a promising method for obtaining multimodal data. <br><br><h2>  Collective Aytreking </h2><br>  The study of the visual attention of a large number of people at one point in time is a very tempting task.  However, its implementation, at first glance, seems to be a difficult and expensive process (at least, already at the stage of procurement, debugging or the creation of equipment with its subsequent synchronization). <br><br>  Shillcock, Wase (2015) proposed an original method for registering the visual attention of a crowd of people, for the realization of which all they need is a box of pens, a pack of paper and their own stimulus material.  The experiment was successfully replicated by Bielecki et al.  (2017) in the study of the visual attention of visitors to the planetarium using a 16-meter hemispherical screen. <br><br>  The essence of the technique is that the presentation is periodically, for a short period of time, interrupted by a slide with a grid, in each of the cells of which there is a letter or some other symbol.  The task of the subjects - to write the character that they just saw.  Thus, it is possible to obtain heat maps of visual attention of the entire audience as a whole, which makes it possible to analyze its distribution among the participants of the lecture not only depending on its content, but also on the location of the individual participant in the hall. <br><br>  Of course, this technique is not applicable for "field" experiments, when there is no stimulus material in the form of video or images.  However, for the natural conditions of the experiment, there were also some tricky solutions. <br><br><h2>  Registration of eye movements in natural conditions </h2><br>  The study of oculomotor behavior in the most natural, everyday, everyday conditions is the dream of many researchers of visual attention.  If the task of registering eye movements in the case of active actions can be done relatively well by eytreker glasses (for example, Ronaldo is <a href="https://www.youtube.com/watch%3Fv%3D2NcUkvIX6no%26t%3D176s">kicking a ball</a> with glasses-tracker), then this experimental design is not suitable for a qualitative study of oculomotor behavior during social interactions, as eye contact The facial expressions of the entire face are important elements of non-verbal communication.  To date, the available software eytrekerov, which would receive the trajectory of the gaze approximately the same as when using eytrekerov-devices, does not exist (but our team is in the process of developing and testing the first software eytrekera EyeCatcher, able to replace a full-fledged laboratory tracker) . <br><br>  The <a href="https://www.idiap.ch/project/g3e">G3E</a> project focuses on extracting human visual attention data from a video, but its initiators abandoned the idea of ‚Äã‚Äãobtaining trajectories of gaze in the form of changing the coordinates of the pupil position and focused on getting the direction of the gaze in the context of determining whether the subject is looking at the interlocutor or not.  This system was developed based on the algorithms for predicting the position of the gaze depending on the position of the head (Ba, Odobez, 2006) and the gaze appearance model (this model includes coupled images with the position of the eye in orbit and the corresponding direction of gaze) (Mora, Odobez , 2013).  In addition, to improve the functional parameters of the system, data from annotated video were used (Siegfried R., Odobez, 2017). <br><br>  Video annotation has found its application not only as an effective tool for improving the quality of the algorithms, but also as an independent method for studying eye movements. <br><br>  Thus, in a study of visual attention and behavioral strategies during the card game Campos et al., 2015, each of the two players was recorded on cameras.  After that, the video was laid out by two annotators in the ELAN program in three categories: look-at-game, look-at-other and look-elsewhere, the consistency of the annotators was calculated using Cohen's kappa and compared the results with behavior strategies (cooperation, competition and avoidance). games).  It turned out that with the motivation to cooperate, the time spent on viewing the interlocutor's face is significantly more, as well as mutual eye contacts.  When motivated to compete, on the contrary, there are short but frequent views of the interlocutor's face, and the tendency to avoid eye contact is distinguished. <br><br>  Jarik, Kingstone, 2015 in the study of the dynamics of mutual eye contact after the game in terms of cooperation and competition also turned to the video annotation method (in this study, as in the previous one, two annotators participated).  Here, after the cooperative game, the subjects had a shorter duration of eye contact, more often interrupted compared with another group of participants in the experiment. <br><br><h2>  Good old contact methods </h2><br>  In terms of alternatives to the method of videooculography, contact methods should also be mentioned (with them, all of the eytracking began!).  You can write a separate article on the history of eytracking (eerie suckers attached to the eyeball, or, say, a description of mechanical recorders the size of an entire table, require detailed text with explanations), so we‚Äôll only stop at the current stage of development of this group of methods.  Among the contact methods of eye movement registration that are actively used today, it is necessary to single out electromagnetic eytrekery and the EOG method. <br><br>  A prime example of electromagnetic trackers are Primelec's Swiss trackers, which can record eye movements with extremely high accuracy - 0.0002 ¬∞ and a sampling frequency of 8000 Hz.  The principle of their work is based on the induction of electric current caused by the movement of the metal circuit in a magnetic field.  The movable element is a ring with two internally arranged inductance circuits, which is put on the subject's eyes like a contact lens (as eyewitnesses report, the installation procedure of this magic ‚Äúlens‚Äù is not pleasant).  With the help of such devices, it turns out to study various features of micro-movements of the eyes, including their changes in astronauts in weightlessness. <br><br>  Electrooculogram (EOG) is a method for recording electrical activity that occurs when an eye moves.  Since the cornea of ‚Äã‚Äãthe eye has a positive charge on the retina, this creates a constant (root-retinal) potential.  When the position of the eye changes, this potential is corrected.  EOG is recorded by electrodes, which are installed near the nasal and temporal angle of the palpebral fissure (for registration of horizontal <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B0%25D0%25BA%25D0%25BA%25D0%25B0%25D0%25B4%25D0%25B0">saccades</a> ), as well as above the eyebrow and under the eye - for registration of vertical saccades.  This method is still widely used in medical practice, sometimes in combination with the <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BB%25D0%25B5%25D0%25BA%25D1%2582%25D1%2580%25D0%25BE%25D1%258D%25D0%25BD%25D1%2586%25D0%25B5%25D1%2584%25D0%25B0%25D0%25BB%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%258F">EEG</a> method. <br><br>  The Neurodata Lab's work group on light tracking and the visual sensory system continues its work. <br><br><div class="spoiler">  <b class="spoiler_title">Literature</b> <div class="spoiler_text"> Al-Khalidi F., Saatchi R., Elphick H., Burke D.  2011. American Journal of Engineering and Applied Sciences 4 (4).  P. 586 - 597. <br>  Ba.SO, Odobez J.-M.  Sitting room meeting.  2006. 3rd Joint Workshop on Multimodal Interaction and Related Machine Learning Algorithms (MLMI). <br>  Bielecki M., Potega vel. Zabik K., Gochna M., Mikulski J. Mass analysis.  2017. ECEM 2017 Program and Abstracts Eds.  Radach R., Deubel H., Vorstius C., Hofmann MJP121. <br>  Campos, J., Alves-Oliveira, P., Paiva A. Looking for a conflict in a dyadic Mixed-Motive Game.  2015. Auton.  Agent.  Multi-Agent.  Syst.  30 (1).  P.112-135. <br>  Efron N., Graeme Y., Brennan NA Ocular surface temperature.  1989. Current eye research 8 (9).  P.901-906. <br>  Funes Mora, KA, Odobez, J.-M.  Person Independent 3D gaze estimation from remote RGBD cameras.  2013. In International Conference on Image Processing.  Ieee. <br>  Park KK, Suk HW, Hwang H., Lee J. mock crime using infrared thermal imaging.  2013. Frontiers in Human Neuroscience 7 (70).  P.1 - 17. <br>  R. Shillcock, Wase C.  2015. ECEM 2015 Program and Abstracts Eds.  Ansorge U., Ditye T., Florack A., Leder HP66. <br>  Siegfried R., Odobez J.-M.  Supervised gaze bias correction for gaze coding in interactions.  COGAIN Symposium Wuppertal, August 21st 2017. <br>  Wang Q., Boccanfuso L., Li B., Ahn AY, Foster CE, Orr MP, Scassellati B., Shic F. Thermographic Eye Tracking.  2016. Conference paper: Proceedings of the Symposium on Eye Tracking Research and Applications. <br>  Okutin OL, Okutina G.Yu.  The main characteristics and possibilities of using Primelec hardware for the study of eye micro-movements (Report on the visit to the department and laboratory of neurology at the University of Zurich Clinic).  2011. Experimental Psychology 4 (3). <br></div></div><br>  <b>Material author:</b> <br>  Maria Konstantinova, Researcher at <a href="http://www.neurodatalab.com/">Neurodata Lab</a> , biologist, physiologist, specialist in visual sensory system, oculography and ocular motorics. </div><p>Source: <a href="https://habr.com/ru/post/344782/">https://habr.com/ru/post/344782/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../344768/index.html">Interface Cheat Sheet</a></li>
<li><a href="../344770/index.html">Fzf Fuzzy search or how to quickly put npm packages and kill processes</a></li>
<li><a href="../344772/index.html">How to get the framework Vue.js from UML diagrams</a></li>
<li><a href="../344774/index.html">Smart IDReader SDK - how to write a Telegram bot in Python to recognize documents in 5 minutes</a></li>
<li><a href="../344780/index.html">Live Rup #RuPostgres: questions and answers with Avito experts. Live decoding</a></li>
<li><a href="../344784/index.html">How I became a tester. Spoiler: not immediately</a></li>
<li><a href="../344786/index.html">Do IT-recruiters dream of round sewers?</a></li>
<li><a href="../344788/index.html">Issue # 4: IT training - current issues and challenges from leading companies</a></li>
<li><a href="../344790/index.html">Non dull API</a></li>
<li><a href="../344794/index.html">WebRTC: how two browsers agree on voice and video calls</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>