<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Mass media robots</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At the beginning of 2006, media mogul Rupert Murdoch warned that publications that by 2010 will not have on the staff of robots editors are doomed to ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Mass media robots</h1><div class="post__text post__text-html js-mediator-article"> <b>At the beginning of 2006, media mogul Rupert Murdoch warned that publications that by 2010 will not have on the staff of robots editors are doomed to failure.</b>  <b>However, today there are media outlets that not only have robot editors, but also do not have human editors.</b>  <b>We are talking about special computer robots that search for information, structure it and publish it.</b> <br><br>  <b>Click and copy</b> <br>  In the mid-90s, a curious legal process took place in New York.  The American publisher, Oleg Pogrebnoy, established a good business - he produced the ‚ÄúCourier‚Äù newspaper for Russian emigrants, which consisted entirely of reprinted materials of the Russian media.  Of course, he did not pay anything for a reprint, hoping that the affected publications (Moskovsky Komsomolets, AiF, KP, Moscow News, Megapolis Express, etc.) would not search for the truth overseas.  Those, however, eventually filed a suit in the court of the city of New York.  The court awarded them compensation in the amount of $ 500 thousand. <br><br>  Oleg Pogrebnoy launched his enterprise at the wrong time.  A decade earlier, he would not be threatened.  A decade later - as well, but on condition that he would transfer his business to the Internet. <br><a name="habracut"></a><br>  The Internet has generated not only the media of a new formation, but also a large-scale phenomenon called ‚Äúcopy-pasting‚Äù.  The process of stealing information from a newspaper or magazine has come down to two simple and, most importantly, free operations.  First, press Ctrl-C on the computer keyboard and copy the information (in English - Copy), then press Ctrl-V and paste the information (in English - Paste) to another location.  Copy and Paste - this is copy-pasteing. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It was the distribution of copy-pasting that led to the emergence of robotic media.  When the cross-stealing of information becomes widespread, it seems that there can be no effective legal measures to curb it.  Technical measures are also not effective.  After all, the adversary can give a technical answer, and then the cost of such a struggle will exceed the possible benefits of eliminating copy-pasting. <br><br>  However, the owners of electronic media quickly realized that it was more profitable not to fight copy-pasting, but to take it under control and wrap it to their advantage.  The point is simple: if you allow copying your materials officially, putting in place an unimportant condition to indicate the source of information, this will not only work as an advertisement, but, more importantly, will increase the credibility of the primary source media on Internet search engines - it will be on the first pages of search queries . <br><br>  As a result, the mechanism of automatic transmission of media materials to other sites, the so-called RSS (Really Simple Syndication), was born.  RSS maximally cheapened the copy-and-pasteing process, eliminating any manual labor: it was enough to perform a one-time setup, and the materials from someone else's site automatically appeared on yours. <br><br>  There were "news aggregators" - online media, which are automatically pulled materials borrowed from various sources.  According to Nikolai Macievsky, head of the online marketing department at Parallels, the best mechanism for tracking information flow in runet ‚Äî certain topics or keywords in the news ‚Äî is currently Yandex.News. <br><br>  However, the emergence of RSS has had negative consequences, having played into the hands of moneymakers - this is the name of a huge and as yet little studied group of small network entrepreneurs who cling to any business that can bring at least some income.  Basically, these are young people - students and even high school students who want to earn some extra money on the Internet and show the wonders of ingenuity in this field. <br><br>  Moneymakers almost instantly realized that RSS provides a good earning opportunity without much effort, and the Internet began to produce thousands of news sites, which in fact served only as a place for advertising and paid links.  Having spent some energy on the promotion of such a site, it was possible to get from it up to several hundred dollars a month.  Of course, the promotion was not carried out by the most correct methods - mainly due to search spam (slipping search engines of useless texts and links, stuffed with keywords).  As a result, useful information began to sink in streams of information garbage.  However, gradually the search engines somehow managed to cope with this scourge, and the number of ‚Äúfalse‚Äù RSS-media has significantly decreased. <br><br>  <b>Creative factor</b> <br>  According to some experts, it makes no sense to talk about any noticeable progress in the field of RSS-media, the processes have been going on for many years.  ‚ÄúIt seems to me,‚Äù says Igor Ashmanov, head of the Ashmanov and Partners company, ‚Äúno revolution in this area is currently taking place.  All technologies have already been created several years ago.  Press clipping using automatic search and filtering news applied for several years.  Yandex.News, Novoteka, and other news aggregators, which allow you to create a personal account and subscribe to news on the desired subject, have been around for five years.  The mentioned moneymakers, doorwayers, optimizers have also been generating pseudo-most-numbered sites for several years now, and for this they don‚Äôt need any roCMS, since the industry has long had the means of automatically synthesizing texts on a given topic.  In general, the emergence of another (against dozens of already existing) technologies for collecting RSS feeds and filtering them by keyword is not a sensation. ‚Äù <br><br>  One way or another, RSS aggregators can be considered the first generation of roboSMI.  They performed purely technical work: they took material from one place indicated to them and transferred it to another.  Information, say, from the blogosphere so not collected. <br><br>  Publishing robots of the second generation did not come from the publishing industry, as one might expect, but from related business, which, depending on the market, is sometimes called ‚Äúanalytics‚Äù, and sometimes - ‚Äúindustrial intelligence‚Äù.  One of the tasks that firms of this profile have always performed is monitoring the media according to certain criteria.  The Internet, firstly, made it possible to automate this process, and secondly, it allowed including in the monitoring blogs and forums that contain valuable information, which is often absent in traditional media. <br><br>  ‚ÄúOur company has been engaged in automated analysis of traditional, paper media for quite a long time,‚Äù recalls the general director of PresScan, Nikolai Dokuchaev. ‚ÄúAnd we initially sought to be made not by flesh and blood analysts, but by robots and programs.  Intrigued by the words of Murdoch about the possible failure of publications, which by 2010 will not have on the staff of robot editors, we began to experiment with the selection of data and very quickly realized that this is a very promising direction.  In the end, we created the site 1001tema.ru, where thematic news streams are collected, collected by the robots themselves.  In the open access only a small part of the material, but subscribers have access to a very rich information base. ‚Äù <br><br>  A typical problem solved in the framework of industrial intelligence is monitoring of blogs and forums.  So you can, for example, to identify at the initial stage of preparation unfriendly towards the company shares or in the shortest possible time to get an idea of ‚Äã‚Äãthe consumer response to a new product.  Of course, a robot that performs such tasks should be reasonable enough to, at a minimum, independently determine the subject and the novelty of the message or track the dynamics of the development of a new topic. <br><br>  According to Ilya Soloviev, Executive Director of the Present Agency, the key advantage of the RoSMI is the ability to quickly provide an accurate selection of thematic information.  Including, by studying the blogosphere, forums, and Web 2.0 resources, to give an objective picture of public opinion on a particular issue. <br><br>  Gradually, analytical firms (from Russian firms owning technologies for analyzing and structuring information flows, in addition to PresScan, we can mention Flexum.ru, Avicom.ru, Quintura.com; from foreign systems Ontos.com became most famous) realized that the information structures they created - This is almost a finished product, suitable for the role of the media, and began to offer it to the market.  The product immediately fell in love with online shopping, travel agencies - all those who were desirable for some reason or other to have on their site a news feed or a thematic selection of articles, but whose plans were not to start their own editors for this purpose.  Examples of sites with robotic news feeds - exotik.ru, digital-expert.ru. <br><br>  Traditional online media also use robotic news feeds, but not only do not advertise it, but also carefully hide it.  According to suppliers of robotic information, online media prefer to buy information not in its pure form, but as a kind of semi-finished product for further processing by editors. <br><br>  According to Nikolai Dokuchaev, a robot can determine the subject of information, extract everything new from the stream, but are hardly able to assess the quality of the material and understand how interesting it is to the reader.  The robot can perform 90-95% of all preliminary work on filling an online newspaper with relevant content.  But to make the final touch - to decide whether to put the material into the work, and on which page to put it - on the first or deeper, only a person can. <br><br>  However, the wide distribution of fully robotized media working without any human participation is not far off.  While such sites are aimed at very narrow niches, they solve highly specialized information tasks.  For example, in connection with the events in South Ossetia, the site-robot Tskhinval.SU opened, which tracked the appearance in the Live Journal of messages on the topic of the conflict and immediately promptly transmitted them to the central tape.  And since many eyewitnesses and participants of the events wrote hot on the heels of the Live Journal, Tskhinval.SU sometimes gave new information several hours earlier than news agencies.  In addition, some objectivity of the picture was achieved in this way, since it was covered from the point of view of all parties to the conflict. <br><br>  Nevertheless, according to Kirill Vishnepolsky, editor-in-chief of Russian Newsweek magazine, robotization will mainly affect the news media: ‚ÄúAt the moment we have three almost non-overlapping markets: informational journalism (this is primarily news agencies) supplying the latest news to the market. ;  journalism of opinions and assessments is the daily and weekly social and political press, as well as entertainment media - this is television (well, the glossy press, if it can be classified as media at all).  The robots do not threaten the last two markets in any way - these media sell their stars, analysts, commentators to the viewer, they cannot be replaced with robots.  I want to hear the assessments of the Georgian crisis from specific Maxim Sokolov or Mikhail Fishman, and not ‚Äúwhite noise‚Äù collected by blogs on robots. ‚Äù <br><br>  <b>Camo ridge</b> <br>  Now RoboSMI is already established in the field of information supply, but if we talk about the traditional media market, the robots have just started to enter it, and not even everyone has realized what is happening.  Robots have almost taken bread from journalists in related areas.  If earlier the owners of portals and online stores hired journalists (at least as freelancers) to prepare thematic information tapes for sites, now almost all such tapes are made automatically - either through the RSS mechanism, or with the help of next-generation robots.  Even if a subscription to such a newsletter costs several hundred y.  e. per month, it is cheaper than keeping journalists and editors.  With a comparable end result. <br><br>  Difficult times are beginning for the employees of traditional inernet-media engaged in the selection and sorting of information for news feeds.  For them, robots are not helpers, but competitors ‚Äî they do this job just as well or slightly worse than a human, but they are much cheaper, they don‚Äôt get sick and they don‚Äôt need a social package. <br><br>  It seems that soon all types of business, one way or another connected with the selection and delivery of information, will become the lot of robots.  So, according to Cyril Vishnepolsky, robots can crush the market of PR-consulting.  Many PR agencies earn by preparing press clippings for customers - collections of publications on a given topic or on a specific object.  This piece of bread robots able to take away from PR people easily. <br><br>  There are already quite a lot of technically savvy journalists who, although they write articles on their own, but all the rough work - collecting baseline data, searching for experts, compiling statistical information - is entrusted to robots.  An example of a robot that is designed to serve this journalistic stratum is the service flexum.ru. <br><br>  Sergey Leonov, the deputy editor-in-chief of Computerra magazine, believes that journalism, like many other types of human activity, should be considered both as creativity and as a craft.  There is no clear distinction between these categories, but in the case of a rocosMI, it is still clearly visible.  If attempts at introducing any kind of automation into a creative process are perceived as hostile, then journalism is a craft, where the main thing is objectivity and efficiency, relegates personal evaluations to the background, and therefore relates to robotic data collection and analysis more loyally. <br><br>  Another sector of the market, which was actually created by robots, can be called the ‚Äúnews agency news agency‚Äù.  Blogs have a lot of interesting information, but it is lost in a huge number of small informational streams.  Of course, sooner or later most of the interesting topics from the blogosphere come to the surface, and the relevant facts become widely known.  But the media in this case turns out to be in the tail: writing that everyone already knows is a thankless job. <br><br>  Andrei Kalinin, Searchum Technologies project manager Flexum.ru, sees robots as a tool to solve this problem.  If a professional journalist is painfully looking for a way to his reader, he observes, the blogger often writes for his own pleasure, without increasing the audience by special means.  Meanwhile, the information value of blog posts can be no less than that of news agencies.  Thus, there is a need for a new link between the producers of information and its consumers.  Means for automatic collection of news, their classification and filtering, are just such a link. <br><br>  Nevertheless, Boris Sorkin, managing director of the Regnum news agency, believes that robots will not be able to discourage the traditional news agencies: ‚ÄúThe robotization of traditional media may change the market greatly, but I do not think that this seriously affects the work of news agencies.‚Äù .  After all, the information with which the robot works does not appear on the Internet by itself.  Its source is precisely news agencies with their correspondent networks.  Traditional reporter work is not going anywhere, its role can only grow.  After all, the fact of receipt of information from the news agency implies that it is based on the qualified work of professional journalists, and this distinguishes it from the same blogosphere.  The thing is that news agencies will simply have another type of information consumer - robots.  Most likely, our credibility will grow as a source of information. ‚Äù <br><br>  The only thing that is now holding back the massive attack of robots on the media market is that the mechanisms for extracting income from the roSMI, or, as it is now fashionable to say, their ‚Äúmonetization‚Äù, have not yet ended.  The main source of revenue for suppliers of robotic content today is a paid subscription to information, while the subscription price is set so that the consumer ‚Äúhiring‚Äù a robot is more profitable than a human: it rarely exceeds five to six hundred y.  e. per month.  At the same time, buyers of news feeds can earn by placing contextual advertising on them, more than they spend on a subscription.  However, the mass distribution of robots can change and certainly will change this alignment. <br><br>  Sergey Leonov believes that, as in any other sphere, the robotization of production has the effect of lowering the price of products.  This means that the cost of advertising may fall, due to which online media mainly exist.  If this happens, then we should probably expect an explosive growth in the number of low-budget information sites.  And not always it will be sites of good quality.  Moneymakers, as usual, use the turned up possibility of easy earnings.  According to various expert estimates, now the share of ‚Äúgarbage‚Äù informational sites that have no informational value and serve only for the placement of sponsored links is 20-30%.  As soon as publishing information with the help of robots becomes available at a price, there will be more than half of such sites.  In this case, the term ‚Äúonline news media‚Äù may acquire a completely different meaning than it has now.  Or even lose it. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">According to Nikolai Dokuchaev, the era of the media is in the stead of the era of the FIC - the means of individual information. </font><font style="vertical-align: inherit;">It is, of course, formed by robots that are trained to collect only what is of interest to a particular person at the moment. </font><font style="vertical-align: inherit;">‚ÄúI personally set up several directions for myself - both for work and for the soul, where our robots find everything interesting to me. </font><font style="vertical-align: inherit;">That is, I have a personal roboSMI, ‚Äùsays Nikolai Dokuchaev. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ANDREI SHIPILOV </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kommersant - Money Magazine No. 34 (689) 01.09.2008 </font></font><br> <a href="http://www.kommersant.ru/doc.aspx%3FDocsID%3D1017422"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Link to the original material</font></font></a> </div><p>Source: <a href="https://habr.com/ru/post/39240/">https://habr.com/ru/post/39240/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../392389/index.html">Lecture Hall Set Up in honor of the Day of Russian Science April 24</a></li>
<li><a href="../39239/index.html">"Antigravitational" micromachine</a></li>
<li><a href="../392391/index.html">Troll paper newspaper</a></li>
<li><a href="../392395/index.html">The extortioner malware ‚ÄúPetya‚Äù encrypts the entire hard disk and requires money</a></li>
<li><a href="../392399/index.html">Espruino: javascript in microcontroller</a></li>
<li><a href="../392401/index.html">Mysterious Planet X could be captured by the Sun from another star system</a></li>
<li><a href="../392403/index.html">About Xiaomi gadgets presented on AliExpress</a></li>
<li><a href="../392405/index.html">Scientists were able to control the speed of a beetle by implanting electrodes into its muscles.</a></li>
<li><a href="../392407/index.html">Microsoft began shipping the HoloLens version for developers and released an emulator</a></li>
<li><a href="../392409/index.html">Node.js broadcasts: Google engineers found vulnerabilities in NPM scripts</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>