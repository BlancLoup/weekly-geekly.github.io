<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Google opens source code for the robots.txt parser</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Today, Google announced a draft of the RFC standard of the Robots Exclusion Protocol (REP) , simultaneously making its parser robots.txt file availabl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Google opens source code for the robots.txt parser</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/b2a/828/47b/b2a82847b0bd01f47a149ba8d3a12d25.png" alt="image"><br><br>  Today, Google announced a <a href="https://webmasters.googleblog.com/2019/07/rep-id.html">draft of the RFC standard of the Robots Exclusion Protocol (REP)</a> , simultaneously making its parser robots.txt file available under the Apache License 2.0 license.  Until today, there was no official standard for Robots Exclusion Protocol (REP) and robots.txt (this was closest to it), which allowed developers and users to interpret it in their own way.  The company's initiative aims to reduce differences between implementations. <br><br>  A draft of the standard can be viewed <a href="https://tools.ietf.org/html/draft-rep-wg-topic">on the IETF website</a> , and the repository is available on Github via <a href="https://github.com/google/robotstxt">https://github.com/google/robotstxt</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The parser is the source code that Google uses as part of its production systems (with the exception of minor edits - such as the cleaned header files used only inside the company) - the robots.txt files are parsed exactly the way Googlebot does (including how he handles unicode characters in patterns).  The parser is written in C ++ and essentially consists of two files - you will need a compiler that is compatible with C ++ 11, although the library code goes back to the 90th, and you will find in it ‚Äúraw‚Äù pointers and <i>strbrk</i> .  In order to collect it, it is recommended to use <a href="https://bazel.build/">Bazel</a> (CMake support is planned in the near future). <br><a name="habracut"></a><br>  The very idea of ‚Äã‚Äãrobots.txt and the standard belongs to Martein Koster, who created it in 1994 - <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">according to legend</a> , the reason for this was the search spider Charles Stross, who "dropped" Koster's server using a DoS attack.  His idea was picked up by others and quickly became the de facto standard for those involved in search engine development.  But those who wanted to parse it sometimes had to do reverse engineering of Googlebot - among them the company Blekko, who wrote his <a href="https://github.com/randomstring/ParseRobotsTXT">own Perl parser</a> for his search engine. <br><br>  The parser has not been without amusing moments: for example, look at <a href="">how much work went into disallow processing</a> . </div><p>Source: <a href="https://habr.com/ru/post/458428/">https://habr.com/ru/post/458428/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../45841/index.html">Congratulations! You found this blog!</a></li>
<li><a href="../458412/index.html">Is blockchain just for PR and HYIP?</a></li>
<li><a href="../458418/index.html">5 browser extensions for working with text in English</a></li>
<li><a href="../458420/index.html">AWS_Ru meetup at Raiffeisenbank</a></li>
<li><a href="../458426/index.html">Map projections: what is xkcd really joking about</a></li>
<li><a href="../458432/index.html">Merge multiple packages into one Python namespace</a></li>
<li><a href="../458434/index.html">Training Cisco 200-125 CCNA v3.0. Day 11. VLAN Basics</a></li>
<li><a href="../458436/index.html">Typical logging errors</a></li>
<li><a href="../45844/index.html">Stages of development of a promotional site</a></li>
<li><a href="../458440/index.html">Weekdays technical support: stories about what happens when you can‚Äôt get to the user</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>