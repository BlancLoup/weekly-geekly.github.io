<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hopfield neural network on fingers</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The article is devoted to the introduction of neural networks and the example of their implementation. The first part gives a small theoretical introd...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hopfield neural network on fingers</h1><div class="post__text post__text-html js-mediator-article"><p>  The article is devoted to the introduction of neural networks and the example of their implementation.  The first part gives a small theoretical introduction to neural networks on the example of the Hopfield neural network.  It is shown how the network is trained and how its dynamics are described.  The second part shows how to implement the algorithms described in the first part using the C ++ language.  The developed program clearly shows the ability of the neural network to clear the key image from noise.  At the end of the article there is a link to the source code of the project. </p><br><a name="habracut"></a><br><h1>  Theoretical description </h1><br><h2>  Introduction </h2><br><p>  To begin with, it is necessary to determine what a neuron is.  In biology, a neuron is a specialized cell that makes up the nervous system.  Biological neuron has the structure shown in Fig.1. </p><br><img src="https://habrastorage.org/files/7dc/b16/466/7dcb16466a4f4384a27498596a508094.jpg"><br><p>  Fig.1 Scheme of the neuron </p><br><p>  A neural network can be entered as a collection of neurons and their interconnections.  Therefore, in order to define an artificial (non-biological) neural network, it is necessary: </p><br><ol><li>  Set the network architecture; </li><li>  Determine the dynamics of individual elements of the network - neurons; </li><li>  Determine the rules by which neurons interact with each other; </li><li>  Describe the learning algorithm, i.e.  formation of relationships to solve the problem. </li></ol><br><p>  The Hopfield network will be used as the neural network architecture.  This model seems to be the most common mathematical model in neuroscience.  This is due to its simplicity and clarity.  The Hopfield network shows how memory can be organized in a network of elements that are not very reliable.  Experimental data show that with an increase in the number of failed neurons to 50%, the probability of a correct answer is extremely close to 100%.  Even a superficial comparison of the neural network (for example, the brain) and the Von Neumann computer shows how strongly these objects differ: for example, the frequency of changes in the states of neurons ("clock frequency") does not exceed 200 Hz, while the frequency of changes in the state of the elements of a modern processor can reach several GHz ( <img src="https://tex.s2cms.ru/svg/10%5E9" alt="10 ^ 9">  Hz). <br>  Formal description of the Hopfield network </p><br><p>  The network consists of N artificial neurons, the axon of each neuron is associated with the dendrites of the rest of the neurons, forming a feedback.  The network architecture is shown in Fig.  2 </p><br><img src="https://habrastorage.org/files/ecf/14b/b8c/ecf14bb8c80a4ccda622b2d51ef6e458.png"><br><p>  Fig.2 Hopfield neural network architecture </p><br><p>  Each neuron can be in one of 2 states: </p><br><p><img align="right" src="https://tex.s2cms.ru/svg/(1)"></p><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%20S(t)%5Cin%5C%7B-1%3B%2B1%5C%7D" alt="S (t) \ in \ {- 1; +1 \}"></div><p></p><br><p>  Where <img src="https://tex.s2cms.ru/svg/S(t)" alt="S (t)">  - the state of the neuron at the time <img src="https://tex.s2cms.ru/svg/t" alt="t">  .  "Excitement" of the neuron corresponds <img src="https://tex.s2cms.ru/svg/%2B1" alt="+1">  , and "braking" <img src="https://tex.s2cms.ru/svg/-1" alt="-one">  .  The discreteness of the states of the neuron reflects the non-linear, threshold nature of its functioning and is known in neurophysiology as the ‚Äúall or nothing‚Äù principle. </p><br><p>  State dynamics over time <img src="https://tex.s2cms.ru/svg/i" alt="i">  -th neuron in the network from <img src="https://tex.s2cms.ru/svg/N" alt="N">  neurons are described by a discrete dynamic system: </p><br><p><img align="right" src="https://tex.s2cms.ru/svg/(2)"></p><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/S_%7Bi%7D(t%2B1)%3Dsign%5B%5Csum%5Climits_%7Bj%3D1%7D%5EN%20J_%7Bi%2Cj%7DS_%7Bi%7D(t)%5D%2C%5Cquad%20i%2Cj%5Cin1%2C..%2CN" alt="S_ {i} (t + 1) = sign [\ sum \ limits_ {j = 1} ^ N J_ {i, j} S_ {i} (t)], \ quad i, j \ in1, .., N"></div><p></p><br><p>  Where <img src="https://tex.s2cms.ru/svg/J_%7Bi%2Cj%7D" alt="J_ {i, j}">  - matrix of weight coefficients describing the interaction of dendrites <img src="https://tex.s2cms.ru/svg/i" alt="i">  2nd neuron with axons <img src="https://tex.s2cms.ru/svg/j" alt="j">  th neuron. </p><br><p>  It is worth noting that <img src="https://tex.s2cms.ru/svg/J_%7Bi%2Ci%7D%3D0%2C%5Cquad%20i%3D1%2C..%2CN" alt="J_ {i, i} = 0, \ quad i = 1, .., N">  and case <img src="https://tex.s2cms.ru/svg/%5Csum%5Climits_%7Bj%3D1%7D%5E%7BN%7DJ_%7Bi%2Cj%7DS_%7Bi%7D(t)%3D0" alt="\ sum \ limits_ {j = 1} ^ {N} J_ {i, j} S_ {i} (t) = 0">  not considered. </p><br><h2>  Training and noise resistance </h2><br><p>  Hopfield network training for weekend images <img src="https://tex.s2cms.ru/svg/%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D" alt="\ zeta _ {\ mu} ^ {in}">  reduced to calculating the values ‚Äã‚Äãof matrix elements <img src="https://tex.s2cms.ru/svg/J_%7Bi%2Cj%7D" alt="J_ {i, j}">  .  Formally, we can describe the learning process in the following way: let it be necessary to train the neural network to recognize <img src="https://tex.s2cms.ru/svg/M" alt="M">  images marked <img src="https://tex.s2cms.ru/svg/%5C%7B%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%2C%5Cmu%3D1%2C..%2CM%5C%7D" alt="\ {\ zeta _ {\ mu} ^ {in}, \ mu = 1, .., M \}">  .  Input image <img src="https://tex.s2cms.ru/svg/%5Coverline%7B%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%7D" alt="\ overline {\ zeta _ {\ mu} ^ {in}}">  represents: <img src="https://tex.s2cms.ru/svg/%5Coverline%7B%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%7D%20%3D%20%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%20%2B%20%5Cacute%7B%5Czeta%7D" alt="\ overline {\ zeta _ {\ mu} ^ {in}} = \ zeta _ {\ mu} ^ {in} + \ acute {\ zeta}">  Where <img src="https://tex.s2cms.ru/svg/%5Cacute%7B%5Czeta%7D" alt="\ acute {\ zeta}">  - noise superimposed on the original image <img src="https://tex.s2cms.ru/svg/%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D" alt="\ zeta _ {\ mu} ^ {in}">  . <br>  In fact, neural network training is the definition of the norm in the image space. <img src="https://tex.s2cms.ru/svg/%7C%7C%20%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%20-%20%5Coverline%7B%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%7D%20%7C%7C" alt="|| \ zeta _ {\ mu} ^ {in} - \ overline {\ zeta _ {\ mu} ^ {in}} ||">  .  Then, clearing the input image from noise can be described as minimizing this expression. </p><br><p>  An important characteristic of the neural network is the ratio of the number of key images <img src="https://tex.s2cms.ru/svg/M" alt="M">  that can be memorized, to the number of neurons in the network <img src="https://tex.s2cms.ru/svg/N" alt="N">  : <img src="https://tex.s2cms.ru/svg/%5Calpha%20%3D%20%5Cfrac%7BM%7D%7BN%7D" alt="\ alpha = \ frac {M} {N}">  .  For the Hopfield network value <img src="https://tex.s2cms.ru/svg/%5Calpha" alt="\ alpha">  not more than 0.14. </p><br><p>  Calculation of a square matrix of size for key images is made according to Hebb's rule: </p><br><p><img align="right" src="https://tex.s2cms.ru/svg/(3)"></p><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/J_%7Bi%2Cj%7D%20%3D%20%7B1%20%5Cover%20N%7D%20%5Ccdot%20%5Csum%5Climits_%7B%5Cmu%3D1%7D%5E%7BM%7D%5Cbig%5B%5Czeta_%7Bi%2C%5Cmu%7D%5E%7Bin%7D%20%5Ccdot%20%5Czeta_%7Bj%2C%5Cmu%7D%5E%7Bin%7D%20%5Cbig%5D%7D" alt="J_ {i, j} = {1 \ over N} \ cdot \ sum \ limits _ {\ mu = 1} ^ {M} \ big [\ zeta_ {i, \ mu} ^ {in} \ cdot \ zeta_ {j , \ mu} ^ {in} \ big]}"></div><p></p><br><p>  Where <img src="https://tex.s2cms.ru/svg/%5Czeta_%7Bj%2C%5Cmu%7D%5E%7Bin%7D" alt="\ zeta_ {j, \ mu} ^ {in}">  means <img src="https://tex.s2cms.ru/svg/j" alt="j">  element of the image <img src="https://tex.s2cms.ru/svg/%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D" alt="\ zeta _ {\ mu} ^ {in}">  . </p><br><p>  It should be noted that due to the commutativity of the multiplication operation, the equality <br><img src="https://tex.s2cms.ru/svg/J_%7Bi%2Cj%7D%3DJ_%7Bj%2Ci%7D" alt="J_ {i, j} = J_ {j, i}"></p><br><p>  The input image that is presented for recognition corresponds to the initial data for the system, which serves as the initial condition for the dynamic system (2): </p><br><p><img align="right" src="https://tex.s2cms.ru/svg/(4)"></p><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/S_%7Bi%7D%3D%5Coverline%7B%5Czeta_%7B%5Cmu%7D%5E%7Bin%7D%7D" alt="S_ {i} = \ overline {\ zeta _ {\ mu} ^ {in}}"></div><p></p><br><p>  Equations (1), (2), (3), (4) are sufficient to determine the Hopfield artificial neural network and you can proceed to its implementation. </p><br><h1>  Hopfield neural network implementation </h1><br><p> The implementation of the Hopfield neural network defined above will be done in C ++.  To simplify the experiments, we add the basic definitions of types that are directly related to the type of neuron and its transfer function in the class <em>simple_neuron</em> , and we define derivatives later. </p><br><p>  The most basic types directly associated with a neuron are: </p><br><ol><li>  type of weight coefficients ( <em>float</em> selected); </li><li>  A type that describes the state of the neuron (an enumerated type is entered with 2 valid values). </li></ol><br><p>  Based on these types, you can enter the remaining basic types: </p><br><ol><li>  The type that describes the state of the network at the time <img src="https://tex.s2cms.ru/svg/t" alt="t">  (standard <em>vector</em> container is selected); </li><li>  A type describing the matrix of weights of neuron connections (the <em>vector</em> container <em>vector is</em> selected). </li></ol><br><div class="spoiler">  <b class="spoiler_title">Listing 1. Defining new types</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">simple_neuron</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> state {LOWER_STATE=<span class="hljs-number"><span class="hljs-number">-1</span></span>, UPPER_STATE=<span class="hljs-number"><span class="hljs-number">1</span></span>}; <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> <span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span>; &lt;&lt;(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> state <span class="hljs-keyword"><span class="hljs-keyword">state_t</span></span>; &lt;&lt;(<span class="hljs-number"><span class="hljs-number">2</span></span>) ... }; <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> simple_neuron <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::<span class="hljs-keyword"><span class="hljs-keyword">state_t</span></span> <span class="hljs-keyword"><span class="hljs-keyword">state_t</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">state_t</span></span>&gt; neurons_line; &lt;&lt;(<span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::<span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span>&gt;&gt; link_coeffs; &lt;&lt;(<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> </div></div><br><p>  Network training, or, calculation of matrix elements <img src="https://tex.s2cms.ru/svg/J_%7Bi%2Cj%7D%3DJ_%7Bj%2Ci%7D" alt="J_ {i, j} = J_ {j, i}">  In accordance with (3), it is produced by the <em>learn_neuro_net</em> function, which accepts a list of training images as input and returns an object of the type <em>link_coeffs_t</em> .  Meanings <img src="https://tex.s2cms.ru/svg/J_%7Bi%2Cj%7D" alt="J_ {i, j}">  calculated for lower triangular elements only.  The values ‚Äã‚Äãof the upper triangular elements are calculated in accordance with (4).  A general view of the <em>learn_neuro_net</em> method <em>is</em> shown in Listing 2. </p><br><div class="spoiler">  <b class="spoiler_title">Listing 2. Neural network training</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">link_coeffs </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">learn_neuro_net</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">list</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;neurons_line&gt; &amp;src_images)</span></span></span><span class="hljs-function"> </span></span>{ link_coeffs result_coeffs; <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> neurons_count = src_images.front().size(); result_coeffs.resize(neurons_count); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; neurons_count; ++i) { result_coeffs[i].resize(neurons_count, <span class="hljs-number"><span class="hljs-number">0</span></span>); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; neurons_count; ++i) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; i; ++j) { <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::<span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span> val = <span class="hljs-number"><span class="hljs-number">0</span></span>; val = <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::accumulate( begin(src_images), end(src_images), <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::<span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span>(<span class="hljs-number"><span class="hljs-number">0.0</span></span>), [i, j] (<span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::<span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span> old_val, <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> neurons_line &amp;image) -&gt; <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::<span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> old_val + (image[i] * image[j]); }); result_coeffs[i][j] = val; result_coeffs[j][i] = val; } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result_coeffs; }</code> </pre> </div></div><br><p>  <em>Neuron</em> states are updated using the <em>neuro_net_system</em> functor.  The argument of the <em>_do</em> functor method is the initial state <img src="https://tex.s2cms.ru/svg/S_%7Bi%7D(0)" alt="S_ {i} (0)">  , which is a recognizable image (in accordance with (5)) - a reference to an object of type <em>neurons_line</em> . </p><br><p>  The functor method modifies the transmitted object of type neurons_line to the state of the neural network at the moment of time <img src="https://tex.s2cms.ru/svg/T" alt="T">  .  The value is not fixed and is determined by the expression: </p><br><p><img align="right" src="https://tex.s2cms.ru/svg/(6)"></p><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/S_%7Bi%7D(T-1)%3DS_%7Bi%7D(T)" alt="S_ {i} (T-1) = S_ {i} (T)"></div><p></p><br><p>  i.e., when the state of each neuron has not changed in 1 ‚Äúcycle‚Äù. </p><br><p>  To calculate (2), 2 STL algorithms are applied: </p><br><ol><li>  <em>std :: inner_product</em> to calculate the sum of the products of weights and neuron states (i.e., calculation (2) for a specific <img src="https://tex.s2cms.ru/svg/i" alt="i">  ); </li><li>  <em>std :: transform</em> to calculate new values ‚Äã‚Äãfor each neuron (i.e., calculate the item above for each possible <img src="https://tex.s2cms.ru/svg/i" alt="i">  ) </li></ol><br><p>  The source code for the <em>neurons_net_system</em> functor and the <em>calculate</em> method for the <em>simple_neuron</em> class <em>is</em> shown in Listing 3. </p><br><div class="spoiler">  <b class="spoiler_title">Listing 3. A functor that implements a neural network</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">simple_neuron</span></span></span><span class="hljs-class"> {</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">template</span></span> &lt;<span class="hljs-keyword"><span class="hljs-keyword">typename</span></span> _Iv, <span class="hljs-keyword"><span class="hljs-keyword">typename</span></span> _Ic&gt; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> state_t </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calculate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(_Iv val_b, _Iv val_e, _Ic coeff_b)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> value = <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::inner_product( val_b, val_e, coeff_b, <span class="hljs-keyword"><span class="hljs-keyword">coeff_t</span></span>(<span class="hljs-number"><span class="hljs-number">0</span></span>) ); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> value &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> ? UPPER_STATE : LOWER_STATE; } }; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">neuro_net_system</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> link_coeffs &amp;_coeffs; neuro_net_system(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> link_coeffs &amp;coeffs): _coeffs(coeffs) {} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">do_step</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(neurons_line&amp; line)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> value_changed = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; <span class="hljs-function"><span class="hljs-function">neurons_line </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">old_values</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(begin(line), end(line))</span></span></span></span>; link_coeffs::const_iterator it_coeffs = begin(_coeffs); <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform( begin(line), end(line), begin(line), [&amp;old_values, &amp;it_coeffs, &amp;value_changed] (<span class="hljs-keyword"><span class="hljs-keyword">state_t</span></span> old_value) -&gt; <span class="hljs-keyword"><span class="hljs-keyword">state_t</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> new_value = <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::calculate( begin(old_values), end(old_values), begin(*it_coeffs++) ); value_changed = (new_value != old_value) || value_changed; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> new_value; }); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> value_changed; } <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> _do(neurons_line&amp; line) { <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> need_continue = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> steps_done = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (need_continue) { need_continue = do_step(line); ++steps_done; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> steps_done; } };</code> </pre> </div></div><br><p>  To output input and output images to the <em>console</em> , a <em>neurons_line_print_descriptor</em> type has been created that stores a link to the image and the formatting format (the width and height of the rectangle in which the image will be written).  For this type, the operator <em>&lt;&lt; is</em> overridden.  The source code for the <em>neurons_line_print_descriptor</em> type and the output operator is shown in Listing 4. </p><br><div class="spoiler">  <b class="spoiler_title">Listing 4. Outputting the state of a neural network to a stream</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">neurons_line_print_descriptor</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> neurons_line &amp;_line; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> _width; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> _height; neurons_line_print_descriptor ( <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> neurons_line &amp;line, <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> width, <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> height ): _line(line), _width(width), _height(height) {} }; <span class="hljs-keyword"><span class="hljs-keyword">template</span></span> &lt;<span class="hljs-keyword"><span class="hljs-keyword">typename</span></span> Ch, <span class="hljs-keyword"><span class="hljs-keyword">typename</span></span> Tr&gt; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::basic_ostream&lt;Ch, Tr&gt;&amp; <span class="hljs-keyword"><span class="hljs-keyword">operator</span></span> &lt;&lt; (<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::basic_ostream&lt;Ch, Tr&gt;&amp;stm, <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> neurons_line_print_descriptor &amp;line) { neurons_line::const_iterator it = begin(line._line), it_end = end(line._line); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; line._height; ++i) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; line._width; ++j) { stm &lt;&lt; <span class="hljs-keyword"><span class="hljs-keyword">neuron_t</span></span>::write(*it); ++it; } stm &lt;&lt; <span class="hljs-built_in"><span class="hljs-built_in">endl</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> stm; }</code> </pre> </div></div><br><h1>  Neural network operation example </h1><br><p>  To test the performance of the implementation, the neural network was trained in 2 key images: </p><br><img src="https://habrastorage.org/files/e12/a41/252/e12a4125256e4507b8c22dac3f117a93.png"><br><img src="https://habrastorage.org/files/cde/225/a75/cde225a75a48475397ea56a7bd6df2ff.png"><br><p>  Fig.3 Key images </p><br><p>  At the entrance were distorted images.  The neural network correctly recognized the original images.  Distorted images and recognized images are shown in Fig.4, 5 </p><br><img src="https://habrastorage.org/files/0a6/615/aa9/0a6615aa9ff64e12a8ad60d10d619485.png"><br><img src="https://habrastorage.org/files/c11/db7/473/c11db7473928409cb7c3d7663b68479c.png"><br><p>  Fig.4. Pattern Recognition 1 </p><br><img src="https://habrastorage.org/files/511/fa1/c42/511fa1c4230f445daa312294441e09ad.png"><br><img src="https://habrastorage.org/files/ee5/b4b/9b8/ee5b4b9b8fcf4469856a8ba7f42303c1.png"><br><p>  Fig.5 Pattern Recognition 2 </p><br><p>  The program is launched from the command line with the following line: AppName WIDTH HEIGHT SOURCE_FILE [LEARNE_FILE_N], where: </p><br><pre>  AppNaame - the name of the executable file;
 WIDTH, HEIGHT - the width and height of the rectangle into which the output and key images will fit;
 SOURCE_FILE - source file with the initial image;
 [LEARNE_FILE_N] - one or more files with key images (separated by spaces).
</pre><br><p>  The source code is posted on GitHub -&gt; <a href="https://github.com/RainM/hopfield_neuro_net">https://github.com/RainM/hopfield_neuro_net</a> </p><br><p>  The CMake project is in the repository, from which you can generate a Visual Studio project (VS2015 compiles the project successfully) or regular Unix Makefiles. </p><br><p>  References </p><br><ol><li>  G.G.  Malinetsky  Mathematical foundations of synergy.  Moscow, URSS, 2009. </li><li>  The article "Neuronnetwork_Hopfilda" on Wikipedia. </li></ol></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/301406/">https://habr.com/ru/post/301406/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../301394/index.html">How not to create a product for people who do not exist</a></li>
<li><a href="../301396/index.html">Translation of excerpts from Robert Heinlein‚Äôs book, Take Your Government Back - part 12</a></li>
<li><a href="../301398/index.html">Python: building a distributed system with PySyncObj</a></li>
<li><a href="../301402/index.html">The digest of interesting events from the world of Java, and around it # 2 (05/09/2016 - 05.22.2016)</a></li>
<li><a href="../301404/index.html">All you need to know about DevCon 2016</a></li>
<li><a href="../301408/index.html">The digest of fresh materials from the world of frontend for the last week ‚Ññ212 (May 16 - 22, 2016)</a></li>
<li><a href="../301416/index.html">FlexboxLayout - part 2</a></li>
<li><a href="../301418/index.html">Creating a VoIP Provider Template in 3CX Phone System</a></li>
<li><a href="../301420/index.html">Office 365 updates</a></li>
<li><a href="../301422/index.html">IPSec VPN for OS X and iOS. Without pain</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>