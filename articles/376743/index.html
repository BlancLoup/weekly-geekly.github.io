<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>"Out of the body" for a few days with the Oculus Rift</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Brief historical background 
 A little more than a hundred years ago, an American psychologist, George Stratton, pondered the question: how rigid is t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>"Out of the body" for a few days with the Oculus Rift</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/bb1/e0a/571/bb1e0a571d95432cba43d63f716415dc.jpg"><br><br><h4>  Brief historical background </h4><br>  A little more than a hundred years ago, an American psychologist, George Stratton, pondered the question: how rigid is the algorithm of human vision in the brain, namely, how attached is the brain to the orientation of an image falling on the retina (as we know, the image gets upside down on the retina)?  As a result of his curiosity, he built an optical device with mirrors that was put on his head, which turned the image upside down (sometimes called an "invertoscope"). <br><br>  On the seventh day of constantly wearing the device, Stratton adapted to the new vision of the world, and the picture began to seem completely natural.  When he removed the device, at first the world seemed strange to him, however, later the scientist's eyes returned to normal. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  My idea </h4><br>  Having received the first Development Kit of Oculus Rift points, I thought: what if you make a similar experiment, only distort the reality of a person even more? <br>  (careful traffic) <br><a name="habracut"></a><br>  The idea was to hang two webcams on the wall (the distance between them corresponds to the distance between the eyes), and broadcast the picture from them to Oculus Rift glasses in real time.  The cameras should hang statically in the same place and see the picture with the greater part of the room and, accordingly, people in it. <br><br>  According to the plan, I had to stay in glasses, seeing myself all the time from the outside, for many days, ideally, long enough for the brain to adapt. <br><br>  The key difference between this idea and the Stratton experiment is that in my case there is a kind of ‚Äúexit from the body‚Äù.  In Stratton's experiment, when a person turns his head, the picture follows his head in the same direction.  In my case, the picture is static, and when I turn my head, I just see the person in the room turning his head. <br><br>  Of course, during the whole time I have to be either in glasses or with my eyes closed.  So that the brain always sees the world in the form to which it needs to get used. <br><br>  Of course, I was primarily interested in the question: will the brain get used to the world in the style of the 3rd person view?  And if I get used to it, will I not only see, but also represent the surrounding reality from a third person? <br><br><h4>  Implementation on the knee </h4><br>  The assembled system consisted of two cameras, a laptop, a Chinese 5V by 25 W source, an HDMI splitter (for outputting a picture for two Oculus Rift glasses), two Oculus Rift, and a pile of wires. <br><br>  As cameras, I used two modified Logitech C310 with lenses from Genius WideCam F100 cameras (to increase the viewing angle).  Here I followed <a href="http://willsteptoe.com/post/66968953089/ar-rift-part-1">the path of William Steptoe</a> , who used two cameras for augmented reality. <br><img src="https://habrastorage.org/files/943/bb7/9b7/943bb79b78a1467d96eeaab950f0f3ff.jpg"><br><br>  Cameras were connected to a laptop with Windows.  As a software, I used a combination of Stereoscopic Multiplexer + Stereoscopic player.  I‚Äôll say right away that unfortunately, as a result there was a rather large delay (by eye - 300 ms).  In addition, screenshots were periodically made from the screen, and video from the laptop‚Äôs own webcam was written all the time. <br><br>  The signal from the screen went via HDMI to the Chinese no-name HDMI splitter, and from there along two wires to two Oculus Rift points.  From the separator went two long HDMI wires to the docking stations of virtual reality glasses.  The docking station itself is in the pants pocket.  I used thin and flexible Rosewill RCHD-12007 as HDMI wires. <br><br>  Two points were connected to each glasses with an electrical tape: a thin HDMI wire and power for virtual reality glasses (in order for the glasses to start, 5 V must be fed to the power input and to the USB port).  The HDMI splitter and the Chinese 5 V power supply, from which the wires go to the two Oculus Rift, are qualitatively tied to the table with an electrical tape so as not to fall when pulled over the wires. <br><br>  The photo shows a 5 V source that supplies virtual reality glasses, an HDMI splitter and long wires leading to the docking stations of the glasses (the docking station is stored in a clothing pocket).  The photo was taken substantially after the experiment. <br><img src="https://habrastorage.org/files/0e7/036/e2e/0e7036e2e84449dca970dcc0f822f94c.jpg"><br><br>  On the computer, I set up voice reading of mail and personal messages, on a smartphone, the mode with the pronunciation of text on the screen turned on, in addition, the voice control of the phone helped. <br><br><h4>  Experiment </h4><br>  I carried out the experiment from May 1 to May 4, 2014, i.e.  just four days.  The girl who wished to participate, lasted less for a day. <br><br>  The stereoscopic pictures in the article show real images that I saw through virtual reality glasses. <br><br><img src="https://habrastorage.org/files/9e1/887/80e/9e188780ef224c6abd31e3ca0ba78512.jpg"><br><br>  I must say at once that a significant change in perception did not happen (probably, it lasted a little time).  But still, I will describe the subjective sensations. <br><br><ol><li>  Dizzy, especially in the first two days.  I predicted this in advance, and bought pills for motion sickness.  But it turned out that they do not have one hundred percent effect. </li><li>  There were significant problems with orientation in space and body management.  That is, in order to go in the right direction, there is some conscious process with feedback (there-not here, turn-here-another turn).  Similarly, in order to take any object with his hands.  Such actions took a lot of time.  On the third and fourth day, it became easier, but probably because the brain just learned how to quickly perform such strange actions. </li><li>  There is no strong feeling that the picture on the screen is you.  Although in general the experience is very unusual and powerful. </li><li>  Trying to represent the surrounding room, I began, in a small percentage of cases, to represent it from the side. </li><li>  I saw ordinary dreams, not from the third person. </li><li>  When I took off my glasses, the whole first day was an unpleasant feeling with every turn of the head (apparently, the brain was used to the fact that the picture should not move).  Feeling slightly reminiscent of motion-blur and alcohol intoxication. </li><li>  In addition, on the first day after removing the glasses, it constantly seemed to me that I see pixels over the surrounding reality.  That is, I saw everything qualitatively and clearly, but it feels as if the pixels are on top of a translucent layer. </li><li>  <s>Sex in the 3rd person I did not really like.</s> </li></ol><br><br>  The experiment became unbearable due to the large delay (about 300 ms by eye) and low resolution (I used the first Oculus Rift development kit with a resolution of 640x800 px in one eye).  Therefore, on the fifth day, I took off the Oculus Rift and left this venture until better times. <br><br><h4>  Future plans </h4><br>  I will wait for the release of virtual reality glasses with a resolution of 4k, I will take the cameras better, I will probably write my software and spend at least 10 days in this world. <br><br><img src="https://habrastorage.org/files/062/dc9/0ba/062dc90ba15d4d3d9e71cd9a9336f68e.gif"></div><p>Source: <a href="https://habr.com/ru/post/376743/">https://habr.com/ru/post/376743/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../376733/index.html">The INION books damaged by the fire will be restored by drying in cryochambers</a></li>
<li><a href="../376735/index.html">During the testing of the solar tower, the Solar Energy Project killed more than a hundred birds.</a></li>
<li><a href="../376737/index.html">Volvo has finished designing an unmanned vehicle</a></li>
<li><a href="../376739/index.html">Windows Defender taught to catch Superfish from the computer</a></li>
<li><a href="../376741/index.html">The most interesting events of astronautics and astronomy for the week</a></li>
<li><a href="../376745/index.html">Telebit - a service for exchanging bitcoins via Telegram</a></li>
<li><a href="../376747/index.html">World Health Organization endorses Fifteen Minute Ebola Test</a></li>
<li><a href="../376749/index.html">How do dinosaurs appear on Mars news?</a></li>
<li><a href="../376751/index.html">The film "Citizen Four" about Snowden took an Oscar</a></li>
<li><a href="../376753/index.html">Microsoft gives 100 GB OneDrive to Dropbox users</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>