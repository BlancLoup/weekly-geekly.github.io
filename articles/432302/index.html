<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Sequence-to-Sequence Part 2 models</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! 

 The second part of the translation, which we posted a couple of weeks ago, in preparation for the start of the second stream of the Data Sci...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Sequence-to-Sequence Part 2 models</h1><div class="post__text post__text-html js-mediator-article"> Hello! <br><br>  The second part of the translation, which we posted a couple of weeks ago, in preparation for the start of the second stream of <a href="https://otus.pw/4SyE/">the Data Scientist</a> course.  There is another interesting material and an open lesson ahead. <br><br>  In the meantime, we went further into the wilds of models. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>Neural Translation Model</b> <br><br>  While the kernel of the model's sequence-to-sequence is created by functions from <code>tensorflow/tensorflow/python/ops/seq2seq.py</code> , there are still a couple of tricks used in our model to translate <code>models/tutorials/rnn/translate/seq2seq_model.py</code> , o which is worth mentioning. <br><br><img src="https://habrastorage.org/webt/3z/s9/fy/3zs9fym7zcpeqweylxlqhknznko.png"><a name="habracut"></a><br><br>  <b>Sampled softmax and projection output</b> <br><br>  As mentioned above, we want to use sampled softmax to work with a large output dictionary.  To decode from it, you have to track the projection of the output.  Both softmax sampled losses and output projections are generated by the following code in <code>seq2seq_model.py</code> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> num_samples &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> num_samples &lt; self.target_vocab_size: w_t = tf.get_variable(<span class="hljs-string"><span class="hljs-string">"proj_w"</span></span>, [self.target_vocab_size, size], dtype=dtype) w = tf.transpose(w_t) b = tf.get_variable(<span class="hljs-string"><span class="hljs-string">"proj_b"</span></span>, [self.target_vocab_size], dtype=dtype) output_projection = (w, b) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sampled_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(labels, inputs)</span></span></span><span class="hljs-function">:</span></span> labels = tf.reshape(labels, [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) <span class="hljs-comment"><span class="hljs-comment"># We need to compute the sampled_softmax_loss using 32bit floats to # avoid numerical instabilities. local_w_t = tf.cast(w_t, tf.float32) local_b = tf.cast(b, tf.float32) local_inputs = tf.cast(inputs, tf.float32) return tf.cast( tf.nn.sampled_softmax_loss( weights=local_w_t, biases=local_b, labels=labels, inputs=local_inputs, num_sampled=num_samples, num_classes=self.target_vocab_size), dtype)</span></span></code> </pre><br>  First, note that we create a sampled softmax only if the number of samples (512 by default) is smaller than the target dictionary size.  For dictionaries smaller than 512, it is better to use standard softmax loss. <br><br>  Then, create a projection of the output.  This is a pair consisting of a matrix of weights and a displacement vector.  When used, the rnn cell returns the shape vectors of the number of training samples to <code>size</code> , rather than the number of training samples on <code>target_vocab_size</code> .  To restore logites, you need to multiply it by the weights matrix and add an offset, which is what happens in lines 124-126 in <code>seq2seq_model.py</code> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> output_projection <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> xrange(len(buckets)): self.outputs[b] = [tf.matmul(output, output_projection[<span class="hljs-number"><span class="hljs-number">0</span></span>]) + output_projection[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ...]</code> </pre> <br>  <b>Bucketing and padding</b> <br><br>  In addition to the softmax sampled, our translation model also uses <i>bucketing</i> , a method that allows you to effectively manage sentences of different lengths.  To begin with, we will explain the problem.  When translating from English to French, we have English sentences of different lengths L1 at the entrance and French sentences of different lengths L2 at the exit.  Since the English sentence is transmitted as <code>encoder_inputs</code> , and the French sentence is output as <code>decoder_inputs</code> (with the prefix of the GO character), you must create a seq2seq model for each pair (L1, L2 + 1) of the lengths of the English and French sentences.  As a result, we get a huge graph consisting of many similar subgraphs.  On the other hand, we can ‚Äúpad‚Äù (pad) each sentence with special PAD symbols.  And then we will need only one seq2seq model for ‚Äúfull‚Äù lengths.  But such a model will be ineffective on short sentences - you will have to encode and decode many useless PAD symbols. <br><br>  As a compromise between creating a graph for each pair of lengths and stuffing up to a single length, we use a certain number of groups (buckets) and stuff each sentence up to the length of the group above.  In <code>translate.py</code> we use the following default groups. <br><br><pre> <code class="python hljs">buckets = [(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>), (<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>), (<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>)]</code> </pre> <br><br>  Thus, if the input comes in an English sentence with 3 tokens, and the corresponding French sentence in the output contains 6 tokens, they will go into the first group and will be packed to length 5 at the input of the encoder and length 10 at the input of the decoder.  And if in the English sentence there are 8 tokens, and in the corresponding French 18, then they will not fall into the group (10, 15) and will be transferred to the group (20, 25), that is, the English sentence will increase to 20 tokens, and the French to 25. <br><br>  Remember that when creating decoder input, we add a special <code>GO</code> character to the input.  This happens in the <code>get_batch()</code> function in <code>seq2seq_model.py</code> , which also turns the English sentence upside down.  Reversal of the input data helped to achieve an improvement in the results of the neural translation model in <a href="">Sutskever et al., 2014 (pdf).</a>  To finally understand, let's imagine that there is a sentence ‚ÄúI go.‚Äù At the input, divided into tokens <code>["I", "go", "."]</code> , And at the output - the sentence "Je vais.", Divided into tokens <code>["Je", "vais", "."]</code> .  They will be added to the group (5, 10), with the input representation of the encoder <code>[PAD PAD "." "go" "I"]</code>  <code>[PAD PAD "." "go" "I"]</code> and input decoder <code>[GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]</code>  <code>[GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]</code> . <br><br>  <b>Run it</b> <br><br>  To train the model described above, you need a large Anglo-French corps.  For training, we will use 10 ^ 9 Franco-English Corps from <a href="http://www.statmt.org/wmt15/translation-task.html">the WMT'15 site</a> , and test news from the same site as a working sample.  Both datasets will be loaded into <code>train_dir</code> when the next command runs. <br><br><pre> <code class="plaintext hljs">python translate.py --data_dir [your_data_directory] --train_dir [checkpoints_directory] --en_vocab_size=40000 --fr_vocab_size=40000</code> </pre> <br>  You will need 18GB of hard disk space and a few hours to prepare the training building.  The body is unpacked, dictionary files are created in <code>data_dir,</code> and then the body is tokenized and converted to integer identifiers.  Pay attention to the parameters responsible for the size of the dictionary.  In the example above, all words outside the 40,000 most frequently used will be converted to a UNK token, which means an unknown word.  Thus, when the dictionary is resized, the binary re-forms the body with the id-token.  After data preparation, training begins. <br><br>  The values ‚Äã‚Äãspecified in the <code>translate</code> are very high by default.  Large models that have been studying for a long time show good results, but this can take too much time or too much GPU memory.  You can set up a smaller model for training, as in the example below. <br><br><pre> <code class="plaintext hljs">python translate.py --data_dir [your_data_directory] --train_dir [checkpoints_directory] --size=256 --num_layers=2 --steps_per_checkpoint=50</code> </pre> <br>  The command above will teach a model with two layers (by default there are 3), each of which has 256 units (by default - 1024), with a checkpoint for every 50 steps (by default - 200).  Experiment with these options to see what size model is appropriate for your graphics processor. <br><br>  During the workout, each step of the <code>steps_per_checkpoin</code> t binary will give you statistics on past steps.  With the default settings (3 layers of size 1024), the first message looks like this: <br><br><pre> <code class="plaintext hljs">global step 200 learning rate 0.5000 step-time 1.39 perplexity 1720.62 eval: bucket 0 perplexity 184.97 eval: bucket 1 perplexity 248.81 eval: bucket 2 perplexity 341.64 eval: bucket 3 perplexity 469.04 global step 400 learning rate 0.5000 step-time 1.38 perplexity 379.89 eval: bucket 0 perplexity 151.32 eval: bucket 1 perplexity 190.36 eval: bucket 2 perplexity 227.46 eval: bucket 3 perplexity 238.66</code> </pre> <br>  Note that each step takes a little less than 1.4 seconds, perplexing the training set and perplexing the working sample in each group.  After about 30 thousand steps, we see how the perplexions of short sentences (groups 0 and 1) become unambiguous.  The training building contains about 22 million sentences, one iteration (one run of training data) takes about 340 thousand steps with the number of training samples in the amount of 64. At this stage, the model can be used to translate English sentences into French using the <code>--decode</code> option. <br><br><pre> <code class="plaintext hljs">python translate.py --decode --data_dir [your_data_directory] --train_dir [checkpoints_directory] Reading model parameters from /tmp/translate.ckpt-340000 &gt; Who is the president of the United States? Qui est le pr√©sident des √âtats-Unis ?</code> </pre> <br>  <b>What's next?</b> <br><br>  The example above shows how to create your own end-to-end English-French translator.  Run it and see how the model works.  Quality is acceptable, but an ideal translation model cannot be obtained with default parameters.  Here are a few things that can be improved. <br><br>  First, we use primitive tokenization, the basic function of <code>basic_tokenizer</code> in <code>data_utils</code> .  A better tokenizer can be found on <a href="http://www.statmt.org/wmt15/translation-task.html">the WMT'15 website</a> .  If you use it and a dictionary of large sizes, you can achieve improved translations. <br><br>  In addition, the default parameters of the translation model are not perfectly configured.  You can try to change the learning rate, attenuation, initialization of the model weights.  You can also replace the standard <code>GradientDescentOptimizer</code> in <code>seq2seq_model.py</code> with something more advanced, for example, <code>AdagradOptimizer</code> .  Try and follow the improvement of the result! <br><br>  Finally, the model presented above can be used not only for translation, but also for any other sequence-to-sequence task.  Even if you want to turn a sequence into a tree, for example, to generate a parse tree, this model can produce state-of-the-art results, as shown in <a href="">Vinyals &amp; Kaiser et al., 2014 (pdf)</a> .  So you can create not only a translator, but also a parser, chat bot or any other program you want.  Experiment! <br><br>  That's all! <br><br>  We are waiting for your comments and questions here or we invite you to ask them to a <a href="https://otus.pw/RQqJn/">teacher</a> in <a href="https://otus.pw/jJPl/">an open lesson</a> . </div><p>Source: <a href="https://habr.com/ru/post/432302/">https://habr.com/ru/post/432302/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../432292/index.html">Variable and parametric fonts - win-win for designers</a></li>
<li><a href="../432294/index.html">Ansible Tower: Workflow Job Templates</a></li>
<li><a href="../432296/index.html">Google keeps you in a personal ‚Äúsearch bubble‚Äù even if you log out.</a></li>
<li><a href="../432298/index.html">Timeweb entered TOP-10 domain registrars in the .RU zone</a></li>
<li><a href="../432300/index.html">Support, service, headache and all-all-all</a></li>
<li><a href="../432304/index.html">A brilliant neuroscientist who may have the key to creating real artificial intelligence.</a></li>
<li><a href="../432306/index.html">Storage Class Memory in the storage system - if you need even faster</a></li>
<li><a href="../432308/index.html">Modular Sci-Fi level on UE4: inspired by Nostromo and Serenity</a></li>
<li><a href="../432310/index.html">Ktor as HTTP client for Android</a></li>
<li><a href="../432312/index.html">Create a Shape Map RF Map in Power BI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>