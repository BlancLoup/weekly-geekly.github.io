<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We copy the human brain: operation "Convolution"</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="What have convolution artificial neural networks (INS) already learned and how are they arranged? 
 1. Preface 


 Such articles are made to begin wit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We copy the human brain: operation "Convolution"</h1><div class="post__text post__text-html js-mediator-article"><p>  What have convolution artificial neural networks (INS) already learned and how are they arranged? </p><br><h2 id="1-predislovie">  1. Preface </h2><br><p>  Such articles are made to begin with an excursion into history in order to describe who invented the first ANNs, how they are arranged and pour on other, useless, for the most part, water.  Boring  Omit it.  Most likely you can imagine, at least figuratively, how the simplest ANNs work.  Let's agree to treat classic neural networks (such as a perceptron), in which there are only neurons and connections, like a black box that has an input and an output, and which can be trained to reproduce the result of a certain function.  The architecture of this box is not important to us, it can be very different for different cases.  The tasks they solve are regression and classification. </p><br><h2 id="2--proryv">  2. Breakthrough </h2><br><p>  What has happened in recent years that caused the rapid development of the INS?  The answer is obvious - this is technical progress and the availability of computing power. </p><br><p>  I will give a simple and very illustrative example: </p><a name="habracut"></a><br><p>  2002: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/586/059/91f/58605991f711b3c926e2163dbdfa76c4.jpg" alt="image"><br><br>  Earth Simulator is one of the fastest computing systems in the world.  It was built in 2002.  Until 2004, this machine remained the most powerful computing device in the world. </p><br><p>  <strong>Cost</strong> : $ 350,000,000. <br>  <strong>Area</strong> : four tennis courts, <br>  <strong>Performance</strong> : 35,600 gigaflops. </p><br><p>  2015: <br><img src="https://habrastorage.org/getpro/habr/post_images/05b/ab4/9e6/05bab49e64806bb5acd60cbf3371a18a.png" alt="image"><br>  NVIDIA Tesla M40 / M4: GPU for Neural Networks </p><br><p>  <strong>Cost</strong> : $ 5000 <br>  <strong>Area</strong> : fits in pocket, <br>  <strong>Performance</strong> : Up to 2.2 Teraflops performance in single-precision operations with NVIDIA GPU Boost </p><br><p>  The result of such a rapid growth of productivity was the general availability of resource-intensive mathematical operations, which made it possible to test the theories that had long been born in practice. </p><br><h2 id="3-operaciya-svertki">  3. Convolution operation. </h2><br><p>  One of the resource-intensive theories in the implementation, or rather the method that requires very large powers, is the convolution operation. </p><br><p>  What is it?  Let's try to sort everything out: </p><br><h3 id="kotiki">  Cats </h3><br><p><img src="https://habrastorage.org/getpro/habr/post_images/e56/393/631/e5639363178b2fa531c2c6d334e7b75e.png" alt="image"><br>  Experimenting on animals, David Hubel and Torsten Wiesel found out that the same image fragments, the simplest forms, activate the same brain areas.  In other words, when the cat sees the circle, then the ‚ÄúA‚Äù zone is activated in it, when the square is, then ‚ÄúB‚Äù.  And this inspired scientists to write a paper in which they presented their ideas on the principles of work of sight, and then they confirmed it with experiments: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/IOHayh06LJ4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  The conclusion was something like this: </p><br><p>  In the brain of animals there is an area of ‚Äã‚Äãneurons that responds to the presence of a particular feature in the image.  Those.  before the image enters the depths of the brain, it passes the so-called feature extractor. </p><br><h3 id="matematika">  Maths </h3><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b5a/330/79a/b5a33079a39c3bdb2c5e90f04fc8ee61.png" alt="image"><br><br>  Graphic editors have long used mathematics to change the style of an image, but as it turned out, the same principles can be applied in the field of pattern recognition. </p><br><p>  If we consider a picture as a two-dimensional array of points, each point is like a set of RGB values, and each value is just an 8-bit number, then we get a completely classical matrix.  Now we will take and invent our own, let's call it Kernel, the matrix, and it will be like this: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/2d5/987/fb6/2d5987fb60c50a9880449d90b988c32a.png" alt="image"></p><br><p>  Let's try to go through all the positions, from the beginning to the end of the image matrix and multiply our Kernel into a plot with the same size, and the results will form the output matrix. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/072/901/48c/07290148c27a50592f3edc0202c74cc5.png" alt="image"><br><br>  Here is what we get: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/6d4/1b4/f4d/6d41b4f4d958568ba7d42e216f6c0373.png" alt="image"></p><br><p>  Looking at the Edge Detection section, we will see that the result is a face, i.e.  we can easily pick up such Kernels, which at the output will define lines and arcs of different directions.  And this is exactly what we need - features of the first level image.  Accordingly, we can assume that by applying the same actions once again, we will get combinations of features of the first level - features of the second level (curves, circles, etc.) and this could be repeated many times if we were not limited in resources. </p><br><p>  Here is an example of Kernel matrix sets: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/491/393/08d/49139308d23ec91316727be04b13629e.png" alt="image"><br><img src="https://habrastorage.org/getpro/habr/post_images/4e0/3ab/331/4e03ab331e60e0d1d2ddc6e9ea75ab3d.png" alt="image"></p><br><p>  And this is how a feature-extractor looks from layer to layer.  On the fifth layer, very complex features are already being formed, for example, eyes, images of animals and other types of objects on which the extractor has been trained. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2a0/e55/29d/2a0e5529dfc5dd422f7788228e625fdf.jpg" alt="image"></p><br><p>  At first, the developers themselves tried to select Kernel, but it soon became clear that it can be obtained by training, and this is much more efficient. </p><br><h3 id="podvodnye-kamni">  Underwater rocks </h3><br><p>  Having understood how the cats' brains work and how to apply the mathematical apparatus, we decided to create our own extractor feature!  But ... having thought how many features we need to extract, how many levels of extraction we need and, having figured that in order to find complex images we have to analyze combinations of features ‚Äúeach with each‚Äù, we realized that we don‚Äôt have enough memory to store all this. </p><br><p>  Mathematicians came to the rescue again and came up with a pooling operation.  Its essence is simple - if in a certain area there is a high-level feature, then others can be thrown away. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/793/c3d/604/793c3d6047af07c535fab6242fe2a091.png" alt="image"></p><br><p>  Such an operation not only helps to save memory, but also eliminates debris and noise in the image. </p><br><p>  In practice, the layers of convolution and merge alternate several times. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/19b/1b1/ccc/19b1b1ccc531a649b14cd4e043343156.png" alt="image"></p><br><h3 id="finalnaya-arhitektura">  Final architecture </h3><br><p>  By applying everything described above, you can get a completely working architecture of a feature extractor, no worse than a cat in the head, moreover, at present, computer vision recognition accuracy in some cases reaches&gt; 98%, and, as scientists have calculated, accuracy human image recognition averages 97%.  The future has come, Skynet is coming! </p><br><p>  Here are examples of several schemes of real feature extractors: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/99c/fa5/1e6/99cfa51e64b611456d65dcf9c8df4448.png" alt="image"><br><img src="https://habrastorage.org/getpro/habr/post_images/ab3/45c/d0b/ab345cd0b69503f831e1edb50d41f77a.png" alt="image"><br><img src="https://habrastorage.org/getpro/habr/post_images/b5a/a73/6bc/b5aa736bc33de84b7dfff79e2f10fcf6.png" alt="image"></p><br><p>  As you can see, at each end there are 2-3 more layers of neurons at the end.  They are not part of the extractor, they are our black box from the preface.  Only here, when recognizing the input of the box, not just the colors of the pixels, as in the simplest networks, are served, but the fact of the presence of a complex feature that the extractor was trained on.  Well, it‚Äôs also easier for you to determine what is in front of you, for example, the face of a person, if you see the nose, eyes, ears, hair, than if you were called separately the color of each pixel? </p><br><p> This video simply demonstrates how feature extractors work: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AgkfIQ4IGaM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2 id="4-kto-vsem-zapravlyaet">  4. Who runs the show? </h2><br><h3 id="1-tensorflowhttpswwwtensorfloworg">  1. <a href="https://www.tensorflow.org/">Tensorflow</a> </h3><br><p>  Free software library for machine learning.  Virtually everything that makes Google‚Äôs services so smart uses this library. </p><br><p>  An example of what Inception-v3 gives (Google's image classifier, built on Tensorflow) and trained on the ImageNet image set: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/168/d35/2f8/168d352f835e338fa7477cb84015532e.jpg" alt="image"></p><br><h3 id="2-ms-cognitive-serviceshttpsazuremicrosoftcomen-usservicescognitive-services-the-microsoft-cognitive-toolkit">  2. <a href="https://azure.microsoft.com/en-us/services/cognitive-services/">MS Cognitive Services</a> (The Microsoft Cognitive Toolkit) </h3><br><p>  Microsoft has gone the other way, it provides ready-made APIs, both for money and for free, for the purpose of familiarization, but limiting the number of requests.  API - very extensive, solve dozens of tasks.  All this can be tried right on their website. </p><br><p>  You can, of course, use MSCT in the same way as TF, even the syntax and the idea are very similar, both describe the stubs column, but why waste time when you can use already trained models? </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/0ef/7dc/12b/0ef7dc12b38a61f60223a55a7f8f314f.png" alt="image"></p><br><h3 id="3-caffe-httpcaffeberkeleyvisionorgcaffe2">  3. <a href="http://caffe.berkeleyvision.org/">Caffe</a> (Caffe2) </h3><br><p>  An open library, a framework on which to build any architecture.  Until recently, was the most popular.  There are many ready-made (trained) free network models on this framework. </p><br><p>  A striking example of the use of Caffe: <br>  Rober Bond, using a network that has been trained in cat recognition, <a href="http://myplace.frontier.com/~r.bond/cats/cats.htm">built an automated propeller for cats</a> from his lawn, which, when he detects a cat in a video, pours water on him. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/083/0e4/d77/0830e4d7774977403603b506b70a87fe.png" alt="image"></p><br><p>  There are many more different libraries popular in their time, wrappers, add-ons: BidMach, Brainstorm, Kaldi, MatConvNet, MaxDNN, Deeplearning4j, Keras, Lasagne (Theano), Leaf, but Tensorflow is considered the leader due to its rapid growth over the past two years . </p><br><h2 id="5-oblasti-primeneniya-vmesto-zaklyucheniya">  5. Scopes (instead of the conclusion) </h2><br><p>  At the end of the article I want to share some vivid examples of the use of convolutional networks: </p><br><table><thead><tr><th>  Application area </th><th>  Comments </th><th>  Links </th></tr></thead><tbody><tr><td>  Handwriting Recognition </td><td>  Accuracy of a person - 97.5% CNN - 99.8% </td><td>  <a href="">Visualization of images of a trained network in TF</a> , <a href="http://scs.ryerson.ca/~aharley/vis/conv/">JS interactive visualization of convolution work</a> , <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> </td></tr><tr><td>  Computer vision </td><td>  CNN recognizes not only simple objects in the photo, but also emotions, actions, and also analyzes video for autopilots (semantic segmentation). </td><td>  <a href="">Emotions</a> , <a href="https://www.youtube.com/watch%3Fv%3DCxanE_W46ts%26feature%3Dyoutu.be">Semantic segmentation</a> , <a href="">Skype Caption bot</a> , <a href="">Google Image search</a> </td></tr><tr><td>  3D reconstruction </td><td>  Creating 3D models for video </td><td>  <a href="https://www.youtube.com/watch%3Fv%3DmaLxp2_JMyk%26feature%3Dyoutu.be">Deep stereo</a> </td></tr><tr><td>  Entertainment </td><td>  Stylization and generation of images </td><td>  <a href="https://github.com/google/deepdream/blob/master/dream.ipynb">Deep dream</a> , <a href="https://github.com/jcjohnson/neural-style">Deep style</a> , <a href="https://github.com/jcjohnson/neural-style">Style</a> <a href="https://www.youtube.com/watch%3Fv%3DKhuj4ASldmU%26feature%3Dyoutu.be">transfer to video</a> , <a href="https://dekennisvannu.nl/site/artikel/Fotogenerator-The-End/9232">Generation of faces</a> , <a href="https://affinelayer.com/pixsrv/">Generation of various objects</a> </td></tr><tr><td>  A photo </td><td>  Improving quality, color </td><td>  <a href="http://people.csail.mit.edu/celiu/FaceHallucination/fh.html">Face Hallucination</a> , <a href="http://tinyclouds.org/colorize/">Colorizing</a> </td></tr><tr><td>  The medicine </td><td></td><td>  <a href="http://www.news-medical.net/news/20170209/Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.aspx">Drug creation</a> </td></tr><tr><td>  Security </td><td>  Detection of abnormal behavior (Convolution + Recurrence) </td><td>  Example <a href="https://www.youtube.com/watch%3Fv%3DhHHmWmJG9Rw%26feature%3Dyoutu.be%26t%3D103">1</a> , <a href="https://www.youtube.com/watch%3Fv%3Du2v4LaGvVSQ%26feature%3Dyoutu.be">2</a> , <a href="https://www.youtube.com/watch%3Fv%3D4PFhDW5l5eU%26feature%3Dyoutu.be">3</a> </td></tr><tr><td>  Games </td><td>  As a result, the network plays steeper than the professional, knocking out a hole and specifically driving the ball there. </td><td>  <a href="https://www.youtube.com/watch%3Fv%3DV1eYniJ0Rnk%26feature%3Dyoutu.be">Atari breakout</a> </td></tr></tbody></table></div><p>Source: <a href="https://habr.com/ru/post/333772/">https://habr.com/ru/post/333772/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../333754/index.html">Critical vulnerability in multityg Parity wallet, hackers withdrew $ 31 million in ethereum (updated)</a></li>
<li><a href="../333756/index.html">How to write on Spring in 2017</a></li>
<li><a href="../333762/index.html">Automatic creation of Liquibase migrations for PostgreSQL</a></li>
<li><a href="../333766/index.html">Fast data recovery. Regeneration butterfly pattern</a></li>
<li><a href="../333768/index.html">Automation IP-network. Part 3 - Monitoring TCP Anomalies</a></li>
<li><a href="../333774/index.html">How to work with UX contractors? Experience messenger "Answer"</a></li>
<li><a href="../333776/index.html">Let the Internet bend under us</a></li>
<li><a href="../333778/index.html">Especially for Habr: interview with Alan Kay</a></li>
<li><a href="../333780/index.html">The birth of Software Tools: how and why did GREP and AWK appear</a></li>
<li><a href="../333782/index.html">Sort by bubble in Qualcomm code</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>