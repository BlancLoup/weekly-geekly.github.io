<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Another article about the recognition of workers without helmets neural networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! My name is Vladimir, I am a student of the 4th course of KubGTU (unfortunately). 


 Some time ago, I came across an article on the developm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Another article about the recognition of workers without helmets neural networks</h1><div class="post__text post__text-html js-mediator-article"><p>  Hi, Habr!  My name is Vladimir, I am a student of the 4th course of KubGTU (unfortunately). </p><br><p>  Some time ago, I came across an <a href="https://habrahabr.ru/company/macroscop/blog/347956/">article</a> on the development of a CV-system for detecting workers without helmets, and decided to share my own experience in this field, obtained during an internship at an industrial company in the summer of 2017.  The theory and practice of OpenCV and TensorFlow in the context of the task of detecting people and helmets - right under the cut. </p><br><img src="https://habrastorage.org/webt/vq/ty/fu/vqtyfudb4tlb97mhcxqpg9ebgz4.jpeg"><br><p>  <em>KDPV, shot in real time from a surveillance camera</em> <a name="habracut"></a></p><br><p>  Given: access to video surveillance cameras of industrial facilities of the employer, 2-4 trainee students (during the development, the number of people involved in the project changed). </p><br><p>  Objective: to develop a prototype system, in real time, detecting employees without helmets.  The choice of technology - at its discretion.  Our choice fell on Python, as a language that allows with the minimum effort to implement the first working prototype, and - at first - OpenCV, as a library of machine vision, about which we were most heard. </p><br><p>  OpenCV is a library that implements mostly classical methods of computer vision, such as cascade classifiers.  The essence of this approach is to create a so-called.  ensemble of weak classifiers, i.e.  such that their ratio of objects correctly classified by them to the total number of positive responses was at least slightly more than 0.5.  One such classifier is not able to give any result, but the union of thousands of such classifiers can give an extremely accurate result. </p><br><img src="https://habrastorage.org/webt/vg/rk/ty/vgrktyopkj93dvxwjjlfey3raze.png"><br><p>  <i>An example of how an ensemble of weak classifiers is capable of performing a fairly accurate classification.</i>  <i><a href="http://cmp.felk.cvut.cz/~sochmj1/adaboost_talk.pdf">A source</a></i> </p><br><p>  Obviously, the task of finding a person without a helmet comes down to the tasks of finding a person as such and ... a helmet!  Or her absence.  Access to the video cameras allowed us to quickly assemble the first dataset from cropped photos of the helmets and the people themselves, both in helmets and without them (they were found quickly enough), and later to increase its volume to 2k + photos. </p><br><img src="https://habrastorage.org/webt/sg/s2/7n/sgs27nqpg9hwgtjr9lpmriqado8.png"><br><p>  <i>Markup images for training</i> </p><br><p>  At this stage, the first unpleasant feature of OpenCV was found - the <a href="https://docs.opencv.org/3.4.1/db/d28/tutorial_cascade_classifier.html">official</a> <a href="https://docs.opencv.org/3.4.1/dc/d88/tutorial_traincascade.html">documentation</a> was scattered and in places simply referred to the book of one of the leading developers of the library.  For many parameters, values ‚Äã‚Äãhad to be chosen experimentally. </p><br><p><img src="https://habrastorage.org/webt/12/3p/w_/123pw_gdmshsnes6ou2mmiyjfwe.png" align="left">  The first launch of a classifier trained on helmets detected them with an accuracy of about 60% in isolated cases of false positives!  We felt that we were on the right track.  The task of detecting people turned out to be much more difficult: unlike helmets, people appeared in the frame from a large number of angles and, in general, demanded from the classifier much more advanced abilities to generalize.  While I was working on refining the classifier trained on helmets, as an alternative, we tested the CV-classical object detection based on the Canny contour extraction algorithm and the counting of moving objects. </p><br><p>  In parallel, we developed a subsystem for processing the data received from the classifier.  The logic of operation is simple: a frame is taken from a surveillance camera and transmitted to the classifier, a check is made whether the number of recognized people and helmets in a frame matches, if a person without a helmet is found, an entry is made in the database with information on the number of recognized objects, and the frame itself is saved for manual analysis.  This solution had one more advantage - the frames saved due to the classifier error allowed to train it on the data with which it could not cope. </p><br><p>  And then a new problem arose: the overwhelming majority of frames were saved due to recognition errors, and not personnel without helmets.  Training on fresh data somewhat improved the recognition result, however helmets were recognized in ~ 75% of cases (with single false positives), and the figures of people overlapping each other in the frame were correctly counted only in a little more than half of the cases.  I convinced the project manager to give me a week to develop a neural network detector. </p><br><p>  One of the features that make working with the NA easy to use - at least compared to classifiers - is the end-to-end approach: in the process of learning the classifier, in addition to the spaced images of helmets / people, background images and images were needed to validate the classifier while the conversion process is controlled by many different non-trivial parameters, not to mention the parameters of the classifier itself!  In the case of working with algorithms for counting moving objects and others, the process becomes even more complex, filters are pre-applied to images, the background is removed, and so on.  End-to-end learning requires the developer to "just" markup dataset and the parameters of the learning model. </p><br><p>  The ML framework <a href="https://www.tensorflow.org/">TensorFlow</a> and the <a href="https://github.com/tensorflow/models">tensorflow / models</a> repository that recently appeared at that time met my requirements - it was fairly well documented, it was possible to quickly write a working prototype (the <a href="">most popular architectures work practically out of the box</a> ), while the functionality is fully suitable for further development if the prototype is successful.  After adapting the existing <a href="https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/object_detection_tutorial.ipynb">tutorial</a> to the existing dataset using 101-layer reznet (the principles of convolutional neural networks have been repeatedly covered in Habr√©, I will only allow myself to refer to the articles <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">[1]</a> , <a href="https://arxiv.org/pdf/1512.03385.pdf">[2]</a> ) trained in COCO dataset (which includes photos of people), I immediately got more than 90% accuracy!  This was a convincing argument to start developing a SNA-based helmet detector. </p><br><img src="https://habrastorage.org/webt/rb/zd/ty/rbzdtyzqt2ptcecqskeypnoa2_a.png"><br><p>  <i>Trained on a third-party dataset SNS easily recognizes people standing nearby, but makes a mistake where it was not expected to recognize it at all :)</i> </p><br><p> During training, TensorFlow models can generate checkpoint files that allow you to compile and test NAs at different stages, which can be useful if something went wrong during the additional training.  The compiled model is an oriented computational graph, the initial vertices of which are the input data (in the case of working with images, the color values ‚Äã‚Äãof each pixel), and the final vertices are the recognition results. </p><br><img src="https://habrastorage.org/webt/h7/cn/4o/h7cn4ocyw08nux_wb-fpblfiwk0.jpeg"><br><p>  In addition to the data about the model itself, the checkpoint may contain metadata about the learning process itself, which can be visualized using <a href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard">Tensorboard</a> . </p><br><img src="https://habrastorage.org/webt/g5/ke/bl/g5kebljoybbdp_lvtij4fbem-ak.png"><br><p>  <i>A cherished schedule for reducing learning errors</i> </p><br><p>  After testing a number of architectures, ResNet-50 was chosen as providing the optimum between speed and recognition quality.  After weighing all the pros and cons, it was decided to leave this trained network as it is, because it already gave an acceptable result, and to train on helmets a simpler Single Shot Detector (SSD) network <a href="https://arxiv.org/pdf/1512.02325.pdf">[3]</a> , which gave less accuracy in recognizing people but provided a satisfactory 90% + when working with helmets.  This seemingly illogical solution was due to the fact that the additional use of SSDs slightly increased the time spent on self recognition, but significantly reduced the time spent on training and testing the network with different parameters and updated data (from several days to 20-30 hours on the GTX 1060 6GB), which means it has increased the development iteration. </p><br><p>  Thus, several conclusions can be made: firstly, modern NA frameworks have a low entry threshold (but, undoubtedly, their effective use requires deep knowledge in machine learning) and are much more convenient and functional in solving image recognition problems;  secondly, students are useful for the rapid development of prototypes and technology testing;) </p><br><p>  I will be glad to answer questions and constructive criticism in the comments. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/354092/">https://habr.com/ru/post/354092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../354080/index.html">No one noticed how MySQL 8.0 came out</a></li>
<li><a href="../354082/index.html">We introduce a system of achievements on the Toaster</a></li>
<li><a href="../354084/index.html">Data Requirements - Should a business analyst care?</a></li>
<li><a href="../354086/index.html">Hall Effect Sensors for a Brushless Motor: Returning Quadrature Encoders</a></li>
<li><a href="../354090/index.html">Overview of the new line of home antivirus Panda Dome</a></li>
<li><a href="../354096/index.html">How to prove the importance of tests for each project participant</a></li>
<li><a href="../354098/index.html">How data sharing affects the quality of recommendations</a></li>
<li><a href="../354104/index.html">React HoC in TypeScript. Typing without pain</a></li>
<li><a href="../354106/index.html">How to get rid of the difficulty in managing a state in React - report on the results of a trip to React Amsterdam</a></li>
<li><a href="../354108/index.html">How to create a neural network with just 30 lines of JavaScript code</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>