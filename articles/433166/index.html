<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Predicting the time to solve a ticket using machine learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Making a ticket in the project management system and tracking tasks, each of us is happy to see the approximate timing of the decision on his request....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Predicting the time to solve a ticket using machine learning</h1><div class="post__text post__text-html js-mediator-article"><p>  Making a ticket in the project management system and tracking tasks, each of us is happy to see the approximate timing of the decision on his request. <br>  When receiving a stream of incoming tickets, the person / team needs to line them up in priority and time order that the solution of each call will take. <br>  All this allows you to more efficiently plan your time for both parties. </p><br><p>  Under the cut, I will talk about how I conducted the analysis and trained the ML models that predict the time of the decision of the tickets issued to our team. </p><a name="habracut"></a><br><p>  I myself work for the SRE position in a team called LAB.  We are flooded with requests from both developers and QA regarding deploying new test environments, updating them to the latest release versions, solving various problems that arise and much more.  These tasks are quite heterogeneous and, which is logical, take a different amount of time to perform.  There is our team for several years already and during this time a good database of references has accumulated.  I decided to analyze this base and, on its basis, using machine learning, create a model that will be engaged in predicting the likely closing time (ticket). </p><br><p>  In our work, we use JIRA, however, the model I present in this article has no reference to a specific product - the necessary information is not a problem to get from any base. </p><br><p>  So let's move from words to deeds. </p><br><h2 id="predvaritelnyy-analiz-dannyh">  Preliminary data analysis </h2><br><p>  We load all necessary and we will display versions of the used packages. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings warnings.simplefilter(<span class="hljs-string"><span class="hljs-string">'ignore'</span></span>) %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> stopwords <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mean_absolute_error, mean_squared_error <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KNeighborsRegressor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LinearRegression <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time, date <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> package <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [pd, np, matplotlib, sklearn, nltk]: print(package.__name__, <span class="hljs-string"><span class="hljs-string">'version:'</span></span>, package.__version__)</code> </pre> </div></div><br><pre> <code class="plaintext hljs">pandas version: 0.23.4 numpy version: 1.15.0 matplotlib version: 2.2.2 sklearn version: 0.19.2 nltk version: 3.3</code> </pre> <br><p>  Load the data from the csv file.  It contains information about tickets closed for the last 1.5 years.  Before writing the data to the file, they were a bit pre-processed.  For example, commas and periods were removed from text fields with descriptions.  However, this is only a preliminary processing and in the future the text will be further cleared. </p><br><p>  Let's see what is in our data set.  A total of 10,783 tickets were included. </p><br><div class="spoiler">  <b class="spoiler_title">Explanation of the fields</b> <div class="spoiler_text"><table><tbody><tr><td width="88">  Created </td><td>  Date and time of the ticket creation </td></tr><tr><td>  Resolved </td><td>  Date and time of closing the ticket </td></tr><tr><td>  Resolution_time </td><td>  The number of minutes elapsed between the creation and closing of the ticket.  It is considered the calendar time, because  the company has offices in different countries, working in different time zones and there is no fixed time for the entire department. </td></tr><tr><td>  Engineer_N </td><td>  ‚ÄúEncoded‚Äù names of engineers (in order not to inadvertently give out any personal or confidential information in the future, the article will contain quite a few ‚Äúcoded‚Äù data, which in fact are simply renamed).  These fields contain the number of tickets in the ‚Äúin progress‚Äù mode at the time of receipt of each of the tickets in the submitted date set.  I will dwell on these fields separately towards the end of the article, since  they deserve extra attention. </td></tr><tr><td>  Assignee </td><td>  The employee who was involved in solving the problem. </td></tr><tr><td>  Issue_type </td><td>  Type of ticket. </td></tr><tr><td>  Environment </td><td>  The name of the test environment for which the ticket was made (it can mean both the specific environment and the location as a whole, for example, a data center). </td></tr><tr><td>  Priority </td><td>  Ticket priority. </td></tr><tr><td>  Worktype </td><td>  Type of work that is expected on this ticket (adding or removing servers, updating the environment, working with monitoring, etc.) </td></tr><tr><td>  Description </td><td>  Description </td></tr><tr><td>  Summary </td><td>  Ticket title. </td></tr><tr><td>  Watchers </td><td>  The number of people who ‚Äúwatch‚Äù the ticket, i.e.  they receive notifications by mail for each of the activities in the ticket. </td></tr><tr><td>  Votes </td><td>  The number of people who "voted" for the ticket, thereby showing its importance and its interest in it. </td></tr><tr><td>  Reporter </td><td>  The person who issued the ticket. </td></tr><tr><td>  Engineer_N_vacation </td><td>  Whether the engineer was on vacation at the time of registration of the ticket. </td></tr></tbody></table><br><pre> <code class="python hljs">df.info()</code> </pre> <br><pre> <code class="plaintext hljs">&lt;class 'pandas.core.frame.DataFrame'&gt; Index: 10783 entries, ENV-36273 to ENV-49164 Data columns (total 37 columns): Created 10783 non-null object Resolved 10783 non-null object Resolution_time 10783 non-null int64 engineer_1 10783 non-null int64 engineer_2 10783 non-null int64 engineer_3 10783 non-null int64 engineer_4 10783 non-null int64 engineer_5 10783 non-null int64 engineer_6 10783 non-null int64 engineer_7 10783 non-null int64 engineer_8 10783 non-null int64 engineer_9 10783 non-null int64 engineer_10 10783 non-null int64 engineer_11 10783 non-null int64 engineer_12 10783 non-null int64 Assignee 10783 non-null object Issue_type 10783 non-null object Environment 10771 non-null object Priority 10783 non-null object Worktype 7273 non-null object Description 10263 non-null object Summary 10783 non-null object Watchers 10783 non-null int64 Votes 10783 non-null int64 Reporter 10783 non-null object engineer_1_vacation 10783 non-null int64 engineer_2_vacation 10783 non-null int64 engineer_3_vacation 10783 non-null int64 engineer_4_vacation 10783 non-null int64 engineer_5_vacation 10783 non-null int64 engineer_6_vacation 10783 non-null int64 engineer_7_vacation 10783 non-null int64 engineer_8_vacation 10783 non-null int64 engineer_9_vacation 10783 non-null int64 engineer_10_vacation 10783 non-null int64 engineer_11_vacation 10783 non-null int64 engineer_12_vacation 10783 non-null int64 dtypes: float64(12), int64(15), object(10) memory usage: 3.1+ MB</code> </pre> </div></div><br><p>  In total, we have 10 "object" fields (i.e. containing a text value) and 27 numeric fields. <br>  First of all, we will immediately look for emissions in our data.  As you can see, there are tickets that have a solution time of millions of minutes.  This is clearly not relevant information, such data will only interfere with the construction of the model.  They got here because the data was collected from JIRA by a query on the Resolved field, not on Created.  Accordingly, those tickets that have been closed in the last 1.5 years have come here, but they could have been opened much earlier.  It is time to get rid of them.  Discard tickets that were created earlier on June 1, 2017.  We will have 9493 tickets left. </p><br><p>  As for the reasons, I think in each project it is easy to find such requests that have been hanging out for quite a long time due to various circumstances and more often close not by solving the problem itself, but after the ‚Äúexpiration of the limitation period‚Äù. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[[<span class="hljs-string"><span class="hljs-string">'Created'</span></span>, <span class="hljs-string"><span class="hljs-string">'Resolved'</span></span>, <span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>]].sort_values(<span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>, ascending=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>).head()</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/gm/ay/ju/gmayjuxuxwxsuljj5xhg8dqrd00.png"><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df = df[df[<span class="hljs-string"><span class="hljs-string">'Created'</span></span>] &gt;= <span class="hljs-string"><span class="hljs-string">'2017-06-01 00:00:00'</span></span>] print(df.shape)</code> </pre> </div></div><br><pre> <code class="plaintext hljs">(9493, 33)</code> </pre> <br><p>  So let's start looking at what's interesting we can find in our data.  To begin with, we will derive the simplest - the most popular environments among our tickets, the most active "reporters" and the like. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df.describe(include=[<span class="hljs-string"><span class="hljs-string">'object'</span></span>])</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/hj/ta/oe/hjtaoeo7rsqv2dcxzvzyiyqkqi4.png"><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'Environment'</span></span>].value_counts().head(<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> </div></div><br><pre> <code class="plaintext hljs">Environment_104 442 ALL 368 Location02 367 Environment_99 342 Location03 342 Environment_31 322 Environment_14 254 Environment_1 232 Environment_87 227 Location01 202 Name: Environment, dtype: int64</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'Reporter'</span></span>].value_counts().head()</code> </pre> </div></div><br><pre> <code class="plaintext hljs">Reporter_16 388 Reporter_97 199 Reporter_04 147 Reporter_110 145 Reporter_133 138 Name: Reporter, dtype: int64</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'Worktype'</span></span>].value_counts()</code> </pre> </div></div><br><pre> <code class="plaintext hljs">Support 2482 Infrastructure 1655 Update environment 1138 Monitoring 388 QA 300 Numbers 110 Create environment 95 Tools 62 Delete environment 24 Name: Worktype, dtype: int64</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'Priority'</span></span>].value_counts().plot(kind=<span class="hljs-string"><span class="hljs-string">'bar'</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">7</span></span>), rot=<span class="hljs-number"><span class="hljs-number">0</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">14</span></span>, title=<span class="hljs-string"><span class="hljs-string">'   '</span></span>);</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/bh/qh/lf/bhqhlfwmdxys3_y1k6qpdom5o4w.png"><br><p>  Well, something we have already learned.  Most often, the priority for tickets is normal, about 2 times less high and even less often critical.  Low priority is very rare, apparently people are afraid to exhibit it, believing that in this case it will hang in the queue for quite a long time and its decision time may be delayed.  Later, when we build the model and analyze its results, we will see that such concerns may be not unreasonable, since low priority does affect the timing of the task and, of course, not in the direction of acceleration. </p><br><p>  From the columns in the most popular environments and the most active reporters, we see Reporter_16 with a large margin, and Environment_104 in the first place in the environment.  Even if you have not yet guessed, I will reveal a small secret - this reporter from the team working on this environment. <br>  Let's look at what the environment most often come critical tickets. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[df[<span class="hljs-string"><span class="hljs-string">'Priority'</span></span>] == <span class="hljs-string"><span class="hljs-string">'Critical'</span></span>][<span class="hljs-string"><span class="hljs-string">'Environment'</span></span>].value_counts().index[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> </div></div><br><pre> <code class="plaintext hljs">'Environment_91'</code> </pre> <br><p>  And now we will display information on how many tickets with other priorities are accounted for from the same ‚Äúcritical‚Äù environment. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df[df[<span class="hljs-string"><span class="hljs-string">'Environment'</span></span>] == df[df[<span class="hljs-string"><span class="hljs-string">'Priority'</span></span>] == <span class="hljs-string"><span class="hljs-string">'Critical'</span></span>][<span class="hljs-string"><span class="hljs-string">'Environment'</span></span>].value_counts().index[<span class="hljs-number"><span class="hljs-number">0</span></span>]][<span class="hljs-string"><span class="hljs-string">'Priority'</span></span>].value_counts()</code> </pre> </div></div><br><pre> <code class="plaintext hljs">High 62 Critical 57 Normal 46 Name: Priority, dtype: int64</code> </pre> <br><p>  Let's look at the runtime of the ticket in the context of priorities.  For example, it is amusing to note that the average execution time of a low priority ticket is more than 70 thousand minutes (almost 1.5 months).  It is also easy to see the dependence of the execution time of a ticket on its priority. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df.groupby([<span class="hljs-string"><span class="hljs-string">'Priority'</span></span>])[<span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>].describe()</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/tc/gs/gc/tcgsgc07_eog0hnm0mcj5i3m790.png"><br><p>  Or here is the median value as a graph.  As you can see, the picture has not changed much, therefore, emissions do not really affect the distribution. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">df.groupby([<span class="hljs-string"><span class="hljs-string">'Priority'</span></span>])[<span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>].median().sort_values().plot(kind=<span class="hljs-string"><span class="hljs-string">'bar'</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">7</span></span>), rot=<span class="hljs-number"><span class="hljs-number">0</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">14</span></span>);</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/ir/zc/go/irzcgo8mkcwkmfeybj2vriormwq.png"><br><p>  Now let's look at the average solution time for each of the engineers, depending on how many tickets the engineer had at that time.  In fact, these charts, to my surprise, do not show any single picture.  For some, the runtime increases as the current tickets increase in work, while for some this dependence is reversed.  For some, the dependence is not traced at all. </p><br><p>  However, looking ahead again, I will say that the presence of this feature in dataset increased the accuracy of the model by more than 2 times and the impact on the execution time is definitely there.  We just do not see it.  And the model sees. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">engineers = [i.replace(<span class="hljs-string"><span class="hljs-string">'_vacation'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> df.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'vacation'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> i] cols = <span class="hljs-number"><span class="hljs-number">2</span></span> rows = int(len(engineers) / cols) fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">24</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(rows): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(cols): df.groupby(engineers[i * cols + j])[<span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>].mean().plot(kind=<span class="hljs-string"><span class="hljs-string">'bar'</span></span>, rot=<span class="hljs-number"><span class="hljs-number">0</span></span>, ax=axes[i, j]).set_xlabel(<span class="hljs-string"><span class="hljs-string">'Engineer_'</span></span> + str(i * cols + j + <span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> cols, rows, fig, axes</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Long picture as a result</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/xn/vb/zk/xnvbzk-0flci0_llfpn6ghuqpts.png"></div></div><br><p>  We will make a small matrix of pairwise interaction of the following features: the time of decision of the ticket, the number of votes and the number of observers.  Bonus diagonally we have the distribution of each feature. </p><br><p>  From the interesting - the dependence of the decrease in the time of decision of the ticket on the growing number of observers is visible.  It is also clear that people use voices not very actively. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">pd.scatter_matrix(df[[<span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>, <span class="hljs-string"><span class="hljs-string">'Watchers'</span></span>, <span class="hljs-string"><span class="hljs-string">'Votes'</span></span>]], figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>), diagonal=<span class="hljs-string"><span class="hljs-string">'hist'</span></span>);</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Picture-result</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/bf/qo/qq/bfqoqq3djaiib4mxn1l5mdsy6ru.png"></div></div><br><p>  So, we conducted a small preliminary analysis of the data, saw the existing dependencies between the target attribute, which is the time of decision of the ticket, and such signs as the number of votes for the ticket, the number of "observers" behind it and its priority.  Moving on. </p><br><h2 id="postroenie-modeli-vystraivaem-priznaki">  Build a model.  We build signs </h2><br><p>  It is time to move on to the construction of the model itself.  But first we need to bring our signs in a clear form for the model.  Those.  decompose categorical features into sparse vectors and get rid of excess.  For example, fields with the time of creation and closing of a ticket will not be needed in the model, as well as the field Assignee, since  we will eventually use this model to predict the runtime of a ticket that has not been assigned to anyone ("zasasaynen"). </p><br><p>  The target feature, as I just mentioned, is the time to solve the problem for us, so we take it as a separate vector and also remove it from the general data set.  In addition, some of our fields turned out to be empty due to the fact that reporters do not always fill in the description field when making a ticket.  In this case, pandas sets their values ‚Äã‚Äãto NaN, we just replace them with an empty string. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">y = df[<span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>] df.drop([<span class="hljs-string"><span class="hljs-string">'Created'</span></span>, <span class="hljs-string"><span class="hljs-string">'Resolved'</span></span>, <span class="hljs-string"><span class="hljs-string">'Resolution_time'</span></span>, <span class="hljs-string"><span class="hljs-string">'Assignee'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) df[<span class="hljs-string"><span class="hljs-string">'Description'</span></span>].fillna(<span class="hljs-string"><span class="hljs-string">''</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) df[<span class="hljs-string"><span class="hljs-string">'Summary'</span></span>].fillna(<span class="hljs-string"><span class="hljs-string">''</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> </div></div><br><p>  We decompose categorical features into sparse vectors ( <a href="https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding">One-hot encoding</a> ).  Until we touch the fields with the description and table of contents of the ticket.  We will use them a little differently.  Some reporter names contain [X].  So JIRA marks inactive employees who no longer work for the company.  I decided to leave them among the signs, although it is possible to clear the data from them, because in the future, when using the model, we will not meet the tickets from these employees. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_df</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dic, feature_list)</span></span></span><span class="hljs-function">:</span></span> out = pd.DataFrame(dic) out = pd.concat([out, pd.get_dummies(out[feature_list])], axis = <span class="hljs-number"><span class="hljs-number">1</span></span>) out.drop(feature_list, axis = <span class="hljs-number"><span class="hljs-number">1</span></span>, inplace = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out X = create_df(df, df.columns[df.dtypes == <span class="hljs-string"><span class="hljs-string">'object'</span></span>].drop([<span class="hljs-string"><span class="hljs-string">'Description'</span></span>, <span class="hljs-string"><span class="hljs-string">'Summary'</span></span>])) X.columns = X.columns.str.replace(<span class="hljs-string"><span class="hljs-string">' \[X\]'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>)</code> </pre> </div></div><br><p>  And now we will deal with the description field in the ticket.  We will work with him in one of the easiest ways - we will collect all the words used in our tickets, count the most popular among them, discard the "extra" words - those that obviously cannot influence the result, like, for example, "please" (please - all communication in JIRA is strictly in English), which is the most popular.  Yes, these are our polite people. </p><br><p>  Also remove the " <a href="https://ru.wikipedia.org/wiki/%25D0%25A8%25D1%2583%25D0%25BC%25D0%25BE%25D0%25B2%25D1%258B%25D0%25B5_%25D1%2581%25D0%25BB%25D0%25BE%25D0%25B2%25D0%25B0">stop words</a> ", according to the nltk library, and more thoroughly clear the text of unnecessary characters.  Let me remind you that this is the easiest thing to do with the text.  We do not " <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2582%25D0%25B5%25D0%25BC%25D0%25BC%25D0%25B8%25D0%25BD%25D0%25B3">stemming</a> " the words, you can also count the most popular <a href="https://ru.wikipedia.org/wiki/N-%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B0">N-grams of</a> words, but we will limit ourselves to just that. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">all_words = np.concatenate(df[<span class="hljs-string"><span class="hljs-string">'Description'</span></span>].apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> s: s.split()).values) stop_words = stopwords.words(<span class="hljs-string"><span class="hljs-string">'english'</span></span>) stop_words.extend([<span class="hljs-string"><span class="hljs-string">'please'</span></span>, <span class="hljs-string"><span class="hljs-string">'hi'</span></span>, <span class="hljs-string"><span class="hljs-string">'-'</span></span>, <span class="hljs-string"><span class="hljs-string">'0'</span></span>, <span class="hljs-string"><span class="hljs-string">'1'</span></span>, <span class="hljs-string"><span class="hljs-string">'2'</span></span>, <span class="hljs-string"><span class="hljs-string">'3'</span></span>, <span class="hljs-string"><span class="hljs-string">'4'</span></span>, <span class="hljs-string"><span class="hljs-string">'5'</span></span>, <span class="hljs-string"><span class="hljs-string">'6'</span></span>, <span class="hljs-string"><span class="hljs-string">'7'</span></span>, <span class="hljs-string"><span class="hljs-string">'8'</span></span>, <span class="hljs-string"><span class="hljs-string">'9'</span></span>, <span class="hljs-string"><span class="hljs-string">'('</span></span>, <span class="hljs-string"><span class="hljs-string">')'</span></span>, <span class="hljs-string"><span class="hljs-string">'='</span></span>, <span class="hljs-string"><span class="hljs-string">'{'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>]) stop_words.extend([<span class="hljs-string"><span class="hljs-string">'h3'</span></span>, <span class="hljs-string"><span class="hljs-string">'+'</span></span>, <span class="hljs-string"><span class="hljs-string">'-'</span></span>, <span class="hljs-string"><span class="hljs-string">'@'</span></span>, <span class="hljs-string"><span class="hljs-string">'!'</span></span>, <span class="hljs-string"><span class="hljs-string">'#'</span></span>, <span class="hljs-string"><span class="hljs-string">'$'</span></span>, <span class="hljs-string"><span class="hljs-string">'%'</span></span>, <span class="hljs-string"><span class="hljs-string">'^'</span></span>, <span class="hljs-string"><span class="hljs-string">'&amp;'</span></span>, <span class="hljs-string"><span class="hljs-string">'*'</span></span>, <span class="hljs-string"><span class="hljs-string">'(for'</span></span>, <span class="hljs-string"><span class="hljs-string">'output)'</span></span>]) stop_symbols = [<span class="hljs-string"><span class="hljs-string">'=&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'|'</span></span>, <span class="hljs-string"><span class="hljs-string">'['</span></span>, <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'#'</span></span>, <span class="hljs-string"><span class="hljs-string">'*'</span></span>, <span class="hljs-string"><span class="hljs-string">'\\'</span></span>, <span class="hljs-string"><span class="hljs-string">'/'</span></span>, <span class="hljs-string"><span class="hljs-string">'-&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&amp;'</span></span>] words_series = pd.Series(list(all_words)) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> all_words words_series = words_series[~words_series.isin(stop_words)] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> symbol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> stop_symbols: words_series = words_series[~words_series.str.contains(symbol, regex=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, na=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)]</code> </pre> </div></div><br><p>  After all this, our output is a pandas.Series object, containing all the words used.  Let's look at the most popular ones and take the first 50 of the list to use as signs.  For each ticket, we will look at whether this word is used in the description, and if so, put 1 in the corresponding column, otherwise 0. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">usefull_words = list(words_series.value_counts().head(<span class="hljs-number"><span class="hljs-number">50</span></span>).index) print(usefull_words[<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> </div></div><br><pre> <code class="plaintext hljs">['error', 'account', 'info', 'call', '{code}', 'behavior', 'array', 'update', 'env', 'actual']</code> </pre> <br><p>  Now in our common data set, we will create separate columns for the words we have chosen.  You can get rid of the description field itself. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> usefull_words: X[<span class="hljs-string"><span class="hljs-string">'Description_'</span></span> + word] = X[<span class="hljs-string"><span class="hljs-string">'Description'</span></span>].str.contains(word).astype(<span class="hljs-string"><span class="hljs-string">'int64'</span></span>) X.drop(<span class="hljs-string"><span class="hljs-string">'Description'</span></span>, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> </div></div><br><p>  Let's do the same for the ticket header field. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">all_words = np.concatenate(df[<span class="hljs-string"><span class="hljs-string">'Summary'</span></span>].apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> s: s.split()).values) words_series = pd.Series(list(all_words)) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> all_words words_series = words_series[~words_series.isin(stop_words)] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> symbol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> stop_symbols: words_series = words_series[~words_series.str.contains(symbol, regex=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, na=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)] usefull_words = list(words_series.value_counts().head(<span class="hljs-number"><span class="hljs-number">50</span></span>).index) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> usefull_words: X[<span class="hljs-string"><span class="hljs-string">'Summary_'</span></span> + word] = X[<span class="hljs-string"><span class="hljs-string">'Summary'</span></span>].str.contains(word).astype(<span class="hljs-string"><span class="hljs-string">'int64'</span></span>) X.drop(<span class="hljs-string"><span class="hljs-string">'Summary'</span></span>, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> </div></div><br><p>  Let's see what we ended up with in the matrix of attributes X and the vector of answers y. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">print(X.shape, y.shape)</code> </pre> </div></div><br><pre> <code class="plaintext hljs">((9493, 1114), (9493,))</code> </pre> <br><p>  Now we divide this data into a training (training) sample and a test sample as a percentage of 75/25.  Total we have 7119 examples on which we will train, and 2374 on which we will estimate our models.  And the dimension of our matrix of attributes increased to 1114 due to the unfolding of categorical signs. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=<span class="hljs-number"><span class="hljs-number">0.25</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>) print(X_train.shape, X_holdout.shape)</code> </pre> </div></div><br><pre> <code class="plaintext hljs">((7119, 1114), (2374, 1114))</code> </pre> <br><h2 id="treniruem-model">  We train the model. </h2><br><h3 id="lineynaya-regressiya">  Linear regression </h3><br><p>  Let's start with the easiest and (expectedly) least accurate model - linear regression.  We will evaluate both the accuracy of the training data and the delayed sample ‚Äî data that the model did not see. </p><br><p>  In the case of linear regression, the model more or less acceptably shows itself on the training data, but the accuracy on the delayed sample is monstrously low.  Even worse than predicting a normal average for all tickets. </p><br><p>  Here you need to make a short pause and tell how the model assesses quality using its score method. <br>  Evaluation is made by the <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D1%258D%25D1%2584%25D1%2584%25D0%25B8%25D1%2586%25D0%25B8%25D0%25B5%25D0%25BD%25D1%2582_%25D0%25B4%25D0%25B5%25D1%2582%25D0%25B5%25D1%2580%25D0%25BC%25D0%25B8%25D0%25BD%25D0%25B0%25D1%2586%25D0%25B8%25D0%25B8">coefficient of determination</a> : </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msup><mi>R</mi><mn>2</mn></msup><mo>=</mo><mn>1</mn><mo>&amp;#x2212;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi></mrow></msubsup><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi></mrow></msub><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><msup><mo stretchy=&quot;false&quot;>)</mo><mn>2</mn></msup><mtext>&amp;#xA0;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi></mrow></msubsup><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi></mrow></msub><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>e</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><msup><mo stretchy=&quot;false&quot;>)</mo><mn>2</mn></msup></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="61.298ex" height="3.262ex" viewBox="0 -987.6 26392.1 1404.6" role="img" focusable="false" style="vertical-align: -0.969ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-32" x="1074" y="583"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-3D" x="1491" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-31" x="2547" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-2212" x="3270" y="0"></use><g transform="translate(4270,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-75" x="719" y="0"></use><g transform="translate(1292,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6D" x="1242" y="499"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-31" x="1124" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-28" x="3419" y="0"></use><g transform="translate(3808,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-69" x="693" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-2212" x="4865" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-68" x="6116" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-61" x="6692" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-74" x="7222" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-79" x="7583" y="0"></use><g transform="translate(8081,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-29" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-32" x="550" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6F" x="9174" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-76" x="9660" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-65" x="10145" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-72" x="10612" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-73" x="11313" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-75" x="11783" y="0"></use><g transform="translate(12355,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6D" x="1242" y="499"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-31" x="1124" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-28" x="14483" y="0"></use><g transform="translate(14872,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-69" x="693" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-2212" x="15929" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6F" x="17180" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-76" x="17665" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-65" x="18151" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-72" x="18617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6C" x="19069" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-69" x="19367" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6E" x="19713" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-65" x="20313" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-79" x="20780" y="0"></use><g transform="translate(21277,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-29" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMAIN-32" x="550" y="583"></use></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msup><mi>R</mi><mn>2</mn></msup><mo>=</mo><mn>1</mn><mo>‚àí</mo><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>m</mi></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi></mrow></msub><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mtext>&nbsp;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>m</mi></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi></mrow></msub><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> R ^ 2 = 1 - {\ sum_ {i = 1} ^ {m} (y_ {i} - \ hat {y}) ^ 2 \ over \ sum_ {i = 1} ^ {m} (y_ {i } - \ overline {y}) ^ 2} </script></p><br><p>  Where <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.145ex" height="2.419ex" viewBox="0 -780.1 2215 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-79" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-2"> \ hat {y} </script>  - the result predicted by model a <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>e</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.097ex" height="2.419ex" viewBox="0 -780.1 4347.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6F" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-76" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-65" x="1221" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-72" x="1687" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6C" x="2139" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-69" x="2437" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-6E" x="2783" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-65" x="3383" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/dins/blog/433166/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjC7jof7CWj_8PXiPlVddNxg8vcUA#MJMATHI-79" x="3850" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ overline {y} </script>  - average over the entire sample. </p><br><p>  We will not dwell too much on the coefficient now.  We note only that it does not fully reflect the accuracy of the model that interests us.  Therefore, at the same time we will use Mean Absolute Error (MAE) to estimate and rely on it. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">lr = LinearRegression() lr.fit(X_train, y_train) print(<span class="hljs-string"><span class="hljs-string">'R^2 train:'</span></span>, lr.score(X_train, y_train)) print(<span class="hljs-string"><span class="hljs-string">'R^2 test:'</span></span>, lr.score(X_holdout, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>, mean_absolute_error(lr.predict(X_train), y_train)) print(<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>, mean_absolute_error(lr.predict(X_holdout), y_holdout))</code> </pre> </div></div><br><pre> <code class="plaintext hljs">R^2 train: 0.3884389470220214 R^2 test: -6.652435243123196e+17 MAE train: 8503.67256637168 MAE test: 1710257520060.8154</code> </pre> <br><h3 id="gradientnyy-busting">  Gradient boosting </h3><br><p>  So where do without it, without gradient boosting?  Let's try to train the model and see what we can do.  We will use the well-known XGBoost for this.  Let's start with the standard settings of the hyperparameters. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> xgboost xgb = xgboost.XGBRegressor() xgb.fit(X_train, y_train) print(<span class="hljs-string"><span class="hljs-string">'R^2 train:'</span></span>, xgb.score(X_train, y_train)) print(<span class="hljs-string"><span class="hljs-string">'R^2 test:'</span></span>, xgb.score(X_holdout, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>, mean_absolute_error(xgb.predict(X_train), y_train)) print(<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>, mean_absolute_error(xgb.predict(X_holdout), y_holdout))</code> </pre> </div></div><br><pre> <code class="plaintext hljs">R^2 train: 0.5138516547636054 R^2 test: 0.12965507684512545 MAE train: 7108.165167471887 MAE test: 8343.433260957032</code> </pre> <br><p>  The result of the box is no longer bad.  Let's try to model the model by selecting hyper parameters: n_estimators, learning_rate and max_depth.  As a result, we will dwell on the values ‚Äã‚Äãof 150, 0.1 and 3, respectively, as showing the best result on the test sample in the absence of overtraining of the model on the training data. </p><br><div class="spoiler">  <b class="spoiler_title">We select n_estimators</b> <div class="spoiler_text"><p>  * <em>Instead of R ^ 2 Score in the picture should be MAE.</em> </p><br><pre> <code class="python hljs">xgb_model_abs_testing = list() xgb_model_abs_training = list() rng = np.arange(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">151</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> rng: xgb = xgboost.XGBRegressor(n_estimators=i) xgb.fit(X_train, y_train) xgb.score(X_holdout, y_holdout) xgb_model_abs_testing.append(mean_absolute_error(xgb.predict(X_holdout), y_holdout)) xgb_model_abs_training.append(mean_absolute_error(xgb.predict(X_train), y_train)) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) plt.plot(rng, xgb_model_abs_testing, label=<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>); plt.plot(rng, xgb_model_abs_training, label=<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>); plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Number of estimators'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'$R^2 Score$'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.show();</code> </pre> <br><img src="https://habrastorage.org/webt/yw/_k/fe/yw_kfe9ov-i5usxjjbvhgnyjnss.png"></div></div><br><div class="spoiler">  <b class="spoiler_title">We select learning_rate</b> <div class="spoiler_text"><pre> <code class="python hljs">xgb_model_abs_testing = list() xgb_model_abs_training = list() rng = np.arange(<span class="hljs-number"><span class="hljs-number">0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.65</span></span>, <span class="hljs-number"><span class="hljs-number">0.05</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> rng: xgb = xgboost.XGBRegressor(n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, learning_rate=i) xgb.fit(X_train, y_train) xgb.score(X_holdout, y_holdout) xgb_model_abs_testing.append(mean_absolute_error(xgb.predict(X_holdout), y_holdout)) xgb_model_abs_training.append(mean_absolute_error(xgb.predict(X_train), y_train)) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) plt.plot(rng, xgb_model_abs_testing, label=<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>); plt.plot(rng, xgb_model_abs_training, label=<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>); plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Learning rate'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'MAE'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.show();</code> </pre> <br><img src="https://habrastorage.org/webt/iv/7n/5n/iv7n5n1dfgccqjx2frkjsjdzxxq.png"></div></div><br><div class="spoiler">  <b class="spoiler_title">We select max_depth</b> <div class="spoiler_text"><pre> <code class="python hljs">xgb_model_abs_testing = list() xgb_model_abs_training = list() rng = np.arange(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> rng: xgb = xgboost.XGBRegressor(n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, max_depth=i) xgb.fit(X_train, y_train) xgb.score(X_holdout, y_holdout) xgb_model_abs_testing.append(mean_absolute_error(xgb.predict(X_holdout), y_holdout)) xgb_model_abs_training.append(mean_absolute_error(xgb.predict(X_train), y_train)) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) plt.plot(rng, xgb_model_abs_testing, label=<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>); plt.plot(rng, xgb_model_abs_training, label=<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>); plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Maximum depth'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'MAE'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.show();</code> </pre> <br><img src="https://habrastorage.org/webt/2b/ej/70/2bej70cirp-wehkeolsd-6klzic.png"></div></div><br><p>  Now we will train the model with selected hyper parameters. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">xgb = xgboost.XGBRegressor(n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>) xgb.fit(X_train, y_train) print(<span class="hljs-string"><span class="hljs-string">'R^2 train:'</span></span>, xgb.score(X_train, y_train)) print(<span class="hljs-string"><span class="hljs-string">'R^2 test:'</span></span>, xgb.score(X_holdout, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>, mean_absolute_error(xgb.predict(X_train), y_train)) print(<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>, mean_absolute_error(xgb.predict(X_holdout), y_holdout))</code> </pre> </div></div><br><pre> <code class="plaintext hljs">R^2 train: 0.6745967150462303 R^2 test: 0.15415143189670344 MAE train: 6328.384400466232 MAE test: 8217.07897417256</code> </pre> <br><p>  The final result with the selected parameters and the visualization of feature importance - the importance of signs in the model's opinion.  In the first place is the number of observers for the ticket, and then 4 engineers go at once.  Accordingly, the time of solving the ticket can be quite affected by the employment of this or that engineer.  And it is quite logical that the free time of some of them is more important.  If only because the team has both senior engineers and the middle (we have no juniors in the team).  By the way, again in secret, the engineer in the first place (orange bar) is indeed one of the most experienced among the whole team.  Moreover, all 4 of these engineers have a senior prefix in their position.  It turns out that the model is once again confirmed. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs">features_df = pd.DataFrame(data=xgb.feature_importances_.reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>), columns=X.columns).sort_values(axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, by=[<span class="hljs-number"><span class="hljs-number">0</span></span>], ascending=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) features_df.loc[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span>].plot(kind=<span class="hljs-string"><span class="hljs-string">'bar'</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>), rot=<span class="hljs-number"><span class="hljs-number">75</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">14</span></span>);</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/yn/er/7o/yner7ojqi-tz7a5je4g8phkmyki.png"><br><h3 id="neyronnaya-set">  Neural network </h3><br><p>  But we will not dwell on one gradient boosting and we will try to train the neural network, or rather the Multilayer perceptron (Multilayer perceptron), a fully connected forward propagation neural network.  This time we will not start with the standard settings of the hyperparameters, since  In the sklearn library, which we will use, by default only one hidden layer with 100 neurons and during training the model gives a warning about non-match in standard 200 iterations.  We use 3 hidden layers with 300, 200 and 100 neurons, respectively. </p><br><p>  As a result, we see that the model is not weakly overtraining on the training set, which, however, does not prevent it from showing a decent result on the test set.  This result is quite a bit inferior to the result of the gradient boosting. </p><br><div class="spoiler">  <b class="spoiler_title">Source</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neural_network <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MLPRegressor nn = MLPRegressor(random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, hidden_layer_sizes=(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">200</span></span> ,<span class="hljs-number"><span class="hljs-number">100</span></span>), alpha=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'adaptive'</span></span>, learning_rate_init=<span class="hljs-number"><span class="hljs-number">0.0005</span></span>, max_iter=<span class="hljs-number"><span class="hljs-number">200</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterovs_momentum=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) nn.fit(X_train, y_train) print(<span class="hljs-string"><span class="hljs-string">'R^2 train:'</span></span>, nn.score(X_train, y_train)) print(<span class="hljs-string"><span class="hljs-string">'R^2 test:'</span></span>, nn.score(X_holdout, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>, mean_absolute_error(nn.predict(X_train), y_train)) print(<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>, mean_absolute_error(nn.predict(X_holdout), y_holdout))</code> </pre> </div></div><br><pre> <code class="plaintext hljs">R^2 train: 0.9771443840549647 R^2 test: -0.15166596239118246 MAE train: 1627.3212161350423 MAE test: 8816.204561947616</code> </pre> <br><p>  Let's see what we can achieve by trying to find the best architecture of our network.  To begin with, we will train several models with one hidden layer and one with two, just to make sure once again that models with one layer do not have time to converge in 200 iterations and, as can be seen from the graph, they can converge for a very, very long time.       . </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [(<span class="hljs-number"><span class="hljs-number">500</span></span>,), (<span class="hljs-number"><span class="hljs-number">750</span></span>,), (<span class="hljs-number"><span class="hljs-number">1000</span></span>,), (<span class="hljs-number"><span class="hljs-number">500</span></span>,<span class="hljs-number"><span class="hljs-number">500</span></span>)]: nn = MLPRegressor(random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, hidden_layer_sizes=i, alpha=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'adaptive'</span></span>, learning_rate_init=<span class="hljs-number"><span class="hljs-number">0.0005</span></span>, max_iter=<span class="hljs-number"><span class="hljs-number">200</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterovs_momentum=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) nn.fit(X_train, y_train) plt.plot(nn.loss_curve_, label=str(i)); plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Iterations'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'MSE'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/eg/xx/3k/egxx3kwhm28pfdsbvn_sp2_sewo.png"></div></div><br><p>         .  3    10        . </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [(<span class="hljs-number"><span class="hljs-number">500</span></span>,<span class="hljs-number"><span class="hljs-number">300</span></span>,<span class="hljs-number"><span class="hljs-number">100</span></span>), (<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">60</span></span>, <span class="hljs-number"><span class="hljs-number">60</span></span>, <span class="hljs-number"><span class="hljs-number">60</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), (<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">60</span></span>, <span class="hljs-number"><span class="hljs-number">60</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), (<span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">60</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), (<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>), (<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), (<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">250</span></span>, <span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>)]: nn = MLPRegressor(random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, hidden_layer_sizes=i, alpha=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'adaptive'</span></span>, learning_rate_init=<span class="hljs-number"><span class="hljs-number">0.001</span></span>, max_iter=<span class="hljs-number"><span class="hljs-number">200</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterovs_momentum=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) nn.fit(X_train, y_train) plt.plot(nn.loss_curve_, label=str(i)); plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Iterations'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'MSE'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/p9/8z/d7/p98zd7u3ppxuzyykvyt91skxjiq.png"></div></div><br><p>    ""    (200, 100, 100, 100, 80, 80, 80, 40, 20)    : <br> 2506    <br> 7351    </p><br><p>   ,    ,        .      learning rate    . </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="python hljs">nn = MLPRegressor(random_state=<span class="hljs-number"><span class="hljs-number">17</span></span>, hidden_layer_sizes=(<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>), alpha=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'adaptive'</span></span>, learning_rate_init=<span class="hljs-number"><span class="hljs-number">0.007</span></span>, max_iter=<span class="hljs-number"><span class="hljs-number">200</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterovs_momentum=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) nn.fit(X_train, y_train) print(<span class="hljs-string"><span class="hljs-string">'R^2 train:'</span></span>, nn.score(X_train, y_train)) print(<span class="hljs-string"><span class="hljs-string">'R^2 test:'</span></span>, nn.score(X_holdout, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'MAE train'</span></span>, mean_absolute_error(nn.predict(X_train), y_train)) print(<span class="hljs-string"><span class="hljs-string">'MAE test'</span></span>, mean_absolute_error(nn.predict(X_holdout), y_holdout))</code> </pre> </div></div><br><pre> <code class="plaintext hljs">R^2 train: 0.836204705204337 R^2 test: 0.15858607391959356 MAE train: 4075.8553476632796 MAE test: 7530.502826043687</code> </pre> <br><p>  ,  .      ,        .   ,       ,    . </p><br><p>     .    :                 ( ,   200 ).  ,        ""   .  , 30   200 ,   issue type: Epic       .         , ..    ,   ,                ,     ,           .    4  5    .         ,    .           ,      . </p><br><p>       ‚Äî      9  ,             .     ,           ,        ,          . </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="python hljs">pd.Series([X_train.columns[abs(nn.coefs_[<span class="hljs-number"><span class="hljs-number">0</span></span>][:,i]).argmax()] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(nn.hidden_layer_sizes[<span class="hljs-number"><span class="hljs-number">0</span></span>])]).value_counts().head(<span class="hljs-number"><span class="hljs-number">5</span></span>).sort_values().plot(kind=<span class="hljs-string"><span class="hljs-string">'barh'</span></span>, title=<span class="hljs-string"><span class="hljs-string">'Feature importance'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">14</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">14</span></span>,<span class="hljs-number"><span class="hljs-number">8</span></span>));</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/t3/f_/pk/t3f_pkvagtacmshpf6ultiteoki.png"><br><h2 id="ansambl-modeley">   </h2><br><p>             .  What for?       7530   8217.     (7530 + 8217) / 2 = 7873,  ,    , ?  No not like this.    ,   .     ,     7526. </p><br><p>      ,     kaggle .     , ,    . </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="python hljs">nn_predict = nn.predict(X_holdout) xgb_predict = xgb.predict(X_holdout) print(<span class="hljs-string"><span class="hljs-string">'NN MSE:'</span></span>, mean_squared_error(nn_predict, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'XGB MSE:'</span></span>, mean_squared_error(xgb_predict, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'Ensemble:'</span></span>, mean_squared_error((nn_predict + xgb_predict) / <span class="hljs-number"><span class="hljs-number">2</span></span>, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'NN MAE:'</span></span>, mean_absolute_error(nn_predict, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'XGB MSE:'</span></span>, mean_absolute_error(xgb_predict, y_holdout)) print(<span class="hljs-string"><span class="hljs-string">'Ensemble:'</span></span>, mean_absolute_error((nn_predict + xgb_predict) / <span class="hljs-number"><span class="hljs-number">2</span></span>, y_holdout))</code> </pre> </div></div><br><pre> <code class="plaintext hljs">NN MSE: 628107316.262393 XGB MSE: 631417733.4224195 Ensemble: 593516226.8298339 NN MAE: 7530.502826043687 XGB MSE: 8217.07897417256 Ensemble: 7526.763569558157</code> </pre> <br><h2 id="analiz-rezultatov">   </h2><br><p>       ?      7500   .  Those.  5   .          .     .  ,         . </p><br><p>      ( ): </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="python hljs">((nn_predict + xgb_predict) / <span class="hljs-number"><span class="hljs-number">2</span></span> - y_holdout).apply(np.abs).sort_values(ascending=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>).head(<span class="hljs-number"><span class="hljs-number">10</span></span>).values</code> </pre> </div></div><br><pre> <code class="plaintext hljs">[469132.30504392, 454064.03521379, 252946.87342439, 251786.22682697, 224012.59016987, 15671.21520735, 13201.12440327, 203548.46460229, 172427.32150665, 171088.75543224]</code> </pre> <br><p>  . ,    . </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="python hljs">df.loc[((nn_predict + xgb_predict) / <span class="hljs-number"><span class="hljs-number">2</span></span> - y_holdout).apply(np.abs).sort_values(ascending=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>).head(<span class="hljs-number"><span class="hljs-number">10</span></span>).index][[<span class="hljs-string"><span class="hljs-string">'Issue_type'</span></span>, <span class="hljs-string"><span class="hljs-string">'Priority'</span></span>, <span class="hljs-string"><span class="hljs-string">'Worktype'</span></span>, <span class="hljs-string"><span class="hljs-string">'Summary'</span></span>, <span class="hljs-string"><span class="hljs-string">'Watchers'</span></span>]]</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/9d/sy/mt/9dsymtwss-2wkd1xy_3h0nx3qvu.png"><br><p>           ,       -  ,          .     4           . </p><br><p>    ,       . </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="python hljs">print(((nn_predict + xgb_predict) / <span class="hljs-number"><span class="hljs-number">2</span></span> - y_holdout).apply(np.abs).sort_values().head(<span class="hljs-number"><span class="hljs-number">10</span></span>).values) df.loc[((nn_predict + xgb_predict) / <span class="hljs-number"><span class="hljs-number">2</span></span> - y_holdout).apply(np.abs).sort_values().head(<span class="hljs-number"><span class="hljs-number">10</span></span>).index][[<span class="hljs-string"><span class="hljs-string">'Issue_type'</span></span>, <span class="hljs-string"><span class="hljs-string">'Priority'</span></span>, <span class="hljs-string"><span class="hljs-string">'Worktype'</span></span>, <span class="hljs-string"><span class="hljs-string">'Summary'</span></span>, <span class="hljs-string"><span class="hljs-string">'Watchers'</span></span>]]</code> </pre> </div></div><br><pre> <code class="plaintext hljs">[ 1.24606014, 2.6723969, 4.51969139, 10.04159236, 11.14335444, 14.4951508, 16.51012874, 17.78445744, 21.56106258, 24.78219295]</code> </pre> <br><img src="https://habrastorage.org/webt/c0/ah/h7/c0ahh76a9u5tti2oinyzpycip3c.png"><br><p> ,      ,     -     ,    -        . ,  ,            ,     . </p><br><h2 id="kak-pole-engineer-uvelichilo-tochnost">   Engineer   </h2><br><p> ,        'Engineer',    ,   ,         ?  . </p><br><p>   ,             2 . , ,    ,       ,       .  ,  ,   ,     ""    ,       (  ) ,         ,     ,   . ,         " ",              . </p><br><p>    ,      .      ,     ,                     12 ,     (  JQL   JIRA): </p><br><pre> <code class="sql hljs">assignee was engineer_N during (ticket_creation_date) and status was "In Progress"</code> </pre> <br><p>    10783 * 12 = 129396 ,  ‚Ä¶ . ,  ,                 , ..   5   . <br>  ,    ,     ,   ,      2 .              . </p><br><h2 id="itogi-i-plany-na-buduschee">      </h2><br><p>               .         <a href="https://en.wikipedia.org/wiki/Service-level_objective">SLO</a>    ,    . </p><br><p>  ,          ,      (      : -   , -  ,  -    )        ,           . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/433166/">https://habr.com/ru/post/433166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../433152/index.html">Transferring Zimbra from a single server to a multi-server infrastructure</a></li>
<li><a href="../433154/index.html">User experience in 5G NR networks expected in real conditions</a></li>
<li><a href="../433156/index.html">Dell goes to the exchange and heading for a hybrid cloud</a></li>
<li><a href="../433158/index.html">Musical parodies from SUSE about Kubernetes, Linus Torvalds and others</a></li>
<li><a href="../433164/index.html">Fast & Furious: Forza Horizon 4 acceleration due to window shaders</a></li>
<li><a href="../433168/index.html">Why does a programmer have an internship in the kitchen - a conversation with ‚ÄúDodo Pizza‚Äù about gembu, .NET and openness</a></li>
<li><a href="../433170/index.html">How did we fail to remake the architecture of the company</a></li>
<li><a href="../433172/index.html">Screwing multiplayer to the mobile game "Make a word from a word" on iOS and Android, written in C ++</a></li>
<li><a href="../433176/index.html">Docker Remote API with certificate authentication with revocation checking</a></li>
<li><a href="../433178/index.html">How we recovered a corrupted .wav file</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>