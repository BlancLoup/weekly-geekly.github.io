<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Distributed xargs, or Execution of Heterogeneous Applications on Hadoop Cluster</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! My name is Alexander Krasheninnikov, I lead DataTeam in Badoo. Today I will share with you a simple and elegant utility for distributed exec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Distributed xargs, or Execution of Heterogeneous Applications on Hadoop Cluster</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/791/0ea/93c/7910ea93c4fb4d87a15b277b98ad0464.png" alt="enter image description here"></p><br><p>  Hi, Habr!  My name is Alexander Krasheninnikov, I lead DataTeam in Badoo.  Today I will share with you a simple and elegant utility for distributed execution of commands in the style of xargs, and at the same time I will tell the story of its occurrence. </p><br><p>  Our BI department works with data volumes that require the processing of resources from more than one machine.  In our ETL processes <a href="https://ru.wikipedia.org/wiki/ETL">(Extract Transform Load),</a> distributed Hadoop and Spark systems familiar to the Big Data world are used in conjunction with the <a href="https://habrahabr.ru/company/badoo/blog/271753/">Exasol</a> OLAP database.  Using these tools allows us to scale horizontally in both disk space and CPU / RAM. </p><br><p>  Of course, in our ETL processes there are not only heavy tasks on the cluster, but also simpler machines.  A wide range of tasks is solved by single PHP / Python scripts without recourse to gigabytes of RAM and a dozen hard drives.  But one fine day we needed to adapt one CPU-bound task for execution in 250 parallel instances.  It is time for the little Python script to leave the limits of the native host and rush into a large cluster! </p><a name="habracut"></a><br><h3 id="varianty-manyovra">  Maneuver options </h3><br><p>  So, we have the following input conditions of the problem: </p><br><ol><li>  Long-running (about one hour) CPU-bound Python task. </li><li>  It is required to perform the task 250 times with various input parameters. </li><li>  The result of the execution is obtained synchronously, that is, start something, wait, exit the exit code according to the results. </li><li>  Minimum execution time - we believe that we have enough computational resources for parallelization. </li></ol><br><h3 id="varianty-realizacii">  Implementation options </h3><br><h4 id="odin-fizicheskiy-host">  One physical host </h4><br><p>  The fact that running applications are single-threaded and do not use more than 100% of a single CPU core allows us to simply fork-out / exec-actions in the implementation of each task. </p><br><p>  Using xargs: </p><br><pre><code class="hljs mel">commands.list: /usr/bin/uptime /bin/<span class="hljs-keyword"><span class="hljs-keyword">pwd</span></span> krash@krash:~$ cat commands.list | xargs -n <span class="hljs-number"><span class="hljs-number">1</span></span> -P <span class="hljs-string"><span class="hljs-string">`nproc`</span></span> bash -c /home/krash <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">40</span></span>:<span class="hljs-number"><span class="hljs-number">10</span></span> up <span class="hljs-number"><span class="hljs-number">14</span></span> days, <span class="hljs-number"><span class="hljs-number">9</span></span>:<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span> users, load average: <span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">45</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">53</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">59</span></span></code> </pre> <br><p>  The approach is simple as a boot and has worked well.  But in our case, we reject it, because when we perform our task on a machine with 32 cores, we get the result in ~ eight hours, and this does not correspond to the formulation ‚Äúminimum execution time‚Äù. </p><br><h4 id="neskolko-fizicheskih-hostov">  Multiple physical hosts </h4><br><p>  The next tool you can use for this solution is <a href="https://www.gnu.org/software/parallel/">GNU Parallel</a> .  In addition to the local mode, similar in functionality to xargs, it has the ability to run programs via SSH on several servers.  We select several hosts on which we will execute tasks (‚Äúcloud‚Äù), divide the list of commands between them and use the parallel to execute tasks. </p><br><p>  Create a <code>nodelist</code> file with a list of machines and the number of cores that we can dispose of there: </p><br><pre> <code class="hljs pgsql"><span class="hljs-number"><span class="hljs-number">1</span></span>/ cloudhost1.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/ cloudhost2.<span class="hljs-keyword"><span class="hljs-keyword">domain</span></span></code> </pre> <br><p>  Run: </p><br><pre> <code class="hljs ruby">commands.<span class="hljs-symbol"><span class="hljs-symbol">list:</span></span> /usr/bin/uptime /usr/bin/uptime krash@krash<span class="hljs-symbol"><span class="hljs-symbol">:~</span></span>$ parallel --sshloginfile nodelist echo <span class="hljs-string"><span class="hljs-string">"Run on host \`hostname\`: "</span></span>\; {} <span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span>: <span class="hljs-string"><span class="hljs-string">`cat commands.list`</span></span> Run on host cloudhost1.<span class="hljs-symbol"><span class="hljs-symbol">domain:</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">54</span></span> up <span class="hljs-number"><span class="hljs-number">358</span></span> days <span class="hljs-number"><span class="hljs-number">19</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span> users, load <span class="hljs-symbol"><span class="hljs-symbol">average:</span></span> <span class="hljs-number"><span class="hljs-number">25</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>, <span class="hljs-number"><span class="hljs-number">21</span></span>,<span class="hljs-number"><span class="hljs-number">35</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">48</span></span> Run on host cloudhost2.<span class="hljs-symbol"><span class="hljs-symbol">domain:</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">54</span></span> up <span class="hljs-number"><span class="hljs-number">358</span></span> days <span class="hljs-number"><span class="hljs-number">15</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">37</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span> users, load <span class="hljs-symbol"><span class="hljs-symbol">average:</span></span> <span class="hljs-number"><span class="hljs-number">24</span></span>,<span class="hljs-number"><span class="hljs-number">11</span></span>, <span class="hljs-number"><span class="hljs-number">21</span></span>,<span class="hljs-number"><span class="hljs-number">35</span></span>, <span class="hljs-number"><span class="hljs-number">21</span></span>,<span class="hljs-number"><span class="hljs-number">46</span></span></code> </pre> <br><p>  However, we also reject this option due to operational features: we do not have information about the current load and availability of cluster hosts, and it is possible to get into a situation where parallelization will only cause harm, since one of the target hosts will be overloaded. </p><br><h4 id="hadoop-based-resheniya">  Hadoop-based solutions </h4><br><p>  We have a proven BI tool that we know and can use, a bunch of Hadoop + Spark.  To cram our code into a cluster framework, there are two solutions: </p><br><h5 id="spark-python-api-pyspark">  Spark Python API (PySpark) </h5><br><p>  Since the original task is written in Python, and Spark has the corresponding API for this language, you can try to port the code to the map / reduce paradigm.  But we also had to reject this option, since the cost of adaptation was unacceptable within the framework of this task. </p><br><h5 id="hadoop-streaming">  Hadoop streaming </h5><br><p>  The Hadoop Map / reduce framework allows you to perform tasks written not only in JVM-compatible programming languages.  In our particular case, the task is called map-only ‚Äî there is no reduce-stage, since the execution results are not subjected to any subsequent aggregation.  The task launch looks like this: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">hadoop</span></span> jar <span class="hljs-variable"><span class="hljs-variable">$path_to_hadoop_install_dir</span></span>/lib/hadoop-streaming-<span class="hljs-number"><span class="hljs-number">2</span></span>.<span class="hljs-number"><span class="hljs-number">7</span></span>.<span class="hljs-number"><span class="hljs-number">1</span></span>.jar \ -D mapreduce.job.reduces=<span class="hljs-number"><span class="hljs-number">0</span></span> \ -D mapred.map.tasks=<span class="hljs-variable"><span class="hljs-variable">$number_of_jobs_to_run</span></span> \ -input hdfs:///path_for_list_of_jobs/ \ -output hdfs:///path_for_saving_results \ -mapper <span class="hljs-string"><span class="hljs-string">"my_python_job.py"</span></span> \ -file <span class="hljs-string"><span class="hljs-string">"my_python_job.py"</span></span></code> </pre> <br><p>  This mechanism works as follows: </p><br><ol><li>  We request resources from the Hadoop cluster ( <a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN</a> ) to perform the task. </li><li>  YARN allocates a number of physical JVMs (YARN containers) on different cluster hosts. </li><li>  The contents of the files (a) located in the hdfs: // path_for_list_of_jobs folder are divided between containers. </li><li>  Each of the containers, having received its own list of strings from a file, runs the my_python_job.py script and sends it to STDIN successively, interpreting the contents of STDOUT as a return value. </li></ol><br><p>  An example of running a child process: </p><br><pre> <code class="hljs scala">#!/usr/bin/python <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> subprocess <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span></span>(argv): command = sys.stdin.readline() subprocess.call(command.split()) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: main(sys.argv)</code> </pre> <br><p>  And an option with a "controller" that runs the business logic: </p><br><pre> <code class="hljs pgsql">#!/usr/bin/python <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys def main(argv): <span class="hljs-type"><span class="hljs-type">line</span></span> = sys.stdin.readline() args = <span class="hljs-type"><span class="hljs-type">line</span></span>.split() MyJob(args).run() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == "__main__": main(sys.argv)</code> </pre> <br><p>  This approach most fully corresponds to our task, but has several disadvantages: </p><br><ol><li>  We lose the STDOUT flow of the task being performed (it is used as a communication channel), and we would like to be able to see logs after the task is completed. </li><li>  If in the future we want to run some more tasks on the cluster, we will have to do a wrapper for them. </li></ol><br><p>  As a result of analyzing the above implementation options, we decided to create our own <del>  bicycle </del>  product. </p><br><h3 id="hadoop-xargs">  Hadoop xargs </h3><br><p>  Requirements for the developed system: </p><br><ol><li>  Perform a task list with optimal use of Hadoop cluster resources. </li><li>  The condition for successful completion is ‚Äúall subtasks worked successfully, otherwise fail.‚Äù </li><li>  The ability to save subtasks for further analysis. </li><li>  Optional restart of the task with an exit code other than zero. </li></ol><br><p>  We chose Apache Spark as a platform for implementation - we are well acquainted with it and know how to ‚Äúprepare‚Äù it. </p><br><p>  Work algorithm: </p><br><ol><li>  Get a list of tasks from STDIN. </li><li>  Make it Spark RDD (distributed array). </li><li>  Request containers for execution from the cluster. </li><li>  Distribute an array of tasks in containers. </li><li>  For each container, start a map function that accepts the text of an external program as input and produces fork-exec. </li></ol><br><p>  The code of the entire application is obscenely simple, and the function code itself is of immediate interest: </p><br><pre> <code class="hljs pgsql">package com.badoo.bi.hadoop.xargs; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lombok.extern.log4j.Log4j; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.commons.exec.CommandLine; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.commons.lang.NullArgumentException; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.log4j.PropertyConfigurator; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.api.java.<span class="hljs-keyword"><span class="hljs-keyword">function</span></span>.VoidFunction; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.IOException; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.Arrays; <span class="hljs-comment"><span class="hljs-comment">/** * Executor of one command * Created by krash on 01.02.17. */</span></span> @Log4j <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> JobExecutor implements VoidFunction&lt;String&gt; { @Override <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> <span class="hljs-type"><span class="hljs-type">void</span></span> <span class="hljs-keyword"><span class="hljs-keyword">call</span></span>(String command) throws <span class="hljs-keyword"><span class="hljs-keyword">Exception</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">null</span></span> == command || command.isEmpty()) { throw <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> NullArgumentException("Command can not be empty"); } <span class="hljs-keyword"><span class="hljs-keyword">log</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">info</span></span>("Going to launch '" + command + "'"); Process process = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; try { CommandLine <span class="hljs-type"><span class="hljs-type">line</span></span> = CommandLine.parse(command); ProcessBuilder builder = getProcessBuilder(); // quotes removal <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> bash-style <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">order</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> pass correctly <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> execve() String[] mapped = Arrays.stream(<span class="hljs-type"><span class="hljs-type">line</span></span>.toStrings()).map(s -&gt; s.replace("\'", "")).toArray(String[]::<span class="hljs-built_in"><span class="hljs-built_in">new</span></span>); builder.command(mapped); process = builder.<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>(); <span class="hljs-type"><span class="hljs-type">int</span></span> exitCode = process.waitFor(); <span class="hljs-keyword"><span class="hljs-keyword">log</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">info</span></span>("Process " + command + " finished with code " + exitCode); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span> != exitCode) { throw <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> InstantiationException("Process " + command + " exited with non-zero exit code (" + exitCode + ")"); } } catch (InterruptedException err) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (process.isAlive()) { process.destroyForcibly(); } } catch (IOException err) { throw <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> InstantiationException(err.getMessage()); } } ProcessBuilder getProcessBuilder() { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> ProcessBuilder().inheritIO(); } }</code> </pre> <br><h4 id="sborka">  Assembly </h4><br><p>  The assembly of the application is made by the standard for Java-world tool - Maven.  The only difference is in the environment in which the application will run.  If you do not use Spark for your cluster, then the assembly looks like this: </p><br><pre> <code class="hljs sql">mvn clean <span class="hljs-keyword"><span class="hljs-keyword">install</span></span></code> </pre> <br><p>  In this case, the resulting JAR file will contain Spark's source code.  If the client code Spark is installed on the machine with which the application is launched, it should be excluded from the assembly: </p><br><pre> <code class="hljs sql">mvn clean <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> -Dwork.scope=provided</code> </pre> <br><p>  As a result of such a build, the application file will be significantly smaller (15 Kb against 80 Mb). </p><br><h4 id="zapusk">  Launch </h4><br><p>  Suppose we have a <code>commands.list</code> file with a list of tasks of the following form: </p><br><pre> <code class="hljs perl">/bin/<span class="hljs-keyword"><span class="hljs-keyword">sleep</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> /bin/<span class="hljs-keyword"><span class="hljs-keyword">sleep</span></span> <span class="hljs-number"><span class="hljs-number">20</span></span> /bin/<span class="hljs-keyword"><span class="hljs-keyword">sleep</span></span> <span class="hljs-number"><span class="hljs-number">30</span></span></code> </pre> <br><p>  Run the application: </p><br><pre> <code class="hljs coffeescript">akrasheninnikov@cloududs1.mlan:~&gt; cat log.log | /local/spark/bin/spark-submit --conf <span class="hljs-string"><span class="hljs-string">"spark.master=yarn-client"</span></span> hadoop-xargs<span class="hljs-number"><span class="hljs-number">-1.0</span></span>.jar <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: Starting application <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: Got <span class="hljs-number"><span class="hljs-number">3</span></span> jobs: <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: /bin/sleep <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: /bin/sleep <span class="hljs-number"><span class="hljs-number">20</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: /bin/sleep <span class="hljs-number"><span class="hljs-number">30</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: Application name: com.badoo.bi.hadoop.xargs.Main <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: Execution environment: yarn-client <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: Explicit executor count was <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> specified, making same <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> job count <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> INFO Application: Initializing Spark <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">40</span></span> INFO Application: Initialization completed, starting jobs <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">52</span></span> INFO Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/sleep 10'</span></span> finished <span class="hljs-literal"><span class="hljs-literal">on</span></span> host bihadoop40.mlan <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">05</span></span>:<span class="hljs-number"><span class="hljs-number">02</span></span> INFO Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/sleep 20'</span></span> finished <span class="hljs-literal"><span class="hljs-literal">on</span></span> host bihadoop31.mlan <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">05</span></span>:<span class="hljs-number"><span class="hljs-number">12</span></span> INFO Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/sleep 30'</span></span> finished <span class="hljs-literal"><span class="hljs-literal">on</span></span> host bihadoop18.mlan <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">05</span></span>:<span class="hljs-number"><span class="hljs-number">13</span></span> INFO Application: All the jobs completed <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span>:<span class="hljs-number"><span class="hljs-number">32.258</span></span></code> </pre> <br><p>  After completing the work via the YARN GUI, we can get the logs of the applications that were running (example for the <code>uptime</code> ): </p><br><p><img src="https://habrastorage.org/files/5c0/9b1/7f9/5c09b17f91ed4a81891a952d23e57d07.png" alt="enter image description here"></p><br><p>  If it is impossible to execute a command, the whole process looks as follows: </p><br><pre> <code class="hljs bash">akrasheninnikov@cloududs1.mlan:~&gt; <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"/bin/unexistent_command"</span></span> | /<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/spark/bin/spark-submit --conf <span class="hljs-string"><span class="hljs-string">"spark.master=yarn-client"</span></span> --conf <span class="hljs-string"><span class="hljs-string">"spark.yarn.queue=uds.misc"</span></span> --conf <span class="hljs-string"><span class="hljs-string">"spark.driver.host=10.10.224.14"</span></span> hadoop-xargs-1.0.jar 17/02/10 15:12:14 INFO Application: Starting application 17/02/10 15:12:14 INFO Main: Expect commands to be passed to STDIN, one per line 17/02/10 15:12:14 INFO Application: Got 1 <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span>: 17/02/10 15:12:14 INFO Application: /bin/unexistent_command 17/02/10 15:12:14 INFO Application: Application name: com.badoo.bi.hadoop.xargs.Main 17/02/10 15:12:14 INFO Application: Execution environment: yarn-client 17/02/10 15:12:14 INFO Application: Explicit executor count was not specified, making same as job count 17/02/10 15:12:14 INFO Application: Initializing Spark 17/02/10 15:12:27 INFO Application: Initialization completed, starting <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span> 17/02/10 15:12:29 ERROR Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/unexistent_command'</span></span> failed on host bihadoop36.mlan, 1 <span class="hljs-built_in"><span class="hljs-built_in">times</span></span> 17/02/10 15:12:29 ERROR Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/unexistent_command'</span></span> failed on host bihadoop36.mlan, 2 <span class="hljs-built_in"><span class="hljs-built_in">times</span></span> 17/02/10 15:12:30 ERROR Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/unexistent_command'</span></span> failed on host bihadoop36.mlan, 3 <span class="hljs-built_in"><span class="hljs-built_in">times</span></span> 17/02/10 15:12:30 ERROR Application: Command <span class="hljs-string"><span class="hljs-string">'/bin/unexistent_command'</span></span> failed on host bihadoop36.mlan, 4 <span class="hljs-built_in"><span class="hljs-built_in">times</span></span> 17/02/10 15:12:30 ERROR Main: FATAL ERROR: Failed to execute all the <span class="hljs-built_in"><span class="hljs-built_in">jobs</span></span> java.lang.InstantiationException: Cannot run program <span class="hljs-string"><span class="hljs-string">"/bin/unexistent_command"</span></span>: error=2, No such file or directory at com.badoo.bi.hadoop.xargs.JobExecutor.call(JobExecutor.java:56) at com.badoo.bi.hadoop.xargs.JobExecutor.call(JobExecutor.java:16) at org.apache.spark.api.java.JavaRDDLike$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$foreachAsync</span></span><span class="hljs-variable"><span class="hljs-variable">$1</span></span>.apply(JavaRDDLike.scala:690) at org.apache.spark.api.java.JavaRDDLike$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$foreachAsync</span></span><span class="hljs-variable"><span class="hljs-variable">$1</span></span>.apply(JavaRDDLike.scala:690) at scala.collection.Iterator<span class="hljs-variable"><span class="hljs-variable">$class</span></span>.foreach(Iterator.scala:727) at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28) at org.apache.spark.rdd.AsyncRDDActions$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$foreachAsync</span></span><span class="hljs-variable"><span class="hljs-variable">$1</span></span>$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$apply</span></span><span class="hljs-variable"><span class="hljs-variable">$15</span></span>.apply(AsyncRDDActions.scala:118) at org.apache.spark.rdd.AsyncRDDActions$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$foreachAsync</span></span><span class="hljs-variable"><span class="hljs-variable">$1</span></span>$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$apply</span></span><span class="hljs-variable"><span class="hljs-variable">$15</span></span>.apply(AsyncRDDActions.scala:118) at org.apache.spark.SparkContext$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$37</span></span>.apply(SparkContext.scala:1984) at org.apache.spark.SparkContext$<span class="hljs-variable"><span class="hljs-variable">$anonfun</span></span><span class="hljs-variable"><span class="hljs-variable">$37</span></span>.apply(SparkContext.scala:1984) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66) at org.apache.spark.scheduler.Task.run(Task.scala:88) at org.apache.spark.executor.Executor<span class="hljs-variable"><span class="hljs-variable">$TaskRunner</span></span>.run(Executor.scala:214) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor<span class="hljs-variable"><span class="hljs-variable">$Worker</span></span>.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)</code> </pre> <br><h3 id="zaklyuchenie">  Conclusion </h3><br><p>  The developed solution allowed us to comply with all the conditions of the original problem: </p><br><ol><li>  We get from Hadoop kernel to run our application, according to the requirements (number of cores) - the maximum level of parallelization. </li><li>  When issuing resources, the load and availability of the hosts are taken into account (due to the API YARN). </li><li>  We save the contents of STDOUT / STDERR of all tasks that we run. </li><li>  Did not have to rewrite the original application. </li><li>  "Write once, run anywhere" ¬© Sun Microsystems - the developed solution can now be used to run any other tasks. </li></ol><br><p>  The joy of the result was so great that we could not share it with you.  <a href="https://github.com/badoo/hadoop-xargs">We published the</a> source code for Hadoop xargs <a href="https://github.com/badoo/hadoop-xargs">on GitHub</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/321692/">https://habr.com/ru/post/321692/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../321682/index.html">Login to the site using Telegram</a></li>
<li><a href="../321684/index.html">Zeigarnik effect in practice</a></li>
<li><a href="../321686/index.html">Development of transactional microservices using aggregates, Event Sourcing and CQRS (Part 1)</a></li>
<li><a href="../321688/index.html">‚ÄúLike an Iceberg in the Ocean‚Äù: Data Center Cooling Technologies</a></li>
<li><a href="../321690/index.html">Iterative Design and GitHub</a></li>
<li><a href="../321694/index.html">Personal experience: Raiffeisen, Alfa-Bank and VTB24</a></li>
<li><a href="../321696/index.html">Remotely reinstalling Linux via ssh without accessing the console</a></li>
<li><a href="../321698/index.html">Advanced Threat Protection in Windows Defender</a></li>
<li><a href="../321700/index.html">Stream WebRTC video stream from browser to YouTube Live in 65 lines of JavaScript / HTML code</a></li>
<li><a href="../321702/index.html">Incremental analysis in PVS-Studio: now also on the assembly server</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>