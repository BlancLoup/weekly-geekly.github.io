<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>QML: how easy it is to get T-shirts in machine learning competitions for mail.ru</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="On Saturday, the monthly machine learning contest from mail.ru ML bootcamp 5 was completed . I took 14th place in it. This is my third contest in whic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>QML: how easy it is to get T-shirts in machine learning competitions for mail.ru</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/ae1/c8d/a56/ae1c8da5641445519b3af33de7cd7ca2.jpg"><br><p><br>  On Saturday, the monthly machine learning contest from mail.ru <a href="http://mlbootcamp.ru/round/12/sandbox/">ML bootcamp 5 was completed</a> .  I took <a href="http://mlbootcamp.ru/round/12/rating/">14th place</a> in it.  This is my third contest in which I won clothes and during my participation I had a <a href="https://github.com/quantum13/qml">framework</a> (which I, without thinking twice, called QML, an abbreviation for nickname and machine learning) to help me choose a solution for such competitions.  Using the example of ML bootcamp 5 solution, I will describe how to use it. </p><br><p>  As it should be, first show the goods face :) </p><br><ul><li>  Saving intermediate results of model calculations for further use in metamodels (including the results of cross-qualifications) </li><li>  Models for various averages and stacking </li><li>  Supporting scripts for feature selection </li></ul><a name="habracut"></a><br><p>  So, let's start solving the competition (the entire solution scripts can be viewed <a href="https://github.com/quantum13/mlbootcamp5">here</a> ). </p><br><p>  First, we will clone the <a href="https://github.com/quantum13/qml">framework</a> repository, install the missing packages described in the <a href="https://github.com/quantum13/mlbootcamp5/blob/master/install">install</a> file, and specify the settings in the <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/classes/config.py">config.py</a> : </p><br><p> Next, create the necessary tables in the database from the file with the <code>qml/db/schema.sql</code> , create files with the id train and test set ( <code>qml_workdir/data/ids_test.csv</code> , <code>qml_workdir/data/ids_train.csv</code> ) and files with the first version of the data ( <code>qml_workdir/data/v0001_test_x.csv</code> , <code>qml_workdir/data/v0001_train_x.csv</code> , <code>qml_workdir/data/train_y.csv</code> ).  How to do this leave outside the scope of this article. </p><br><p>  Now create a file <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/work.py">work.py</a> , in which we write the code below and run it </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># imports cv = QCV(qm) print(cv.cross_val(1, 1)) qm.qpredict(1, 1)</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">The output will be something like this:</b> <div class="spoiler_text"><pre>     1 0.545776154551
     2 0.545405471315
     3 0.543444368229
     4 0.539330473549
     5 0.537107693689
 0.542212832267
</pre></div></div><br><p>  In three lines of code we: </p><br><ul><li>  held a crossvalidation on 5 folds (hardcode) of model No. 1 from the <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/classes/models.py">models.py</a> file </li><li>  fixed splitting to fold, so that later it was convenient to compare the results </li><li>  saw the result of each fold and the average result for the folds </li><li>  saved the results of cross-qualification in the database (see <code>qml_results</code> and <code>qml_results_statistic</code> ) </li><li>  received a prediction file for test set ( <code>qml_workdir/data/res/m0000001_d001__tr_70000_ts_30000__h_29c96aaed585f02e30096f265faca72c_s_1000.csv</code> ) </li></ul><br><p>  Delete the column with id and title and send it to the contest website.  The result will be something like this: </p><br><img src="https://habrastorage.org/web/df5/b6e/c16/df5b6ec169f947b6846590538cb80153.png"><br><p><br>  With such a result, we would be on 497 place on the public board, and on the private board on 484 place. </p><br><p>  Well, not enough.  It's time to look at the data. </p><br><p>  We see that in the fields <code>weight</code> , <code>height</code> , <code>ap_hi</code> and <code>ap_lo</code> there are a lot of incomprehensible data, we <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/data.ipynb">clean them</a> , we add the <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D0%25BD%25D0%25B4%25D0%25B5%25D0%25BA%25D1%2581_%25D0%25BC%25D0%25B0%25D1%2581%25D1%2581%25D1%258B_%25D1%2582%25D0%25B5%25D0%25BB%25D0%25B0">body mass index</a> and the BMI classes from the table. </p><br><p>  In the test set, some subjective signs were removed, looking at the distribution of the values ‚Äã‚Äãof these columns, replace <code>NaN</code> in active by 1, in smoke and alco by 0. We already have the 6th version of the data. </p><br><p>  By the way, do not be surprised at such an activity among people of that age, so that during the clinical examination you are recorded as active, you only need to walk more than half an hour a day. </p><br><div class="spoiler">  <b class="spoiler_title">Run the cross-issue on the new data and prepare a file for sending:</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># imports cv = QCV(qm) print(cv.cross_val(1, 6)) qm.qpredict(1, 6)</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Conclusion:</b> <div class="spoiler_text"><pre>     1 0.545776154551
     2 0.545405471315
     3 0.543444368229
     4 0.539330473549
     5 0.537107693689
 0.542212832267
</pre></div></div><br><p>  Result: </p><br><img src="https://habrastorage.org/web/6f0/cc1/754/6f0cc1754a904f0cbbd3667f8786d6b5.png"><br><p><br>  477 on the public board and 470 on the private, C - stability :) But we have little stability, in this hot summer we need to go in cool black T-shirts. </p><br><p>  Both times we <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/classes/models.py">ran the</a> data through <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/classes/models.py">xgboost with the parameters set at random</a> .  We select the optimal parameters of the model using <a href="https://github.com/hyperopt/hyperopt">hyperopt</a> . </p><br><p>  <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level1_models_xgb1.py">An example of the</a> selection of parameters.  From the interesting in the script: </p><br><ul><li>  <code>DATAS = [6]</code> - you can tyunit on several versions of data at once </li><li>  The <code>early_stop_cv</code> parameter stops <code>early_stop_cv</code> with the current parameters and returns the result of the current fold, if the callback returns <code>True</code> , it is convenient to manually sort the folds in the saved partitions so that the fold with the highest CV score goes first.  Then you can filter out unsuccessful models without waiting for validation for all folds </li><li>  <code>num_boost_rounds</code> and <code>eta</code> <code>num_boost_rounds</code> through in 1.3 steps </li><li>  <code>model_id = qm.add_by_params(..</code> add to the database a model with such parameters so that it can later be loaded by number </li><li>  <code>tree_method='hist'</code> - for haters of Microsoft products </li><li>  <code>seed=1000</code> - we run each model by 8 sidam to reveal stability </li><li>  the results of predictions of each fold from the splits for each sid are saved, which will be useful later for metamodels </li></ul><br><p>  Leaving the selection of parameters for the night in the morning, you can see what we have learned with the help of </p><br><div class="spoiler">  <b class="spoiler_title">mysql query</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> data_id, model_id, <span class="hljs-keyword"><span class="hljs-keyword">max</span></span>(cv_diff), <span class="hljs-keyword"><span class="hljs-keyword">max</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">std</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(sum_sc)/<span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(cnt), <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(cnt), r.cv_time, m.cls, m.level, m.params <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> model_id, fold, data_id, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(cv_score) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sum_sc, <span class="hljs-keyword"><span class="hljs-keyword">std</span></span>(cv_score) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-keyword"><span class="hljs-keyword">std</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">max</span></span>(cv_score)-<span class="hljs-keyword"><span class="hljs-keyword">min</span></span>(cv_score) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cv_diff, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cnt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> qml_results_statistic <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> model_id, data_id, fold ) q <span class="hljs-keyword"><span class="hljs-keyword">left</span></span> <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> qml_results r <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (model_id, data_id) <span class="hljs-keyword"><span class="hljs-keyword">left</span></span> <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> qml_models m <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (model_id) <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> data_id, model_id <span class="hljs-keyword"><span class="hljs-keyword">order</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(sum_sc)/<span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(cnt) <span class="hljs-keyword"><span class="hljs-keyword">limit</span></span> <span class="hljs-number"><span class="hljs-number">10000</span></span>;</code> </pre> </div></div><br><p>  Approximate result: </p><br><img src="https://habrastorage.org/web/0b7/e40/714/0b7e40714276441db5568058485cf657.png"><br><p><br>  We see that the model 1255 is better in CV, but the spread of one fold among 8 sids is greater.  Further to check the addition of signs we will use the model 1395, as the most stable of those found. </p><br><p>  Since  CV score has improved significantly, try sending: </p><br><img src="https://habrastorage.org/web/a16/bc3/b1a/a16bc3b1a03143738ac352bf9f7545b6.png"><br><p><br>  Oh, 161 places on public leaderboard and 164 places on private!  Better than Lev Litrovodochkin, who was in seventh in public, Vladimir Omelchenko (tenth) and Andriy Parkov (fourteenth). </p><br><p>  It's time to overtake <a href="https://www.linkedin.com/in/venheads/">Valery Babushkina</a> ! </p><br><p>  Let's create the <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/data.ipynb">twentieth version of the data</a> , in which we add columns with alternate addition, subtraction, multiplication and division of combinations of two and three of the available columns. </p><br><p>  If we drive our model on new data, the result will be worse than without them (If I knew about it during bootcamp 3 ..).  it is necessary to add new columns one by one, to start cross-qualification and leave only if the result has improved. </p><br><p>  Let's feed the resulting data to a <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/data_work/feat_sel_12.py">similar script</a> by specifying the available columns as the third parameter, the fourth columns that need to be checked. </p><br><p>  From the interesting: </p><br><ul><li>  <code>QAvgOneModelData(model_id, 8)</code> - we run the crossvalidation not of the initial model, but averaging the predictions of the initial model with 8 different views for greater stability </li><li>  <code>early_stop_cv</code> - again we do not chase all partitions </li><li>  <code>log_file='qml_workdir/logs/feat12.txt'</code> - write the result of the work in the log file, sorting out which you can easily get the best column of the current run. </li></ul><br><p>  As a result, we found out that by adding columns below (47th version of the data), CV improves: </p><br><div class="spoiler">  <b class="spoiler_title">Columns</b> <div class="spoiler_text"><ul><li> <code>x__age__gluc_all</code> </li> <li> <code>x__ap_hi__cholesterol_all</code> </li> <li>  <code>div6__height__gluc_all__imt</code> - <code>1/height/gluc_all*imt</code> </li><li> <code>plus__age_norm__ap_hi_norm__gluc_all_norm</code> </li> <li> <code>x__age__weight</code> </li> <li>  <code>div1__age__weight__cholesterol_all</code> - <code>age*weight/cholesterol_all</code> </li><li>  <code>div6__age__weight__cholesterol_all</code> - <code>1/age/weight*cholesterol_all</code> </li><li> <code>plus__height_norm__weight_norm__gluc_all_norm</code> </li> <li>  <code>div1__ap_hi__ap_lo__cholesterol_all</code> - <code>ap_hi*ap_lo/cholesterol_all</code> </li><li>  <code>div6__ap_hi__ap_lo__cholesterol_all</code> - <code>1/ap_hi/ap_lo*cholesterol_all</code> </li><li> <code>plus__age_norm__gluc_all_norm__imt_norm</code> </li> <li> <code>minus6__ap_hi_norm__ap_lo_norm__cholesterol_all_norm</code> </li> <li> <code>minus1__ap_hi_norm__ap_lo_norm__cholesterol_all_norm</code> </li> <li> <code>minus6__age_norm__ap_lo_norm__cholesterol_all_norm</code> </li> <li> <code>minus1__age_norm__ap_lo_norm__cholesterol_all_norm</code> </li> <li>  <code>div6__height__weight__ap_lo</code> - <code>1/height/weight*ap_lo</code> </li><li> <code>div2__ap_lo__cholesterol_all__gluc_all</code> </li> <li> <code>x__age__ap_hi__gluc_all</code> </li> <li> <code>div5__ap_lo__cholesterol_all__gluc_all</code> </li> </ul></div></div><br><p>  Well, at least there was no imt * height * height column in this list. </p><br><p>  Let's run our model on new data: </p><br><img src="https://habrastorage.org/web/905/710/f24/905710f24f4c4b03bd7547d63fb553c2.png"><br><p><br>  Oooh, 40 place on public and 81 on private.  Valery is far behind, but oil chat hypnotists are looming ahead.  Need to catch up. </p><br><p>  Sit down to brainstorm: </p><br><ul><li>  We take KMeans from the <a href="https://habrahabr.ru/post/270367/">reference book</a> </li><li>  We study the <a href="http://www.garant.ru/products/ipo/prime/doc/70229844/">subject</a> and find the <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B5%25D1%2580%25D0%25B4%25D0%25B5%25D1%2587%25D0%25BD%25D0%25BE-%25D1%2581%25D0%25BE%25D1%2581%25D1%2583%25D0%25B4%25D0%25B8%25D1%2581%25D1%2582%25D1%258B%25D0%25B9_%25D1%2580%25D0%25B8%25D1%2581%25D0%25BA">SCORE scale</a> </li><li>  We google how else it is possible to generate features, we find how <a href="https://youtu.be/drUToKxEAUA%3Ft%3D247">people do it in Excel</a> </li></ul><br><p>  We implement all this (the 66th version of the data) and once again run the tuning of the model on the final data. </p><br><div class="spoiler">  <b class="spoiler_title">New best model</b> <div class="spoiler_text"><pre> <code class="python hljs">{<span class="hljs-string"><span class="hljs-string">"alpha"</span></span>: <span class="hljs-number"><span class="hljs-number">0.008</span></span>, <span class="hljs-string"><span class="hljs-string">"booster"</span></span>: <span class="hljs-string"><span class="hljs-string">"gbtree"</span></span>, <span class="hljs-string"><span class="hljs-string">"colsample_bylevel"</span></span>: <span class="hljs-number"><span class="hljs-number">0.6</span></span>, <span class="hljs-string"><span class="hljs-string">"colsample_bytree"</span></span>: <span class="hljs-number"><span class="hljs-number">1.0</span></span>, <span class="hljs-string"><span class="hljs-string">"eta"</span></span>: <span class="hljs-number"><span class="hljs-number">0.004</span></span>, <span class="hljs-string"><span class="hljs-string">"eval_metric"</span></span>: <span class="hljs-string"><span class="hljs-string">"logloss"</span></span>, <span class="hljs-string"><span class="hljs-string">"gamma"</span></span>: <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-string"><span class="hljs-string">"num_boost_round"</span></span>: <span class="hljs-number"><span class="hljs-number">2015</span></span>, <span class="hljs-string"><span class="hljs-string">"objective"</span></span>: <span class="hljs-string"><span class="hljs-string">"binary:logistic"</span></span>, <span class="hljs-string"><span class="hljs-string">"subsample"</span></span>: <span class="hljs-number"><span class="hljs-number">0.7</span></span>, <span class="hljs-string"><span class="hljs-string">"tree_method"</span></span>: <span class="hljs-string"><span class="hljs-string">"hist"</span></span>}</code> </pre> </div></div><br><p>  After that, <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/data_work/feat_sel_18_del_66.py">alternately, we throw out</a> one column and find out that without a column <code>div6__height__weight__ap_lo</code> CV score better and mercilessly throw it out (version 69). </p><br><p>  We will drive the new best single model on the initial data: </p><br><img src="https://habrastorage.org/web/687/05a/fad/68705afad60a461f93c46f1eef52e520.png"><br><p><br>  Public - 26, private - 50. Hurray!  The hypnotists got around, our shirt! </p><br><p>  It seems to be time to stop, but I want more.  Send averaging over 8 sidam of this model: </p><br><img src="https://habrastorage.org/web/51f/39b/0e9/51f39b0e9d9b426389db510676751976.png"><br><p><br>  Public - 21 places (these averaging were chosen as one of the solutions, can be found under ‚Ññ0109872 from the <a href="">dump</a> ), private - 34 places.  Hypnotists went around and in public. </p><br><p>  Good but not enough.  <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level1_models_extra1.py">Let's generate</a> <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level1_models_logregr1.py">different</a> <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level1_models_nn01.py">models</a> and <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level1_models_nn02.py">a</a> <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level1_models_rf1.py">little bit more</a> .  For some models, normalization and filling of NaN is performed. </p><br><p>  <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level2_models_avg_01.py">We average</a> and <a href="https://github.com/quantum13/mlbootcamp5/blob/master/qml_workdir/ensembling/level2_models_avg_02.py">stack the</a> best models on various data.  After this we once again average the best second-level models. </p><br><p>  From the interesting: </p><br><ul><li>  Since  results of cross-qualification of models are preserved, then miscalculation of averages occurs <br>  instantly </li><li>  The first calculation stacking for the model takes some time, then saved results are reused </li><li>  <a href="https://mlwave.com/kaggle-ensembling-guide/">Kaggle Ensembling Guide</a> </li><li>  <a href="https://alexanderdyakonov.wordpress.com/2017/03/10/c%25D1%2582%25D0%25B5%25D0%25BA%25D0%25B8%25D0%25BD%25D0%25B3-stacking-%25D0%25B8-%25D0%25B1%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B4%25D0%25B8%25D0%25BD%25D0%25B3-blending/">Stacking and Blending</a> </li><li>  Initially, I took xgboost and LogisticRegression as second-level models, but this did not work.  Then I remembered that <a href="https://www.linkedin.com/in/venheads/">Valery</a> Babushkin <a href="https://t.me/mailrucontests">in the chat</a> mentioned the ridge regression, when he was talking about <a href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing">Mercedes</a> , googled, found an article from the paragraph above, began using it as a second-level model and everything turned out.  And I bypassed it with a single xgboost.  It turned out badly. </li></ul><br><p>  My second final model is averaging 7 stacks on different numbers of models with different data.  If you are interested in cramming, then this is model number 109639 from <a href="">dump</a> </p><br><p>  On the public board, this model gave a worse result than just averaging over 8 sidims of various single xgboost, but I believed in crossvalidation and selected it.  From the xgboost averages, I chose such averaging so that the CV results on the folds were different from the stack model, i.e.  on some folds the stack model was noticeably better (-0.0001), on others it was noticeably worse </p><br><p>  Yes, the headline turned out to be yellow, it was not as easy as some of the winners: </p><br><p>  1 <a href="http://mlbootcamp.ru/forums/topic/18/%3Fpage%3D2">Nikita Churkin</a> <br>  2 <a href="https://github.com/shayakhmetov/mlbootcampV">Rome Shayakhmetov</a> <br>  3 <a href="https://github.com/ivan-filonov/mlbootcamp_5">Ivan Filonov</a> <br>  4 <a href="https://github.com/mortido/ML-Boot-Camp-V">Alexander I-MORTIDO by </a> <br>  9 <a href="https://github.com/tyamgin/mlbootcamp/tree/master/championship12">Ivan Tyamgin</a> (caution, <a href="https://github.com/tyamgin/mlbootcamp/tree/master/championship12">Rr</a> -r) </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/333554/">https://habr.com/ru/post/333554/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../333540/index.html">E-democracy or how to collect and process data on voting (and turnout) for renovation in Moscow</a></li>
<li><a href="../333544/index.html">How To Make Progressive Web Apps: A Beginner's Guide</a></li>
<li><a href="../333546/index.html">Translation of the Appium Essentials book. Chapter 6</a></li>
<li><a href="../333548/index.html">Testing the Mobile Delphi Application Database</a></li>
<li><a href="../333552/index.html">You don't know a damn thing in colors</a></li>
<li><a href="../333556/index.html">Hybrid Memory Cube (HMC): what it is and how to connect it to FPGA</a></li>
<li><a href="../333558/index.html">Features of the national SMS authorization</a></li>
<li><a href="../333560/index.html">Cisco Meeting Server - now all video conferencing from one place</a></li>
<li><a href="../333562/index.html">Cash gap: the main reason for closing stores with beginners</a></li>
<li><a href="../333564/index.html">Disable any items from our DOM tree using MutationObserver</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>