<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Textures for 64k intro: how it is done today</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article is the second part of our H-Immersion series . The first part can be read here: Immersion Immersion . 

 When creating an animation of on...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Textures for 64k intro: how it is done today</h1><div class="post__text post__text-html js-mediator-article">  <i>This article is the second part of our</i> <a href="http://www.ctrl-alt-test.fr/productions/h-immersion/"><i>H-Immersion</i></a> <i>series</i> <i>.</i>  <i>The first part can be read here:</i> <a href="https://habr.com/post/352970/"><i>Immersion Immersion</i></a> <i>.</i> <br><br>  When creating an animation of only 64 KB, it is difficult to use ready-made images.  We can not store them in the traditional way, because it is not efficient enough, even if you use compression, such as JPEG.  An alternative solution is procedural generation, that is, writing code that describes the creation of images during program execution.  Our implementation of this solution was a texture generator - a fundamental part of our toolchain.  In this post we will explain how it was developed and used in <a href="http://www.ctrl-alt-test.fr/%3Fpage_id%3D444"><i>H - Immersion</i></a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6a8/2ee/a7e/6a82eea7ea42a6ca5cf4b437545b3893.jpg"></div><br>  <i>Submarine floodlights illuminate the details of the seabed.</i> <br><a name="habracut"></a><br><h2>  Early version </h2><br>  Texture generation was one of the very first elements of our code base: procedural textures were already used in our first <a href="http://www.ctrl-alt-test.fr/%3Fpage_id%3D94"><i>B - Incubation</i></a> intro.  <a href="">The code</a> consisted of a set of functions that fill, filter, transform and combine textures, as well as one large loop that bypasses all textures.  These functions were written in pure C ++, but later the C API interaction was added so that they could be computed by the <a href="https://github.com/zsaleeba/picoc">PicoC</a> C <a href="https://github.com/zsaleeba/picoc">interpreter</a> .  At that time, we used PicoC to reduce the time taken for each iteration: this was the way we managed to change and reload textures during program execution.  Switching to subset C was a small sacrifice compared to the fact that now we could change the code and see the result immediately, without bothering to close, recompile, and reload the entire demo. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/70d/88e/4c9/70d88e4c948bfbd24f7d003b5a92f6af.png"></div><br>  <i>With the help of a simple pattern, a little noise and deformations, we can get a stylized wood texture.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e28/a67/83b/e28a6783bd53715bb1514bc6aa2c655f.jpg"></div><br>  <i>In this scene from the</i> F - Felix's workshop <i>various wood textures were used.</i> <br><br>  For a while we explored the possibilities of this generator, and as a result we put it on a web server with a small PHP script and a simple web interface.  We could write the texture code in the text field, and the script passed it to the generator, which then dumped the result as a PNG file for display on the page.  Very soon, we started sketching right at work during the lunch break and sharing our small masterpieces with other members of the group.  Such interaction strongly motivated us to the creative process. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f15/be6/722/f15be672247f38176102734d115a5001.png"></div><br>  <i>Web gallery of our old texture generator.</i>  <i>All textures can be edited in the browser.</i> <br><br><h2>  Full redesign </h2><br>  For a long time, the texture generator almost did not change;  we thought he was good, and our efficiency ceased to increase.  But once we discovered that there are a lot of <a href="http://polycount.com/discussion/145615/josh-lynch-substance-designer-sketchbook">artists</a> on Internet forums that demonstrate their fully procedurally generated textures, as well as arranging <a href="http://polycount.com/discussion/196297/the-bi-weekly-substance-challenge-challenge-16-17-18">challenges</a> on various topics.  Procedural content was once a "trick" of the demo scene, but <a href="https://www.allegorithmic.com/products/substance-designer">Allegorithmic</a> , <a href="https://www.shadertoy.com/">ShaderToy,</a> and similar tools made it available to the general public.  We did not pay attention to this, and they began to put us on the shoulder blades with ease.  Unacceptable! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/12a/7cb/e33/12a7cbe33257454ca8e23c53dd84ef00.jpg"></div><br>  <i><a href="https://www.artstation.com/artwork/gv9rL">Fabric Couch</a> .</i>  <i>Fully procedural fabric texture created by Substance Designer.</i>  <i>Posted by: Imanol Delgado.</i>  <i><a href="https://www.artstation.com/imanoldelgado">www.artstation.com/imanoldelgado</a></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b3e/25a/47e/b3e25a47ed73c407de4335f5e58cc87b.jpg" alt="image"></div><br>  <i><a href="https://www.artstation.com/artwork/evGD6">Forest Floor</a> .</i>  <i>Fully procedural forest soil texture created by Substance Designer.</i>  <i>Posted by: Daniel Thiger.</i>  <i><a href="https://www.artstation.com/dete">www.artstation.com/dete</a></i> <br><br>  We have long had to revise their tools.  Fortunately, many years of work with the same texture generator has allowed us to realize its shortcomings.  In addition, our nascent mesh generator also told us what the procedural content pipeline should look like. <br><br>  The most important architectural error was the implementation of generating as a set of operations with texture objects.  From a high-level perspective, this may be the right approach, but in terms of implementation, functions such as <b>texture.DoSomething ()</b> or <b>Combine (textureA, textureB)</b> have serious drawbacks. <br><br>  First, the OOP style requires declaring these functions as part of the API, no matter how simple they are.  This is a serious problem because it doesn‚Äôt scale well and, more importantly, creates unnecessary friction in the creative process.  We did not want to change the API every time we need to try something new.  This complicates experimentation and limits creative freedom. <br><br>  Secondly, from the point of view of performance, this approach requires processing texture data in cycles as many times as there are operations.  This would not be particularly important if these operations were expensive in terms of the cost of accessing large chunks of memory, but this is usually not the case.  With the exception of a very small fraction of operations, for example, <a href="https://mzucker.github.io/html/perlin-noise-math-faq.html">Perlin noise</a> generation or <a href="https://en.wikipedia.org/wiki/Flood_fill">filling</a> , they are basically very simple and require only a few instructions to a texture point.  That is, we circumvented texture data to perform trivial operations, which is extremely inefficient from the point of view of caching. <br><br>  The new structure solves these problems through the reorganization of logic.  Most of the functions in practice independently perform the same operation for each texture element.  Therefore, instead of writing the <b>texture.DoSomething ()</b> function, bypassing all the elements, we can write <b>texture.ApplyFunction (f)</b> , where <b>f (element)</b> works only for a single texture element.  Then <b>f (element)</b> can be written according to a specific texture. <br><br>  This seems like a minor change.  However, such a structure simplifies the API, makes the generation code more flexible and expressive, more cache-friendly, and allows parallel processing to be easy.  Many of the readers have already understood that this is essentially a shader.  However, the implementation in fact remains the C ++ code executed in the processor.  We still retain the ability to perform operations outside the cycle, but use this option only when necessary, for example, performing a convolution. <br><br><h3>  It was: </h3><br><pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//     . // API . //    -  API. //      . class ProceduralTexture { void DoSomething(parameters) { for (int i = 0; i &lt; size; ++i) { //   . (*this)[i] = ‚Ä¶ } } void PerlinNoise(parameters) { ‚Ä¶ } void Voronoi(parameters) { ‚Ä¶ } void Filter(parameters) { ‚Ä¶ } void GenerateNormalMap() { ‚Ä¶ } }; void GenerateSomeTexture(texture t) { t.PerlinNoise(someParameter); t.Filter(someOtherParameter); ‚Ä¶ //  .. t.GenerateNormalMap(); }</span></span></code> </pre> <br><h3>  It became: </h3><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//       . // API . //     . //      . class ProceduralTexture { void ApplyFunction(functionPointer f) { for (int i = 0; i &lt; size; ++i) { //    . (*this)[i] = f((*this)[i]); } } }; void GenerateNormalMap(ProceduralTexture t) { ‚Ä¶ } void SomeTextureGenerationPass(void* out, PixelInfo in) { result = PerlinNoise(in); result = Filter(result); ‚Ä¶ //  .. *out = result; } void GenerateSomeTexture(texture t) { t.ApplyFunction(SomeTextureGenerationPass); GenerateNormalMap(t); }</span></span></code> </pre> <br><h2>  Parallelization </h2><br>  It takes time to generate textures, and an obvious candidate to reduce this time is parallel code execution.  At the very least, you can learn to generate multiple textures at the same time.  This is what we did for the <a href="http://www.ctrl-alt-test.fr/%3Fpage_id%3D373"><i>F <em>-</em> Felix's workshop</i></a> , and this greatly reduced the load time. <br><br>  However, this does not save time where it is needed most.  Still, it takes a long time to generate one texture.  This also applies to the change when we continue to reload the texture again and again before each modification.  Instead, it is better to parallelize the internal code for generating textures.  Since now the code essentially consists of one large function applied in a loop to each texel, parallelization becomes simple and efficient.  Costs for experiments, customization and sketches are reduced, which directly affects the creative process. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ac9/cb7/21f/ac9cb721febdfc0b32300bb02f84fefe.jpg"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/191/c1e/a6d/191c1ea6de84670abe256fb67e7dc165.jpg"></div><br>  <i>Illustration of the idea explored and rejected by us for <a href="http://www.ctrl-alt-test.fr/%3Fpage_id%3D444"><i>H - Immersion</i></a> : mosaic decoration with orichalka veneer.</i>  <i>Here it is shown in our online editing tool.</i> <br><br><h2>  GPU Generation </h2><br>  If this is still not obvious, then I will say that texture generation is fully performed in the CPU.  Perhaps one of you is reading these lines now and wondering ‚Äúbut why ?!‚Äù.  It seems that the obvious step is to generate textures in the video processor.  For a start, it will increase the generation rate by an order of magnitude.  So why don't we use it? <br><br>  The main reason is that the goal of our small redesign was to stay on the CPU.  Going to a GPU would mean a lot more work.  We would have to solve additional problems for which we still do not have enough experience.  Working with the CPU, we have a clear understanding of what we want, and we know how to correct previous errors. <br><br>  However, the good news is that thanks to the new structure, experiments with GPUs now seem rather trivial.  Testing combinations of both types of processors will be an interesting experiment for the future. <br><br><h2>  Texture generation and physically accurate shading </h2><br>  Another limitation of the old design was that the texture was viewed only as an RGB image.  If we needed to generate more information, say diffuse texture and normal texture for the same surface, then nothing prevented us from doing this, but the API didn‚Äôt help much.  This has become particularly important in the context of <a href="http://lousodrome.net/blog/light/2011/12/27/readings-on-physically-based-rendering/">physically accurate shading</a> (Physically Based Shading, PBR). <br><br>  In a traditional conveyor without PBR, color textures are usually used, in which a lot of information is baked.  Such textures often represent the final appearance of the surface: they already have a certain volume, the cracks are darkened, and there may even be reflections on them.  If several textures are used at the same time, then large-scale and small-scale details are usually combined to add normal or reflectivity maps. <br><br>  In a PBR surface conveyor, usually sets of several textures are used that represent physical values, rather than the desired artistic result.  The diffuse color texture, which is closest to what is often called the "color" of the surface, is usually flat and uninteresting.  The color specular is determined by the refractive index of the surface.  Most of the details and variability are taken from the textures of normals and roughness (roughness) (which someone may consider to be the same, but with two different scales).  The perceived reflectivity of the surface becomes a consequence of its roughness level.  At this stage it will be more logical to think in terms of not textures, but materials. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2e6/ad2/e95/2e6ad2e9555afadc279ff0227d1ff54a.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c2d/3a4/71f/c2d3a471f7fb9a352db83454e0288a91.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/446/8d1/52c/4468d152ce8ba5b8a4f563c8cc428533.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b58/dad/d05/b58dadd05ca838c5fdc4ec5daec0855b.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6a8/2ee/a7e/6a82eea7ea42a6ca5cf4b437545b3893.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/156/2a7/53f/1562a753fe3172e4add501ed110d3f7d.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f1e/91d/c4e/f1e91dc4ec162b76e1ba139f22e0e1d9.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cf5/627/9e8/cf56279e8263eaea1411824f60d10503.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a9/525/b03/0a9525b03c6033b76587107f7a87a4bf.jpg"></div><br>  The new structure allows us to declare arbitrary pixel formats for textures.  By making it part of the API, we allow it to deal with all the boilerplate code.  After declaring the pixel format, we can focus on the creative code, without wasting any extra effort on processing this data.  At runtime, it will generate several textures and transparently transfer them to the GPU. <br><br>  In some PBR pipelines, diffuse and specular colors are not transmitted directly.  Instead, they use the parameters "base color" and "metalness", which has its advantages and disadvantages.  In <a href="http://www.ctrl-alt-test.fr/%3Fpage_id%3D444"><i>H - Immersion,</i></a> we use the diffuse + specular model, and the material usually consists of five layers: <br><br><ol><li>  Color Diffuse (RGB; 0: <a href="https://en.wikipedia.org/wiki/Vantablack">Vantablack</a> ; 1: <a href="https://en.wikipedia.org/wiki/Albedo">fresh snow</a> ). </li><li>  Specular color (RGB: the proportion of light reflected under 90 ¬∞, also known as <a href="https://seblagarde.wordpress.com/2013/04/29/memo-on-fresnel-equations/"><i>F0</i> or <i>R0</i></a> ). </li><li>  Roughness (A; 0: perfectly smooth; 1: similar to rubber). </li><li>  Normals (XYZ; unit vector). </li><li>  Relief elevation (A; used for parallax occlusion mapping). </li></ol><br>  When using information about the emission of light was added directly to the shader.  We did not find it necessary to have ambient occlusion, because in most scenes there is no ambient lighting at all.  However, I would not be surprised that we will have additional layers or other types of information, for example, anisotropy or opacity. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8b8/185/de9/8b8185de93298b085276109a8f30efef.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a2c/6bb/876/a2c6bb876297e1b0a21fbe8463e19b66.jpg"></div><br>  The images above show a recent experiment with generating local ambient occlusion based on height.  For each direction we travel a given distance and keep the greatest slope (height difference divided by the distance).  Then we calculate the occlusion from the average slope. <br><br><h2>  Restrictions and work for the future </h2><br>  As you can see, the new structure has become a major improvement over the old one.  In addition, she encourages creative expressiveness.  However, she still has limitations that we want to eliminate in the future. <br><br>  For example, although there were no problems with this intro, we noticed that memory allocation could be an obstacle.  When generating textures, one array of float values ‚Äã‚Äãis used.  With large textures with multiple layers, you can quickly come to a problem with memory allocation.  There are various ways to solve it, but they all have their drawbacks.  For example, we can generate textures indiscriminately, while scalability will be better, however, the implementation of some operations, such as convolutions, becomes less obvious. <br><br>  In addition, in this article, despite the use of the word "materials", we talked only about textures, but not about shaders.  However, the use of materials should lead to shaders.  This contradiction reflects the limitations of the existing structure: texture generation and shading are two separate parts separated by a bridge.  We tried to make this bridge as easy as possible to cross, but actually we want these parts to become one.  For example, if the material has both static and dynamic parameters, then we want to describe them in one place.  This is a complex topic and we do not yet know whether there will be a good solution, but let's not get ahead of ourselves. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a5/ee7/42d/0a5ee742d8f5f83b3f0255176caa90c3.jpg" alt="image"></div><br>  <i>An experiment to create a fabric texture similar to the one shown above by Imadol Delgado.</i> </div><p>Source: <a href="https://habr.com/ru/post/419007/">https://habr.com/ru/post/419007/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../418997/index.html">Real contribution to real open source</a></li>
<li><a href="../418999/index.html">[Announcement, Peter] Meeting JUG.ru with Andrey Belyaev and Alexey Stukalov ‚Äî Troll oppression CUBA: FAQ</a></li>
<li><a href="../419001/index.html">5 "super skills" necessary for the work of the future</a></li>
<li><a href="../419003/index.html">Digest news from the sphere of blockchain technologies</a></li>
<li><a href="../419005/index.html">Excursion to the substation 220/110/20</a></li>
<li><a href="../419009/index.html">clang and IDE: a story about friendship and foe</a></li>
<li><a href="../419011/index.html">Jinja2 in the world of C ++, part two. Rendering</a></li>
<li><a href="../419013/index.html">Funnel-based attribution for SaaS B2B businesses - as we considered the value of all marketing efforts</a></li>
<li><a href="../419017/index.html">What's new in ConstraintLayout 1.1</a></li>
<li><a href="../419019/index.html">AlterEgo: a device that can read (some) thoughts</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>