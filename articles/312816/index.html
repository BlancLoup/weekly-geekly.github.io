<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Scrolling endlessly scrolling page</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Scrolling endlessly scrolling page 


 Welcome to the Scrapy tips from the pros! This month we‚Äôll share a few tricks to help speed up your web scrapin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Scrolling endlessly scrolling page</h1><div class="post__text post__text-html js-mediator-article"><h1 id="skraping-beskonechno-prokruchivayuscheysya-stranicy">  Scrolling endlessly scrolling page </h1><br><p>  Welcome to the Scrapy tips from the pros!  This month we‚Äôll share a few tricks to help speed up your web scraping work.  As the leading maintainers of Scrapy, we face every obstacle you can imagine.  So do not worry - you are in safe hands.  Feel free to contact us on twitter or facebook with any suggestions for future articles. </p><br><p><img src="https://habrastorage.org/files/db2/9ac/2f7/db29ac2f70634f9b945d00288af74e57.png"></p><br><p>  In the era of one-page apps and tons of AJAX requests on one page, many websites have replaced the forward / back navigation button with a fancy mechanism for endless page scrolling.  Websites using this mechanism load a new entity each time a user reaches the end of the page while scrolling vertically (remember Twitter, Facebook, Google Images).  Even though <a href="https://www.smashingmagazine.com/2013/05/infinite-scrolling-lets-get-to-the-bottom-of-this/">UX experts</a> claim that the infinite scrolling mechanism provides an excessive amount of data for users, we see an increasing number of web pages resorting to providing an infinite list of results. <a name="habracut"></a></p><br><p>  One of the first things we do when developing our web scraper is that we are looking for user interface components on the site that contain links to the next page of results.  Unfortunately, such links are not presented on pages with endless scrolling. </p><br><p>  Although this scenario may seem like a classic case for JavaScript frameworks such as Splash or Selenium, it is really easy to implement.  All you need to do instead of simulating user interaction through one of those frameworks is to examine your browser's AJAX requests while scrolling the page and then recreate these requests in your spider in Scrapy. </p><br><p>  Let's use <a href="http://spidyquotes.herokuapp.com/scroll">Spidy Quotes</a> as an example and build a spider that gets all the elements listed on the page. </p><br><h2 id="inspektirovanie-stranicy">  Page inspection </h2><br><p> First of all, we need to understand how endless scrolling on the page works.  And we can do this using the Network panel in the developer tools in the browser.  Open the panel and scroll the page to see the requests sent by the browser: <br><img src="https://habrastorage.org/files/6b9/24a/cd1/6b924acd12124bdfb5a74d8e5f9191ef.png"><br>  Click on the request to view it in more detail.  As we can see, the browser sends a request for <code>/api/quotes?page=x</code> and receives a JSON object like this in the response: </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"has_next"</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"page"</span></span>:<span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-attr"><span class="hljs-attr">"quotes"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"author"</span></span>:{ <span class="hljs-attr"><span class="hljs-attr">"goodreads_link"</span></span>:<span class="hljs-string"><span class="hljs-string">"/author/show/1244.Mark_Twain"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"Mark Twain"</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"tags"</span></span>:[<span class="hljs-string"><span class="hljs-string">"individuality"</span></span>, <span class="hljs-string"><span class="hljs-string">"majority"</span></span>, <span class="hljs-string"><span class="hljs-string">"minority"</span></span>, <span class="hljs-string"><span class="hljs-string">"wisdom"</span></span>], <span class="hljs-attr"><span class="hljs-attr">"text"</span></span>:<span class="hljs-string"><span class="hljs-string">"Whenever you find yourself on the side of the ..."</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"author"</span></span>:{ <span class="hljs-attr"><span class="hljs-attr">"goodreads_link"</span></span>:<span class="hljs-string"><span class="hljs-string">"/author/show/1244.Mark_Twain"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"Mark Twain"</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"tags"</span></span>:[<span class="hljs-string"><span class="hljs-string">"books"</span></span>, <span class="hljs-string"><span class="hljs-string">"contentment"</span></span>, <span class="hljs-string"><span class="hljs-string">"friends"</span></span>], <span class="hljs-attr"><span class="hljs-attr">"text"</span></span>:<span class="hljs-string"><span class="hljs-string">"Good friends, good books, and a sleepy ..."</span></span> } ], <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-attr"><span class="hljs-attr">"top_ten_tags"</span></span>:[[<span class="hljs-string"><span class="hljs-string">"love"</span></span>, <span class="hljs-number"><span class="hljs-number">49</span></span>], [<span class="hljs-string"><span class="hljs-string">"inspirational"</span></span>, <span class="hljs-number"><span class="hljs-number">43</span></span>], ...] }</code> </pre> <br><p>  This is the information we need for our spider.  All you need to do in it is to generate requests for <code>/api/quotes?page=x</code> increasing <code>x</code> until the value of the <code>has_next</code> field becomes <code>false</code> .  The great thing about this is that we don‚Äôt even have to scrap the HTML content to get the data we need.  This is all contained in a beautiful machine-readable JSON format. </p><br><h2 id="postroenie-pauka">  Building a spider </h2><br><p>  Here is our spider.  It retrieves the target data from the content in JSON-format, which we received in response from the server.  This approach is simpler and more reliable than digging through the HTML tree of the page, hoping that changing the markup will not break our spiders. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scrapy <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SpidyQuotesSpider</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(scrapy.Spider)</span></span></span><span class="hljs-class">:</span></span> name = <span class="hljs-string"><span class="hljs-string">'spidyquotes'</span></span> quotes_base_url = <span class="hljs-string"><span class="hljs-string">'http://spidyquotes.herokuapp.com/api/quotes?page=%s'</span></span> start_urls = [quotes_base_url % <span class="hljs-number"><span class="hljs-number">1</span></span>] download_delay = <span class="hljs-number"><span class="hljs-number">1.5</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, response)</span></span></span><span class="hljs-function">:</span></span> data = json.loads(response.body) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.get(<span class="hljs-string"><span class="hljs-string">'quotes'</span></span>, []): <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> { <span class="hljs-string"><span class="hljs-string">'text'</span></span>: item.get(<span class="hljs-string"><span class="hljs-string">'text'</span></span>), <span class="hljs-string"><span class="hljs-string">'author'</span></span>: item.get(<span class="hljs-string"><span class="hljs-string">'author'</span></span>, {}).get(<span class="hljs-string"><span class="hljs-string">'name'</span></span>), <span class="hljs-string"><span class="hljs-string">'tags'</span></span>: item.get(<span class="hljs-string"><span class="hljs-string">'tags'</span></span>), } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[<span class="hljs-string"><span class="hljs-string">'has_next'</span></span>]: next_page = data[<span class="hljs-string"><span class="hljs-string">'page'</span></span>] + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> scrapy.Request(self.quotes_base_url % next_page)</code> </pre><br><p>  If you want to do something else, using the knowledge gained, then you can experiment with creating a spider for our blog, as it also uses an endless scrolling to load old posts </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  If you feel somewhat discouraged about the prospect of scraping websites with endless scrolling, then I hope you now feel more confident.  The next time you deal with a page based on AJAX call calls as a result of user actions, see what kind of request your browser makes and play it in your spider.  The response to the request is usually in JSON format, which makes your spider much easier. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/312816/">https://habr.com/ru/post/312816/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312800/index.html">Introducing 3CX V15 SP2 with Debian Linux 8 support</a></li>
<li><a href="../312806/index.html">How neural networks are now used: from research projects to entertainment services</a></li>
<li><a href="../312808/index.html">Project AirGig: Broadband Power Line Access</a></li>
<li><a href="../312810/index.html">Getting started in STM32CubeMX. Part 2</a></li>
<li><a href="../312814/index.html">Silicon Valley Etiquette</a></li>
<li><a href="../312818/index.html">A few thoughts on the job search algorithm</a></li>
<li><a href="../312820/index.html">Site to Zone Assignment list and Internet Explorer with Enhanced Security Configuration enabled</a></li>
<li><a href="../312822/index.html">Create and estimate the number of sudoku</a></li>
<li><a href="../312826/index.html">233 nuts for Cinderella: we select colors for the ‚Äúperfect‚Äù palette</a></li>
<li><a href="../312828/index.html">Cisco and Apple partnership for business mobility transformation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>