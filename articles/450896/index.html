<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Lab: set up lvm, raid on linux</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A small digression: this l \ r is synthetic. 


 Some tasks that are described here can be made much easier, but since the task of the l / r is to get...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Lab: set up lvm, raid on linux</h1><div class="post__text post__text-html js-mediator-article"><p>  A small digression: this l \ r is synthetic. </p><br><p>  Some tasks that are described here can be made much easier, but since the task of the l / r is to get acquainted with the functional raid, lvm, some operations are artificially complicated. </p><br><h2 id="trebovaniya-k-instrumentam-dlya-vypolneniya-lr">  Requirements for tools to perform l \ r: </h2><br><ul><li>  Virtualization tools, such as Virtualbox </li><li>  A linux installation image, for example <a href="">Debian9</a> </li><li>  Internet availability for downloading multiple packages </li><li>  Connect via ssh to the installed VM (optional) </li></ul><br><h2 id="vnimanie">  ATTENTION </h2><br><p>  This laboratory work is associated with such delicate matter as data integrity - this is an area that allows you to lose all your data because of the smallest error - one extra letter or digit. </p><br><p>  Since you are doing laboratory work, nothing threatens you, unless you have to start doing it again. </p><br><p>  In real life, everything is much more serious, so you should very carefully enter the names of the disks, understanding what you are doing with the current command and what disks you are working with. </p><a name="habracut"></a><br><p>  The second important point is the naming of disks and partitions: depending on the situation, the disk numbers may differ from the values ‚Äã‚Äãpresented in the teams in the laboratory work. <br>  So, for example, if you remove the sda ‚Äã‚Äãdisk from the array and then add a new disk, the new disk will be displayed in the system with the name sda.  If you reboot before adding a new disk, the new disk will have the name sdb, and the old one will become sda </p><br><p>  Lab work must be performed under the superuser (root) since most commands require elevated privileges and it does not make sense to constantly raise privileges through sudo. </p><br><h2 id="materialy-dlya-izucheniya">  Materials for study </h2><br><ul><li>  RAID </li><li>  Lvm </li><li>  Disk naming in Linux </li><li>  What is a section </li><li>  What is a partition table and where is it stored </li><li>  What is grub </li></ul><br><h2 id="ispolzuemye-utility">  Utilities Used </h2><br><ol><li>  View disk information: <br><ul><li>  lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT </li><li>  fdisk -l </li></ul></li><li>  View information and work with LVM <br><ul><li>  pvs </li><li>  pvextend </li><li>  pvcreate </li><li>  pvresize </li><li>  vgs </li><li>  vgreduce </li><li>  lvs </li><li>  lvextend </li></ul></li><li>  View information and work with RAID: <br><ul><li>  at / proc / mdstat </li><li>  mdadm </li></ul></li><li>  Mount points: <br><ul><li>  mount </li><li>  umount </li><li>  cat / etc / fstab </li><li>  cat / etc / mtab </li></ul></li><li>  Disk re-partitioning: <br><ul><li>  fdisk / dev / XXX </li></ul></li><li>  Copying sections: <br><ul><li>  dd if = / dev / xxx of = / dev / yyy </li></ul></li><li>  Work with partition table: <br><ul><li>  partx </li><li>  sfdisk </li><li>  mkfs.ext4 </li></ul></li><li>  Work with the loader: <br><ul><li>  grub-install / dev / XXX </li><li>  update-grub </li></ul></li><li>  misc <br><ul><li>  lsof </li><li>  apt </li><li>  rsync </li></ul></li></ol><br><h2 id="laboratornaya-rabota-sostoit-iz-3-h-chastey">  Laboratory work consists of 3 parts: </h2><br><ul><li>  Setting up a working system using lvm, raid. </li><li>  Emulation of one disk failure. </li><li>  Replacing disks on the fly, with the addition of new disks and transfer partitions. </li></ul><br><h2 id="zadanie-1-ustanovka-os-i-nastroyka-lvm-raid">  Task 1 (Installing the OS and configure LVM, RAID) </h2><br><ol><li><p>  Create a new virtual machine with the following characteristics: </p><br><ul><li>  1 gb ram </li><li>  1 cpu </li><li>  2 hdd (call them ssd1, ssd2 and assign an equal size, tick hot swap and ssd) </li><li>  The SATA controller is configured for 4 ports: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18f/6f5/be6/18f6f5be6afbc13138abc3dfe960813b.png" alt="select ssd disks"></li></ul><br></li><li><p>  Start installing Linux and go to the choice of hard drives to do the following: </p><br><ul><li>  Partitioning method: manual, after which you should see this picture: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/77a/eb5/3a1/77aeb53a1de2bc7b91d1396dc9b4148e.png" alt="partition disks"></li><li>  Setting up a separate partition under / boot: Select the first disk and create a new partition table on it: <br><ul><li>  Partition size: 512M </li><li>  Mount point: / boot </li></ul></li><li>  Repeat the setup for the second disk, but since you cannot mount / boot 2 times at the same time, select mount point: none as a result having received the following (picture with a joint, redoing laziness): 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/3db/2f0/e48/3db2f0e48423f182016bde06c39dfb8d.png" alt="partition disks"></li><li>  RAID configuration: </li><li>  Select the free space on the first disk and set the partition type as physical volume for RAID </li><li>  Select "Done setting up the partition" </li><li>  Repeat the exact same setup for the second disk, resulting in the following: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/93f/37c/ec3/93f37cec319d628a3267f94d138145e7.png" alt="partition disks"></li><li>  Select "Configure software RAID" <br><ul><li>  Create MD device </li><li>  Software RAID device type: Choose a mirror array </li><li>  Active devices for the RAID XXXX array: select both drives </li><li>  Spare devices: Leave 0 by default </li><li>  Active devices for the RAID XX array: select partitions that you created under the raid </li><li>  Finish </li></ul></li><li>  As a result, you should get this picture: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7a7/9b0/3f5/7a79b03f556925d1fd53ccc4ca77b494.png" alt="partition disks"></li><li>  LVM Setup: Select Configure the Logical Volume Manager </li><li>  Keep current partition layout and configure LVM: Yes </li><li>  Create volume group </li><li>  Volume group name: system </li><li>  Devices for the new volume group: Choose your created RAID </li><li>  Create logical volume <br><ul><li>  logical volume name: root </li><li>  logical volume size: 2 \ 5 of the size of your disk </li></ul></li><li>  Create logical volume <br><ul><li>  logical volume name: var </li><li>  logical volume size: 2 \ 5 of the size of your disk </li></ul></li><li>  Create logical volume <br><ul><li>  logical volume name: log </li><li>  logical volume size: 1 \ 5 of the size of your disk </li></ul></li><li>  Selecting the Display configuration details you should get the following picture: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b8/8dd/11f/0b88dd11f9372dbf8e53a6727fc69b27.png" alt="partition disks"></li><li>  After completing the LVM setup, you should see the following: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/72b/9d4/00d/72b9d400d9b83392c759b7aeb3e9d573.png" alt="partition disks"></li><li>  Partition partitioning: in turn, select each volume created in LVM and mark them up, for example, for root like this: <br><ul><li>  Use as: ext4 </li><li>  mount point: / </li></ul></li><li>  The result of the markup of the root partition should be: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/225/61e/0be/22561e0be2cd905e0948a63ae3460461.png" alt="partition disks"></li><li>  Repeat the markup operation for var and log by selecting the appropriate mount points (/ var / log / log manually enter), obtaining the following result: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5da/58c/756/5da58c756fd8d205a93ebfd49acc396f.png" alt="partition disks"></li><li>  Select Finish Partitioning </li><li>  You will be asked a few questions about the fact that you have an unmounted partition and not set up swap.  It is necessary to answer negatively to both questions. </li><li>  The final result should be like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/117/381/a61/117381a61b766df3c89d2646baa2b33d.png" alt="partition disks"></li></ul><br></li><li><p>  Finish the OS installation by installing grub on the first device (sda) and boot the system. </p><br></li><li><p>  Copy the contents of the / boot partition from the sda ‚Äã‚Äãdisk (ssd1) to the sdb disk (ssd2) </p><br><pre><code class="plaintext hljs">dd if=/dev/sda1 of=/dev/sdb1</code> </pre> <br></li><li><p>  Install grub on the second device: </p><br><ul><li><p>  View drives in the system: </p><br><pre> <code class="plaintext hljs">fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li>  List all the disks that the previous command issued to you and describe what kind of disk it is. </li><li><p>  Find the disk on which grub was not installed and perform this installation: </p><br><pre> <code class="plaintext hljs">grub-install /dev/sdb</code> </pre> <br></li><li>  View the current raid information with cat / proc / mdstat and record what you see. </li><li>  Look at the conclusions of the commands: pvs, vgs, lvs, mount and write down exactly what you saw. </li></ul><br></li></ol><br><p>  Describe in your own words what you have done and what result you received as a result of the task done. </p><br><p>  After completing this task, it is recommended to save a backup of the folder with the virtual machine or make a <a href="https://t.me/bykvaadm/191">vagrant box</a> . </p><br><p>  Result: Virtual machine with ssd1, ssd2 disks. </p><br><h2 id="zadanie-2-emulyaciya-otkaza-odnogo-iz-diskov">  Task 2 (Emulation of failure of one of the disks) </h2><br><ol><li>  If you tick the hot swap, then you can delete disks on the fly: <br><ul><li>  Delete the ssd1 drive in the properties of the machine. </li><li>  Locate the directory where your virtual machine files are stored and delete ssd1.vmdk. </li></ul></li><li>  Make sure your virtual machine is still running. </li><li>  Restart the virtual machine and make sure it is still working. </li><li>  Check the status of the RAID: <code>cat /proc/mdstat</code> </li><li>  Add a new disk of the same size in the VM interface and name it ssd3. </li><li>  Perform operations: <br><ul><li>  See that the new disk came to the system with the <code>fdisk -l</code> </li><li>  Copy the partition table from the old disk to the new one: <code>sfdisk -d /dev/XXXX | sfdisk /dev/YYY</code> <code>sfdisk -d /dev/XXXX | sfdisk /dev/YYY</code> </li><li>  See the result with <code>fdisk -l</code> </li><li>  Add a new disk to the raid array: <code>mdadm --manage /dev/md0 --add /dev/YYY</code> </li><li>  See the result: <code>cat /proc/mdstat</code> .  You should see the sync start. </li></ul></li><li><p>  Now you need to manually synchronize non-RAID partitions.  To do this, use the dd utility, copying it from a live disk to a new one, which you recently installed: </p><br><pre> <code class="plaintext hljs">dd if=/dev/XXX of=/dev/YYY</code> </pre> <br></li><li>  After synchronization is complete, install grub to the new disk. </li><li>  Reboot the VM to make sure everything works. </li></ol><br><p>  Describe in your own words what you have done and what result you received as a result of the task done. </p><br><p>  <strong>Result: the</strong> ssd1 disk is deleted, the ssd2 disk is saved, the ssd3 disk is added. </p><br><h2 id="zadanie-3-dobavlenie-novyh-diskov-i-perenos-razdela">  Task 3 (Adding New Disks and Transfer Partitions) </h2><br><p>  This is the most difficult and voluminous task of all presented.  Very carefully check what you are doing and with what disks and partitions.  It is recommended to make a copy before making it.  This task, regardless of task number 2, can be performed after task number 1, adjusted for the names of the disks. </p><br><p>  The second part of the task of this laboratory should bring in exactly the same condition that was after the first part. </p><br><p>  In order to make it easier for you to work, I can recommend not to remove the physical disks from the host machine, but only to disconnect them in the properties of the machine.  From the point of view of the OS in the VM, it will look exactly the same, but in case of anything, you can connect the disk back and continue the work by rolling back a couple of points if you have problems.  For example, you might have done wrong or forgot to copy the / boot partition to a new disk.  I can only advise you to recheck several times with which disks and partitions you are working, and even better to write out on a piece of paper the correspondence of disks, partitions and the "physical" disk number.  The <code>lsblk</code> command draws a beautiful and clear tree, use it as often as possible to analyze what you have done and what you need to do. </p><br><p>  To the story ... </p><br><p>  Imagine that your server worked for a long time on 2 ssd disks, when suddenly ... </p><br><ol><li><p>  Emulate ssd2 disk failure by removing the disk from the properties of the VM and rebooting. </p><br></li><li><p>  View the current status of disks and RAID: </p><br><pre> <code class="plaintext hljs">cat /proc/mdstat fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  You were lucky - the authorities allowed to buy several new CDs: </p><br><p>  2 SATA large volume for the long overdue task of making a partition with logs on a separate disk.  2 SSD for the replacement of the deceased, as well as the replacement is still functioning. </p><br><p>  It should be noted that the server cart supports the installation of only 4 discs.  at the same time, therefore it is impossible to add all the disks at once </p><br><p>  HDD volume to choose 2 times more than SSD. <br>  SSD volume to choose 1.25 times the former SSD. </p><br></li><li><p>  Add one new ssd disk, calling it ssd4, and after adding, check what happened: </p><br><pre> <code class="plaintext hljs">fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  First of all, you should take care to preserve the data of the old disk.  This time we will transfer data using LVM: </p><br><ul><li><p>  First of all, you need to copy the file table from the old disk to the new one: </p><br><pre> <code class="plaintext hljs">sfdisk -d /dev/XXX | sfdisk /dev/YYY</code> </pre> <br><p>  Substitute the correct disks instead of x, y and disassemble what this command does. </p><br></li><li>  Run the lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT command and compare its output with the previous call.  What has changed? </li><li><p>  Using the dd command, copy the / boot data to a new disk: </p><br><pre> <code class="plaintext hljs">dd if=/dev/XXX of=/dev/YYY</code> </pre> <br></li><li><p>  If / boot remains mounted on the old disk, it should be remounted on a live disk: </p><br><pre> <code class="bash hljs">mount | grep boot <span class="hljs-comment"><span class="hljs-comment">#     lsblk #           ,     umount /boot #  /boot mount -a #      /etc/fstab. #      /dev/sda,        </span></span></code> </pre> <br></li><li><p>  Install the bootloader on a new ssd disk: </p><br><pre> <code class="plaintext hljs">grub-install /dev/YYY</code> </pre> <br><p>  Why do we perform this operation? </p><br></li><li><p>  Create a new raid array with the inclusion of only one new ssd disk: </p><br><pre> <code class="plaintext hljs">mdadm --create --verbose /dev/md63 --level=1 --raid-devices=1 /dev/YYY</code> </pre> <br><p>  The command above will not work without a special key. Read the help and add this key to the command. </p><br></li><li>  Use the cat / proc / mdstat command to verify the result of your operation.  What has changed? </li><li>  Run the lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT command and compare its output with the previous call.  What has changed? </li></ul><br></li><li><p>  The next step is to configure LVM </p><br><ul><li>  Run the pvs command to view information about current physical volumes. </li><li><p>  Create a new physical volume to include a previously created RAID array: </p><br><pre> <code class="plaintext hljs">pvcreate /dev/md63</code> </pre> <br></li><li>  Run the lsblk -o NAME, SIZE, FSTYPE, TYPE, MOUNTPOINT command and compare its output with the previous call.  What has changed? </li><li>  Run the pvs command again.  What has changed? </li><li><p>  Increase the size of the Volume Group system using this command: </p><br><pre> <code class="plaintext hljs">vgextend system /dev/md63</code> </pre> <br></li><li><p>  Execute commands and write down what you see and what has changed. </p><br><pre> <code class="plaintext hljs">vgdisplay system -v pvs vgs lvs -a -o+devices</code> </pre> <br><p>  On which physical disk are LV var, log, root now? </p><br></li><li><p>  Move the data from the old disk to the new one by substituting the correct device names. </p><br><pre> <code class="plaintext hljs">pvmove -i 10 -n /dev/system/root /dev/md0 /dev/md63</code> </pre> <br><p>  Repeat the operation for all logical volume. </p><br></li><li><p>  Execute commands and write down what you see and what has changed. </p><br><pre> <code class="plaintext hljs">vgdisplay system -v pvs vgs lvs -a -o+devices lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  Change our VG by removing the old raid disk from it.  Substitute the correct raid name. </p><br><pre> <code class="plaintext hljs">vgreduce system /dev/md0</code> </pre> <br></li><li><p>  Execute commands and write down what you see and what has changed. </p><br><pre> <code class="plaintext hljs">lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT pvs vgs</code> </pre> <br></li><li>  For the beauty of the picture, remount / boot to the second ssd disk (ssd4) and execute lsblk.  As a result, nothing should be mounted on the ssd3 disk.  Carefully check that the / boot partition is not empty!  <code>ls /boot</code> should show multiple files and folders.  Examine what is stored in this section and write down what file \ directory for what is responsible. </li></ul><br></li><li><p>  Remove the ssd3 disk and add ssd5, hdd1, hdd2 according to the above TK, eventually getting: </p><br><ul><li>  ssd4 - the first new ssd </li><li>  ssd5 - second new ssd </li><li>  hdd1 - the first new hdd </li><li>  hdd2 - second new hdd </li></ul><br></li><li><p>  Check what happened after adding the disks: </p><br><pre> <code class="plaintext hljs">fdisk -l lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li><li><p>  Restore the operation of the main raid array: </p><br><ul><li><p>  Copy the partition table, substituting the correct disks: </p><br><pre> <code class="plaintext hljs">sfdisk -d /dev/XXX | sfdisk /dev/YYY</code> </pre> <br></li><li><p>  Please note that when we copied the partition table from the old disk, it was said that the new size does not use the entire volume of the hard disk.  Therefore, soon we will need to change the size of this section and expand the raid.  See for yourself by entering the command: </p><br><pre> <code class="plaintext hljs">lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li></ul><br></li><li><p>  Copy the boot partition from the ssd4 disk to ssd5: </p><br><pre> <code class="plaintext hljs">dd if=/dev/XXX of=/dev/YYY</code> </pre> <br></li><li><p>  Install grub to a new disk (ssd5). </p><br></li><li><p>  Change the size of the second partition of the ssd5 drive. </p><br><ul><li><p>  Run the disk layout utility: </p><br><pre> <code class="plaintext hljs">fdisk /dev/XXX</code> </pre> <br></li><li>  Enter key d to delete the existing partition (select 2). </li><li>  Enter the key n to create a new partition. </li><li>  Enter the p key to specify the primary partition type. </li><li>  Enter key 2 for the new partition to have a second number. </li><li>  First sector: press enter to accept the automatically calculated size of the beginning of the section. </li><li>  Last sector: press enter to accept the automatically calculated end-of-partition size. </li><li>  Enter the key l to see a list of all possible partition types and find the Linux raid auto in it. </li><li>  Enter the key t to change the type of the created partition (2) and enter the number found in the previous step. </li><li>  Enter the key w to write the change to the disk. </li></ul><br></li><li><p>  Re-read the partition table and check the result: </p><br><pre> <code class="plaintext hljs">partx -u /dev/XXX lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br><ul><li><p>  Add a new disk to the current raid array (do not forget to substitute the correct disks): </p><br><pre> <code class="plaintext hljs">mdadm --manage /dev/md63 --add /dev/sda2</code> </pre> <br></li><li><p>  Expand the number of disks in our array to 2 pieces: </p><br><pre> <code class="plaintext hljs">mdadm --grow /dev/md63 --raid-devices=2</code> </pre> <br></li><li><p>  See the result: we have 2 arrays marked up, but both sections included in this array have different sizes: </p><br><pre> <code class="plaintext hljs">lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br></li></ul><br></li><li><p>  Increase partition size on ssd4 disk </p><br><ul><li><p>  Run the disk layout utility: </p><br><pre> <code class="plaintext hljs">fdisk /dev/XXX</code> </pre> <br></li><li>  Enter key d to delete the existing partition (select 2). </li><li>  Enter the key n to create a new partition. </li><li>  Enter the p key to specify the primary partition type. </li><li>  Enter key 2 for the new partition to have a second number. </li><li>  First sector: press enter to accept the automatically calculated size of the beginning of the section. </li><li>  Last sector: press enter to accept the automatically calculated end-of-partition size. </li><li>  At the end of the markup, select No to leave the signature of the partition belonging to the array. </li><li>  Enter the key w to write the change to the disk. </li></ul><br></li><li><p>  Re-read the partition table and check the result. </p><br><pre> <code class="plaintext hljs">partx -u /dev/XXX lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT</code> </pre> <br><p>  Notice that now the sda2, sdc2 partitions are larger than the size of the raid device. </p><br></li><li><p>  At this stage, the raid size can now be expanded: </p><br><pre> <code class="bash hljs">mdadm --grow /dev/md63 --size=max lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT <span class="hljs-comment"><span class="hljs-comment"># check result</span></span></code> </pre> <br><p>  View lsblk and write down what has changed. </p><br></li><li><p>  However, even though we changed the raid size, the sizes of vg root, var, log themselves have not changed </p><br><ul><li><p>  Look at what size PV equals: </p><br><pre> <code class="bash hljs">pvs</code> </pre> <br></li><li><p>  Expand the size of our PV: </p><br><pre> <code class="bash hljs">pvresize /dev/md63</code> </pre> <br></li><li><p>  Look at what size PV equals: </p><br><pre> <code class="bash hljs">pvs</code> </pre> <br></li></ul><br></li><li><p>  Add the newly appeared place VG var, root: </p><br><pre> <code class="bash hljs">lvs <span class="hljs-comment"><span class="hljs-comment">#     lvextend -l +50%FREE /dev/system/root lvextend -l +100%FREE /dev/system/var lvs #   </span></span></code> </pre> <br><p>  At this stage, you have completed the migration of the main array to new disks.  Work with ssd1, ssd2 is over. </p><br></li><li><p>  Our next task is to move / var / log to new disks, for this we will create a new array and lvm on hdd disks. </p><br><ul><li><p>  Let's see what names the new hdd drives have: </p><br><pre> <code class="bash hljs">fdisk -l</code> </pre> <br></li><li><p>  Create a raid array: </p><br><pre> <code class="bash hljs">mdadm --create /dev/md127 --level=1 --raid-devices=2 /dev/sdc /dev/sdd</code> </pre> <br></li><li><p>  Create a new PV on the raid of large disks: </p><br><pre> <code class="bash hljs">pvcreate data /dev/md127</code> </pre> <br></li><li><p>  Create a group in this PV called data: </p><br><pre> <code class="bash hljs">vgcreate data /dev/md127</code> </pre> <br></li><li><p>  Create a logical volume the size of the entire free space and call it val_log: </p><br><pre> <code class="bash hljs">lvcreate -l 100%FREE -n var_log data <span class="hljs-comment"><span class="hljs-comment"># lvs #  </span></span></code> </pre> <br></li><li><p>  Format the created partition in ext4: </p><br><pre> <code class="bash hljs">mkfs.ext4 /dev/mapper/data-var_log</code> </pre> <br></li><li><p>  Let's see the result: </p><br><pre> <code class="bash hljs">lsblk</code> </pre> <br></li></ul><br></li><li><p>  Transfer the log data from the old section to the new one </p><br><ul><li><p>  Mount temporarily new log repository: </p><br><pre> <code class="plaintext hljs">mount /dev/mapper/data-var_log /mnt</code> </pre> <br></li><li><p>  Perform partition synchronization: </p><br><pre> <code class="bash hljs">apt install rsync rsync -avzr /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/ /mnt/</code> </pre> <br></li><li><p>  Find out what processes are currently working with / var / log: </p><br><pre> <code class="bash hljs">apt install lsof lsof | grep <span class="hljs-string"><span class="hljs-string">'/var/log'</span></span></code> </pre> <br></li><li><p>  We stop these processes: </p><br><pre> <code class="bash hljs">systemctl stop rsyslog.service syslog.socket</code> </pre> <br></li><li><p>  Perform the final synchronization of partitions (the data that may have changed since the last synchronization): </p><br><pre> <code class="bash hljs">rsync -avzr /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/ /mnt/</code> </pre> <br></li><li><p>  Swap the sections: </p><br><pre> <code class="bash hljs">umount /mnt umount /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span> mount /dev/mapper/data-var_log /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span></code> </pre> <br></li><li><p>  Checking what happened: </p><br><pre> <code class="bash hljs">lsblk</code> </pre> <br></li></ul><br></li><li><p>  Rule / etc / fstab </p><br><p>  fstab is a file in which the rules are written according to which partitions will be mounted at boot time.  Our task is to find the line in which the / var / log is mounted and fix the <code>system-log</code> device on the <code>data-var_log</code> . </p><br></li><li><p>  The most important thing at this stage is to remember to change the table of the sections (ext4, for example).  Since no matter how we change any raid, lvm, until the file system on the partition is notified that the partition size has now changed, we will not be able to use the new space.  Use the <code>resize2fs</code> command to change the file system. </p><br></li><li><p>  Final chord </p><br><ul><li>  Perform a reboot.  If you did everything correctly, you will again get into your OS (this is necessary in order to make sure that everything works. There is no point other than self-checking that this step does not carry) </li><li><p>  Perform checks that all we wanted to do was really done: </p><br><pre> <code class="bash hljs">pvs lvs vgs lsblk cat /proc/mdstat</code> </pre> <br></li></ul><br></li><li><p>  [OPTIONAL] Perform actions </p><br><ul><li>  Reboot by pressing F12 to specify different disks when loading, in order to make sure that you can boot from any of the ssd disks, so that we do not fear the failure of one of them. </li><li><p>  You now have an unnecessary LV log in the VG system.  Distribute this space between root or var, but instead of using the 100% FREE construction, specify the size with your hands using the -L switch: </p><br><pre> <code class="bash hljs">-L 500M</code> </pre> <br></li><li>  Correct the problem with the fact that / boot is on two partitions without synchronization, you don‚Äôt need to do this properly, here it is added as an example.  Do not forget to copy somewhere the contents of / boot. </li><li>  Create a new raid and include sda1, sda2. </li><li>  Include these partitions in the existing raid and restore / boot to the main raid, but not mounting it anymore. </li></ul><br></li></ol></div><p>Source: <a href="https://habr.com/ru/post/450896/">https://habr.com/ru/post/450896/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../450886/index.html">Background: how hydrogen cars work and when they will appear on the roads</a></li>
<li><a href="../450888/index.html">Swift: Eratosthenes Sieve</a></li>
<li><a href="../450890/index.html">Google News I / O 2019: Pixel 3a, Android Q, Kotlin, etc.</a></li>
<li><a href="../450892/index.html">Is storage speed suitable for etcd? Ask fio</a></li>
<li><a href="../450894/index.html">Pro antennas for the smallest</a></li>
<li><a href="../450898/index.html">Interface development on multiple screens. Step to using AI</a></li>
<li><a href="../4509/index.html">Yahoo collects "parcel" for aliens</a></li>
<li><a href="../450902/index.html">Want loyal employees - start with yourself</a></li>
<li><a href="../450906/index.html">How to start living and growing salad</a></li>
<li><a href="../450908/index.html">Black list of networks for Asterisk</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>