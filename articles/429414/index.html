<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Future VR Video - Google's VR180</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hint: this gif starts and stops on click 
 S3D: No pain IS gain 
 In April of this year, Google announced the technical details of the new format for ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Future VR Video - Google's VR180</h1><div class="post__text post__text-html js-mediator-article"><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Hint: this gif starts and stops on click</i> <br><h2>  S3D: No pain IS gain </h2><br>  In April of this year, Google announced the technical details of the new format for VR-video - <a href="https://www.extremetech.com/mobile/267271-google-opens-up-vr180-standard-for-virtual-reality-photos-and-videos">VR180</a> .  The format specifications were uploaded to the <a href="">Google</a> repository <a href="">on GitHub</a> , camera manufacturers were asked to make <a href="https://www.lenovo.com/us/en/virtual-reality-and-smart-devices/virtual-and-augmented-reality/lenovo-mirage-camera/Mirage-Camera/p/ZA3A0022US">special cameras</a> , the format was supported <a href="https://www.youtube.com/playlist%3Flist%3DPLU8wpH_Lfhmu_kk955BFwvV0yT0PEcenA">on YouTube</a> . <br><br>  The basic idea is quite simple.  In the "usual" VR-video - <a href="https://en.wikipedia.org/wiki/360-degree_video">360-video</a> - you can turn your head horizontally in all directions, while the main action takes place, as a rule, from one side or another, and the whole stream is transmitted to the device, which leads to transmission and storage. <i>redundant</i> information.  In fact, in the overwhelming majority of cases, there is no need to implement a 360-degree view - to achieve the same effect, 180 degrees are enough.  In this case, the ‚Äúsecond half‚Äù of the frame is used for the second angle, that is, stereo is obtained. <br><br>  Thus, the proposed format provides an even greater sense of immersion than from 360-video, is cheaper to produce, easier to shoot, and has no problems with <a href="https://en.wikipedia.org/wiki/Image_stitching">stitch</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      How is this possible, and what did Google offer? <br><br>  Anyone interested in a VR video of the near future - welcome under the cat! <br><a name="habracut"></a><hr><br><h3>  Introduction to the VR180 </h3><br>  First about the good. <br><br>  VR180 is noticeably easier to shoot than 360 videos.  For shooting <i>high</i> - <i>quality</i> 360-video, up to 17 cameras are used (example from Xiaomi below), which causes a lot of problems with the size of working video, partial failure, overheating, unstable focus of cameras, etc. At the same time, from the point of view of a simple user, the best were recognized cameras with <i>two</i> fisheye lenses ( <a href="https://www.pcmag.com/roundup/354276/the-best-360-cameras">one</a> , <a href="https://www.tomsguide.com/us/best-360-cameras,review-3737.html">two</a> , <a href="https://www.digitaltrends.com/photography/best-360-cameras/">three</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/734/e7d/81b/734e7d81b53a87373a6db0bb437f1ef9.png"><br>  <i><a href="https://vrscout.com/news/vr-professionals-best-360-cameras/">A source</a></i> <br><br>  The new format is also removed by two cameras.  This markedly reduces the cost of the end device.  At the same time, the shooting technique is greatly simplified, since all methods of working with a conventional camera remain relevant (only the result is potentially more spectacular and with greater immersion).  For the success of the format, it is important that every housewife and every student can easily use it.  Therefore, the simpler - the better. <br><br>  Further, in VR180, the problems of the so-called stiching (gluing) disappear - extremely noticeable artifacts in places where images from two cameras were stitched together.  Recently it seemed that a little time would have passed, and the problems of stitching would be solved.  Alas, they were much more difficult.  If there is a fast moving or translucent object on the border of gluing, then at the current level of development of video processing algorithms in automatic mode the problem is not solved.  Of course, automatic matting algorithms are evolving, but the <a href="http://videomatting.com/">absence of artifacts is not guaranteed even with Deep Learning methods</a> .  There is no stiching in VR180, which means there are no problems in principle either. <br><br>  And finally, almost always shot 360-video is flat.  That is, from the binocular point of view, the picture is perceived hanging on some screen before the eyes, which often reduces the ‚Äúwow effect‚Äù and the immersion effect, and the VR180 initially and by default - the stereo format. <br><br>  All these points look very promising from the point of view of predicting the success of the format.  As a result, manufacturers rather actively began to produce cameras specifically targeted at the VR180, for example: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b10/28b/407/b1028b407ca2ce205b1fe4ad60b63234.jpg"><br>  The fact that <a href="https://www.yitechnology.com/180-vr-camera">Xiaomi has entered the</a> VR180 market is certainly encouraging. <br><br>  Also, there were solutions that allow you to assemble the camera for shooting VR180 from two ordinary cameras with fisheye-lenses.  Sometimes it is enough just to print or buy a mount to start experiments (below are examples of GoPro, digital soap, Sony mirrors): <br><br><img width="350" src="https://habrastorage.org/getpro/habr/post_images/c56/203/79f/c5620379ff975402bc5cc64ec1569402.png"><img width="200" src="https://habrastorage.org/getpro/habr/post_images/18c/958/22d/18c95822df38b1f5cd14a0ff8a3c2f35.png"><br>  <i><a href="https://www.ettoday.net/news/20171128/1061641.htm">A source</a></i> <i><br><br><img width="350" src="https://habrastorage.org/getpro/habr/post_images/012/b94/ec3/012b94ec3ba8beea3ca942fe4decb7f2.png"><img width="350" src="https://habrastorage.org/getpro/habr/post_images/35d/0cd/5dc/35d0cd5dc25cb5347555a7ab7be258fd.png"><br></i>  <i>Source: <a href="http://products.entaniya.co.jp/en/products/equipment-for-3d-stereo-180-vr/">http://products.entaniya.co.jp/en/products/equipment-for-3d-stereo-180-vr/</a></i> <br><br>  In addition, funny solutions appeared when one camera supports shooting in both VR180 and 360 video formats (this is a clamshell, which shoots 360 when folded and VR180 when maximized): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/11b/823/176/11b823176e464b8c5a1dfa2f14a98020.png"><br>  <i><a href="https://vuze.camera/camera/vuze-xr-camera/">A source</a></i> <br><br>  Among other things, <a href="https://www.youtube.com/channel/UCkieN6utfUttxFJsHh7Y_7g/search%3Fquery%3Dvr180">new horizons of experiments</a> on shooting VR-video have opened (in the photo YI Horizon VR180 camera from Xiaomi): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0ea/eb7/7e7/0eaeb77e7bfb367f1441e51f1cc477ba.png"><br><br>  The number of new devices for shooting in the VR180 is very large, and this markedly contributes to the popularity of the new format. <br><br><h3>  VR180 implementation </h3><br>  Today, companies are trying to introduce VR wherever possible, they want to make the format more popular and popular.  And most importantly - cheap.  Google is no exception.  Everyone remembers their budget solution for the introduction of ‚Äúvirtual reality helmets‚Äù (English Head Mounted Display, HMD) for wide use - <a href="https://vr.google.com/intl/ru_ru/cardboard/">Google Cardboard</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c8d/f8a/ce5/c8df8ace5b7baf7919154161cad7ac8a.jpg"><br><br>  Its functionality, of course, can not be compared with expensive HMDs, but the main goal has been achieved: to make VR more accessible and turn every smartphone into a virtual reality headset at an additional cost of less than $ 1. <br><br>  <a href="https://vr.google.com/vr180/">Building</a> on success, Google launches the new <a href="https://vr.google.com/vr180/">VR180</a> format with support for uploading to YouTube and with a special search filter: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/730/a18/326/730a18326df42eabebb44a9ce584d228.jpg"><br><br>  This is the frame of the <a href="https://www.youtube.com/watch%3Fv%3DTH_MMXinRsA">video</a> from the inside: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a63/22a/6c1/a6322a6c1f0bee9d3be7bbbcaaf7c7c9.jpg"><br>  <i>Special meta-data has been added to MP4, which turns the video into spherical.</i>  <i>Generally speaking, if you simply click on the link, then most likely you will see a plain flat video. This is due to the fact that besides the VR180 video, a projection of one of the views (left) onto a regular rectangle is also uploaded to the site.</i>  <i>To see the picture as in the picture above, you need, for example, to download the video in pure MP4 format.</i>  <i>Basically, they have 4K resolution.</i>  <i>The possibility of camera movement is guaranteed when viewed on a mobile device with the Cardboard application ( <a href="https://play.google.com/store/apps/details%3Fid%3Dcom.google.samples.apps.cardboarddemo%26hl%3Dru">Google Play</a> , <a href="https://itunes.apple.com/ru/app/google-cardboard/id987962261%3Fmt%3D8">AppStore</a> ).</i>  <i>And, of course, in a full HMD.</i> <br><br>  Shooting such videos, by analogy with cardboard helmets, was also supposed to be cheap enough <i>for wide distribution among users.</i>  A camera that shoots video in this format costs around $ 300.  Compared with expensive <a href="https://en.wikipedia.org/wiki/3D_rig">stereo,</a> this is a completely new level.  It would seem that everything is fine.  However, the problem is that the new format is a stereo format, and in stereo, as you know, there are many difficult problems to solve. <br><br><hr><br><h2>  VR stereo quality </h2><br>  As soon as it comes to stereo (3D), <i>headaches</i> from trips to 3D cinemas are immediately recalled.  We considered the reasons for such discomfort in a large series of articles ( <a href="https://habr.com/post/377493/">one</a> , <a href="https://habr.com/post/377709/">two</a> , <a href="https://habr.com/post/378107/">three</a> , <a href="https://habr.com/post/378387/">four</a> , <a href="https://habr.com/post/378721/">five</a> , <a href="https://habr.com/post/379115/">six</a> , <a href="https://habr.com/post/379671/">seven</a> ) in much more detail, but with reference to stereo films.  In short, for a number of reasons, many 3D movies are shot (or converted) so that viewers who are sensitive to artifacts of a stereo video can only take citramon in advance.  Unfortunately, most of the problems in 3D movies are related to stereoscopic artifacts, which are also found in VR180.  This means that all the factors causing discomfort in such films will also cause discomfort when watching a video in virtual reality.  Even the basic quality check of the VR180 content showed that it is comparable to the quality of conventional stereos around the middle of the last century ... <br><br>  In other words, enthusiasts will be delighted, but the mass audience will complain. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6c1/86f/3aa/6c186f3aac2da8e239806d04d0a8a86c.png"><br><br>  For the analysis of the quality of stereovideo, the <a href="http://www.compression.ru/video/vqmt3d/">VQMT3D</a> project was <a href="http://www.compression.ru/video/vqmt3d/">used</a> , which is being developed in the <a href="http://www.compression.ru/video/index.htm">video group of a</a> computer graphics and multimedia laboratory at the faculty of VMK, MSU.  Its purpose is to provide authors of stereo films with the ability to track the occurrence of <i>all</i> possible artifacts at the post-production stage.  And since the VR180 is also stereo, the de facto project is applicable to this format with some reservations.  In the following examples, frame information is obtained using VQMT3D. <br><br><h3>  Color distortion </h3><br>  This problem is the easiest to understand and relatively easy to fix.  Close one eye and look at some object.  Now do the same with the other eye and answer the question: do the colors change when the eye changes?  In general, no.  So in stereovideo there should be no differences in the color of the same objects for the left and right angles.  However, this is what we see in real videos taken on YouTube (pay attention to monochrome areas, for example, sky or water): <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/f03/477/ad7/f03477ad7026ba738bc5c12acfa3d9d5.gif"><img width="375" src="https://habrastorage.org/getpro/habr/post_images/6bf/29d/62d/6bf29d62dcf87019a9e1fd47789b6985.gif"><br>  <a href="https://www.youtube.com/watch%3Fv%3DYV35KTUfebY"><i>Link to video</i></a> <br><br>  Color distortions can occur for many reasons, for example, due to different calibrations of cameras, heating of their matrices or when the edge of the lens is lit.  Therefore, even with identical shooting parameters for identical cameras, the colors can diverge noticeably. <br><br>  It is most convenient to visualize this artifact using ‚Äúchess‚Äù, when the right angle is brought to the left using motion compensation, and then blocks are selected from the left and reduced right angles in a checkerboard pattern. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/657/794/736/65779473673ce18a736244f1647c7aed.jpg"><br><br>  Below is an example when light sources fall into the frame: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4c8/e04/9fb/4c8e049fb604687f8bc79545d7359364.gif"><br>  <a href="https://www.youtube.com/watch%3Fv%3Dx2RkQYK3je0"><i>Link to video</i></a> <br><br>  Not only do the light sources themselves vary greatly in their perspectives, they also distort the colors in the whole image with highlights. <br><br>  A tougher example is when the sun hits the frame: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/92f/a76/7bb/92fa767bbb1a166b776c054969cbbf55.gif"><br>  <a href="https://www.youtube.com/watch%3Fv%3DqGdBMir7ICY"><i>Link to video</i></a> <br><br>  Due to the unsuccessful setting of the camera in front of the sun, a terrible artifact appears in the form of a red highlight on the matrix.  Color distortions are quite rare in real life, and artifacts of the above type are not found at all, which ultimately leads to an accumulation of fatigue when viewing.  Unfortunately, in the most sensitive part of the audience fatigue turns into a headache. <br><br><h3>  Sharpness Differences </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f1a/d33/d03/f1ad33d03b27e40fb7c8c4b0ba0b130e.png"><br><br>  Another problem that arises when shooting stereovideo is the differences in sharpness in the left and right angles.  In real life, this problem is quite common.  For example, if you spend 10‚Äì12 hours at a computer, peering intensely at the screen <i>(you will agree, this happens)</i> , then at the end of the day, the right and left eyes can noticeably diverge in focus, and light myopia / hyperopia is guaranteed until the evening.  In this case, the brain successfully compensates for this problem.  Relatively speaking, we get clear image details from the right or left eye for distant / close objects.  That is, in engineering language, the problem is regularly solved with built-in tools.  And in the morning, as a rule, vision is restored.  And everything would be fine, but in real stereo video, focusing can ‚Äújump‚Äù from scene to scene.  It turns out that the ‚Äúfar-sighted‚Äù becomes either the right eye or the left, and sometimes both see well, which leads to noticeable discomfort when viewed.  Especially for people in the age, whose eyes are already "stationary" diverged in sharpness. <br><br>  Examples of discrepancies for VR180, where for better clarity, enlarged fragments of the same area are presented for two views: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/5d6/64a/c4c/5d664ac4c052e0d892908412ea27e38d.jpg"><br>  <a href="https://www.youtube.com/watch%3Fv%3DqGdBMir7ICY"><i>Link to video</i></a> <br><br>  Here is another fragment of this frame: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/113/69f/780/11369f780651fe4438657d65da6ba2f1.jpg"><br>  <a href="https://www.youtube.com/watch%3Fv%3DqGdBMir7ICY"><i>Link to video</i></a> <br><br>  The appearance of this artifact is due to the divergence of focusing cameras for technical reasons.  And because of the lack of professional post-processing, even ‚Äúvygvlaznye‚Äù scenes fall on YouTube. <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/2b9/de6/6f0/2b9de66f0f028e8c71d5af546fbff7de.jpg"><br>  <a href="https://www.youtube.com/watch%3Fv%3Dx2RkQYK3je0"><i>Link to video</i></a> <br><br>  Almost all the inscriptions on the zoomed image differ in sharpness.  Pay attention to the inscription "12 CH", which will be uncomfortable to "strobe" when viewing. <br><br><h3>  Time shift </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/a88/ce0/a5c/a88ce0a5c0cc0f3de0029c42d51577fe.png"><br><br>  Strangely enough, although computer cores have long been successfully synchronized for millionths of a second, stereo cameras when shooting still differ in time by hundredths or even tenths of a second.  One eye sees events that have not yet happened for the other eye!  You can not even come up with an analogue for this problem in the real world.  And this artifact was also found in VR180. <br><br>  Pay attention to the window with a neon sign on the right side of the frame: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/593/d03/220/593d032205583a0d23fc623bc10d0453.gif"><br>  <a href="https://www.youtube.com/watch%3Fv%3DJUni1emq1AQ"><i>Link to video</i></a> <br><br>  This time shift was noticed by chance when analyzing discrepancies in color, which is also present here.  The glimmering sign catches the eye, even without the use of special metrics aimed at finding a <a href="https://habr.com/post/379671/">time shift</a> .  Simply left the frame behind the right! <br><br>  Here is another example from the same scene.  Look at the feet of pedestrians: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c6/473/b7e/3c6473b7e10a178c8d4ce599940eca59.gif"><br>  <a href="https://www.youtube.com/watch%3Fv%3DJUni1emq1AQ"><i>Link to video</i></a> <br><br>  It is clearly visible that on the right frame the leg is moved further than on the left, as if one frame lags behind the other for a few moments, although they should have been shot at exactly the same moment.  We conducted an experiment in which we <a href="https://ieeexplore.ieee.org/document/8251897">showed 302 viewers short fragments of stereo films with different artifacts</a> and asked after each fragment from a smartphone / laptop to fill out a form indicating the level of pain.  The shift in time has shown itself to be the most painful artifact - this is an impossible situation for the brain and an attempt to "process" it leads to obvious tangible discomfort.  Unfortunately, a shift of less than 1 frame is most common, and it is not so easy to correct. <br><br>  By the way, the example above shows with the naked eye also the rotation of the frame between the angles (especially in the lower left corner), which is also quite uncomfortable, but it is much easier to correct.  However, other artifacts are a separate big story, to which we will, I hope, return. <br><br><h3>  Google "nakosyachil"? </h3><br>  It could well seem that these artifacts are inherent in the video obtained during amateur photography, and if used correctly, the same cameras can give a good image.  Unfortunately, this is not the case.  Here is <a href="https://www.youtube.com/watch%3Fv%3DTH_MMXinRsA">the VR180 format promotional video</a> , which is located on the official <a href="https://vr.google.com/vr180/">VR180</a> page.  It would seem that he should set the standard of quality.  But if you look ... <br><br>  Differences in color: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e8/f77/405/6e8f774055e0fe2e4977c3710749e5e6.gif"><br><br>  Absolutely at all points there is color distortion.  As if at one of the angles a slightly larger white balance was mistakenly set. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8d5/70c/f57/8d570cf578fb0d68451bf251e063bdc0.gif"><br><br>  And here is a large part of the frame without distortion.  But the lower right corner still differs noticeably in color, which causes a characteristic visual ‚Äúgating‚Äù when viewed. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fe6/859/931/fe6859931d6610cb080bc89228b6c3ce.gif"><br><br>  It is noteworthy that the color distortion on the road was also noticed without special tools for stereo analysis.  It was discovered just when watching video frame by frame (similar to video processing with different parameters). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2b7/640/6e7/2b76406e7c1278b19238d8a27ccace2d.gif"><br><br>  Differences in sharpness: <br><br><img width="375" src="https://habrastorage.org/getpro/habr/post_images/135/413/1c8/1354131c850ef820368e9f327fbc0924.jpg"><br><br>  Here the difference is most noticeable on the floor and on the seams of the sofa.  The greatest difference in sharpness is precisely at the edges of the objects. <br><br><hr><br><h2>  Conclusion </h2><br><h3>  What do we have in the end? </h3><br>  VR, including 360-video, is actively distributed.  The technology attracts users and looks very promising.  But the technical quality of the current implementation causes discomfort from viewing.  As a result, a certain number of people interested in trying a new format get a headache, and when shooting is unsuccessful (as a rule, when the camera moves sharply), in addition, dizziness and nausea, which leads to disappointment in the format. <br><br><h3>  What can be done with this? </h3><br>  At the moment, many (including us) are developing <a href="http://compression.ru/video/vqmt3d/">tools for quality control</a> , as well as to correct stereo problems. <br><br>  For example, here are examples of color correction: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/14e/cd4/a84/14ecd4a84719b9484448d884bcb48660.gif"><br><br>  On the left - the original angles, on the right - color-corrected using our algorithm.  The illuminated view is completely corrected. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad0/867/73d/ad086773d4c04306fbd6af8d7c3ad03b.gif"><br><br>  The color on the ceiling returned to normal. <br><br><img src="https://habrastorage.org/webt/6j/0y/lz/6j0ylz9d22ongb5vdvt8kbiywic.gif"><br><br>  For more examples of automatic color correction, see a separate article <a href="https://habr.com/post/379115/">on stereo color distortion</a> . <br><br>  In total, at the moment, about 20 types of artifacts of the shot and converted stereo video are detected, most of which are also relevant for the VR180.  In the future we plan to expand the methods of monitoring and improving the quality of VR video: <br><br><ul><li>  adaptation of current quality control methods under VR <br></li><li>  addition and implementation of artifact correction methods <br></li><li>  compiling automatic video reports with the prediction of pain caused by viewing, in order to warn users and review the content of producers, motivating them to be more attentive to quality <br></li></ul><br><h3>  What are the prospects for the format as a whole? </h3><br>  It is obvious that the current problems are the problems of the infancy of technology and they will be actively solved.  It can be expected that: <br><br><ul><li>  camera makers bundled with the camera will supply software, a crucial part of the basic problems <br></li><li>  over time (if there is demand) a professional software will appear to correct artifacts <br></li><li>  it is very likely that YouTube will be implemented to correct part of the artifacts automatically when loading VR180 video, much the same way the jitter and interlacing of good old 2D video is now automatically corrected <br></li></ul><br>  From the funny: now came the fashion for smartphones with 3-4 cameras on the back side, which provide a dramatic improvement in the quality of photos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7b8/284/72d/7b828472d1d82aa42dd58363b8044f4d.png"><br>  <i>Source: <a href="https://www.samsung.com/global/galaxy/">Samsung Galaxy A7</a> (2018) &amp; <a href="https://www.samsung.com/global/galaxy/galaxy-a9/">Samsung Galaxy A9</a> (2018)</i> <br><br>  It is logical to expect that with the growing popularity of the VR180, its out-of-box support will be built into all major smartphone models. <br><br>  <i>Yes,</i> most likely the angle of view will be not 180 ¬∞, but less. <br>  <i>Yes,</i> most likely the quality will be worse than that of specialized cameras. <br>  <i>Yes,</i> shooting stereovideo will require compression of large streams of information (which today's smartphones are still poorly designed for). <br>  <i>Yes,</i> you will need to put two wide-angle cameras at a greater distance. <br>  But technically, today there are no major obstacles to the implementation of support for the VR180 flagship models.  The question is only in the growing popularity of the format, so that demand becomes massive, creating an incentive for this. <br><br>  And it is clear that when VR180 shooting will start to support top smartphones, the number of relevant videos on YouTube will start to grow like an avalanche. <br><br>  Also at exhibitions you can see autostereoscopic displays of smartphones and tablets, which with increasing resolution show more and more interesting quality.  At least, it cannot be compared with what could be <a href="https://en.wikipedia.org/wiki/List_of_3D-enabled_mobile_phones">massively observed in 2010‚Äì2011</a> during the last wave.  At the time of writing this article, <a href="https://www.google.ru/search%3Fq%3DRED%2BHydrogen%2BOne">RED Hydrogen One</a> was announced - the first SERIAL smartphone with a 3D screen of a new generation, so it was possible to buy what the professionals saw at the exhibitions.  The process goes on and, as screen resolution grows, it will obviously go faster and faster.  The main obstacle is the lack of content. <br><br>  Obviously, this ‚Äúchicken and egg‚Äù problem will be solved soon. <br><br><hr><br><h2>  General conclusions: </h2><br><h5>  VR180 has the following significant advantages: </h5><br><ul><li>  Significantly higher immersion in 3D for VR180 compared to 360-video <br></li><li>  There are no stitching artifacts (gluing) video from multiple cameras <br></li><li>  Cameras for shooting VR180 are cheap enough and will be cheaper <br></li><li>  Shooting the VR180 is noticeably closer to shooting with a regular camera and much easier for non-professionals, i.e., it will be relatively easy for a huge mass of fans to shoot their own video in the VR180 format <br></li><li>  You can expect VR180 support in smartphones over time <br></li><li>  You can expect cheap high-quality autostereoscopic displays of smartphones that will allow you to view VR180 without glasses and helmets (at the moment such solutions can already be seen at exhibitions, and the lack of content separates them from mass production) <br></li></ul><br><h5>  Cons VR180: </h5><br><ul><li>  Cheap cameras are now filming bad stereo that causes discomfort when watching <br></li><li>  Currently there are no available post-processing programs for the received VR180 videos and fixes for artifacts.           ,     ,   ,     ‚Ä¶ <br></li></ul><br><h5>  Total: </h5><br><ul><li>  VR180     ,      , ,   ,      ¬´¬ª    <br></li><li>    VR180  ¬´ ¬ª,      ,         ,      .     <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The popularity of the format rests on the problem of "chicken and eggs": there should be enough devices for shooting and viewing. </font><font style="vertical-align: inherit;">At the same time, unlike the 360-video, the VR180 will technically soon be easy to shoot on any smartphone. </font><font style="vertical-align: inherit;">And if Google Pixel 5 XL will support VR180 out of the box - it will be natural</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> As a result: in the future 10 years VR180 is doomed to popularity! </font></font><br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">All smaller headaches! </font></font><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yours Konstantin Kozhemyakov and Dmitry Vatolin</font></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> PS Thanks </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I would like to sincerely thank: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> our colleagues from the video group, thanks to which the algorithms presented above were created, and the results were calculated, </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Google for the VR180 commercials artifacts, as well as the fact that it promotes new formats no matter what, </font></font><br></li><li>      . ..      , <br></li><li>         , <br></li><li> , ,  ,  ,  ,  ,            ,     ! <br></li></ul><br>  See also: <br><ul><li> <a href="https://habr.com/ru/post/377493/">  3D   /  1:  </a> <br></li><li> <a href="https://habr.com/ru/post/377709/">  3D   /  2:  -  </a> <br></li><li> <a href="https://habr.com/ru/post/378107/">  3D   /  3:  </a> <br></li><li> <a href="https://habr.com/ru/post/378387/">  3D   /  4: </a> <br></li><li> <a href="https://habr.com/ru/post/378721/">  3D   /  5:    </a> <br></li><li> <a href="https://habr.com/ru/post/379115/">  3D   /  6:  </a> <br></li><li> <a href="https://habr.com/ru/post/379671/">  3D   /  7:     </a> <br></li></ul></div><p>Source: <a href="https://habr.com/ru/post/429414/">https://habr.com/ru/post/429414/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../429400/index.html">Seals vs neural network 2. Or run SqueezeNet v.1.1 on Raspberry Zero in realtime (almost)</a></li>
<li><a href="../429402/index.html">ML.NET 0.7 (Machine Learning .NET)</a></li>
<li><a href="../429404/index.html">8 s ¬Ω ways to prioritize functionality</a></li>
<li><a href="../429406/index.html">"Monsters in games or how to create fear"</a></li>
<li><a href="../429410/index.html">Port 22 SSH port or not</a></li>
<li><a href="../429416/index.html">Build a chat bot using Azure Bot</a></li>
<li><a href="../429418/index.html">.NET Standard 2.1</a></li>
<li><a href="../429420/index.html">PlayStation Classic uses PCSX ReARMed emulator for work, there are no proprietary solutions.</a></li>
<li><a href="../429422/index.html">UHCI, or the very first USB</a></li>
<li><a href="../429424/index.html">In California, there will be a robot from Daimler and Bosch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>