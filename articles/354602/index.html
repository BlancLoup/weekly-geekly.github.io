<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Comparing Google TPUv2 and Nvidia V100 on ResNet-50</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, Google has added the Tensor Processing Unit v2 (TPUv2) to the list of cloud services ‚Äî a processor specifically designed to accelerate deep ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Comparing Google TPUv2 and Nvidia V100 on ResNet-50</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/-q/zj/vn/-qzjvnbp_okicijrm_gbgiskxrk.jpeg"><br><br>  Recently, Google has added the <a href="https://cloudplatform.googleblog.com/2018/02/Cloud-TPU-machine-learning-accelerators-now-available-in-beta.html">Tensor Processing Unit v2 (TPUv2)</a> to the list of cloud services ‚Äî a processor specifically designed to accelerate deep learning.  This is the second generation of the world's first publicly available deep learning accelerator, which claims to be an alternative to Nvidia GPUs.  Recently, we talked about <a href="https://habrahabr.ru/post/350042/">first impressions</a> .  Many have asked for a more detailed comparison with <a href="https://www.nvidia.com/en-us/data-center/tesla-v100/">Nvidia V100</a> graphics processors. <br><br>  Objectively and meaningfully comparing the accelerators of deep learning is not a trivial task.  But because of the future importance of this category of products and the lack of detailed comparisons, we felt the need to conduct independent tests.  This includes taking into account the views of potentially opposing sides.  That's why we contacted Google and Nvidia engineers - and invited them to comment on the draft of this article.  To guarantee the absence of bias, we also invited independent experts.  Due to this, as far as we know, the most complete to date comparison of TPUv2 and V100 has turned out. <br><a name="habracut"></a><br><h2>  Experimental setup </h2><br>  Below are compared four TPUv2 (which form one Cloud TPU) with four Nvidia V100.  Both have a full memory of 64 GB, so they can be taught the same models with the same size of the training sample.  In the experiments, we teach models in the same way: four TPUv2 in Cloud TPU and four V100s perform the task of simultaneous distributed distributed learning. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As a model, we chose <a href="https://arxiv.org/abs/1512.03385">ResNet-50</a> on <a href="http://www.image-net.org/">ImageNet</a> , the de facto standard and benchmark for image classification.  ResNet-50 benchmark implementations are publicly available, but none of them support learning simultaneously on Cloud TPU and on several GPUs. <br><br>  Nvidia recommends using <a href="https://mxnet.incubator.apache.org/">MXNet</a> for multiple <a href="https://mxnet.incubator.apache.org/">V100s</a> or <a href="https://mxnet.incubator.apache.org/">TensorFlow</a> implementations that are available as Docker images on the <a href="https://ngc.nvidia.com/">Nvidia GPU Cloud</a> .  Unfortunately, it turned out that both implementations do not agree well with the default settings when working on several GPUs with large training samples.  It is necessary to make changes, in particular, in the learning rate (learning rate schedule). <br><br>  Instead, we took the implementation of ResNet-50 from the TensorFlow <a href="https://github.com/tensorflow/benchmarks/tree/a03070c016ab33f491ea7962765e378000490d99/scripts/tf_cnn_benchmarks">benchmark</a> repository and launched it as a Docker image (tensorflow / tensorflow: 1.7.0-gpu, CUDA 9.0, CuDNN 7.1.2).  It is significantly faster than the Nvidia recommended TensorFlow implementation and is only slightly inferior (by about 3%, see below) to the MXNet implementation.  But it fits well.  In addition, there is an additional advantage that we compare two implementations on the same version of the framework (TensorFlow 1.7.0). <br><br>  Google recommends using the Cloud TPU <a href="https://github.com/tensorflow/tpu/tree/16f9fd0514caeae87c09ae73ea1d665421d8750a/models/experimental/resnet_bfloat16">implementation of bfloat16</a> with TensorFlow 1.7.0 from the official TPU repository.  In both implementations, TPU and GPU, mixed precision calculations are used on the appropriate architecture, and most tensors are stored in half-precision numbers. <br><br>  The V100 tests were run on the p3.8xlarge instance (16 Xeon E5-2686@2.30GHz cores, 244 GB of memory, Ubuntu 16.04) on AWS with <b>four V100 GPUs</b> (each with 16 GB of memory).  The TPU tests were run on a small n1-standard-4 instance (2 Xeon@2.3GHz cores, 15 GB of memory, Debian 9), for which Cloud TPU (v2‚Äì8) of <b>four TPUv2</b> (each with 16 GB of memory) was allocated. <br><br>  We made two different comparisons.  First, we studied the performance in terms of bandwidth (images per second) on synthetic data without augmentation, that is, without creating additional training data from the available data.  This comparison is independent of convergence, there are no I / O bottlenecks, and augmentation of data does not affect the result.  The second comparison examined the accuracy and convergence of the two implementations on ImageNet. <br><br><h2>  Bandwidth test </h2><br>  We measured the bandwidth by the number of <b>images per second</b> on <b>synthetic data</b> , that is, with the creation of data for learning on the fly, with different sample sizes (batch size).  Note that only sample size of 1024 is recommended for TPU, but according to numerous requests from readers, we report the rest of the results. <br><br><img src="https://habrastorage.org/webt/yp/iv/xb/ypivxbpox5bkr84pp74pali4cmw.png"><br>  <i><font color="gray">Performance (images per second) on different sample sizes on synthetic data and without augmentation.</font></i>  <i><font color="gray">The sample sizes are ‚Äúglobal‚Äù, that is, 1024 means the size 256 on each of the GPU / TPU chips at each step</font></i> <br><br>  With a training sample size of 1024, there is practically no difference in throughput!  TPU is only slightly ahead with a difference of about 2%.  On smaller training samples, bandwidth drops on both platforms, and GPUs work a little better.  But as mentioned above, such training sample sizes are currently not recommended for TPU. <br><br>  Following the recommendations of Nvidia, we conducted an experiment with a GPU on <a href="https://mxnet.incubator.apache.org/">MXNet</a> .  The ResNet-50 implementation was used in the Docker image ( <i>mxnet: 18.03-py3</i> ), available on the <a href="https://ngc.nvidia.com/">Nvidia GPU Cloud</a> .  With a training sample size of 768 (1024 too many), the GPU processes <b>about 3280 images per second</b> .  This is about 3% faster than the best result for TPU.  But as mentioned above, the MXNet implementation does not converge very well on several GPUs with this size of the training sample, so here and below we will focus on the implementation of TensorFlow. <br><br><h2>  Cost in the cloud </h2><br>  Cloud TPU (four TPUv2 chips) is currently available only in the Google cloud.  It connects on request to any VM instance only when such calculations are required.  For V100, we looked at a cloud solution from AWS (V100 is not yet available in the Google cloud).  Based on the results above, we can normalize the <i>number of images per second per dollar</i> for each platform and provider. <br><br>  <b>Performance: images per second per dollar</b> <br><table><tbody><tr><th></th><th>  Cloud TPU </th><th>  4 √ó V100 </th><th>  4 √ó V100 </th></tr><tr><td>  Cloud </td><td>  Google cloud </td><td>  AWS </td><td>  Reserved AWS Instance </td></tr><tr><td>  Price per hour </td><td>  $ 6.7 </td><td>  $ 12.2 </td><td>  $ 8.4 </td></tr><tr><td>  Images per second </td><td>  3186 </td><td>  3128 </td><td>  3128 </td></tr><tr><td>  Performance (images per second per dollar) </td><td>  <b>476</b> </td><td>  <b>256</b> </td><td>  <b>374</b> </td></tr></tbody></table><br>  With such prices Cloud TPU comes out a clear winner.  However, the situation may look different if you are considering renting for a longer period or purchasing equipment (although this option is currently not available for Cloud TPU).  The table above also includes the price of the p3.8xlarge reserved instance on AWS when renting for 12 months (without prepayment).  This significantly improves performance per dollar up to 374 images / s per $ 1. <br><br>  For the GPU, there are other interesting options.  For example, <a href="http://www.cirrascale.com/pricing_x86BM.php">Cirrascale</a> offers a monthly server rental with four V100 for about $ 7,500 (about ~ $ 10.3 per hour).  But for direct comparison, additional tests are required, since this equipment differs from the equipment on AWS (type of CPU, memory, support for NVLink, etc.). <br><br><h2>  Accuracy and convergence </h2><br>  In addition to the performance reports, we wanted to check that the calculations are actually ‚Äúmeaningful‚Äù, that is, the implementations converge to good results.  <b>Since two different implementations were compared, some deviation can be expected.</b>  Therefore, our comparison is not only an indicator of the speed of the equipment, but also the quality of implementation.  For example, implementing a TPU involves very resource-intensive preprocessing steps and actually sacrifices bandwidth.  According to Google, this is the expected behavior.  As we will see below, it is justified. <br><br>  We trained models on the <a href="http://www.image-net.org/">ImageNet</a> data <a href="http://www.image-net.org/">set</a> , where the challenge is to classify the image into one of 1000 categories, such as <i>hummingbirds</i> , <i>burritos,</i> or <i>pizza</i> .  The dataset consists of 1.3 million images for learning (~ 142 GB) and 50,000 images for validation (~ 7 GB). <br><br>  Training goes 90 epochs with a sample size of 1024, after which the results are compared with control data.  The implementation of TPU sequentially processes about <b>2796 images per second</b> , and the implementation of the GPU - about <b>2839 images per second</b> .  This is different from previous throughput results, where we turned off augmentation and used synthetic data to compare the net speed of TPU and GPU. <br><br><img src="https://habrastorage.org/webt/rt/l7/cu/rtl7cuxpwchcrdfkrjzwhh33slc.png"><br>  <i><font color="gray">The accuracy of the top 1 (i.e., for each image, only the prediction with the most confidence is taken into account) of two realizations after 90 epochs</font></i> <br><br>  As shown above, the accuracy of the top 1 after 90 epochs for the implementation of TPU by 0.7 percentage points  it is better.  This may seem insignificant, but it is extremely difficult to achieve improvement at this very high level.  Depending on the application, such small improvements can significantly affect the result. <br><br>  Let's look at the accuracy of the top 1 in different eras during training models. <br><br><img src="https://habrastorage.org/webt/zv/fr/y0/zvfry0cr6o74de7dkmyiuahksgq.png"><br>  <i><font color="gray">Top-1 accuracy on a control set for two implementations</font></i> <br><br>  The dramatic changes in the above graph coincide with changes in learning speed.  The trend of convergence is better in the implementation of TPU.  Here the final accuracy is reached 76.4% after 86 epochs.  The GPU implementation is lagging behind and reaches a final accuracy of 75.7% after 84 epochs, whereas only 64 epochs are required to achieve such accuracy on TPU.  The improvement in TPU convergence is likely to be associated with better pre-processing and augmentation of data, but more experiments are needed to confirm this hypothesis. <br><br><h2>  Cost-effective cloud based solution </h2><br>  Ultimately, time and cost are important to achieve a certain accuracy.  If we take the solution at the level of 75.7% (the best accuracy achieved by the implementation of the GPU), then we can calculate the cost of achieving this accuracy based on the required epochs and the speed of learning in images per second.  This eliminates the time to evaluate the model in between periods and the time to start training. <br><br><img src="https://habrastorage.org/webt/xg/cd/e6/xgcde6-4eeoxdpunhqy5nx58zvs.png"><br>  <i><font color="gray">Price to achieve accuracy top 75.7%.</font></i>  <i><font color="gray">* Reserved for 12 months</font></i> <br><br>  As shown above, Cloud TPU's current pricing policy allows you to train a model from zero to 75.7% accuracy on ImageNet in less than 9 hours for $ 55!  Education to the convergence of 76.4% costs $ 73.  Although the V100 works just as fast, the higher price and the slower convergence result in a significantly higher solution cost. <br><br>  Again, note that the comparison depends on the quality of the implementation, as well as on the price of the cloud. <br><br>  It would be interesting to compare the difference in energy consumption.  But currently there is no publicly available information on the energy consumption of TPUv2. <br><br><h2>  Conclusion </h2><br>  As for the base performance on ResNet-50, the four TPUv2 chips (one Cloud TPU module) and the four V100 graphics processors are equally fast in our tests (a difference of 2%).  Probably, due to future software optimizations (for example, TensorFlow or CUDA), performance will improve and the ratio will change. <br><br>  However, in practice, most often the main thing is the time and financial costs necessary to achieve a certain accuracy on a specific task.  The current TPU Cloud pricing, combined with the excellent implementation of the ResNet-50, lead to impressive results in time and cost on ImageNet, which allows training the model to 76.4% accuracy for about $ 73. <br><br>  For detailed comparison, benchmarks are needed on models from other areas and with different network architectures.  It is also interesting to understand how much effort is required to effectively use each hardware platform.  For example, calculations with mixed accuracy are accompanied by a significant increase in performance, but are implemented differently on the GPU and TPU. </div><p>Source: <a href="https://habr.com/ru/post/354602/">https://habr.com/ru/post/354602/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../354590/index.html">Daniel Story's Comics (Part 3)</a></li>
<li><a href="../354592/index.html">000 000 111 (Nikolos Negroponet's fundamental article on the digital economy for 1995, part 3)</a></li>
<li><a href="../354594/index.html">Marvin Minsky "The Emotion Machine": Chapter 1 "Answers to Questions"</a></li>
<li><a href="../354596/index.html">Rome Club Report 2018, Chapter 1: ‚ÄúSustainable Development - Bullshit‚Äù</a></li>
<li><a href="../354598/index.html">Quickly create SELinux modules using sepolicy</a></li>
<li><a href="../354606/index.html">How to spoil a useful service (for example, Yandex.Maps)</a></li>
<li><a href="../354608/index.html">We understand the concept of BPM. What is business process management?</a></li>
<li><a href="../354612/index.html">What we read in April: useful articles for Angular-developers and a selection of the best with ng-conf</a></li>
<li><a href="../354614/index.html">The financial revolution: how IT startups change the rules of the game on Wall Street</a></li>
<li><a href="../354616/index.html">How does Qlean use Machine Learning?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>