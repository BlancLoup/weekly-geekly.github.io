<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Android NDK: working with OpenSL ES</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day, Habrazhiteli. 

 I previously wrote about OpenAL. Later, comrade zagayevskiy wrote a good article on OpenSL ES. In one of our games, in orde...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Android NDK: working with OpenSL ES</h1><div class="post__text post__text-html js-mediator-article">  Good day, Habrazhiteli. <br><br>  I previously <a href="http://habrahabr.ru/post/176559/">wrote</a> about OpenAL.  Later, comrade <a href="https://habrahabr.ru/users/zagayevskiy/" class="user_link">zagayevskiy</a> <a href="http://habrahabr.ru/post/176933/">wrote a</a> good article on OpenSL ES.  In one of our games, in order not to rewrite all the code for working with sound, we did not rewrite everything on OpenSL ES (at the port on Android).  Not many sounds were used in the game, so there was no problem with OpenAL.  But in the last game, we used a lot of sounds (the specificity of the game requires it), it was here that we ran into a big problem (delays during playback - the least of them).  It was decided to rewrite everything on <a href="http://suvitruf.ru/2014/04/05/3457/">OpenSL ES</a> .  For this, I wrote a couple of wraps, about which I already told.  I decided to share this and on Habr√©, maybe someone will come in handy. <br><br><ol><li>  <a href="https://habr.com/ru/post/235795/">A brief description of OpenSL ES</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">Audio content</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">A little bit about wrappers</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">The principle of working with objects</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">Library initialization (context)</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">Work with sounds</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">Playing PCM</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">Playing compressed formats</a> . </li><li>  <a href="https://habr.com/ru/post/235795/">Conclusion</a> </li><li>  <a href="https://habr.com/ru/post/235795/">Add.</a>  <a href="https://habr.com/ru/post/235795/">information</a> . </li></ol><br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="anc1"></a><h4>  OpenSL ES Short Description </h4>  This case is available with Android API 9 (Android 2.3) and higher.  Some features are only available in Android API 14 (Android 4.0) and higher.  OpenSL ES provides an interface in C, which can also be called from C ++, providing the same capabilities as the Android Java API parts for working with sounds: <ul><li>  <a href="http://developer.android.com/reference/android/media/MediaPlayer.html">android.media.MediaPlayer</a> </li><li>  <a href="http://developer.android.com/reference/android/media/MediaRecorder.html">android.media.MediaRecorder</a> </li></ul><br><br>  <b>Note</b> : Although it is based on OpenSL ES, this API is not a complete implementation of any profile from OpenSL ES 1.0.1. <br><br>  Liba, as you might have guessed, is written in pure C. Therefore, there is no full-fledged OOP.  Special structures are used (let's call them pseudo-object-oriented structures (:), which are the usual C structures that contain pointers to functions that receive pointers to the structure by the first argument. Something like this in C ++, but explicitly. In OpenSL ES are two types of such structures: <br><br><ul><li>  <b>An object</b> ( <code>SLObjectItf</code> ) is an abstraction of a set of resources designed to perform a specific set of tasks and to store information about these resources.  When creating an object, its type is defined, which determines the range of tasks that can be solved with its help. </li><li>  <b>Interface</b> ( <code>SLEngineItf</code> , <code>SLSeekItf</code> , etc.) is an abstraction of a set of interrelated functionality provided by a particular object.  The interface includes a variety of methods used to perform actions on an object.  The interface has a type that defines the exact list of methods supported by this interface.  The interface is determined by its identifier, which can be used in the code to refer to the type of interface (for example, <code>SL_IID_VOLUME, SL_IID_SEEK</code> ).  All constants and interface names are pretty obvious, so special problems should not arise. </li></ul><br><br>  <b>To summarize</b> : objects are used to allocate resources and get interfaces.  And then with the help of these interfaces we work with the object.  One object can have several interfaces (for changing volume, for changing position, etc.).  Depending on the device (or object type), some interfaces may not be available.  I will say in advance, you can stream audio from your assets directory using <code>SLDataLocator_AndroidFD</code> , which supports an interface for moving positions around a track.  At the same time, you can load the entire file into the buffer (using <code>SLDataLocator_AndroidFD</code> ), and play it from there.  But this object does not support the <code>SL_IID_SEEK</code> interface, therefore it will not be possible to move around the track = / <br><br><a name="anc2"></a><h4>  Audio content </h4>  There are many ways to pack audio content into an app: <br><ul><li>  <b>Resources</b> .  By placing audio files in <b>res / raw /</b> directories, you can easily access them using the API for <a href="http://developer.android.com/reference/android/content/res/Resources.html">Resources</a> .  However, there is no direct native access to these resources, so you will have to copy them from Java code. </li><li>  <b>Assets</b> .  By placing the audio files in the <b>assets /</b> directory, you can access them from C ++ with the help of the native manager.  See <b>android / asset_manager.h and android / asset_manager_jni.h headers</b> for more information. </li><li>  <b>Network</b>  You can use the URI data locator to play audio directly from the network.  Do not forget about the necessary permisheny for this (: </li><li>  <b>Local file system</b> .  The URI data locator supports the <b>file:</b> scheme for accessing local files, provided that the files are accessible to the application (well, that is, it will not work to read files from the internal storage of another application).  Please note that in Android, access to files is restricted using the Linux user ID and group ID mechanisms. </li><li>  <b>Record</b> .  Your application can record audio from a microphone, save content, and later play. </li><li>  <b>Compiled and linked inline</b> .  You can directly cram audio content into the library, and then play with the buffer queue data locator.  This is very well suited for short PCM compositions.  PCM data is converted to a hex string using the bin2c tool. </li><li>  <b>Generation in real time</b> .  An application can generate (synthesize) PCM data on the fly, and then play it back using the buffer queue data locator. </li></ul><br><br><a name="anc3"></a><h4>  Something about my wrappers </h4>  In general, I am a fan of OOP, so I try to somehow group a certain functional of C-methods and wrap my classes so that it will be convenient to work in the future.  By analogy with the way I did it for <a href="http://suvitruf.ru/2013/04/19/3149/">OpenAL</a> , classes appeared: <br><br><ol><li>  <code>OSLContext</code> .  It is responsible for initializing the library and creating instances of the required buffers. </li><li>  <code>OSLSound</code> .  Base class for working with sounds. </li><li>  <code>OSLWav</code> .  Class to work with wav.  Inherited from OSLSound to keep the overall interface to work.  To work with ogg, you can then create a class OSLOgg, as I did in OpenAL.  This distinction is made, since these formats have a completely different loading process.  WAV is a clean format, it‚Äôs enough just to read the bytes, but ogg must also be decompressed with <a href="http://svn.xiph.org/trunk/Tremor/">Ogg Vorbis</a> , I‚Äôm generally silent about mp3 (: </li><li>  <code>OSLMp3</code> .  Class for working with Mp3.  Inherited from OSLSound to keep the overall interface to work.  The class almost doesn't implement anything at all, because the mp3 stream is.  But if you want to decode mp3 with the help of some lame or something else, then in the load (char * filename) method you can implement decoding and use the BufferPlayer. </li><li>  <code>OSLPlayer</code> .  Actually, the main class for working with sound.  The fact is that the mechanism of work in OpenSL ES is not the same as in OpenAL.  In OpenAL there is a special structure for the buffer and sound source (on which we hang the buffer).  In OpenSL ES, everything revolves around players that are different. </li><li>  <code>OSLBufferPlayer</code> .  We use this player when we want to load the entire file into memory.  As a rule, it is used for short sound effects (shot, explosion, etc.).  As already said, it does not support the <code>SL_IID_SEEK</code> interface, therefore it will not be possible to move around the track. </li><li>  <code>OSLAssetPlayer</code> , allows you to stream from the assets directory (that is, do not load the entire file into memory).  Use to play long tracks (background music, for example). </li></ol><br><br><a name="anc4"></a><h4>  The principle of working with objects </h4>  The whole cycle of working with objects like this: <br><ol><li>  Get the object by specifying the desired interfaces. </li><li>  Implement it by calling <code>(*obj)-&gt;Realize(obj, async)</code> . </li><li>  Get the required interfaces by calling <code>(*obj)-&gt; GetInterface (obj, ID, &amp;itf)</code> </li><li>  Work through interfaces. </li><li>  Delete the object and clear the used resources by calling <code>(*obj)-&gt;Destroy(obj)</code> . </li></ol><br><br><a name="anc5"></a><h4>  Library initialization (context) </h4>  First you need to add the lOpenSLES flag to the LOCAL_LDLIBS section of the <b>Android.mk</b> file in the jni directory: <code>LOCAL_LDLIBS += -lOpenSLES</code> and connect two header files: <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;SLES/OpenSLES.h&gt; #include &lt;SLES/OpenSLES_Android.h&gt;</span></span></span></span></code> </pre><br>  Now you need to create an object through which we will work with the library (something similar to the context in OpenAL) using the <code>slCreateEngine</code> method.  The resulting object becomes the central object for accessing the OpenSL ES API.  Next, we initialize the object using the <code>Realize</code> method. <br><pre> <code class="cpp hljs">result = slCreateEngine(&amp;engineObj, <span class="hljs-comment"><span class="hljs-comment">//pointer to object 0, // count of elements is array of additional options NULL, // array of additional options lEngineMixIIDCount, // interface count lEngineMixIIDs, // array of interface ids lEngineMixReqs); if (result != SL_RESULT_SUCCESS ) { LOGE("Error after slCreateEngine"); return; } result = (*engineObj)-&gt;Realize(engineObj, SL_BOOLEAN_FALSE ); if (result != SL_RESULT_SUCCESS ) { LOGE("Error after Realize"); return; }</span></span></code> </pre><br><br>  Now you need to get the interface <code>SL_IID_ENGINE</code> , through which you will get access to the speakers, playing sounds, and so on. <br><pre> <code class="cpp hljs">result = (*engineObj)-&gt;GetInterface(engineObj, SL_IID_ENGINE, &amp;engine); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (result != SL_RESULT_SUCCESS ) { LOGE(<span class="hljs-string"><span class="hljs-string">"Error after GetInterface"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; }</code> </pre><br>  It remains to get and initialize the OutputMix object for working with speakers using the <code>CreateOutputMix</code> method: <br><pre> <code class="cpp hljs">result = (*engine)-&gt;CreateOutputMix(engine, &amp;outputMixObj, lOutputMixIIDCount, lOutputMixIIDs, lOutputMixReqs); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(result != SL_RESULT_SUCCESS){ LOGE(<span class="hljs-string"><span class="hljs-string">"Error after CreateOutputMix"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } result = (*outputMixObj)-&gt;Realize(outputMixObj, SL_BOOLEAN_FALSE); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(result != SL_RESULT_SUCCESS){ LOGE(<span class="hljs-string"><span class="hljs-string">"Error after Realize"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; }</code> </pre><br><br>  In addition to the initialization of the main objects in the constructor of my OSLContext <code>OSLContext</code> , all the necessary players are initialized.  The maximum possible number of players is limited.  I recommend to create no more than 20. <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> OSLContext::initPlayers(){ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt; MAX_ASSET_PLAYERS_COUNT; ++i) assetPlayers[i] = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> OSLAssetPlayer(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt; MAX_BUF_PLAYERS_COUNT; ++i) bufPlayers[i] = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> OSLBufferPlayer(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>); }</code> </pre><br><br><a name="anc6"></a><h4>  Work with sounds </h4>  In fact, the types of sounds can be divided into two categories: pure (not compressed data) PCM, which are contained in WAV and compressed formats (mp3, ogg, etc.).  Mp3 and ogg can decode and receive all the same uncompressed PCM audio data.  To work with PCM use BufferPlayer.  For AssetPlayer compressed formats, as decoding files will be quite expensive.  If you take an mp3, then hardware will not decode it on old phones, and with the help of third-party software solutions, decoding will take more than a dozen seconds, which, you see, is not acceptable.  In addition, such PCM data will weigh too much. <br><br>  When calling the player () method, it requests the free player from the context ( <code>OSLContext</code> ).  If you want to loop the sound, we get <code>OSLAssetPlayer</code> , in another case <code>OSLBufferPlayer</code> . <br><br><a name="anc7"></a><h4>  PCM playback </h4>  I will not write about reading WAV again, you can see about it in the article about OpenAL.  In the same article I will tell you how to create BufferPlayer using the received PCM data. <br><br><div class="spoiler">  <b class="spoiler_title">Initializing BufferPlayer for PCM</b> <div class="spoiler_text"><pre> <code class="cpp hljs">locatorBufferQueue.locatorType = SL_DATALOCATOR_ANDROIDSIMPLEBUFFERQUEUE; locatorBufferQueue.numBuffers = <span class="hljs-number"><span class="hljs-number">16</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   ,      SLDataFormat_PCM formatPCM; formatPCM.formatType = SL_DATAFORMAT_PCM; formatPCM.numChannels = 2; formatPCM.samplesPerSec = SL_SAMPLINGRATE_44_1;// header.samplesPerSec*1000; formatPCM.bitsPerSample = SL_PCMSAMPLEFORMAT_FIXED_16 ;//header.bitsPerSample; formatPCM.containerSize = SL_PCMSAMPLEFORMAT_FIXED_16;// header.fmtSize; formatPCM.channelMask = SL_SPEAKER_FRONT_LEFT|SL_SPEAKER_FRONT_RIGHT ; formatPCM.endianness = SL_BYTEORDER_LITTLEENDIAN; audioSrc.pLocator = &amp;locatorBufferQueue; audioSrc.pFormat = &amp;formatPCM; locatorOutMix.locatorType = SL_DATALOCATOR_OUTPUTMIX; locatorOutMix.outputMix = context-&gt;getOutputMixObject(); audioSnk.pLocator = &amp;locatorOutMix; audioSnk.pFormat = NULL; //   const SLInterfaceID ids[2] = {SL_IID_ANDROIDSIMPLEBUFFERQUEUE,/*SL_IID_MUTESOLO,*/ /*SL_IID_EFFECTSEND,SL_IID_SEEK,*/ /*SL_IID_MUTESOLO,*/ SL_IID_VOLUME}; const SLboolean req[2] = {SL_BOOLEAN_TRUE,SL_BOOLEAN_TRUE}; result = (*context-&gt;getEngine())-&gt;CreateAudioPlayer(context-&gt;getEngine(), &amp;playerObj, &amp;audioSrc, &amp;audioSnk,2, ids, req); assert(SL_RESULT_SUCCESS == result); result = (*playerObj)-&gt;Realize(playerObj, SL_BOOLEAN_FALSE ); assert(SL_RESULT_SUCCESS == result); if (result != SL_RESULT_SUCCESS ) { LOGE("Can not CreateAudioPlayer %d", result); playerObj = NULL; } //   result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_PLAY, &amp;player); assert(SL_RESULT_SUCCESS == result); //       result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_VOLUME, &amp;fdPlayerVolume); assert(SL_RESULT_SUCCESS == result); result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_ANDROIDSIMPLEBUFFERQUEUE, &amp;bufferQueue); assert(SL_RESULT_SUCCESS == result);</span></span></code> </pre><br></div></div><br><br>  In general, there is nothing complicated.  Here only there is a HUGE problem.  Notice the <code>SLDataFormat_PCM</code> structure.  Why did I explicitly fill in the parameters myself and not read the WAV file from the headers?  Because I have all the WAV files in the same format, i.e.  the same number of channels, frequency, bit rate, etc.  The fact is that if you create a buffer and specify 2 channels in the parameters, and try to play a track with 1 channel, the application will fall.  The only option is to reinitialize the entire buffer if the file has a different format.  But after all, the beauty is just that we initialize the player 1 time, and then just change the buffer on it.  Therefore, there are two options here, either create several players with different parameters, or all of your .wav files lead to the same format.  Well, or initialize the buffer every time again -_- <br><br>  In addition to the interface for volume, there are two other interfaces: <br><br><ul><li>  <code>SL_IID_MUTESOLO</code> for managing channels (for multichannel audio only, this is indicated in the numChannels field of the SLDataFormat_PCM structure). </li><li>  <code>SL_IID_EFFECTSEND</code> for applying effects (by specification - only the reverb effect). </li></ul><br><br>  Adding sound to the queue when selecting a player and installing sound to it: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> OSLBufferPlayer::setSound(OSLSound * sound){ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(bufferQueue == <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>) LOGD(<span class="hljs-string"><span class="hljs-string">"bufferQueue is null"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>-&gt;sound = sound; (*bufferQueue)-&gt;Clear(bufferQueue); (*bufferQueue)-&gt;Enqueue(bufferQueue, sound-&gt;getBuffer() , sound-&gt;getSize()); }</code> </pre><br><br><a name="anc8"></a><h4>  Playing compressed formats </h4>  In WAV, all sounds are not an option.  And not because the files themselves take up a lot of space (although this too), just when you load them into memory, there simply is not enough RAM for this (: <br><br>  I create classes for each of the formats, so that in the future, if necessary, write a part on decoding them.  For mp3, there is <code>OSLMp3</code> class, which, in fact, only stores the file name in order to install it on the player in the future.  The same can be done for ogg and other supported formats. <br><br>  I will give a complete method for initialization, explanations in the comments. <br><br><div class="spoiler">  <b class="spoiler_title">Initializing AssetPlayer to work with compressed formats</b> <div class="spoiler_text"><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> OSLAssetPlayer::init(<span class="hljs-keyword"><span class="hljs-keyword">char</span></span> * filename){ SLresult result; AAsset* asset = AAssetManager_open(mgr, filename, AASSET_MODE_UNKNOWN); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-literal"><span class="hljs-literal">NULL</span></span> == asset) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> JNI_FALSE; } <span class="hljs-comment"><span class="hljs-comment">//   off_t start, length; int fd = AAsset_openFileDescriptor(asset, &amp;start, &amp;length); assert(0 &lt;= fd); AAsset_close(asset); //     SLDataLocator_AndroidFD loc_fd = {SL_DATALOCATOR_ANDROIDFD, fd, start, length}; SLDataFormat_MIME format_mime = {SL_DATAFORMAT_MIME, NULL, SL_CONTAINERTYPE_UNSPECIFIED}; SLDataSource audioSrc = {&amp;loc_fd, &amp;format_mime}; SLDataLocator_OutputMix loc_outmix = {SL_DATALOCATOR_OUTPUTMIX, context-&gt;getOutputMixObject()}; SLDataSink audioSnk = {&amp;loc_outmix, NULL}; //   const SLInterfaceID ids[3] = {SL_IID_SEEK, SL_IID_MUTESOLO, SL_IID_VOLUME}; const SLboolean req[3] = {SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE, SL_BOOLEAN_TRUE}; result = (*context-&gt;getEngine())-&gt;CreateAudioPlayer(context-&gt;getEngine(), &amp;playerObj, &amp;audioSrc, &amp;audioSnk, 3, ids, req); assert(SL_RESULT_SUCCESS == result); //   result = (*playerObj)-&gt;Realize(playerObj, SL_BOOLEAN_FALSE); assert(SL_RESULT_SUCCESS == result); //       result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_PLAY, &amp;player); assert(SL_RESULT_SUCCESS == result); //       result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_SEEK, &amp;fdPlayerSeek); assert(SL_RESULT_SUCCESS == result); //      result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_MUTESOLO, &amp;fdPlayerMuteSolo); assert(SL_RESULT_SUCCESS == result); //      result = (*playerObj)-&gt;GetInterface(playerObj, SL_IID_VOLUME, &amp;fdPlayerVolume); assert(SL_RESULT_SUCCESS == result); //      result = (*fdPlayerSeek)-&gt;SetLoop(fdPlayerSeek, sound-&gt;isLooping() ? SL_BOOLEAN_TRUE : SL_BOOLEAN_FALSE, 0, SL_TIME_UNKNOWN); assert(SL_RESULT_SUCCESS == result); // return JNI_TRUE; }</span></span></code> </pre><br></div></div><br><br><a name="anc9"></a><h4>  Conclusion </h4>  OpenSL ES is quite easy to learn.  Yes, and he has a lot of opportunities (for example, you can record audio).  It is a pity that with cross-platform problems.  OpenAL is cross-platform, but on Android it does not behave very much.  OpenSL has a couple of minuses, weird callback behavior, not all specification features are supported, etc.  But in general, ease of implementation and stable work cover these disadvantages. <br><br>  Sors can be taken on <a href="https://github.com/Suvitruf/Android-ndk/tree/master/OpenSLES">github.com</a> <br><br><a name="anc10"></a><h4>  Add.  infa </h4><br>  Interesting reading on the topic: <br><ol><li>  <a href="http://www.khronos.org/opensles/">The Standard for Embedded Audio Acceleration</a> on the developer‚Äôs site. </li><li>  <a href="http://www.khronos.org/registry/sles/specs/OpenSL_ES_Specification_1.1.pdf" title="OpenSL ES Specification">The Khronos Group Inc.</a>  <a href="http://www.khronos.org/registry/sles/specs/OpenSL_ES_Specification_1.1.pdf" title="OpenSL ES Specification">OpenSL ES Specification</a> . </li><li>  Android NDK.  Development of applications for Android on C / C ++. </li><li>  <a href="http://svn.xiph.org/trunk/Tremor/">Ogg Vorbis</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/235795/">https://habr.com/ru/post/235795/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../235779/index.html">September 13th - Programmer's Day (early congratulations)</a></li>
<li><a href="../235781/index.html">How are designers worse than musicians?</a></li>
<li><a href="../235783/index.html">Experience successful crowdfunding. Top 5 best projects Indiegogo</a></li>
<li><a href="../235785/index.html">A few words about vSphere vFRC</a></li>
<li><a href="../235789/index.html">Rust: how code can be both fast and secure. Stepan Koltsov's story in Yandex</a></li>
<li><a href="../235799/index.html">Those who want to teach children to program and make games</a></li>
<li><a href="../235801/index.html">09.09.2014 | Autumn presentation of Apple's new products</a></li>
<li><a href="../235803/index.html">Containerization - new shared-hosting</a></li>
<li><a href="../235805/index.html">A small Japanese trick on organizing your notebook</a></li>
<li><a href="../235809/index.html">OnePlus One - Chinese Beast</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>