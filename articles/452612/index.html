<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Machine learning of a deep neural network with reinforcement at tensorflow.js: stunts</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Teaching deep neural networks from scratch is not an easy task. 

 It takes a lot of data and time to learn, but some tricks can help speed up the pro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Machine learning of a deep neural network with reinforcement at tensorflow.js: stunts</h1><div class="post__text post__text-html js-mediator-article">  Teaching deep neural networks from scratch is not an easy task. <br><br>  It takes a lot of data and time to learn, but some tricks can help speed up the process, which I will discuss under the cut. <br><br>  Demonstration of the passage of a simple maze using tricks.  Duration of training network: 1 hour 06 minutes.  Record accelerated by 8 times. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/KbuNjZKidpw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  For each task you need to develop your own set of tricks to speed up network learning.  I will share a few tricks that helped me train the network much faster. <br><br>  For theoretical knowledge, I recommend switching to the channel <a href="https://www.youtube.com/channel/UCQj_dwbIydi588xrfjWSL5g">sim0nsays</a> . <br>  And I will tell you about my modest success in learning neural networks. <br><br><h2>  Formulation of the problem </h2><br>  <i>Approximate the convergence function minimizing the quadratic loss function by back propagation of error by deep neural networks.</i> <br><br>  I had a choice of strategy how to train a neural network. <br>  Encourage the successful completion of the task or encourage as you approach the completion of the task. <br><br>  I chose the second method for two reasons: <br><br><ul><li>  The probability that the network will ever reach the finish line on its own is very small, so it will be doomed to receive a lot of negative reinforcement.  This will reset the weights of all neurons and the network will be incapable of further learning. <br></li><li>  Deep neural networks are powerful.  I do not exclude that the first method would have been successful if I had huge computational power and a lot of time for training.  I went the way of the least expenses - having developed tricks. <br></li></ul><br><h2>  Neural network architecture </h2><br>  The architecture is developed experimentally, based on the experience of the architect and good luck. <br><br>  Architecture for solving the problem: <br><br><ul><li>  3 input neurons - the coordinates of the agent and the value of the traversed cell (normalized in the range from 0 to 1). <br></li><li>  2 hidden layers of 256 and 128 neurons (reduce the dimension of the layers in the direction of the network output). <br></li><li>  1 layer reset random neurons for the sustainability of learning network. <br></li><li>  4 output neurons - the probability of making a choice of the side for the next step. <br></li><li>  Neuron activation function: sigmoid.  Optimizer: adam. <br></li></ul><br>  sigmoid gives at exit 4 probabilities in the range from 0 to 1, choosing the maximum, we get the side for the next step: [jumpTop, jumpRight, jumpBottom, jumpLeft]. <br><br><h2>  Architecture development </h2><br>  Overtraining occurs when using overly complex models. <br><br>  This is when the network remembers the training data and for the new data that the network has not yet seen, it will work poorly, because the network did not need to look for generalizations, since it had plenty of memory to remember. <br><br>  Under-training - with not enough complex models.  This is when the network had little training data to find generalizations. <br><br>  <b>Conclusion:</b> the more layers and neurons in them, the more data is needed for training. <br><br><h2>  Playing field </h2><br><img src="https://habrastorage.org/webt/3n/we/ck/3nweckh5jsx0-pfebojf_yq3n3k.png"><br><br><h3>  Rules of the game </h3><br>  0 - Entering this cell, the agent is destroyed. <br>  1..44 - Cells whose values ‚Äã‚Äãincrease with each step. <br>  The farther the agent has gone, the greater the reward he will receive. <br>  45 - Finish.  No training takes place, it is only when all agents are destroyed, and the finish is an exception that simply uses the already trained network for the next prediction from the very beginning of the maze. <br><br><h2>  Description of parameters </h2><br>  The agent has ‚Äúantennae‚Äù in four directions from it - they play the role of environmental intelligence and are descriptions for the coordinates of the agent and the value of the cell on which it stands. <br><br>  The description plays the role of predicting the next direction for the movement of the agent.  That is, the agent scans in advance, that there the network learns how to move further towards the increase in the cell value and not to go beyond the limits of the permissible movement. <br><br>  <b>The purpose of the neural network:</b> get more reward. <br>  <b>The purpose of training: to</b> encourage for the right actions, the closer the agent to the task, the higher the reward will be for the neural network. <br><br><h2>  Tricks </h2><br>  The first attempts at training without tricks took several hours of training and the result was far from complete.  Applying certain techniques, the result was achieved in just one hour and six minutes! <br><br><h3>  Agent looping </h3><br>  During the training, the network began to make decisions, make moves back and forth - the problem of ‚Äúuse‚Äù.  Both moves give the network a positive reward, which stopped the process of exploring the maze and did not allow to get out of the local minimum. <br><br>  The first attempt at a solution was to limit the number of agent moves, but this was not optimal, since the agent spent a lot of time looping before self-destructing.  The best solution was to destroy the agent if he went to a cell with a lower value than the one on which he stood - the prohibition to go in the opposite direction. <br><br><h3>  Explore or use </h3><br>  To explore the paths around the current position of the agent, a simple trick was used: at every step, 5 agents would be ‚Äúvoluntary‚Äù researchers.  The progress of these agents will be chosen randomly, and not by the neural network prediction. <br><br>  Thus, we have an increased likelihood that one of the five agents will move beyond the rest and will help in training the network with the best results. <br><br><h3>  Genetic algorithm </h3><br>  Each era on the playing field involved 500 agents.  Prediction for all agents is performed asynchronously for all agents at once, and calculations are delegated to gpu.  Thus, we obtain a more efficient use of the computing power of the computer, which leads to a reduction in the time required to predict a neural network for 500 agents simultaneously. <br><br>  Prediction works faster than learning, therefore the network is more likely to move further along the maze with the least amount of time and the best result. <br><br><h3>  Training on the best in a generation </h3><br>  Throughout the era, for 500 agents, the results of their progress through the maze are preserved.  When the last agent is destroyed, the top 5 agents out of 500 are selected - who have reached the furthest maze through the maze <br><br>  On the results of the best in the era, the neural network will be trained. <br><br>  In this way, we will reduce the amount of memory used by not saving and training the network on agents that do not advance the network. <br><br><h2>  Completion </h2><br>  Not being a specialist in this field, I managed to achieve some success in learning the neural network, and it will turn out for you - dare! <br><br>  Strive to learn faster computers, while we do it better. <br><br><h3>  Materials </h3><br>  <a href="">Code Repository</a> <br>  <a href="https://slavikse.github.io/syntet/index.html">Start learning in the browser</a> <br>  <a href="https://www.tensorflow.org/js">Documentation on tensorflow.js</a> , where you can also find additional resources to learn. <br><br><h3>  Books </h3><br><ul><li>  Deep learning.  Immersion in the world of neural networks <br>  S. Nikolenko, A. Kadurin, E. Arkhangelskaya <br></li><li>  Machine Learning and TensorFlow <br>  N. Shakla <br></li><li>  Self-learning systems <br>  S.I. Nikolenko, A.L. Tulupyev <br></li><li>  Reinforcement training <br>  R.S. Sutton, E.G. Barto <br></li><li>  Self-organizing cards <br>  T. Kohonen <br></li></ul><br><h2>  Thanks for attention! </h2></div><p>Source: <a href="https://habr.com/ru/post/452612/">https://habr.com/ru/post/452612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../4526/index.html">Should corporations be allowed to edit Wikipedia?</a></li>
<li><a href="../452602/index.html">Cisco Hyperflex for high-load DBMS</a></li>
<li><a href="../452608/index.html">Part 1. QInst: it is better to lose a day, then fly five minutes later (we write the instrumentation is trivial)</a></li>
<li><a href="../45261/index.html">Venture Dating Service</a></li>
<li><a href="../452610/index.html">Help and request for it. Article about information security for ordinary users</a></li>
<li><a href="../452614/index.html">How to start programming in Adobe Illustrator. Part two</a></li>
<li><a href="../452618/index.html">What did Google I / O 2019 talk about: Android 10, AR apps and more</a></li>
<li><a href="../452622/index.html">An introduction to genomics for programmers</a></li>
<li><a href="../452624/index.html">Introduction to Spring Boot Actuator</a></li>
<li><a href="../452636/index.html">‚ÄúI am inevitability myself‚Äù: how do ecosystems appear and what can we expect from them</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>