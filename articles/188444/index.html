<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>To-do: Filter everything and everything</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article is more of a FAQ rather than a full manual. However, much has already been written on Habr√© and for that there is a search by tags. There...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>To-do: Filter everything and everything</h1><div class="post__text post__text-html js-mediator-article">  This article is more of a FAQ rather than a full manual.  However, much has already been written on Habr√© and for that there is a search by tags.  There is no sense to rewrite everything anew. <br><br>  Recently, our state, fortunately or not fortunately, took up the Internet and its contents. <br>  Many will undoubtedly say that rights, freedoms, etc. are violated.  Of course, I think few people have doubts about the fact that the laws that were invented were made by few people who understood the Internet, and their main goal is not to protect us from what is there.  Being a responsible person and driven by prosecutors in some institutions, the question arises of limiting incoming information.  Such institutions, for example, include schools, kindergartens, universities, etc.  them institutions.  And the business also needs to take care of information security. <br>  And our first point on the way to local content filter is <br><a name="habracut"></a><br><h4>  Analysis of what the Internet is and how it works. </h4><br>  It's no secret that 99 percent of the Internet is http.  Further, it is known that each site has a name, page content, url, ip address.  It is also known that several sites can sit on one ip, and vice versa.  Also, url addresses can be both dynamic and constant. <br>  And what is written on the page is written.  From here we draw conclusions that sites can be monitored for: <br><br><ol><li>  Site name </li><li>  page url </li><li>  According to the content written on the page of the site </li><li>  By ip address. </li></ol><br>  Further, all content on the Internet can be divided into three groups: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  This is bad </li><li>  This is an unknown </li><li>  This is good. </li></ol><br>  And from this follows two ideological paths: <br><br><ol><li>  We only allow what is good and prohibit the bad and the unknown.  This path is called - <b>BOOLSH</b> (and sometimes small). White list </li><li>  We only allow what is good and unknown.  We prohibit only the bad.  This path bears the proud name Blacklist. </li></ol><br>  <u>And of course between these two paths there is a middle ground ‚Äî we prohibit bad, we resolve the good, and we analyze the unknown and decide online whether it is bad or good.</u> <br><br><h4>  Means of their implementation. </h4><br>  Here again, two ways: <br><br><ul><li>  We take a turnkey solution. </li></ul>  Such solutions also come in 3 types ‚Äî paid, free, limited (until you give the money). <br><br>  Paid solutions are hardware (tobish a box with what is not known, but doing its job), hardware-software (this is the same box, but already with full-fledged OS and corresponding applications) and software. <br>  Free solutions are software only.  But there are exceptions, but this is exactly the case that confirms the rule. <br>  These include, for example, Kaspersky antivirus related functionality, ideco.ru, netpolice, kerio, etc.  It is easy to find them, because they are well advertised and it is enough to enter something like this in the search bar - to buy a content filter. <br>  Free solutions have one drawback ‚Äî they can't do everything at once.  to find them more difficult.  But here is a list of them: PfSense, SmoothWall (there are two types - paid and free. Free bit is not functional), UntangleGateway, Endian Firewall (also paid and free), IPCOP, Vyatta, ebox platform, Comixwall (A wonderful solution. You can download from my site is <a href="http://93.190.205.100/main/moya-biblioteka/comixwall">93.190.205.100/main/moya-biblioteka/comixwall</a> ).  All these solutions have one drawback - limitations. <br><br><ul><li>  We do everything by hand. </li></ul>  This path is the most difficult, but the most flexible.  Allows you to create everything that your heart desires (including a loophole). <br>  There is a great many components.  But the most powerful and necessary is <br><br><ol><li>  Squid. Without a proxy or where. </li><li>  Dansguardian.  This is the heart of the entire content filter.  His only free rival (not counting his forks) is the POESIA filter (but he is very dense). </li><li>  DNS server bind. </li><li>  Clamav.  Antivirus. </li><li>  Squidguard, rezhik and to them similar redirectors for a proxy. </li><li>  Squidclamav. </li><li>  Sslstrip.  This utility makes encrypted https traffic, decrypted http traffic. <br>  <a href="http://www.thoughtcrime.org/software/sslstrip">www.thoughtcrime.org/software/sslstrip</a> .  Analogs to her proxy server flipper and charly proxy.  But analogs work on Windows.  And the second is paid.  But who needs it, then you can expand the wine. </li><li>  Black lists.  These lists can be <a href="http://www.shallalist.de/">obtained</a> from <a href="http://www.shallalist.de/">www.shallalist.de</a> (1.7 million sites), <a href="http://www.urlblacklist.com/">www.urlblacklist.com</a> (namely the big version with more than 10 million sites), <a href="http://www.digincore.com/">www.digincore.com</a> (about 4 million), lists of directories. </li><li>  Whitelists.  It's all very tight.  The only normal (meaning-big) Russian-language list can be obtained from the <b>Safe Internet League</b> , and then only as a proxy of the Safe Internet League or the program <a href="http://www.ligainternet.ru/encyclopedia-of-security/parents-and-teachers/parents-and-teachers-detail.php%3FID%3D532">www.ligainternet.ru/encyclopedia-of-security/parents-and-teachers/parents-and-teachers -detail.php? ID = 532</a> .  By the way, in connection with the digest authorization on the proxy league, this proxy can not be picked up by squid.  If anyone knows how to pick up as a parent proxy, proxy server with digest authentication, please inform. </li><li>  DNS lists.  There are two well-known options.  The first is skydns filter <a href="https://www.skydns.ru/">www.skydns.ru</a> . <br>  The second is yandex dns <a href="http://dns.yandex.ru/">dns.yandex.ru</a> . <br>  Skydns is more functional, in contrast to Yandex. </li></ol><br><br><h4>  Where filtering occurs. </h4><br>  The following options are possible: <br><br><ol><li>  On the user's computers without centralized management, as a system component or application. </li><li>  The same as the first, but with centralized management (as an example of KASPERSKY ADMINISTRATION KIT). </li><li>  Component to the browser.  There are appropriate plugins for chrome and fox </li><li>  On a single computer or cluster of computers (including option-on the gateway). </li><li>  Distributed. </li></ol><br>  1 and 2, 3 options in terms of filtering speed are the fastest with mass network use. <br>  In terms of effort, 1 and 3 are the most labor-intensive. <br>  From the point of view of reliability not bypassing the filtering by the user, then 4-first place. <br>  5 option is a dream.  But it is not anywhere. <br><br>  Now the next question: <br><br><h4>  Reliability filtering. </h4><br>  I think it is clear.  Protection needs to be made multi-level, because what leaks at one level of protection will be blocked by another level. <br><br>  let `s talk about <br><br><h4>  On the shortcomings of the levels of protection. </h4><br><ul><li>  Lists </li></ul>  The Internet is constantly and most importantly, a very rapidly changing environment.  It is clear that our lists will not keep up with the Internet, and even more so if we keep their hands.  Therefore, participate in the list-making communities and use not only files with lists, but also list services, where everything will be done for us (for example, skydns and yandex). <br>  And the list does not guarantee that something is written on some page, but the site itself is completely white and fluffy. <br>  <b>Use multiple lists.</b>  <b>What did not fall into one may fall into another. !!!</b> <br>  The list programs include Netpolice (http://netpolice.ru), censor (http://icensor.ru/), Traffic Inspector for schools (http://www.smart-soft.ru/ru) and etc. Usually, programs that can do lexical parsing can work according to lists. <br>  Censor has an old base from 2008.  But free in everything.  Netpolice has many versions and is free but truncated. <br>  And do not forget, neither black nor whitelists can protect you by 100%.  Only lexical analysis is capable of that. <br><br><ul><li>  Analysis for viruses. </li></ul>  Here the main problem is the anti-virus database.  Again, one antivirus on the gateway, the other in the workplace. <br><br><ul><li>  Analysis of the content written on the page. </li></ul> Here the main problem is the lexical analysis of the text.  Nobody has money for artificial intelligence, therefore they use a base of words and expressions with a weighting factor.  The smaller the base, the less effective the filtering, but the larger the base, the more effective it is, but also labor-intensive.  For example, parsing the work of Jules Verne. The mysterious island with lib.ru takes 8 seconds with my base and dansguardian (core2duo 2.66).  And the base must be taken somewhere.  I had to do a normal base myself than with you and share <a href="http://93.190.205.100/main/dlya-dansguardian/spiski/view">93.190.205.100/main/dlya-dansguardian/spiski/view</a> . <br><br>  The next question is <br><br><h4>  Ability to bypass the user content filtering. </h4><br>  This issue can be solved in two radical ways. <br><ol><li>  To prohibit direct access to the network, with the exception of passing through a proxy server (the proxy must also be limited to the CONNECT method to the list of domains and / or ip or mac addresses.) We do this either using iptables, or simply write net.ipv4.ip_forward in sysctl.conf = 0  Well iptables is a question of a separate article. </li><li>  To prohibit users in the workplace to put something.  The thing is clear: no program, no crawl. </li></ol><br><h4>  The issue is performance. </h4><br>  There is more or less everything is clear, more memory, more hertz, more cache.  And it is very useful for those who have small powers to use CFLAGS optimization.  This allows you to do all the Linux and fryahi, but especially convenient gentoo, calculate linux, slackware, freebsd. <br>  Who has multi-core processors, then use OPEMNP (dansguardian suitable for it can take <a href="http://93.190.205.100/main/dlya-dansguardian">93.190.205.100/main/dlya-dansguardian</a> from me. By the way, it also fixed the error with the impossibility of downloading data to the Internet.) CFLAGS = "- fopenmp".  LDFLAGS = "- lgomp".  Remember to include -O3 -mfpmath = sse + 387.  About autopatching here. <br><br><h4>  Question hierarchy of caches and proxies. </h4><br>  If you have a lot of computers and you have the opportunity to use several as a filter, then do so.  On one, put the squid proxy server and point it to the parameters of the parent caches with the round-robin parameter (http://habrahabr.ru/post/28063/).  The dansguardian acts as a parent on each specific computer with squid in conjunction (for without a superior dansguardian does not know how).  Higher rankings are located on the same computers on which dansguardians are located.  For the upstream big cache does not make sense, and for the first, necessarily the largest cache.  Even if you have one machine, then on it, anyway, do a bunch of squid1-&gt; dansguardian-&gt; squid2-&gt; provider with the same distribution of caching.  On dansguardian, do not impose anything, except for the analysis written on the pages, redrawing the content, headers and some url blocking mime types.  In no case do not hang on it antivirus and black sheets, otherwise there will be brakes. <br><br>  List analysis let them do squid1 and squid2. <br>  Let squidclamav do a virus scan via c-icap on squid2.  We hang white lists on squid1. <br>  Everything in the white list should go directly to the Internet, bypassing the parent proxy. !!! <br><br>  The DNS server is sure to use ours, in which we use redirection to skydns or dns from yandex.  If there are local resources of the provider, then add the forward zone to the provider dns.  Also, in the dns server, we register the local zone for the necessary intranet resources (and that would be beautiful, they are needed).  Specify nosslsearch google search.  In squid configs, we will definitely use our dns. <br>  For all we use Webmin webcam and command line.  On windows servers we do everything with the mouse. <br><br><h4>  LAN setting </h4><br><ol><li>  Use authentication by ip address.  If you are not a ‚Äúserious‚Äù organization, access with obligatory logging does not require anything. </li><li>  Use logically separated networks in one solid physical network.  Give IP addresses to MAC addresses.  Forbid the connection to the proxy port if the MAC address of the machine does not match the IP address assigned to this MAC address. </li><li>  Configure iptables so that calls to any ports (3128, 80, 80, 3130, 443) go through the port of the proxy server. </li><li>  Configure the automatic configuration of the proxy server on the network via dns and dhcp.  <a href="http://www.lissyara.su/articles/freebsd/trivia/proxy_auto_configuration/">www.lissyara.su/articles/freebsd/trivia/proxy_auto_configuration</a> </li><li>  Group and filtering level do by ip address. </li><li>  You can configure the proxy in the browser settings. </li></ol><br><br><h4>  We are going to check. </h4><br>  In this case, all the sliders to the maximum. <br>  Additionally, prohibit all video sites, contact, social networks, music portals, file sharing and file sharing networks. <br>  Forbid mp3. <br>  Put a tick in front of a safe search in your SKYDNS account. <br>  Be sure to tidy up the documentation !!! <br><br><h4>  Https filtering </h4><br>  To do this, between squid2 and the provider, we insert sslstrip.  This utility makes encrypted https traffic, decrypted http traffic.  <a href="http://www.thoughtcrime.org/software/sslstrip/">www.thoughtcrime.org/software/sslstrip</a> .  It is also possible in the squid1 rules to set matches for port 443 and domains for ban / permission. <br><br><h4>  Another couple of tips. </h4><br><ul><li>  Not all sites are correctly filtered.  Therefore, use the bypass feature blocked by dansguardian.  A ready page can be taken from me <a href="http://93.190.205.100/main/dlya-dansguardian/stranichka-blokirovka-i-razblokirovka-dlya-dansguardian/view">93.190.205.100/main/dlya-dansguardian/stranichka-blokirovka-i-razblokirovka-dlya-dansguardian/view</a> . </li><li>  Always keep logs of site visits and keep statistics for the year.  There will always be smart people who want to do something illegal on the Internet.  It is enough ip identifier, by virtue of sufficiency and in the name of enforcing the law of personal data protection.  Statistics do open. </li><li>  There are sites that are not subject to dansguardian.  These are the ones who use json.  This, for example, yandex.ru, video.yandex.ru.  Do for them authorization by password, through squid1. </li><li>  Not all providers comply with the law and from what is written in the federal list of extremist materials and on <a href="http://zapret-info.gov.ru/">zapret-info.gov.ru is</a> not blocked.  Therefore, for the first, read and fill out the database of words and expressions, and for the second, use the unloading antizapret.info. <br>  Know, most prosecutors do not care who is to blame.  Seen means visible.  And at least do what. </li><li>  Do not forget and put snort with snortsam.  Security is above all, even more so if you have a white ip address on the gateway. </li><li>  Many search engines have the ability to filter the results.  This is done by adding a special parameter to the request, or via cookies.  Recently, they have increasingly begun to switch to cookies, so a corresponding dansguardian setting is needed.  Yes, and configs thereof, <a href="http://93.190.205.100/main/dlya-dansguardian/rabochie-i-prailnye-konfigi-dlya-dansguardian-2-12-0-3-r2/view">you can take from me</a> .  There they are registered.  In addition, lists must be made in 4 encodings (1251, utf8, koi8r, utf16) and select the correct filtering method (more details in configs).  For youtube use <a href="https://support.google.com/youtube/answer/2695317%3Fhl%3Den%26ref_topic%3D2592688">edufilter</a> . </li><li>  A good squid configuration manual can be found <a href="http://wiki.rsu.edu.ru/wiki/%25D0%259D%25D0%25B0%25D1%2581%25D1%2582%25D1%2580%25D0%25BE%25D0%25B9%25D0%25BA%25D0%25B0_proxy-%25D1%2581%25D0%25B5%25D1%2580%25D0%25B2%25D0%25B5%25D1%2580%25D0%25B0">here</a> . </li></ul></div><p>Source: <a href="https://habr.com/ru/post/188444/">https://habr.com/ru/post/188444/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../188430/index.html">Seven skills of a professional programmer</a></li>
<li><a href="../188432/index.html">First PyPy3 beta released with Python 3 support</a></li>
<li><a href="../188436/index.html">Habrahabr now accepts images for blog posts for permanent storage</a></li>
<li><a href="../188438/index.html">Dependency Injection in Unity3d</a></li>
<li><a href="../188440/index.html">Security asterisk</a></li>
<li><a href="../188446/index.html">How I collected a silent computer</a></li>
<li><a href="../188448/index.html">Regular expressions in nuclear transmutation calculations</a></li>
<li><a href="../188450/index.html">This is a mythical word team</a></li>
<li><a href="../188454/index.html">MGTS GPon subscribers under threat of hacking, new networks - new problems</a></li>
<li><a href="../188458/index.html">Principles of designer portfolio organization</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>