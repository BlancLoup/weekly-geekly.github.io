<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Protected by router: QoS</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="QoS is a big topic. Before we talk about the subtleties of settings and various approaches in the application of traffic processing rules, it makes se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Protected by router: QoS</h1><div class="post__text post__text-html js-mediator-article"> QoS is a big topic.  Before we talk about the subtleties of settings and various approaches in the application of traffic processing rules, it makes sense to recall what QoS is in general. <br><br>  <b>Quality of Service (QoS)</b> is a technology for providing different classes of traffic with different priorities in service. <br><br>  First, it is easy to understand that any prioritization makes sense only when there is a queue for service.  It is there, in the queue, that you can ‚Äúslip in‚Äù first, using your right. <br>  The queue is formed where the narrow (usually such places are called "bottle neck", bottle-neck).  A typical ‚Äúneck‚Äù is an Internet connection to an office, where computers connected to the network at least at a speed of 100 Mbit / s all use the channel to the provider, which rarely exceeds 100 Mbit / s, and often amounts to a small 1-2-10 Mbit / s .  For everyone. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Secondly, QoS is not a panacea: if the ‚Äúneck‚Äù is too narrow, then the physical interface buffer is often full, where all the packets that are about to exit through this interface are placed.  And then newly arrived packages will be destroyed, even if they are super-necessary.  Therefore, if the queue on the interface on average exceeds 20% of its maximum size (on cisco routers, the maximum queue size is usually 128-256 packets), there is reason to think hard about the design of your network, build additional routes or extend the band to the provider. <br><br>  We will deal with the components of technology <br><br>  (further under the cut, a lot) <br><a name="habracut"></a><br>  <b>Marking</b>  In the fields of the headers of various network protocols (Ethernet, IP, ATM, MPLS, etc.) there are special fields allocated for marking traffic.  To mark the same traffic is necessary for the subsequent more simple processing in queues. <br><br>  Ethernet  The Class of Service (CoS) field is 3 bits.  Allows you to divide traffic into 8 streams with different markings. <br><br>  IP.  There are 2 standards: old and new.  In the old one there was a ToS field (8 bits), from which, in turn, 3 bits were allocated called IP Precedence.  This field has been copied to the CoS Ethernet header field. <br>  Later a new standard was defined.  The ToS field has been renamed DiffServ, and an additional 6 bits are allocated for the Differencial Service Code Point (DSCP) field, in which the parameters required for this type of traffic can be transmitted. <br><br>  Marking data is best closer to the source of this data.  For this reason, most IP phones themselves add the DSCP = EF or CS5 field to the IP header of voice packets.  Many applications also tag traffic on their own in the hope that their packets will be processed priority.  For example, this "sin" peer-to-peer networks. <br><br>  <b>The queues.</b> <br><br>  Even if we do not use any prioritization technologies, this does not mean that there are no queues.  In a narrow place the queue will arise in any case and will provide the standard First In First Out FIFO mechanism.  Such a queue, obviously, will allow not to destroy the packets immediately, saving them before sending them to the buffer, but will not provide any preferences, say, to voice traffic. <br><br>  If you want to give some selected class an absolute priority (that is, packets from this class will always be processed first), then this technology is called <b>Priority queuing</b> .  All packets that are in the physical outgoing interface buffer will be divided into 2 logical queues and packets from the privileged queue will be sent until it becomes empty.  Only then will the packets from the second queue be transmitted.  This technology is simple, rather rough, it can be considered obsolete, because  processing of non-priority traffic will constantly stop.  On cisco routers you can create <br>  4 queues with different priorities.  They maintain a strict hierarchy: packets from less privileged queues will not be served until all queues with a higher priority are empty. <br><br>  <b>Fair Queuing</b> .  A technology that allows each class of traffic to grant the same rights.  As a rule, it is not used, because  gives little in terms of improving the quality of service. <br><br>  <b>Weighted Fair Queuing (WFQ</b> ).  A technology that provides different rights to different classes of traffic (it can be said that the ‚Äúweight‚Äù is different for different queues), but at the same time serves all the queues.  "On the fingers" it looks like this: all packets are divided into logical queues, using <br>  IP Precedence as a criterion.  The same field sets the priority (the more, the better).  Further, the router calculates the packet from which queue "faster" to transmit and sends it. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb2/3e8/e25/fb23e8e253dafa6e865d573237f8a4cd.jpg" alt="image"><br><br>  He considers it according to the formula: <br><br>  dT = (t (i) -t (0)) / (1 + IPP) <br><br>  IPP - IP Precedence field value <br>  t (i) - The time required for the actual transmission of the packet by the interface.  It can be calculated as L / Speed, where L is the packet length, and Speed ‚Äã‚Äãis the interface transfer rate <br><br>  This queue is enabled by default on all interfaces of cisco routers, except for point-to-point interfaces (HDLC or PPP encapsulation). <br><br>  WFQ has a number of drawbacks: such a queue uses previously marked packets, and does not allow to determine traffic classes and allocated band independently.  Moreover, as a rule, no one marks the IP Precedence field, so packets are unmarked, i.e.  all fall into one queue. <br><br>  The development of WFQ has become a weighted fair queue based on classes ( <b>Class-Based Weighted Fair Queuing, CBWFQ</b> ).  In this queue, the administrator himself sets up traffic classes, following various criteria, for example, using ACLs as a template or analyzing protocol headers (see NBAR).  Next, for these classes <br>  the ‚Äúweight‚Äù is determined and the packets of their queues are serviced in proportion to the weight (more weight - more packets will go out of this queue per unit of time) <br><br>  But such a queue does not provide for the strict transmission of the most important packets (as a rule, voice packets or packets of other interactive applications).  Therefore, a hybrid of Priority and Class-Based Weighted Fair Queuing - <b>PQ-CBWFQ</b> , also known as <b>Low Latency Queuing (LLQ), appeared</b> .  In this technology, you can set up to 4 priority queues, the rest of the classes served by the mechanism of CBWFQ <br><br>  LLQ is the most convenient, flexible and frequently used mechanism.  But it requires setting up classes, setting policies and applying policies on the interface. <br><br>  I will tell you more about the settings further. <br><br>  Thus, the process of providing quality service can be divided into 2 stages: <br>  <b>Marking</b>  Close to the sources. <br>  <b>Packet handling</b>  Putting them in a physical queue on the interface, subdivision into logical queues and providing these logical queues with various resources. <br><br>  QoS technology is quite resource-intensive and loads the processor quite significantly.  And the more it loads, the deeper the headers have to climb to classify packets.  For comparison: it is much easier for a router to look at the header of an IP packet and analyze 3 bits of IPP there, rather than unwind the stream almost to the application level, determining what protocol goes inside (NBAR technology) <br><br>  To simplify further traffic processing, as well as to create a so-called ‚Äútrusted boundary‚Äù (trusted boundary), where we believe all QoS-related headers, we can do the following: <br>  1. On switches and access level routers (close to client machines), catch packets, scatter them into classes <br>  2. In the policy as an action, repaint the headers in one's own way or transfer the values ‚Äã‚Äãof the higher level QoS headers to the lower ones. <br><br>  For example, on the router we catch all the packets from the guest WiFi domain (we assume that there may be non-managed computers and software that can use non-standard QoS headers), change any IP headers to default ones, match header 3 headers (DSCP) level (CoS) <br>  so that further switches can efficiently prioritize traffic using only the data link layer label. <br><br>  <b>LLQ Setup</b> <br><br>  Setting up the queues is to configure the classes, then for these classes it is necessary to determine the parameters of the bandwidth and apply the entire structure to the interface. <br><br>  Creating classes: <br><br>  <i>class-map NAME</i> <i><br></i>  <i>match?</i> <i><br><br></i>  <i><b>access-group</b> Access group</i> <i><br></i>  <i><b>Any</b> Any packets</i> <i><br></i>  <i><b>class-map</b> Class map</i> <i><br></i>  <i><b>cos</b> IEEE 802.1Q / ISL class of service / user priority values</i> <i><br></i>  <i><b>destination-address</b> Destination address</i> <i><br></i>  <i><b>discard-class</b> Discard behavior identifier</i> <i><br></i>  <i><b>dscp</b> Match DSCP in IP (v4) and IPv6 packets</i> <i><br></i>  <i><b>flow flow</b> based QoS parameters</i> <i><br></i>  <i><b>fr-de</b> Match on frame-relay de bit</i> <i><br></i>  <i><b>fr-dlci</b> Match on fr-dlci</i> <i><br></i>  <i><b>input interface</b> select an input interface to match</i> <i><br></i>  <i><b>ip</b> IP specific values</i> <i><br></i>  <i><b>mpls</b> multi protocol label <b>switching</b></i> <i><br></i>  <i><b>not</b> Negate this match result</i> <i><br></i>  <i><b>packet</b> layer 3 <b>packet</b> length</i> <i><br></i>  <i><b>precedence</b> Match Precedence in IP (v4) and IPv6 packets</i> <i><br></i>  <i><b>protocol</b> protocol</i> <i><br></i>  <i><b>qos-group</b> Qos-group</i> <i><br></i>  <i><b>source-address</b> Source address</i> <i><br></i>  <i><b>vlan</b> vlans to match</i> <i><br><br></i> <br><br>  Packages can be sorted into classes by various attributes, for example, by specifying an ACL as a template, or by a DSCP field, or by highlighting a specific protocol (NBAR technology is turned on) <br><br>  Creating a policy: <br><br>  <i>policy-map POLICY</i> <i><br></i>  <i>class NAME1</i> <i><br></i>  <i>?</i> <i><br><br></i>  <i><b>bandwidth</b> bandwidth</i> <i><br></i>  <i><b>compression</b> Activate Compression</i> <i><br></i>  <i><b>drop</b> Drop all packets</i> <i><br></i>  <i><b>log</b> log IPv4 and ARP packets</i> <i><br></i>  <i><b>netflow-sampler</b> netflow action</i> <i><br></i>  <i><b>police police</b></i> <i><br></i>  <i><b>priority</b> Strict Scheduling Priority for this Class</i> <i><br></i>  <i><b>queue-limit</b> Queue Max Threshold for Tail Drop</i> <i><br></i>  <i>Random <b>-detect</b> Enable Early Detection as drop policy</i> <i><br></i>  <i><b>service-policy</b> Configure Flow Next</i> <i><br></i>  <i><b>set</b> set QoS values</i> <i><br></i>  <i><b>shape</b> Traffic Shaping</i> <i><br><br></i> <br>  For each class in politics, you can either allocate a priority piece of the band: <br><br>  <i>policy-map POLICY</i> <i><br></i>  <i>class NAME1</i> <i><br></i>  <i>priority?</i> <i><br><br></i>  <i><b>[8-2000000]</b> Kilo Bits per second</i> <i><br></i>  <i><b>percent</b> % of total bandwidth</i> <i><br><br></i> <br>  and then packages of this class will always be able to count at least on this piece. <br><br>  Or describe what ‚Äúweight‚Äù this class has within the CBWFQ <br><br>  <i>policy-map POLICY</i> <i><br></i>  <i>class NAME1</i> <i><br></i>  <i>bandwidth?</i> <i><br><br></i>  <i><b>[8-2000000]</b> Kilo Bits per second</i> <i><br></i>  <i><b>percent</b> % of total Bandwidth</i> <i><br></i>  <i><b>remaining</b> % of the remaining bandwidth</i> <i><br><br></i> <br>  In both cases, you can specify both the absolute value and the percentage of the entire available band. <br><br>  A reasonable question arises: how does the router know the whole band?  The answer is trivial: from the bandwidth parameter on the interface.  Even if it is not configured explicitly, some of its value is required.  It can be viewed with the sh int command. <br><br>  Also be sure to remember that by default you do not dispose of the entire band, but only 75%.  Packages that are clearly not included in other classes fall into the class-default.  This setting for the default class can be set explicitly. <br><br>  <i>policy-map POLICY</i> <i><br></i>  <i>class class-default</i> <i><br></i>  <i>bandwidth percent 10</i> <i><br></i> <br><br><h6>  (UPD, thanks OlegD) </h6>  Change the maximum available band from the default 75% can be a command on the interface <br><br>  <i>max-reserved-bandwidth [percent]</i> <br><br>  Routers jealously watch that the admin does not accidentally give out more bandwidth than there is and swear at such attempts. <br><br>  It seems that the policy will issue no more than what is written to the classes.  However, this situation will be only if all the queues are full.  If some kind of is empty, then the line allocated to it will fill the queues in proportion to its ‚Äúweight‚Äù. <br><br>  All this construction will work like this: <br><br>  If there are packets from the class with the priority indication, then the router focuses on the transfer of these packets.  Moreover, since  There may be several such priority queues, then the band is divided between them in proportion to the specified percentages. <br><br>  Once all priority packets have ended, the CBWFQ queue comes.  For each countdown from each queue, the share of packets specified in the settings for this class is ‚Äúscratched out‚Äù.  If part of the queues is empty, then their band is divided in proportion to the class ‚Äúweight‚Äù between the loaded queues. <br><br>  Application on the interface: <br><br>  <i>int s0 / 0</i> <i><br></i>  <i>service-policy [input | output] POLICY</i> <i><br></i> <br><br>  And what to do if you need to strictly cut packages from the class that go beyond the permitted speed?  After all, the indication of bandwidth only distributes the band between classes when the queues are loaded. <br><br>  To solve this problem, for the traffic class, the policy has technology <br><br>  <i>police [speed] [birst] conform-action [action] exceed-action [action]</i> <br><br>  it allows you to explicitly specify the desired average speed (speed), the maximum ‚Äúoutlier‚Äù, i.e.  amount of data transmitted per unit of time.  The larger the ‚Äúovershoot‚Äù, the greater the actual transfer rate may deviate from the desired average.  Also indicated: action for normal traffic, not exceeding <br>  specified speed and action for traffic exceeding the average speed.  Actions may be <br><br>  <i>police 100000 8000 conform-action?</i> <i><br><br></i>  <i><b>drop</b> drop packet</i> <i><br></i>  <i><b>exceed-action</b></i> <i><br></i>  <i>conform + exceed burst</i> <i><br></i>  <i><b>set-clp-transmit</b> set atm clp and send it</i> <i><br></i>  <i><b>set-discard-class-transmit</b> set discard-class and send it</i> <i><br></i>  <i><b>set-dscp-transmit</b> set-up dscp and send it</i> <i><br></i>  <i>FR DE send and send it</i> <i><br></i>  <i><b>set-mpls-exp-imposition-transmit</b> set</i> <i><br></i>  <i><b>set-mpls-exp-top-</b> set</i> <i><br></i>  <i><b>set-prec-transmit</b> packet forwarding and send it</i> <i><br></i>  <i><b>set-qos-transmit</b> set-qos-group and send it</i> <i><br></i>  <i><b>transmit</b> transmit packet</i> <i><br><br><br></i> <br><br>  Often there is also another task.  Suppose that it is necessary to limit the flow going towards the neighbor with the slow channel. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c7/3b1/6c4/8c73b16c47a02d460b24dda022eae309.jpg" alt="image"><br><br>  In order to accurately predict which packets will reach the neighbor, and which will be destroyed due to channel congestion on the ‚Äúslow‚Äù side, it is necessary to create a policy on the ‚Äúfast‚Äù side that would process queues in advance and destroy redundant packets. <br><br>  And here we are faced with one very important thing: to solve this problem, we need to emulate the ‚Äúslow‚Äù channel.  For this emulation, it is not enough just to scatter packets in queues, you also need to emulate the physical buffer of the ‚Äúslow‚Äù interface.  Each interface has a packet rate.  Those.  per unit of time, each interface can transmit no more than N packets.  Usually, the physical interface buffer is calculated so as to provide an ‚Äúautonomous‚Äù operation of the interface for several units of time.  Therefore, the physical buffer, say, GigabitEthernet will be ten times larger than any Serial interface. <br><br>  What is wrong with remembering a lot?  Let's take a closer look at what will happen if the buffer on the fast transmitting side is substantially larger than the buffer of the host. <br><br>  Let for simplicity there is 1 queue.  On the ‚Äúfast‚Äù side we simulate a low transmission rate.  This means that when packages fall under our policy, they will start to accumulate in the queue.  Because  Since the physical buffer is large, then the logical queue will be impressive.  Some applications (working through TCP) will receive a late notification that some packets have not been received and will keep the large window size for a long time, loading the receiving side.  This will occur in the ideal case, when the transmission rate will be equal to or less than the reception rate.  But the host interface can also be loaded by other packages. <br>  and then a small queue on the receiving side will not be able to accommodate all the packets transmitted to it from the center.  There will be losses that will entail additional transfers, but there will still remain a solid ‚Äútail‚Äù of previously accumulated packets in the transfer buffer, which will be transmitted ‚Äúidle‚Äù, since  on the receiving side did not wait for an earlier package, which means that more of the post will be simply ignored. <br><br>  Therefore, in order to correctly solve the problem of reducing the transmission rate to a slow neighbor, the physical buffer must also be limited. <br><br>  This is done by the team <br><br>  <i>shape average [speed]</i> <br><br>  And now the most interesting thing: what to do if, in addition to emulating a physical buffer, I need to create logical queues inside it?  For example, prioritize voice? <br><br>  For this, a so-called nested policy is created, which is applied inside the main one and divides into logical queues what gets into it from the parent. <br><br>  It is time to disassemble some romping example based on the above picture. <br><br>  Suppose we are going to create sustainable voice channels via the Internet between CO and Remote.  For simplicity, let the Remote network (172.16.1.0/24) have only a connection to the CO (10.0.0.0/8).  The interface speed on the Remote is 1 Mbps and 25% of this speed is allocated to voice traffic. <br><br>  Then first we need to highlight the priority class of traffic from both sides and create a policy for this class.  In addition, create a class that describes the traffic between offices. <br><br>  WITH: <br><br>  <i>class-map RTP</i> <i><br></i>  <i>match protocol rtp</i> <i><br><br></i>  <i>policy-map RTP</i> <i><br></i>  <i>class RTP</i> <i><br></i>  <i>priority percent 25</i> <i><br><br></i>  <i>ip access-list extended CO_REMOTE</i> <i><br></i>  <i>permit ip 10.0.0.0 0.255.255.255 172.16.1.0 0.0.0.255</i> <i><br><br></i>  <i>class-map CO_REMOTE</i> <i><br></i>  <i>match access-list CO_REMOTE</i> <i><br><br></i> <br>  On the Remote, we‚Äôll do it differently: let us, because of the iron's strength, we cannot use NBAR, then all we have to do is explicitly describe the ports for RTP <br><br>  <i>ip access-list extended RTP</i> <i><br></i>  <i>permit udp 172.16.1.0 0.0.0.255 range 16384 32768 10.0.0.0 0.255.255.255 range 16384 32768</i> <i><br><br></i>  <i>class-map RTP</i> <i><br></i>  <i>match access-list RTP</i> <i><br><br></i>  <i>policy-map QoS</i> <i><br></i>  <i>class RTP</i> <i><br></i>  <i>priority percent 25</i> <i><br><br></i> <br><br>  Next, you need to emulate a slow interface in CO, apply a nested policy to prioritize voice packets <br><br>  <i>policy-map QoS</i> <i><br></i>  <i>class CO_REMOTE</i> <i><br></i>  <i>shape average 1,000,000</i> <i><br></i>  <i>service-policy RTP</i> <i><br><br></i> <br>  and apply the policy on the interface <br><br>  <i>int g0 / 0</i> <i><br></i>  <i>service-policy output QoS</i> <i><br></i> <br><br>  On the Remote, set the bandwidth parameter (in kbps) in accordance with the speed of the interface.  Let me remind you that it is from this parameter that 25% will be considered.  And apply the policy. <br><br>  <i>int s0 / 0</i> <i><br></i>  <i>bandwidth 1000</i> <i><br></i>  <i>service-policy output QoS</i> <i><br></i> <br><br>  The narrative would not be complete if not cover the capabilities of the switches.  It is clear that pure L2 switches are not able to look so deep into packets and divide them into classes according to the same criteria. <br><br>  On smarter L2 / 3 switches on routed interfaces (i.e., either on interface vlan, or if the port is derived from the second level with the <i>no switchport</i> command), the same construction is used that works on routers, and if the port or the entire switch works in L2 mode (true for models 2950/60), then only the indication ‚Äúpolice‚Äù can be used for the traffic class, and priority or bandwidth are not available. <br><br>  From a purely defensive point of view, knowledge of the fundamentals of QoS will quickly prevent bottlenecks caused by the work of worms.  As you know, the worm itself is quite aggressive in the propagation phase and creates a lot of parasitic traffic, i.e.  essentially denial of service (DoS) attack. <br><br>  And often the worm spreads through the ports required for operation (TCP / 135,445.80, etc.). It would be rash to simply close these ports on the router, so it‚Äôs more humane to do this: <br><br>  1. We collect statistics on network traffic.  Either via NetFlow, or NBAR, or via SNMP. <br><br>  2. We identify the profile of normal traffic, i.e.  According to statistics, on average, the HTTP protocol takes no more than 70%, ICMP does not exceed 5%, and so on.  Such a profile can either be created manually or by applying statistics accumulated by NBAR.  ,     ,      <br>  <i>autoqos</i> :) <br><br> 3. ,       .        ,      :         . <br><br> 4.   ( <i>class-map ‚Äî policy-map ‚Äî service-policy</i> )        ,            . <br><br>   </div><p>Source: <a href="https://habr.com/ru/post/62831/">https://habr.com/ru/post/62831/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../62815/index.html">Dicto project is closed</a></li>
<li><a href="../62816/index.html">partnership with Promdex</a></li>
<li><a href="../62823/index.html">JsImageBox - a lightweight LightBox equivalent</a></li>
<li><a href="../62824/index.html">Technical problems with the registrar webnames.ru</a></li>
<li><a href="../62830/index.html">DI and IoC for beginners</a></li>
<li><a href="../62833/index.html">Fincher Films Facebook</a></li>
<li><a href="../62834/index.html">What is the reason for the family on Facebook</a></li>
<li><a href="../62835/index.html">Conference PM-Labs 2009. July 25, Kiev</a></li>
<li><a href="../62838/index.html">Android received Flash support</a></li>
<li><a href="../62839/index.html">Pieces of video SPIC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>