<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>NUM ismatics, Numerology and just about NUMA</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="NUMA (Non-Uniform Memory Access - ‚ÄúUneven Memory Access‚Äù or Non-Uniform Memory Architecture - ‚ÄúUneven Memory Architecture‚Äù) is not a new technology. I...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>NUM ismatics, Numerology and just about NUMA</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/893/443/2fe/8934432fe642a0c214479a8119ae6efb.jpg" align="right">  <b>NUMA</b> (Non-Uniform Memory Access - ‚ÄúUneven Memory Access‚Äù or Non-Uniform Memory Architecture - ‚ÄúUneven Memory Architecture‚Äù) is not a new technology.  I would even say that it is quite old.  That is, in terms of musical instruments, this is not even a button accordion, but rather a <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B0%25D1%2580%25D0%25B3%25D0%25B0%25D0%25BD">harp</a> . <br>  But despite this, there are no sensible articles explaining what it is, and most importantly, how to work with it effectively.  This post, which corrects this situation, is primarily intended for those who know nothing about NUMA, but also contain something interesting for NUM experts, and most importantly, it makes my life easier for me, an Intel engineer, since from now on everyone interested in NUMA Russian-speaking developers will be sent to him. <br><a name="habracut"></a><br><h5>  Three heroes </h5><br>  And we start with the negation of negation.  That is, look at Uniform Memory Access (Uniform Memory Access), also known as <b>SMP</b> (Symmetric Multi Processing - Symmetric Multi-Processing). <br><br>  SMP is an architecture in which processors are connected to common system memory using a bus or similar connection) symmetrically and have equal access to it.  Just as shown in the diagram below (using the example of two CPUs), all Intel multiprocessor machines were arranged when the memory controller (MCH / MGCH), better known as the ‚ÄúNorth Bridge‚Äù (‚ÄúNorthBridge‚Äù) was located in the chipset. <br><br><img src="https://habrastorage.org/storage2/25f/b59/81b/25fb5981bef7af2cced9c51094611988.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The disadvantage of SMP is obvious - as the number of CPUs grows, the bus becomes a bottleneck, significantly limiting the performance of memory-intensive applications.  That is why SMP systems almost do not scale, two or three dozens of processors for them is already a theoretical limit. <br><br>  An alternative to SMP for productive computing is <b>MPP</b> (Massive Parallel Processing). <br>  MPP is an architecture that divides the system into multiple nodes, in which processors have access exclusively to local resources.  MPP scales well, but not so well programmed.  Namely, it does not provide a built-in mechanism for exchanging data between nodes.  That is, MPP software should implement communications, distribution and scheduling of tasks on nodes, which is not suitable for all tasks and their programmers. <br><br>  And finally, <b>NUMA</b> (Non-Uniform Memory Access).  This architecture combines the positive features of SMP and MPP.  A NUMA system is divided into multiple nodes that have access to both its local memory and to the memory of other nodes (logically called ‚Äúremote‚Äù).  <b>Naturally, access to remote memory is much slower than local</b> .  From there, and the name - "non-uniform memory access."  This is not only the name, but also a lack of NUMA architecture, which may be mitigated by special software optimization, which is further. <br><br>  This is how the two-socket NUMA Intel Xeon system (namely, Intel NUMA debuted) with memory controllers integrated into the CPU looks like. <br><img src="https://habrastorage.org/storage2/f28/8c0/b04/f288c0b04ae8ee048800694932b84213.png"><br><br>  The processors are connected here by QPI - <a href="http://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect">Intel QuickPath</a> point-to-point connection with high bandwidth and low transmission latency. <br><br>  The figure does not show the processor cache, but all three levels of the memory cache, of course, are there.  This means that there is also a NUMA feature that needs to be said: NUMA, used in Intel systems, supports the <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25B3%25D0%25B5%25D1%2580%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C_%25D0%25BA%25D1%258D%25D1%2588%25D0%25B0">coherence of caches</a> and shared memory (that is, data correspondence between caches of different CPUs), so it is sometimes called <b>ccNUMA</b> - cache coherent NUMA.  This means that there is a special hardware solution for matching the contents of the caches, as well as the memory, when more than one cache stores the same part of it.  Of course, such a communication cache reduces the overall system performance, but without it, it would be extremely <s>interesting</s> to program a system with an unpredictable current data state.  To reduce the effect of this effect, you should avoid situations where several processors work with one block of memory at once (not necessarily with one variable!).  This is exactly what NUMA products are trying to do. <br><br>  Thus, from hardware, we smoothly moved to the software and performance of NUMA systems. <br><br><h5>  So NUMA is supported by the following OS: </h5><br>  <b>Windows Server 2003</b> , <b>Windows XP</b> 64-bit and <b>Windows Vista</b> - up to 64 logical processors, <br>  <b>Windows 7</b> , <b>Windows Server 2008 R2</b> - full support. <br>  <b>Linux OS</b> kernel: <b>2.6</b> and higher, UNIX OS - <b>Solaris</b> and <b>HP-Unix</b> . <br><br>  If we talk about databases, then NUMA is supported by <b>Oracle8i, Oracle9i, Oracle10g</b> and <b>Oracle11g</b> , as well as <b>SQL Server 2005</b> and <b>SQL Server 2008</b> . <br><br>  NUMA support is also available in <b>Java SE 6u2</b> , <b>JVM 1.6</b> , and also <b>.NET runtime</b> on the aforementioned versions of Windows. <br>  Fully supports NUMA Intel Mathematical Library - <a href="http://software.intel.com/en-us/intel-mkl">MKL</a> . <br>  " <i>NUMA support</i> " means the following - the product is aware of the NUMA topology of the machine on which it is executed, and tries to use it as efficiently as possible, that is, to organize the work of the streams so that they fully use the memory of their node (the one on which this thread is running ) and minimally - aliens.  The key word here is ‚Äútrying‚Äù, since in general it is not always possible to do this. <br>  Therefore, it may happen that a product that does not support NUMA, that is, simply does not know about it, which does not prevent it from being launched and executed on NUMA-systems, will show not worse performance than officially supporting NUMA.  An example of such a product is the famous <a href="http://threadingbuildingblocks.org/">Intel Threading Building Blocks</a> library. <br><br>  That is why in the BIOS of multi-socket servers with NUMA there is a special item ‚Äú <i>Allow / deny NUMA</i> ‚Äù.  Of course, the system topology will not change in any way from the banning of NUMA in the BIOS - remote memory will not come close.  Only the following will happen - the system will not inform the OS and software that it is NUMA, which means that memory allocation and thread layout will be ‚Äúnormal‚Äù, such as on symmetric multiprocessor systems. <br><br>  If the BIOS allows NUMA, then the operating system will be able to learn about the configuration of NUMA nodes from the System Resource Affinity Table (SRAT) in the <a href="http://www.acpi.info/DOWNLOADS/ACPIspec40a.pdf">Advanced Configuration and Power Interface (ACPI)</a> .  Applications can get this information using the <a href="http://oss.sgi.com/projects/libnuma/">libnuma</a> library on Linux, and you know on what systems the <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa363804(v%3Dvs.85).aspx">Windows NUMA interface</a> . <br>  This information is the beginning of NUMA support by your application.  It should be followed directly by an attempt to maximize the use of NUMA.  Common words on this topic have already been said, for further explanation I will turn to a particular example. <br><br>  Suppose you allocate memory with <b>malloc</b> .  If it happens in Linux, then malloc only reserves memory, and its physical allocation occurs only when the memory is actually accessed.  In this case, the memory is automatically allocated on the node that uses it, which is very good for NUMA.  In Windows, malloc works differently, it allocates physical memory directly during allocation, that is, on the node of the thread allocating memory.  Therefore, it may well be removed for other threads that use it.  But there is a NUMA-friendly memory allocation in Windows.  This is <b>VirtualAlloc</b> , which can work just like malloc in Linux.  An even more advanced option is <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa366891(v%3Dvs.85).aspx">VirtualAllocExNuma</a> from the Windows NUMA API. <br><br>  The following simple example using OpenMP, <br><pre><code class="hljs pgsql">main() { ‚Ä¶ #pragma omp parallel { //Parallelized TRIAD <span class="hljs-keyword"><span class="hljs-keyword">loop</span></span>‚Ä¶ #pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> private(j) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (j=<span class="hljs-number"><span class="hljs-number">0</span></span>; j&lt;N; j++) a[j] = b[j]+scalar*c[j]; } //<span class="hljs-keyword"><span class="hljs-keyword">end</span></span> omp parallel ‚Ä¶ } //<span class="hljs-keyword"><span class="hljs-keyword">end</span></span> main</code> </pre> <br>  You can make friends with NUMA by ensuring that each stream initializes the data, causing the corresponding physical memory to bind to the node using it: <br><br><pre> <code class="hljs pgsql">KMP_AFFINITY=compact,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">verbose</span></span> main() { ‚Ä¶ a* = (<span class="hljs-type"><span class="hljs-type">char</span></span> *) VirtualAlloc(<span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>, //same <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b* <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> c* N*(sizeof(<span class="hljs-type"><span class="hljs-type">double</span></span>))+<span class="hljs-number"><span class="hljs-number">1024</span></span>, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE); ‚Ä¶ #pragma omp parallel { #pragma omp <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> private(i) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i=<span class="hljs-number"><span class="hljs-number">0</span></span>;i&lt;N;i++) { a[i] = <span class="hljs-number"><span class="hljs-number">10.0</span></span>; b[i] = <span class="hljs-number"><span class="hljs-number">10.0</span></span>; c[i] = <span class="hljs-number"><span class="hljs-number">10.0</span></span>;} ‚Ä¶ //OpenMP <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> TRIAD <span class="hljs-keyword"><span class="hljs-keyword">loop</span></span>‚Ä¶ #pragma omp parallel <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> private(j) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (j=<span class="hljs-number"><span class="hljs-number">0</span></span>; j&lt;N; j++) a[j] = b[j]+scalar*c[j]; } //<span class="hljs-keyword"><span class="hljs-keyword">end</span></span> omp parallel ‚Ä¶ } //<span class="hljs-keyword"><span class="hljs-keyword">end</span></span> main</code> </pre><br>  <b>Affinity</b> should be mentioned here as a separate item - the forced binding of threads to specific processors, preventing a possible transfer of threads between the processors by the operating system and which could cause a potential "separation" of threads from its used local memory. <br>  To install Affinity, there are corresponding APIs in both Linux and Windows (standard Windows API, and <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa363804(v%3Dvs.85).aspx">NUMA WinAPI</a> ).  Also, the functionality for setting the binding is present in many parallel libraries (for example, in the OpenMP example shown above, the environment variable KMP_AFFINITY is responsible for this). <br>  But you have to understand that, firstly, affinity does not always work (for a system, this is rather a hint than an order), and secondly, the positive effect of the Affinity installation will be only when you fully control the system, that is, , your application works exclusively on it, and the OS itself does not heavily load the system.  If, as is most often the case, there are several applications, moreover, they intensively use the CPU and memory while trying to attach to the same processor, not knowing anything about each other, and the OS competes for the same resources, then using Affinity can be more harm than good <br><br><h5>  Performance. </h5><br>  And now the fun part.  Let us try to find out how, in reality, memory access in NUMA is heterogeneous, and the performance of real applications, respectively, depends on this heterogeneity. <br>  First of all, let's look at the theoretical data.  According to Intel presentations, ‚Äúthe delay of access to remote memory is ~ 1.7x of access to local memory, and the bandwidth of local memory can be up to two times more than remote‚Äù <br>  The real server data on the Xeon 5500 is provided in the Dell datasheet - ‚Äú <i>local memory access latency is 70 nanoseconds, to the remote, 100 nanoseconds (ie, ~ 1.4 times), the local memory bandwidth exceeds remote memory by 40%</i> ‚Äù. <br><br>  On your real system, these approximate data can be obtained using the free Microsoft Sysinternals utility <a href="http://technet.microsoft.com/en-us/sysinternals/cc835722">CoreInfo</a> , which estimates the relative ‚Äúcost‚Äù of memory access for different NUMA nodes.  The result, of course, is very approximate, but some conclusions are worth making. <br>  Coreinfo result example: <br><pre> <code class="bash hljs">Calculating Cross-NUMA Node Access Cost... Approximate Cross-NUMA Node Access Cost (relative to fastest): 00 01 00: 1.0 1.3 01: 1.2 1.0</code> </pre><br>  But the main question is how much the difference in the ‚Äúcost‚Äù of access to NUMA memory will affect the performance of a real application as a whole.  In preparing this article, I came across a very interesting <a href="http://sqlblog.com/blogs/linchi_shea/archive/2012/01/30/performance-impact-the-cost-of-numa-remote-memory-access.aspx">post</a> by SQL specialist Linchi Shea, assessing the impact of NUMA on SQL Server performance. <br>  The measurements were carried out on the HP ProLiant 360 G7 with two Intel Xeon X5690s, giving a total of 12 processors (24 logical CPUs) and were a comparison of two scenarios of Microsoft SQL Server 2008 R2 Enterprise X64: <br><ol><li>  Use only local memory (all requests are processed on the first NUMA node, in memory of which lies the test table) </li><li>  Using remote memory only (all requests are processed on the second NUMA node, using the same table in the first node's memory. </li></ol><br>  The test is performed exclusively technically competently, so there is no reason to doubt its authenticity.  For details, refer to the <a href="http://sqlblog.com/blogs/linchi_shea/archive/2012/01/30/performance-impact-the-cost-of-numa-remote-memory-access.aspx">original post</a> Linchi (in English). <br>  Here I will give the results - an estimate of the amount of request processing in time for both scenarios: <br><img src="http://habrastorage.org/storage2/a19/49f/3b0/a1949f3b07302e9a3476b76a38678a15.png"><br><br>  As you can see, the difference is just over 5%!  The result is pleasantly amazing.  And this is the case of the maximum difference achieved with 32 simultaneously running threads with queries (with a different number of threads the difference is even smaller). <br><br>  So is it necessary to optimize for NUMA?  I will come from afar.  Although I do not have time to clean the house, but I have time to read the cleaning tips :).  And one of the useful tips I have seen is that in order to get out less, you need to avoid potential confusion, for which purpose try to keep all things as close as possible to their place of use. <br><br>  Now replace ‚Äúthings‚Äù with ‚Äúdata‚Äù, and ‚Äúapartment‚Äù with ‚Äúprogram‚Äù and see one of the ways to achieve order in your programs.  But this is exactly the NUMA optimization that you have just read about. </div><p>Source: <a href="https://habr.com/ru/post/165903/">https://habr.com/ru/post/165903/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../165893/index.html">The brightest events of the gaming industry 2012-2013 | Video digest Geek Week, special issue</a></li>
<li><a href="../165895/index.html">Extra join in SQL queries</a></li>
<li><a href="../165897/index.html">Substitution DSDT via GRUB2</a></li>
<li><a href="../165899/index.html">Metadata for organizing photo archive storage</a></li>
<li><a href="../165901/index.html">Kiev - a free seminar "Proliant Gen8: new opportunities and technologies"</a></li>
<li><a href="../165907/index.html">Top-up developers in the Smart TV Alliance</a></li>
<li><a href="../165909/index.html">Introduction to the development of WinRT applications in HTML / JavaScript. Improving data handling</a></li>
<li><a href="../165915/index.html">Death penalty for copying</a></li>
<li><a href="../165919/index.html">Three ways to support the insertion of images in the input field from the developers of Yandex. Mail</a></li>
<li><a href="../165921/index.html">Content orientation as trend 2013</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>