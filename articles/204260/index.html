<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>SSAO on OpenGL ES 3.0</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="One day, looking at another demo with effect, the question arose: is it possible to make SSAO on a mobile device so that it looks good and does not sl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>SSAO on OpenGL ES 3.0</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/326/955/9ae/3269559aee89dbc6575ee594bca6b330.png"><br>  One day, looking at another demo with effect, the question arose: is it possible to make <a href="http://ru.wikipedia.org/wiki/Screen_Space_Ambient_Occlusion">SSAO</a> on a mobile device so that it looks good and does not slow down? <br>  The device was taken Galaxy Note 3 n9000 (mali T62), the goal - FPS is not lower than 30, and the quality should be as in the picture above. <br><a name="habracut"></a><br>  I will not go into details about this effect, it is assumed that the reader can learn about the effect from other sources ( <a href="http://ru.wikipedia.org/wiki/Screen_Space_Ambient_Occlusion">wiki</a> or <a href="http://steps3d.narod.ru/tutorials/ssao-tutorial.html">steps3d</a> ).  The article focuses on adaptation for a mobile platform, however, a brief overview will be made in the section "SSAO species". <br><br>  SSAO has a rather gluttonous effect in terms of performance and, at the same time, quite invisible to the average user, so I still haven‚Äôt seen it on a mobile device.  Especially to speed it up, you need support for <a href="http://www.gamedev.ru/terms/MRT">MRT</a> , which appeared only in OpenGL ES version 3.0. <br><br><h3>  SSAO Varieties </h3><br>  The basic idea of ‚Äã‚Äãthe algorithm is to determine the shading of a surface point in space.  In order to determine the degree of shading of this point in a certain radius from it, the presence of objects is checked, the more in the vicinity of the objects, the more shadowed the point is. <br><img src="https://habrastorage.org/getpro/habr/post_images/ee7/7b1/b67/ee77b1b67096787f0d2cd8f05f8b5b3a.png"><br>  Of course, it is impossible to calculate the shading for each point on surfaces in three-dimensional space, so the entire work of the algorithm is carried out in image space (hence the name <b>screen space</b> ambient occlusion).  In other words, the pixel on the screen acts as a point on the surface (in fact, not necessarily on the screen, the SSAO buffer size is often smaller than the screen size, so it would be more correct to say a pixel in a frame or frame).  It is also impossible to process the values ‚Äã‚Äãof all points of space in the neighborhood, therefore they are usually limited to a small <i>sample of</i> random points within a certain radius from the point in question. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the simplest implementation, a depth buffer is sufficient to calculate the shading ‚Äî so the z-coordinate of the pixel in question is compared with the z-coordinates of the pixels from the sample, and based on this difference, shading is considered. <br><br>  However, look at the picture above - it shows that the (‚Äúuseless‚Äù) contribution to the shading is also made by the surface itself under the point.  As a result, the picture is obtained in gray tones, that is, where there should not be shading - it is there.  It looks like this: <br><img src="https://habrastorage.org/getpro/habr/post_images/86c/743/166/86c7431662ef360ce0b4785d3781c671.png"><br><br>  In order to avoid this, in addition to information about the depth, we need more information about the normal at this point.  To do this, during the rendering of the scene in addition to the color, it is also recorded in a separate normal buffer.  Given these, you can change the position of the point from the sample so that it makes a ‚Äúuseful‚Äù contribution.  This is done on the basis of the angle between the normal at the point in question and the point normal from the sample, if it (angle) is more than 90 ¬∞ - the normal is inverted from the sample and its point is recalculated on its basis.  This modification of the algorithm gives shading only where it is needed, but it has a serious drawback - for each point from the sample, in addition to reading from the depth buffer, an additional reading from the normal texture appears.  And the bottleneck in SSAO is a large number of reads from different buffers, and these readings are performed in random order, which is a kill for the cache.  Especially on a mobile device. <br><br>  Another modification implies using as a neighborhood not a sphere, but a hemisphere within which points from the sample are located.  In this case, it is necessary to orient this sphere along the normal of the point in question. <br><img src="https://habrastorage.org/getpro/habr/post_images/932/3a9/a30/9323a9a306631b59aaaf33d486878fe1.png"><br>  In this case, it is not necessary to read the normals for each point from the sample, since all of them are already located as it should, it is enough to get the normal to the point in question. <br><br>  In my opinion this is the best modification, and it is applicable. <br><br><h3>  Implementation </h3><br>  First we need buffers for storing normals, depth and color.  Here we use technology from OpenGL ES 3.0 - Multiple Render Targets, we create several buffers, and then write to them at the same time.  In the code, it looks like this (I rendered the creation of a texture into a separate function): <br><pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// ,        (  ),     GLenum buffers[] = {GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1}; GLuint fbo; GLuint colorBuff; GLuint normBuff; GLuint depthBuff; //     void createTexture(GLuint &amp;id, int inFormat, int w, int h, int format, int type, int filter, int wrap, void* pix=NULL) { glGenTextures(1, &amp;id); glBindTexture(GL_TEXTURE_2D, id); glTexImage2D(GL_TEXTURE_2D, 0, inFormat, w, h, 0, format, type, pix); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, filter); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, filter); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, wrap); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, wrap); } ... glGenFramebuffers(1, &amp;fbo); //   glBindFramebuffer(GL_FRAMEBUFFER, fbo); // width  height -   createTexture(colorBuff, GL_RGB8, width, height, GL_RGB, GL_UNSIGNED_BYTE, GL_NEAREST, GL_MIRRORED_REPEAT); createTexture(normBuff, GL_RGB8, width, height, GL_RGB, GL_UNSIGNED_BYTE, GL_NEAREST, GL_MIRRORED_REPEAT); createTexture(depthBuff, GL_DEPTH_COMPONENT24, width, height, GL_DEPTH_COMPONENT, GL_UNSIGNED_INT, GL_NEAREST, GL_MIRRORED_REPEAT); //    ,        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, colorBuff, 0); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, normBuff, 0); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, depthBuff, 0); int err = glCheckFramebufferStatus(GL_FRAMEBUFFER); if (err != GL_FRAMEBUFFER_COMPLETE) LOGE("Main framebuffer error: %i", err); glDrawBuffers(2, buffers);</span></span></code> </pre> <br>  Further in a similar way, but already with one texture, you need to create a buffer for SSAO. <br><div class="spoiler">  <b class="spoiler_title">SSAO buffer</b> <div class="spoiler_text"><pre> <code class="cpp hljs">glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoFbo1); glBindFramebuffer(GL_FRAMEBUFFER, ssaoFbo1); <span class="hljs-comment"><span class="hljs-comment">//     ,     ,    GL_R8 createTexture(ssaoBuff1, GL_R8, width/ssaoScaleW, height/ssaoScaleH, GL_RED, GL_UNSIGNED_BYTE, GL_LINEAR, GL_MIRRORED_REPEAT); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoBuff1, 0); // glDrawBuffers   ,       </span></span></code> </pre><br></div></div><br>  This buffer may be smaller, but for now let's make it the same as the screen resolution (in my case, 1920x1080). <br><br>  Separately it is necessary to say about the z-buffer.  To be used in SSAO, it must first be made linear, otherwise the mean and background will lose much accuracy.  Usually, for this, the depth values ‚Äã‚Äãare written in a separate buffer, often with normals.  However, the additional buffer does not bode well for performance, so we will not linearize the values ‚Äã‚Äãand write them to a separate buffer, but directly to the current, standard depth buffer (gl_FragDepth).  This can cause artifacts in the foreground (very close, almost near the front cut-off plane), but in general this buffer behaves quite normally. <br><br>  The scene is rendered as usual, with the only difference being that, in addition to color, we also write normals and slightly change the depth buffer.  Vertex shader for scene rendering: <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es uniform mat4 matrixProj; uniform mat4 matrixView; uniform vec3 lightPos; layout(location = 0) in vec3 vPos; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//   layout(location = 1) in vec3 nPos; //  layout(location = 2) in vec3 tPos; //     layout(location = 3) in vec2 tCoord; //   out vec3 light; out vec3 gNorm; out float zPos; out vec2 texCoord; void main() { vec4 p = matrixProj*matrixView*vec4(vPos, 1.0); gl_Position = p; texCoord = tCoord; //      ,           vec3 bitangent = cross(tPos, nPos); mat3 tbn = mat3(tPos, bitangent, nPos); light = normalize(lightPos-vPos)*tbn; zPos = pz; //  z-  -      vec4 n = (matrixView*vec4(nPos, 0.0)); //      gNorm = normalize(n.xyz); }</span></span></span></span></code> </pre><br>  Fragment Shader: <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es precision highp float; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//      24- ,     ,     24 ,       uniform sampler2D texDiff; //   uniform sampler2D texNorm; //       layout(location = 0) out vec3 colorBuff; //    layout(location = 1) out vec3 normBuff; //   in vec3 light; in vec3 gNorm; in float zPos; in vec2 texCoord; const vec3 ambientColor = vec3(0.3); const float zFar = 40.0; //    void main() { vec3 n = normalize(texture(texNorm, texCoord).xyz*2.0-1.0); vec3 l = normalize(light); vec3 c = texture(texDiff, texCoord).rgb; float a = clamp(dot(n, l), 0.0, 1.0); colorBuff = c*(a+ambientColor); //   normBuff = normalize(gNorm)*0.5+0.5; //   gl_FragDepth = zPos/zFar; //       }</span></span></span></span></code> </pre><br><br>  We also need an array of random points in the hemisphere (the sample itself).  In order for the shading to turn out beautiful (if you can say so, more physical) - the density of the points in the hemisphere must be higher towards the center and lower towards the border.  That is, to have a normal distribution law. <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;samples; i++) { rndTable[i] = vec3(random(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), random(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), random(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-0</span></span>)); <span class="hljs-comment"><span class="hljs-comment">//    ( ) rndTable[i].normalize(); //   rndTable[i] *= (i+1.0f)/samples; //  ( ) }</span></span></code> </pre><br><img src="//habrastorage.org/files/d90/1ef/34f/d901ef34fc96461baa24ffdf652f2a65.png" align="left"><br><img src="//habrastorage.org/files/006/d9b/e6a/006d9be6ae0d449d917a075f82a165da.png" align="right"><br><br clear="left"><br clear="right"><br>  Of course, the number of points in the sample will not be so large.  Let's make so far equal to 10. <br><br>  However, such a sample with pseudo-random values ‚Äã‚Äãis small - these values ‚Äã‚Äãare random only within one fragment, the next fragment will take the same points, albeit with a slight offset.  To eliminate this drawback, a small texture (approximately 4x4 pixels) with pseudo-random values ‚Äã‚Äãis usually used.  Now, in each fragment, we can take values ‚Äã‚Äãfrom this texture and form a rotation matrix for them from our hemisphere points.  And at the same time turn them relative to the normal, which we will read already from the texture of the normals.  Thus, multiplying the points by the resulting matrix, we will simultaneously orient them relative to the normal and rotate by a pseudo-random vector.  The construction of such a matrix is ‚Äã‚Äãcalled <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581_%25D0%2593%25D1%2580%25D0%25B0%25D0%25BC%25D0%25B0_%25E2%2580%2595_%25D0%25A8%25D0%25BC%25D0%25B8%25D0%25B4%25D1%2582%25D0%25B0">the Gram-Schmidt process</a> . <br><br>  In the shader, it will look like this: <br><pre> <code class="cpp hljs">vec3 normal = texture(normBuff, texCoord).xyz*<span class="hljs-number"><span class="hljs-number">2.0</span></span><span class="hljs-number"><span class="hljs-number">-1.0</span></span>; vec3 rvec = texture(randMap, texCoord*scr).xyz*<span class="hljs-number"><span class="hljs-number">2.0</span></span><span class="hljs-number"><span class="hljs-number">-1.0</span></span>; vec3 tangent = normalize(rvec-normal*dot(rvec, normal)); vec3 bitangent = cross(tangent, normal); mat3 rotate = mat3(tangent, bitangent, normal);</code> </pre><br><br>  We also need to restore the coordinates of a point in space.  To do this, you can multiply the coordinates of a point in the image space by the inverse matrix of the perspective transformation, or you can do more simply: multiply the vector (ray) directed from the camera through the current pixel by the value of the z-coordinates of this pixel.  Z-coordinates are stored in the depth buffer, and the beam from the camera is based on the viewing angle, which is used when building the perspective matrix (projection matrix) - this is fov.  I decided to save on uniform-ah, and just scored this value in the vertex shader as a constant. <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es const fov = 0.57735; layout(location = 0) in vec2 vPos; layout(location = 1) in vec2 tCoord; uniform float aspect; out vec2 texCoord; out vec3 viewRay; void main() { gl_Position = vec4(vPos, 0.0, 1.0); texCoord = tCoord; viewRay = vec3(-vPos.x*aspect*fov, -vPos.y*fov, 1.0); </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//   ,      }</span></span></span></span></code> </pre><br>  In the pixel shader, the position of the point on the basis of the beam is restored as follows: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> depth = texture(depthBuff, texCoord).x; <span class="hljs-comment"><span class="hljs-comment">//    ,   depth *= zFar; //  z- vec3 pos = viewRay*depth; //     </span></span></code> </pre><br>  After obtaining the rotation matrix and the position of the point, you can begin to obtain the shading value from the samples: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> acc = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;samples; i++) { vec3 samplePos = rotate*rndTable[i]; <span class="hljs-comment"><span class="hljs-comment">//  samplePos = samplePos*radius+pos; //        //          ,            vec4 shift = proj*vec4(samplePos, 1.0); shift.xy /= shift.w; shift.xy = shift.xy*0.5+0.5; //   z- float sampleDepth = texture(depthBuff, shift.xy).x*zFar; //       -      .     ,       ,   smoothstep,   -   float distanceCheck = smoothstep(0.0, 1.0, radius/abs(pos.z-sampleDepth)); //       -     .  - ,    step acc += step(sampleDepth, samplePos.z)*distanceCheck; }</span></span></code> </pre><br>  The result can be blurred, so we will create another buffer for blurring in Gauss.  We make the number of samples small, in the end it‚Äôs just a shadow, which also lays over the texture, so the artifacts should not be very noticeable.  Here the cache is already on our side, if in the case of a random reading in SSAO, cache misses occur constantly, then texture samples should be well cached. <br><div class="spoiler">  <b class="spoiler_title">shader for vertical blur</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es precision mediump float; uniform sampler2D ssaoBuff; layout(location = 0) out float outColor; in vec2 texCoord; const float blurSize = 2.5/1920.0; void main() { float sum = 0.0; sum += texture(ssaoBuff, vec2(texCoord.x, texCoord.y - 2.0*blurSize)).r * 0.0625; sum += texture(ssaoBuff, vec2(texCoord.x, texCoord.y - blurSize)).r * 0.25; sum += texture(ssaoBuff, vec2(texCoord.x, texCoord.y )).r * 0.375; sum += texture(ssaoBuff, vec2(texCoord.x, texCoord.y + blurSize)).r * 0.25; sum += texture(ssaoBuff, vec2(texCoord.x, texCoord.y + 2.0*blurSize)).r * 0.0625; outColor = sum; }</span></span></code> </pre><br></div></div><div class="spoiler">  <b class="spoiler_title">shader for horizontal blur</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es precision mediump float; uniform sampler2D ssaoBuff; layout(location = 0) out float outColor; in vec2 texCoord; const float blurSize = 2.5/1080.0; void main() { float sum = 0.0; sum += texture(ssaoBuff, vec2(texCoord.x - 2.0*blurSize, texCoord.y)).r * 0.0625; sum += texture(ssaoBuff, vec2(texCoord.x - blurSize, texCoord.y)).r * 0.25; sum += texture(ssaoBuff, vec2(texCoord.x, texCoord.y)).r * 0.375; sum += texture(ssaoBuff, vec2(texCoord.x + blurSize, texCoord.y)).r * 0.25; sum += texture(ssaoBuff, vec2(texCoord.x + 2.0*blurSize, texCoord.y)).r * 0.0625; outColor = sum; }</span></span></code> </pre><br></div></div><br>  You can see the result: <br><img src="//habrastorage.org/files/d79/250/7ec/d792507ec4c140d58d2eff7b92be286c.png"><br>  The number in the upper left shows the number of frames per second.  Not much.  Also pay attention to the stripes on the surface.  The fact is, in the representation of the depth buffer, the surface is not perfectly smooth.  There, everything is completely discrete and any surface looks like a ladder, so some of the points from the samples appear to be inside these ‚Äústeps‚Äù: <br><img src="//habrastorage.org/files/1ce/cbb/2da/1cecbb2da18c4c5c8d5d631d9aa3bf9f.png"><br>  Therefore, when sampling, it is better to start not from the zero z-coordinate, but from some small value, for example, from 0.1.  In this case, the hemisphere will be cut down from below: <br><img src="//habrastorage.org/files/1e2/ff8/7db/1e2ff87db1e14e7dab542e29148ba80f.png"><br>  and then the points from the sample will not fall into the "steps".  The picture will be better: <br><img src="//habrastorage.org/files/4d0/aaf/b3c/4d0aafb3cb4745d198f4163deae42411.png"><br>  But FPS is still not high. <br><br><h3>  Optimization </h3><br>  The obvious and most common solutions are to reduce the number of points in the sample and reduce the size of the SSAO buffer.  Reducing the buffer size in half we get an increase in FPS of about 150%.  However, changing the size of the buffer, we get artifacts on the borders of objects, so we will not greatly reduce it. <br><br>  Look at the result of the algorithm - it is clear that most of the image is white and does not have any shading at all.  But the algorithm works for each pixel.  It would be nice to create a kind of mask, which could cut off unnecessary fragments. <br>  This mask can be obtained by roughly calculating SSAO for a smaller buffer.  That is, we will create another buffer, say 16 times less in width and height than the buffer for SSAO.  Reduce the number of samples to five and make them not random, but located at the same distance from the center of the hemisphere: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;samplesLow; i++) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> angle = DEG2RAD*<span class="hljs-number"><span class="hljs-number">360.0f</span></span>*i/samplesLow; rndTableLow[i] = vec3(sinf(angle), cosf(angle), <span class="hljs-number"><span class="hljs-number">-0.1</span></span>); }</code> </pre><br>  Since we need a mask, without smooth shadow transitions, we will make the result very contrasting - a pixel is either black or white: <br><pre> <code class="cpp hljs">outColor = step(<span class="hljs-number"><span class="hljs-number">254.0</span></span>/<span class="hljs-number"><span class="hljs-number">255.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>-(acc/<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>(samples)));</code> </pre><br>  The blur shader is also simplified; now it will not be two fragment shaders, but one with four samples located at the corners of the square: <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es precision mediump float; uniform sampler2D ssaoLowBuff; uniform float aspect; layout(location = 0) out float outColor; in vec2 texCoord; const float blurSize = 0.01; void main() { float sum = 0.0; sum += texture(ssaoLowBuff, vec2(texCoord.x - blurSize, texCoord.y - blurSize*aspect)).r; sum += texture(ssaoLowBuff, vec2(texCoord.x - blurSize, texCoord.y + blurSize*aspect)).r; sum += texture(ssaoLowBuff, vec2(texCoord.x, texCoord.y )).r; sum += texture(ssaoLowBuff, vec2(texCoord.x + blurSize, texCoord.y - blurSize*aspect)).r; sum += texture(ssaoLowBuff, vec2(texCoord.x + blurSize, texCoord.y + blurSize*aspect)).r; outColor = step(254.0/255.0, sum/5.0); }</span></span></code> </pre><br>  We get just such a mask: <br><img src="//habrastorage.org/files/62f/fee/8b9/62ffee8b99e04a23a17f0fbf5a751da8.png"><br>  Using it we calculate SSAO (I reduced the buffer size 1.5 times, and reduced the number of samples to 8): <br><img src="//habrastorage.org/files/16b/ca2/3a0/16bca23a0f1e43ed99ac5002d01bc8f2.png"><br>  As a result, FPS increased three times, without visual loss of quality.  This method has a drawback - if there are many corners or other shading places in the scene, the mask can become almost completely black, which means the effectiveness of such optimization will decrease dramatically and even add an additional overhead to the calculation of the reduced SSAO. <br>  The full code of the fragment SSAO shader: <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 300 es precision highp float; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//  24-   const int samples = 8; //   const float radius = 0.5; //   const float power = 2.0; //   const float zFar = 40.0; //    uniform sampler2D normBuff; //   uniform sampler2D depthBuff; //   uniform sampler2D randMap; //      uniform sampler2D ssaoMask; //  SSAO -  uniform vec2 scr; //    randMap,     SSAO uniform vec3 rndTable[samples]; //  uniform mat4 proj; //   layout(location = 0) out float outColor; //   in vec2 texCoord; //   in vec3 viewRay; //    void main() { //      ,    -   float k = texture(ssaoMask, texCoord).x; if (k==1.0) discard; //          -  float depth = texture(depthBuff, texCoord).x; if (depth==1.0) discard; depth *= zFar; vec3 pos = viewRay*depth; vec3 normal = texture(normBuff, texCoord).xyz*2.0-1.0; vec3 rvec = texture(randMap, texCoord*scr).xyz*2.0-1.0; vec3 tangent = normalize(rvec-normal*dot(rvec, normal)); vec3 bitangent = cross(tangent, normal); mat3 rotate = mat3(tangent, bitangent, normal); float acc = 0.0; for (int i=0; i&lt;samples; i++) { vec3 samplePos = rotate*rndTable[i]; //  samplePos = samplePos*radius+pos; //        //          ,            vec4 shift = proj*vec4(samplePos, 1.0); shift.xy /= shift.w; shift.xy = shift.xy*0.5+0.5; //   z- float sampleDepth = texture(depthBuff, shift.xy).x*zFar; //       -      .     ,       ,   smoothstep,   -   float distanceCheck = smoothstep(0.0, 1.0, radius/abs(pos.z-sampleDepth)); //       -     .  - ,    step acc += step(sampleDepth, samplePos.z)*distanceCheck; } outColor = pow(1.0-(acc/float(samples)), power); //   }</span></span></span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Comparative screenshots with textured objects</b> <div class="spoiler_text"><img src="//habrastorage.org/files/f77/3f5/ef1/f773f5ef1c3e4f218d109b795c94a01f.png"><br><br><img src="//habrastorage.org/files/366/9f7/502/3669f75023274107a809bf8e50c600f6.png"><br></div></div><br>  Video demonstration (SSAO size is 2 times smaller than the screen): <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/zccQsbKagZc%3Ffeature%3Doembed&amp;xid=17259,15700019,15700186,15700190,15700253,15700256&amp;usg=ALkJrhgXUcw0ycROZkkVshnoDpUCc2B-Eg" frameborder="0" allowfullscreen=""></iframe><br>  (SSAO is 1.5 times smaller than the screen): <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/2Co7fzFoDss%3Ffeature%3Doembed&amp;xid=17259,15700019,15700186,15700190,15700253,15700256&amp;usg=ALkJrhgbUYmb0ab2-Z9rPQyTAqA5poNWTA" frameborder="0" allowfullscreen=""></iframe><br><br><h3>  Subtleties </h3><br>  In the process, I ran into some interesting things, but since this is a bit offtopic, I hid it under spoilers. <br><div class="spoiler">  <b class="spoiler_title">Byte order</b> <div class="spoiler_text">  When I wrote a converter for textures and models, I ran into the fact that on ARM processors the <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D0%25BE%25D1%2580%25D1%258F%25D0%25B4%25D0%25BE%25D0%25BA_%25D0%25B1%25D0%25B0%25D0%25B9%25D1%2582%25D0%25BE%25D0%25B2">byte order is</a> different from x86.  Accordingly, when writing to a binary file, in all types of data having a length of more than one byte, it is desirable to invert the order of bytes in order not to do this on the device. <br>  For this, I used the functions: <br><ul><li>  uint32_t htonl (uint32_t hostlong); </li><li>  uint16_t htons (uint16_t hostshort); </li></ul><br>  For example, output to the file of some values ‚Äã‚Äãwith a changed byte order (using Qt): <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;netinet/in.h&gt; ... QDataStream out(&amp;file); out &lt;&lt; htons(s); //     unsigned short out &lt;&lt; htonl(*((unsigned int*)&amp;f)); //     float</span></span></span></span></code> </pre></div></div><div class="spoiler">  <b class="spoiler_title">Fractional separator</b> <div class="spoiler_text">  Depending on the regional settings and the operating system, the sscanf function can interpret floating point numbers in different ways.  Somewhere for the separation of the fractional and integer parts can be used a point, somewhere - a comma. <br>  For example: <br><pre> <code class="cpp hljs">readed1 = <span class="hljs-built_in"><span class="hljs-built_in">sscanf</span></span>(<span class="hljs-string"><span class="hljs-string">"float: 1,5"</span></span>, <span class="hljs-string"><span class="hljs-string">"float: %f"</span></span>, &amp;f); readed2 = <span class="hljs-built_in"><span class="hljs-built_in">sscanf</span></span>(<span class="hljs-string"><span class="hljs-string">"float: 1.5"</span></span>, <span class="hljs-string"><span class="hljs-string">"float: %f"</span></span>, &amp;f);</code> </pre><br>  The values ‚Äã‚Äãof readed1 and readed2 may vary on different systems.  Usually these settings are set in the regional settings of the operating system.  This should be taken into account, for example, when writing a parser for * .obj files. <br></div></div><div class="spoiler">  <b class="spoiler_title">Brakes due to log overflow</b> <div class="spoiler_text">  If you use logcat, do not forget to clear the log on the android.  At least on Note 3 n9000 when outputting a large amount of information to the log (I wrote there every second the current frame rate), everything starts to slow down terribly.  For a long time, I could not understand what was going on until I cleared the log (adb logcat -c command). <br></div></div><div class="spoiler">  <b class="spoiler_title">Different GPUs</b> <div class="spoiler_text">  Having written a shader, it would be nice to check it on several devices with different gpu.  The above SSAO shader code works fine on mali, but is buggy on adreno (in particular, 320 and 330).  It turned out to be on adreno (at least in the es 300 shaders version) the cycles do not work correctly, I can‚Äôt say more precisely, but it looks like the same iteration is working through the loop, although the counter is increasing.  I had to slightly change the shader code, get rid of the loop: <br><pre> <code class="cpp hljs">... <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getSample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> i, in mat3 rotate, in vec3 pos, in vec3 rnd)</span></span></span><span class="hljs-function"> </span></span>{ vec3 samplePos = rotate*rnd; samplePos = samplePos*radius+pos; vec4 shift = proj*vec4(samplePos, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); shift.xy /= shift.w; shift.xy = shift.xy*<span class="hljs-number"><span class="hljs-number">0.5</span></span>+<span class="hljs-number"><span class="hljs-number">0.5</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> sampleDepth = texture(depthBuff, shift.xy).x*zFar; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> distanceCheck = smoothstep(<span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, radius/<span class="hljs-built_in"><span class="hljs-built_in">abs</span></span>(pos.z-sampleDepth)); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> step(sampleDepth, samplePos.z)*distanceCheck; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ ... <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> acc = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; acc += getSample(<span class="hljs-number"><span class="hljs-number">0</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">0</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">1</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">1</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">2</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">2</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">3</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">3</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">4</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">4</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">5</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">5</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">6</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">6</span></span>]); acc += getSample(<span class="hljs-number"><span class="hljs-number">7</span></span>, rotate, pos, rndTable[<span class="hljs-number"><span class="hljs-number">7</span></span>]); outColor = <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span>-(acc/<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>(samples)), power); }</code> </pre><br>  It looks awful, but if someone knows the reason for this strange behavior, please write in the comments or in HP. <br></div></div><div class="spoiler">  <b class="spoiler_title">QtCreator as IDE for NDK project</b> <div class="spoiler_text">  I personally like QtCreator more than Eclipse or Android Studio, especially since I mainly write on NDK.  Therefore, I usually create a project in Eclipse and transfer it to QtCreator.  If anyone is interested, here is the project transfer process: <br>  Open Qt Creator and go to File -&gt; New File or Project ... -&gt; Import Project -&gt; Import Existing Project <br><div class="spoiler">  <b class="spoiler_title">screenshot</b> <div class="spoiler_text"><img src="http://habrastorage.org/getpro/habr/post_images/7c8/c3d/200/7c8c3d200365d6918c1c1a285b3d15ea.png"><br></div></div><br>  Next, enter the project name and specify the path to the already created project.  How to create a project for Android can be found in the official documentation: <a href="http://developer.android.com/tools/projects/projects-eclipse.html">creating a project in Eclipse</a> , <a href="http://developer.android.com/tools/projects/projects-cmdline.html">from the command line</a> and <a href="https://developer.android.com/tools/sdk/ndk/index.html">adding support for the NDK</a> . <br><div class="spoiler">  <b class="spoiler_title">screenshot</b> <div class="spoiler_text"><img src="http://habrastorage.org/getpro/habr/post_images/a91/cd6/389/a91cd63893bc0bf88d0ffff587f8913a.png"><br></div></div><br>  After that, we choose which files will be displayed in the project tree and, in fact, create the project.  Qt Creator will automatically create the following files: <br>  <b>MyProject.config</b> - here you can enter the diffines for compilation, for example, I added the line #define __ARM_NEON__ to support NEON <br>  <b>MyProject.files</b> - all files related to the project tree <br>  <b>MyProject.includes</b> - here you need to register the paths to the libraries included in the project, for example: <br><pre> <code class="hljs ruby">/home/torvald/android-ndk-r9/sources/android/cpufeatures /home/torvald/android-ndk-r9/sources/cxx-stl/stlport/stlport /home/torvald/android-ndk-r9/sources/cxx-stl/gabi++<span class="hljs-regexp"><span class="hljs-regexp">/include /home</span></span><span class="hljs-regexp"><span class="hljs-regexp">/torvald/android</span></span>-ndk-r9/toolchains/arm-linux-androideabi-<span class="hljs-number"><span class="hljs-number">4.6</span></span>/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/<span class="hljs-number"><span class="hljs-number">4.6</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">include</span></span> /home/torvald/android-ndk-r9/toolchains/arm-linux-androideabi-<span class="hljs-number"><span class="hljs-number">4.6</span></span>/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/<span class="hljs-number"><span class="hljs-number">4.6</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">include</span></span>-fixed /home/torvald/android-ndk-r9/platforms/android-<span class="hljs-number"><span class="hljs-number">18</span></span>/arch-arm/usr/<span class="hljs-keyword"><span class="hljs-keyword">include</span></span> /home/torvald/android-ndk-r9/toolchains/arm-linux-androideabi-<span class="hljs-number"><span class="hljs-number">4.6</span></span>/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/<span class="hljs-number"><span class="hljs-number">4.6</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">include</span></span>/ <span class="hljs-regexp"><span class="hljs-regexp">/home/torvald</span></span><span class="hljs-regexp"><span class="hljs-regexp">/android-ndk-r9/toolchains</span></span><span class="hljs-regexp"><span class="hljs-regexp">/arm-linux-androideabi-4.6/prebuilt</span></span><span class="hljs-regexp"><span class="hljs-regexp">/linux-x86_64/lib</span></span><span class="hljs-regexp"><span class="hljs-regexp">/gcc/arm</span></span>-linux-androideabi/<span class="hljs-number"><span class="hljs-number">4.6</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">include</span></span>/-fixed</code> </pre> <br>  You can also write a small script to manage the compilation and deployment of the project: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh case "$1" in clean) ndk-build clean &amp;&amp; ant clean ;; deploy) adb install -r bin/MainActivity-debug.apk &gt; /dev/null 2&gt;&amp;1 &amp; # &amp;&amp; adb logcat -c &amp;&amp; adb logcat -s "SSAOTest" #      Qt Creator -    ;; run) #adb shell am start -n com.torvald.ssaotest/com.torvald.ssaotest.MainActivity &gt; /dev/null 2&gt;&amp;1 &amp; ;; *) #kill $(ps aux | grep "adb logcat" | grep -v "grep" | awk '{print $2}') &gt; /dev/null 2&gt;&amp;1 &amp; ndk-build NDK_DEBUG=0 -j9 &amp;&amp; ant debug ;; esac</span></span></code> </pre><br>  In the Projects tab, this script is assigned to the appropriate actions: <br><div class="spoiler">  <b class="spoiler_title">screenshots</b> <div class="spoiler_text"><img src="http://habrastorage.org/getpro/habr/post_images/0ff/b8d/ad3/0ffb8dad331c91d53ddaf306aa2041c2.png"><br><br><img src="http://habrastorage.org/getpro/habr/post_images/ec4/f68/c3f/ec4f68c3fdc7bf7884c6c675a0c8b8c1.png"><br></div></div><br>  That's all, now you can clear the project with standard Qt Creator tools, chop it and pour it onto the device.  Works syntax highlighting, autocompletion and other buns for GLSL and C ++. <br></div></div><br><br><h3>  Demo </h3><br>  If there is a device on android with OpenGL ES 3.0, you can try running the application.  I decided not to waste time on the GUI, so there are no special settings, and the control is performed by conditional areas on the screen: <br><img src="http://habrastorage.org/getpro/habr/post_images/26a/f35/aae/26af35aae24976e6f042b28b835ad11d.png" align="left"><br><ol><li>  slide up / down - zoom in / out </li><li>  change output buffer (ssao, low ssao, ssao + color, color only) </li><li>  on / off blur </li><li>  scene change </li></ol><br>  free screen area - camera rotation <br><br clear="left"><br>  The parameters I set are as follows: <br><ul><li>  number of samples = 8. </li><li>  The size of the ssao and blur buffers is one and a half times smaller than the screen resolution. </li><li>  The number of samples for the reduced ssao = 5. </li><li>  The size of the reduced ssao buffer is 16 times smaller than the screen resolution. </li></ul><br>  <a href="">Source code</a> - do not forget to change the path to your <br>  <a href="">apk</a> - tested on Note 3 n9000 (mali T62), Note 3 n9005 (adreno 330), Nexus 5 (adreno 330), HTC One (adreno 320). <br><br><h3>  Links </h3><br>  Various references that were useful in this project: <br>  <a href="http://steps3d.narod.ru/tutorials/ssao-tutorial.html">Screen Space Ambient Occlusion</a> at steps3d.  Several ways to create SSAO <br> <a href="https://www.khronos.org/files/opengles3-quick-reference-card.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenGL ES 3.0 API Reference Card</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äî QuickGL ES 3.0 Quick Reference </font></font><br> <a href="http://blog.evoserv.at/index.php/2012/12/hemispherical-screen-space-ambient-occlusion-ssao-for-deferred-renderers-using-openglglsl/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hemispherical Screen Space Ambient Occlusion</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is one of the ways to implement the Hemispherical SSAO </font></font><br> <a href="http://tf3dm.com/3d-model/stone-bridge-37857.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stone Bridge 3d model</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äî the bridge model I used in the </font></font><br> <a href="http://john-chapman-graphics.blogspot.ru/2013/01/ssao-tutorial.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">john-chapman-graphics</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> demo </font><a href="http://john-chapman-graphics.blogspot.ru/2013/01/ssao-tutorial.html"><font style="vertical-align: inherit;">: SSAO Tutorial</font></a><font style="vertical-align: inherit;"> ‚Äî on my look best implementation of Hemispherical SSAO </font></font><br> <a href="http://www.gamerendering.com/2009/01/14/ssao/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SSAO | </font><font style="vertical-align: inherit;">Game Rendering </font></font></a> <br> <a href="http://mynameismjp.wordpress.com/2010/03/22/attack-of-the-depth-buffer/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Attack of the depth buffer</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - various z-buffer views </font></font><br> <a href="http://habrahabr.ru/post/131931/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Linear algebra for game developers </font></font></a> <br> <a href="http://mtnphil.wordpress.com/2013/06/26/know-your-ssao-artifacts/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Know your SSAO artifacts</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><a href="http://mtnphil.wordpress.com/2013/06/26/know-your-ssao-artifacts/"><font style="vertical-align: inherit;">SSAO artifacts</font></a><font style="vertical-align: inherit;"> / jambs / inaccuracies and how to eliminate them</font></font></div><p>Source: <a href="https://habr.com/ru/post/204260/">https://habr.com/ru/post/204260/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../204248/index.html">Highlighting code on android. My experience</a></li>
<li><a href="../204250/index.html">Service robot Tod. First steps with ROS</a></li>
<li><a href="../204252/index.html">10 months of free clouds on DigitalOcean</a></li>
<li><a href="../204254/index.html">Gnuplot vs. 2MASS</a></li>
<li><a href="../204258/index.html">Generating functions back and forth</a></li>
<li><a href="../204262/index.html">Real development experience at Meteor</a></li>
<li><a href="../204264/index.html">STM32 + Visual Studio</a></li>
<li><a href="../204266/index.html">Methods of anonymity online. Part 4. Tor & VPN. Whonix</a></li>
<li><a href="../204274/index.html">Wireshark - taming a shark</a></li>
<li><a href="../204276/index.html">How to use pirates to your advantage</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>