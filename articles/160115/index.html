<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Progress in the development of neural networks for machine learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The Friday edition of the NY Times published an article about the significant successes that the developers of algorithms for self-learning neural net...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Progress in the development of neural networks for machine learning</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/ffe/db6/678/ffedb66784193a7f541a5f9b9311ac90.png" align="right">  The Friday edition of the NY Times published <a href="http://nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">an article</a> about the significant successes that the developers of algorithms for self-learning neural networks have been demonstrating in recent years.  In deep structures there are several hidden layers that have traditionally been difficult to train.  But that all changed with the use of a stack of Boltzmann machines (RBM) for pre-training.  After that, you can conveniently reconfigure the weights using the backpropagation method.  Plus, the emergence of fast GPUs - all this has led to significant progress, which we have seen in recent years. <br><br>  The developers themselves do not make loud statements in order not to raise the hype around neural networks - such as in the 1960s rose around cybernetics.  Nevertheless, it is possible to speak about a revival of interest in research in this area. <br><a name="habracut"></a><br>  Researches on neural networks were actively conducted in the 1960s, then this sphere for a while went into the shadows.  But in 2011-2012 a number of excellent results in the field of speech recognition, computer vision and artificial intelligence are shown.  Here are some recent successes: <br><br>  ‚Ä¢ In 2011, the program for recognition of road signs was won by a program created by <a href="http://www.idsia.ch/">Swiss AI Lab</a> specialists from the University of Lugano.  Based on 50 thousand images of German road signs, it showed a result of 99.46%, ahead of not only other programs, but even the best of 32 people participating in the competition (99.22%).  The average for people was 98.84%.  The Swiss AI Lab's neural network has also won other contests, including the most accurate recognition of handwritten Chinese characters. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      ‚Ä¢ In the summer of 2012, Google specialists raised a cluster of 16 thousand computers for a self-learning neural network that trained on the basis of 14 million images, corresponding to 20 thousand objects.  Although the recognition accuracy is not very high (15.8%), but it is much higher than that of previous systems of similar purpose. <br><br>  ‚Ä¢ In October 2012, a program that uses neural networks won the <a href="http://www.kaggle.com/c/MerckActivity">Merck Molecular Activity Challenge</a> software <a href="http://www.kaggle.com/c/MerckActivity">competition</a> for statistical analysis of activity for the development of new drugs.  It was developed by a team of the University of Toronto under the guidance of Professor Geoffrey E. Hinton, a well-known expert on neural networks. <br><br>  ‚Ä¢ In November 2012, the director of Microsoft‚Äôs research division spoke at Microsoft Research Asia‚Äôs 21st Century Computing conference in China with <a href="http://blogs.technet.com/b/next/archive/2012/11/08/microsoft-research-shows-a-promising-new-breakthrough-in-speech-translation-technology.aspx">an impressive demonstration</a> of speech recognition, simultaneous translation into Chinese, and real-time speech synthesis in another language, in his own voice). <br><br>  It is believed that it was the aforementioned Jeffrey Hinton who introduced the backpropagation <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F_%25D0%25BE%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8">method</a> invented in 1969, but little known before his work, into the field of neural network training. <br><br>  A breakthrough in the training of neural networks occurred after the publication in 2006 of a scientific article by Hinton and his colleague Ruslan Salakhutdinov (Ruslan Salakhutdinov) ‚Äú <a href="http://www.cs.toronto.edu/~hinton/science.pdf">Reducing the Dimensionality of Data with Neural Networks</a> ‚Äù.  There he described the technique of pre-training the neural network and the subsequent fine-tuning using the Boltzmann machine stack (RBM) and the back propagation error method (backpropagation).  Schematically, this technique is shown in the illustration. <br><br><img src="https://habrastorage.org/storage2/92b/9f2/fd3/92b9f2fd31a29181ff387bbc10e75b82.png"><br><br>  Mark Watson on his blog published a <a href="http://blog.markwatson.com/2012/11/deep-learning.html">couple of links</a> to useful resources to start learning in this area. <br><br><ol><li>  Hinton's online <a href="https://www.coursera.org/course/neuralnets">Neural Networks for Machine Learning</a> course on Coursera. </li><li>  <a href="http://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial">Deep Learning Tutorial</a> , a very large presentation (pdf, 184 slides), which provides all the necessary theoretical base, mathematics and Python code examples. </li></ol><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/IF5tGEgRCTQ%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700190,15700253,15700256,15700259&amp;usg=ALkJrhgJH-Rb4ZQC-O4m4g9xBi4AM5xWpQ" frameborder="0" allowfullscreen=""></iframe></div><p>Source: <a href="https://habr.com/ru/post/160115/">https://habr.com/ru/post/160115/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../160093/index.html">PHP extensions: some interesting features</a></li>
<li><a href="../160105/index.html">Simple state machines in the service of the developer</a></li>
<li><a href="../160107/index.html">How I became a copywriter: Confession</a></li>
<li><a href="../160111/index.html">The appearance of dust on the matrix D600 in slow motion by a Canadian photographer</a></li>
<li><a href="../160113/index.html">The Manifesto of the Master / The Fixer's Manifesto</a></li>
<li><a href="../160117/index.html">Web API using the Django REST framework</a></li>
<li><a href="../160121/index.html">Logic - a compact selection of the latest gaming and IT-industry news number 2</a></li>
<li><a href="../160123/index.html">Tornado WebSocket Chat for your Django project</a></li>
<li><a href="../160125/index.html">Filter for comments Habrahabr as userscript</a></li>
<li><a href="../160127/index.html">Web server abroad + statics in Russia = speeding up page loading speed</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>