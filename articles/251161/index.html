<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Introduction to the course "Image and video analysis". Lectures from Yandex</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We are starting to publish lectures by Natalia Vasilyeva , Senior Researcher at HP Labs and Head of HP Labs Russia. Natalya Sergeevna gave a course on...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Introduction to the course "Image and video analysis". Lectures from Yandex</h1><div class="post__text post__text-html js-mediator-article">  We are starting to publish lectures by <a href="http://www.hpl.hp.com/people/nvassilieva/">Natalia Vasilyeva</a> , Senior Researcher at HP Labs and Head of HP Labs Russia.  Natalya Sergeevna gave a course on image analysis at the St. Petersburg Computer Science Center, which was created on the joint initiative of the Yandex Data Analysis School, JetBrains and CS Club <br><br><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://video.yandex.ru/iframe/csc-video/m-42301-150433499ca-8c5f0b53dc01d391/&amp;xid=17259,1500008,15700002,15700021,15700186,15700190,15700253&amp;usg=ALkJrhj3yFoF5iMkj6DTqbxIqBjE-q8Jxg" width="450" height="253" frameborder="0" scrolling="no" allowfullscreen="1"></iframe><br><br>  In total, the program - nine lectures.  The first of them tells how image analysis is used in medicine, security systems and industry, which tasks it has not yet learned to solve, what advantages human visual perception has.  Decryption of this part of the lectures - under the cut.  Starting from the 40th minute, the lecturer talks about Weber's experiment, color representation and perception, Mansell color system, color spaces and digital representations of the image.  Fully lecture slides are available <a href="https://yadi.sk/d/_w8dMYggepSht">here</a> . <br><a name="habracut"></a><br>  Images everywhere around us.  The volume of multimedia information is growing every second.  Films, sports matches are being made, equipment for video surveillance is being installed.  Every day we ourselves take a large number of photos and videos - almost every telephone has such an opportunity. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      For all these images to be useful, you need to be able to do something with them.  You can put them in a box, but then it is not clear why they should be created.  It is necessary to be able to search for the right pictures, to do something with video data - to solve problems specific to a particular area. <br><br>  Our course is called ‚ÄúImage and Video Analysis‚Äù, but it‚Äôs mainly about images.  It‚Äôs impossible to start video processing without knowing what to do with the picture.  Video is a collection of static images.  Of course, there are tasks specific to the video.  For example, tracking objects or the allocation of some key frames.  But at the heart of all the algorithms for working with video are algorithms for processing and analyzing images. <br><br>  What is image analysis?  This is largely adjacent and intersecting with computer vision area.  She has no exact and only definition.  For example, we give three. <br><br><blockquote>  Computing properties of the 3D world.  Trucco and Veri </blockquote><br>  This definition implies that regardless of whether we are or not, there is some surrounding world and its images, analyzing which we want to understand something about it.  And it is suitable not only for determining the analysis of digital images by a machine, but also for analyzing them with our head.  We have a sensor - the eyes, we have a transforming device - the brain, and we perceive the world by analyzing those pictures that we see. <br><br><blockquote>  Make it a useful decision.  Shapiro </blockquote><br>  Probably, this is more related to robotics.  We want to make decisions and draw conclusions about real objects around us based on the images that the sensors capture.  For example, this definition fits perfectly into the description of what a robot vacuum cleaner does.  He decides where to go next and what angle to vacuum based on what he sees. <br><br><blockquote>  Explicit construction, meaningful decisions of physical objects from images </blockquote><br>  The most common definition of the three.  If you rely on it, we just want to describe the phenomena and objects around us on the basis of image analysis. <br><br>  Summing up, we can say that, on average, image analysis comes down to extracting meaningful information from images.  For each specific situation, this meaningful information may be different. <br><br>  If we look at a photo in which a little girl eats ice cream, then we can describe it with words - this is how the brain interprets what we see.  About this we want to teach the car.  To describe an image with text, it is necessary to carry out such operations as recognizing objects and faces, determining the sex and age of a person, highlighting areas of uniform color, recognizing actions, and extracting textures. <br><br><h3>  Relationship with other disciplines </h3><br>  In the course of the course we will talk about image processing algorithms.  They are used when we increase the contrast, remove color or noise, apply filters, etc ... In principle, changing images is all that is done in image processing. <br><br><img src="https://habrastorage.org/files/6a4/28a/21c/6a428a21cdd2422abaae52ddf340d6a1.jpg"><br><br>  Next come image analysis and computer vision.  There are no exact definitions for them, but, in my opinion, they are characterized by the fact that having an image at the input, at the output we get a certain model or a certain set of features.  That is, some numeric parameters that describe this image.  For example, the histogram of the distribution of gray levels. <br><br>  In the image analysis, as a result, we get a feature vector.  Computer vision solves wider tasks.  In particular, models are built.  For example, a set of two-dimensional images can be constructed three-dimensional model of the premises.  And there is another adjacent area - computer graphics, in which they generate an image by model. <br><br>  All this is impossible without the use of knowledge and algorithms from a number of areas.  Such as pattern recognition and machine learning.  In principle, it can be said that image analysis is a special case of data analysis, an area of ‚Äã‚Äãartificial intelligence.  Neuropsychology can be attributed to the related discipline - in order to understand what opportunities we have and how the perception of pictures is arranged, it would be good to understand how our brain solves these problems. <br><br><h3>  What is image analysis for? </h3><br>  There are huge archives and collections of images, and one of the most important tasks is the <b>indexing and search for</b> pictures.  Collections are different: <br><br><ul><li>  Personalized  For example, on vacation, a person can take a couple of thousand photographs, with which then you need to do something. </li><li>  Professional.  They have millions of photos.  Here, too, there is a need to somehow organize, search, find what is required. </li><li>  Collections of reproductions.  These are also millions of images.  Now a large number of museums have virtual versions for which reproductions are digitized, i.e.  we get pictures of pictures.  For the time being, the utopian task is to search for all reproductions of the same author.  A person in style may assume that he sees, say, paintings by Salvador Dali.  It would be great if the car learned it. </li></ul><br>  What can you do with all these pictures?  The simplest thing is to somehow intelligently build <b>navigation</b> on them, classifying them by topic.  Separately fold the bears, the elephants separately, the oranges separately - so that the user would later be comfortable navigating through this collection. <br><br>  A separate task is the <b><a href="http://habrahabr.ru/company/yandex/blog/158067/">search for duplicates</a></b> .  In two thousand photographs from a non-repeating vacation are not so much.  We love to experiment, shoot with different shutter speeds, focal length, etc., which ultimately gives us a large number of <i>fuzzy duplicates</i> .  In addition, a duplicate search can help detect the illegal use of your photo, which you once could put on the Internet. <br><br>  An excellent task is to <b>choose the best photo</b> .  With the help of the algorithm, it is possible to understand which picture the user most likes.  For example, if this is a portrait, the face should be lit, the eyes open, the image should be clear, etc.  Modern cameras already have this feature. <br><br>  The search task is also the <b>creation of collages</b> , i.e.  selection of photos that will look good next. <br><br><h3>  Application of image analysis algorithms </h3><br>  Now absolutely amazing things are happening in medicine. <br><br><ul><li>  <b>Detection of anomalies</b> .  Already widely known and solved problem.  For example, using an X-ray picture, they try to understand whether the patient is healthy or not ‚Äî whether this picture is different from the picture of a healthy person.  This can be either a snapshot of the entire body, or a separate circulatory system to isolate abnormal vessels from it.  As part of this task - the search for cancer cells. </li><li>  <b>Diagnosis of diseases</b> .  Also made based on snapshots.  If you have a database of images of patients and it is known that the first anomaly occurs in healthy people, and the second means that the person has cancer, then, based on the similarity of images, you can help doctors diagnose diseases. </li><li>  <b>Modeling the body and predicting the effects of treatment</b> .  Now this is what is called cutting edge.  Although we are all similar, each organism is organized individually.  For example, we may have a different location or thickness of blood vessels.  If a person needs to connect a torn vessel with a shunt, then it is possible to determine where to put it, based on the expert opinion of the doctor, or by simulating the circulatory system and inserting the shunt in this model.  So we will be able to see how the blood flow changes, and predict how the patient will feel in different ways. </li></ul><br>  Another application is <b>security systems</b> .  In addition to the use of fingerprints and retina for authorization, there are still unsolved problems.  For example, ** detection of "suspicious" items **.  Its complexity is that you cannot give a description in advance of what is a suspicious subject.  Another interesting task is ** identifying suspicious behavior ** of a person in a video surveillance system.  It is impossible to provide all possible examples of anomalous behavior, so the recognition will be arranged to identify deviations from what is marked as normal. <br><br><img src="https://habrastorage.org/files/bcb/526/23a/bcb52623a966465fb8d92020523893ca.jpg"><br><br>  There are still a large number of areas where image analysis is used: military industry, robotics, filmmaking, the creation of computer games, and the automotive industry.  In 2010, an Italian company equipped a truck with cameras, which, using maps and a GPS signal, automatically drove from Italy to Shanghai.  The path passed through Siberia, not all of which is on the maps.  On this segment, a man-driven car that was driving in front of him passed the map to him.  The truck itself recognized traffic signs, pedestrians and understood how it can be rebuilt. <br><br><h3>  Difficulties </h3><br>  But why do we still drive cars ourselves, and even a person should be assigned to video surveillance systems?  One of the key problems is the <b>semantic gap</b> . <br><br><img src="https://habrastorage.org/files/aca/5fc/439/aca5fc43942c471d949cd33e26ee8917.jpg"><br><br>  A person, looking at a picture, understands its semantics.  The computer also understands the color of the pixels, knows how to select the texture and ultimately distinguish the brick wall from the carpet and recognize the person in the photo, but to determine whether he is happy, the machine can still.  We ourselves can not always understand this.  That is, an automatic understanding of whether students miss a lecture is the next level. <br><br>  In addition, our brain is a unique system of understanding and processing the picture that we see.  He is inclined to see what we want to see, and how to teach the same computer is an open question. <br><br><img src="https://habrastorage.org/files/50a/00c/a6a/50a00ca6acd14af8b94b3e5901ea3585.jpg"><br><br>  We are very good at summarizing.  In the image we are able to guess that we see the lamp.  We do not need to know all the modifications of an item from one class in order to assign a sample to it.  It is more difficult for a computer to do this, because visually different lamps can be very different. <br><br>  There are a number of difficulties that image analysis has not yet coped with. <br><img src="https://habrastorage.org/files/073/b28/ca6/073b28ca62e04a26bcaa70043c4488eb.jpg"><br><br><h3>  Human visual perception </h3><br>  Our brain often "completes" the picture and adds semantics.  We can all see ‚Äúsomething‚Äù or ‚Äúsomeone‚Äù in the outline of a cloud.  The visual system is self-learning.  It is difficult for Europeans to distinguish the faces of Asians, as he usually rarely meets them in life.  The visual system has learned to capture differences in European faces, and Asians, whom he saw little, seem to him "to the same person."  And vice versa.  There was a case with colleagues from Palo Alto who, together with the Chinese, developed an algorithm for detecting faces.  As a result, he miraculously found Asians, but could not see the Europeans. <br><br>  In each picture, we first look for familiar images.  For example, we see squares and circles here. <br><img src="https://habrastorage.org/files/010/06b/937/01006b9373f9454bac7121ccde51e171.jpg"><br><br><img src="https://habrastorage.org/files/92e/a23/185/92ea231853944fa29a68fceae6ed3b05.jpg"><br><br>  The eye is able to perceive very large ranges of brightness, but it does this in a sly way.  The visual system adapts to the range of brightness values ‚Äã‚Äãof the order of 10 ^ 10.  But at any given moment we can recognize a small patch of brightness.  That is, our eye chooses some point for itself, adapts to the brightness value in it and recognizes only a small range around this point.  All that is darker appears black, all that is lighter white.  But the eye moves very quickly and the brain completes the picture, so we see well. <br><br><img src="https://habrastorage.org/files/660/cb7/431/660cb7431bec4f8cb9639bb5f335a835.jpg"><br><br>  Subjective brightness is the logarithm of physical brightness.  If we look at the change in the brightness of any source and begin to change the brightness linearly, our eye will perceive it as a logarithm. <br><br><img src="https://habrastorage.org/files/071/ee8/c1f/071ee8c1f0c24c64b9ca2a5f84c76b99.jpg"><br><br>  Two types of components are responsible for visual perception - cones and rods.  Cones are responsible for color perception and can very clearly perceive the picture, but if it is not very dark.  This is called <b><a href="https://en.wikipedia.org/wiki/Photopic_vision">photopic vision</a></b> .  <b><a href="https://en.wikipedia.org/wiki/Scotopic_vision">Skotopic vision</a></b> works in the dark - sticks are included, which are smaller than cones and which do not perceive color, therefore the picture is blurred. </div><p>Source: <a href="https://habr.com/ru/post/251161/">https://habr.com/ru/post/251161/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../251141/index.html">Another software UART on ATtiny13</a></li>
<li><a href="../251143/index.html">Own implementation of https using crypto ++ for I2P bootstrapping</a></li>
<li><a href="../251149/index.html">We write a bot for MMORPG with assembler and draenei. Part 1</a></li>
<li><a href="../251155/index.html">Creating MMC Management Console</a></li>
<li><a href="../251157/index.html">The most needed plugins for Grunt</a></li>
<li><a href="../251163/index.html">About Intel Hyper-Threading and Virtual Machine Performance</a></li>
<li><a href="../251165/index.html">22 tips, tricks and shokkat for Android Lollipop</a></li>
<li><a href="../251167/index.html">Adding Wi-Fi to various devices</a></li>
<li><a href="../251171/index.html">Operating systems lost and acquired by extra-browser javascript</a></li>
<li><a href="../251173/index.html">Why less does not mean more boring</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>