<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Robot Tank on Raspberry Pi with OpenCV</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At one time I was fond of assembling machine robots on Arduino and Raspberry Pi. I liked to play constructor, but I wanted something more. 

 And once...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Robot Tank on Raspberry Pi with OpenCV</h1><div class="post__text post__text-html js-mediator-article">  At one time I was fond of assembling machine robots on Arduino and Raspberry Pi.  I liked to play constructor, but I wanted something more. <br><br>  And once, wandering around Aliexpress, I came across an aluminum chassis for a tank.  This creation looked in comparison with plastic cars like Ferrari in comparison with a cart. <br><a name="habracut"></a><br>  I made myself a gift for the New Year, the tank arrived, it was assembled and then I had to revive it.  I took my own Raspberry, power converter, motor controller and battery.  All this was put on the tank and earned joy. <br><br>  Further on, a simple REST API for taxiing was written on the python, and on Android it was the same simple program that allowed you to control the tank by pulling this API. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The tank should shoot, and the next step was the appearance of his camera.  I didn‚Äôt manage to guess with the camera body - he didn‚Äôt hold the camera in the open position and was so tight in the shut that the camera had a lens flying off.  Having suffered, I simply wound the camera tape to the cover of the case.  Now the tank could not just drive around the room, but also take pictures. <br><br><img src="https://habrastorage.org/webt/nh/bs/k_/nhbsk_t4yqz9v-upqnp13paf4_q.jpeg" alt="image"><br><br>  It is worth noting a serious advantage of the tank over the cars at home - on the track it does not make a difference, go on hard floor or on the carpet.  Wheeled transport slips on a soft carpet, up to the impossibility of turning. <br><br>  Then I wanted to develop the tank in the direction of autonomous navigation, relying on pictures from the camera.  I had to immerse myself in the world of computer vision and discover OpenCV.  It all started with the recognition of color and contour - printed a red circle on paper, pasted it on the TV and made the robot spin until the circle was found. <br><br>  The idea was to mark visible objects in the room (sofa, TV, table) with colored circles and teach the robot to navigate by color. <br><br>  Using OpenCV, we searched for the contours of the desired color (with permissible tolerance), then we looked for a circle among the contours. <br><br>  It seemed that the main problem could be a random circle of the desired color on any of the objects. <br><br>  However, the main problem turned out to be that the color is very changeable depending on the lighting, so the range in which red was recognized (for example) had to be stretched to shades that very remotely resemble the original color.  Or choose the desired color from the image, but in any case it was not red anymore, but a shade of brown. <br><br>  Search mug red: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mask_color</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img, c1, c2)</span></span></span><span class="hljs-function">:</span></span> img = cv2.medianBlur(img, <span class="hljs-number"><span class="hljs-number">5</span></span>) hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) mask = cv2.inRange(hsv, c1, c2) mask = cv2.erode(mask, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, iterations=<span class="hljs-number"><span class="hljs-number">2</span></span>) mask = cv2.dilate(mask, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, iterations=<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mask <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">find_contours</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img)</span></span></span><span class="hljs-function">:</span></span> gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) blurred = cv2.GaussianBlur(gray, (<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), <span class="hljs-number"><span class="hljs-number">0</span></span>) thresh = cv2.threshold(blurred, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY)[<span class="hljs-number"><span class="hljs-number">1</span></span>] thresh = cv2.bitwise_not(thresh) im2, cnts, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE) cp_img = img.copy() cv2.drawContours(cp_img, cnts, <span class="hljs-number"><span class="hljs-number">-1</span></span>, (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">255</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>), <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cp_img <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">find_circles</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img)</span></span></span><span class="hljs-function">:</span></span> gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) blurred = cv2.medianBlur(gray,<span class="hljs-number"><span class="hljs-number">5</span></span>) circles = cv2.HoughCircles(blurred,cv2.HOUGH_GRADIENT,<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>,param1=<span class="hljs-number"><span class="hljs-number">50</span></span>,param2=<span class="hljs-number"><span class="hljs-number">30</span></span>,minRadius=<span class="hljs-number"><span class="hljs-number">0</span></span>,maxRadius=<span class="hljs-number"><span class="hljs-number">0</span></span>) cimg = img <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> circles <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: circles = np.uint16(np.around(circles)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> circles[<span class="hljs-number"><span class="hljs-number">0</span></span>,:]: cv2.circle(img,(i[<span class="hljs-number"><span class="hljs-number">0</span></span>],i[<span class="hljs-number"><span class="hljs-number">1</span></span>]),i[<span class="hljs-number"><span class="hljs-number">2</span></span>],(<span class="hljs-number"><span class="hljs-number">255</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>),<span class="hljs-number"><span class="hljs-number">2</span></span>) cv2.circle(img,(i[<span class="hljs-number"><span class="hljs-number">0</span></span>],i[<span class="hljs-number"><span class="hljs-number">1</span></span>]),<span class="hljs-number"><span class="hljs-number">2</span></span>,(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">255</span></span>),<span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">"C"</span></span>, i[<span class="hljs-number"><span class="hljs-number">0</span></span>],i[<span class="hljs-number"><span class="hljs-number">1</span></span>],i[<span class="hljs-number"><span class="hljs-number">2</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cimg <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">find_circle</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img, rgb)</span></span></span><span class="hljs-function">:</span></span> tolerance = <span class="hljs-number"><span class="hljs-number">4</span></span> hsv = cv2.cvtColor(rgb, cv2.COLOR_BGR2HSV) H = hsv[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] c1 = (H - tolerance, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>) c2 = (H + tolerance, <span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>) c_mask = mask_color(img, c1, c2) rgb = cv2.cvtColor(c_mask,cv2.COLOR_GRAY2RGB) cont_img = find_contours(rgb) circ_img = find_circles(cont_img) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"Image"</span></span>, circ_img) cv2.waitKey(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: img_name = sys.argv[<span class="hljs-number"><span class="hljs-number">1</span></span>] img = cv2.imread(img_name) rgb = np.uint8([[[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span> ]]]) find_circle(img, rgb)</code> </pre> <br>  Color recognition has come to a standstill, I was distracted by the cascades of Haar, using a tank for photo-hunting for a cat.  The cat was disguised well, forcing the cascade to make mistakes in half of the cases (if anyone does not know, OpenCV comes with the Haar cascade specially trained on the seals - take it and use it). <br><br>  The hunt for a cat had beneficial consequences for the robot - since it was not always possible to catch the object of the hunt in a static camera, I put a tripod with two servomotors (and a PWM module to control them through Raspberry). <br><br>  Continuing research on what can be squeezed out of the pictures of the room, I naturally came to neural networks.  Having swallowed the Tensorflow tutorial, I processed a photo from the tank with the detector and the results were promising - a TV, a table, a sofa, a cat, a refrigerator were recognized unmistakably. <br><br>  These experiments were carried out on a computer, and the matter remained for a small one - to transfer the TF to the Raspberry Pi.  Fortunately, a unique person lives on a githaba who has gained patience and broke through the installation of all dependencies and many hours of compilation - and laid out the shared Tensorflow for Raspberry Pi. <br><br>  However, further study of the topic revealed that OpenCV does not stand still and its contributors released the DNN module (Deep Neural Networks), which offers integration with neural networks trained in TensorFlow.  This solution is much more convenient to develop, plus there is no need for the TF itself.  I had to conjure a little, since the latest version of the Mobile SSD neural network for TF was no longer picked up by the latest version of OpenCV.  Should have been looking for <br>  and check the working version of Mobile SSD.  Plus, DNN normally works only under OpenCV 3.4, and I did not find this version for Raspberry.  I had to collect it myself, the benefit is much easier than messing with TensorFlow.  At the same time, Raspbian (Stretch) failed to assemble OpenCV under the latest version, but on the latest version of the previous generation (Jessie) everything took off as it should. <br><br>  Sample code using DNN and not using Tensorflow. <br><br>  Several files responsible for the names of the objects were pulled from the TF and the dependence on the TF itself was removed (there was only read from the file). <br>  Source code on githaba. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cv <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tf_labels <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys DNN_PATH = <span class="hljs-string"><span class="hljs-string">"---path-to:ssd_mobilenet_v1_coco_11_06_2017/frozen_inference_graph.pb"</span></span> DNN_TXT_PATH = <span class="hljs-string"><span class="hljs-string">"--path-to:ssd_mobilenet_v1_coco.pbtxt"</span></span> LABELS_PATH = <span class="hljs-string"><span class="hljs-string">"--path-to:mscoco_label_map.pbtxt"</span></span> tf_labels.initLabels(PATH_TO_LABELS) cvNet = cv.dnn.readNetFromTensorflow(pb_path, pb_txt) img = cv.imread(sys.argv[<span class="hljs-number"><span class="hljs-number">1</span></span>]) rows = img.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cols = img.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] cvNet.setInput(cv.dnn.blobFromImage(img, <span class="hljs-number"><span class="hljs-number">1.0</span></span>/<span class="hljs-number"><span class="hljs-number">127.5</span></span>, (<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>), (<span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>), swapRB=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, crop=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)) cvOut = cvNet.forward() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detection <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cvOut[<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,:,:]: score = float(detection[<span class="hljs-number"><span class="hljs-number">2</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> score &gt; <span class="hljs-number"><span class="hljs-number">0.25</span></span>: left = int(detection[<span class="hljs-number"><span class="hljs-number">3</span></span>] * cols) top = int(detection[<span class="hljs-number"><span class="hljs-number">4</span></span>] * rows) right = int(detection[<span class="hljs-number"><span class="hljs-number">5</span></span>] * cols) bottom = int(detection[<span class="hljs-number"><span class="hljs-number">6</span></span>] * rows) label = tf_labels.getLabel(int(detection[<span class="hljs-number"><span class="hljs-number">1</span></span>])) print(label, score, left, top, right, bottom) text_color = (<span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">230</span></span>, <span class="hljs-number"><span class="hljs-number">210</span></span>) cv.rectangle(img, (left, top), (right, bottom), text_color, thickness=<span class="hljs-number"><span class="hljs-number">2</span></span>) cv.putText(img, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">1</span></span>, text_color, <span class="hljs-number"><span class="hljs-number">2</span></span>) cv.imshow(<span class="hljs-string"><span class="hljs-string">'img'</span></span>, img) cv.waitKey()</code> </pre><br>  In general, the tank's pictures can now be recognized by the neural network, and this is a very important step in navigation in terms of recognizing landmarks.  However, some images were not enough for full navigation, it was necessary to measure the distance to obstacles.  So the robot has an echo sounder.  To connect the echo sounder to the Raspberry, you need to work a little - the echo sounder returns the signal to 5V, and the Raspberry takes 3.3V.  On the knee, this problem is solved mainly by resistors on the brainboard, but I did not want to fence such amateur work on the robot.  As a result, the Level Shifter microcircuit was found, which does everything that is needed, and is the size of a nail. <br><br>  In addition, I attended to the appearance of the robot - I didn‚Äôt like it very much that the microcircuits and the camera with the echo sounder were stuck to the cardboard boxes.  The development of technology in our world allows you to cut plastic with a laser with a reasonable investment of time and money.  In general, I found a workshop with a laser machine, spent some time studying the instructions for this wonderful machine, and not on the first attempt cut out the panels for the microcircuits and the camera with an echo sounder. <br><br><img src="https://habrastorage.org/webt/pp/dd/4m/ppdd4mdryjvnu0_wszqxefkuhco.jpeg" alt="image"><br><br>  Everything is ready for autonomous navigation, but the task turned out to be not so simple and on the first attempt I dug a little.  I decided to take a pause, think about everything, study analogs.  Perhaps this navigation will serve as a topic for a separate article. <br><br>  REST interface that the robot provides as a base for further use: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /ping <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">version</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /<span class="hljs-type"><span class="hljs-type">name</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /dist POST /fwd/<span class="hljs-keyword"><span class="hljs-keyword">on</span></span> POST /fwd/<span class="hljs-keyword"><span class="hljs-keyword">off</span></span> POST /back/<span class="hljs-keyword"><span class="hljs-keyword">on</span></span> POST /back/<span class="hljs-keyword"><span class="hljs-keyword">off</span></span> POST /left/<span class="hljs-keyword"><span class="hljs-keyword">on</span></span> POST /left/<span class="hljs-keyword"><span class="hljs-keyword">off</span></span> POST /right/<span class="hljs-keyword"><span class="hljs-keyword">on</span></span> POST /right/<span class="hljs-keyword"><span class="hljs-keyword">off</span></span> POST /photo/make <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /photo/:phid <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /photo/list POST /cam/up POST /cam/down POST /cam/right POST /cam/left POST /detect/haar/:phid POST /detect/dnn/:phid</code> </pre><br><h3>  References: </h3><br><ol><li>  <a href="https://habr.com/company/intel/blog/333612/">OpenCV DNN</a> </li><li>  <a href="">SSD MobileNet compatible with OpenCV-3.4.1</a> </li><li>  <a href="https://github.com/samjabrahams/tensorflow-on-raspberry-pi">Tensorflow for Raspberry Pi</a> </li><li>  <a href="https://github.com/tprlab/pitanq">Rest server code for a github robot</a> </li><li>  <a href="https://github.com/tprlab/pi-opencv">Compiled OpenCV 3.4.1 with DNN support for Raspbian Jessie</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/358230/">https://habr.com/ru/post/358230/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../358220/index.html">A selection of books from the Massachusetts Institute of Technology</a></li>
<li><a href="../358222/index.html">A little investigation: how YouTube uses WebRTC for streaming</a></li>
<li><a href="../358224/index.html">Software testing: automation, evaluation and ... utopian</a></li>
<li><a href="../358226/index.html">Fintech-digest: online banking unhappy because of the lack of "humanity"; $ 10 billion bitcoins are stored in Switzerland</a></li>
<li><a href="../358228/index.html">How we conduct experiments in humans. A / b testing for advanced</a></li>
<li><a href="../358232/index.html">Support for HTTP / 2 Server Push technology in Node.js</a></li>
<li><a href="../358234/index.html">"Calendar tester" for May. Load service</a></li>
<li><a href="../358236/index.html">DevOps Moscow meetup: Monitoring</a></li>
<li><a href="../358238/index.html">Women's networks: who makes the choice for us?</a></li>
<li><a href="../358242/index.html">AI.Hack St. Petersburg</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>