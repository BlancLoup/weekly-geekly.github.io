<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Optical character recognition on the microcontroller</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Today, optical character recognition is part of solving such applied tasks as text recognition and digitization, document recognition, license plate r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Optical character recognition on the microcontroller</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/f84/4f9/fc6/f844f9fc61a04c09994017436efeb43f.jpg"><br><br>  Today, optical character recognition is part of solving such applied tasks as text recognition and digitization, document recognition, license plate recognition, identification of bank cards, reading meter readings, identification of house numbers for creating maps (Google Street View), etc. d. <br><br>  The recognition of a symbol means the analysis of its image in order to obtain a certain set of signs for comparing them with the signs of a class [ <a href="https://habrahabr.ru/company/abbyy/blog/228251/">1</a> ].  The choice of such a set and the methods for its determination are distinguished by different recognition methods, but for most of them, instantaneous information about all the pixels of the image is needed. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The latter circumstance and a sufficiently large amount of computation make it impossible to use low-power computing devices (microcontrollers) for optical character recognition.  ‚ÄúAnd why?‚Äù, The informed reader exclaims, ‚Äúthe power of computing devices is constantly growing, and their price is falling!‚Äù [ <a href="https://geektimes.ru/company/dadget/blog/279418/">2</a> , <a href="https://geektimes.ru/post/289759/">3</a> ].  Suppose the answer is: just wondering, is it possible to simplify the recognition method to such an extent that you can use a microcontroller? <br><a name="habracut"></a><br>  It turned out possible, moreover, it turned out to be possible what seems to be related to the field of fiction, namely: <br><br><ul><li>  recognition regardless of the font; </li><li>  recognition of a character string without division into individual characters; </li><li>  recognition of "shielded" characters, for example, a character in a character; </li><li>  recognition of "broken" characters; </li><li>  recognition of characters consisting of several parts; </li><li>  recognition without changing signs when turning up to 15 ¬∞.  Opportunity <br>  recognition of rotated characters at a greater angle due to changes in its signs; </li><li>  character recognition in a video stream from one frame; </li><li>  handwriting recognition; </li><li>  limited number of characters to describe a character class, for Arabic numerals <br>  and Latin - one, for Cyrillic - maximum two (for example, for some <br>  variants of writing W); </li><li>  simple "manual" definition of signs for a new class; </li><li>  automatic detection of signs for a new class; </li><li>  expansion of classes of characters by simply adding its features to the database; </li></ul><br>  And all this on a microcontroller. <br><br><h2>  The main idea of ‚Äã‚Äãthe method </h2><br>  Now more about the method itself.  Consider, for example, the various styles of the symbol A: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/39c/640/93a/39c64093a92745459223e06f8b97e3f7.jpg"></div><br>  Despite the visible differences, one can distinguish common features of the structural type, which are <i>necessary</i> signs of an A capital letter (for unbroken characters), namely: <i>if the character in question is an A capital letter, then it will contain a closed area and an area open down.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/d13/9e6/55e/d139e655ee2e47feb776c4c1925bce24.jpg"></div><br>  Once again we emphasize that the indicated signs are necessary, but not sufficient: if we describe the contours around two areas of the specified type, <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/b45/6cc/7a9/b456cc7a97d94ceab7d11165caa564ff.jpg"></div><br>  then it will not necessarily be capital letters A, are possible, for example, D, I, R, lowercase handwritten A, ..: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/16a/ee1/261/16aee1261df84c75b8e8580ac0ef39a7.jpg"></div><br>  However, the use of areas as elements of a symbol allows you to generate sufficient features, and, for the vast majority of alphanumeric characters, you can form a single sufficient attribute!  It is very easy to form it for each class and, unlike the structural features used by <a href="https://habrahabr.ru/users/abbyyteam/" class="user_link">ABBYYTeam</a> in recognizing handwritten characters [ <a href="https://habrahabr.ru/company/abbyy/blog/228251/">1</a> ], its variability is very low and it is possible to form it automatically!  In other words, such signs work well for both printed and handwritten characters. <br><br><h2>  Recognition device </h2><br>  The first verification of the method was described in article [ <a href="https://geektimes.ru/post/279886/">4</a> ].  The method was tested on single digits, obtained by a primitive camera from a mouse from a seven-segment indicator or printed on paper.  After the first success, a natural desire arose to check the possibility of recognizing a sequence of characters, and for this you need to use another camera.  We used the camera OV7670 (0.3MP).  The remaining main components of the scheme remained unchanged - this is the Arduino and ESP8266, but their functions have changed.  Arduino is now used to initialize the camera, as a master oscillator, receive recognized characters and display them on indicators.  ESP8266 is engaged in obtaining images from the camera and its recognition, in addition, it provides data transmission to Arduino for display and transmission of recognized information via WiFi to external devices, for example, a smartphone.  The used circuitry of the device is shown in the figure: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/06e/787/e1c/06e787e1c7154d27aaba2dcfa81d588c.jpg"></div><br>  The image enters the device through the slit in its lower part and, being reflected from the mirror, enters the camera.  The image is illuminated by an LED through the same mirror.  The mechanical scheme of the device is shown in the figure. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/a5d/547/01a/a5d54701a367414a98ef103f4450a8c6.jpg"></div><br><div class="spoiler">  <b class="spoiler_title">Photos of the working prototype</b> <div class="spoiler_text"><h4>  The first version of the working prototype: </h4><br><img src="https://habrastorage.org/web/cfe/f67/13f/cfef6713fb204796bcb7510f8ac9e2ba.JPG"><img src="https://habrastorage.org/web/e39/375/f7f/e39375f7ff954270ac9f4ff226194461.JPG"><br><img src="https://habrastorage.org/web/8bc/b7e/42a/8bcb7e42a7214bdd90415a063311bd39.JPG"><img src="https://habrastorage.org/web/fdb/f02/925/fdbf02925c13467fa0a485a30a3f9740.JPG"><br><img src="https://habrastorage.org/web/0d5/eff/72d/0d5eff72da764fd7b1cb9f97ee65ad94.JPG"><img src="https://habrastorage.org/web/912/c71/50f/912c7150f61c4397b3d7de39e8b09dba.JPG"><br><br><h4>  The second version of the working prototype: </h4><br><img src="https://habrastorage.org/web/800/019/935/800019935c574280864b21626b7ac88f.JPG"><img src="https://habrastorage.org/web/fae/0dd/143/fae0dd143ff841929e287ced6d24fbbd.JPG"><br><img src="https://habrastorage.org/web/992/ec4/f31/992ec4f3151348bfb888d39ab730070a.JPG"><img src="https://habrastorage.org/web/531/6e8/284/5316e828441546278eca1783957fc643.JPG"><br><img src="https://habrastorage.org/web/cef/095/b03/cef095b033734448b9a73c6101463ee0.JPG"><img src="https://habrastorage.org/web/1c5/eb7/5e6/1c5eb75e6ae44447aa45be92ee9edc99.JPG"><br><img src="https://habrastorage.org/web/392/2c1/a38/3922c1a38c074202a7008b016ef199da.JPG"><img src="https://habrastorage.org/web/7ab/839/972/7ab8399721414cbcb5d9af9b0d5aa281.JPG"><br></div></div><br><h2>  Image Acquisition on ESP8266 </h2><br>  Camera settings during initialization are taken from [ <a href="">5</a> ].  The frame rate is approximately 0.4 fps. Since the number of pins of the ESP8266 is not enough, only 6 high-order bits of each brightness byte of the image are processed (the camera is configured in YUV mode).  To obtain an image, a state machine is used (state machine). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/63a/34c/5d4/63a34c5d41264892b4dfef1dc13961b4.jpg"></div><br>  According to the datasheet camera OV7670 [ <a href="https://www.voti.nl/docs/OV7670.pdf">6</a> ] <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/0f4/cc0/685/0f4cc068539e455a98c6fd0dc49db42c.jpg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/web/4ff/a10/cfa/4ffa10cfafe64296b90c9e32b26886f2.jpg"></div><br>  The following conditions of the camera, conditions and signals during its operation can be distinguished: <br><table><tbody><tr><td>  <font>State name,</font> <font>number</font> </td><td>  State description </td><td>  Signal to transition <br>  to another state </td></tr><tr><td>  camoff, 0 </td><td>  camera <br>  not ready to work </td><td>  <font>vzz</font> <font><br></font>  <font>(vsync = 1, href =</font> <font>0</font> <font>, pclk =</font> <font>0</font> <font>)</font> </td></tr><tr><td>  frapause, 1 </td><td>  pause <br>  between frames.  waiting for the start of the frame. </td><td>  zzz (vsync = 0, href = 0, pclk = 0) </td></tr><tr><td>  framebeg, 2 </td><td>  reading <br>  frame.  waiting for the beginning of the line in the frame. </td><td>  zhz (vsync = 0, href = 1, pclk = 0) </td></tr><tr><td>  framebeg, 2 </td><td>  reading <br>  frame.  waiting for the end of the frame after reading <br>  last pixel </td><td>  <font>vzz</font> <font><br></font>  <font>(vsync = 1, href =</font> <font>0</font> <font>, pclk =</font> <font>0</font> <font>)</font> </td></tr><tr><td>  <font>fbyteread,</font> <font>3</font> </td><td>  brightness <br>  bytes read.  waiting for the pause to start <br>  before the color difference byte. </td><td>  zhz (vsync = 0, href = 1, pclk = 0) </td></tr><tr><td>  <font>fpause,</font> <font>4</font> </td><td>  pause <br>  before the color difference byte.  expectation <br>  start reading the color difference byte. </td><td>  <font>zhp</font> <font><br></font>  <font>(vsync = 0, href =</font> <font>1</font> <font>, pclk =</font> <font>1</font> <font>)</font> </td></tr><tr><td>  <font>sbyteread,</font> <font>5</font> </td><td>  color difference <br>  bytes read.  waiting for the pause to start <br>  before the luminance byte. </td><td>  zhz (vsync = 0, href = 1, pclk = 0) </td></tr><tr><td>  <font>spause,</font> <font>6</font> </td><td>  pause <br>  before the luminance byte.  expectation <br>  end of line. </td><td>  <font>zzz</font> <font><br></font>  <font>(vsync = 0, href =</font> <font>0,</font> <font>pclk = 0)</font> </td></tr><tr><td>  <font>spause,</font> <font>6</font> </td><td>  pause <br>  before the luminance byte.  waiting to start <br>  read luminance byte. </td><td>  <font>zhp</font> <font><br></font>  <font>(vsync = 0, href =</font> <font>1</font> <font>, pclk =</font> <font>1</font> <font>)</font> </td></tr></tbody></table><br>  The implementation of the machine is based on the same principles as outlined in [ <a href="https://habrahabr.ru/post/302226/">7</a> ].  The whole machine is described by its genome - a three-dimensional vector, the first component of which contains the keys, and the second - the names of the new states, the third - the names of the functions.  The key contains information on the current state and the transition signal.  For the formation of the key and the signal bit operations are used.  The implementation details are clear from the code of the camera reading module. <br><br><div class="spoiler">  <b class="spoiler_title">user_main.c</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ets_sys.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"osapi.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"os_type.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;gpio.h&gt; #include "driver/uart_register.h" #include "user_config.h" #include "user_interface.h" #include "driver/uart.h" #include "readCam.h" #define DELAY 5000 /* milliseconds */ LOCAL os_timer_t cam_timer; uint16_t frN; extern uint8_t pixVal; uint8_t rN[10]; LOCAL void ICACHE_FLASH_ATTR getNFrame(void *arg){ uint16_t sig, sV,sH,sP; uint16_t pVal; uint16_t d7,d6,d5,d4,d3,d2; stateMashine camSM; ets_uart_printf("getNFrame...\r\n"); initSMcm(&amp;camSM); while(frN&lt;20){ system_soft_wdt_feed(); pVal= *GPIO_IN; sV=((pVal&amp;(1UL&lt;&lt;VSYNC))&gt;&gt;VSYNC); sH=((pVal&amp;(1UL&lt;&lt;HREF))&gt;&gt;HREF); sP=((pVal&amp;(1UL&lt;&lt;PCLK))&gt;&gt;PCLK); sig=4*sV+2*sH+sP*sH; d7=((pVal&amp;(1UL&lt;&lt;D7))&gt;&gt;D7); d6=((pVal&amp;(1UL&lt;&lt;D6))&gt;&gt;D6); d5=((pVal&amp;(1UL&lt;&lt;D5))&gt;&gt;D5); d4=((pVal&amp;(1UL&lt;&lt;D4))&gt;&gt;D4); d3=((pVal&amp;(1UL&lt;&lt;D3))&gt;&gt;D3); d2=((pVal&amp;(1UL&lt;&lt;D2))&gt;&gt;D2); pixVal=128*d7+64*d6+32*d5+16*d4+8*d3+4*d2; exCAM(&amp;camSM,sig,&amp;frN,rN); } } uint32 ICACHE_FLASH_ATTR user_rf_cal_sector_set(void) { enum flash_size_map size_map = system_get_flash_size_map(); uint32 rf_cal_sec = 0; switch (size_map) { case FLASH_SIZE_4M_MAP_256_256: rf_cal_sec = 128 - 8; break; case FLASH_SIZE_8M_MAP_512_512: rf_cal_sec = 256 - 5; break; case FLASH_SIZE_16M_MAP_512_512: case FLASH_SIZE_16M_MAP_1024_1024: rf_cal_sec = 512 - 5; break; case FLASH_SIZE_32M_MAP_512_512: case FLASH_SIZE_32M_MAP_1024_1024: rf_cal_sec = 1024 - 5; break; default: rf_cal_sec = 0; break; } return rf_cal_sec; } void ICACHE_FLASH_ATTR user_init(void){ void (*cbGetFrame)(void *arg); cbGetFrame=(void*)getNFrame; UARTInit(BIT_RATE_921600); user_gpio_init(); os_timer_disarm(&amp;cam_timer); os_timer_setfn(&amp;cam_timer, (os_timer_func_t *)cbGetFrame, NULL); os_timer_arm(&amp;cam_timer, DELAY, 0); }</span></span></span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">readCam.h</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifndef</span></span></span><span class="hljs-meta"> INCLUDE_READCAM_H_ #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> INCLUDE_READCAM_H_ #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> GPIO_IN ((volatile uint32_t*) 0x60000318) #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> WP 320 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> HP 240 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> PIXTYP 0 </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//image __________________________________________ #define IMAGEY0 60 #define IMAGEH HP/3 //____________________pins_____________________ #define VSYNC 15 #define HREF 13 #define PCLK 3 #define D7 4 #define D6 12 #define D5 0 #define D4 14 #define D3 2 #define D2 5 //*************signals OV7670***************** #define ZZZ 0 #define VZZ 4 #define ZHZ 2 #define ZHP 3 //*************states OV7670******************* #define CAMOFF 0 #define FRAPAUSE 1 #define FRAMEBEG 2 #define FBYTEREAD 3 #define FPAUSE 4 #define SBYTEREAD 5 #define SPAUSE 6 #define SSCC 40//max state_signal_condition count #define STATE_L 5 #define STATE_V 0x1F #define SIG_L 8 #define SIG_V 0xFF typedef struct { uint8 pix[WP] ; }linePixel; typedef struct gen{ uint8_t state; uint8_t sig; uint8_t stateX; void *fp; }gen; typedef struct stateMashine{ uint8_t count; uint16_t ssc[SSCC]; uint8_t stateX[SSCC]; void *fPoint[SSCC]; void *fpd; }stateMashine; #endif /* INCLUDE_READCAM_H_ */</span></span></span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">readCam.c</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ets_sys.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"osapi.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"os_type.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;gpio.h&gt; #include "driver/uart_register.h" #include "user_config.h" #include "user_interface.h" #include "driver/uart.h" #include "readCam.h" void sendLine(uint16_t lN); void ICACHE_FLASH_ATTR sendFramMark(void); void ICACHE_FLASH_ATTR sendCtr3Byte(uint8_t typ,uint16_t len); void user_gpio_init(void); void sendByte(uint8_t bt); void ICACHE_FLASH_ATTR initSMcm(stateMashine *psm); void exCAM( stateMashine *psm,uint8_t sig,uint16_t *frameN,uint8_t *rN); int indexOf(stateMashine *psm,uint16_t ssc); linePixel lp; uint8_t pixVal; void exCAM( stateMashine *psm,uint8_t sig,uint16_t *frameN,uint8_t *rN){ int16_t ind; uint16_t lN; uint16_t pN; static uint8_t state=CAMOFF,stateX=CAMOFF; static void (*pfun)()=NULL; uint16_t stateSigCond=0; stateSigCond|=((state&amp;STATE_V)&lt;&lt;(16-STATE_L))|((sig&amp;SIG_V)&lt;&lt;(16-STATE_L-SIG_L)); ind=indexOf(psm,stateSigCond); if(ind&gt;-1) stateX=(*psm).stateX[ind]; if(ind&gt;-1) pfun=(*psm).fPoint[ind]; else pfun=(*psm).fpd; pfun(frameN,&amp;lN,&amp;pN,rN); state=stateX; } void _cm0(){} void _cm1(uint16_t *fN,uint16_t *lN,uint16_t *pN){//new frame sendFramMark(); sendCtr3Byte(PIXTYP,0); (*lN)=0; } void _cm2(uint16_t *fN,uint16_t *lN,uint16_t *pN){//frame end if(*lN==HP-1)(*fN)++; } void _cm3(uint16_t *fN,uint16_t *lN,uint16_t *pN){//new line uint16_t pixN; (*pN)=0; // pixN=(*pN);//right image pixN=WP-1-(*pN);//revers image (lp).pix[pixN]=pixVal; (*pN)++; } void _cm4(uint16_t *fN,uint16_t *lN,uint16_t *pN){// first byte uint16_t pixN; // pixN=(*pN);//right image pixN=WP-1-(*pN);//reverse image (lp).pix[pixN]=pixVal; // if(pixN&lt;WP-1)(*pN)++;//right image if(pixN)(*pN)++;//reverse image } void _cm5(uint16_t *fN,uint16_t *lN,uint16_t *pN,uint8_t *rN){//end line uint16_t lineN; lineN=(*lN); sendLine(lineN); if((*lN)&lt;HP-1)(*lN)++; } void _cm99(){} int indexOf(stateMashine *psm,uint16_t ssc){ uint8_t i,count; count=(*psm).count; for(i=0;i&lt;count;i++){ if((*psm).ssc[i]==ssc) return i; } return -1; } void ICACHE_FLASH_ATTR initSMcm(stateMashine *psm){ uint8_t i,count; count=10; gen gen[]={ {CAMOFF,VZZ,FRAPAUSE,_cm0},//0#1 {FRAPAUSE,ZZZ,FRAMEBEG,_cm1},//1#2 {FRAMEBEG,VZZ,FRAPAUSE,_cm2},//2#1 {FRAMEBEG,ZHZ,FBYTEREAD,_cm3},//2#3 {FBYTEREAD,ZHP,FPAUSE,_cm0},//3#4 {FPAUSE,ZHZ,SBYTEREAD,_cm0},//4#5 {SBYTEREAD,ZHP,SPAUSE,_cm0},//5#6 {SPAUSE,ZHZ,FBYTEREAD,_cm4},//6#3 {SPAUSE,ZZZ,FRAMEBEG,_cm5},//6#2 {FPAUSE,ZZZ,FRAMEBEG,_cm5},//5#2 }; (*psm).count=count; for(i=0;i&lt;count;i++){ (*psm).ssc[i]=0; (*psm).ssc[i]|=((gen[i].state&amp;STATE_V)&lt;&lt;(16-STATE_L))| ((gen[i].sig&amp;SIG_V)&lt;&lt;(16-STATE_L-SIG_L)); (*psm).stateX[i]=gen[i].stateX; (*psm).fPoint[i]=gen[i].fp; } (*psm).fpd=_cm99; } void sendByte(uint8_t bt){ uint16_t lenBuff; uint8_t buf[TX_BUFF_SIZE]; while(lenBuff){ lenBuff = (READ_PERI_REG(UART_STATUS(0))&gt;&gt;UART_TXFIFO_CNT_S) &amp; UART_TXFIFO_CNT; } buf[lenBuff] =bt; uart0_tx_buffer(buf, lenBuff + 1); } void sendLine(uint16_t lN){ uint16_t j; uint8_t sByt; for(j=0;j&lt;WP;j++){ sByt=(lp).pix[j]; if(lN&lt;IMAGEY0||lN&gt;(IMAGEY0+IMAGEH))sByt=0xFF; sendByte(sByt); } } void ICACHE_FLASH_ATTR user_gpio_init(void) { ets_uart_printf("GPIO initialisation...\r\n"); PIN_FUNC_SELECT(PERIPHS_IO_MUX_GPIO0_U, FUNC_GPIO0); gpio_output_set(0, 0, 0, BIT0); // Set GPIO0 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_GPIO2_U, FUNC_GPIO2); gpio_output_set(0, 0, 0, BIT2); // Set GPIO2 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_U0RXD_U, FUNC_GPIO3); gpio_output_set(0, 0, 0, BIT3); // Set GPIO3 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_GPIO4_U, FUNC_GPIO4); gpio_output_set(0, 0, 0, BIT4); // Set GPIO4 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_GPIO5_U, FUNC_GPIO5); gpio_output_set(0, 0, 0, BIT5); // Set GPIO5 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_MTDI_U, FUNC_GPIO12); gpio_output_set(0, 0, 0, BIT1); // Set GPIO13 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_MTMS_U, FUNC_GPIO14); gpio_output_set(0, 0, 0, BIT14); // Set GPIO14 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_MTCK_U, FUNC_GPIO13); // Set GPIO13 function gpio_output_set(0, 0, 0, BIT13); // Set GPIO13 as input PIN_FUNC_SELECT(PERIPHS_IO_MUX_MTDO_U, FUNC_GPIO15); gpio_output_set(0, 0, 0, BIT15); // Set GPIO15 as input ets_uart_printf("...init done!\r\n"); } void ICACHE_FLASH_ATTR sendFramMark(void){ sendByte(42); sendByte(42); } void ICACHE_FLASH_ATTR sendCtr3Byte(uint8_t typ,uint16_t len){ uint8_t lLen,hLen; sendByte(typ); lLen=len&amp;0xFF; hLen=(len&amp;(0xFF&lt;&lt;8))&gt;&gt;8; sendByte(lLen); sendByte(hLen); }</span></span></span></span></code> </pre><br></div></div><br><h2>  Image processing </h2><br>  Image processing consists in progressive binarization, combining the obtained segments, analyzing and synthesizing the obtained figures.  The purpose of processing is the formation of integral features, including the properties of the areas included in the figures.  Despite the simplicity of the main idea, its implementation contains a number of specific points that cannot be disclosed within the framework of this article. <br><br><h2>  Visualization of the recognition process </h2><br>  To debug the recognition process, we used the visualization on the PC of the original image, binarized, and the image that the microcontroller ‚Äúsees‚Äù or ‚Äúunderstands‚Äù.  Despite the fact that the latter is not very pleased with our eyes, its details are enough to recognize the characters.  The figure shows examples of visualization. <br><br><img src="https://habrastorage.org/web/458/709/d8f/458709d8f67c4bb2b2528985e8f7f3c5.jpg"><img src="https://habrastorage.org/web/1ff/c29/fbb/1ffc29fbb48647468cdd1f164d56eec1.jpg"><br><br><img src="https://habrastorage.org/web/d18/c54/973/d18c549736344afcb3b8e26adf686e8b.jpg"><img src="https://habrastorage.org/web/ed0/136/824/ed01368241634db08822959917e4fcd0.jpg"><br><br>  It should be noted that sometimes, due to camera synchronization errors, there are situations when lines with color-difference rather than brightness bytes appear in the original picture.  In this case, the picture is blurred and recognition does not occur.  The task of handling such situations at this stage was not set <br><br><img src="https://habrastorage.org/web/327/983/807/327983807370452fa02df894249a40b9.jpg"><br><br>  Also, recognition does not occur if the text is incorrectly positioned: <br><br><img src="https://habrastorage.org/web/348/d27/caa/348d27caa0f54fb1a7f372d3f01d5f38.jpg"><br><br>  For visualization, a small program written in Java Script using nodeWebkit was used. <br><br><div class="spoiler">  <b class="spoiler_title">app.js</b> <div class="spoiler_text">  * to work with the COM port, you need to assemble the nodeJS "serialport" module under nodewebkit <br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> btn = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'com'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> gui = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">"nw.gui"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> select_com = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'select_com'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bdr = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'bdr'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> canvas = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'canvas'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> dev = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'dev'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> ctx = canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> width = <span class="hljs-number"><span class="hljs-number">320</span></span>, height = <span class="hljs-number"><span class="hljs-number">240</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> byteCount = (width * height)/<span class="hljs-number"><span class="hljs-number">3</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> lastStr=byteCount-width; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> dataArr; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> dataStr; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> indArr = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> dataArrLen = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> byteCounter = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> newStr = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sendTyp=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.addEventListener(<span class="hljs-string"><span class="hljs-string">'DOMContentLoaded'</span></span>, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ btn.addEventListener(<span class="hljs-string"><span class="hljs-string">'click'</span></span>, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ connectCom(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">vector</span></span></span><span class="hljs-function">) </span></span>{ drawImg(vector); }); }); dev.addEventListener(<span class="hljs-string"><span class="hljs-string">'click'</span></span>, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> win = gui.Window.get(); win.showDevTools(); }); }); <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">drawImg</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">imgArr</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> imgData = ctx.createImageData(width, height); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> ind; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; imgArr.length; i++) { imgData.data[<span class="hljs-number"><span class="hljs-number">4</span></span> * i] = imgArr[i]; imgData.data[<span class="hljs-number"><span class="hljs-number">4</span></span> * i + <span class="hljs-number"><span class="hljs-number">1</span></span>] = imgArr[i]; imgData.data[<span class="hljs-number"><span class="hljs-number">4</span></span> * i + <span class="hljs-number"><span class="hljs-number">2</span></span>] = imgArr[i]; imgData.data[<span class="hljs-number"><span class="hljs-number">4</span></span> * i + <span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">255</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(i&lt;byteCount&amp;&amp;i&gt;lastStr){ <span class="hljs-comment"><span class="hljs-comment">//red line imgData.data[4 * i] = 255; imgData.data[4 * i + 1] = 0; imgData.data[4 * i + 2] = 0; imgData.data[4 * i + 3] = 255; } if(i&lt;2*byteCount&amp;&amp;i&gt;byteCount+lastStr){ //green line imgData.data[4 * i] = 0; imgData.data[4 * i + 1] = 255; imgData.data[4 * i + 2] = 0; imgData.data[4 * i + 3] = 255; } if(i&lt;3*byteCount&amp;&amp;i&gt;2*byteCount+lastStr){ //blue line imgData.data[4 * i] = 0; imgData.data[4 * i + 1] = 0; imgData.data[4 * i + 2] = 255; imgData.data[4 * i + 3] = 255; } } ctx.putImageData(imgData, 0, 0); imgArr.length=0; } function connectCom(callback) { const PIXTYPE=0,BINTYPE=1,FIGTYPE=2; var imgTyp=PIXTYPE; var serialport = require('serialport'); var imgArr = []; var framCount=0,strNum,colNum; var pix=false; var comm = 'COM' + select_com.value; var boudrate = +bdr.value; var SerialPort = serialport.SerialPort; var port = new SerialPort(comm, { baudRate: boudrate, dataBits: 8, stopBits: 1, parity: "none", bufferSize: 65536, parser: SerialPort.parsers.byteLength(1) }); port.on('open', function() { console.log('Port ' + comm + ' Open'); }); port.on('data', function(data) { if(imgTyp==PIXTYPE||imgTyp==BINTYPE){ if (data[0] == 42 &amp;&amp; newStr == 0) { newStr = 1; data[0]=255; } if (newStr == 1 &amp;&amp; data[0] == 42) { newStr = 2; } if (newStr == 2 &amp;&amp; byteCounter &lt;2*byteCount) { colNum=byteCounter%width; strNum=(byteCounter-colNum)/width; if(strNum%2==0){ imgArr[(strNum/2)*width+colNum]=data[0]; } if(strNum%2==1){ imgArr[((strNum-1)/2)*width+byteCount+colNum]=data[0]; } byteCounter++; } if (newStr == 2 &amp;&amp; byteCounter == 2*byteCount) { newStr = 0; byteCounter = 0; framCount++; console.log('Frame Num ', framCount); imgTyp=FIGTYPE; } } if(imgTyp==FIGTYPE){ if (data[0] == 42 &amp;&amp; newStr == 0) { newStr = 1; data[0]=255; } if (newStr == 1 &amp;&amp; data[0] == 42) { newStr = 2; } if (newStr == 2 &amp;&amp; byteCounter &lt; byteCount) { imgArr[byteCounter+2*byteCount] = data[0]; byteCounter++; } if (newStr == 2 &amp;&amp; byteCounter == byteCount) { newStr = 0; byteCounter = 0; framCount++; console.log('Frame Num ', framCount); imgTyp=PIXTYPE; callback(imgArr); } } }); port.on('error', function() { alert('    '); }); }</span></span></code> </pre><br></div></div><br>  An example of the operation of the device is shown in a short video. <br><br><div class="spoiler">  <b class="spoiler_title">Video with prototype number 1</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/DxphYFW3jyQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Video with prototype number 2</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/PaMtYAc_aws" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></div></div><br><h2>  Conclusion </h2><br>  The obtained results show the high efficiency of the recognition method on devices that would seem completely unsuitable for this.  A slight improvement in the method associated with the use of information from several frames for additional ‚Äúpeering into‚Äù the areas of interest will allow raising the quality of recognition to the level of commercial products. <br><br>  The approach to analyzing and recognizing multi-attribute objects, such as handwriting strings or hieroglyphs, is also understandable, but this requires devices with more memory than our esp (512K, program size is more than 250K). <br>  Thanks for attention. <br><br>  References: <br><br>  1. <a href="https://habrahabr.ru/company/abbyy/blog/228251/">Text recognition in ABBYY FineReader (2/2)</a> <br>  2. <a href="https://geektimes.ru/company/dadget/blog/279418/">Omega2: the world's smallest microcomputer with Linux and Wi-Fi</a> <br>  3. <a href="https://geektimes.ru/post/289759/">Orange Pi 2G-IoT - the perfect single board for IoT</a> <br>  4. <a href="https://geektimes.ru/post/279886/">Recognition of numbers on the microcontroller</a> <br>  5. <a href="">Sketch Arduino to work with the camera OV7670</a> <br>  6. <a href="https://www.voti.nl/docs/OV7670.pdf">Datasheet camera OV7670</a> <br>  7. <a href="https://habrahabr.ru/post/302226/">Reflection of dynamics in the access control model</a> </div><p>Source: <a href="https://habr.com/ru/post/330936/">https://habr.com/ru/post/330936/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../330926/index.html">Startup of the day (May 2017)</a></li>
<li><a href="../330928/index.html">IT Management: What ITSM is and the ServiceNow Platform</a></li>
<li><a href="../330930/index.html">It is a little about ServiceNow, ITSM and ServiceDesk in a format of selection of useful materials</a></li>
<li><a href="../330932/index.html">40 unusual questions asked at the interview at Apple</a></li>
<li><a href="../330934/index.html">And terrible Russian firewall will burst</a></li>
<li><a href="../330938/index.html">Java: automatically generate SQL queries</a></li>
<li><a href="../330940/index.html">We compile, as if in the yard 1992</a></li>
<li><a href="../330942/index.html">The story of how cognitive technologies help preserve karma</a></li>
<li><a href="../330944/index.html">[Administrator's abstract] Domains, addresses and Windows: mix, but do not shake</a></li>
<li><a href="../330946/index.html">‚ÄúWhen a critical crash occurs with databases, it always happens somewhat epically‚Äù - Ilya Kosmodemyansky</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>