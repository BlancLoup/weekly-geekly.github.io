<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The task of changing the voice. Part 3. Applied speech signal models: LPC</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We continue the cycle of articles devoted to the task of changing the human voice, on the solution of which we work in the company i-Free . In the pre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The task of changing the voice. Part 3. Applied speech signal models: LPC</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/83b/064/134/83b0641344786240604938e4101e8df2.png" alt="image" align="right"><br><br>  We continue the cycle of articles devoted to the task of changing the human voice, on the solution of which we work in the company <a href="http://habrahabr.ru/company/ifree/">i-Free</a> .  In the <a href="http://habrahabr.ru/company/ifree/blog/210646/">previous article</a> I tried to briefly describe the mathematical apparatus used to describe complex physical processes occurring in a person‚Äôs vocal tract when pronouncing sounds.  Issues related to the modeling of the acoustics of the vocal tract were raised.  Admissible simplifications and approximations were described.  The result of the article was the reduction of the physical model of sound propagation in the speech path to a simple discrete filter. <br><br>  In this article, on the one hand, it would be desirable to continue the previous undertakings, and on the other, to move away a bit from the fundamental theory and talk about more practical (more ‚Äúengineering‚Äù) things.  One of the applied models that is often used when working with a speech signal will be briefly considered.  The mathematical basis of this approach, as is often the case, was originally laid as part of a completely different research.  Nevertheless, the physical features of the speech signal made it possible to apply these ideas precisely for its effective analysis and modification. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The previous article, due to the specifics of the issue under consideration, was oversaturated with scientific terms and formulas.  In this one, we will try, instead of a detailed description of mathematical constructions, to focus on the ideological concept and the qualitative characteristics of the model being described. <br><br>  The theory of the LPC (Linear Prediction Coding) model will be discussed in more detail - a remarkable slender approach to describing the speech signal, which in the past determined the direction of speech technology development for several decades and is still often used as one of the basic tools for analyzing and describing the speech signal . <br><br><a name="habracut"></a><br><br><h4>  Simplified discrete speech model </h4><br>  In this <a href="http://habrahabr.ru/company/ifree/blog/210646/">section</a> , we will make the transition from the discrete model of the vocal tract from the <a href="http://habrahabr.ru/company/ifree/blog/210646/">previous article</a> (that model described only the propagation of sound in pipes with a constant cross-sectional area), to a more complete model describing the entire articulation process.  The basic idea of ‚Äã‚Äãthe model is formulated quite simply - let us imagine that the discrete signal y (n) * analyzed by us is the output of a <a href="http://en.wikipedia.org/wiki/Digital_filter">linear digital filter</a> a ** h, through which a certain ‚Äúexciting‚Äù signal x (n) passes: <br>  _____________________________ <br>  * - hereinafter we will talk only about discrete signals and the time variable t will be replaced with a discrete reference index n <br>  ** - we immediately apologize for some references to English-language sources, but often they contain the required question more fully and in one place, we hope the language barrier will not be a big obstacle. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e91/f3d/747/e91f3d7476c0b33550ae8f61a5ee5477.jpg"><br><br>  It is logical to assume that by changing the filter coefficients h_k, and, perhaps, in some cases, the ‚Äúexciting‚Äù signal itself, you can achieve a different sound of the output sound *.  In words, everything is quite simple, but now we will try to figure out what relation this completely abstract generalized idea may have to a speech signal. <br>  _____________________________ <br>  * - as in the previous article, the symbol "_" we will denote the indexing operation, and the symbol "^" - the operation of raising to a power. <br><br>  We briefly recall, but at the same time we summarize a little of what was told in the <a href="http://habrahabr.ru/company/ifree/blog/203946/">very first article</a> .  The formation of speech sounds can, with some reservations, be described as follows: <br><br>  1) the glottis in the larynx is a ‚Äúbasic‚Äù sound source (here, with the participation of the vocal cords, the same vocalized or unvoiced excitation signal from Section 1 is generated) <br><br>  2) the organs of the vocal tract above the larynx are one complex acoustic filter that strengthens one and weakens other frequencies <br><br>  3) ‚Äúthe final touch‚Äù to the final sound adds the process of emission of sound waves by mouth or nose <br><br>  The last point can be neglected to some extent, since  This transformation above the signal can be approximated by differentiation and, accordingly, it is relatively easy to reverse its effect on the signal.  With the first two the story is somewhat more complicated.  Both process data are not stationary in time.  When generating a voiced excitation signal, the period of closure and the degree of closure of the folds of the glottis in the larynx continuously change, which causes a change in the duration and in the form of "guttural" air pulses: as a result, the intonation and sound intensity, emotional color of speech changes.  The speech path above the larynx is one large moving acoustic filter; its chambers and connections, changing their geometry, change the position of the resonant (formant) and antiresonant frequencies ‚Äî the type of pronounced vocalized sound changes in terms of phonetics.  When pronouncing unvoiced sound, vocal folds do not work, and the larynx is the source of the noise signal.  The work of the rest of the vocal tract does not fundamentally change and, as a result, the spectrum of noisy speech sounds also has a formant structure, albeit somewhat less ‚Äúnoticeable.‚Äù  The above can be illustrated by the following simplified scheme: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f82/d35/bd0/f82d35bd05f8330622944b38abd6e6a2.jpg"><br><br>  Corresponding elements from the 1st figure are indicated in gray font at the top. <br><br>  In real life, there are a lot of nuances and mechanisms of the mutual influence of the vocal tract on the larynx and vice versa, as well as the breathing apparatus on the entire acoustics of the vocal tract at the moment when the speech gap is open.  However, considering several ‚Äúidealized‚Äù processes, we can say that this picture adapts the previous abstract idea ‚Äúexcitation signal - filter - sound‚Äù to the articulation of speech sounds and at the same time takes into account the basic properties of a real speech signal quite well. <br><br>  The advantages of this look at the process of sound formation: <br><br>  - the ability to consider the signal of excitation of the vocal tract and its further distribution along the vocal tract independently of each other (in fact, they are nevertheless interconnected, however, this interrelation is not always clearly expressed and in some cases it can be neglected) <br><br>  - the ability to analyze the vocal tract as a linear stationary (at short time intervals) system <br><br>  - the ability to well approximate most of the sounds in the speech signal <br><br>  Of course, as is always the case in real life, this simplified approach is not so simple for practical use.  Many uncertainties arise even at the stage of splitting the analyzed signal into voiced / unvoiced segments.  Only for this task, in general, is it necessary to carry out a complex signal processing involving a serious mate.  apparatus.  The next difficult point is the nonstationarity of the processes under consideration, and in this case x (n) changes much more rapidly than h (n).  To obtain reliable estimates of the parameters of this model, the most optimal is signal processing on time segments, the duration of which is a multiple of the pitch period, which is not easy, given that this period is constantly changing.  It is also worth mentioning the limited applicability of this model for describing some consonant sounds, in particular fricative and ‚Äúexplosive‚Äù ones.  When pronouncing a ringing fricative sound, the voiced excitation signal passes through a significant contraction in one or another part of the vocal tract, which leads to the formation of strong turbulent noise.  A deaf fricative is pronounced similarly, with the difference that the exciting signal is initially noisy.  Thus, the noise component of fricative sounds is largely formed already in the vocal tract, and not only in the larynx, which is not taken into account by this model.  ‚ÄúExplosive‚Äù sounds are a special case, the consideration of which we have so far omitted. <br><br>  We now turn from a generalized discrete model to concrete applied models, which allow one to estimate certain parameters of a speech signal. <br><br><h4>  Linear Prediction Coefficients (Linear Prediction Coding Coefficients or simply LPC) </h4><br>  The LPC method is a simple approach to the generalized discrete model of a speech signal described above.  Namely, the LPC coefficients directly describe the V speech path (see the previous figure).  This description is of course not exhaustive and is a kind of approximation of a real speaker system.  However, as claimed by the theory, and as many times proved by practice (take at least the <a href="http://en.wikipedia.org/wiki/Code-excited_linear_prediction">CELP</a> algorithms used in modern cellular networks), this approximation is quite sufficient for many, many cases.  The white spot in the LPC model is the signal of the excitation of the vocal tract, which in practice either does not change significantly, or, for example, is replaced with some previously calculated one, as in CELP. <br><br>  We describe in more formal terms exactly what place the LPC coefficients occupy in the system under consideration.  The signal at the input of the vocal tract (at the exit of the glottis) will be referred to as g [n].  For now, let's not focus on the nature of this signal - noise or harmonic.  The signal at the output of the discrete filter, which we approximate the speech path will be denoted by v [n].  The LPC model thus solves the inverse problem - we will look for g [n], as well as the filter parameters that turned g [n] into v [n], having only v [n] at our disposal. <br><br>  Let us recall the previous article, and the idea described in it of representing the vocal tract by a series of connected pipes.  The main result of this approach is a convenient representation of the speech path in the form of a discrete filter (a system consisting of addition / multiplication / delay operations).  With the help of algebraic transformations, it is possible to derive from the difference equations describing a similar model, its transfer characteristic of the form: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/11a/eb7/cc6/11aeb7cc6589824291a479215b2fded1.jpg"><br><br>  where G is some complex polynomial depending on the reflection coefficients r_k, a_k are some real coefficients also dependent on r_k, P is the number of pipes in the model under consideration.  Since we consider the signal at short time intervals, it is fair to assume the ‚Äúimmobility‚Äù of the vocal tract during the analysis, and, accordingly, the constant values ‚Äã‚Äãof the areas of articulated tubes with which we approximate the vocal tract (see the previous article).  On this basis, we consider the reflection coefficients r_k to be constant, which, in particular, leads to a constant value of the polynomials G and a_k on the analyzed speech segment. <br><br>  The algebra of reduction of difference equations describing the state of each pipe as part of the vocal tract (see <a href="http://habrahabr.ru/company/ifree/blog/210646/">previous article</a> ) will not be reduced to this simple-looking equation for obvious reasons.  The equation itself is an important fundamental result - <i><b>when considering the vocal tract as a system of articulated pipes, it is possible to bring it to the form of a linear stationary system (LTS), namely, an <a href="http://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B8%25D0%25BB%25D1%258C%25D1%2582%25D1%2580_%25D1%2581_%25D0%25B1%25D0%25B5%25D1%2581%25D0%25BA%25D0%25BE%25D0%25BD%25D0%25B5%25D1%2587%25D0%25BD%25D0%25BE%25D0%25B9_%25D0%25B8%25D0%25BC%25D0%25BF%25D1%2583%25D0%25BB%25D1%258C%25D1%2581%25D0%25BD%25D0%25BE%25D0%25B9_%25D1%2585%25D0%25B0%25D1%2580%25D0%25B0%25D0%25BA%25D1%2582%25D0%25B5%25D1%2580%25D0%25B8%25D1%2581%25D1%2582%25D0%25B8%25D0%25BA%25D0%25BE%25D0%25B9">IIR</a> filter containing only poles</b></i> (looking ahead to say that these poles and correspond to the so-beloved "formant" frequencies).  The scheme of work of such a system is shown below: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/abb/639/7c7/abb6397c7b955ace749a94e22ad5106b.jpg"><br><br>  Using the above transfer characteristic of the vocal tract, it can be shown that the signal at the output of the system has the following form in the time domain: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/967/d7e/21e/967d7e21eb876b270dfa10a3811ef140.jpg"><br><br>  A very interesting result: a complex sound formation process in the vocal tract is reduced to the fact that the signal at the system output at time n is a superposition of the input signal at time n, multiplied by a constant, and a linear combination of the previous output samples at times n - 1, n - 2 ... n - p.  But let's not forget that of course this is just an approximation, ignoring many details. <br><br>  To get a description of the state of the speech path on the analyzed segment of speech, it is necessary to solve the problem of estimating the coefficients a_k and G. The theory of adaptive filtering as a whole, and the LPC model in particular, allow solving this problem relatively simply and computationally efficiently.  The resulting description of the vocal tract will be far from exhaustive, but sufficient for many tasks. <br><br><h4>  Finding LPC Ratios </h4><br>  To solve the problem of estimating the coefficients a_k, it is convenient to introduce the concept of a linear prediction filter, the task of which is to obtain reliable estimates of the desired coefficients (we will further denote the estimates as a'_k).  The output of the prediction filter (v '(n)) can be subtracted from the signal at the output of the vocal tract (the resulting difference will be called ‚Äúsignal-error‚Äù): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/754/77c/6b1/75477c6b1348e2e408f5a1bae3ef774c.jpg"><br><br>  e (n) is a signal-error.  The coefficients a'_k, along with G, are called linear prediction coefficients, LPC coefficients.  In the case when the estimates a'_k are close to the true values ‚Äã‚Äãof a_k, e (n) will tend to G ‚àô g (n).  Note that the linear prediction filter in this problem is the inverse filter to our approximation of the vocal tract.  If the estimates a'_k are close to true a_k, then this filter (denoted as v ^ (- 1) _k) is able to reverse the effect of the speech path on the signal g (n) up to a constant G: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/46f/af1/ccd/46faf1ccd946ac6b2cfdfb196f871ba7.jpg"><br><br>  Let us return to the estimates a'_k.  Choosing a certain segment of the signal for analysis (suppose length M), using the expression (3), we can obtain the error signal vector of a similar length.  The question is - how now, having this vector, form well-founded estimates a'_k?  This problem can be solved using the <a href="http://en.wikipedia.org/wiki/Least_squares">method of least squares</a> .  To do this, we search for the minimum of the function E_n, the value of which is equal to the average of the sum of the squares of the error signal values ‚Äã‚Äãon some analyzed time interval (the function E_n is nothing other than the <a href="http://en.wikipedia.org/wiki/Mean_squared_error">rms error</a> ).  In other words, the parameters a'_k are sought for which the root-mean-square error function E_n takes the minimum value.  The standard error in our case is expressed by the formula: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/860/d73/0ba/860d730ba896d7a21015a11197859eea.jpg"><br><br>  Finding the mean implies a division by the number of elements (multiplication by 1 / M), however, this factor will not affect the solution of the desired system, so it can be omitted. <br><br>  <i>Once again, for clarity, we describe what formula (4) expresses:</i> <i><br><br></i>  <i>1) in the vicinity of the time point 'n', M samples of the signal are taken (usually from n to n + M - 1). The number M depends on the sampling rate of the signal and our assumptions about the stationarity interval of this signal.</i> <i><br><br></i>  <i>2) For the selected samples, an expression is compiled corresponding to the prediction error e (m), m = n: n + M-1</i> <i><br><br></i>  <i>3) The average of the squares e (m) is found (in the expression for the average, we omit the division by the number of terms of the sum).</i> <i><br><br></i>  <i>4) We will minimize the average E_n (which is a function of the reference number n).</i> <br><br>  Why is the standard error used as a measure of the reliability of our prediction filter?  Firstly, it is a good numerical approximation of the variance of a random process in some cases.  If we assume that our error is distributed normally and our prediction filter is not very biased, then the root-mean-square error will tend to the dispersion D [e (m)] and we, therefore, look for the minimum dispersion of our error signal.  Secondly (although this is probably not the cause, but a convenient consequence), it is very convenient to differentiate this function by the desired a'_k, and it is convenient to find the minimum of the function using differentiation. <br><br>  Expanding the square sign under the sum in (4) and equating to zero the values ‚Äã‚Äãof the derivatives of E_n for each a'_k, it is possible to obtain a system of P linear equations of the form: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6c1/143/b36/6c1143b368bc8bfe398fff49f2a3390d.jpg"><br><br>  We will not also give a detailed conclusion (5) from (4) - for this we need to apply several formulas from school algebra and some formulas for converting <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2583%25D0%25BC%25D0%25BC%25D0%25B0_%2528%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B5%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0%2529">certain amounts</a> .  The system of equations (5) is the ‚Äúcore‚Äù in the LPC algorithm.  The index i corresponds to the number of the equation in the system (the number a'_k, which took the derivative) and, like the index k, passes all values ‚Äã‚Äãfrom 1 to P. Recall that P corresponds to the number of pipes in the model that approximates the voice path.  The same number is called the linear prediction order.  The solution of systems of linear algebraic equations is a separate applied area with its mathematical apparatus, therefore we will not go deeper into this task.  We only say that for solving the system (5) specifically, taking into account its properties, as a rule, <a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D0%25B7%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A5%25D0%25BE%25D0%25BB%25D0%25B5%25D1%2586%25D0%25BA%25D0%25BE%25D0%25B3%25D0%25BE">Cholesky decomposition</a> or <a href="http://en.wikipedia.org/wiki/Levinson_recursion">Levinson-Durbin recursion is used.</a> <br><br>  Having solved the system of P equations from P unknowns, we get the estimates a'_k, and it remains only to find the gain factor G. In the LPC method, the estimate of G is found after the estimate of a'_k, assuming that the signal at the input of the filter V is either offset in time n is a discrete <a href="http://en.wikipedia.org/wiki/Dirac_delta_function">delta function</a> (single impulse at time n), or white noise.  In both cases, G can be found from the relationship: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/52f/a8c/b39/52fa8cb39ef0175ce2db2e3378328496.jpg"><br><br>  The very derivation of this formula is purely mathematical (that in the case of the delta function, that in the case of white noise) and how to explain the physical meaning of this formula popularly, the author of the article does not represent - let‚Äôs leave it as it is.  However, the very assumption that the input signal suddenly became a single impulse or white noise should be explained in more detail. <br><br>  Strictly speaking, at the exit of the glottis in the larynx - at the input of the vocal tract, we have either a ‚Äúlaryngeal‚Äù impulse, or a colored noise signal, but not the delta function or white noise.  And here, in the theory of LPC, a very tricky ‚Äúfeint with ears‚Äù is made.  We imagined the larynx as part of the vocal tract and say that it was precisely the larynx that allegedly included either a single impulse or white noise.  Thus, the concept of the vocal tract is somewhat broadened within our model, and in order to take into account the new model effects that make a ‚Äúlaryngeal‚Äù impulse from a single impulse, and colored noise from white noise, we increase the linear prediction order P. Moreover, we go further and include in our ‚ÄúLPC-filter‚Äù effects associated with signal emission, which we also compensate by adding additional coefficients.  These operations correspond to an increase in the length of our pole filter, with which we approximate the speech path, which will lead to an increase in the number of its poles, and it is these additional poles that are responsible for the imaginary transformation mentioned above.  Obviously, in this case, the LPC model no longer fully corresponds to the initial discrete filter that approximates the speech path.  However, ideologically, these two approaches remain very close, if not to say ‚Äúrelated‚Äù.  Using the LPC, it is impossible to reconstruct the g [n] excitation signal of the vocal tract as we would like at the beginning.  Nevertheless, the final approximation of the frequency response of the vocal tract (coefficients a'_k), obtained using LPC, is sufficiently accurate for many problems. <br><br>  Once we talked about choosing the order P, it is logical to give some general recommendations on his choice.  It is believed that, on average, formant frequencies in a speech signal are located with a density of approximately 1 formant per kilohertz.  Then, since each complex pole of our model filter corresponds to one formant frequency, it is convenient to choose an order like: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/050/ba0/17d/050ba017d922dcf83092cf3642364a8f.jpg"><br><br>  where [] is the rounding to the nearest integer, Fs is the sampling rate of the signal in hertz.  To compensate for the effect of combining the larynx and the vocal tract, as well as to take into account the effect of the radiation of the signal by the lips / nose in the model, various sources recommend increasing P by an additional 2‚Äì4 coefficients.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">That is, for operation, for example, with a 10 KHz signal, the order P can be chosen equal to 12-14 coefficients. </font><font style="vertical-align: inherit;">Some authors also advise to use the density of "1 formant at 1200-1300 Hz" when analyzing a female voice. </font><font style="vertical-align: inherit;">This is due to the shorter length of the vocal tract in women and, as a consequence, the higher formant frequencies in female voices.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> LPC summary </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What ultimately gives us the calculation of the LPC coefficients for a certain signal: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1) The output of the LPC calculation algorithm is a set of numerical coefficients that describe the pole filter. These coefficients in their pure form allow us to obtain an expression for the output of a given filter in the time domain (expression (2)), as well as a general view of its z-characteristics (expression (1)). Since this filter is polar, it is based on recursion and it is not possible to express the impulse response for such a filter. Using the z-characteristics, however, a full analysis of the resulting filter is possible in both the time and frequency domains.</font></font><br><br> 2)       z-,      ,    .             . (  ,          LPC ‚Äî  P,    M,    n.         .) <br><br> 3)    LPC - (   ,     )      ,      -. (       ) <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Below, for example, is the logarithmic spectrum of a signal obtained by a conventional FFT and using LPC. </font><font style="vertical-align: inherit;">Processed vowel "A", pronounced in a male voice. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/46c/505/ed9/46c505ed9d55c0e14adabf33229bc109.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As you can see, the ‚ÄúLPC spectrum‚Äù is some smoothed version of the usual ‚ÄúFFT spectrum‚Äù. </font><font style="vertical-align: inherit;">At the same time, formant frequencies appear as ‚Äúbright‚Äù local maxima, which is a good ‚Äústart‚Äù for their detection and tracking.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> LPC application for speech path analysis </font></font></h4><br>      ,             ,         ,    .         r_k,  k ‚Äì   .                 .   (       )    ,     ,           .        ,      ,   ,    (1),       LPC-. <br><br>  - LPC- ‚Äì  ¬´¬ª   .    ,   ,  LPC-  , -     ?       100%  .   , LPC-    r_k,       ‚Äì  r_k  a'_k.         PARCOR (partial correlation) . . .  LPC-  PARCOR-,     r_k.     :   LPC  ,            ,               (            P).  ,  -        ,   LPC-   ,           LPC.    ,     ,              ‚Äî     ,      . . .     ,    ,        . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are many works whose authors solve the problem of restoring the function of the area of ‚Äã‚Äãthe vocal tract, and in these works the LPC coefficients take not the last place in the mathematical tools used. In particular, LPC is often used as a basic method for determining the values ‚Äã‚Äãof formant frequencies, with the help of which the function of the vocal tract area is already restored.</font></font><br><br>            LPC   ,   ,    ,          ‚Äî        .       ,   ,               ,    LPC,    -   . <br><br><h4>  findings </h4><br>          LPC-   .             ,     ,       .       : <br><br> ‚Äî   <br><br> ‚Äî    <br><br> ‚Äî    (   ) <br><br>       HPN- (Harmonics-plus-noise)  ,              . <br><br>  : <br> <i>[1] JL Flanagan. Speech Analysis, Synthesis and Perception. <br> [2] LR Rabiner, RW Schafer, Digital Processing of Speech Signals // <b>(   )</b> <br> [3]  ..    , 2-  // <b>( ,   ¬´¬ª ,     )</b> <br> [4] Mark Hasegawa-Johnson, Lecture Notes in Speech Production, Speech Coding, and Speech Recognition <br> [5] G. Fant. Speech Acoustics and Phonetics. Selected Writings</i> . </div><p>Source: <a href="https://habr.com/ru/post/222173/">https://habr.com/ru/post/222173/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../222159/index.html">Ëû¢ÁÅ´Ëü≤ (Firefly): You can't take the sky from me</a></li>
<li><a href="../222161/index.html">Remote work: how we do it</a></li>
<li><a href="../222165/index.html">The standoff of Apple and Google in the gaming application sector</a></li>
<li><a href="../222167/index.html">Firefox Developer Tools Update</a></li>
<li><a href="../222169/index.html">Measurement Protocol - just about simple</a></li>
<li><a href="../222183/index.html">Bacteria from Earth are able to colonize Mars</a></li>
<li><a href="../222187/index.html">PocketBook Reader - we read on phones comfortably</a></li>
<li><a href="../222189/index.html">We start the Weekend contest ‚ÄúI want to DevConf 2014!‚Äù With the draw of free passes on the main day of DevConf 2014</a></li>
<li><a href="../222191/index.html">Testing Web UI with Vika in pleasure or Virtual Intellect in testing</a></li>
<li><a href="../222193/index.html">Idea, team, technology, money, methodology - what really depends on the success of the project?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>