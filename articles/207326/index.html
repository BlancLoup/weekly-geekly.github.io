<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Amazon SQS Testing</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The network already has several performance reviews of this solution from Amazon, in this article I did not pursue the goal of verifying the results a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Amazon SQS Testing</h1><div class="post__text post__text-html js-mediator-article">  The network already has several performance reviews of this solution from Amazon, in this article I did not pursue the goal of verifying the results already obtained, I was interested in some features not covered in other sources, namely: <br><ol><li>  the documentation says that Amazon is trying to preserve the order of messages, how well is it stored? </li><li>  How fast does a message get when using Long Polling? </li><li>  How much does batch processing speed up? </li></ol><br><br><a name="habracut"></a><br><br><h4>  Formulation of the problem </h4><br>  The most supported library for AWS on erlang is erlcloud [1], to initialize the library, just call the start and configure methods, as indicated on github.  My messages will contain a set of random characters generated by the following function: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre><code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">random_string</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> -&gt;</span></span> []; random_string(Length) -&gt; [random_char() | random_string(Length-<span class="hljs-number"><span class="hljs-number">1</span></span>)]. random_char() -&gt; random:uniform(<span class="hljs-number"><span class="hljs-number">95</span></span>) + <span class="hljs-number"><span class="hljs-number">31</span></span> .</code> </pre> <br><br>  To measure the speed, we use a known function that uses timer: tc, but with some changes: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test_avg</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(M, F, A, R, N)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">when</span></span></span><span class="hljs-function"> N &gt; 0 -&gt;</span></span> {Ret, L} = test_loop(M, F, A, R, N, []), Length = length(L), Min = lists:min(L), Max = lists:max(L), Med = lists:nth(round((Length / <span class="hljs-number"><span class="hljs-number">2</span></span>)), lists:sort(L)), Avg = round(lists:foldl(<span class="hljs-keyword"><span class="hljs-keyword">fun</span></span>(X, Sum) -&gt; X + Sum <span class="hljs-keyword"><span class="hljs-keyword">end</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, L) / Length), io:format(<span class="hljs-string"><span class="hljs-string">"Range: ~b - ~b mics~n"</span></span> <span class="hljs-string"><span class="hljs-string">"Median: ~b mics~n"</span></span> <span class="hljs-string"><span class="hljs-string">"Average: ~b mics~n"</span></span>, [Min, Max, Med, Avg]), Ret. test_loop(_M, _F, _A, R, <span class="hljs-number"><span class="hljs-number">0</span></span>, List) -&gt; {R, List}; test_loop(M, F, A, R, N, List) -&gt; {T, Result} = timer:tc(M, F, [R|A]), test_loop(M, F, A, Result, N - <span class="hljs-number"><span class="hljs-number">1</span></span>, [T|List]).</code> </pre><br><br>  The changes relate to the call of the function being tested. In this variant, I added the R argument, which allows using the value returned on the previous run, this is necessary in order to generate message numbers and collect additional information regarding mixing when receiving the message.  Thus, the function of sending a message with a number will look like this: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send_random</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(N, Queue)</span></span></span><span class="hljs-function"> -&gt;</span></span> erlcloud_sqs:send_message(Queue, [N + <span class="hljs-number"><span class="hljs-number">1</span></span> | random_string(<span class="hljs-number"><span class="hljs-number">6000</span></span> + random:uniform(<span class="hljs-number"><span class="hljs-number">6000</span></span>))]), N + <span class="hljs-number"><span class="hljs-number">1</span></span> .</code> </pre><br><br>  And her call with the collection of statistics: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test_avg</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(?MODULE, send_random, [QueueName], </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">31</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">20</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span></code> </pre><br><br>  here 31 is the number of the first message, the number is not randomly chosen, the fact is that erlang does not distinguish too well the sequence of numbers and strings and in the message it will be symbol number 31, smaller numbers can be sent to SQS, but continuous ranges are obtained in this case small (# x9 | #xA | #xD | [# x20 to # xD7FF] | [# xE000 to #xFFFD] | [# x10000 to # x10FFFF], in more detail [2]) and when leaving the allowable range you will get an exception.  Thus, the send_random function generates and sends a message to a queue with the name Queue, at the beginning of which there is a number defining its number, the function returns the number of the next number, which is used further by the next generation function.  The test_avg function accepts QueueName, which becomes the second argument of the send_random function, the first argument is the number and the number of repetitions. <br><br>  The function that will receive messages and check their order will look like this: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">checkorder</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(N, [])</span></span></span><span class="hljs-function"> -&gt;</span></span> N; checkorder(N, [H | T]) -&gt; [{body, [M | _]}|_] = H, K = <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> M &gt; N -&gt; M; <span class="hljs-literal"><span class="hljs-literal">true</span></span> -&gt; io:format(<span class="hljs-string"><span class="hljs-string">"Wrong ~b less than ~b~n"</span></span>, [M, N]), N <span class="hljs-keyword"><span class="hljs-keyword">end</span></span>, checkorder(K, T). receive_checkorder(LastN, Queue) -&gt; [{messages, List} | _] = erlcloud_sqs:receive_message(Queue), remove_list(Queue, List), checkorder(LastN, List).</code> </pre><br><br>  Deleting messages: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">remove_msg</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(_, [])</span></span></span><span class="hljs-function"> -&gt;</span></span> wrong; remove_msg(Q, [{receipt_handle, Handle} | _]) -&gt; erlcloud_sqs:delete_message(Q, Handle); remove_msg(Q, [_ | T]) -&gt; remove_msg(Q, T). remove_list(_, []) -&gt; ok; remove_list(Q, [H | T]) -&gt; remove_msg(Q, H), remove_list(Q, T).</code> </pre><br><br>  The list sent to delete contains a lot of unnecessary information (message body, etc.), the delete function finds the receipt_handle that is required to form a request or returns the wrong if the receipt_handle is not found <br><br><h4>  Shuffle messages </h4><br>  Looking ahead, I can say that even on a small number of messages, mixing turned out to be quite significant and an additional task arose: you need to evaluate the degree of mixing.  Unfortunately, no good criteria could be found and it was decided to display the maximum and average discrepancy with the correct position.  Knowing the size of such a window, you can restore the order of messages upon receipt, while, of course, processing speed worsens. <br><br>  To calculate this difference, it is enough to change only the function of checking the order of messages: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">checkorder</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(N, [])</span></span></span><span class="hljs-function"> -&gt;</span></span> N; checkorder({N, Cnt, Sum, Max}, [H | T]) -&gt; [{body, [M | _]}|_] = H, {N1, Cnt1, Sum1, Max1} = <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> M &lt; N -&gt; {N, Cnt + <span class="hljs-number"><span class="hljs-number">1</span></span>, Sum + N - M, <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> Max &lt; N - M -&gt; N - M; <span class="hljs-literal"><span class="hljs-literal">true</span></span> -&gt; Max <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> }; <span class="hljs-literal"><span class="hljs-literal">true</span></span> -&gt; {M, Cnt, Sum, Max} <span class="hljs-keyword"><span class="hljs-keyword">end</span></span>, checkorder({N1, Cnt1, Sum1, Max1}, T).</code> </pre><br><br>  The call to the function of executing the series will look as follows <br><br><pre> <code class="erlang hljs">{_, Cnt, Sum, Max} = test_avg(?MODULE, receive_checkorder, [QueueName], {<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>}, Size)</code> </pre><br><br>  I get the number of elements that came later than needed, the sum of their distances from the largest of the received elements and the maximum offset.  The most interesting thing for me here is the maximum offset, the remaining characteristics can be called controversial and they may not be calculated very well (for example, if one element is read earlier, then all elements that must go to it will be considered permuted in this case).  To the results: <br><br><table><tbody><tr><th>  Size (pcs) </th><th>  20 </th><th>  50 </th><th>  100 </th><th>  150 </th><th>  200 </th><th>  250 </th><th>  300 </th><th>  400 </th><th>  500 </th><th>  600 </th><th>  700 </th><th>  800 </th><th>  900 </th><th>  1000 </th></tr><tr><td>  Maximum offset (pcs) </td><td>  eleven </td><td>  32 </td><td>  66 </td><td>  93 </td><td>  65 </td><td>  139 </td><td>  184 </td><td>  155 </td><td>  251 </td><td>  241 </td><td>  218 </td><td>  249 </td><td>  359 </td><td>  227 </td></tr><tr><td>  Average displacement (pcs) </td><td>  5.3 </td><td>  10.5 </td><td>  23.9 </td><td>  43 </td><td>  25.6 </td><td>  45.9 </td><td>  48.4 </td><td>  65.6 </td><td>  74.2 </td><td>  74.2 </td><td>  78.3 </td><td>  72.3 </td><td>  110.8 </td><td>  82.8 </td></tr></tbody></table><br><br>  The first line is the number of messages in the queue, the second is the maximum offset, the third is the average offset. <br><br>  The results surprised me, the messages are not just mixed up, there are simply no boundaries, that is, with an increase in the number of messages, you need to increase the size of the window being viewed.  The same in the form of a graph: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7fe/d5f/2f6/7fed5f2f69262bac503f6b10fb08f488.png"><br><br><h4>  Long polling </h4><br>  As I already wrote, Amazon SQS does not support subscriptions, you can use Amazon SNS for this, but if fast queues with multiple handlers are required, this does not work, in order not to pull the message receiving method Amazon implemented Long Polling, which allows you to hang while waiting for messages up to twenty seconds, and since SQS is charged by the number of methods called, this should significantly reduce the cost of queues, but what is the problem: for a small number of messages (according to official documentation), the queue may not return  nothing.  This behavior is critical for queues in which you need to quickly respond to an event and generally speaking, if this happens often then Long Polling does not make much sense, since it becomes equivalent to periodic polls with an SQS reaction time. <br><br>  For verification, we will create two processes, one of which will send messages at random times, and the second one will reside in Long Polling, while the moments of sending and receiving messages will be saved for later comparison.  In order to enable this mode, set Receive Message Wait Time = 20 seconds in the queue parameters. <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send_sleep</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(L, Queue)</span></span></span><span class="hljs-function"> -&gt;</span></span> timer:sleep(random:uniform(<span class="hljs-number"><span class="hljs-number">10000</span></span>)), Call = erlang:now(), erlcloud_sqs:send_message(Queue, random_string(<span class="hljs-number"><span class="hljs-number">6000</span></span> + random:uniform(<span class="hljs-number"><span class="hljs-number">6000</span></span>))), [Call | L].</code> </pre><br><br>  this function falls asleep for a random number of milliseconds, after which it remembers the moment and sends a message <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">remember_moment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(L, [])</span></span></span><span class="hljs-function"> -&gt;</span></span> L; remember_moment(L, [_ | _]) -&gt; [erlang:now() | L]. receive_polling(L, Queue) -&gt; [{messages, List} | _] = erlcloud_sqs:receive_message(Queue), remove_list(Queue, List), remember_moment(L, List).</code> </pre><br><br>  These two functions allow you to receive messages and memorize the moments in which this happened.  After the simultaneous execution of these functions with the help of spawn, I get two lists, the difference between which shows the reaction time to the message.  It does not take into account the fact that messages can be mixed, in general, it will simply increase the additional reaction time. <br><br>  Let's see what happened: <br><br><table><tbody><tr><th>  Sleep interval </th><th>  10,000 </th><th>  7500 </th><th>  5000 </th><th>  2500 </th></tr><tr><td>  Minimum time (sec) </td><td>  0.27 </td><td>  0.28 </td><td>  0.27 </td><td>  0.66 </td></tr><tr><td>  Maximum time (sec) </td><td>  10.25 </td><td>  7.8 </td><td>  5.36 </td><td>  5.53 </td></tr><tr><td>  Average time (s) </td><td>  1.87 </td><td>  1.87 </td><td>  1.84 </td><td>  1.88 </td></tr></tbody></table><br><br>  The first line is the value set as the maximum delay for the sending process.  That is: 10 seconds, 7.5 seconds ... The remaining lines - the minimum, maximum and average waiting time for receiving a message. <br><br>  The same in the form of a graph: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3dd/4aa/4cd/3dd4aa4cdb7dea444bdede516ff64099.png"><br><br>  The average time turned out to be the same in all cases; it can be said that, on average, it takes two seconds between sending such single messages before receiving them.  Long enough.  In this test, the sample was rather small, 20 messages, so the minimum-maximum values ‚Äã‚Äãare more a matter of luck rather than some kind of dependency. <br><br><h4>  Batch shipping </h4><br>  To begin with, let's check how important the effect of ‚Äúwarming up‚Äù the queue when sending messages: <br><br><table><tbody><tr><th>  Number of records </th><th>  20 </th><th>  50 </th><th>  100 </th><th>  150 </th><th>  200 </th><th>  250 </th><th>  300 </th><th>  400 </th><th>  500 </th><th>  600 </th><th>  700 </th><th>  800 </th><th>  900 </th><th>  1000 </th></tr><tr><td>  Minimum time (sec) </td><td>  0.1 </td><td>  0.1 </td><td>  0.1 </td><td>  0.09 </td><td>  0.09 </td><td>  0.09 </td><td>  0.09 </td><td>  0.1 </td><td>  0.09 </td><td>  0.1 </td><td>  0.1 </td><td>  0.09 </td><td>  0.09 </td><td>  0.09 </td></tr><tr><td>  Maximum time (sec) </td><td>  0.19 </td><td>  0.37 </td><td>  0.41 </td><td>  0.41 </td><td>  0.37 </td><td>  0.38 </td><td>  0.37 </td><td>  0.43 </td><td>  0.39 </td><td>  0.66 </td><td>  0.74 </td><td>  0.48 </td><td>  0.53 </td><td>  0.77 </td></tr><tr><td>  Average time (s) </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td><td>  0.12 </td></tr></tbody></table><br><br>  The same in the form of a graph: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ac8/a76/f6a/ac8a76f6aefcac9e60953c173cdf952a.png"><br><br>  we can say that no warm-up is observed, that is, the queue behaves approximately equally in these data volumes, only the maximum for some reason rises, but the average and minimum remain in their places. <br>  Same for read-delete <br><br><table><tbody><tr><th>  Number of records </th><th>  20 </th><th>  50 </th><th>  100 </th><th>  150 </th><th>  200 </th><th>  250 </th><th>  300 </th><th>  400 </th><th>  500 </th><th>  600 </th><th>  700 </th><th>  800 </th><th>  900 </th><th>  1000 </th></tr><tr><td>  Minimum time (sec) </td><td>  0.001 </td><td>  0.14 </td><td>  0 </td><td>  0.135 </td><td>  0 </td><td>  0.135 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  Maximum time (sec) </td><td>  0.72 </td><td>  0.47 </td><td>  0.65 </td><td>  0.65 </td><td>  0.69 </td><td>  0.51 </td><td>  0.75 </td><td>  0.75 </td><td>  0.76 </td><td>  0.73 </td><td>  0.82 </td><td>  0.79 </td><td>  0.74 </td><td>  0.91 </td></tr><tr><td>  Average time (s) </td><td>  0.23 </td><td>  0.21 </td><td>  0.21 </td><td>  0.21 </td><td>  0.21 </td><td>  0.21 </td><td>  0.21 </td><td>  0.21 </td><td>  0.21 </td><td>  0.2 </td><td>  0.2 </td><td>  0.2 </td><td>  0.2 </td><td>  0.21 </td></tr></tbody></table><br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/dd4/b75/05cdd4b7500a9f28ecc8e0b4f12c51d8.png"><br><br>  There is also no saturation, an average of around 200ms.  Sometimes reading happened instantly (faster than 1 ms), but this means that the message was not received, according to the documentation, the SQS server can do this, you just need to re-request the message. <br><br>  Let's go directly to the block and multi-threaded testing. <br><br>  Unfortunately, the erlcloud library does not contain functions for batch sending messages, but such functions are not difficult to implement on the basis of the existing ones, in the function of sending messages you need to change the request to the following: <br><br><pre> <code class="erlang hljs">Doc = sqs_xml_request(Config, QueueName, <span class="hljs-string"><span class="hljs-string">"SendMessageBatch"</span></span>, encode_message_list(Messages, <span class="hljs-number"><span class="hljs-number">1</span></span>)),</code> </pre><br><br>  and add the query generation function: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_message_list</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">([], _)</span></span></span><span class="hljs-function"> -&gt;</span></span> []; encode_message_list([H | T], N) -&gt; MesssageId = string:concat(<span class="hljs-string"><span class="hljs-string">"SendMessageBatchRequestEntry."</span></span>, integer_to_list(N)), [{string:concat(MesssageId, <span class="hljs-string"><span class="hljs-string">".Id"</span></span>), integer_to_list(N)}, {string:concat(MesssageId, <span class="hljs-string"><span class="hljs-string">".MessageBody"</span></span>), H} | encode_message_list(T, N + <span class="hljs-number"><span class="hljs-number">1</span></span>)].</code> </pre><br><br>  In the library, you should also fix the API version, for example, on 2011-10-01, otherwise Amazon will return Bad request in response to your requests. <br><br>  testing functions are similar to those used in other tests: <br><br><pre> <code class="erlang hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen_messages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> -&gt;</span></span> []; gen_messages(N) -&gt; [random_string(<span class="hljs-number"><span class="hljs-number">5000</span></span> + random:uniform(<span class="hljs-number"><span class="hljs-number">1000</span></span>)) | gen_messages(N - <span class="hljs-number"><span class="hljs-number">1</span></span>)]. send_batch(N, Queue) -&gt; erlang:display(erlcloud_sqs:send_message_batch(Queue, gen_messages(<span class="hljs-number"><span class="hljs-number">10</span></span>))), N + <span class="hljs-number"><span class="hljs-number">1</span></span> .</code> </pre><br><br>  Here, I just had to change the length of the messages so that the whole package would fit in 64kb, otherwise an exception is generated. <br><br>  The following recording data was obtained: <br><br><table><tbody><tr><th>  Number of threads </th><th>  0 </th><th>  one </th><th>  2 </th><th>  four </th><th>  five </th><th>  ten </th><th>  20 </th><th>  50 </th><th>  100 </th></tr><tr><td>  Maximum delay (sec) </td><td>  0.452 </td><td>  0.761 </td><td>  0.858 </td><td>  1.464 </td><td>  1.698 </td><td>  3.14 </td><td>  5.272 </td><td>  11.793 </td><td>  20.215 </td></tr><tr><td>  Average delay (sec) </td><td>  0.118 </td><td>  0.48 </td><td>  0.436 </td><td>  0.652 </td><td>  0.784 </td><td>  1.524 </td><td>  3.178 </td><td>  9.1 </td><td>  19.889 </td></tr><tr><td>  Time per message (s) </td><td>  0.118 </td><td>  0.048 </td><td>  0.022 </td><td>  0.017 </td><td>  0.016 </td><td>  0.016 </td><td>  0.017 </td><td>  0.019 </td><td>  0.02 </td></tr></tbody></table><br><br>  here 0 means reading one in 1 stream, then reading 1 in 10 in 1 stream, in 10 in 2 streams, in 10 in 4 streams, and so on <br><br>  For reading: <br><br><table><tbody><tr><th>  Number of threads </th><th>  0 </th><th>  one </th><th>  2 </th><th>  four </th><th>  five </th><th>  ten </th><th>  20 </th><th>  50 </th><th>  100 </th></tr><tr><td>  Maximum delay (sec) </td><td>  0.762 </td><td>  2.998 </td><td>  2.511 </td><td>  2.4 </td><td>  2.606 </td><td>  2.751 </td><td>  4.944 </td><td>  11.653 </td><td>  18.517 </td></tr><tr><td>  Average delay (sec) </td><td>  0.205 </td><td>  1.256 </td><td>  1.528 </td><td>  1.566 </td><td>  1.532 </td><td>  1.87 </td><td>  3.377 </td><td>  7.823 </td><td>  17.786 </td></tr><tr><td>  Time per message (s) </td><td>  0.205 </td><td>  0.126 </td><td>  0.077 </td><td>  0.04 </td><td>  0.031 </td><td>  0.02 </td><td>  0.019 </td><td>  0.017 </td><td>  0.019 </td></tr></tbody></table><br><br>  graph showing bandwidth for reading and writing (messages per second): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4c5/c28/47e/4c5c2847ec35243ad4e50d53144209a8.png"><br><br>  Blue - write, red - read. <br><br>  From this data, we can conclude that the maximum throughput is achieved for recording in the region of 10 streams, and for reading - about 50, with a further increase in the number of streams, the number of messages sent per unit of time does not increase. <br><br><h4>  findings </h4><br>  It turns out that Amazon SQS significantly changes the order of messages, it has not very good reaction time and throughput; only reliability and a small (in the case of a small number of messages) charge can counter this.  That is, if your speed is not critical, it doesn‚Äôt matter that the messages are mixed up and you don‚Äôt want to administer or hire a queue server administrator - this is your choice. <br><br><h4>  Links </h4><br><ol><li>  Erlcloud on github <a href="https://github.com/gleber/erlcloud">github.com/gleber/erlcloud</a> </li><li>  <a href="http://www.w3.org/TR/REC-xml/">www.w3.org/TR/REC-xml/#charsets</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/207326/">https://habr.com/ru/post/207326/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../207312/index.html">How we made new year cards with lifehacks</a></li>
<li><a href="../207314/index.html">Raspberry Pi: Encode H.264 live video</a></li>
<li><a href="../207316/index.html">Agile Board. How do we plan in Yandex. Pictures and how did we come to this?</a></li>
<li><a href="../207318/index.html">Significant events for IT business</a></li>
<li><a href="../207320/index.html">Qt 5.2.0 is out!</a></li>
<li><a href="../207328/index.html">Call to Santa Claus 2014</a></li>
<li><a href="../207330/index.html">Bought> filled> in your pocket! Review PocketBook 515</a></li>
<li><a href="../207332/index.html">The development of startup ecosystems and e-commerce market on the example of CentroBit</a></li>
<li><a href="../207334/index.html">Is it possible to make money on a mobile application for viewing advertising for money?</a></li>
<li><a href="../207336/index.html">Do I need to read the code of the libraries used?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>