<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Instructions for working with TensorFlow Object Detection API</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Translation TensorFlow Object Detection API tutorial - Training and Evaluating Custom Object Detector . 

 We all know how to drive a car, because it'...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Instructions for working with TensorFlow Object Detection API</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e69/109/61a/e6910961a21edc6bc6f3f4b58b92c9cd.png"></div><br>  <i>Translation <a href="https://becominghuman.ai/tensorflow-object-detection-api-tutorial-training-and-evaluating-custom-object-detector-ed2594afcf73">TensorFlow Object Detection API tutorial - Training and Evaluating Custom Object Detector</a> .</i> <br><br>  We all know how to drive a car, because it's pretty easy, right?  But what will you do if someone asks you to sit at the controls of an airplane?  That's right - you read the instructions.  Similarly, the guide you will find below will help you set up the API and enjoy a pleasant flight. <br><a name="habracut"></a><br>  First of all, clone the repository by <a href="https://github.com/tensorflow/models">reference</a> .  I hope you already have <a href="https://www.tensorflow.org/install/">TensorFlow</a> installed. <br><br>  <i>git clone <a href="">github.com/tensorflow/models.git</a></i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In machine learning, we usually train and test the model using a CSV file.  But in this case, we act according to the scheme shown in the figure: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ccb/6f5/7df/ccb6f57dfab5c0f35040019be7f60f87.png"><br><br>  Before proceeding, we will focus on the directory structure that we will use. <br><br><ul><li>  data / - This will contain entries and CSV files. </li><li>  images / - Here is a data set for teaching our model. </li><li>  training / - Here we will save the trained model. </li><li>  eval / - The results of the model performance evaluation will be stored here. </li></ul><br><h2>  Step 1: Save Images to CSV </h2><br>  Everything is pretty simple here.  We will not delve into this task, just give a few useful links. <br><br>  Our task is to mark the image and create the train.CSV and test.CSV files. <br><br><ul><li>  Use the <a href="https://github.com/tzutalin/labelImg">labelImg</a> tool <a href="https://github.com/tzutalin/labelImg">to</a> label the image.  How to do this, see <a href="https://www.youtube.com/watch%3Fv%3DK_mFnvzyLvc%26list%3DPLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku%26index%3D3">here</a> . </li><li>  Convert XML to CSV, as shown <a href="https://www.youtube.com/watch%3Fv%3Dkq2Gjv_pPe8%26index%3D4%26list%3DPLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku">here</a> . </li></ul><br>  There are many ways to create CSV files that are more or less suitable for working with each specific data set. <br><br>  As part of our project, we will try to achieve the detection of pulmonary nodes using the <a href="https://luna16.grand-challenge.org/data/">LUNA dataset</a> .  The coordinates of the nodes were already known, and therefore the creation of CSV files was not difficult.  To locate the nodes, we use the 6 coordinates shown below: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a64/edd/019/a64edd0197a38edf75ee699e80e7f319.png"><br><br>  You should correct only the class name <code>nodules</code> (nodes), everything else will remain unchanged.  As soon as the marked objects are presented in the form of numbers, you can proceed to the creation of TFRecords. <br><br><h2>  Step 2: Create TFRecords </h2><br>  TensorFlow Object Detection API does not accept input data for training the model in CSV format, so you need to create a TFRecords using <a href="https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py">this file.</a> <br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">""" Usage: # From tensorflow/models/ # Create train data: python generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=train.record # Create test data: python generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=test.record """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> division <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> print_function <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> object_detection.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> dataset_util <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> namedtuple, OrderedDict flags = tf.app.flags flags.DEFINE_string(<span class="hljs-string"><span class="hljs-string">'csv_input'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'Path to the CSV input'</span></span>) flags.DEFINE_string(<span class="hljs-string"><span class="hljs-string">'output_path'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'Path to output TFRecord'</span></span>) FLAGS = flags.FLAGS <span class="hljs-comment"><span class="hljs-comment"># TO-DO replace this with label map def class_text_to_int(row_label): if row_label == 'raccoon': return 1 else: None def split(df, group): data = namedtuple('data', ['filename', 'object']) gb = df.groupby(group) return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)] def create_tf_example(group, path): with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid: encoded_jpg = fid.read() encoded_jpg_io = io.BytesIO(encoded_jpg) image = Image.open(encoded_jpg_io) width, height = image.size filename = group.filename.encode('utf8') image_format = b'jpg' xmins = [] xmaxs = [] ymins = [] ymaxs = [] classes_text = [] classes = [] for index, row in group.object.iterrows(): xmins.append(row['xmin'] / width) xmaxs.append(row['xmax'] / width) ymins.append(row['ymin'] / height) ymaxs.append(row['ymax'] / height) classes_text.append(row['class'].encode('utf8')) classes.append(class_text_to_int(row['class'])) tf_example = tf.train.Example(features=tf.train.Features(feature={ 'image/height': dataset_util.int64_feature(height), 'image/width': dataset_util.int64_feature(width), 'image/filename': dataset_util.bytes_feature(filename), 'image/source_id': dataset_util.bytes_feature(filename), 'image/encoded': dataset_util.bytes_feature(encoded_jpg), 'image/format': dataset_util.bytes_feature(image_format), 'image/object/bbox/xmin': dataset_util.float_list_feature(xmins), 'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs), 'image/object/bbox/ymin': dataset_util.float_list_feature(ymins), 'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs), 'image/object/class/text': dataset_util.bytes_list_feature(classes_text), 'image/object/class/label': dataset_util.int64_list_feature(classes), })) return tf_example def main(_): writer = tf.python_io.TFRecordWriter(FLAGS.output_path) path = os.path.join(os.getcwd(), 'images') examples = pd.read_csv(FLAGS.csv_input) grouped = split(examples, 'filename') for group in grouped: tf_example = create_tf_example(group, path) writer.write(tf_example.SerializeToString()) writer.close() output_path = os.path.join(os.getcwd(), FLAGS.output_path) print('Successfully created the TFRecords: {}'.format(output_path)) if __name__ == '__main__': tf.app.run()</span></span></code> </pre> <br>  After downloading the file, make one small change: in line 31 instead of the word <code>raccoon</code> put your own mark.  In the example above, these are <code>nodules</code> , nodes.  If your model will need to define several kinds of objects, create additional classes. <br><br>  <i>Note.</i>  <i>Label numbering should start from one, not from scratch.</i>  <i>For example, if you use three kinds of objects, they should be assigned the values ‚Äã‚Äã1, 2, and 3, respectively.</i> <br><br>  To create the <i>train.record</i> file <i>,</i> use the following code: <br><br><pre> <code class="python hljs">python generate_tfRecord.py --CSV_input=data/train.CSV --output_path=data/train.record</code> </pre> <br>  To create the <i>test.record</i> file <i>,</i> use the following code: <br><br><pre> <code class="python hljs">python generate_tfrecord.py ‚Äî CSV_input=data/test.CSV ‚Äî output_path=data/test.record</code> </pre> <br><h2>  Step 3: model training </h2><br>  Once the files we need are created, we are almost ready to start learning. <br><br><ol><li>  <a href="">Choose a model that you will be</a> teaching.  You should find a compromise between speed and accuracy: the higher the speed, the lower the accuracy of the determination, and vice versa.  As an example, <code>sd_mobilenet_v1_coco</code> used <code>sd_mobilenet_v1_coco</code> . </li><li>  Deciding which model you will work with, <a href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs">download the appropriate configuration file</a> .  In this example, this is <code>ssd_mobilenet_v1_coco.config</code> . </li><li>  Create an <i>object-detection.pbtxt</i> file that looks like this: <br><br><pre> <code class="python hljs">item { id: <span class="hljs-number"><span class="hljs-number">1</span></span> name: <span class="hljs-string"><span class="hljs-string">'nodule'</span></span> }</code> </pre> <br>  Give the <code>nodule</code> class a different name.  If there are several classes, increase the <code>id</code> value and enter new names. </li></ol><br>  It's time to customize the configuration file, making the following adjustments. <br><br>  Change the number of classes according to your requirements. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before num_classes: 90 #After num_classes: 1</span></span></code> </pre> <br>  If the power of your GPU is insufficient, lower the <code>batch_size</code> value. <br><br><pre> <code class="python hljs">batch_size: <span class="hljs-number"><span class="hljs-number">24</span></span></code> </pre> <br>  Specify the path to the <code>ssd_mobilenet_v1_coco</code> model that we downloaded earlier. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED/model.ckpt" #after fine_tune_checkpoint: "ssd_mobilenet_v1_coco/model.ckpt"</span></span></code> </pre> <br>  Specify the path to the <i>train.record</i> file. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before train_input_reader: { tf_record_input_reader { input_path: "PATH_TO_BE_CONFIGURED/mscoco_train.record" } label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt" } #after train_input_reader: { tf_record_input_reader { input_path: "data/train.record" } label_map_path: "data/object-detection.pbtxt" }</span></span></code> </pre> <br>  Specify the path to the <i>test.record</i> file <i>.</i> <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#before eval_input_reader: { tf_record_input_reader { input_path: "PATH_TO_BE_CONFIGURED/mscoco_val.record" } label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt" shuffle: false num_readers: 1} #after eval_input_reader: { tf_record_input_reader { input_path: "data/test.record" } label_map_path: "data/object-detection.pbtxt" shuffle: false num_readers: 1}</span></span></code> </pre> <br>  Now copy the <i>data /</i> and <i>images /</i> folders into the <i>models / research / object-detection</i> folders.  If you are prompted to merge folders, accept it. <br><br>  In addition, we will need the <i>object-detection</i> / <i>train.py</i> file located in the directory <i>.</i> <br><br><pre> <code class="python hljs">cd models/research/object-detection</code> </pre> <br>  Create in the <i>object-detection</i> folder <i>/ training /</i> folder <i>.</i>  It is in <i>training /</i> we will save our model.  Copy the <i>ssd_mobilenet_v1_coco.config</i> to the <i>training /</i> configuration <i>file</i> .  Training is performed using the command: <br><br><pre> <code class="python hljs">python train.py --logtostderr \ --train_dir=training/ \ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config</code> </pre> <br>  If everything goes according to plan, you will see how the loss function changes at each stage. <br><br><h2>  Step 4: Model Evaluation </h2><br>  Finally, we evaluate the model stored in the <i>training /</i> directory.  To do this, run the <i>eval.py</i> file and enter the following command: <br><br><pre> <code class="python hljs">python eval.py \ --logtostderr \ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config \ --checkpoint_dir=training/ \ --eval_dir=eval/</code> </pre> <br>  The test results are reflected in the <i>eval /</i> folder.  They can be visualized using TensorBoard. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#To visualize the eval results tensorboard --logdir=eval/ #TO visualize the training results tensorboard --logdir=training/</span></span></code> </pre> <br>  Open the link through the browser.  In the <i>Images</i> tab, you will see the results of the model: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d25/107/871/d25107871dfd23defc48ade0e0c61bd5.png"><br><br>  That's all, you have successfully configured the TensorFlow Object Detection API. <br><br>  One of the most common mistakes: <br><br> <code>No module named deployment on object_detection/train.py</code> <br> <br>  It is solved with the help of the command: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># From tensorflow/models/research/ export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim</span></span></code> </pre> <br>  You can read about how to change Faster-RCNN / SSD parameters <a href="https://towardsdatascience.com/3-steps-to-update-parameters-of-faster-r-cnn-ssd-models-in-tensorflow-object-detection-api-7eddb11273ed">here</a> . <br><br>  Thanks for attention! </div><p>Source: <a href="https://habr.com/ru/post/422353/">https://habr.com/ru/post/422353/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422339/index.html">"I think JavaScript is not suitable for the web." 10 Questions to the Programmer, 4th Edition (from Berlin)</a></li>
<li><a href="../422341/index.html">IoT - promote while others think</a></li>
<li><a href="../422345/index.html">Server in the clouds: the results of the project</a></li>
<li><a href="../422347/index.html">Migrating a real-world application from standalone MySQL to Percona XtraDB Cluster</a></li>
<li><a href="../422351/index.html">Remote code execution via uploading pictures on your server or local computer to ghostscript / imagick</a></li>
<li><a href="../422355/index.html">Games with time: we accelerate the application at the level of perception</a></li>
<li><a href="../422357/index.html">Deep learning to determine the style and genre of paintings</a></li>
<li><a href="../422359/index.html">The results of the quest that you have passed. Or not</a></li>
<li><a href="../422361/index.html">Corporate Syndrome</a></li>
<li><a href="../422363/index.html">Conference PyCon Russia 2018: video of all reports and presentations</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>