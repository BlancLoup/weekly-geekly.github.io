<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Being a technophobe is pointless, even if technophobia is justified.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In several of Kurt Vonnegut's novels there is the fictional planet Tralfamador. Its inhabitants live in four dimensions, and see at once all the time ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Being a technophobe is pointless, even if technophobia is justified.</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/hm/1j/8r/hm1j8rv4v4tfuevoo-emfee5o-m.jpeg"><br><br>  In several of Kurt Vonnegut's novels there is the fictional planet Tralfamador.  Its inhabitants live in four dimensions, and see at once all the time from beginning to end.  They know how the universe began, and they know how it will die: the Tralfamadore test scientists will launch the super-engine, it will explode and destroy everything.  But they do not even try to prevent a catastrophe.  There is no hint in their thinking that the course of events should be changed.  They continue to make progress towards this engine, because in their world everything that has happened has already happened. <br><br>  Sometimes it seems to me, we think the same way, only a little less consciously.  The idea that progress cannot be stopped instills in us unshakable optimism.  If you do not stop, then everything goes as it goes, and there are continuous endless successes ahead.  We must relax and row with the flow.  Even disturbing scenarios echo in the nook of consciousness with romantic delight.  ‚ÄúWill machines become smart and slaughter everyone?‚Äù  Great!  Like in the movies! ‚ÄùThis is treated with serious pessimism - almost madness. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It is clear that reality is always more boring than fiction, and alarmists and Luddites usually die before progress justifies their fears.  But if some futurologists are to be believed, we can still witness in our time large points of no return, to which we happily rush at full speed. <br><a name="habracut"></a><br><hr><br>  Recently, <a href="https://habr.com/ru/users/fillpackart/" class="user_link">packpackart has</a> written a <a href="https://habr.com/ru/post/442112/">column</a> on abstraction levels in modern programming languages.  Ostensibly between the code and the execution on the hardware with so many automated layers of interpretation and compilation, we begin to lose control over low-level things. <br><br>  We discussed this topic a lot, and, of course, we do not believe that all programmers should unite to renounce their usual languages ‚Äã‚Äãand go to the hammer with a soldering iron.  Abstractions are great.  Modern capabilities, ease of problem solving and level of comfort - everything is just fine.  Probably now be a cool developer, more than ever. <br><br>  But the world is a thing full of paradoxes.  To think about what will happen to the industry in ten years seems important.  But in 60‚Äì70‚Äì170 - somehow not very much.  It is as if we are not concerned.  Even if we are living, by that time we will be more interested in atmospheric pressure and calls from grandchildren.  But at least for a second, imagine what will happen if you constantly increase the thickness of abstractions and increase the comfort of programming.  If automate, and automate, and automate. <br><br>  I think, in this case, the descendants of our descendants will inherit the ‚Äúblack box‚Äù - a technology that works on its own, understandable only to her and to us, the long-dead creators (who left some unreadable documentation), in a way.  The technology will not need to know, it just needs to be serviced.  And I am sure that on this IT business will build its culture, and each manifesto will say - ‚ÄúDo not get into the essence of technology, just let it solve problems.‚Äù <br><br>  Just imagine what the conversations will be like then, the year in 2199. Probably something in the spirit: ‚ÄúAccording to our observations, if the system says the word‚Äú execute ‚Äù, it will turn out 0.8 seconds faster than if you say‚Äú do it ‚Äù.  And if at the end of the program speech to sustain a three-second pause and then add "asparagus" - the conversion will increase by 3%. " <br><br>  And if you have a better opinion about humanity - look at the people who put a link on Facebook in the first comment.  Already today we are starting ‚Äúrationally sound‚Äù dances with a tambourine by the fire, it is only a popular algorithm that just a little bit closes the wall from us. <br><br><hr><br><img src="https://habrastorage.org/webt/qw/j1/ax/qwj1axulkl2mxwtbae5afz8c06s.jpeg"><br><br>  The really important question is not ‚ÄúWill technology turn into a black box,‚Äù but ‚ÄúWhen will this happen‚Äù.  And there are people who are much smarter than me, who believe that magic instead of science will begin earlier than it seemed to me. <br><br>  Last summer, I listened to a speech by Leonid Tkachenko from MTS at a conference on big data.  At first he spoke about the death of the telecom, then he amused the people with predictions: <br><blockquote>  There is a theory about technological singularity.  Human intelligence is growing rather slowly, and artificial intelligence is growing fast.  We are progressing in a stupid way, accidentally mate, when someone looks like it, and human evolution is slow.  We are the same as we were a half million years ago.  The brain progresses for a long time, because everything happens randomly. <br><br>  When we talk about AI, we train it purposefully, so that it will be better and better.  He does not mate with anyone by chance, he does what we want.  And according to some calculations, artificial intelligence will catch up with human in 2030-40. <br><br>  This means that technological progress will go further.  He will not stop.  But the AI ‚Äã‚Äãwill move it.  We will not be able to understand what he has invented, and he will continue to make technological breakthroughs. <br><br>  And there is a separate ethical question - will it work against us?  How can we control it?  After all, he will be stronger.  Will he work for our good, or will we become cows. <br><br>  Cows live on the Earth, nobody destroys them.  But the cows do not even understand that there are still people on Earth who use them as they wish.  Yes, cows are not erased from the face of the Earth, but now we are, of course, the owners of life.  At some point, someone else may become the owner, it can happen.  And this moment is near. </blockquote><br>  Leonid, when he spoke, relied on the predictions of Vernon Vinge and Raymond Kurzweil.  Vinge is a writer, and although the term ‚Äútechnological singularity‚Äù belongs to him, his forecast is too optimistic (pessimistic?).  Supposedly, we will lose control over technological progress by 2030.  Kurzweil is an engineer, and counted a little more time - by the 2045th. <br><br>  Both built their predictions on Moore's law on the constant increase in the frequency of processors.  "Everything lies in the capabilities of hardware and software," said Kurzweil in the 2006th. <br><blockquote>  In my book ‚ÄúThe singularity is near,‚Äù I wrote that we need to achieve 10 quadrillion (10 <sup>16</sup> ) operations per second in order to provide a functional equivalent of all areas of the brain ‚Äî by some estimates even less.  Some supercomputers are already at around 100 trillion (10 <sup>14</sup> ), and will reach 10 <sup>16</sup> by the end of this decade. <br><br>  Supercomputers with one quadrillion operations are already in the project, and two Japanese manufacturers plan to reach 10 <sup>16</sup> in a few years.  By 2020, computers with 10 quadrillion operations will cost a thousand dollars. <br><br>  The fact that iron reaches such capacity was controversial when I wrote the first book in 1999, and now this is quite a popular opinion.  Now disputes lead more around algorithms. </blockquote><br>  But now, in 2019, it can be seen how Kurzweil's forecasts, if they do not come true, at least are moving away.  Firstly, the algorithms and the ways to pump iron went a little different ways.  At about the same time that Kurzweil wrote this, manufacturers began to switch to multi-core architectures, which made Moore's law somewhat more complicated.  And the most powerful supercomputer for today, which began to be designed in the same 2006th, handles only two hundred trillion operations per second.  There is still a long way to a full-fledged reconstruction of the brain, and even further to a thousand dollars worth. <br><br>  Kurzweil's other predictions seem quite fantastic.  For example, the first attempt to unleash VR failed, although Kurzweil was counting on a full-fledged move to the virtual world a couple of years ago.  Nanorobots implanted in the head, which greatly increase our abilities, also exist so far only in movies and books. <br><br>  On the other hand, almost every technological failure is being answered by ‚Äújust the time has not come yet‚Äù.  Optimism, pessimism and a sense of inevitability can not be swept out of the head by any logic, as if everything predicted already in Tralfamadorsky happened, we just cannot see the exact date. <br><br><hr><br><img src="https://habrastorage.org/webt/r3/nx/6i/r3nx6iaig6fkcrr2lwceuaxp0mo.jpeg"><br><br>  If the question ‚Äúwhen‚Äù is solved only by waiting, then the choice ‚Äúto be an optimist or a pessimist‚Äù should be made by oneself. <br><br>  In the views of Kurzweil, it seems, there is not a drop of technophobia.  He is a rare optimist and to this day believes that the singularity is approaching, and this is not a problem, but a challenge, our indulgence, to finally begin to augment organic brains with something that has hardware and microprocessors.  And beyond the horizon of a singularity, there is no loss of control over technology, not a scenario when AI will wake up and interrupt us all - but some kind of revolution, as a result of which a person will finally cease to be a purely biological being. <br><br>  Origins presenter at National Geographic Jason Silva believes that this has already happened, we just did not notice, because it did not happen on a sci-fi scale, but as always happens in reality - gradually and ordinary: <br><blockquote>  Kurzweil and Kevin Kelly say that we will continue to augment our thinking, giving more and more ways to process information to non-biological media.  The AI ‚Äã‚Äãwill not stand against us, we will make our own intelligence more and more artificial. <br><br>  But we are already unloading a part of consciousness onto artificial carriers.  When we write something on paper, some of the thinking happens on this paper.  Part of thinking is that we move the handle.  Part of thinking happens when you look at your own thoughts, unloaded on paper and react to what you wrote yourself. <br><br>  The built environment is already part of the thinking apparatus.  Philosophers David Chalmers and Andy Clark expressed the thesis about ‚Äúexpanded consciousness‚Äù, according to which a smartphone is already an addition to thinking, and that thinking is not limited to the brain, that consciousness actually exists in the loop of constant feedback between the brain, tools and the environment.  That is why we say that our thoughts mold the environment, and the environment influences thoughts.  Everything that we create creates us too.  There is no "we are against them."  There is one large distributed intelligence, which consists of biological and non-biological parts. <br><br>  So I think we have nothing to fear.  These are just billions of small steps that expand our ability to create. </blockquote><br>  Their optimistic attitude is based on the fact that nothing new will happen, and there is nothing to lose control over.  That, developing technologies, we pump over the consciousness, and these things are inseparable.  If you look closely, it makes sense.  Most of all, for example, I am amazed by our inner sense of time, completely built on tools. <br><br>  Having invented and written down ‚Äúon paper‚Äù hours, minutes and seconds, we began to measure everything by them, at first glance, subconsciously.  You can immerse yourself in any business, and having finished it, without thinking to understand: ‚ÄúI spent three hours‚Äù.  You can get carried away with the film so that you forget everything, but on the credits you clearly feel that two hours have passed.  But if you remove from yourself all the environment, all the tools and all the cases, the awareness of time will begin to elude consciousness.  A person, having spent a week in a dark cave, will be mistaken with an estimate of the past time for several days.  Even sitting in an empty room is impossible to assess, an hour or two has passed.  It turns out that the sense of time does not live inside the consciousness, but outside. <br><br>  And we live very well with the fact that the knowledge of humanity has long been stored not in the brain, but on external carriers.  That all civilization, infrastructure, communication are built on things unloaded from memory.  This is normal, because the carriers seem even more reliable and understandable than our own brain. <br><br>  But modern technology is built on a funny paradox.  People do not trust their consciousness and try to fix everything beyond its borders and at the same time consider human consciousness to be the most reliable controller.  But if a person is so unpredictable, and the mechanisms are so clear and reliable, why, for example, military directives prohibit the development of AI-systems without human control? <br><br>  Irrational pessimism in optimism? <br><br>  Control, the cornerstone of the paradox of modern progress, is the last thing we are ready to give to the external environment, although we do not trust it ourselves. <br><br><hr><br><img src="https://habrastorage.org/webt/xp/tn/1h/xptn1hmel73yqcyzeqirqvduwkq.jpeg"><br><br>  I am a pessimist in life, but I know that it is better to look at everything with optimism.  The more accessible the technology, the more everything is automated - the easier it is to live.  Problems will click like nuts.  I imagine optimism in relation to technology, like flying on an airplane.  To fly with comfort, you must believe that you will land.  This is easy, because the chances are very high.  But the slightest chance to break is always there.  And if the belief in him is overcome by optimism, the flight will turn into a nerveless hell. <br><br>  I believe that both optimism and pessimism around the influence of progress on us grows from the same place.  I gave an example with an airplane because I am an aerophobe.  I tried to understand my fear and realized that under it lies the fear of lack of control. <br><br>  I hated the primitiveness of my brain when the problem was solved with a simple psychological trick.  It was helped by an application that monitors the state of the aircraft and explains all its sounds, inclinations, etc., on the go.  Having received the illusion of control in the form of knowledge, I got rid of anxiety, having corrupted all my rationality and logic.  After all, from the fact that I know something, the chance to break is not reduced by a percentage, but it became psychologically easier for me. <br><br>  Fear of losing control and not having information is irrational.  People are generally divided into two types.  Those who in childhood slept face to the door to see the monster who enters it - and with their backs to the door, so as not to see it in any way.  Monster will eat you in both cases.  The only question is the amount of information received before the inevitable death, so that it is not so scary.  Although, what's the difference in the global sense? <br><br>  If I wanted to create an AI that should take control of a person, I would do everything to give the user the illusion of openness, understanding and control. <br><br>  And I think the thinking of modern Luddites and technophobes is built just on this irrational fear - not knowing enough.  Optimists are probably calm about the same thing.  They are sure that they will always know and control as much as is necessary to gain and live comfortably. <br><br>  Roughly speaking, if programming turns into an ordinary human conversation with a voice system, and it will actually work effectively - then why not?  A pessimist will say, ‚Äúhow do we know if the system understood well enough‚Äù.  The optimist will keep silent, show the effectively solved problem and throw the microphone. <br><br><hr><br><img src="https://habrastorage.org/webt/ky/y_/l4/kyy_l4sk4nwn1uohz7lxepbd7mg.jpeg"><br><br>  The fear of a lack of knowledge lies in the understanding that knowledge exists, but it will not be possible to recognize it.  After all, not knowing what you do not know is not so scary. <br><br>  In 1984, Thomas Pynchon wrote an essay " <a href="http://pollen-press.ru/2017/11/07/is-it-o-k-to-be-a-luddite/">Is it Normal to Be a Luddite</a> " and even then said that the source of ignorance is too much of a stream of knowledge. <br><blockquote>  In today's world, anyone who has the time, competence and money to pay for access can reach out to any specialized knowledge that he or she may need.  The problem, in fact, is how to find time to read something outside of your own specialization. </blockquote><br>  In the text, Pynchon understands how the fear of technology has changed over time.  After the workers 'strikes (hence the name ‚ÄúLuddites‚Äù), who smashed the looms for taking their work, technophobia was best recorded in the writers' books.  After all, writers, unlike scientists, think that ignorance is unremovable, and there are a lot of things around that they will never understand.  Scientists at every moment know exactly what will allow to learn even more in the future.  That is, the disclosure of absolutely all knowledge is a matter of time.  If it's very rude - the writers think that they have no control, scientists think that they control just as much as they need to take control even more. <br><br>  In the days when pogroms and the industrial revolution were a hot topic, Mary Shelley wrote the novel Frankenstein, or Modern Prometheus.  Speaking with great stretch, this is the first science fiction, and immediately how the scientist was killed by his creation (sorry for the spoiler). <br><br>  Since then, in science fiction books about technology, pessimism and optimism have constantly changed, because flying into space is cool, and nuclear bombing is bad ‚Äî but all are the results of modern progress.  Over time, the writers' technophobia turned from horror into something more and more strange.  Whether from the realization that they were wrong, and technology does not need to be afraid.  Whether on the contrary - because everything is already lost, the points of no return have been passed, and pessimism turns into a feeling of hopelessness. <br><blockquote>  Will mainframes attract as much hostile attention as weaving machines?  I strongly doubt it.  Writers of all kinds in a panic run to get their own word processors.  The machines have already become so user-friendly that even the most unadapted of the Luddites can be so enchanted by them that they set aside an old sledge hammer and knock on the keys instead. <br><br>  With proper allocation of budget and computer time, we will be able to cure cancer, save humanity from nuclear annihilation, grow food [which is enough] for all, neutralize the effects of environmental pollution by the hawking industry - in short, we realize all the sad dream dreams of our time. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If our world survives, there will be another big challenge that you should pay attention to: you will hear it for the first time when all the research and development curves in the field of artificial intelligence, molecular biology and robotics come together. </font><font style="vertical-align: inherit;">Just think about it! </font><font style="vertical-align: inherit;">It will be surprising and unpredictable, and even the greatest bosses, on which we sincerely hope, will be caught off guard. </font><font style="vertical-align: inherit;">This will certainly be something that all approximate Luddites will look forward to if, God willing, we will live to this point.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">That is, the fear of technophobes has become not just a sense of hopelessness, but a gloating expectation when scientists stay with their noses. </font><font style="vertical-align: inherit;">When greed to knowledge and self-confidence will stand all sideways.</font></font><br><br><hr><br><img src="https://habrastorage.org/webt/l8/zo/a_/l8zoa__eab9ry5spfcb7hx1wakw.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pessimism, which is lost, now seems like a lot of madmen who do not understand anything (if you are a technophobe, go live in the forest and do not bother me). He turned into the opinion "we want the best, but we will do as always." But it‚Äôs customary to think about the points of no return in the future tense. To think that they have already been passed, especially at a time when not only computers, even writing, were not at all wild and pointless. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Such an unpopular opinion was expressed by the anthropologist Yuval Noi Harari in the book Sapiens: A Brief History of Humanity. According to him, we invented our Tralfamadorsky super engine ten thousand years ago, when we carried out an agrarian revolution, and since then our evolution has gone in the opposite direction. Allegedly, a man-collector had the most developed brain in history, he lived much more comfortable and happier.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But then he planted wheat and became dependent on her. </font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The agrarian revolution was by no means the beginning of a new, easy life ‚Äî it was much harder and sometimes more hungry for the ancient farmers than for the collectors. </font><font style="vertical-align: inherit;">Hunters and gatherers led a healthier lifestyle, didn‚Äôt work so hard, found more varied and enjoyable occupations, less often suffered from hunger and disease. </font><font style="vertical-align: inherit;">Thanks to the agrarian revolution, the total amount of food consumed by mankind has certainly increased, but more food is not necessarily a more beneficial diet. </font><font style="vertical-align: inherit;">No, as a result there was a population explosion and an elite arose, but the average cattle farmer or farmer worked more and ate worse than the average hunter or collector. </font><font style="vertical-align: inherit;">The agrarian revolution is the greatest scam in history.</font></font><br><br>        .          .           ‚Äì ,    ,      .   : ¬´,  .      !    -  .       . - !¬ª <br><br>          ‚Äì  ,  - , ‚Äì        -             . </blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But according to Harari, the ancient people who planted her trapped not themselves. At the first farmers everything was fine, they really simplified their lives and brought comfort to which their ancestors sought for centuries. It became a trap for their great-great-great-great-grandchildren who have already lost the qualities of their ancestors to live and so, and so and choose the best. They had only farming left, and they gradually fell into captivity of all the shortcomings of the new way of life.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The theory is speculative, strained and full of speculation. And it is possible that the creation of a super automated system, which in the distant future will solve all the problems of our descendants, will be considered harmful by the same forcing. But we will create it anyway. Because progress, productivity and constant growth are the new religion and meaning of our atheistic time. And if now we are getting better and better, then why worry for nothing? We still think that a little bit more and everything will be perfect. We just need a little more work. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But if optimism is muffled for a second, and a solutionist ‚Äúis solved by the technology that solves the problems that they themselves create‚Äù - what will happen? Nothing but, perhaps, the realization that you are not going on your own, but are dragging you behind a speeding train.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A little thought experiment. Imagine that you saw the future, and you know that in a hundred years the technology will get out of control, that the super-engine will blow up the universe during trials (or at least turn descendants into underdeveloped idiots). Will you change something? Would you give up on technology development? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Or a couple of details. If you really had a huge impact on progress, would you stop it in this case? If so, would you be embarrassed by the idea that your choice is already recorded in the timeline? What influence on the future does not exist? That knowledge does not really give control - it is simply knowledge for the sake of knowing that, in global terms, it will only give passive contemplation of the monster entering the room.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When I try to answer myself, I feel only stiffness. </font><font style="vertical-align: inherit;">This is how to find out about the crash of the plane in which you are already flying. </font><font style="vertical-align: inherit;">The best thing to do is not to shout in panic, but to order vodka and smoke, although it is forbidden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A large part of our lives is humility with an inexplicable existence. </font><font style="vertical-align: inherit;">Everything will be easier if you just make an effort and consciously decide to enjoy this far from endless attraction. </font><font style="vertical-align: inherit;">After all, it is always good to think about something, you come to the same thing: it is better to not think about it.</font></font></div><p>Source: <a href="https://habr.com/ru/post/443304/">https://habr.com/ru/post/443304/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../443292/index.html">Flexible preloader using em units</a></li>
<li><a href="../443294/index.html">What is allowed by Jupyter?</a></li>
<li><a href="../443298/index.html">Wireless charger. How does it work in practice</a></li>
<li><a href="../443300/index.html">How is the development of United Traders</a></li>
<li><a href="../443302/index.html">How Apple is preparing for the era after the iPhone</a></li>
<li><a href="../443306/index.html">Eight named laws in UX design (part 1)</a></li>
<li><a href="../443308/index.html">Myths of modern physics. Conservation laws</a></li>
<li><a href="../443310/index.html">Bellabeat Women Wellness Gadget Review</a></li>
<li><a href="../443312/index.html">Python memory management</a></li>
<li><a href="../443314/index.html">What is Cordentity? [Translation of the article]</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>