<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Making a machine learning project in Python. Part 1</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Translation of A Complete Machine Learning Project Walkthrough in Python: Part One . 

 When you read a book or listen to a training course on data an...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Making a machine learning project in Python. Part 1</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/5de/fed/62e/5defed62ea348f6e02365e283415b2fb.png"><br><br>  <i>Translation of <a href="https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420">A Complete Machine Learning Project Walkthrough in Python: Part One</a> .</i> <br><br>  When you read a book or listen to a training course on data analysis, there is often a feeling that there are some parts of a picture that do not come together in front of you.  You may be intimidated by the prospect of taking the next step and completely solving some problem using machine learning, but with the help of this series of articles you will gain confidence in the ability to solve any problem in the field of data science. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In order to finally create a complete picture in your head, we suggest that you analyze the project of using machine learning using real data from beginning to end. <br><a name="habracut"></a><br>  Let's go through the stages: <br><br><ol><li>  Cleaning and formatting data. </li><li>  Exploratory data analysis. </li><li>  Design and selection of features. </li><li>  Comparison of metrics of several machine learning models. </li><li>  Hyperparametric adjustment of the best model. </li><li>  Evaluate the best model on the test dataset. </li><li>  Interpreting the results of the model. </li><li>  Conclusions and work with documents. </li></ol><br>  You will learn how the stages go into one another and how to implement them in Python.  <a href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough">The whole project</a> is available on GitHub, the first part is <a href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%2520Learning%2520Project%2520Part%25201.ipynb">here.</a>  In this article we will look at the first three stages. <br><br><h2>  Task Description </h2><br>  Before writing code, you need to understand the problem being solved and the available data.  In this project, we will be working with shared <a href="http://www.nyc.gov/html/gbee/html/plan/ll84_scores.shtml">energy efficiency data for buildings</a> in New York. <br><br>  Our goal is to use the available data to build a model that predicts the amount of Energy Star Score for a particular building, and interpret the results to find the factors that affect the final score. <br><br>  The data already includes Energy Star Score scores, so our task is machine learning with controlled regression: <br><br><ul><li>  Managed (Supervised): we know the signs and the goal, and our task is to train a model that can match the first with the second. </li><li>  Regression: The Energy Star Score is a continuous variable. </li></ul><br>  Our model must be accurate - so that it can predict the value of the Energy Star Score close to true, and interpreted - so that we can understand its predictions.  Knowing the target data, we can use it when making decisions as we go deeper into the data and create a model. <br><br><h2>  Data cleansing </h2><br>  Not every dataset is a perfectly matched set of observations, without anomalies and missing values ‚Äã‚Äã(hint of datasets <a href="http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html">mtcars</a> and <a href="https://archive.ics.uci.edu/ml/datasets/iris">iris</a> ).  There is little order in real data, so before proceeding with the analysis, they need to be <a href="https://www.springboard.com/blog/data-wrangling/">cleaned and brought</a> to an acceptable format.  Data cleansing is an unpleasant, but mandatory procedure for solving most data analysis tasks. <br><br>  First, you can load data as a Pandas data frame (dataframe) and examine it: <br><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np # <span class="hljs-keyword"><span class="hljs-keyword">Read</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">into</span></span> a dataframe data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'data/Energy_and_Water_Data_Disclosure_for_Local_Law_84_2017__Data_for_Calendar_Year_2016_.csv'</span></span>) # Display top <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> dataframe data.head()</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/4ac/637/b86/4ac637b8682b2fcacddd155004681a0d.png"><br>  <i>This is the real data.</i> <br><br>  This is a fragment of a table of 60 columns.  Even here there are several problems: we need to predict <code>Energy Star Score</code> , but we do not know what all these columns mean.  Although this is not necessarily a problem, because it is often possible to create an exact model without knowing anything about variables at all.  But interpretability is important to us, so you need to figure out the value of at least a few columns. <br><br>  When we received this data, we did not ask about the values, but looked at the file name: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a86/c00/ab2/a86c00ab2d64629e644e7186c78724f7.png"><br><br>  and decided to search for "Local Law 84".  We found <a href="http://www.nyc.gov/html/gbee/html/plan/ll84.shtml">this page</a> , which said that we are talking about the law in force in New York, according to which the owners of all buildings of a certain size must report on energy consumption.  Further search helped find <a href="http://www.nyc.gov/html/gbee/downloads/misc/nyc_benchmarking_disclosure_data_definitions_2017.pdf">all the values ‚Äã‚Äãof the columns</a> .  So do not neglect the file names, they can be a good starting point.  In addition, this is a reminder that you do not hurry and do not miss something important! <br><br>  We will not study all the columns, but we‚Äôll just look at the Energy Star Score, which is described as follows: <br><br><blockquote>  The ranking is based on percentiles from 1 to 100, which is calculated based on the energy consumption reports for the year independently filled in by the building owners.  <a href="https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/interpret-your-results/what">Energy Star Score</a> is a relative measure used to compare the energy efficiency of buildings. </blockquote><br>  The first problem was solved, but the second remained - missing values ‚Äã‚Äãmarked as ‚ÄúNot Available‚Äù.  This is a string value in Python, which means that even strings with numbers will be stored as <code>object</code> data types, because if there is a string in the column, Pandas converts it into a column that consists entirely of strings.  The types of data columns can be found using the <code>dataframe.info()</code> method: <br><br><pre> <code class="hljs pgsql"># See the <span class="hljs-keyword"><span class="hljs-keyword">column</span></span> data <span class="hljs-keyword"><span class="hljs-keyword">types</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> non-missing <span class="hljs-keyword"><span class="hljs-keyword">values</span></span> data.<span class="hljs-keyword"><span class="hljs-keyword">info</span></span>()</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/db3/b4d/013/db3b4d013ca25d7e5ac483f0c24fa1e4.png"><br><br>  Certainly some columns that explicitly contain numbers (for example, ft¬≤) are saved as objects.  We cannot apply numerical analysis to string values, so we convert them into numeric data types (especially <code>float</code> )! <br><br>  This code first replaces all ‚ÄúNot Available‚Äù with <i>not a number</i> ( <code>np.nan</code> ), which can be interpreted as numbers, and then converts the contents of certain columns into the <code>float</code> type: <br><br><pre> <code class="hljs pgsql"># Replace <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> occurrences <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Not</span></span> Available <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> a number data = data.replace({<span class="hljs-string"><span class="hljs-string">'Not Available'</span></span>: np.<span class="hljs-keyword"><span class="hljs-keyword">nan</span></span>}) # Iterate through the <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> list(data.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>): # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> that should be <span class="hljs-type"><span class="hljs-type">numeric</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-string"><span class="hljs-string">'ft¬≤'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-string"><span class="hljs-string">'kBtu'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-string"><span class="hljs-string">'Metric Tons CO2e'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-string"><span class="hljs-string">'kWh'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-string"><span class="hljs-string">'therms'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-string"><span class="hljs-string">'gal'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> <span class="hljs-string"><span class="hljs-string">'Score'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> col): # Convert the data <span class="hljs-keyword"><span class="hljs-keyword">type</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-type"><span class="hljs-type">float</span></span> data[col] = data[col].astype(<span class="hljs-type"><span class="hljs-type">float</span></span>)</code> </pre> <br>  When the values ‚Äã‚Äãin the corresponding columns become numbers, we can begin to explore the data. <br><br><h4>  Missing and anomalous data </h4><br>  Along with incorrect data types, one of the most common problems is missing values.  They can be absent for various reasons, and before training the model, these values ‚Äã‚Äãmust either be filled in or deleted.  First, let's find out how much we lack in each column (the <a href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%2520Learning%2520Project%2520Part%25201.ipynb">code is here</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b0/5da/a40/0b05daa40ba77acca25ed859856759f2.png"><br>  <i>To create a table, a function from a branch on <u>StackOverflow is used</u> .</i> <br><br>  It is always necessary to remove information with caution, and if there are no many values ‚Äã‚Äãin the column, then it probably will not benefit our model.  The threshold after which it is better to throw out the columns depends on your task ( <a href="https://discuss.analyticsvidhya.com/t/what-should-be-the-allowed-percentage-of-missing-values/2456">here is a discussion</a> ), and in our project we will delete columns that are more than half empty. <br><br>  Also at this stage it is better to remove the anomalous values.  They may occur due to typos during data entry or due to errors in the units of measurement, or they may be correct but extreme values.  In this case, we will remove the "extra" values, guided by the <a href="https://www.itl.nist.gov/div898/handbook/prc/section1/prc16.htm">definition of extreme anomalies</a> : <br><br><ul><li>  Below the first quartile - 3 ‚àó interquartile range. </li><li>  Above the third quartile + 3 ‚àó interquartile range. </li></ul><br>  The code that removes columns and anomalies is shown in a notebook on Github.  Upon completion of the data cleansing process and the removal of anomalies, we have more than 11,000 buildings and 49 signs left. <br><br><h2>  Exploratory data analysis </h2><br>  A boring, but necessary stage of data cleaning is over, you can proceed to the study!  <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D0%25B7%25D0%25B2%25D0%25B5%25D0%25B4%25D0%25BE%25D1%2587%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B0%25D0%25BD%25D0%25B0%25D0%25BB%25D0%25B8%25D0%25B7_%25D0%25B4%25D0%25B0%25D0%25BD%25D0%25BD%25D1%258B%25D1%2585">Exploratory data analysis</a> (AHR) is a time-unlimited process, during which we calculate statistics and look for trends, anomalies, patterns, or relationships in the data. <br><br>  In short, AHRF is an attempt to figure out what the data can tell us.  Usually the analysis begins with a superficial review, then we find interesting fragments and analyze them in more detail.  The findings may be interesting in their own right, or they may contribute to the choice of model, helping to decide which signs we will use. <br><br><h4>  Single variable charts </h4><br>  Our goal is to predict the value of the Energy Star Score (renamed ‚Äú <code>score</code> ‚Äù in our data), so it makes sense to start by examining the distribution of this variable.  A histogram is a simple but effective way to visualize the distribution of a single variable, and it can be easily constructed using <code>matplotlib</code> . <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt # Histogram <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> the Energy Star Score plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.hist(data[<span class="hljs-string"><span class="hljs-string">'score'</span></span>].dropna(), bins = <span class="hljs-number"><span class="hljs-number">100</span></span>, edgecolor = <span class="hljs-string"><span class="hljs-string">'k'</span></span>); plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Score'</span></span>); plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Number of Buildings'</span></span>); plt.title(<span class="hljs-string"><span class="hljs-string">'Energy Star Score Distribution'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/f82/bf3/84a/f82bf384af1bd0c407f1e680d0b47263.png"><br><br>  It looks suspicious!  The Energy Star Score is a percentile, so you should expect a uniform distribution when each score is assigned to the same number of buildings.  However, a higher and lower number of buildings received a disproportionately large number of buildings (for Energy Star Score, the more, the better). <br><br>  If we look again at the definition of this score, we will see that it is calculated on the basis of ‚Äúself-filled in by building owners of reports‚Äù, which may explain the excess of very large values.  Asking building owners to report their energy use is like asking students to report their grades in exams.  So this is probably not the most objective criterion for assessing the energy efficiency of real estate. <br><br>  If we had an unlimited supply of time, it would be possible to find out why so many buildings received very high and very low scores.  To do this, we would have to select the appropriate buildings and carefully analyze them.  But we only need to learn how to predict points, and not to develop a more accurate assessment method.  You can mark yourself that the points have a suspicious distribution, but we will focus on forecasting. <br><br><h4>  Relationship Search </h4><br>  The main part of the AHRF is the search for interrelations between signs and our goal.  The variables that correlate with it are useful for use in the model because they can be used for prediction.  One way to study the effect of the categorical variable (which accepts only a limited set of values) on the goal is to plot the density using the Seaborn library. <br><br>  <a href="https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0">The density graph can be considered a flattened histogram</a> , because it shows the distribution of a single variable.  You can color individual classes on the graph to see how the categorical variable changes the distribution.  This code builds the Energy Star Score density chart, colored according to the building type (for a list of buildings with more than 100 measurements): <br><br><pre> <code class="hljs pgsql"># <span class="hljs-keyword"><span class="hljs-keyword">Create</span></span> a list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> buildings <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> more than <span class="hljs-number"><span class="hljs-number">100</span></span> measurements <span class="hljs-keyword"><span class="hljs-keyword">types</span></span> = data.dropna(subset=[<span class="hljs-string"><span class="hljs-string">'score'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">types</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">types</span></span>[<span class="hljs-string"><span class="hljs-string">'Largest Property Use Type'</span></span>].value_counts() <span class="hljs-keyword"><span class="hljs-keyword">types</span></span> = list(<span class="hljs-keyword"><span class="hljs-keyword">types</span></span>[<span class="hljs-keyword"><span class="hljs-keyword">types</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">values</span></span> &gt; <span class="hljs-number"><span class="hljs-number">100</span></span>].<span class="hljs-keyword"><span class="hljs-keyword">index</span></span>) # Plot <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> distribution <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> scores <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> building categories figsize(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) # Plot <span class="hljs-keyword"><span class="hljs-keyword">each</span></span> building <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b_type <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">types</span></span>: # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> the building <span class="hljs-keyword"><span class="hljs-keyword">type</span></span> subset = data[data[<span class="hljs-string"><span class="hljs-string">'Largest Property Use Type'</span></span>] == b_type] # Density plot <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> Energy Star Scores sns.kdeplot(subset[<span class="hljs-string"><span class="hljs-string">'score'</span></span>].dropna(), label = b_type, shade = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, alpha = <span class="hljs-number"><span class="hljs-number">0.8</span></span>); # label the plot plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Energy Star Score'</span></span>, size = <span class="hljs-number"><span class="hljs-number">20</span></span>); plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Density'</span></span>, size = <span class="hljs-number"><span class="hljs-number">20</span></span>); plt.title(<span class="hljs-string"><span class="hljs-string">'Density Plot of Energy Star Scores by Building Type'</span></span>, size = <span class="hljs-number"><span class="hljs-number">28</span></span>);</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/23a/718/fd3/23a718fd3139123b609e2521ffe46e3c.png"><br><br>  As you can see, the type of building greatly affects the number of points.  Office buildings usually have a higher score, and hotels lower.  So you need to include the type of building in the model, because this feature affects our goal.  As a categorical variable, we must perform one-hot coding of the building type. <br><br>  A similar graph can be used to estimate the Energy Star Score by areas of the city: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/224/c69/820/224c69820a5c0362f804e37ae7d5de55.png"><br><br>  The area does not affect the score as much as the type of building.  Nevertheless, we will include it in the model, because there is a slight difference between the districts. <br><br>  To calculate the relationships between variables, you can use <a href="http://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/">the Pearson correlation coefficient</a> .  This is a measure of the intensity and direction of the linear relationship between two variables.  A value of +1 means a perfectly linear positive relationship, and -1 means a perfectly linear negative relationship.  Here are some examples of <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation coefficient</a> values: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b3/455/654/0b34556548ab206112024fb0e8f69c01.png"><br><br>  Although this coefficient cannot reflect non-linear dependencies, it is possible to begin an assessment of the interrelationships of variables.  In Pandas, you can easily calculate correlations between any columns in a data frame (dataframe): <br><br><pre> <code class="hljs pgsql"># Find <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> correlations <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> the score <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> sort correlations_data = data.corr()[<span class="hljs-string"><span class="hljs-string">'score'</span></span>].sort_values()</code> </pre> <br>  The most negative correlations with the goal: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b62/181/178/b62181178669962fccf7caa472d9e2e8.png"><br><br>  and the most positive ones: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/598/47f/14a/59847f14a4d8afe1ce8ff237c5d3fa36.png"><br><br>  There are several strong negative correlations between the signs and the goal, and the largest of them belong to different EUI categories (methods for calculating these indicators differ slightly).  <a href="https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/what-energy">EUI (Energy Use Intensity</a> ) is the amount of energy consumed by a building divided by square foot square.  This specific value is used to assess energy efficiency, and the smaller it is, the better.  Logic dictates that these correlations are justified: if the EUI increases, then the Energy Star Score should decrease. <br><br><h4>  Two-variable charts </h4><br>  We use scatter diagrams to visualize the relationship between two continuous variables.  Additional information can be added to the point colors, for example, a categorical variable.  The following shows the relationship between the Energy Star Score and the EUI, the different building types are indicated in color: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/974/204/7de/9742047ded29c74a9a8e6df9bf6396d1.png"><br><br>  This graph allows you to visualize the correlation coefficient of -0.7.  As the EUI decreases, the Energy Star Score increases, this relationship is observed in buildings of different types. <br><br>  Our latest research schedule is called <a href="https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166">Pairs Plot</a> .  This is a great tool to see the relationships between different pairs of variables and the distribution of single variables.  We will use the Seaborn library and the PairGrid function to create a pairwise graph with a scatter diagram in the upper triangle, with a histogram diagonally, a two-dimensional kernel density diagram, and correlation coefficients in the lower triangle. <br><br><pre> <code class="hljs pgsql"># Extract the <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> plot plot_data = features[[<span class="hljs-string"><span class="hljs-string">'score'</span></span>, <span class="hljs-string"><span class="hljs-string">'Site EUI (kBtu/ft¬≤)'</span></span>, <span class="hljs-string"><span class="hljs-string">'Weather Normalized Source EUI (kBtu/ft¬≤)'</span></span>, <span class="hljs-string"><span class="hljs-string">'log_Total GHG Emissions (Metric Tons CO2e)'</span></span>]] # Replace the inf <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">nan</span></span> plot_data = plot_data.replace({np.inf: np.<span class="hljs-keyword"><span class="hljs-keyword">nan</span></span>, -np.inf: np.<span class="hljs-keyword"><span class="hljs-keyword">nan</span></span>}) # <span class="hljs-keyword"><span class="hljs-keyword">Rename</span></span> <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> plot_data = plot_data.<span class="hljs-keyword"><span class="hljs-keyword">rename</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> = {<span class="hljs-string"><span class="hljs-string">'Site EUI (kBtu/ft¬≤)'</span></span>: <span class="hljs-string"><span class="hljs-string">'Site EUI'</span></span>, <span class="hljs-string"><span class="hljs-string">'Weather Normalized Source EUI (kBtu/ft¬≤)'</span></span>: <span class="hljs-string"><span class="hljs-string">'Weather Norm EUI'</span></span>, <span class="hljs-string"><span class="hljs-string">'log_Total GHG Emissions (Metric Tons CO2e)'</span></span>: <span class="hljs-string"><span class="hljs-string">'log GHG Emissions'</span></span>}) # <span class="hljs-keyword"><span class="hljs-keyword">Drop</span></span> na <span class="hljs-keyword"><span class="hljs-keyword">values</span></span> plot_data = plot_data.dropna() # <span class="hljs-keyword"><span class="hljs-keyword">Function</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> calculate correlation coefficient <span class="hljs-keyword"><span class="hljs-keyword">between</span></span> two <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(<span class="hljs-number"><span class="hljs-number">.2</span></span>, <span class="hljs-number"><span class="hljs-number">.8</span></span>), xycoords=ax.transAxes, size = <span class="hljs-number"><span class="hljs-number">20</span></span>) # <span class="hljs-keyword"><span class="hljs-keyword">Create</span></span> the pairgrid <span class="hljs-keyword"><span class="hljs-keyword">object</span></span> grid = sns.PairGrid(data = plot_data, size = <span class="hljs-number"><span class="hljs-number">3</span></span>) # Upper <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a scatter plot grid.map_upper(plt.scatter, color = <span class="hljs-string"><span class="hljs-string">'red'</span></span>, alpha = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) # Diagonal <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a histogram grid.map_diag(plt.hist, color = <span class="hljs-string"><span class="hljs-string">'red'</span></span>, edgecolor = <span class="hljs-string"><span class="hljs-string">'black'</span></span>) # Bottom <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> correlation <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> density plot grid.map_lower(corr_func); grid.map_lower(sns.kdeplot, cmap = plt.cm.Reds) # Title <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entire plot plt.suptitle(<span class="hljs-string"><span class="hljs-string">'Pairs Plot of Energy Data'</span></span>, size = <span class="hljs-number"><span class="hljs-number">36</span></span>, y = <span class="hljs-number"><span class="hljs-number">1.02</span></span>);</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/5fa/4cc/94f/5fa4cc94f9b91df5ad4fda37aa3ae1f0.png"><br><br>  To see the relationship of variables, look for the intersection of rows and columns.  Suppose you need to look at the <code>Weather Norm EUI</code> correlation and <code>score</code> , then we look for the <code>Weather Norm EUI</code> series and the <code>score</code> column, at the intersection of which the correlation coefficient is -0.67.  These graphs not only look great, but also help to select variables for the model. <br><br><h2>  Design and selection of features </h2><br>  <a href="https://elitedatascience.com/feature-engineering-best-practices">Designing and selecting features</a> often brings the greatest return in terms of the time spent on machine learning.  First we give the definitions: <br><br><ul><li>  <a href="https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/">Designing traits: the</a> process of extracting or creating new traits from raw data.  To use variables in a model, you may have to convert, say, take the natural logarithm, or extract the square root, or apply one-hot coding of categorical variables.  Designing features can be viewed as creating additional features from raw data. </li><li>  <a href="https://machinelearningmastery.com/an-introduction-to-feature-selection/">Feature Selection: the</a> process of selecting the most relevant features from the data, during which we remove some features to help the model better summarize the new data for the sake of a more interpretable model.  The choice of signs can be considered as the removal of "excess", so that only the most important remains. </li></ul><br>  The machine learning model can only learn from the data we provide, so it is crucial to make sure that we include all the information relevant to our task.  If you do not provide the model with correct data, it will not be able to learn and will not produce accurate predictions! <br><br>  We will do the following: <br><br><ul><li>  Apply to categorical variables (quarter and type of property) one-hot coding. </li><li>  Add the taking of the natural logarithm of all numeric variables. </li></ul><br>  <a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f">One-hot coding is</a> necessary to include categorical variables in the model.  The machine learning algorithm will not be able to understand the type of ‚Äúoffice‚Äù, so if the building is office, we will assign it sign 1, and if not office, then 0. <br><br>  Adding transformed attributes will help the model learn about non-linear relationships within the data.  In data analysis, it is normal practice <a href="https://datascience.stackexchange.com/questions/21650/feature-transformation-on-input-data">to extract square roots, take natural logarithms, or somehow transform the signs</a> , it depends on the specific task or your knowledge of the best techniques.  In this case, we add the natural logarithm of all numeric characters. <br><br>  This code selects numeric attributes, calculates their logarithms, selects two categorical attributes, applies one-hot coding to them, and combines both sets into one.  Judging by the description, there is a lot of work to be done, but in Pandas everything is pretty simple! <br><br><pre> <code class="hljs pgsql"># <span class="hljs-keyword"><span class="hljs-keyword">Copy</span></span> the original data features = data.<span class="hljs-keyword"><span class="hljs-keyword">copy</span></span>() # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> the <span class="hljs-type"><span class="hljs-type">numeric</span></span> <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> numeric_subset = data.select_dtypes(<span class="hljs-string"><span class="hljs-string">'number'</span></span>) # <span class="hljs-keyword"><span class="hljs-keyword">Create</span></span> <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">log</span></span> <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> <span class="hljs-type"><span class="hljs-type">numeric</span></span> <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> numeric_subset.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>: # Skip the Energy Star Score <span class="hljs-keyword"><span class="hljs-keyword">column</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> col == <span class="hljs-string"><span class="hljs-string">'score'</span></span>: next <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: numeric_subset[<span class="hljs-string"><span class="hljs-string">'log_'</span></span> + col] = np.log(numeric_subset[col]) # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> the categorical <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> categorical_subset = data[[<span class="hljs-string"><span class="hljs-string">'Borough'</span></span>, <span class="hljs-string"><span class="hljs-string">'Largest Property Use Type'</span></span>]] # One hot encode categorical_subset = pd.get_dummies(categorical_subset) # <span class="hljs-keyword"><span class="hljs-keyword">Join</span></span> the two dataframes <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> concat # Make sure <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> use axis = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">perform</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">column</span></span> bind features = pd.concat([numeric_subset, categorical_subset], axis = <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  We now have over 11,000 observations (buildings) with 110 columns (features).  Not all signs will be useful for predicting Energy Star Score, so let's take a choice of signs and remove some of the variables. <br><br><h4>  Feature selection </h4><br>  Many of the 110 signs available are redundant because they are strongly correlated with each other.  For example, here is a graph of the EUI and Weather Normalized Site EUI, in which the correlation coefficient is 0.997. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4ab/c4f/ad8/4abc4fad887ef202d8d40961a8b02c34.png"><br><br>  Signs that strongly correlate with each other are called <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D1%2583%25D0%25BB%25D1%258C%25D1%2582%25D0%25B8%25D0%25BA%25D0%25BE%25D0%25BB%25D0%25BB%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B0%25D1%2580%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">collinear</a> .  Removing one variable in such pairs of attributes often helps the <a href="https://www.quora.com/Why-is-multicollinearity-bad-in-laymans-terms-In-feature-selection-for-a-regression-model-intended-for-use-in-prediction-why-is-it-a-bad-thing-to-have-multicollinearity-or-highly-correlated-independent-variables">model to generalize and be more interpretable</a> .  Please note that this is a correlation of some signs with others, and not a correlation with a goal that would only help our model! <br><br>  There are a number of methods for calculating the collinearity of features, and one of the most popular is the <a href="http://www.statisticshowto.com/variance-inflation-factor/">variance inflation factor</a> .  We use the B-correlation coefficient (thebcorrelation coefficient) to find and remove collinear signs.  Drop one pair of signs if the correlation coefficient between them is greater than 0.6.  The code is in notepad (and in response to <a href="https://stackoverflow.com/a/43104383">Stack Overflow</a> ). <br><br>  This value looks arbitrary, but in fact I tried different thresholds, and the one above allowed me to create the best model.  Machine learning is <a href="http://www.dictionary.com/browse/empirical">empirical</a> , and one often has to experiment to find the best solution.  After choosing, we have 64 signs left and one goal. <br><br><pre> <code class="hljs pgsql"># Remove <span class="hljs-keyword"><span class="hljs-keyword">any</span></span> <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> na <span class="hljs-keyword"><span class="hljs-keyword">values</span></span> features = features.dropna(axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, how = <span class="hljs-string"><span class="hljs-string">'all'</span></span>) print(features.shape) (<span class="hljs-number"><span class="hljs-number">11319</span></span>, <span class="hljs-number"><span class="hljs-number">65</span></span>)</code> </pre> <br><h2>  Choose a baseline </h2><br>  We cleared the data, conducted an exploratory analysis, and constructed the signs.  And before proceeding to the creation of a model, you need to select the initial baseline (naive baseline) - a kind of assumption with which we will compare the results of the models.  If they are below the base level, we will assume that machine learning is not applicable to the solution of this problem, or that we need to try a different approach. <br><br>  For regression problems, as a baseline, it is reasonable to guess the median goal value on the training set for all examples in the test set.  These kits set a barrier that is relatively low for any model. <br><br>  As a metric, we take the <a href="https://en.wikipedia.org/wiki/Mean_absolute_error">average absolute error (mae)</a> in the predictions.  There are many other metrics for regressions, but I like the <a href="https://www.coursera.org/learn/machine-learning-projects/lecture/wIKkC/single-number-evaluation-metric">advice of</a> choosing one metric and evaluating models with it.  And the mean absolute error is easy to calculate and interpret. <br><br>  Before calculating the base level, you need to split the data into training and test suites: <br><br><ol><li>  The training set of features is that we provide our model along with the answers during the training.  The model must learn the consistency of the target. </li><li>  A test feature set is used to evaluate a trained model.  When she processes the test set, she does not see the correct answers and should predict based only on the available signs.  We know the answers for the test data and can compare the prediction results with them. </li></ol><br>  For training use 70% of the data, and for testing - 30%: <br><br><pre> <code class="hljs pgsql"># Split <span class="hljs-keyword"><span class="hljs-keyword">into</span></span> <span class="hljs-number"><span class="hljs-number">70</span></span>% training <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-number"><span class="hljs-number">30</span></span>% testing <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> X, X_test, y, y_test = train_test_split(features, targets, test_size = <span class="hljs-number"><span class="hljs-number">0.3</span></span>, random_state = <span class="hljs-number"><span class="hljs-number">42</span></span>)</code> </pre> <br>  Now we calculate the indicator for the original base level: <br><br><pre> <code class="hljs vhdl"># <span class="hljs-keyword"><span class="hljs-keyword">Function</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> calculate mean absolute <span class="hljs-literal"><span class="hljs-literal">error</span></span> def mae(y_true, y_pred): <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.mean(<span class="hljs-keyword"><span class="hljs-keyword">abs</span></span>(y_true - y_pred)) baseline_guess = np.median(y) print(<span class="hljs-symbol"><span class="hljs-symbol">'The</span></span> baseline guess <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a score <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> %<span class="hljs-number"><span class="hljs-number">0.2</span></span>f' % baseline_guess) print(<span class="hljs-string"><span class="hljs-string">"Baseline Performance on the test set: MAE = %0.4f"</span></span> % mae(y_test, baseline_guess))</code> </pre> <br>  <b>The baseline guess is a score of 66.00</b> <b><br></b>  <b>Baseline Performance on the test set: MAE = 24.5164</b> <br><br>  The average absolute error on the test set was about 25 points.  As we estimate in the range from 1 to 100, the error is 25% - a rather low barrier for the model! <br><br><h2>  Conclusion </h2><br>  You of this article went through the first three stages of solving a problem using machine learning.  After setting the problem, we: <br><br><ol><li>  Cleared and formatted raw data. </li><li>  Conducted an exploratory analysis to examine the available data. </li><li>  We developed a set of attributes that we will use for our models. </li></ol><br> ,    ,       . <br><br>  <a href="https://habr.com/company/nixsolutions/blog/425907/"> </a>     <a href="http://scikit-learn.org/stable/">Scikit-Learn</a>    ,        . </div><p>Source: <a href="https://habr.com/ru/post/425253/">https://habr.com/ru/post/425253/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../425243/index.html">The john willis handbook</a></li>
<li><a href="../425245/index.html">Preview RamblerFront & # 6</a></li>
<li><a href="../425247/index.html">Crowdsourcing Testing</a></li>
<li><a href="../425249/index.html">How is familiarity with the LLP at ITMO University: the course "Low-level programming"</a></li>
<li><a href="../425251/index.html">LoJax: the first known UEFI rootkit used in a malicious campaign</a></li>
<li><a href="../425255/index.html">Broo lossless compression algorithm and delta encoding, compared with Xdelta3. Home project development</a></li>
<li><a href="../425259/index.html">Backing up your site with git and a makefile</a></li>
<li><a href="../425261/index.html">EV certificates are dead</a></li>
<li><a href="../425263/index.html">IFEST festival will be held in Nizhny Novgorod</a></li>
<li><a href="../425265/index.html">Development rules in Yandex. Health</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>