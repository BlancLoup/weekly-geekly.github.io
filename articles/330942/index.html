<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The story of how cognitive technologies help preserve karma</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, we argued with one of my friends about whether to leave negative feedback and negatively evaluate someone‚Äôs work. For example, you come to t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The story of how cognitive technologies help preserve karma</h1><div class="post__text post__text-html js-mediator-article">  Recently, we argued with one of my friends about whether to leave negative feedback and negatively evaluate someone‚Äôs work.  For example, you come to the bank, and there you are a Naham consultant.  I am convinced that it is worth it, because without this assessment a person will continue to be rude.  A friend believes that this is a big minus in your karma, you can not offend people, they themselves will understand everything with time.  At about the same time, we had a hackfest for partners, where I saw a solution that could save the karma of each of us.  Sin is not to share.  As you may have guessed from the title, under the cut, we will focus on the development based on cognitive services. <br><br><img src="https://habrastorage.org/web/78c/17d/366/78c17d366cee42f486e18e9d796a7391.jpg"><br><a name="habracut"></a><br><h2>  Introduction </h2><br>  There should be a text from the series ‚Äúyou know how important it is for any company to evaluate the quality of service is the basis of development‚Äù.  In my opinion, these are quite commonplace truths, so we‚Äôll omit them. <br><br><h2>  Save karma, inexpensive </h2><br>  The <a href="https://heedbook.com/">Heedbook</a> service, which I will talk about today, has one very cool advantage over other ways of evaluating the work of employees with customers - this is an automatic assessment of a client's emotions in real time.  That is, returning to my friend, his tolerance will not save the consultant from a real evaluation of the work.  And the wolves are fed, and the sheep are safe, and the karma of a friend too. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  How it works: </h4><br>  1. A front-line employee of a bank (or a pharmacy, or a MFC, or a store, or similar enterprises) at the beginning of the working day enters the system through a browser. <br>  2. A client comes to him, for example, my friend. <br>  3. The system receives and analyzes the video stream from a webcam in real time in the background. <br>  4. Information is processed by the systems of intellectual recognition of emotions, speech and other parameters of the client. <br>  5. According to the results of the analysis, the system provides detailed analytics on the structure of emotions and the proportion of positive / negative emotions of the client, the attention of the client to the employee, the content of the dialogue, the use of the script service or prohibited phrases. <br>  6. The head of the office and the employees of the parent company receive detailed information about the quality of customer service in the context of managers and clients.  (And here we see how our consultant begins to get nervous.)) <br><br>  In addition to the above, for each employee, the average customer service time, the number of customers served, the structure of the client base by demographic indicators are determined. <br><br><img src="https://habrastorage.org/web/0e0/b7a/e84/0e0b7ae8494f43258a239a2dd848af40.jpg"><br><br>  Another interesting feature is that the director can connect to the video stream from the workstations of the front-line employees, as well as watch the video recordings of the conversations later with detailed analytics on them.  That is, a new scenario is added to our history when the consultant begins to be rude to my friend, and then suddenly his eyes are rounded and he becomes sweet and polite.  ) <br><br><img src="https://habrastorage.org/web/dee/cdb/6b8/deecdb6b84f74b2e9d9f837107ac1230.png"><br><br>  Well and the last interesting detail, in Heedbook there is a rating system for employees. <br><br><h2>  How it works: through the eyes of the developer </h2><br><h4>  Azure Functions Microservice Architecture </h4><br>  Together with Dima Soshnikov, we partially helped the guys in designing the solution.  The first thing we did was decide to leave the monolithic architecture and make a system built on microservices (as you can see from my last articles, in my opinion this is a very interesting topic).  For this, <a href="https://azure.microsoft.com/ru-ru/services/functions/">Azure Functions were used</a> .  In fact, we also thought about WebJob, but it has performance limitations and pricing is not based on the number of operations performed. <br><br>  The main AF development environment is the online feature editor on the Azure portal.  Also, from the end of May 2017, you can create AF using Visual Studio 2017 UPD 3. <br><br>  Since AF is a new Microsoft product, there is no complete documentation on it yet, therefore we will analyze an example of one AF project from Heedbook below.  This will save time if you decide to build an Azure based microservice architecture. <br><br>  The trigger for triggering AF can be an Http request, the appearance of Blob in Azure Blob storage, actions in OneDrive, or just a timer.  The project implemented almost all the above options for AF triggers.  We also implemented AF cascades when the work of one AF starts another, thus providing a single business data analysis process. <br><br>  An example of our AF is triggered by the appearance of a blob - pictures.  With this AF, we will determine the number of people in the picture and their emotions.  We do this using the cognitive service <a href="https://azure.microsoft.com/ru-ru/services/cognitive-services/face/">Microsoft Face API</a> . <br><br>  First you need to connect the necessary libraries of cognitive services.  For the AF online editor, you will have to do this manually by creating the project.json file and writing all the necessary dependencies there: <br><br><pre><code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"frameworks"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"net46"</span></span>:{ <span class="hljs-attr"><span class="hljs-attr">"dependencies"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"Microsoft.ProjectOxford.Common"</span></span>: <span class="hljs-string"><span class="hljs-string">"1.0.324"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"Microsoft.ProjectOxford.Face"</span></span>: <span class="hljs-string"><span class="hljs-string">"1.2.5"</span></span> } } } }</code> </pre> <br>  In the case of creating AF in Visual Studio 2017 UPD 3, we simply connect the necessary dependencies using Nuget. <br><br>  Next we need to register the AF trigger and output parameters.  In our case, this is the appearance of a blob in a specific container and the recording of the recognition results in the Azure MsSql table.  This is done in the function.json file: <br><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"bindings"</span></span>: [ { <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"InputFace"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"blobTrigger"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"direction"</span></span>: <span class="hljs-string"><span class="hljs-string">"in"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"path"</span></span>: <span class="hljs-string"><span class="hljs-string">"frames/{name}"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"connection"</span></span>: <span class="hljs-string"><span class="hljs-string">"heedbookhackfest_STORAGE"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"apiHubTable"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"FaceData"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"dataSetName"</span></span>: <span class="hljs-string"><span class="hljs-string">"default"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"tableName"</span></span>: <span class="hljs-string"><span class="hljs-string">"FaceEmotionGuid"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"connection"</span></span>: <span class="hljs-string"><span class="hljs-string">"sql_SQL"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"direction"</span></span>: <span class="hljs-string"><span class="hljs-string">"out"</span></span> } ], <span class="hljs-attr"><span class="hljs-attr">"disabled"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }</code> </pre><br>  So, the Azure Functions code itself! <br><br><pre> <code class="cs hljs"><span class="hljs-meta"><span class="hljs-meta">#r "System.IO" using System.IO; using Microsoft.ProjectOxford.Face; using Microsoft.ProjectOxford.Common.Contract; public static async Task Run(Stream InputFace, string name, IAsyncCollector&lt;FaceEmotion&gt; FaceData, TraceWriter log) { log.Info($"Processing face {name}"); var namea = Path.GetFileNameWithoutExtension(name).Split('-'); var cli = new FaceServiceClient(&lt;Face_Api_Key&gt;); var res = await cli.DetectAsync(InputFace,false,false,new FaceAttributeType[] { FaceAttributeType.Age, FaceAttributeType.Emotion, FaceAttributeType.Gender}); var fc = (from f in res orderby f.FaceRectangle.Width select f).FirstOrDefault(); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (fc!=null) { var R = new FaceEmotion(); R.Time = DateTime.ParseExact(namea[1],"yyyyMMddHHmmss",System.Globalization.CultureInfo.InvariantCulture.DateTimeFormat); R.DialogId = int.Parse(namea[0]); var t = GetMainEmotion(fc.FaceAttributes.Emotion); R.EmotionType = t.Item1; R.FaceEmotionGuidId = Guid.NewGuid(); R.EmotionValue = (int)(100*t.Item2); R.Sex = fc.FaceAttributes.Gender.ToLower().StartsWith("m"); R.Age = (int)fc.FaceAttributes.Age; await FaceData.AddAsync(R); log.Info($" - recorded face, age={fc.FaceAttributes.Age}, emotion={R.EmotionType}"); } </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> log.Info(" - no faces found"); } public static Tuple&lt;string,float&gt; GetMainEmotion(EmotionScores s) { float m = 0; string e = ""; foreach (var p in s.GetType().GetProperties()) { </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> ((float)p.GetValue(s)&gt;m) { m = (float)p.GetValue(s); e = p.Name; } } return new Tuple&lt;string,float&gt;(e,m); } public class FaceEmotion { public Guid FaceEmotionGuidId { get; set; } public DateTime Time { get; set; } public string EmotionType { get; set; } public float EmotionValue { get; set; } public int DialogId { get; set; } public bool Sex { get; set; } public int Age { get; set; } }</span></span></code> </pre><br>  In this case, it is an asynchronous procedure in conjunction with the Cognitive Services Face API.  AF receives a blob Stream and sends it to CS: <br><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> res = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> cli.DetectAsync(InputFace,<span class="hljs-literal"><span class="hljs-literal">false</span></span>,<span class="hljs-literal"><span class="hljs-literal">false</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FaceAttributeType[] { FaceAttributeType.Age, FaceAttributeType.Emotion, FaceAttributeType.Gender});</code> </pre><br>  Next, selects the largest person in the frame: <br><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> fc = (<span class="hljs-keyword"><span class="hljs-keyword">from</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res <span class="hljs-keyword"><span class="hljs-keyword">orderby</span></span> f.FaceRectangle.Width <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> f).FirstOrDefault();</code> </pre><br>  And writes the recognition results to the database: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">await</span></span> FaceData.AddAsync(R);</code> </pre><br>  It's simple, isn't it?  The future is microservices.  ) <br><br><h2>  About problems </h2><br>  Okay, not so simple, in fact. <br><br>  AF, unfortunately, currently has a number of restrictions (the binding of names does not work, there are library conflicts).  Fortunately, there is always a lot of walkarround in the .Net development world ‚Äî and if you don‚Äôt manage to solve a problem in a basic scenario, you can find several workarounds. <br><br><h4>  Shooting video and audio in the background </h4><br>  As you know, modern OSs try to save battery life as much as possible, stopping the proactive work of all applications that are in the background.  This also applies to streaming in a web, mobile or desktop application.  Having spent a long prospecting work on this issue.  we chose a web solution. <br><br>  We get video and audio stream from a webcam using <code>GetUserMedia()</code> .  Next, we have to record the received video and audio stream and extract data from there for transfer to the backend.  This works if the browser window is constantly active, as soon as you bookmark a browser as inactive, it becomes inaccessible for recording data.  Our task was to make a system that will work in the background and will not interfere with the employee to perform their direct duties.  Therefore, the decision was to create our own stream variable, where we record and extract data of the video and audio stream. <br><br><h4>  The quality of recognition of the Russian language </h4><br>  In the future, the service will move towards creating its own models of audio recognition, but currently it is necessary to use external providers of Russian language recognition services.  It was difficult to choose a good service that provides high-quality speech recognition in Russian.  The current configuration of the system uses a combination of speech recognition systems, Goolge Speech Api is used for Russian speech, in testing it has shown the best recognition quality results. <br><br><h2>  Back to reality </h2><br>  In fact, this decision is not just a fairy tale about the future.  In the near future, Heedbook will start working in the Moscow region MFC and the country's largest bank. <br><br>  The Heedbook team will appreciate comments on their decisions, and will also be glad to collaborate with professionals in the field of ML, data analysis, SEO and working with large clients.  Write your thoughts in the comments or email <a href="http://maito:info%40heedbook.com/">info@heedbook.com</a> . </div><p>Source: <a href="https://habr.com/ru/post/330942/">https://habr.com/ru/post/330942/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../330932/index.html">40 unusual questions asked at the interview at Apple</a></li>
<li><a href="../330934/index.html">And terrible Russian firewall will burst</a></li>
<li><a href="../330936/index.html">Optical character recognition on the microcontroller</a></li>
<li><a href="../330938/index.html">Java: automatically generate SQL queries</a></li>
<li><a href="../330940/index.html">We compile, as if in the yard 1992</a></li>
<li><a href="../330944/index.html">[Administrator's abstract] Domains, addresses and Windows: mix, but do not shake</a></li>
<li><a href="../330946/index.html">‚ÄúWhen a critical crash occurs with databases, it always happens somewhat epically‚Äù - Ilya Kosmodemyansky</a></li>
<li><a href="../330948/index.html">How to ensure that learning in games is not annoying</a></li>
<li><a href="../330950/index.html">Online conference DEV Labs JavaScript. June 24</a></li>
<li><a href="../330952/index.html">Save data and faith in humanity: large migration of ElasticSearch cluster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>