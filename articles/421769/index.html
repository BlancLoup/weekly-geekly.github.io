<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The book "Deep learning on R"</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Deep learning - Deep learning is a set of machine learning algorithms that model high-level abstractions in data using architectures made up of many n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The book "Deep learning on R"</h1><div class="post__text post__text-html js-mediator-article"> <a href="https://habr.com/company/piter/blog/421769/"><img src="https://habrastorage.org/webt/j_/ay/e5/j_aye5gfuv42scevofj0paoaptq.jpeg" align="left" alt="image"></a>  Deep learning - Deep learning is a set of machine learning algorithms that model high-level abstractions in data using architectures made up of many non-linear transformations.  Agree, this phrase sounds ominously.  But everything is not so bad if Francois Chollet, who created Keras, the most powerful library for working with neural networks, tells us about deep learning.  Get to know deep learning from practical examples from a wide variety of areas.  The book is divided into two parts, in the first are the theoretical foundations, the second is devoted to solving specific problems.  This will allow you to not only understand the basics of DL, but also learn how to use the new features in practice.  This book is written for people with R programming experience who want to quickly learn deep learning in practice, and is an excerpt of Francois Schollet‚Äôs best-selling Deep Learning in Python, but using examples based on the R interface of Keras. <br><a name="habracut"></a><br><h3>  About this book </h3><br>  The book Deep Learning in R is addressed to statisticians, analysts, engineers, and students who have R programming skills but do not have significant knowledge of machine and deep learning.  This book is a redesigned version of the previous book, <a href="https://habr.com/company/piter/blog/413291/">Deep Learning in Python</a> , containing examples that use the R interface for Keras.  The purpose of this book is to provide the R community with a guide containing everything you need, from basic theory to advanced practical applications.  You will see more than 30 examples of program code with detailed comments, practical recommendations and simple generalized explanations of everything you need to know to use in-depth training in solving specific problems. <br><br>  The examples use the Keras deep learning framework and the TensorFlow library as an internal mechanism.  Keras is one of the most popular and rapidly developing deep learning frameworks.  It is often recommended as the most successful tool for beginners to learn deep learning.  After reading this book, you will understand what deep learning is, for what tasks this technology can be involved and what limitations it has.  You will become familiar with the standard process of interpreting and solving machine learning problems and learn how to deal with typical problems.  You will learn how to use Keras to solve practical problems from pattern recognition to natural language processing: image classification, prediction of temporal sequences, analysis of emotions and the generation of images and text and much more. <br><br><h3>  Excerpt  5.4.1.  Visualization of intermediate activations </h3><br>  The visualization of intermediate activations consists in displaying the feature maps, which are output by different convolutional and unifying levels in the network in response to certain input data (level output, the result of the activation function, often called its activation).  This technique allows you to see how the input data is decomposed into various filters received by the network in the learning process.  Typically, feature maps are used for visualization with three dimensions: width, height, and depth (color channels).  Channels encode relatively independent features, therefore, in order to visualize these feature maps, it is preferable to construct two-dimensional images for each channel separately.  Let's start by loading the model saved in section 5.2: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre><code class="hljs haskell">&gt; library(keras) &gt; model &lt;- load_model_hdf5(<span class="hljs-string"><span class="hljs-string">"cats_and_dogs_small_2.h5"</span></span>) &gt; model________________________________________________________________ <span class="hljs-type"><span class="hljs-type">Layer</span></span> (<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">type</span></span></span><span class="hljs-class">) </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Output</span></span></span><span class="hljs-class"> </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Shape</span></span></span><span class="hljs-class"> </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Param</span></span></span><span class="hljs-class"> # ============================================================== conv2d_5 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Conv2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 148, 148, 32) 896 ________________________________________________________________ maxpooling2d_5 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">MaxPooling2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 74, 74, 32) 0 ________________________________________________________________ conv2d_6 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Conv2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 72, 72, 64) 18496 ________________________________________________________________ maxpooling2d_6 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">MaxPooling2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 36, 36, 64) 0 ________________________________________________________________ conv2d_7 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Conv2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 34, 34, 128) 73856 ________________________________________________________________ maxpooling2d_7 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">MaxPooling2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 17, 17, 128) 0 ________________________________________________________________ conv2d_8 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Conv2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 15, 15, 128) 147584 ________________________________________________________________ maxpooling2d_8 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">MaxPooling2D</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 7, 7, 128) 0 ________________________________________________________________ flatten_2 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Flatten</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 6272) 0 ________________________________________________________________ dropout_1 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Dropout</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 6272) 0 ________________________________________________________________ dense_3 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Dense</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 512) 3211776 ________________________________________________________________ dense_4 (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Dense</span></span></span><span class="hljs-class">) (</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">None</span></span></span><span class="hljs-class">, 1) 513 ================================================================ </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Total</span></span></span><span class="hljs-class"> params: 3,453,121 </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Trainable</span></span></span><span class="hljs-class"> params: 3,453,121 </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Non</span></span></span><span class="hljs-class">-trainable params: 0</span></span></code> </pre> <br>  Next, select the input image of the cat, which is not part of the training set. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yu/kv/8d/yukv8dfjrpomkins35ks8guxlkm.png" alt="image"></div><br>  Listing 5.25.  Display test image <br><br><pre> <code class="hljs lisp">plot(<span class="hljs-name"><span class="hljs-name">as</span></span>.raster(<span class="hljs-name"><span class="hljs-name">img_tensor</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>,,,]))</code> </pre> <br>  To extract the feature maps to be visualized, create a Keras model that accepts image packages and displays the activation of all convolutional and unifying levels.  To do this, use the keras_model function from the Keras framework, which takes two arguments: an input tensor (or a list of input tensors) and an output tensor (or a list of output tensors).  The result is a Keras model object, similar to the models, returned by the keras_sequential_model () function with which you are already familiar;  This model displays the specified input data in the specified output.  Feature of the models <br>  This type is the ability to create models with multiple outputs (unlike keras_sequential_model ()).  The keras_model function is discussed in more detail in section 7.1. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ez/gy/sx/ezgysx1wbtufzyaopus2dpjhjfs.png" alt="image"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jm/08/y9/jm08y9ru_6mgb6_96c00k7pmhwi.png" alt="image"></div><br>  If you transfer an image to this model, it will return the activation values ‚Äã‚Äãof the layers in the original model.  This is the first example of a model with several outputs in this book: until now, all the models presented above had exactly one input and one output.  In general, a model can have any number of inputs and outputs.  In particular, this model has one input and eight outputs: one for each activation level. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/id/y2/-w/idy2-wa3qr4bua1buc9okwlhwxu.png" alt="image"></div><br>  Take for example the activation of the first convolutional layer for the input image of a cat: <br><br><pre> <code class="hljs lua">&gt; first_layer_activation &lt;- activations<span class="hljs-string"><span class="hljs-string">[[1]]</span></span> &gt; dim(first_layer_activation) [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">148</span></span> <span class="hljs-number"><span class="hljs-number">148</span></span> <span class="hljs-number"><span class="hljs-number">32</span></span></code> </pre> <br>  This is a feature map of 148 √ó 148 with 32 channels.  Let's try to display some of them.  First, we define a function to visualize the channel. <br><br>  Listing 5.28.  Channel visualization function <br><br><pre> <code class="hljs php">plot_channel &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(channel)</span></span></span><span class="hljs-function"> </span></span>{ rotate &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">t</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(apply</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(x, </span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">, rev)</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(rotate</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(channel)</span></span></span></span><span class="hljs-function"><span class="hljs-params">, axes = FALSE, asp = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, col = terrain.colors</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">12</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> }</span></span></code> </pre> <br>  Now let's display the second channel of activation of the first level of the original model (Fig. 5.18).  It looks like this channel is a contour detector. <br>  Listing 5.29.  Visualization of the second channel <br><br><pre> <code class="hljs lisp">plot_channel(<span class="hljs-name"><span class="hljs-name">first_layer_activation</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>,,,<span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre> <br>  Now take a look at the seventh channel (Fig. 5.19), but keep in mind that your channels may differ, because the training of specific filters is not a deterministic operation.  This channel is slightly different and it looks like it gives off cat's eye iris. <br>  Listing 5.30.  Channel 7 Visualization <br><br><pre> <code class="hljs lisp">plot_channel(<span class="hljs-name"><span class="hljs-name">first_layer_activation</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>,,,<span class="hljs-number"><span class="hljs-number">7</span></span>])</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ea/ng/ky/eangkyuz74aeras3xgjjy92nbgi.png" alt="image"></div><br>  Now we will build a full visualization of all activations in the network (Listing 5.31).  To do this, we extract and display each channel in all eight activation cards, placing the results in one larger tensor with images (Fig. 5.20‚Äì5.23). <br><br>  Listing 5.31.  Visualization of all channels for all intermediate activations <br><br><pre> <code class="hljs lua">image_size &lt;- <span class="hljs-number"><span class="hljs-number">58</span></span> images_per_row &lt;- <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">8</span></span>) { layer_activation &lt;- activations<span class="hljs-string"><span class="hljs-string">[[i]]</span></span> layer_name &lt;- model$layers<span class="hljs-string"><span class="hljs-string">[[i]]</span></span>$name n_features &lt;- dim(layer_activation)<span class="hljs-string"><span class="hljs-string">[[4]]</span></span> n_cols &lt;- n_features %/% images_per_row png(paste0(<span class="hljs-string"><span class="hljs-string">"cat_activations_"</span></span>, i, <span class="hljs-string"><span class="hljs-string">"_"</span></span>, layer_name, <span class="hljs-string"><span class="hljs-string">".png"</span></span>), width = image_size * images_per_row, height = image_size * n_cols) op &lt;- par(mfrow = c(n_cols, images_per_row), mai = rep_len(<span class="hljs-number"><span class="hljs-number">0.02</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:(n_cols<span class="hljs-number"><span class="hljs-number">-1</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (row <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:(images_per_row<span class="hljs-number"><span class="hljs-number">-1</span></span>)) { channel_image &lt;- layer_activation[<span class="hljs-number"><span class="hljs-number">1</span></span>,,,(col*images_per_row) + row + <span class="hljs-number"><span class="hljs-number">1</span></span>] plot_channel(channel_image) } } par(op) dev.off() }</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rb/qy/ev/rbqyev1ecyocl2xpwpsrj2gjaea.png" alt="image"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/13/i6/t-/13i6t-cqajkhzjf7su3fjsfq3yq.png" alt="image"></div><br>  Here are a few comments on the results. <br><br><ul><li>  The first layer acts as a collection of different contour detectors.  At this stage, the activation saves almost all the information available in the original image. </li><li>  As you climb up the layers of activation, they become more and more abstract, and their visual interpretation becomes more and more complex.  They begin to encode higher-level concepts, such as "cat's ear" or "cat's eye."  High-level views carry less information about the source image and more about the image class. </li><li>  The sparsity of activations increases with the depth of the layer: in the first layer, all filters are activated by the original image, but more and more empty filters remain in the subsequent layers.  This means that the pattern corresponding to the filter is not found in the original image. </li></ul><br>  We have just considered an important universal characteristic of representations created by deep neural networks: the signs extracted by layers become more and more abstract with the depth of the layer.  Activations on the upper layers contain less and less information about a particular input image, and more and more about the target (in this case, the image of the cat or dog class).  A deep neural network actually acts as an information clearing pipeline that receives raw data that is not cleaned (in this case, RGB images) and subjected to multiple transformations, filtering unnecessary information (for example, the specific appearance of the image) and leaving and clearing the necessary data ( Images). <br><br>  People and animals perceive the world around in the same way: after observing the scene for a few seconds, a person remembers what abstract objects are present in it (bicycle, tree), but does not remember all the details of the appearance of these objects.  In fact, when you try to draw a bicycle from memory, you most likely will not be able to get a more or less correct image, even though you may have seen bicycles a thousand times (see examples in Figure 5.24).  Try to do it right now and you will be convinced of the truth of what has been said.  Your brain has learned to completely abstract the visible image received at the input, and transform it into high-level visual concepts, while filtering unimportant visual details, making it difficult for them to remember. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/hu/o1/yehuo1lc-u4mksm3wuqdpnf80lk.png" alt="image"></div><br><br>  ¬ªMore information about the book can be found on <a href="https://www.piter.com/collection/all/product/glubokoe-obuchenie-na-r">the publisher site.</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610902/978544610902_X.pdf">Table of Contents</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610902/978544610902_p.pdf">Excerpt</a> <br><br>  For Habrozhiteley a 20% discount on coupon - <b>Deep Learning with R</b> </div><p>Source: <a href="https://habr.com/ru/post/421769/">https://habr.com/ru/post/421769/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../421759/index.html">QSAN XCubeNAS - NAS for corporate use</a></li>
<li><a href="../421761/index.html">Silicon Valley makes a cautious step towards autonomous aircraft</a></li>
<li><a href="../421763/index.html">Kolmogorov complexity and our search for meaning</a></li>
<li><a href="../421765/index.html">What is a web application in production?</a></li>
<li><a href="../421767/index.html">Miner offer to give the status of self-employed</a></li>
<li><a href="../421773/index.html">As a team of techies created their company, season 3 (finally flew!)</a></li>
<li><a href="../421775/index.html">The neural network was trained to recognize depression from a person‚Äôs random speech without context.</a></li>
<li><a href="../421779/index.html">OceanLotus: New Backdoor, Old Schemes</a></li>
<li><a href="../421781/index.html">Yandex has deleted both pirated links and links to the sites of the copyright holder</a></li>
<li><a href="../421783/index.html">Fun State Management Huex Framework</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>