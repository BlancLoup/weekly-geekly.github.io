<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we automate testing with release management - Part 1</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In November 2015, we opened access to the Release Management version for public testing in Visual Studio Team Services. The materials on this blog wil...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we automate testing with release management - Part 1</h1><div class="post__text post__text-html js-mediator-article">  In November 2015, we opened access to the Release Management version for public testing in Visual Studio Team Services.  The materials on <a href="http://blogs.msdn.com/b/visualstudioalm/archive/2015/11/18/announcing-the-new-release-management-service-in-visual-studio-team-services.aspx">this blog</a> will help you quickly start using the full range of RM capabilities.  The MSDN documentation available <a href="https://msdn.microsoft.com/Library/vs/alm/release/overview-rmpreview">here</a> will allow you to deeply understand the scripts and concepts of RM. <br><br>  You can use the RM service in two scenarios: to embed code in several used environments and to perform tests during product development.  In this post, I‚Äôll talk about the second scenario, namely, how we (Microsoft‚Äôs RM development team) automate testing using RM.  For the past seven months, we have been using RM for testing, for which I thank my colleague Lova. <br><br>  I have divided this article into two parts.  The first part is a general description of our experience with the integrated test automation process.  In the second part, we will discuss some design solutions, problems that we encountered in the process of testing automation, and ways to solve these problems. <br><a name="habracut"></a><br><h2>  Overview and General Description </h2>  VSTS consists of several scale units (SU) that provide services such as version control, build, release management, work item tracking, and others. All groups involved in the development and using VSTS tools use SU0 in their daily work.  Thus, SU0 is a ‚Äúworking version‚Äù.  As a rule, groups first deploy new code in SU0 and transfer it to other scaling units only after experimenting with it for some time. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Similarly, the RM group uses the services of SU0 in their daily work.  We are developing (we supplement the code and make corrections) in the functional branch of TF Git called features / rmmaster, compile the code using the Build service and test it using the RM service. <br><br>  The general purpose of our technical system is to simultaneously test each test on multiple configurations in order to detect regressions as early as possible in the development cycle.  At the moment there are three stages of debugging the developed code: <br><ol><li>  <b>Pre-review stage or requests to incorporate changes</b> : At this stage, we perform mainly modular and some complex tests in order to guarantee the correct operation of the basic functions in the features / rmmaster branch. <ul><li>  Note that this step is not performed if checks are enabled on the git branch. </li></ul></li><li>  <b>Continuous Integration (CI)</b> phase: At this stage, the CI assembly is launched immediately after verification.  For this assembly, we once again perform unit tests and make sure that parallel tests carried out did not lead to errors, and then publish the artifacts that were used by the RM group in test automation. </li><li>  <b>Test automation phase</b> : It starts at the moment of the end of the assembly and includes a set of concurrently launched Release Definitions (RD).  Each release definition tests a specific scenario;  output definitions collectively cover the entire product.  I will pay most attention to this stage in this publication. </li></ol><br><h2>  Configure "continuous automation pipeline" </h2>  The name of our <b>continuous integration CI assembly</b> is VSO.RM.CI.  The assembly publishes a single artifact called ‚Äúdrop‚Äù, which contains all the binaries created as a result of its execution. <br><img src="https://habrastorage.org/getpro/habr/post_images/8e4/b35/391/8e4b35391e0afc871aa640d23c6ca48b.png"><br><br>  <b>We associate this assembly definition with the release definition set</b> using the release definition trigger property.  In other words, each release definition highlighted below is automatically activated at the end of the VSO.RM.CI assembly. <br><img src="https://habrastorage.org/getpro/habr/post_images/2f0/13c/65e/2f013c65e2a0d50c3297f90e53050906.png"><br><br>  (Note that each release definition has a single environment. We were forced to use nine release definitions, because RM does not support parallel execution of environments. Such a function will appear soon. When this happens, we will combine nine release definitions into one release definition with nine concurrently running environments that improve build traceability). <br>  The general idea is that each release definition loads the binaries needed to test it, sets up the test environment, deletes the old and new binaries (dependent services and test DLLs), runs the tests using the VsTest task (which also publishes the results , which simplifies the preparation of reports and subsequent analysis) and once again clears the environment.  Later I will take a closer look at the release detection device in this blog. <br>  The process of processing the code and publishing the test is schematically as follows: <br><img src="https://habrastorage.org/getpro/habr/post_images/54b/0c9/6f3/54b0c96f39e4eb9f8b8fc1c999737a40.jpg"><br><h2>  Agent Pool Configuration </h2>  In order to proceed with the tasks, you must first configure the build / release agent for our CI continuous integration and release definitions.  Typically, on some servers, tasks are first run in the assembly / release agent pool to deploy RM / SPS / TFS services, and on other servers, tests are performed for these tasks.  In this case, we decided to deploy services on the agent's computer in order to simultaneously use several instances of the same test. <br><br>  Each test had its own requirements, which did not allow the use of a hosted agent pool.  For this reason, we created a single agent pool called RMAgentPool.  We prepared separate computers for each RM.CDP. * Release definition, installed the build / release agent for each of them, and added these computers to the RMAgentPool pool. <br><br>  (To do this, we downloaded the agent to each test computer using the ‚ÄúDownload Agent‚Äù link, highlighted in the figure below).  We unpacked the zip file of the agent and configured it by specifying our account in the URL for Team Foundation Server parameter (the URL for Team Foundation Server), for example: <a href="https://ouraccount.visualstudio.com/">https://OurAccount.visualstudio.com</a> ). <br><br>  Each computer was given a new user experience called "RmCdpCapability".  The value of this parameter determined the purpose of the computer: for example, on computers prepared for continuous integration assemblies, the parameter RmCdpCapability = CI was used. <br><img src="https://habrastorage.org/getpro/habr/post_images/a8f/a64/190/a8fa641907185fc92f6beb4e0dbf540c.png"><br><br>  Another example: For the agent on which the definition of the release RM.CDP.TfsOnPrem was performed, the parameter ‚ÄúRmCdpCapability = TfsOnPrem‚Äù was used. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/660/ae5/9ed/660ae59ed0f8a1faefdd5f94ca373243.png"><br><br>  The release definitions then used the RmCdpCapability parameter as a requirement for the tests to be performed on suitable agents. <br><br><h2>  Review of RM.CDP. * Release definitions </h2>  Terminology note: RM based on the web client is also called Team Web Access (TWA) <br><ul><li>  The RM TWA service in VSTS is called RM Online (or RMO) </li><li>  The RM TWA service in the local TFS version control system is called RM on-prem (this service has not yet been released, but we are doing everything possible to make the release happen as soon as possible) </li></ul><br>  Note that VSTS is a collection of several micro-services that are developed using a single Sprint model (all groups work in the same three-week cycle), but each group is independently deployed.  RM is one of these microservices and depends on other microservices, including SPS and TFS. <br>  A brief description of the tests we perform for RM TWA: <br><ol><li>  Tests for RMO: <ul><li>  RM.CDP.RmEqTfs: Performs complex tests (e2e) based on the API for RMO when the release versions of the RM sprint and the dependent services (SPS, TFS) are the same.  For example, RM, SPS and FTS are in the S92 sprint. </li><li>  RM.CDP.RmGtTfs: Performs complex tests (e2e) for the RMO release version when, in the scaling unit, the release version of the RM is ahead of the dependent services (SPS, TFS).  For example, RM is in S92, and SPS / TFS is in S91. </li><li>  RM.CDP.RmLtTfs: Performs complex tests (e2e) for the release version of RMO when, in the scaling unit, the release version of RM lags behind the dependent services (SPS, TFS).  For example, RM is in S91, and SPS / TFS is in S92. </li></ul><br>  The above test matrix allows you to deploy RMO in scaling units regardless of whether the dependent SPS / TFS services are deployed (if these services do not have dependencies on the new function; in this case, the RmGtTfs test suite will fail, at least we hope so) . </li><li>  RM on-prem tests: <ul><li>  RM.CDP.TfsOnPrem: performs RM on-prem tests based on both the API and the user interface. </li></ul></li><li>  Update Tests <ul><li>  RM.CDP.DevFabricUpgrade: tests the upgrade script for RMO (for example, from S91 to S92). </li><li>  RM.CDP.OnPremUpgrade: tests the upgrade script RM on-prem. </li></ul></li><li>  Test x-plat RM, i.e.  RM agent runs on Linux / iOS: <ul><li>  RM.CDP.XPlat </li></ul></li></ol><br><h2>  Development of a release definition for RM.CDP. * </h2>  I will take a closer look at the definition of the release RM.CDP.TfsOnPrem, since it creates the canonical pattern used by other release definitions. <br><ol><li>  The release definition is configured to <b>run on a suitable agent</b> , as shown in the screenshot below: RM.CDP.TfsOnPrem -&gt; Edit -&gt; Environment -&gt; ... -&gt; Agent Options -&gt; Options tab. </li><li>  The release definition then <b>skips the artifact download (Skips Artifact Download)</b> : <br><img src="https://habrastorage.org/getpro/habr/post_images/11a/bc9/559/11abc95595c828c01212bdbb851b55b1.png"><br><br>  Downloading the artifact is skipped because our continuous integration CI build publishes a single large artifact called ‚Äúdrop‚Äù with a size of several GB, while all tests need different subsets of files. <br>  (Currently, RM does not allow to easily download a subset of artifacts published by the assembly. As soon as this opportunity arises, we will do two things: (1) instead of one large drop artifact, we will start publishing smaller TfsDrop artifacts in the continuous integration assembly, "RmDrop", "SpsDrop", etc. (2) will download those artifacts that are necessary to determine the release of RM.CDP. *). </li><li>  Each of the release definitions downloads a set of standard files (including the vssbinfetch.exe program, which can download specific fragments of an assembly) by executing the downloadArtifacts.ps1 file, available on the \\ file resource.  The release definition then <b>downloads the required binaries from the build</b> for its test script using the vssbinfetch task we created, which calls the vssbinfetch.exe program.  For example, RM.CDP.RmEqTfs downloads binaries for SPS, TFS, and RMO services, and RM.CDP.TfsOnPrem for TFS on-prem.  These two tasks are highlighted below.  The release definition cleans the computer and deletes old binaries. <br><img src="https://habrastorage.org/getpro/habr/post_images/abd/764/dc5/abd764dc5dd91b2d3e3a1eaa124026fc.png"></li><li>  The release definition then <b>deploys the necessary services and test dll libraries</b> on the computer.  For example, ‚Äútfat‚Äù is an internal tool that installs TFS on-prem on a computer. <br><img src="https://habrastorage.org/getpro/habr/post_images/228/28b/4e9/22828b4e9893c325bb69f9380279d476.png"></li><li>  At the end, the release definition sets up the test environment file and <b>invokes the Visual Studio Test</b> task (or the VsTest task, which we prefer to use :)).  This leads to the publication of test results called "TfsOnPrem". <br><img src="https://habrastorage.org/getpro/habr/post_images/ffc/828/88c/ffc82888c71dd2c5bd59b8ff2833b9d8.png"></li><li> As a rule, the release definition is completed after the execution of the ‚ÄúPause agent on test failure‚Äù task and cleaning, if necessary.  As a rule, the ‚ÄúPause‚Äù task is disabled, and I will talk more about this in the next blog post. </li></ol><br><h2>  Analysis of test results </h2>  As developers make changes, we can easily determine whose changes caused the crashes.  For example, in the screenshot below, testing began to fail after building VSO.RM.CI_rmmaster_20151231.5.  Double-clicking on the selected release opens the Release Summary page: <br><img src="https://habrastorage.org/getpro/habr/post_images/5a4/69d/689/5a469d689e8df9efb39547c9704461ad.png"><br><br>  Then we go to the Test Results section of the Release Summary page and see that after this test, two user interface tests began to fail.  Clicking on the highlighted link to the test, we get to the Test section: <br><img src="https://habrastorage.org/getpro/habr/post_images/1ae/b50/cf1/1aeb50cf18f0a670bed8cb356c8c6187.png"><br><br>  The Test Results subtab gives us valuable background information for detailed problem analysis: <br><img src="https://habrastorage.org/getpro/habr/post_images/cbc/052/1c0/cbc0521c0f6ee9305cc637d3a592ea55.png"><br><br>  Test logs are available in the Run summary sub-tab. <br>  We can get more detailed information about the fixations of this release in order to determine their possible connection with the regression using the Commits tab of the Release Summary page.  For example, the screen shot below shows that some user interface changes in this test could have caused two failed tests. <br><img src="https://habrastorage.org/getpro/habr/post_images/406/4dd/9f1/4064dd9f1ba147e5c15a5c67b5ea8f1e.png"><br><br><h2>  Benefits of testing with RM </h2>  Testing with RM gives us the following benefits: <br><ol><li>  We quickly check the build due to the parallel execution of all test cases. <ul><li>  We can detect the slowest release definitions and add additional agents to run test cases, which speeds up parallel processing.  For example, we have two computers for building continuous integration (‚ÄúRmCdpCapability = CI‚Äù), and we plan to add another one to them for RM.CDP.RmEqTfs, since its execution lasts longer than the others. </li></ul></li><li>  This setup makes it easy to test different branches.  Since continuous integration is configured on a branch of our function (features / rmmaster), we can just as easily put the assembly in a queue from the release branch, for example, releases / M92, as shown in the screenshot below.  At the end of the build, the same release definitions RM.CDP. * Will be activated to handle the binary code from this branch of the release. <ul><li>  The flexible work with branches can be expanded in the following scenario: testing the code before testing it can be tedious for developers (as a rule, developers perform it when they are going to make a large number of changes), for example, in the branch selected below / users / rahudha / rifi.  The main idea is that developers can solve the same problem by reusing group resources without setting up a test infrastructure in their development environments. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/596/b7f/607/596b7f6071cbb7b3b39d3d80627ed7d4.png"></li><li>  We can perform the same tests in the production environment as in the automated testing environment: Since we use RMO for deployment to the production environment (this is how we deploy RMO using RMO), we can test the deployment using the same test tasks. </li><li>  Since all test suites are applied to the same binary code set, we can easily answer the question: ‚ÄúWhat is the build quality?‚Äù As a rule, we want to know about the build quality before we deploy it in a production environment.  The screen shot below shows a simple query to determine build quality. <br><img src="https://habrastorage.org/getpro/habr/post_images/2cf/ca0/3ad/2cfca03adeb09d0a3540ab18e94b134b.png"></li></ol><br><br>  (In the next few months, this feature will become more integrated with the Release Summary page. <br><br><h2>  Conclusion </h2>  Initially, we used RMO when testing development processes only to understand its capabilities.  Over time, we concluded that the efficiency of RMO is significantly higher than that of the test infrastructure we used earlier.  Developers love the fact that they can test major changes without time-consuming customization of the local test environment. <br><br>  Now you have an idea of ‚Äã‚Äãhow the RM development team uses RM to automate testing.  We hope that our experience will give you ideas on how to automate the testing process. <br><br>  In the <a href="http://blogs.msdn.com/b/abhishea/archive/2016/01/04/how-we-use-the-release-management-for-our-test-automation-part-2.aspx">second part of this article,</a> we will discuss some design solutions, the problems that we encountered in the process of organizing the management of releases and ways to solve these problems. </div><p>Source: <a href="https://habr.com/ru/post/277601/">https://habr.com/ru/post/277601/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../277589/index.html">5 educational opportunities abroad for students and recent graduates</a></li>
<li><a href="../277591/index.html">What are the latest changes in the 63-FZ "on electronic signature"</a></li>
<li><a href="../277593/index.html">List of machine learning resources. Part 2</a></li>
<li><a href="../277597/index.html">How we used Git, CI and code review in the learning process</a></li>
<li><a href="../277599/index.html">Hello, World! On FPGA. Blink LED</a></li>
<li><a href="../277603/index.html">The rules of good tone when writing a plugin on jQuery</a></li>
<li><a href="../277605/index.html">Nuances of developing a plugin for Unity</a></li>
<li><a href="../277609/index.html">What to replace Cisco? Import Substitution Access Switches</a></li>
<li><a href="../277615/index.html">Testing plugins for Apache Cordova</a></li>
<li><a href="../277617/index.html">Do not miss the chance to get on // Build: develop or update the UWP application and participate in Race to Build 2016</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>