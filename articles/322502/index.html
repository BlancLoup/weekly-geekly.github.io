<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Downloading audio from mail.ru</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The task that we face is downloading music from the site providing such an opportunity. We will use the programming language Python . 

 To accomplish...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Downloading audio from mail.ru</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/acd/81b/801/acd81b801099484da89072ee4c096f90.png"><br><br>  The task that we face is downloading music from the site providing such an opportunity.  We will use the programming <a href="https://ru.wikipedia.org/wiki/Python"><b>language Python</b></a> . <br><a name="habracut"></a><br>  To accomplish this, we will need knowledge about site parsing and working with media files. <br><br>  The figure above shows the general algorithm for parsing sat.  We will perform the parsing using the <a href="http://wiki.python.su/%25D0%2594%25D0%25BE%25D0%25BA%25D1%2583%25D0%25BC%25D0%25B5%25D0%25BD%25D1%2582%25D0%25B0%25D1%2586%25D0%25B8%25D0%25B8/BeautifulSoup"><strong>BeautifulSoup</strong></a> and <a href="https://khashtamov.com/2015/12/python-requests/"><strong>request</strong></a> modules, and the <a href="https://tproger.ru/translations/regular-expression-python/"><strong>re</strong></a> module will be enough for us to work with the text. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Import </h2><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-comment"><span class="hljs-comment">#   HTTP- import urllib.request # HTTP from bs4 import BeautifulSoup #    HTML import re #    </span></span></code> </pre> <br><h2>  Variable declaration and main procedure </h2><br>  We will need only two arrays and one variable to store information: <br><br><pre> <code class="python hljs">page_count = [] <span class="hljs-comment"><span class="hljs-comment">#    ,   perehod = '' #      ,       download = [] #          </span></span></code> </pre><br>  We write a procedure where first of all we consider all pages on the site containing the songs we need. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: <span class="hljs-comment"><span class="hljs-comment">#    u = str(input('   :\n')) #input -      .       ,    base_url = 'http://go.mail.ru/zaycev?sbmt=1486991736446&amp;q='+u #  http ,    count=0 #           page_count = [base_url] #     ,      print(' . ...') #print -     while True: #  try: #try   .  ,        ,      except,      page_count = page_count+[get_page_count(get_html(page_count[count]),page_count)] #   ,    get_page_count,      page_count   .      get_html (  http)  page_count[count],  count   .  ,        -  ,     -     count = count + 1 #,       except TypeError: #    ,   TypeError.   break # break             print("   - ",len(page_count)) #         len,      </span></span></code> </pre><br><h2>  Getting HTTP Pages </h2><br>  For the life of the previously written, you need to write two functions, the first - will receive http and pass this parameter to the second, which in turn will receive data from this link by means of parsing. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_html</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       url,   page_count[count] response = urllib.request.urlopen(url) #   ¬´¬ª  httplib,  ,          return response.read() #      read   </span></span></code> </pre><br>  The next function will be the parsing itself.  The main thing that we need to get information about building a site is to view its html layout.  To do this, go to the site, press Shift + Ctrl + C and get the source code, which displays all the names of the widgets. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_page_count</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(html,page_count)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      page_count (    )  html     ,     : get_html(page_count[count]) soup = BeautifulSoup(html, "html.parser") #     html-  href = soup.find('a', text = '') #       -     "". "" -   ,    .       (Shift+Ctrl+C). base_url = 'http://go.mail.ru' # ,     .        ,      page_count = base_url + href['href'] #   .         href,    html-,  ,     ['href']      (      html-). return page_count #    </span></span></code> </pre><br>  <b>Important!</b>  All data obtained using BeautifulSoup is not a string data type, but a separate ‚Äúbeautiful soup‚Äù data type. <br><br>  The next task is to get a new download address when you click ‚ÄúDownload‚Äù on each of the pages.  Note that we will not use the array, since in this case we will have to fill it in completely and only then start downloading, which will greatly slow down the performance of the program.  We will take every time a new link and work directly with it.  To do this, we write the second function and add to the procedure: <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">''</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  ''     try: #    for i in page_count: #     perehod = parsing1(get_html(i),perehod) #   ,  url   .       -        url except TypeError: #,    TypeError (     ) print(' ') #  ' '    </span></span></code> </pre><br>  In the third function, we will meet using re.findall (Pattern, string) ‚Äîsearch for a given pattern in a string variable. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parsing1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(html,perehod)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  soup = BeautifulSoup(html, "html.parser") #  html-  perehod = [] #    ,          for row in soup.find_all('a'): # ,      ( ,    ,   20)      if re.findall(r'', str(row)): #     re,      html-,   ,   ,     row, -   ( "a"    ,   ),    perehod=perehod+[row['href']] #      ,        return perehod # </span></span></code> </pre><br>  Now the procedure takes every time a new link from each page and we need to find the address of the new page, where the new button with the text field ‚ÄúDownload‚Äù is located, with the final address for downloading.  In the main procedure we write: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> perehod: <span class="hljs-comment"><span class="hljs-comment">#           download = parsing2(get_html(y),download #download -      -       </span></span></code> </pre><br><h2>  Getting HTTP for direct download </h2><br>  In the last function we will find links for direct download.  Here we will use two new procedures: <br><br><ol><li>  re.sub (Template, New Fragment, Replace Line) searches for all matches with the template and replaces them with the specified value.  As the first parameter, you can specify a function reference. </li><li>  text - gets the text from the html-code (only from the search result BeautifulSoup, the string data type will not work). </li></ol><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parsing2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(html,download)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  soup = BeautifulSoup(html, "html.parser") #     html  table = soup.find('a', {'id':'audiotrack-download-link'}) # html    "a"   "id".       -       href='' #    name='' #    if table != None: #:     ,    else row = soup.find('h1', {'class':"block__header block__header_audiotrack"}) #     "h1"         name = re.sub(r'\n\t\t\t\t\t\t','',row.text) #       -     .      html-  row href=table.get('href') #     .get('href')  ['href'] -   download=[href]+[name] #,     ,     return download #  else: #        download return download #  </span></span></code> </pre><br><h2>  Write file </h2><br>  It remains for us to download and write the file. <br><br><ol><li>  The get procedure allows you to send an HTTP request, which we later check with the req.status_code procedure: this is a list of HTTP status codes (the list can be found on the Internet, status &lt;200&gt; means successful login). </li><li>  The open procedure opens and closes a file for writing in binary format, wb creates a file with a name if one does not exist. </li></ol><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> download != []: <span class="hljs-comment"><span class="hljs-comment">#, ,       req = requests.get(download[0],stream = True) #             stream  True if req.status_code == requests.codes.ok: #   http    ,   with open(download[1]+'.mp3', 'wb') as a: #     a.write(req.content) #       write</span></span></code> </pre><br>  Using only two modules BeautifulSoup and request, you can achieve solutions to virtually any tasks associated with parsing the site.  Using this knowledge, you can adapt the program to download other data, even from other sites.  Good luck in your work! </div><p>Source: <a href="https://habr.com/ru/post/322502/">https://habr.com/ru/post/322502/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../322492/index.html">The exclusive role of the boss</a></li>
<li><a href="../322494/index.html">The simplest way to avoid routine</a></li>
<li><a href="../322496/index.html">The world's easiest lock-free hash table</a></li>
<li><a href="../322498/index.html">11 steps to high email deliverability</a></li>
<li><a href="../322500/index.html">The CDN provider Cloudflare has injected the contents of its server‚Äôs memory into arbitrary webpage code.</a></li>
<li><a href="../322504/index.html">Generation of polygonal maps for games</a></li>
<li><a href="../322508/index.html">15 oddities in ruby ‚Äã‚Äãthat you should know</a></li>
<li><a href="../322510/index.html">Vertica + Anchor Modeling = start growing your mycelium</a></li>
<li><a href="../322512/index.html">Conversion and payment types in traffic arbitration</a></li>
<li><a href="../322514/index.html">Neural network imitation game</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>