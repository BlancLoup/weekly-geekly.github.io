<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>On the use of entropy to identify texts</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="One of the practical problems faced by the theory of information is the question of the identification of texts and the definition of authorship. Let ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>On the use of entropy to identify texts</h1><div class="post__text post__text-html js-mediator-article">  One of the practical problems faced by the theory of information is the question of the identification of texts and the definition of authorship.  Let us study one of the possible ways to solve this problem, based on the measurement and comparison of the entropy indicators of this and reference texts for the problem of determining the identity of a piece of text. <br><a name="habracut"></a>  Usually, the entropy of the Markov process is used for comparing texts and determining authorship, which shows the average amount of information in bits, which is reported by one character if <em>k ‚Äì 1 is</em> known.  After reviewing some of these works, which did not take into account that the compared works have a different volume, I decided to study the dependence of the text entropy on its volume. <br>  Of the six texts of three authors, samples of various volumes were made and the average entropy values ‚Äã‚Äãwere calculated from 1 to 6 orders of magnitude inclusive.  The results of the work can be seen in the graphs (the upper lines correspond to the entropy of the first order, the lower ones - 6): <br><img src="https://habrastorage.org/getpro/habr/olpictures/e98/76e/248/e9876e248e119b9b596b84c6b67d88a8.gif" width="450" height="300" alt="Dependence of conditional entropy on text size" hspace="10" vspace="10"><br>  Thus, the higher the order, the stronger the logarithmic dependence of the entropy on the volume of the text.  And already for the second order with given samples, the logarithmic trend explains on average 85% of the variance, when considering volumes of less than 50 thousand sunflowers - more than 90%.  This means that the first-order entropy, that is, the distribution of frequencies of individual characters without taking into account their sequences, is the most stable and independent of the length of the text. <br>  A more detailed consideration of the first-order entropy can be seen that for a volume of less than 30 thousand characters the average entropy is less than the entropy of the whole text, but the general relations remain (the dotted line shows the entropy of the whole text) <br><img src="https://habrastorage.org/getpro/habr/olpictures/8be/bd5/716/8bebd5716ceab548579d74073ee71cf5.gif" width="450" height="300" alt="Comparison of entropy 1 order for three books (for samples from text of different volume)" hspace="10" vspace="10"><br>  It can be seen that the graphs overlap, which already indicates that it is impossible to unambiguously determine the ownership of the text at the intersection points. <br>  However, to answer the question about the solvability of our problem, it is necessary to estimate the spread of values ‚Äã‚Äãwithin one text.  In the following graph, all intermediate samples are shown in dots.  The resulting fluctuation of entropy within one text exceeds the difference between the average values, which indicates the impossibility of an exact solution of the problem of a text fragment belonging under these conditions. <br><img src="https://habrastorage.org/getpro/habr/olpictures/01a/805/5da/01a8055dabc16a4ca67f449dd05548d0.gif" width="450" height="300" alt="Comparison of entropy 1 order for three books taking into account all intermediate values" hspace="10" vspace="10"><br><br>  Thus, the method based on direct comparison of the entropy of the text-fragment and the reference text is extremely inaccurate and is not suitable for identifying texts because of the large scatter of values ‚Äã‚Äãwithin the text.  Unlike characteristics based on the number of N-grams and direct comparison of the relative frequencies of their distribution, entropy is an impersonal parameter and its use in exact problems can lead to errors. </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/14389/">https://habr.com/ru/post/14389/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../143884/index.html">Hackspace do it yourself</a></li>
<li><a href="../143885/index.html">Sensors are coming</a></li>
<li><a href="../143886/index.html">Automaton-style programs - translation difficulties</a></li>
<li><a href="../143887/index.html">Infinite scrolling, as a dubious interface improvement</a></li>
<li><a href="../143888/index.html">Recover dead pixels by freezing</a></li>
<li><a href="../143890/index.html">Scala Conference in St. Petersburg in 4 days</a></li>
<li><a href="../143891/index.html">Create a cloud for software testing</a></li>
<li><a href="../143892/index.html">Gamification diet</a></li>
<li><a href="../143893/index.html">Using a synthesizer as a computer keyboard</a></li>
<li><a href="../143894/index.html">What applications are you testing?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>