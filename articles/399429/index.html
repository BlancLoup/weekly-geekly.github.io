<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The neural network reads lips on 46.8% of words on TV, man - only 12.4%</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Frames of four programs for which the program was taught, as well as the word "afternoon", pronounced by two different announcers 

 Two weeks ago, Li...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The neural network reads lips on 46.8% of words on TV, man - only 12.4%</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/ec4/57a/c95/ec457ac95f72435cbb483bf431da7794.jpg"><br>  <i>Frames of four programs for which the program was taught, as well as the word "afternoon", pronounced by two different announcers</i> <br><br>  Two weeks ago, <a href="https://geektimes.ru/post/282320/">LipNet</a> 's <a href="https://geektimes.ru/post/282320/">neural network was told</a> , which showed a record quality of 93.4% lip-sensing of human speech.  Even then, many applications were supposed for this kind of computer systems: medical hearing aids of new generation with speech recognition, systems for silent lectures in public places, biometric identification, hidden information transmission systems for espionage, speech recognition by video from surveillance cameras, etc.  And now, experts from the University of Oxford, together with a staff member of Google DeepMind, <a href="https://arxiv.org/pdf/1611.05358v1.pdf">told about their own developments</a> in this area. <br><a name="habracut"></a><br>  A new neural network was trained on <b>arbitrary texts of</b> people speaking on the BBC channel.  Interestingly, the training was performed automatically, without prior annotating the speech manually.  The system itself recognized the speech, annotated the video, found faces in the frame, and then learned to identify the relationship between words (sounds) and lip movement. <br><br>  As a result, this system effectively recognizes just <i>arbitrary</i> texts, and not instances from the special body of GRID sentences, as LipNet did.  The GRID corpus has a strictly limited structure and vocabulary, therefore only 33,000 sentences are possible.  Thus, the number of variants is reduced by orders of magnitude and the recognition is simplified. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The special GRID package is composed of the following pattern: <br><br>  <i>command (4) + color (4) + preposition (4) + letter (25) + digit (10) + adverb (4),</i> <br><br>  where the number corresponds to the number of variants of words for each of the six verbal categories. <br><br>  Unlike LipNet, the development of the company DeepMind and specialists from the University of Oxford works on arbitrary speech streams on television picture quality.  It is much more like a real system, ready for practical use. <br><br>  The AI ‚Äã‚Äãwas trained on 5,000 hours of video recorded from six television shows on the British television channel BBC from January 2010 to December 2015: these are regular news bulletins (1,584 hours), morning news (1997 hours), Newsnight programs (590 hours), World News (194 hours), Question Time (323 hours) and World Today (272 hours).  In total, the videos contain 118,116 sentences of consistent human speech. <br><br>  After that, the program was checked on broadcasts that went on the air between March and September 2016. <br><br><div class="spoiler">  <b class="spoiler_title">An example of reading lips from the TV screen</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/c82/0d8/a76/c820d8a763214b4db9c28565a8ffaa25.gif"></div></div><br>  The program showed a fairly high quality of reading.  She correctly recognized even very complex sentences with unusual grammatical constructions and the use of proper names.  Examples of perfectly recognized sentences: <br><br><ul><li>  MANY MORE PEOPLE WHO WERE INVOLVED IN THE ATTACKS </li><li>  CLOSE TO THE EUROPEAN COMMISSION'S MAIN BUILDING </li><li>  WEST WALES AND THE SOUTH WEST AS WELL AS WESTERN SCOTLAND </li><li>  WE KNOW THERE WILL BE HUNDREDS OF JOURNALISTS HERE AS WELL </li><li>  ACCORDING TO PROVISIONAL FIGURES FROM THE ELECTORAL COMMISSION </li><li>  THAT'S THE LOWEST FIGURE FOR EIGHT YEARS </li><li>  MANCHESTER FOOTBALL CORRESPONDENT FOR THE DAILY MIRROR </li><li>  LAYING THE GROUNDS FOR A POSSIBLE SECOND REFERENDUM </li><li>  ACCORDING TO THE LATEST FIGURES FROM THE NATIONAL STATISTICS </li><li>  IT COMES AFTER A DAMNING REPORT BY THE HEALTH WATCHDOG </li></ul><br>  The AI ‚Äã‚Äãsignificantly outperformed the work of a man, a lip-reading expert, who tried to recognize 200 random video clips from a recorded video test archive. <br><br>  The professional was able to annotate without a single error just 12.4% of the words, while the AI ‚Äã‚Äãcorrectly recorded 46.8%.  Researchers note that many errors can be called insignificant.  For example, the missing "s" at the end of words.  If we approach the analysis of the results less strictly, then the system actually recognized much more than half of the words on television. <br><br>  With this result, DeepMind significantly surpasses all other lip-reading programs, including the aforementioned LipNet, which was also developed at Oxford University.  However, it is too early to talk about final superiority, since LipNet was not trained on such a large data set. <br><br>  According <a href="https://www.newscientist.com/article/2113299-googles-deepmind-ai-can-lip-read-tv-shows-better-than-a-pro/">to experts</a> , DeepMind is a big step towards developing a fully automatic lip reading system. <br><br><img src="https://habrastorage.org/files/ea1/f0c/ae3/ea1f0cae324341439194e33b61fd9f3e.png"><br>  <i>The architecture of the WLAS module (Watch, Listen, Attend and Spell) and the convolutional neural network for lip reading</i> <br><br>  The great merit of the researchers is that they have compiled a gigantic data set for learning and testing the system with 17,500 unique words.  After all, this is not just five years of continuous recording of television broadcasts in competent English, but also clear synchronization of video and sound (TV often rassinhron up to 1 second, even on professional English television), as well as the development of a speech recognition module that overlaps in the video and is used in the lip-reading training system (WLAS module, see diagram above). <br><br>  In the case of the slightest rassinhrona training of the system becomes almost useless, because the program can not determine the correct match of sounds and lip movements.  After a thorough preparatory work, the training of the program was completely automatic - she independently processed all 5,000 videos. <br><br>  Previously, such a set simply did not exist, so the same LipNet authors were forced to restrict themselves to the GRID base.  To the credit of developers DeepMind, they promised to publish a data set in open access for training other AI.  Colleagues from the LipNet development team have already said that they are waiting for this with impatience. <br><br>  The scientific work is <a href="https://arxiv.org/pdf/1611.05358v1.pdf">published</a> in the public domain on the site arXiv (arXiv: 1611.05358v1). <br><br>  If commercial lip-reading systems appear on the market, then the life of ordinary people will become much easier.  It can be assumed that such systems will immediately integrate into televisions and other household appliances to improve voice control and practically unmistakable speech recognition. </div><p>Source: <a href="https://habr.com/ru/post/399429/">https://habr.com/ru/post/399429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../399419/index.html">Lenovo Y27g Razer Edition Bent Game Monitor Review</a></li>
<li><a href="../399421/index.html">Why MacBook Pro's Memory Size is Limited 16GB</a></li>
<li><a href="../399423/index.html">Roskomnadzor began negotiations with Opera about filtering prohibited sites</a></li>
<li><a href="../399425/index.html">Electronic aliens: alien mind can be machine</a></li>
<li><a href="../399427/index.html">‚ÄúKuz'kina's mother‚Äù in overclocker-style: how a Russian enthusiast knocked out three world records in one day</a></li>
<li><a href="../399431/index.html">Fake news and the era of post-truth: everything is just beginning</a></li>
<li><a href="../399433/index.html">GFDM - how to use radio resources even more efficiently</a></li>
<li><a href="../399435/index.html">Once again about the Chinese light bulbs: everything is very bad</a></li>
<li><a href="../399437/index.html">In 2018, China will begin to transform its thermal power plants into nuclear power plants.</a></li>
<li><a href="../399439/index.html">The history of world epidemics, part 3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>