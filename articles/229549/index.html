<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Face recognition</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄúMy light, mirror! tell me 
 Yes, tell the whole truth: 
 I am the sweetest in the world, 
 All blush and whiter? " 

 A.S. Pushkin 

 Little by littl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Face recognition</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/c82/dac/8f5/c82dac8f57c49599c174da1f895d8f5a.jpg" align="right"><br>  <i>‚ÄúMy light, mirror!</i>  <i>tell me</i> <i><br></i>  <i>Yes, tell the whole truth:</i> <i><br></i>  <i>I am the sweetest in the world,</i> <i><br></i>  <i>All blush and whiter? "</i> <br><br>  <b>A.S.</b>  <b>Pushkin</b> <br><br>  Little by little magic things from fairy tales are realized in real reality through the use of new technologies and scientific discoveries.  Such devices as carpet-plane (aviation), boots-walkers (cars), an apple on a saucer (netbook with internet), a ball that shows the way (GPS-navigator) and other necessary things are already implemented and actively used.  We tried to implement the system for assessing the beauty of a person‚Äôs face mentioned in the ‚Äútale of a dead princess and seven heroes‚Äù using artificial intelligence and machine vision, because we believe that the author of the epigraph actually meant a tablet with a front-facing camera and special installed software. <br><a name="habracut"></a><br>  The question of what exactly makes a person's face attractive is the subject of research by physiologists, biologists, philosophers, art historians, and specialists in plastic surgery for a long time.  At present, it is considered established that people, in addition to individual preferences, are also affected by the general biologically-motivated principles of beauty assessment [1-2].  Among the possible candidates for typical signs, physiologists distinguish the symmetry of facial features [3], the difference between a facial image and averaged image of a large number of people [4], the correspondence of facial proportions to the ‚Äúgolden section‚Äù [5], etc. For example, [4] shows that, on the one hand, symmetrical facial features correspond to genes less susceptible to mutations and therefore people with such facial features are more resistant to mutations and diseases, and on the other, people with more symmetrical facial features receive higher beauty ratings when evaluating them  otografy experts. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In recent years, several pioneering works have appeared on computerized beauty recognition systems based on the use of machine vision systems [6‚Äì8] and trainee classifiers.  These works can be considered as an attempt to endow robotic systems with the ability to ‚Äúsee beautiful‚Äù.  In [6], the proportions of facial features are used as signs, with the key points on the face being highlighted manually.  In [7], in addition to the proportions, the method of principal components was applied to extract features.  In [8], <a href="http://habrahabr.ru/post/226347/">deep neural networks were</a> used for the beauty recognition task. <br><br>  We have developed an automatic beauty assessment system based on the method of extracting key points on the face using the tools of the <a href="http://opencv.org/">OpenCV</a> machine vision <a href="http://opencv.org/">library</a> and a <a href="http://habrahabr.ru/post/211610/">neural network</a> trained on the expert assessment data and conducted an experimental evaluation of the quality of its work. <br><br><h2>  Image database for training </h2><br>  We have collected our own image database, consisting of 180 photos of young women, the images were taken from open sources.  Were selected photographs of faces in the frontal projection with a neutral facial expression, without glasses and jewelry.  To make the sample representative, we tried to include in the database examples of both beautiful and ugly faces (Fig. 1). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c1/eda/d1a/3c1edad1ad9ea02c2099bc5098d84889.jpg"><br><br>  Fig.  1. An example of a photo of persons from the database of images <br><br>  Unlike the work [7], the collected base includes photographs of women of different races, skin color, and their age ranges from 18 to 35 years.  After the images were collected, the group of experts was asked to set subjective ratings of aesthetic appeal for each of the photos on a scale from 1 to 7. In total, 8 experts, 4 men and 4 women aged 16 to 63 were involved in the labeling of photos. grades were set independently.  According to the conditions of the experiment, before the beginning of the scoring process, each expert was presented with all the photos for initial review.  To check the consistency of the sample was carried out correlation analysis, its results are presented in Table.  one. <br><br>  Table 1. Pairwise correlations of assessments of various experts <br><br><img src="https://habrastorage.org/getpro/habr/post_images/54d/104/944/54d104944107d2a436fc1e5af572bd02.jpg"><br><br>  The average correlation of the sample was 0.7, which makes it possible for a neural network to be trained on such data and roughly corresponds to the results of other researchers [4.7]. <br><br><h2>  The general scheme of the algorithm </h2><br>  The beauty recognition system receives as input an image containing a frontal photo of a person‚Äôs face (Fig. 2). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a3c/82b/a36/a3c82ba36deb559d625f78395657b654.jpg"><br><br>  Fig.  2. Scheme of the face beauty recognition algorithm <br><br>  Before the start of the algorithm, we assume that the face in the image has already been allocated earlier and occupies most of the image area.  Next, using the <a href="http://habrahabr.ru/post/133826/">Viola-Jones</a> standard boosting classifier, which is part of the OpenCV computer vision library, the areas on the face corresponding to the right and left eye, nose and mouth are highlighted. <br>  On the basis of these coordinates, the basic proportions of the face are calculated, which are then used as a feature vector for the neural network.  The neural network is first trained on this input using expert evaluations as a target sample, and then it can be used to recognize new data that has not been previously seen by the network. <br><br><h2>  Feature highlighting </h2><br>  We conditionally divided the signs we distinguished into two groups: the ratio of the distances between the selected key points and the ratios of the found face sizes. <br><br>  The group of signs 1 is shown in fig.  3, left: AB / CD, AC / BC, AD / BD, EC / ED, EC / AB, AC / AD, BC / BD.  The group of features 2 is shown in Fig.  3, right: L / R, Mw / Mh, Nw / Nh, Mw / Nw, Mh / Nh.  The final feature vector consists of the combined features of both groups.  Before submission to the neural network, the data were brought to the range [1; 1]. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a5/b57/64e/8a5b5764eac2d86caa95c87accc152ae.jpg"><br><br>  Fig.  3. Calculation of feature vectors for selected key points on the face <br><br><h2>  Training neural networks </h2><br>  As a trained neural network, we used the standard multilayer perceptron [10, p.  219] with one hidden layer containing 5 neurons in the hidden layer.  The hyperbolic tangent function was used as the activation functions of the neurons of the hidden and output layers.  The neural network was trained using the advanced Kalman filter [10, p.  219], [11], which is currently one of the most effective second-order learning methods for neural networks.  Before training, the sample was divided into 2 parts: the training (110 examples, 60% of the sample) and the examination (70 examples, 40% of the sample).  The learning outcomes are presented in Table.  2 <br><br>  Table 2. Neural network learning results on the beauty recognition task <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f9c/b66/545/f9cb665453b57b65ef2a594ab4f7d460.jpg"><br><br>  We believe that the obtained correlation result of 0.5 on the exam sample that was not used in training is very good for the small amount of information supplied to the neural network as features.  In fact, the neural network makes a decision based on the analysis of the structure of the bones of the skull, ignoring other data that a person takes into account when solving a similar task. <br>  In the future, we plan to improve the algorithm by expanding the base of images for training, highlighting new key points on the face and incorporating a smooth skin detector into it. <br><br>  Original article (ours): <i>Chernodub AN, Pashchenko Yu.A., Golovchenko K.A.</i>  <i>Neural network system for determining the attractiveness of the human face // XV All-Russian Scientific and Technical Conference "Neuroinformatics-2013", Moscow, January 21-25, 2013, p.</i>  <i>254 - 259.</i> <br><br><h2>  Bibliography </h2><br><ol><li>  Kovach, FJ Philosophy of beauty // Norman: University of Oklahoma Press.  1974. </li><li>  Grammer K, Thornhill R. Human (Homo sapiens)  // J Comp Psychol, 1994. V. 108. No. 3. P. 233-242. </li><li>  Rhodes G. The Evolutionary Psychology of Facial Beauty // Annu.  Rev.  Psychol.  2006. V. 57. P. 199-226. </li><li>  Sheib JE, Gangestad SW, Thornhill R. Facial attractiveness, symmetry and cues of good genes // Proc Biol Sci.  1999 September 22;  266 (1431).  R. 1913-1917. </li><li>  Holland E. Marquardt's Phi Mask: A Beautiful Face // Aesthetic Plastic Surgery, 2008. V. 32, No. 2. P. 200-208. </li><li>  Aarabi, P., Hughes, D., Mohajer, K., Emami, M. The IEEE International Conference on Systems, Man, and Cybernetics, 710 October 2001, Tucson, USA.  V. 4. P. 2644-2647. </li><li>  Eisenthal Y., Dror G., Ruppin E. Facial Attractiveness: Beauty and the Machine // Neural Computation, 2006. V. 18. No. 1. P. 119-142. </li><li>  Gan J., Li L., Zhai Y. Deep self-taught by facial beauty prediction // Neurocomputing.  DOI: 10.1016 / j.neucom.2014.05.028 </li><li> Gray D., Yu. K., Xu W., Gong Y. Predicting Facial Beauty without Landmarks // Computer Vision - ECCV 2010, Lecture Notes in Computer Science, 2010, V. 6316/2010.  P. 434-447. </li><li>  Khaikin S. Neural networks: a full course.  M .: Williams, 2006. </li><li>  Calman Filter: A comparative study // Optical Memory and Neural Networks, 2014. Vol.  23, Issue 2, pp 96-103. </li></ol></div><p>Source: <a href="https://habr.com/ru/post/229549/">https://habr.com/ru/post/229549/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../229535/index.html">Conversion of a wireless USB Wi-Fi adapter TP-LINK TL-WN722N to Philips PTA01 adapter for Philips 55PFL7606H TV and others</a></li>
<li><a href="../229539/index.html">Get Zabbix statistics from Kyocera devices</a></li>
<li><a href="../229541/index.html">I will study at the Computer Science Center</a></li>
<li><a href="../229543/index.html">How to create and earn SaaS (Part 10 / Business Model Metrics)</a></li>
<li><a href="../229545/index.html">Astronomers have finally seen Voyager 1 entering interstellar space.</a></li>
<li><a href="../229551/index.html">Microsoft issues an urgent update to block fake SSL certificates</a></li>
<li><a href="../229555/index.html">Graphic models in machine learning. Yandex Workshop</a></li>
<li><a href="../229557/index.html">[Translation] Office confidentiality: where is the line that should not be crossed</a></li>
<li><a href="../229559/index.html">Overview of the 7 most popular cross-platform mobile frameworks</a></li>
<li><a href="../229561/index.html">Modern back office of IT company</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>