<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Machine Learning Hackathon: Come. To train a model. To win</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Standard plan of any hackathon ‚Üì 



 This weekend will be held on hackathon machine learning , organized by the company Microsoft. Participants of th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Machine Learning Hackathon: Come. To train a model. To win</h1><div class="post__text post__text-html js-mediator-article">  <b>Standard plan of any hackathon</b> ‚Üì <br><br><img alt="Microsoft Azure Machine Learning Hackathon" src="https://habrastorage.org/files/94d/860/165/94d860165b0049fb9cedcc24a30e7557.png"><br><br>  This weekend will be held on <a href="https://events.techdays.ru/machine-learning/2015-11/">hackathon machine learning</a> , organized by the company Microsoft.  Participants of the hackathon will have 2 days in order not to sleep well and make the world a better place. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The story in this article will be held in the same impetuous manner in which, I believe, for the majority of the participants, the hackathon will pass.  No <a href="http://0xcode.in/azure-ml-for-data-scientist">water</a> (if you are not familiar with Azure ML, then it is better to read ‚Äúwater‚Äù or some introductory material), long definitions and such long introductions as this is just what you need to win at the hackathon. <br><a name="habracut"></a><br><h2>  Keep it simple </h2><br>  one) <del>  Grab </del>  Find a coffee machine. <br>  2) You have only 2 days, so do not <del>  to make a fuss </del>  complex models: they are easily retrained and do them for a long time.  Take the most naive assumption and iteratively complicate it.  At each successful iteration, save a set of data supplied to the machine learning algorithm and the resulting model.  This is done using the ‚ÄúSave as Dataset‚Äù, ‚ÄúSave Model‚Äù menu items in the context menu of Azure ML Studio (this is the web IDE).  This way you will have dataset ‚Äì trained_model pairs for each of the iterations. <br><br><div class="spoiler">  <b class="spoiler_title">About the structure of the article</b> <div class="spoiler_text">  This is more or less the standard workflow of learning with a teacher.  I will begin with the most delicious - from the heart of this process - the training model ( <em>Train model</em> ), gradually moving to the <em>Pre-processing data</em> stage. <br><img src="https://habrastorage.org/getpro/habr/post_images/2e9/094/d47/2e9094d4744d0454a72544682bf7a6dd.png"><br><br></div></div><br><br><h2>  Collaboration </h2><br>  Create already Workspace!  Open manage.windowsazure.com, select Azure ML and create a faster Workspace.  One for the whole team, and not for everyone his personal!  Collect email from all participants and expand the Workspace between them. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1d9/343/4fd/1d93434fd9ffff2be38e7b70e00a018a.png"><br><br><br><h2>  Contribute to global warming <br></h2><br>  Below is what the simplest learning graph in Azure ML looks like. <br><br><img alt="Azure ML train model.png" src="https://habrastorage.org/getpro/habr/post_images/f82/74a/a22/f8274aa220490465a6411fd47abc3c10.png"><br><br>  But it is not that!  So you will do at home: run, drink tea, go for a walk, come, watch what happened, think, scratch your shoulder, start again, drink tea ... There is no time for this hackathon! <br><br>  Check at once all the algorithms that may come up.  ‚ÄúEverything‚Äù is Azure, not your home laptop!  Azure datacenters will warm the atmosphere of the west coast of the United States, but the process of learning models will perform!  Here is an example of what this should look like on 5 algorithms of two-class classification. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d02/e59/6a0/d02e596a037037cbf561705cdc756f80.png"><br><br>  Comparison of models trained on the logistic regression algorithm (blue curve) and the support vector machine (red curve): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0ca/965/9db/0ca9659dbafb96fe6e45815946d56dfe.png"><br><br><br><h2>  Cross validation <br></h2><br>  Include already cross-validation!  And turn it on correctly: with validation dataset, with folds, with indication of the metric you want to maximize (that is, as shown in the illustration with cross-validation). <br><br>  By enabling cross-validation, you will find out what potential best results can show the machine learning algorithm on your data, and understand how stable this algorithm is (the smaller the standard deviation, the more stable the algorithm shows). <br><br>  Results for each fold: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0b/ff7/c91/d0bff7c9164895a94a37ccef12388e02.png"><br><br><br><h2>  Sweep parameters <br></h2><br>  The key impact on the <em>performance of the</em> model is provided by the parameters of the machine learning algorithm.  So for a neural network, this is the number of hidden layers of neurons, the initial weights, for a decision tree, the number of trees, the number of leaves per tree. <br><br>  You will be engaged in the new year (and maybe in time) by manually searching several parameters for 4 classification algorithms, in the conditions of a gushing fountain of new ideas.  Make the new year something else!  And on the hackathon use the built-in module Sweep Parameters. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/15a/306/280/15a3062803d115d6087f156db321c47a.png"><br><br>  Module settings: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/488/f14/50a/488f1450ac8ae382f8f266a631eea4f8.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/476/35c/46a/47635c46a9e965d987cdb1ac95955676.png"><br><br><br><h2>  Fair data split <br></h2><br>  Separate the test and training sets (Split module).  Depending on the amount of available data in data science, it is customary to leave in the test set from 10% to 30% of the data.  Not <del>  engage in self-deception </del>  teach the model on a test suite, do not use it to check the results of cross-validation.  You only need a test dataset for one thing - check the final model. <br><br><h2>  Speed ‚Äã‚Äãup learning <br></h2><br>  The faster your model is in time to study, the more hypotheses you will have time to test.  Use modules from the Feature Selection section to not only reduce training time, but also to get the most relevant predictors and generalize the model (to make its performance better with real data). <br><br>  So, using the filter-based feature selection module in the task of determining the tonalities of tweets, I reduced the number of predictors from 160K to 20K. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d33/74d/a11/d3374da11f16523e3cb5edeb7ce166aa.png"><br><br>  Result - see the number of predictors (columns) before and after filtering: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f13/806/f10/f13806f10aeb3006ed50fa143f098324.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/3d8/623/fdb/3d8623fdb17409ab1c89f9932f249585.png"><br><br>  And the fisher linear discriminant module helped me reduce Iris Dataset from the 4xN matrix to 2xN, where N is the number of observations. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/568/d9b/5fe/568d9b5fe373ceb59b9dbfea2f49ea3d.png"><br><br>  Result - see the number of predictors (columns) before and after filtering: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9dd/a8d/0b6/9dda8d0b6cd2777ad8ca2a1dd203eae3.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/52d/85c/1bf/52d85c1bf011988ee719d48a627f4b51.png"><br><br><br><h2>  Accelerate learning.  Part 2 <br></h2><br>  Azure ML can execute your R / Python scripts.  So out of the box there is support for ~ 400 R-packages, export to Python Notebooks and this is just the beginning. <br><br>  But (!) Do not write R / Python-scripts simply because you are too lazy to understand which module in Azure ML does the same thing.  Built-in modules: <br><br><ul><li>  Optimized for Azure ML (most likely most of them are written in C ++, which sounds like ‚Äúthis is fast‚Äù); <br></li><li>  the work inside them is potentially parallelized and is distributed (since it is known in advance which modules perform parallel tasks and which ones do not); <br></li><li>  machine learning algorithms implemented in embedded modules can also potentially be <abbr title="Large-Scale Machine Learning">LSML</abbr> history (run distributed on a cluster). <br></li></ul><br>  Without pleading your programming talent, I note that your wonderfully written python script is unlikely to be executed this way, because  for Azure ML, such a script is a black box. <br><br><h2>  Feature Engineering <br></h2><br>  Understand your data!  To do this, Azure ML has both visualization tools and the ability to use ggplot2.  In addition, do not neglect the Descriptive Statistics module of descriptive statistics, which at any stage of the experiment can tell you a lot about the data. <br><br><h2>  Pre-processing <br></h2><br>  Mark the data correctly - use the Metadata Editor module. <br><br>  The Clean Missing Data module will help you cope with the missing data (delete them, replace them with the default value, median or mode). <br><br>  Anomaly Detection section and simple visualization will help detect outliers. <br><br>  Normalize (at least try) all the numeric data, whose distribution is different from the normal, using the Normalize module.  Using the same module, scale (scale) all numeric data whose absolute values ‚Äã‚Äãare large. <br><br><br><h2>  <strong>Jedi technology</strong> <br></h2><br><h2>  Jedi Techniques: Boosting and Stacking <br></h2><br>  Go to the terminology: <br><br>  <strong>Boosting</strong> is an approach in which the result is a weighted / empirically calculated estimate of several different models. <br><br>  <strong>Stacking</strong> is an approach similar to boosting: you also have several models trained in data, but you no longer have any empirical formula ‚Äî you are building a metamodel based on estimates of the initial models. <br><br>  These are very cool techniques that use data scientists of level 80 with kaggle to the fullest.  Azure ML does not have any built-in modules implementing boosting or stacking (or just bagging).  Their implementation is not very difficult, but it has its long list of subtleties. <br><br>  Here's how my application of stacking looks like to create a metamodel trained using a neural network on the Boosted Decision Tree classifiers and logistic regression. <br><br>  Schematic diagram of implemented stacking: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c28/f6a/e29/c28f6ae298041c65eba7a97d3fbcce8e.png"><br><br>  Level 1: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a59/249/39d/a5924939d96897b44a374114ec4eb079.png"><br><br>  Level 2: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/277/b05/1ba/277b051ba5da106269f4c199bc9f6c76.png"><br><br>  <em>Implementing the boosting and stacking approaches in Azure ML is a topic for a separate interesting article</em> that cannot be covered in this article.  But (!) <em>On the second day of the hackathon you can find me</em> (the bottom right <a href="http://events.techdays.ru/machine-learning/2015-11/speakers">on the page of the</a> hackathon <a href="http://events.techdays.ru/machine-learning/2015-11/speakers">speakers</a> ; I will look as bad as in the photo), and I <em>will</em> definitely <em>show how to add stacking to your model</em> and possibly improve its performance on important ones. such events are a couple-five percent. <br><br><h2>  Jedi techniques: Hadoop / HBase / Spark-cluster <br></h2><br>  I'm not kidding: you need a cluster!  But do not rush to buy hardware and start to deploy / administer the entire Hadoop ecosystem rich in software products.  It is long, expensive and ... good.  And we need to quickly and well, i.e.  HDInsight. <br><br>  <a href="https://habr.com/2012/12/hdinsight.html">Azure HDInsight</a> is a cloud service that provides a Hadoop / HBase / Spark cluster on demand.  Passing the cluster creation wizard takes 2 minutes, the cluster creation itself goes to Azure <del>  1 coffee mug </del>  ~ 10 minutes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b58/ad6/2b2/b58ad62b22134cf6c43291767ed1102d.png"><br><br>  But the most delicious thing is that HBase (if exactly, Hive requests) is supported as one of the data sources in Azure ML.  So if there is a lot of data and you need to make complex queries on them, then without hesitation, deploy the HBase cluster to Azure and upload the data to Azure ML directly from there. <br><br><h2>  Jedi Techniques: Data Science VM <br></h2><br>  Use one of the virtual machine images available in Azure VM ‚Äî the ‚ÄúData Science VM‚Äù image with the pre-installed Revolution R Open, Anaconda Python, Power BI, and <a href="http://blogs.technet.com/b/machinelearning/archive/2015/11/23/announcing-the-availability-of-the-microsoft-data-science-virtual-machine.aspx">more</a> . <br><br>  Do not limit yourself to a loved one: take a virtual machine with the right amount of memory (up to 448 GB of RAM is available), the number of cores (up to 32-cores), and, if necessary, an SSD-drive.  In general, create a comfortable working environment. <br><br><h2><del>  Look over your shoulder.  Build conspiracies.  Find the oil! </del><br></h2><br><h2>  Participate not for prizes <br></h2><br>  <em>A hackathon is an event for which one should go for the sake of the atmosphere, for the sake of communication with like-minded people, acquaintances with experts,</em> free coffee and, if it's cold outside, but there is no place to live.  Communicate, share experiences!  (The trickiest will win anyway.) <br><br><br>  By the way about communication, tomorrow <a href="https://habr.com/company/mailru/blog/271499/">Moscow Data Science Meetup</a> will be held - the most outstanding event in the most pleasant format for data scientists and those who are interested in this area. <br></div><p>Source: <a href="https://habr.com/ru/post/271697/">https://habr.com/ru/post/271697/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../271685/index.html">Spreadsheets under the hood</a></li>
<li><a href="../271687/index.html">Httplug - abstraction from HTTP client for PHP</a></li>
<li><a href="../271689/index.html">Developing your own solution: risks and responsibilities</a></li>
<li><a href="../271693/index.html">We write software for generating music card data. Part one: parse the MIDI file</a></li>
<li><a href="../271695/index.html">Developer Economics Tenth Study</a></li>
<li><a href="../271699/index.html">Professional test on the knowledge of the realities of the market for customized development and digital communications</a></li>
<li><a href="../271701/index.html">Design prototypes of cells in the same XIB with UITableView</a></li>
<li><a href="../271703/index.html">How sometimes bad code and antipattern solve</a></li>
<li><a href="../271705/index.html">End of an era of dynamic languages</a></li>
<li><a href="../271707/index.html">Mikrotik: small utility. Part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>