<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Introduction to the analysis of textual information using Python and machine learning methods</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 Today I will continue the story about the application of data analysis and machine learning methods with practical examples. In the las...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Introduction to the analysis of textual information using Python and machine learning methods</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  Today I will continue the story about the application of data analysis and machine learning methods with practical examples.  In the last <a href="http://habrahabr.ru/post/204500/">article</a> we dealt with the task of credit scoring.  Below, I will try to demonstrate the solution of another problem from the same <a href="https://www.tcsbank.ru/tournament/">tournament</a> , namely, ‚ÄúPassport Tasks‚Äù (Task No. 2). <br>  The solution will show the basics of textual information analysis, as well as its coding for building a model using Python and data analysis modules ( <a href="http://pandas.pydata.org/pandas-docs/stable/">pandas</a> , <a href="http://scikit-learn.org/">scikit-learn</a> , <a href="https://pymorphy2.readthedocs.org/en/latest/index.html">pymorphy</a> ). <br><a name="habracut"></a><br><h4>  Formulation of the problem </h4><br>  When working with large amounts of data, it is important to keep them clean.  And when filling in an application for a banking product, it is necessary to indicate full passport data, including the ‚Äúpassport issued by whom‚Äù field; the number of different spellings of the same department by potential clients can reach several hundred.  It is important to understand whether the client was not mistaken in filling in other fields: "division code", "passport number / series".  To do this, you need to check the "division code" and "who issued the passport." <br>  The task is to put down the codes of divisions for the records from the <a href="">test sample</a> , based on the <a href="">training sample</a> . <br><br><h4>  Preliminary data processing </h4><br>  Load the data and see what we have: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_csv <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pymorphy2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HashingVectorizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.cross_validation <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score, roc_auc_score <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA train = read_csv(<span class="hljs-string"><span class="hljs-string">'https://static.tcsbank.ru/documents/olymp/passport_training_set.csv'</span></span>,<span class="hljs-string"><span class="hljs-string">';'</span></span>, index_col=<span class="hljs-string"><span class="hljs-string">'id'</span></span> ,encoding=<span class="hljs-string"><span class="hljs-string">'cp1251'</span></span>) train.head(<span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br><table><tbody><tr><th></th><th>  passport_div_code </th><th>  passport_issuer_name </th><th>  passport_issue_month / year </th></tr><tr><th>  id </th><th></th><th></th><th></th></tr><tr><th>  one </th><td>  422008 </td><td>  BELOVSKY ATC KEMEROVSK REGION </td><td>  11M2001 </td></tr><tr><th>  2 </th><td>  500112 </td><td>  TP ‚Ññ2 V GOR.  NUT-ZUYEVO OUFMS RUSSIA IN MO ... </td><td>  03M2009 </td></tr><tr><th>  3 </th><td>  642001 </td><td>  VOLGA ROVD GOR.SARATOV </td><td>  04M2002 </td></tr><tr><th>  four </th><td>  162004 </td><td>  ATC MOSCOW DISTRICT KAZAN </td><td>  12M2002 </td></tr><tr><th>  five </th><td>  80001 </td><td>  THE DEPARTMENT OF OF RUSSIAN FEDERATION BY RESP. KALMYKIA IN G ELIST </td><td>  08M2009 </td></tr></tbody></table><br>  Now you can see how users record the "passport issued by anyone" field using the example of a department: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="python hljs">example_code = train.passport_div_code[train.passport_div_code.duplicated()].values[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> train.passport_issuer_name[train.passport_div_code == example_code].drop_duplicates(): <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> i</code> </pre><br>  DEPARTMENT OF UFMS OF RUSSIA IN THE REPUBLIC OF KARELIA IN BEAR.  - <br>  THE DEPARTMENT OF THE UFMS OF RUSSIA ACCORDING TO R. KARELIA IN MEDVEZHEGORSK REGION <br>  DEPARTMENT OF UFMS OF RUSSIA IN RESP KARELIA IN MEDVEZHEGORSK reg. <br>  DEPARTMENT OF UFMS OF RUSSIA IN THE REPUBLIC OF KARELIA IN MEDVEZHEGORSK DISTRICT <br>  OUFMS RUSSIA IN THE REPUBLIC OF KARELIA IN MEDVEZHEGORSK DISTRICT <br>  UFMS of Russia in Kazakhstan in Medvezhiegorsky district <br>  THE DEPARTMENT OF THE UFMS OF RUSSIA IN THE REPUBLIC OF KARELIA BEARS OF MEDVEZHEGORSK R-ONE <br>  DEPARTMENT OF UFMS OF RUSSIA IN RK IN MEDVEZHEGORSK DISTRICT <br>  THE DEPARTMENT OF THE UFMS OF RUSSIA IN THE REPUBLIC OF KORELIA IN MEDVAJIGOR DISTRICT <br>  UFMS OF RUSSIA ACROSS KARELIA OF MEDVEJEGORSKA REGION <br>  THE DEPARTMENT OF UFMS OF RUSSIA IN THE REPUBLIC OF KARELIA IN MEDWEZHORGIA <br>  UFMS REPUBLIC OF KARELIA BEARSHIP R-ON <br>  BEAR OF LAW <br><br>  As you can see, the field is really filled crookedly.  But for normal coding, we must bring this field to a more or less normal (unambiguous) form. <br>  To begin with, I would suggest to bring all the entries to one register, for example, so that all letters become lowercase.  This is easily done using the str attribute, a DataFrame column.  This attribute allows you to work with a column as with a string, as well as perform various kinds of search and replace for regular expressions: <br><br><pre> <code class="python hljs">train.passport_issuer_name = train.passport_issuer_name.str.lower() train[train.passport_div_code == example_code].head(<span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre><br><table><tbody><tr><th></th><th>  passport_div_code </th><th>  passport_issuer_name </th><th>  passport_issue_month / year </th></tr><tr><th>  id </th><th></th><th></th><th></th></tr><tr><th>  nineteen </th><td>  100010 </td><td>  Department of the UFMS of Russia in the Republic of Karelia in ... </td><td>  04M2008 </td></tr><tr><th>  22 </th><td>  100010 </td><td>  Branch Ufms Russia on the river.  Karelia in the bear ... </td><td>  10M2009 </td></tr><tr><th>  5642 </th><td>  100010 </td><td>  Department of the Ufms of Russia in Karelia in Medve ... </td><td>  08M2008 </td></tr><tr><th>  6668 </th><td>  100010 </td><td>  Department of the UFMS of Russia in the Republic of Karelia in ... </td><td>  08M2011 </td></tr><tr><th>  8732 </th><td>  100010 </td><td>  Department of the UFMS of Russia in the Republic of Karelia in ... </td><td>  08M2012 </td></tr></tbody></table><br>  C register defined.  Then you need to get rid of popular cuts, for example, a district, a city, etc.  We do this with regular expressions.  <b>Pandas</b> provides convenient use of regular expressions for each column.  It looks like this: <br><br><pre> <code class="python hljs">train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u'-(||||)*'</span></span>,<span class="hljs-string"><span class="hljs-string">u''</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u' ( |\.|((\.| )))'</span></span>, <span class="hljs-string"><span class="hljs-string">u'  '</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u' (\.| )'</span></span>, <span class="hljs-string"><span class="hljs-string">u'  '</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u' ([-]*)(\.)?'</span></span>, <span class="hljs-string"><span class="hljs-string">u'  '</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u' (\.| |( )?)'</span></span>, <span class="hljs-string"><span class="hljs-string">u'  '</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u'   '</span></span>)</code> </pre><br>  Now we will get rid of all unnecessary characters, except Russian letters, hyphens and spaces.  This is due to the fact that a passport of the same subdivision can be issued by departments with different numbers, and this will worsen further coding: <br><br><pre> <code class="python hljs">train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u' - ?'</span></span>, <span class="hljs-string"><span class="hljs-string">u'-'</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u'[^- -]'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u'- '</span></span>,<span class="hljs-string"><span class="hljs-string">' '</span></span>) train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u' *'</span></span>,<span class="hljs-string"><span class="hljs-string">' '</span></span>)</code> </pre><br>  In the next step, it is necessary to decipher the abbreviations, such as ATC, UFNS, CAD, HLW, etc., because  In principle, there are not many of them, but this will have a positive effect on the quality of further coding.  For example, if we have two records "ATC" and "management of internal affairs", then they will be encoded in different ways, because for a computer these are different values. <br>  So go to the decoding.  And, to begin with, we will get a dictionary of abbreviations, with the help of which we will do the decoding: <br><br><pre> <code class="python hljs">sokr = {<span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'-  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'-  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u'c'</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'- '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'- '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'- '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'- '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'    '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'   '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'   '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'   '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'   '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'   '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'  '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u'   '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u' '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u' '</span></span>, <span class="hljs-string"><span class="hljs-string">u''</span></span>: <span class="hljs-string"><span class="hljs-string">u' '</span></span>}</code> </pre><br><br>  Now, we will actually decrypt the abbreviations and format the resulting records: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sokr.iterkeys(): train.passport_issuer_name = train.passport_issuer_name.str.replace(<span class="hljs-string"><span class="hljs-string">u'( %s )|(^%s)|(%s$)'</span></span> % (i,i,i), <span class="hljs-string"><span class="hljs-string">u' %s '</span></span> % (sokr[i])) <span class="hljs-comment"><span class="hljs-comment">#        train.passport_issuer_name = train.passport_issuer_name.str.lstrip() train.passport_issuer_name = train.passport_issuer_name.str.rstrip()</span></span></code> </pre><br>  The preliminary stage of processing the field "by whom the passport was issued" on this finish.  And go to the field in which the date of issue. <br>  As you can see, the data in it is stored in the form: <i>month <b>M</b> year</i> . <br>  Accordingly, you can simply remove the letter ‚ÄúM‚Äù and bring the field to a numeric type.  But if you think well, then this field can be removed, because  for one month in a year, there may be several units issuing a passport, and accordingly this may spoil our model.  Based on this, remove it from the sample: <br><br><pre> <code class="python hljs">train = train.drop([<span class="hljs-string"><span class="hljs-string">'passport_issue_month/year'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br>  Now we can proceed to data analysis. <br><br><h4>  Data analysis </h4><br>  So, we have data for building a model, but they are in text form.  To build a model, it would be nice to encode them in numerical form. <br>  The authors of the <a href="http://scikit-learn.org/">scikit-learn</a> package thoughtfully took care of us and added <a href="http://scikit-learn.org/stable/modules/feature_extraction.html">several ways</a> to extract and encode text data.  Of these, I like the most two: <br><ol><li>  <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.FeatureHasher.html">FeatureHasher</a> </li><li>  <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">CountVectorizer</a> </li><li>  <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html">HashingVectorizer</a> </li></ol><br>  <b>FeatureHasher</b> converts a string to a numeric array of a specified length using a hash function (32-bit <a href="http://ru.wikipedia.org/wiki/Murmur2">Murmurhash3</a> ) <br>  <b>CountVectorizer</b> converts input text into a matrix, the values ‚Äã‚Äãof which are the numbers of occurrences of a given key (word) into text.  Unlike FeatureHasher, it has more configurable parameters (for example, you can set a <a href="http://lingvocourse.ru/wiki/index.php/%25D0%25A2%25D0%25BE%25D0%25BA%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B7%25D0%25B0%25D1%2582%25D0%25BE%25D1%2580">tokenizer</a> ), but it works slower. <br>  For a more accurate understanding of the work of CountVectorizer we give a simple example.  Suppose there is a table with text values: <br><table><tbody><tr><th>  Value </th></tr><tr><td>  one two Three </td></tr><tr><td>  three four two two </td></tr><tr><td>  four times </td></tr></tbody></table><br>  To begin with, CountVectorizer collects unique keys from all records, in our example it will be: <br><br>  [one two three four] <br><br>  The length of the list of unique keys will be the length of our coded text (in our case, this is 4).  And the numbers of the elements will correspond to the number of times the meeting of the given key with the given number in the line: <br><br>  one two three -&gt; [1,1,1,0] <br>  three four two two -&gt; [0,2,1,1] <br><br>  Accordingly, after encoding, the application of this method we get: <br><table><tbody><tr><th>  Value </th></tr><tr><td>  1,1,1,0 </td></tr><tr><td>  0,2,1,1 </td></tr><tr><td>  3,0,0,1 </td></tr></tbody></table><br>  <b>HashingVectorizer</b> is a mixture of the two methods described above.  It is possible to adjust the size of the encoded string (as in <i>FeatureHasher</i> ) and configure the tokenizer (as in the <i>CountVectorizer</i> ).  In addition, its performance is closer to the FeatureHasher. <br>  So back to the analysis.  If we take a closer look at our data set, it can be noted that there are similar lines but recorded in different ways, for example: " <i>... republics <b>and</b> Karelia ...</i> " and " <i>... according to the republic <b>,</b> Karelia ...</i> ". <br>  Accordingly, if we try to apply one of the coding methods, we now get very similar values.  Such cases can be minimized if all the words in the record are reduced to <a href="http://pymorphy2.readthedocs.org/en/0.1/glossary.html">normal form</a> . <br>  <a href="http://habrahabr.ru/post/176575/">Pymorphy</a> or <a href="http://nltk.org/">nltk works</a> well for this task.  I will use the first, because  He was originally created to work with the Russian language.  So, the function that will be responsible for normalizing and cleaning the line looks like this: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f_tokenizer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> morph = pymorphy2.MorphAnalyzer() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> type(s) == unicode: t = s.split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: t = s f = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> t: m = morph.parse(j.replace(<span class="hljs-string"><span class="hljs-string">'.'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(m) &lt;&gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: wrd = m[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> wrd.tag.POS <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (<span class="hljs-string"><span class="hljs-string">'NUMR'</span></span>,<span class="hljs-string"><span class="hljs-string">'PREP'</span></span>,<span class="hljs-string"><span class="hljs-string">'CONJ'</span></span>,<span class="hljs-string"><span class="hljs-string">'PRCL'</span></span>,<span class="hljs-string"><span class="hljs-string">'INTJ'</span></span>): f.append(wrd.normal_form) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> f</code> </pre><br>  The function does the following: <br><ul><li>  It first converts the string to a list. </li><li>  Then for all words parses </li><li>  If the word is numeral, predicative, preposition, union, particle or interjection, do not include it in the final set </li><li>  If the word does not fall into the previous list, take its normal form and add it to the final set </li></ul><br>  Now, when there is a function for normalization, we can proceed to coding using the <i>CountVectorizer</i> method.  It is chosen because it can transfer our function as a tokenizer and it will compile a list of keys using the values ‚Äã‚Äãobtained as a result of the operation of our function: <br><br><pre> <code class="python hljs">coder = HashingVectorizer(tokenizer=f_tokenizer, n_features=<span class="hljs-number"><span class="hljs-number">256</span></span>)</code> </pre><br>  As you can see, when creating a method, in addition to the tokenizer, we set another parameter <i>n_features</i> .  This parameter specifies the length of the encoded string (in our case, the string is encoded using 256 columns).  In addition, the <i>HashingVectorizer</i> has another advantage over the <i>CountVectorizer</i> , but it can immediately perform value normalization, which is good for algorithms like SVM. <br>  Now apply our encoder to the training set: <br><br><pre> <code class="python hljs">TrainNotDuble = train.drop_duplicates() trn = coder.fit_transform(TrainNotDuble.passport_issuer_name.tolist()).toarray()</code> </pre><br><h4>  Model building </h4><br>  First we need to set the values ‚Äã‚Äãfor the column, which will contain the class labels: <br><br><pre> <code class="python hljs">target = TrainNotDuble.passport_div_code.values</code> </pre><br>  The task that we solve today belongs to the class of classification problems with a variety of classes.  To solve this problem, the <a href="http://ru.wikipedia.org/wiki/Random_forest">RandomForest</a> algorithm was <a href="http://ru.wikipedia.org/wiki/Random_forest">best suited</a> .  The remaining algorithms showed very poor results (less than 50%), so I decided not to occupy space in the article.  If you wish, anyone interested can check these results. <br>  To assess the quality of the classification, we will use the number of documents for which the correct decision was made, i.e. <br><img src="https://habrastorage.org/getpro/habr/post_images/090/795/d9a/090795d9a1358f2ab41e31d0b4d38539.png" title="LaTeX: Accuracy = \ frac {P} {N}"><br>  where <i>P</i> is the number of documents on which the classifier made the right decision, and <i>N</i> is the size of the training sample. <br>  The scikit-learn package has a function for this: <b><a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html">accuracy_score</a></b> <br>  Before starting building the model itself, let's reduce the dimension using the ‚Äúprincipal component method‚Äù, since  There are a lot of 256 learning columns: <br><br><pre> <code class="python hljs">pca = PCA(n_components = <span class="hljs-number"><span class="hljs-number">15</span></span>) trn = pca.fit_transform(trn)</code> </pre><br>  The model will look like this: <br><br><pre> <code class="python hljs">model = RandomForestClassifier(n_estimators = <span class="hljs-number"><span class="hljs-number">100</span></span>, criterion=<span class="hljs-string"><span class="hljs-string">'entropy'</span></span>) TRNtrain, TRNtest, TARtrain, TARtest = train_test_split(trn, target, test_size=<span class="hljs-number"><span class="hljs-number">0.4</span></span>) model.fit(TRNtrain, TARtrain) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'accuracy_score: '</span></span>, accuracy_score(TARtest, model.predict(TRNtest))</code> </pre><br>  accuracy_score: 0.6523456 <br><br><h4>  Conclusion </h4><br>  As a conclusion, it should be noted that the resulting accuracy of 65% is close to guessing.  In order to improve, you need to handle grammatical errors and various kinds of censuses during primary processing.  This action will also have a positive effect on the dictionary when the field is encoded, i.e., its size decreases and, accordingly, the length of the string after its encoding decreases. <br>  In addition, the learning phase of the test sample was omitted specifically, since there is nothing special about it, except for bringing it to the desired form (this can be easily done using the transformation of the training sample as the basis) <br>  In the article I tried to show the minimum list of steps for processing textual information for submitting it to machine learning algorithms.  Perhaps making the first steps in data analysis, this information will be useful. <br><br>  <b>UPD</b> : <i>IPython Notebook</i> <a href="https://raw.github.com/kuznetsovin/DataScience/master/%25D0%259E%25D0%25BF%25D1%2583%25D0%25B1%25D0%25BB%25D0%25B8%25D0%25BA%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25BD%25D1%258B%25D0%25B5%2520%25D1%2581%25D1%2582%25D0%25B0%25D1%2582%25D1%258C%25D0%25B8/TKCPasportQuest.ipynb">Console TKCTask2Answer.ipynb</a> </div><p>Source: <a href="https://habr.com/ru/post/205360/">https://habr.com/ru/post/205360/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../205344/index.html">Zombie phone society</a></li>
<li><a href="../205348/index.html">Call-to-action in e-mail newsletter</a></li>
<li><a href="../205352/index.html">Fujitsu ETERNUS CS800 S4 - backup deduplication system</a></li>
<li><a href="../205354/index.html">Service for logs in 5 minutes</a></li>
<li><a href="../205358/index.html">British startup PlayCanvas became the best in Europe</a></li>
<li><a href="../205362/index.html">The new version of the components DevExpress 13.2!</a></li>
<li><a href="../205364/index.html">A prototype of an unusual add-on for GitHub, a web-help preparation system using GitHub Pages</a></li>
<li><a href="../205366/index.html">5 Things I Learned Working in a SaaS Model</a></li>
<li><a href="../205368/index.html">Application for Android - Meople.Streamer. When you do not need an account in social networks</a></li>
<li><a href="../205370/index.html">Open interface micro-conference UX-Medium ‚Ññ18</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>