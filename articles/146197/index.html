<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural networks with reflection</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, I was invited to speak at TEDx, I tried to popularly talk about the current state of affairs in AI, and in addition I set out the essence of...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural networks with reflection</h1><div class="post__text post__text-html js-mediator-article">  Recently, I was invited to speak at TEDx, I tried to popularly talk about the current state of affairs in AI, and in addition I set out the essence of those neural networks that we are currently working on (see video). <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/dUOWWuXqc3s%3Ffeature%3Doembed&amp;xid=17259,15700021,15700043,15700186,15700190,15700253,15700255,15700259&amp;usg=ALkJrhhzHZk1z0g9AeN7be3lWX68SCygXw" frameborder="0" allowfullscreen=""></iframe><br><br>  Since the report was very popular, I did not provide any details there, but the model has interesting properties that I want to talk about in more detail. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  Network structure </h5><br>  The basis was the widely known Hopfield network, but in addition to the main connections from each neuron to each (which can technically be considered as links with a delay of one cycle), additional links with delays of more than 1 cycle were added (delays of 2-8 cycles were practically investigated ). <a name="habracut"></a><br>  These additional connections also went from each neuron to each, moreover, several blocks of such connections were present at the same time - in particular, there are links from each to each video, which are delayed for 2, 3, 4, 5 and 6 cycles. <br>  Thus, for a network of N neurons, it is not N ^ 2 connections that are created, but (k + 1) * N ^ 2 connections, where k is the number of blocks of the delayed connections. <br><br><h5>  Formulation of the problem </h5><br>  In general, the task that I would like to solve with such a network in the future is self-study of dynamic images (that is, roughly speaking, the ability to select and memorize frequently encountered subsequences in some continuous sequence of images at the input). <br>  But first we decided to have a simpler task - there are several well-known sequences (namely, words composed of consecutively displayed letters), they are given in a noisy form to the input (and the show can start with any letter in the word, not necessarily the first), and the network should as soon as possible understand what kind of word is now at the entrance (this is not possible to determine right away - words have common letters and even syllables). <br>  The parameters of the model task are as follows: 6 words with 7 letters each, each letter is a picture of 100 pixels, the degree of noise is about 20% (i.e., at each display of each letter, 20% of randomly selected pixels are inverted). <br><br><h5>  Solution of the original problem </h5><br>  The network quite successfully solved the problem - almost at the human level, with such a degree of noise, when it is not always possible to understand by eye exactly which letter is being displayed, with several full-time word displays, the network can confidently say which word is being displayed.  With a small degree of noise word is recognized after the display of the first 2-4 letters. <br>  The result is good, but quite achievable by other methods. <br><br><h5>  Reflection effect </h5><br>  The behavior of the network turned out to be the most interesting after it was presented with some sequence at the input, and then ‚Äúturned off‚Äù the input, but continued to calculate its states.  It turned out that the network at the same time consistently turns into states that outwardly basically resemble letters (which is natural - according to the learning algorithm, letters should be stable states of the network), but firstly not always, and secondly, these letters are added in the sequence which somewhat resemble the syllables of the memorized words, but are not identical to them, change in a different rhythm (some letters repeat for a long time until the state changes, others pass quickly), and have a cycle length significantly exceeding the original words (remembered  words of 7 letters, and the resulting words from this process can be more than 50 letters to loop). <br>  And when showing different words at the entrance before turning it off, and when turning off at different times, the resulting words were different. <br>  Those.  it can be argued that the state of the network is extremely nontrivially dependent on its previous states.  If you allow yourself a loose interpretation of what is happening, then you can draw an analogy with dreams - they line up in complex plots, reflecting in some way previous experience, but do not repeat it directly. <br><br>  In general, the model has an interesting behavior, which certainly makes you wonder.  In the video, I allowed myself a rather bold interpretation of this behavior, but if it is wrong, you can still hope that in the foreseeable future you will still be able to explain the basic mechanisms of thinking, albeit in a rough, but fundamentally correct approximation. <br><br>  PS The discussion is extremely welcome - I cannot figure out how to solve the learning problem in the case when the sequences are not set from the outside, but need to be extracted from the input stream, and I will be very happy with any thoughts on the topic and not only. </div><p>Source: <a href="https://habr.com/ru/post/146197/">https://habr.com/ru/post/146197/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../146192/index.html">PaymentGate: PaySto Universal Payments</a></li>
<li><a href="../146193/index.html">The first programming language in modern universities of the CIS? (actual)</a></li>
<li><a href="../146194/index.html">Recovery of CISCO Linksys E2500 router</a></li>
<li><a href="../146195/index.html">GodMode in Backyard Monsters or ‚ÄúHow do you exchange data with the application?‚Äù</a></li>
<li><a href="../146196/index.html">Simple paranoid password management method</a></li>
<li><a href="../146199/index.html">Intellectual SCS. Molex MIIM system</a></li>
<li><a href="../146200/index.html">We get lost articles from network storages</a></li>
<li><a href="../146201/index.html">eBay lured the director of Google Russia to its Russian office</a></li>
<li><a href="../146202/index.html">Trends in the fall Technology Forum 2012: habrarosop</a></li>
<li><a href="../146203/index.html">One character in the UTF-16 encoding is occupied (do not spy on Wikipedia and Google!):</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>