<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Future robots will be trained through curiosity and self-determination of goals.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Imagine that a friend asks you to help tidy up his room full of different things and furniture. But also imagine that he will not help you with this, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Future robots will be trained through curiosity and self-determination of goals.</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/geektimes/post_images/81b/56c/6fa/81b56c6fab6881aabe16b1fd04f3ec7b.png"><br><br>  Imagine that a friend asks you to help tidy up his room full of different things and furniture.  But also imagine that he will not help you with this, but will simply describe to you, by showing the photos, how he would like his room to look like in the end.  The task may seem boring, but any of us will cope with it.  As children, we discovered new objects, learned to recognize them, and developed skills to deal with them.  Encouraged by curiosity, we gradually gained visual, attentive, and sensory-motor knowledge, allowing us, adults, to deal with our physical environment of our choice. <br><br>  Today's robots are not adapted for such tasks.  Imagine a humanoid robot helping to clean the room.  Suppose you showed the robot a room in a normal, cleaned state, and when there was a mess in it, you order the robot to remove it to its original state.  In such conditions, it would be very tiring to teach the robot where to direct attention, and how to manage each of the objects, to put it in the right position at the right place, or how to build a sequence of actions. <br><a name="habracut"></a><br>  And although new, complex robots and advanced algorithms appear annually, performing complex duties and finding unknown solutions for different tasks requires tedious programming of parts related to lower-level motor skills.  At best, robots are able to learn a small set of inflexible actions.  Comparing today's achievements of AI with biological intelligence, we will see that AI still has limitations in autonomy and flexibility. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The robots of the future will have to be able to learn autonomously to comprehend their surroundings, that is, to determine their own goals and effectively acquire the skills to achieve them, on the basis of acquiring, changing, summarizing and recombining the previously acquired knowledge and skills.  This will allow them, with a little extra training, to change the environment from the current state to a wide range of end states defined as a target by the user.  The question is, how can we create robots of the future that can cope with such a task? <br><br><h3>  Project GOAL-Robots </h3><br>  In search of an answer to this question, a project was launched that is important for the application of AI - a European project supervised by the <a href="http://www.istc.cnr.it/group/locen">Laboratory of Computational Embodied Neuroscience</a> (LOCEN), an Italian research group based in the Institute of Cognitive Sciences and Technologies, owned by the Italian State Research Committee ( <a href="http://www.istc.cnr.it/">ISTC-CNR</a> ). <br><br>  The project " <a href="http://cordis.europa.eu/project/rcn/203543_en.html">GOAL-Robots</a> - Targeted Autonomous Learning Robots of the Open System" [Goal-based Open-ended Autonomous Learning Robots] got the first place in the list of 11 projects that received funding from 800 participants of the <a href="https://ec.europa.eu/programmes/horizon2020/en/news/grant-agreements-signed-13-new-fet-open-projects">EU FET-OPEN call</a> (Future Emergent Technologies), and is part of the Horizon 2020 EU research program.  LOCEN and its supervisor Zhanluka Baldassar [Gianluca Baldassarre] will coordinate a consortium comprising three more important European research groups: <br><br>  <strong>1. The</strong> <a href="http://lpp.psycho.univ-paris5.fr/">Laboratory of Psychology and Perception</a> (LPP) from France, led by Kevin O'Regan, working at the Descartes Institute of Neuroscience and Cognitive Sciences in Paris, will conduct experiments related to the acquisition of skills and goals in children. <br><br>  <strong>2. The</strong> <a href="http://fias.uni-frankfurt.de/">Frankfurt Institute for Advanced Studies</a> (FIAS) in Germany, led by Jochen Triesch, will focus on the development of visual systems and motor skills similar to biological ones. <br><br>  <strong>3.</strong> A group of robotics specialists led by Jan Peters [Jan Peters], <a href="https://www.tudarmstadt.de/">Darmstadt Technical University</a> (TUDa) in Germany, will be involved in the demonstration of robots for the project. <br><br>  GOAL-Robots follows the previous European project <a href="http://www.im-clever.eu/">IM-CLeVeR</a> (‚Äúinternally motivated cumulatively learning universal robots‚Äù), in which LOCEN with previous partners studied the role of intrinsic motivation (VM) in encouraging independent learning in both living organisms and robots.  VM research began with observing how children out of curiosity explore and interact with the outside world, gaining knowledge of how things work, and acquiring a large repertoire of sensory-motor skills to interact with them. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/863/3ec/c52/8633ecc527652e24d28f73117cb89f45.jpg"><br><br>  If curiosity and VM are the basis of human universality and adaptability, then an AI with architecture and algorithm that emulates VMs can help create a ‚Äúmotivational engine‚Äù that will lead robots through an autonomous open learning process that does not require constant programming and training by humans. <br><br>  GOAL-Robots also adds an important component to developing open learning robots: goals.  A goal is an internal representation of a person about the world, a state of the body or an event, or a set of events that has two important properties.  First, a person can cause this view even in the absence of a perception of the corresponding state of the world or event.  Secondly, this challenge has a motivational effect, that is, it can influence the choice, focus the attention of the individual and behavior, and lead his learning process towards achieving the goal.  The ability to create motivational goals at will, albeit abstract ones, and their use in selecting actions and learning, is a key element of behavioral flexibility and the possibility of learning biological personalities.  The project participants believe that providing robots with suitable mechanisms for the formation and pursuit of learning objectives will radically increase their potential for independent learning. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/4eb/22d/e7c/4eb22de7c7cf597db42d3935728fdb7a.jpg"><br><br><h3>  Tasks and ideas </h3><br>  The idea of ‚Äã‚Äãthe project is in a combination of mechanisms related to the VM and the motivating power of goals.  In particular, VM will stimulate robots to independently discover new interesting events that occurred due to the actions of themselves.  Robots will explore their surroundings under the influence of curiosity and for self-setting of more and more complex goals, and use them to obtain various skills in an open style. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/a5b/c22/20b/a5bc2220b616768ee093c2ae4a022208.jpg"><br><br>  An open process of acquiring abilities requires complex mechanisms and integration of various components of the architecture.  In particular, robots will need to acquire new skills without violating previously acquired ones, and at the same time, reuse previously acquired skills to speed up the acquisition of new (knowledge transfer).  In addition, they will need to learn to combine pre-acquired skills to create more complex ones.  These are the most important tasks for AI today.  To solve them, the project will use advanced algorithms, both for processing sensory information (for example, using deep learning networks) and for organizing and using knowledge related to motor skills (for example, using dynamic motion primitives and neural networks with an echo effect [echo]. -state neural networks]). <br><br>  All mechanisms associated with different parts of the learning process will need to be integrated into a single control architecture: high-level processes of goal formation will be combined with motivational layers in which, based on VM, the robot will form and select goals.  Goals will be gradually linked to the lower level of the controllers so that the robot can recall the acquired skills to achieve the required goals and build more complex skills based on a combination of the previous ones.  The transfer of knowledge between different skills will be integrated, taking into account the need to eliminate mutual interference, and so on.  These mechanisms are useful not only for the phase of independent learning, but also for the possibility of using the knowledge gained by the user. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/81a/45e/b6b/81a45eb6b99d031859c068efb0a20bd2.jpg"><br><br>  Each year, the project will be represented by a ‚Äúrobot demonstrator‚Äù, and complex robotic platforms (such as iCub or Kuka) will be managed by architectures developed in the project for solving problems of increasing complexity.  These demonstrators will not only show progress in the project, but will also become criteria for comparing progress in the development of independent robots. <br><br>  The final demonstrator will have to face the task formulated at the beginning of the article: is it possible for a robot to demonstrate universality and adaptability, similar to human ones, interacting with the real world?  In particular, the robots will be given the task: a) to study the corresponding order of the position of several objects in containers and on the shelves, and b) to reproduce this state after the user has moved and swapped the objects. <br><br>  If the GOAL-Robots project fulfills its promises, you will no longer have to worry about lazy friends: when they ask you for help, you just ask your artificial friends to help them! </div><p>Source: <a href="https://habr.com/ru/post/398815/">https://habr.com/ru/post/398815/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../398805/index.html">Black Friday: China adopts tradition</a></li>
<li><a href="../398807/index.html">Kick NOW: Crowd Funding Trends, Part 4</a></li>
<li><a href="../398809/index.html">IP phones Akuvox. Review of budget models</a></li>
<li><a href="../398811/index.html">NASA: Scientists underestimate the rate of rise in the water level of the oceans</a></li>
<li><a href="../398813/index.html">IoT for a penny: make a device with a web interface</a></li>
<li><a href="../398817/index.html">Marketers have already won or why I will never buy myself a top smartphone</a></li>
<li><a href="../398819/index.html">60 years with hard drives</a></li>
<li><a href="../398823/index.html">Is something falling from the sky?</a></li>
<li><a href="../398825/index.html">Unbreakable code exists</a></li>
<li><a href="../398827/index.html">Created a flexible solar panel that can be used as a blinds or wallpaper</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>