<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Fast C / C ++ cache, thread safety</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Comparative testing of multithreaded caches implemented in C / C ++ and a description of how the LRU / MRU O (n) Cache series cache is designed ** RU ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Fast C / C ++ cache, thread safety</h1><div class="post__text post__text-html js-mediator-article"><h2>  Comparative testing of multithreaded caches implemented in C / C ++ and a description of how the LRU / MRU O (n) Cache series cache is designed ** RU </h2><a name="habracut"></a><br><p>  For decades, many caching algorithms have been developed: <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC%25D1%258B_%25D0%25BA%25D1%258D%25D1%2588%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D1%258F">LRU, MRU, ARC, and others ...</a>  However, when the cache was needed for multi-threaded work, a googling on this topic gave one and a half options, and the question on StackOverflow remained unanswered.  Found a <a href="">solution from Facebook</a> that relies on <a href="https://github.com/01org/tbb">Intel TBB's</a> thread-safe <a href="https://github.com/01org/tbb">repository</a> containers.  The latter also has a <a href="">multi-threaded LRU cache</a> while still in beta testing, and therefore to use it you must explicitly specify in the project: </p><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> TBB_PREVIEW_CONCURRENT_LRU_CACHE true</span></span></code> </pre> <br><p>  Otherwise, the compiler will show an error as in the Intel TBB code there is a check: </p><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> ! TBB_PREVIEW_CONCURRENT_LRU_CACHE #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">error</span></span></span><span class="hljs-meta"> Set TBB_PREVIEW_CONCURRENT_LRU_CACHE to </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> concurrent_lru_cache.h #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span></span></code> </pre> <br><p>  I wanted to somehow compare the performance of the caches - which one to choose?  Or write your own?  Earlier, when comparing single-threaded caches ( <a href="https://github.com/DimaBond174/cache_single_thread">link</a> ), I received offers to try other conditions with other keys and realized that a more convenient extensible bench was required for testing.  To make it easier to add competing algorithms to tests, I decided to wrap them in a standard interface: </p><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">IAlgorithmTester</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: IAlgorithmTester() = <span class="hljs-keyword"><span class="hljs-keyword">default</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">virtual</span></span> ~IAlgorithmTester() { } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">virtual</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onStart</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">shared_ptr</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;IConfig&gt; &amp;cfg)</span></span></span><span class="hljs-function"> </span></span>= <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">virtual</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onStop</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>= <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">virtual</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">insert</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *elem)</span></span></span><span class="hljs-function"> </span></span>= <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">virtual</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">exist</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *elem)</span></span></span><span class="hljs-function"> </span></span>= <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">virtual</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">const</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">char</span></span></span><span class="hljs-function"> * </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_algorithm_name</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>= <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span>: IAlgorithmTester(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> IAlgorithmTester&amp;) = <span class="hljs-keyword"><span class="hljs-keyword">delete</span></span>; IAlgorithmTester&amp; <span class="hljs-keyword"><span class="hljs-keyword">operator</span></span>=(<span class="hljs-keyword"><span class="hljs-keyword">const</span></span> IAlgorithmTester&amp;) = <span class="hljs-keyword"><span class="hljs-keyword">delete</span></span>; };</code> </pre> <br><p>  Similarly, the interfaces are wrapped: working with the operating system, getting settings, test cases, etc. The <a href="https://github.com/DimaBond174/cache_multi_thread">sources are uploaded to the repository</a> .  Now there are two test cases on the stand: insert / search up to 1,000,000 items with a key of randomly generated numbers and up to 100,000 items with a string key (taken from 10MB lines of wiki.train.tokens).  To estimate the execution time, each test cache is first heated to the target volume without time measurements, then the semaphore drops the data stream for adding and searching data.  The number of streams and test case <a href="">settings</a> are set in <a href="">assets / settings.json</a> .  Step-by-step instructions for compiling and describing JSON settings are described in the <a href="https://github.com/DimaBond174/cache_multi_thread/wiki">WiKi repository</a> .  The time is recorded from the moment the semaphore is lowered until the last thread stops.  Here's what happened: </p><br><p>  Test case1 is a key in the form of an array of random numbers uint64_t keyArray [3]: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2af/2d2/f31/2af2d2f3164176a1cf471c2cad1a4046.png" alt="TestCase1.Nthread"></p><br><p>  Test case2 - key as a string: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/1c7/217/af4/1c7217af425c0aa4df787539f1da5533.png" alt="TestCase2.Nthread"></p><br><p>  Please note that the amount of inserted / searched data at each step of the test case increases 10 times.  Then I divide the time for processing the next volume by 10, 100, 1000, respectively ... If the algorithm, according to the time complexity, behaves like O (n), then the timeline will remain approximately parallel to the X axis. get 3-5 fold superiority over Facebook cache in O (n) Cache ** RU algorithms when working with a string key: </p><br><ol><li>  The hash function, instead of counting each letter of a string, simply casts a pointer to the given string to the uint64_t keyArray [3] and counts the sum of the integers.  That is, it works like the transfer "Guess the melody" - and I guess the melody by 3 notes ... 3 * 8 = 24 letters if the Latin alphabet, and this already allows you to scatter the lines well enough on the hash baskets.  Yes, many lines can be collected in a hash basket, and then the algorithm starts to accelerate: </li><li>  <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BF%25D0%25B8%25D1%2581%25D0%25BE%25D0%25BA_%25D1%2581_%25D0%25BF%25D1%2580%25D0%25BE%25D0%25BF%25D1%2583%25D1%2581%25D0%25BA%25D0%25B0%25D0%25BC%25D0%25B8">Skip List</a> in each basket allows you to quickly move irregularly first on different hashes (basket id = hash% number of baskets, so different hashes may appear in one basket), then within one hash along the vertices: <br><img src="https://habrastorage.org/getpro/habr/post_images/920/cc6/95b/920cc695bd3a4a41f956a7782a3b65aa.gif" alt="skip"></li><li>  Nodes in which keys are stored and data are taken from a previously allocated array of nodes, the number of nodes coincides with the cache capacity.  Atomic identifier indicates which node to take next - if it reaches the end of the node pool, it starts with 0 = so the allocator walks in a circle overwriting the old nodes ( <a href="">LRU cache in OnCacheMLRU</a> ). </li></ol><br><p>  For the case when it is necessary that the most popular items in search queries are saved in the cache, the <a href="">second class OnCacheMMRU is created</a> , the algorithm is as follows: in the class constructor, besides the cache capacity, the second parameter is passed to uint32_t uselessness if the number of search queries that wanted the current node from the cyclic pool is less border uselessness, then the node is reused for the next insert operation (to be evicted).  If the node‚Äôs popularity (std :: atomic &lt;uint32_t&gt; used {0}) is high on this circle, then at the time of the cyclic pool allocator request, the node will survive, but the popularity counter will be reset to 0. This node will have one more pass of the allocator on the pool of nodes and get a chance to gain popularity again to continue to exist.  That is, it is a mixture of MRU algorithms (where the most popular ones hang in the cache forever) and MQ (where the lifetime is tracked).  The cache is constantly updated and it works very fast - instead of 10 servers you can put 1 </p><br><p>  In large, the caching algorithm spends time on the following: </p><br><ol><li>  Maintaining the cache infrastructure (containers, allocators, tracking the lifetime and popularity of items) </li><li>  Calculation of the hash and key comparison operations when adding / searching data </li><li>  Search Algorithms: Red-Black Tree, Hash Table, Skip List, ... </li></ol><br><p>  It was necessary to simply reduce the operating time of each of these points, given the fact that the simplest algorithm turns out to be most efficient in terms of time complexity, since any logic takes CPU cycles.  That is, no matter what you write, these are operations that should pay off in time in comparison with the simple iteration method: while another function is called, the search will have to go through another hundred or two nodes.  In this light, multi-threaded caches will always be single-threaded, since protecting the baskets through std :: shared_mutex and nodes via std :: atomic_flag in_use is not free.  Therefore, for issuing on the server, I use the <a href="">OnCacheSMRU</a> single-thread cache in the main thread of the Epoll server (only parallel operations with the DBMS, disk, and cryptography have been made into parallel workflows).  For comparative evaluation, a single-flow test case version is used: </p><br><p>  Test case1 is a key in the form of an array of random numbers uint64_t keyArray [3]: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/1ce/b9f/648/1ceb9f648a8899ed3ac711d236c6c0d1.png" alt="TestCase1.1thread"></p><br><p>  Test case2 - key as a string: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d9d/b3f/aef/d9db3faefdd6c2ab68dd86b89fda15a6.png" alt="TestCase2.1thread"></p><br><p>  In conclusion, I want to tell you what else can be interesting to extract from the source of the test bench: </p><br><ul><li>  <a href="">The JSON parsing library, consisting of a single file, specjson.h,</a> is a small, simple, fast algorithm for those who do not want to drag a few megabytes of someone else‚Äôs code into their project in order to parse the settings file or incoming JSON of a known format. </li><li>  Approach with injecting implementation of platform-specific operations in the form of (class LinuxSystem: public ISystem {...}) instead of the traditional (#ifdef _WIN32).  So it is more convenient to wrap, for example, semaphores, work with dynamically connected libraries, services ‚Äî in classes, only code and headers from a specific operating system.  If you need another operating system, you inject another implementation (class WindowsSystem: public ISystem {...}). </li><li>  The stand is going to CMake - the CMakeLists.txt project is easy to open in Qt Creator or Microsoft Visual Studio 2017. Working with a project through CmakeLists.txt allows you to automate some preparatory operations ‚Äî for example, copy test case files and setup files to the installation directory: </li></ul><br><pre> <code class="cmake hljs"> <span class="hljs-comment"><span class="hljs-comment"># Coping assets (TODO any change&amp;rerun CMake to copy): FILE(MAKE_DIRECTORY ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/assets) FILE(GLOB_RECURSE SpecAssets ${CMAKE_CURRENT_SOURCE_DIR}/assets/*.* ${CMAKE_CURRENT_SOURCE_DIR}/assets/* ) FOREACH(file ${SpecAssets}) FILE(RELATIVE_PATH ITEM_PATH_REL ${CMAKE_CURRENT_SOURCE_DIR}/assets ${file} ) GET_FILENAME_COMPONENT(dirname ${ITEM_PATH_REL} DIRECTORY) FILE(MAKE_DIRECTORY ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/assets/${dirname}) FILE(COPY ${file} DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/assets/${dirname}) ENDFOREACH()</span></span></code> </pre> <br><ul><li>  For those who are mastering the new features of C ++ 17, this is an example of working with std :: shared_mutex, std :: allocator &lt;std :: shared_mutex&gt;, static thread_local in templates (are there nuances - where is the allotment?), Running a large number of tests in flows in different ways with the measurement of execution time: </li></ul><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">//Prepare insert threads: for (i = cnt_insert_threads; i; --i) { std::promise&lt;InsertResults&gt; prom; fut_insert_results.emplace_back(prom.get_future()); threads.emplace_back(std::thread (&amp;TestCase2::insert_in_thread, this, curSize, std::move(prom), p_tester)); } // for insert //Prepare find threads: for (i = cnt_find_threads; i; --i) { std::packaged_task&lt;FindResults(TestCase2 *i, int, IAlgorithmTester *)&gt; ta( [](TestCase2 *i, int count, IAlgorithmTester *p_tester){ return i-&gt;find_in_thread(count, p_tester); }); fut_find_results.emplace_back(ta.get_future()); threads.emplace_back( std::thread (std::move(ta), this, curSize, p_tester)); } // for find //Banzai!!! auto start = std::chrono::high_resolution_clock::now(); l_cur_system.get()-&gt;signal_semaphore(cnt_find_threads + cnt_insert_threads); std::for_each(threads.begin(), threads.end(), std::mem_fn(&amp;std::thread::join)); auto end = std::chrono::high_resolution_clock::now();</span></span></code> </pre> <br><ul><li>  Step by step instructions on how to compile, configure and run this test bench - <a href="https://github.com/DimaBond174/cache_multi_thread/wiki">WiKi</a> . <br>  If you don‚Äôt have step-by-step instructions for your operating system, then I would be grateful for your contribution to the repository for the implementation of the ISystem and step-by-step compilation instructions (for WiKi) ... Or just write me - I will try to find time to raise the virtual machine and describe the build steps. </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/450004/">https://habr.com/ru/post/450004/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../449998/index.html">FAQ: what a traveler should know about vaccinations before the trip</a></li>
<li><a href="../45/index.html">Ratings for comments.</a></li>
<li><a href="../450/index.html">Changes in the search interface Webalta</a></li>
<li><a href="../4500/index.html">Mark Kyuban about creating GooTube: this is crazy</a></li>
<li><a href="../450000/index.html">(Left to right (Through the Looking Glass)</a></li>
<li><a href="../450006/index.html">Chiller cooling data center: which coolant to choose?</a></li>
<li><a href="../450010/index.html">Photo storage, backup and cataloging</a></li>
<li><a href="../450016/index.html">Creating a system of formal verification from scratch. Part 1: symbolic virtual machine in PHP and Python</a></li>
<li><a href="../450018/index.html">Mathematical duet mapped an infinite area of ‚Äã‚Äãminimal surfaces</a></li>
<li><a href="../450024/index.html">On open-source implementations of the GOST R 34.11-2012 hash function and their impact on the electronic signature GOST R 34.10-2012</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>