<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Autoencoders in Keras, Part 2: Manifold learning and latent variables</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content 


- Part 1: Introduction 
- Part 2: Manifold learning and latent variables 
- Part 3: Variational autoencoders ( VAE ) 
- Part 4: Conditional...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Autoencoders in Keras, Part 2: Manifold learning and latent variables</h1><div class="post__text post__text-html js-mediator-article"><h3>  Content </h3><br><ul><li>  Part 1: <a href="https://habrahabr.ru/post/331382/">Introduction</a> <br></li><li>  <strong>Part 2: <em>Manifold learning</em> and <em>latent</em> variables</strong> <br></li><li>  Part 3: <a href="https://habrahabr.ru/post/331552/">Variational autoencoders ( <em>VAE</em> )</a> <br></li><li>  Part 4: <a href="https://habrahabr.ru/post/331664/"><em>Conditional VAE</em></a> <br></li><li>  Part 5: <a href="https://habrahabr.ru/post/332000/"><em>GAN</em> (Generative Adversarial Networks) and tensorflow</a> <br></li><li>  Part 6: <a href="https://habrahabr.ru/post/332074/"><em>VAE</em> + <em>GAN</em></a> <br></li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/46b/e14/15d/46be1415d995915a25aeb8fae24b8295.gif"><br><br>  In order to better understand how autoencoders work, and also to subsequently generate something new from codes, it is worth understanding what codes are and how they can be interpreted. <br><a name="habracut"></a><br><h2>  Manifold learning </h2><br>  Images of numbers <em>mnist</em> (in which examples in the last part) are elements <img src="https://habrastorage.org/getpro/habr/post_images/9e9/7b1/e54/9e97b1e54ea7148a6fbe395ee91fe79e.svg" alt="28 * 28 = 784">  -dimensional space, as in general, any monochrome image 28 to 28. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      However, among all images, images of numbers occupy only a tiny part, the absolute majority of images are just noise. <br><br>  On the other hand, if you take an arbitrary image of a digit, then all the images from a certain neighborhood can also be considered a digit. <br><br>  And if you take two arbitrary images of a digit, then in the original 784-dimensional space you can most likely find a continuous curve, all points along which you can also be considered as numbers (at least for images of numbers of one label), and along with the previous remark, all points of some area along this curve. <br><br>  Thus, in the space of all images there is a certain subspace of smaller dimension in the area around which the images of numbers are concentrated.  That is, if our population is all images of numbers that can be drawn in principle, then the density of probability to meet such a figure within the region is much higher than outside. <br><br>  Autoencoders with the dimension of code k are looking for a k-dimensional manifold in the space of objects, which most fully conveys all variations in the sample.  And the code itself sets the parameterization of this manifold.  In this case, the encoder associates an object with its parameter on a manifold, and the decoder associates a point in the object space with a parameter. <br><br>  The larger the dimension of the codes, the more variations in the data the autoencoder can transmit.  If the dimension of the codes is too small, the autoencoder will memorize something in between the missing variations in the given metric (this is one of the reasons why <em>mnist</em> numbers become more blurred as the code dimension decreases in the autoencoders). <br><br>  In order to better understand what is <strong><em>manifold learning</em></strong> , we will create a simple two-dimensional dataset in the form of a curve plus noise and we will train an autoencoder on it. <br><br><div class="spoiler">  <b class="spoiler_title">Code and visualization</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    import numpy as np import matplotlib.pyplot as plt %matplotlib inline import seaborn as sns #   x1 = np.linspace(-2.2, 2.2, 1000) fx = np.sin(x1) dots = np.vstack([x1, fx]).T noise = 0.06 * np.random.randn(*dots.shape) dots += noise #       from itertools import cycle size = 25 colors = ["r", "g", "c", "y", "m"] idxs = range(0, x1.shape[0], x1.shape[0]//size) vx1 = x1[idxs] vdots = dots[idxs]</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  plt.figure(figsize=(12, 10)) plt.xlim([-2.5, 2.5]) plt.scatter(dots[:, 0], dots[:, 1]) plt.plot(x1, fx, color="red", linewidth=4) plt.grid(False)</span></span></code> </pre><br></div></div><br><img src="https://habrastorage.org/web/466/06c/a7c/46606ca7cbdf460ca3987022664dc1a7.png"><br>  In the picture above: the blue dots are the data, and the red curve is the variety that defines our data. <br><br><h3>  Linear compression autoencoder </h3><br>  The simplest autoencoder is a two-layer compression autoencoder with linear activation functions (more layers do not make sense with linear activation). <br><br>  Such an autoencoder is looking for an affine (linear with a shift) subspace in the object space that describes the greatest variation in objects, the <strong><em>PCA</em></strong> (principal component method) does the same thing, and both of them find the same subspace <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">linear_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_dots = Input((<span class="hljs-number"><span class="hljs-number">2</span></span>,)) code = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)(input_dots) out = Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)(code) ae = Model(input_dots, out) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ae ae = linear_ae() ae.compile(Adam(<span class="hljs-number"><span class="hljs-number">0.01</span></span>), <span class="hljs-string"><span class="hljs-string">'mse'</span></span>) ae.fit(dots, dots, epochs=<span class="hljs-number"><span class="hljs-number">15</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">30</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    pdots = ae.predict(dots, batch_size=30) vpdots = pdots[idxs] #  PCA from sklearn.decomposition import PCA pca = PCA(1) pdots_pca = pca.inverse_transform(pca.fit_transform(dots))</span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Visualization</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  plt.figure(figsize=(12, 10)) plt.xlim([-2.5, 2.5]) plt.scatter(dots[:, 0], dots[:, 1], zorder=1) plt.plot(x1, fx, color="red", linewidth=4, zorder=10) plt.plot(pdots[:,0], pdots[:,1], color='white', linewidth=12, zorder=3) plt.plot(pdots_pca[:,0], pdots_pca[:,1], color='orange', linewidth=4, zorder=4) plt.scatter(vpdots[:,0], vpdots[:,1], color=colors*5, marker='*', s=150, zorder=5) plt.scatter(vdots[:,0], vdots[:,1], color=colors*5, s=150, zorder=6) plt.grid(False)</span></span></code> </pre><br></div></div><br><img src="https://habrastorage.org/web/47c/50d/2d8/47c50d2d8ab34d1bb9268b953d50ac25.png"><br>  In the picture above: <br><br><ul><li>  the white line is the manifold to which the blue data points after the autoencoder go, that is, the autoencoder's attempt to construct the manifold that determines the most variations in the data, <br></li><li>  the orange line is the manifold to which the blue data points go after the PCA, <br></li><li>  colored circles are points that turn into asterisks of the corresponding color after the autoencoder, <br></li><li>  multi-colored asterisks - respectively, the images of circles after the auto-encoder. <br></li></ul><br>  An autoencoder looking for linear dependencies may not be as useful as an autoencoder, which can find arbitrary dependencies in data.  It would be useful if both the encoder and the decoder could approximate arbitrary functions.  If both the encoder and the decoder are added at least one layer of sufficient size and a non-linear activation function between them, they can find arbitrary dependencies. <br><br><h3>  Deep autoencoder </h3><br>  A deep autoencoder has more layers and the most important is a non-linear activation function between them (in our case, <em>ELU</em> is the Exponential Linear Unit). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">deep_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_dots = Input((<span class="hljs-number"><span class="hljs-number">2</span></span>,)) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(input_dots) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(x) code = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)(x) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(code) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(x) out = Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)(x) ae = Model(input_dots, out) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ae dae = deep_ae() dae.compile(Adam(<span class="hljs-number"><span class="hljs-number">0.003</span></span>), <span class="hljs-string"><span class="hljs-string">'mse'</span></span>) dae.fit(dots, dots, epochs=<span class="hljs-number"><span class="hljs-number">200</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">30</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>) pdots_d = dae.predict(dots, batch_size=<span class="hljs-number"><span class="hljs-number">30</span></span>) vpdots_d = pdots_d[idxs]</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Visualization</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  plt.figure(figsize=(12, 10)) plt.xlim([-2.5, 2.5]) plt.scatter(dots[:, 0], dots[:, 1], zorder=1) plt.plot(x1, fx, color="red", linewidth=4, zorder=10) plt.plot(pdots_d[:,0], pdots_d[:,1], color='white', linewidth=12, zorder=3) plt.plot(pdots_pca[:,0], pdots_pca[:,1], color='orange', linewidth=4, zorder=4) plt.scatter(vpdots_d[:,0], vpdots_d[:,1], color=colors*5, marker='*', s=150, zorder=5) plt.scatter(vdots[:,0], vdots[:,1], color=colors*5, s=150, zorder=6) plt.grid(False)</span></span></code> </pre><br></div></div><br><img src="https://habrastorage.org/web/2ac/23b/f25/2ac23bf258a44a3eb795e09668a734de.png"><br><br>  Such an autoencoder made it almost perfectly possible to build a defining manifold: the white curve almost coincides with the red one. <br><br>  A deep autoencoder can theoretically find a variety of arbitrary complexity, for example, one about which numbers lie in a 784-dimensional space. <br><br>  If we take two objects and look at objects lying on an arbitrary curve between them, then most likely intermediate objects will not belong to the general population, since the variety on which the general population lies may be highly curved and small. <br><br>  Let's return to the handwritten numbers from the previous part. <br><br>  First, we move in a straight line in the space of numbers from one bit to another: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Conv2D, MaxPooling2D, UpSampling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test .astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_train = np.reshape(x_train, (len(x_train), <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x_test = np.reshape(x_test, (len(x_test), <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-comment"><span class="hljs-comment">#   def create_deep_conv_ae(): input_img = Input(shape=(28, 28, 1)) x = Conv2D(128, (7, 7), activation='relu', padding='same')(input_img) x = MaxPooling2D((2, 2), padding='same')(x) x = Conv2D(32, (2, 2), activation='relu', padding='same')(x) x = MaxPooling2D((2, 2), padding='same')(x) encoded = Conv2D(1, (7, 7), activation='relu', padding='same')(x) #     (7, 7, 1) .. 49- input_encoded = Input(shape=(7, 7, 1)) x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded) x = UpSampling2D((2, 2))(x) x = Conv2D(128, (2, 2), activation='relu', padding='same')(x) x = UpSampling2D((2, 2))(x) decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(x) #  encoder = Model(input_img, encoded, name="encoder") decoder = Model(input_encoded, decoded, name="decoder") autoencoder = Model(input_img, decoder(encoder(input_img)), name="autoencoder") return encoder, decoder, autoencoder c_encoder, c_decoder, c_autoencoder = create_deep_conv_ae() c_autoencoder.compile(optimizer='adam', loss='binary_crossentropy') c_autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test)) def plot_digits(*args): args = [x.squeeze() for x in args] n = min([x.shape[0] for x in args]) plt.figure(figsize=(2*n, 2*len(args))) for j in range(n): for i in range(len(args)): ax = plt.subplot(len(args), n, i*n + j + 1) plt.imshow(args[i][j]) plt.gray() ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) plt.show() #         def plot_homotopy(frm, to, n=10, decoder=None): z = np.zeros(([n] + list(frm.shape))) for i, t in enumerate(np.linspace(0., 1., n)): z[i] = frm * (1-t) + to * t if decoder: plot_digits(decoder.predict(z, batch_size=n)) else: plot_digits(z)</span></span></code> </pre><br></div></div><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      frm, to = x_test[y_test == 8][1:3] plot_homotopy(frm, to)</span></span></code> </pre><br><img src="https://habrastorage.org/web/c5a/022/779/c5a0227796c84ac8994bec7e34d939e0.png"><br><br>  If we move along a curve between the codes (and if the variety of codes is well parametrized), then the decoder will translate this curve from the code space to a curve that does not leave the defining manifold in the space of objects.  That is, intermediate objects on the curve will belong to the entire population. <br><br><pre> <code class="python hljs">codes = c_encoder.predict(x_test[y_test == <span class="hljs-number"><span class="hljs-number">8</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">3</span></span>]) plot_homotopy(codes[<span class="hljs-number"><span class="hljs-number">0</span></span>], codes[<span class="hljs-number"><span class="hljs-number">1</span></span>], n=<span class="hljs-number"><span class="hljs-number">10</span></span>, decoder=c_decoder)</code> </pre><br><img src="https://habrastorage.org/web/ed0/721/dc6/ed0721dc647143839e16f4c61a33cb22.png"><br>  Intermediate figures - quite a good eight. <br><br>  Thus, it can be said that the autoencoder, at least locally, learned the form of the defining manifold. <br><br><h3>  Reengineering autoencoder </h3><br>  In order for the autoencoder to learn how to isolate any complex patterns, the generalizing abilities of the encoder and decoder must be limited, otherwise even an autoencoder with a one-dimensional code can simply draw a one-dimensional curve through each point in the training set, i.e.  just remember each object.  But this complex manifold, which the autoencoder will build, will not have much in common with the manifold defining population. <br><br>  Let's take the same problem with artificial data, train the same deep autoencoder on a very small subset of points and look at the resulting variety: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs">dae = deep_ae() dae.compile(Adam(<span class="hljs-number"><span class="hljs-number">0.0003</span></span>), <span class="hljs-string"><span class="hljs-string">'mse'</span></span>) x_train_oft = np.vstack([dots[idxs]]*<span class="hljs-number"><span class="hljs-number">4000</span></span>)</code> </pre><br><br><pre> <code class="python hljs">dae.fit(x_train_oft, x_train_oft, epochs=<span class="hljs-number"><span class="hljs-number">200</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">15</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><br><pre> <code class="python hljs">pdots_d = dae.predict(dots, batch_size=<span class="hljs-number"><span class="hljs-number">30</span></span>) vpdots_d = pdots_d[idxs] plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) plt.xlim([<span class="hljs-number"><span class="hljs-number">-2.5</span></span>, <span class="hljs-number"><span class="hljs-number">2.5</span></span>]) plt.scatter(dots[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], dots[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], zorder=<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(x1, fx, color=<span class="hljs-string"><span class="hljs-string">"red"</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">4</span></span>, zorder=<span class="hljs-number"><span class="hljs-number">10</span></span>) plt.plot(pdots_d[:,<span class="hljs-number"><span class="hljs-number">0</span></span>], pdots_d[:,<span class="hljs-number"><span class="hljs-number">1</span></span>], color=<span class="hljs-string"><span class="hljs-string">'white'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">6</span></span>, zorder=<span class="hljs-number"><span class="hljs-number">3</span></span>) plt.plot(pdots_pca[:,<span class="hljs-number"><span class="hljs-number">0</span></span>], pdots_pca[:,<span class="hljs-number"><span class="hljs-number">1</span></span>], color=<span class="hljs-string"><span class="hljs-string">'orange'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">4</span></span>, zorder=<span class="hljs-number"><span class="hljs-number">4</span></span>) plt.scatter(vpdots_d[:,<span class="hljs-number"><span class="hljs-number">0</span></span>], vpdots_d[:,<span class="hljs-number"><span class="hljs-number">1</span></span>], color=colors*<span class="hljs-number"><span class="hljs-number">5</span></span>, marker=<span class="hljs-string"><span class="hljs-string">'*'</span></span>, s=<span class="hljs-number"><span class="hljs-number">150</span></span>, zorder=<span class="hljs-number"><span class="hljs-number">5</span></span>) plt.scatter(vdots[:,<span class="hljs-number"><span class="hljs-number">0</span></span>], vdots[:,<span class="hljs-number"><span class="hljs-number">1</span></span>], color=colors*<span class="hljs-number"><span class="hljs-number">5</span></span>, s=<span class="hljs-number"><span class="hljs-number">150</span></span>, zorder=<span class="hljs-number"><span class="hljs-number">6</span></span>) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre><br></div></div><br><img src="https://habrastorage.org/web/6ea/bd6/fa8/6eabd6fa8110439e975e77ce8d20f281.png"><br><br>  It can be seen that the white curve has passed through each data point and is slightly similar to the red curve defining the data: the face has a typical re-training. <br><br><h2>  Hidden variables </h2><br>  You can consider the population as some data generation process. <img src="https://habrastorage.org/getpro/habr/post_images/321/8c7/f74/3218c7f74f7f865cc525a03fdd9aed8f.svg" alt="X">  which depends on a number of hidden variables. <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  (random variables).  Data dimension <img src="https://habrastorage.org/getpro/habr/post_images/321/8c7/f74/3218c7f74f7f865cc525a03fdd9aed8f.svg" alt="X">  may be much higher than the dimension of hidden random variables <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  which this data defines.  Consider the process of generating regular numbers: how the figure will look can depend on many factors: <br><br><ul><li>  desired digits <br></li><li>  stroke thickness <br></li><li>  tilt digits <br></li><li>  neatness <br></li><li>  etc. <br></li></ul><br>  Each of these factors has its own prior distribution, for example, the probability that a figure of eight will be drawn is the Bernoulli distribution with a probability of 1/10, the thickness of the stroke also has some distribution and may depend on both accuracy and its hidden variables, such as the thickness of the handle or the temperament of a person (again with their own distributions). <br><br>  Autoencoder itself in the process of learning must come to hidden factors, for example, such as those listed above, some of their complex combinations, or in general to completely different ones.  However, the joint distribution that he learns does not have to be simple, it can be some kind of complex curved area.  (The decoder can also transfer values ‚Äã‚Äãfrom outside this area, only the results will no longer be from the defining manifold, but from its random continuous continuation). <br><br>  That's why we can't just generate new ones. <img src="https://habrastorage.org/getpro/habr/post_images/321/8c7/f74/3218c7f74f7f865cc525a03fdd9aed8f.svg" alt="X">  from the distribution of these hidden variables.  It is difficult to remain within the region, and even harder to somehow interpret the values ‚Äã‚Äãof the hidden variables in this curve region. <br><br>  For definiteness, we introduce some notation on the example of numbers: <br><br><ul><li><img src="https://habrastorage.org/getpro/habr/post_images/321/8c7/f74/3218c7f74f7f865cc525a03fdd9aed8f.svg" alt="X">  - random size of the picture 2828, <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  - random value of hidden factors that determine the number in the picture, <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/07c/ac3/48a/07cac348a2fbdab83d94fc609c515ec6.svg" alt="p (x)">  - the probability distribution of images of figures in pictures, i.e.  the probability of a particular image of a digit is in principle to be drawn (if the picture is not like a digit, then this probability is extremely small), <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/80a/5b2/13f/80a5b213fc4521fb411f92840c8495a2.svg" alt="p (z)">  - the probability distribution of hidden factors, for example, the distribution of the thickness of the stroke, <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/12f/bf4/45c/12fbf445c3d9cbc5369b206b362da43f.svg" alt="p (Z | X)">  - probability distribution of hidden factors for a given picture (a different combination of hidden variables and noise can lead to the same picture), <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/69e/396/f74/69e396f74618eb938446472e7cf8db2a.svg" alt="p (X | Z)">  - the probability distribution of pictures for given hidden factors, the same factors can lead to different pictures (the same person in the same conditions does not draw absolutely identical numbers), <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/164/ac8/fc2/164ac8fc2aa6d73698db8cea0764e327.svg" alt="p (X, Z)">  - joint distribution <img src="https://habrastorage.org/getpro/habr/post_images/321/8c7/f74/3218c7f74f7f865cc525a03fdd9aed8f.svg" alt="X">  and <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  , the most complete understanding of the data needed to generate new objects. <br></li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9e5/725/7b3/9e57257b3faf756ff29e88ce330e964a.svg" alt="p (X, Z) = p (X | Z) p (Z)"></div><br><img src="https://habrastorage.org/getpro/habr/post_images/69e/396/f74/69e396f74618eb938446472e7cf8db2a.svg" alt="p (X | Z)">  the decoder brings us closer but <img src="https://habrastorage.org/getpro/habr/post_images/80a/5b2/13f/80a5b213fc4521fb411f92840c8495a2.svg" alt="p (z)">  at the moment we still do not understand. <br><br>  Let's see how the hidden variables are distributed in the usual autoencoder: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flatten, Reshape <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.regularizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> L1L2 <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_deep_sparse_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(lambda_l1)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    encoding_dim = 16 #  input_img = Input(shape=(28, 28, 1)) flat_img = Flatten()(input_img) x = Dense(encoding_dim*4, activation='relu')(flat_img) x = Dense(encoding_dim*3, activation='relu')(x) x = Dense(encoding_dim*2, activation='relu')(x) encoded = Dense(encoding_dim, activation='linear', activity_regularizer=L1L2(lambda_l1, 0))(x) #  input_encoded = Input(shape=(encoding_dim,)) x = Dense(encoding_dim*2, activation='relu')(input_encoded) x = Dense(encoding_dim*3, activation='relu')(x) x = Dense(encoding_dim*4, activation='relu')(x) flat_decoded = Dense(28*28, activation='sigmoid')(x) decoded = Reshape((28, 28, 1))(flat_decoded) #  encoder = Model(input_img, encoded, name="encoder") decoder = Model(input_encoded, decoded, name="decoder") autoencoder = Model(input_img, decoder(encoder(input_img)), name="autoencoder") return encoder, decoder, autoencoder encoder, decoder, autoencoder = create_deep_sparse_ae(0.) autoencoder.compile(optimizer=Adam(0.0003), loss='binary_crossentropy')</span></span></code> </pre><br><pre> <code class="python hljs">autoencoder.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">100</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> imgs = x_test[:n] decoded_imgs = autoencoder.predict(imgs, batch_size=n) plot_digits(imgs, decoded_imgs)</code> </pre><br></div></div><br>  Here are the images recovered by this encoder: <br><br><div class="spoiler">  <b class="spoiler_title">Images</b> <div class="spoiler_text"><img src="https://habrastorage.org/web/10c/cad/203/10ccad2039094750bd04caccaca4fcc0.png"><br></div></div><br>  Joint allocation of hidden variables <img src="https://habrastorage.org/getpro/habr/post_images/cc3/12e/bec/cc312ebec5765cc5dfb0ad49a77e7665.svg" alt="P (Z_1, Z_3)"><br><br><pre> <code class="python hljs">codes = encoder.predict(x_test) sns.jointplot(codes[:,<span class="hljs-number"><span class="hljs-number">1</span></span>], codes[:,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre><br><img src="https://habrastorage.org/web/76c/1ac/9eb/76c1ac9eb7f04ce582102c1c62d924ba.png"><br><br>  It is seen that the joint distribution <img src="https://habrastorage.org/getpro/habr/post_images/cc3/12e/bec/cc312ebec5765cc5dfb0ad49a77e7665.svg" alt="P (Z_1, Z_3)">  has a complex shape; <img src="https://habrastorage.org/getpro/habr/post_images/8dc/ed9/9aa/8dced99aa56cfe168d13700d9f5999a8.svg" alt="Z_1">  and <img src="https://habrastorage.org/getpro/habr/post_images/3a7/b7c/4e2/3a7b7c4e299d2b352db666d4910cbb4e.svg" alt="Z_3">  addicted to each other. <br><br>  Is there some way to control the distribution of hidden variables <img src="https://habrastorage.org/getpro/habr/post_images/a30/620/58e/a3062058ed53bbfca2cd5199c5a84843.svg" alt="P (Z)">  ? <br><br>  The easiest way is to add a regularizer <img src="https://habrastorage.org/getpro/habr/post_images/4fc/145/592/4fc1455928ad0f7374e86fbe7e369d06.svg" alt="L_1">  or <img src="https://habrastorage.org/getpro/habr/post_images/446/5e5/b18/4465e5b1814e664ed806a987abd04819.svg" alt="L_2">  on values <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  , this will add a priori assumptions on the distribution of hidden variables, respectively, the laplass or normal (similar to the a priori distribution added to the values ‚Äã‚Äãof the weights during regularization). <br><br>  The regularizer forces the autoencoder to look for hidden variables that are distributed according to the necessary laws, whether it will work out is another question.  However, this does not make them independent, i.e. <img src="https://habrastorage.org/getpro/habr/post_images/bad/8a1/3bd/bad8a13bd4bfefade4334769d48920f7.svg" alt="P (Z_i) \ neq P (Z_i | Z_j)">  . <br><br>  Let's look at the joint distribution of hidden parameters in a sparse autoencoder. <br><br><div class="spoiler">  <b class="spoiler_title">Code and visualization</b> <div class="spoiler_text"><pre> <code class="python hljs">s_encoder, s_decoder, s_autoencoder = create_deep_sparse_ae(<span class="hljs-number"><span class="hljs-number">0.00001</span></span>) s_autoencoder.compile(optimizer=Adam(<span class="hljs-number"><span class="hljs-number">0.0003</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>)</code> </pre><br><pre> <code class="python hljs">s_autoencoder.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">200</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">256</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br><pre> <code class="python hljs">imgs = x_test[:n] decoded_imgs = s_autoencoder.predict(imgs, batch_size=n) plot_digits(imgs, decoded_imgs)</code> </pre><br><img src="https://habrastorage.org/web/ece/db3/a87/ecedb3a8705d4456aa75e321ffe99497.png"><br></div></div><br><pre> <code class="python hljs">codes = s_encoder.predict(x_test) snt.jointplot(codes[:,<span class="hljs-number"><span class="hljs-number">1</span></span>], codes[:,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre><br><img src="https://habrastorage.org/web/6e0/99b/0f4/6e099b0f4c604c60bc14903c2cccde76.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/8dc/ed9/9aa/8dced99aa56cfe168d13700d9f5999a8.svg" alt="Z_1">  and <img src="https://habrastorage.org/getpro/habr/post_images/3a7/b7c/4e2/3a7b7c4e299d2b352db666d4910cbb4e.svg" alt="Z_3">  still dependent on each other, but now at least distributed around 0, and even more or less normal. <br><br>  How to control the hidden space, so that you can intelligently generate images from it - in the <a href="https://habrahabr.ru/post/331552//">next part</a> about variational autoencoders (VAE). <br><br><h2>  Useful links and literature </h2><br>  This post is based on the chapter on <a href="http://www.deeplearningbook.org/contents/autoencoders.html">autoencoders</a> (in particular the subchapters of the <em>Learning Maifolds with autoencoders</em> ) in the <em>Deep Learning Book</em> . </div><p>Source: <a href="https://habr.com/ru/post/331500/">https://habr.com/ru/post/331500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../331488/index.html">Thirteenth Developer Economics Survey</a></li>
<li><a href="../331490/index.html">How to stop looking for a good data center and start living</a></li>
<li><a href="../331494/index.html">Tables! Tables? Tables ...</a></li>
<li><a href="../331496/index.html">Milestones in the history of encryption and combat</a></li>
<li><a href="../331498/index.html">Fighting spam on hosting. Setup EFA Project Free Spam / antivirus filter</a></li>
<li><a href="../331502/index.html">Registration using telegram bot</a></li>
<li><a href="../331506/index.html">ECS (Elastic Cloud Storage) - Dell EMC Cloud Storage Platform</a></li>
<li><a href="../331508/index.html">What did Avito.iOS talk about? Report, Guest Reviews and Videos</a></li>
<li><a href="../331510/index.html">13 questions to find out if you are ready to hire a mobile development team</a></li>
<li><a href="../331512/index.html">Administrator's sin or data recovery from knocking HDD Western Digital WD5000AAKX</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>