<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>CUDA: Working with memory. Part II.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The main theme of this part is the optimization of working with global memory when programming a GPU. 

 The GPU has a number of features that, if ign...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>CUDA: Working with memory. Part II.</h1><div class="post__text post__text-html js-mediator-article"><img align="left" title="Memory" src="http://www.picamatic.com/show/2009/04/06/11/15/3153047_132x132.png">  The main theme of this part is the optimization of working with global memory when programming a GPU. <br><br>  The GPU has a number of features that, if ignored, can cost multiple losses in performance when using global memory.  But if you take into account all the subtleties, you can get really effective CUDA-programs. <br><br>  Getting started. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><h2>  What is wrong with global memory? </h2><br>  The amount of global memory is the largest of all types of memory, but at the same time, this memory is the slowest in terms of technical characteristics: read and write speeds. <br><br>  In the previous part, I considered an example of matrix transposition.  To improve performance, a shared memory buffer was used, which increased the performance by almost four times.  But it was enough for the country to see this increase with an extra mediator.  The secret lies in the correct access to global memory. <br><br>  There are two ways to optimize when working with global memory: the alignment of the sizes of the types used and the use of combined queries. <br><br><h2>  Alignment of sizes of used types </h2><br>  Aligning the data type allows you to compile the request into global memory into a single GPU command, otherwise the compiler will generate additional code, which can significantly reduce performance.  For optimal performance, the data type should be 4, 8, or 16 bytes. <br><br>  If the type size does not correspond to 4, 8, or 16 bytes, then it is better to use the type of a higher dimension or to align using the __align __ (alignment size) keyword. <br><br>  An example of optimization when using built-in CUDA-types. <br><br>  The type of type int3 is 12 bytes, the access to memory will not be optimal: <br><br><blockquote><code><a href="http://virtser.net/blog/post/source-code-highlighter.aspx"></a> <font color="black"><font color="#0000ff">__device__ int3</font> data[512]; <br> <br> <font color="#0000ff">__global__ void</font> initData() <br> { <br> <font color="#0000ff">int</font> idx = threadIdx.x <br> data[idx] = make_int3(idx, idx, idx); <br> }; <br></font> <br> <font color="gray">* This source code was highlighted with <font color="gray">Source Code Highlighter</font> .</font></code> </blockquote> <br><br>  It is better to use the int4 type (16 bytes), even if you do not need the fourth component: <br><br><blockquote> <code><a href="http://virtser.net/blog/post/source-code-highlighter.aspx"></a> <font color="black"><font color="#0000ff">__device__ int4</font> data[512]; <br> <br> <font color="#0000ff">__global__ void</font> initData() <br> { <br> <font color="#0000ff">int</font> idx = threadIdx.x <br> data[idx] = make_int4(idx, idx, idx, 0); <br> }; <br></font> <br> <font color="gray">* This source code was highlighted with <font color="gray">Source Code Highlighter</font> .</font></code> </blockquote> <br><br>  When working with structures, you must use the __align__ keyword, which allows you to align the type to a given size. <br><br>  An example of the alignment of the size of the structure. <br><br>  Before alignment, the size of the vector3 structure will be 12 bytes: <br><br><blockquote> <code><a href="http://virtser.net/blog/post/source-code-highlighter.aspx"></a> <font color="black"><font color="#0000ff">struct</font> vector3 <br> { <br> <font color="#0000ff">float</font> x; <br> <font color="#0000ff">float</font> y; <br> <font color="#0000ff">float</font> z; <br> }; <br> <br> <font color="#0000ff">int</font> main() <br> { <br> printf( <font color="#A31515">"%i\n"</font> , <font color="#0000ff">sizeof</font> (vector3)); <br> <font color="#0000ff">return</font> 0; <br> };</font> <br> <br> <font color="gray">* This source code was highlighted with <font color="gray">Source Code Highlighter</font> .</font></code> </blockquote> <br><br>  The number 12 is displayed on the console. <br><br>  After alignment, the size of vector3 will be 16 bytes: <br><br><blockquote> <code><a href="http://virtser.net/blog/post/source-code-highlighter.aspx"></a> <font color="black"><font color="#0000ff">struct</font> __align__(16) vector3 <br> { <br> <font color="#0000ff">float</font> x; <br> <font color="#0000ff">float</font> y; <br> <font color="#0000ff">float</font> z; <br> }; <br> <br> <font color="#0000ff">int</font> main() <br> { <br> printf( <font color="#A31515">"%i\n"</font> , <font color="#0000ff">sizeof</font> (vector3)); <br> <font color="#0000ff">return</font> 0; <br> }; <br></font> <br> <font color="gray">* This source code was highlighted with <font color="gray">Source Code Highlighter</font> .</font></code> </blockquote> <br><br>  The number 16 is displayed on the console. <br><br><h2>  Using combined queries </h2><br>  Much greater performance gains can be obtained by combining a large number of requests into global memory into one (sometimes requests are called transactions).  In the nVidia documentation, this is called <b>coalescing global memory accesses</b> .  But, before proceeding to a direct discussion of what is necessary to combine requests into memory, you need to know a couple of additional things about the work of the GPU. <br><br>  To control the execution of the work threads GPU uses the so-called warp.  From a programmatic point of view, warp represents a thread pool.  It is within this warp that parallel work of the threads that were requested when the kernel was called occurs, it is in the warp that threads can interact with each other.  The size of warp for all GPUs is 32, that is, only 32 threads are executed in parallel in the warp.  At the same time, several warps can be run on the GPU, this number is determined by the size of the available register and shared memory.  Another interesting feature is that half-warp is used for memory access, that is, the first 16 threads are addressed to the memory at the beginning, and then the second half of the 16 threads.  Why access occurs exactly this way, I can‚Äôt say for sure, I can only assume that this is related to the primary tasks of the GPU - graphics processing. <br><br>  Now consider the requirements needed to merge requests into global memory.  Do not forget that memory access occurs through half-warp. <br><br>  The conditions necessary for combining memory access depend on the version of Compute Capability, I give them for versions 1.0 and 1.1, more details can be found in the documentation from nVidia. <br><ul><li>  Threads must refer to either 32-bit words, resulting in a single 64-byte block (transaction), or 64-bit words, while giving one 128-byte block (transaction) </li><li>  If you use 128-bit words, the result will be two transactions, each of which will return 128 bytes of information </li><li>  The threads should refer to the memory elements sequentially, each next thread should correspond to the next word in the memory (some threads may not refer to the corresponding words at all) </li><li>  All 16 words must be within the block of memory being accessed </li></ul><br>  A couple of notes to the conditions: <br><ul><li>  Words imply any type of data, the main thing is respect for the necessary dimensions. </li><li>  The dimension of the words is given in bits, and the dimension of the received data blocks in bytes. </li></ul><br><br><img title="Ways to combine when accessing memory" src="http://www.picamatic.com/show/2009/04/04/01/42/3140845_595x498.png"><br>  Fig.  1. Requests that give a union when accessing memory <br><br>  In fig.  1 shows examples of global memory queries that give a single transaction.  On the left, all conditions are fulfilled: each stream from a half-warp refers to the 32-bit word corresponding in order, the memory start address is aligned to the size of the transaction block (16 threads * 4 bytes = 64 bytes).  On the right is an example when some streams from the block do not refer to the corresponding words in memory at all. <br><br><img title="Requests that do not give a union when accessing memory" src="http://www.picamatic.com/show/2009/04/04/01/43/3140853_595x528.png"><br>  Fig.  2. Requests that do not give a union when accessing memory <br><br>  In fig.  2 shows examples that do not give a union when accessing global memory.  On the left, the condition for converting threads to the corresponding words in the memory is not fulfilled.  On the right, the condition for aligning the memory address to the block size is not fulfilled.  As a result: instead of one unified transaction, we get 16 separate ones, one for each half-warp stream. <br><br><h2>  Array structures or arrays of structures? </h2><br><br>  A few words should be given to the question of working with structures and how to achieve increased productivity.  If there is a need to use an array of structures, it is better to create separate arrays of components of the structure, which will reduce the number of requests to global memory at the expense of associations. <br><br>  Consider an example. <br><br>  Inefficient work with global memory: <br><br><blockquote> <code><a href="http://virtser.net/blog/post/source-code-highlighter.aspx"></a> <font color="black"><font color="#0000ff">struct</font> __align__(16) vec3 <br> { <br> <font color="#0000ff">float</font> x; <br> <font color="#0000ff">float</font> y; <br> <font color="#0000ff">float</font> z; <br> }; <br> <br> <font color="#0000ff">__device__</font> vec3 data[SIZE]; <br> <br> <font color="#0000ff">__global__ void</font> initData() <br> { <br> <font color="#0000ff">int</font> idx = blockDim.x * blockIdx.x + threadIdx.x; <br> data[idx].x = idx; <br> data[idx].y = idx * 2; <br> data[idx].z = idx * 3; <br> }; <br></font> <br> <font color="gray">* This source code was highlighted with <font color="gray">Source Code Highlighter</font> .</font></code> </blockquote> <br><br>  It is more efficient to use separate arrays: <br><br><blockquote> <code><a href="http://virtser.net/blog/post/source-code-highlighter.aspx"></a> <font color="black"><font color="#0000ff">__device__ float</font> x[SIZE]; <br> <font color="#0000ff">__device__ float</font> y[SIZE]; <br> <font color="#0000ff">__device__ float</font> z[SIZE]; <br> <br> <font color="#0000ff">__global__ void</font> initArr() <br> { <br> <font color="#0000ff">int</font> idx = blockDim.x * blockIdx.x + threadIdx.x; <br> x[idx] = idx; <br> y[idx] = idx * 2; <br> z[idx] = idx * 3; <br> }; <br></font> <br> <font color="gray">* This source code was highlighted with <font color="gray">Source Code Highlighter</font> .</font></code> </blockquote> <br><br>  In the first case of using an array of vectors, a separate request to the memory is needed to access each field of the structure; in the second case, by combining only 3 requests for each half-warp.  On average, this approach allows you to increase productivity by 2 times. <br><br><h2>  Conclusion </h2><br>  In conclusion of all the above, I want to give the most important advice when working with memory in CUDA: <br><br>  NEVER ATTEMPT TO CHANGE THE VALUE OF A SINGLE CELL MEMORY WITH SEVERAL THREADS SIMULTANEOUSLY. <br><br>  This is the most common mistake in multithreaded programming.  In fact, CUDA does not guarantee atomic access for each thread to a specific area of ‚Äã‚Äãmemory, so the results may not be exactly as expected.  Although atomic operations in CUDA exist, it is better to use the concept of immutable data and save the results of calculations in new objects, which are transferred to the next stages of calculations. </div><p>Source: <a href="https://habr.com/ru/post/56514/">https://habr.com/ru/post/56514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../56508/index.html">Do I need a store that sells computers / laptops only with Ubuntu preinstalled?</a></li>
<li><a href="../56509/index.html">"The right driver." Project Diary. Part 2. Development and support.</a></li>
<li><a href="../56510/index.html">Agile Labs Conference Report, March 31, 2009</a></li>
<li><a href="../56511/index.html">Selection of SMS billing under the route</a></li>
<li><a href="../56512/index.html">Creating a simple module on Joomla 1.5. # (Using the connection to the database)</a></li>
<li><a href="../56515/index.html">The people project</a></li>
<li><a href="../56517/index.html">We collect the netbook and the case for the laptop</a></li>
<li><a href="../56521/index.html">Openmoko: Epic Fail?</a></li>
<li><a href="../56522/index.html">How often do you use a taxi?</a></li>
<li><a href="../56525/index.html">Abaco Primo: nettop for only 99 euros!</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>