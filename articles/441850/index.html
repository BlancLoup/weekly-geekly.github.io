<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Guessing on neural networks: whether the author himself noted in the comments to the post</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I will share a story about a small project: how to find in the comments the author's answers, knowingly not knowing who the author of the post is. 

 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Guessing on neural networks: whether the author himself noted in the comments to the post</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/dg/5l/lw/dg5llwwkakl3ndxtcjjwlwudupk.jpeg"><br><br>  I will share a story about a small project: how to find in the comments the author's answers, knowingly not knowing who the author of the post is. <br><br>  I started my project with minimal knowledge of machine learning and I think for specialists there will not be anything new.  This material is in a sense a compilation of various articles, I will tell you how it approached the problem, in the code you can find useful trivia and techniques with processing natural language. <br><a name="habracut"></a><br>  My initial data were as follows: a database containing 2.5M media materials and 39.5M comments on them.  For 1M posts, one way or another, the author of the material was known (this information was either present in the database, or was obtained by analyzing data on circumstantial evidence).  On this basis, <a href="https://github.com/xeonvs/dnn_comments/blob/master/export_clean_dataframe.py">a</a> dataset of 215K markup records was <a href="https://github.com/xeonvs/dnn_comments/blob/master/export_clean_dataframe.py">formed</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Initially, I applied an approach based on heuristics produced by natural intelligence and translated into sql queries with full-text search or regular expressions.  The simplest examples of the text for the analysis: ‚Äúthanks for the comment‚Äù or ‚Äúthank you for the good grades‚Äù is the author in 99.99% of cases, and ‚Äúthanks for the work‚Äù or ‚ÄúThank you!  Send mail to the material.  Thank you! ‚Äù- a normal review.  With this approach, it was possible to filter out only explicit matches, excluding the cases of trivial typos, or when the author conducts a dialogue with commentators.  Therefore, it was decided to use neural networks, this idea came not without the help of a friend. <br><br>  A typical sequence of comments, which one is the author? <br><br><img src="https://habrastorage.org/webt/vv/sy/st/vvsystg0cv8nbrkntqqcrkbt45g.png"><br><br><div class="spoiler">  <b class="spoiler_title">Answer</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/nx/jd/dq/nxjddq9-3dckcrg_26r81hvufgy.png"><br></div></div><br>  The method for determining the tonality of the text was taken as a basis; the task is simple: we have two classes: the author and not the author.  For training models, I used the <a href="https://colab.research.google.com/">service</a> from Google that provides virtual machines with GPU and Jupiter notebook interface. <br><br>  Examples of networks found on the Internet: <br><br><pre><code class="python hljs">embed_dim = <span class="hljs-number"><span class="hljs-number">128</span></span> model = Sequential() model.add(Embedding(max_fatures, embed_dim,input_length = X_train.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>])) model.add(SpatialDropout1D(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">196</span></span>, dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, recurrent_dropout=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>,activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss = <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>,metrics = [<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br>  on lines cleared of html-tags and special characters, they gave about 65-74% percent accuracy, which was not much different from coin flip. <br><br>  An interesting point, aligning the input sequences via <code>pad_sequences(x_train, maxlen=max_len, padding='pre')</code> gave a significant difference in the results.  In my case, the best result was when padding = 'post'. <br><br>  The next step was the use of lemmatization, which immediately gave an increase in accuracy up to 80% and with this it was already possible to work further.  Now the main problem was the correct cleaning of the text.  For example, typos in the word ‚Äúthank you‚Äù were converted (typos were chosen according to the frequency of use) into such a regular expression (there were a half or two dozen of similar expressions). <br><br><pre> <code class="python hljs">re16 = re.compile(<span class="hljs-string"><span class="hljs-string">ur"(?:\b:(?:1|c(?:|)|(?:|)|(?:(?:|(?:(?:(?:|(?:)?|))?|(?:)?))|)|(?:(?:(?:|)|)||||(?:(?:||(?:|)|(?:|(?:(?:(?:||(?:(?:||(?:[]|)|[]))?|[—ñ]))?|||1)||)|)|||[]|(?:|)|(?:(?:(?:[]|)|?|(?:(?:(?:|(?:)?))?|)|(?:|)))?)||)|(?:|x))\b)"</span></span>, re.UNICODE)</code> </pre> <br>  Here I would like to express a special thanks to the overly polite people who consider it necessary to add this word to each of their sentences. <br><br>  Reducing the proportion of typos was necessary, because  at the exit from the lemmatizer, they give strange words and we lose useful information. <br><br>  But a blessing in disguise, tired of struggling with typos, doing complex text cleaning, applied the word2vec vector representation of words.  The method allowed to translate all typos, clerks and synonyms into closely spaced vectors. <br><br><img src="https://habrastorage.org/webt/54/r5/r9/54r5r9mqktawmbwxstrjaeyckvo.png"><br><br>  Words and their relationships in vector space. <br><br>  Cleaning rules were significantly simplified (aha, storyteller), all messages, user names, were divided into sentences and uploaded to a file.  An important point: in view of the brevity of our commentators, to build quality vectors, words need additional contextual information, for example, from the forum and wikipedia.  Three models were trained on the resulting file: classic word2vec, Glove and FastText.  After many experiments I finally stopped at FastText, as the most qualitatively distinguishing clusters of words in my case. <br><br><img src="https://habrastorage.org/webt/t6/lu/t6/t6lut6wyvpf8b2lba8l2bgjjbd8.png"><br><br>  All these changes brought a stable 84-85 percent accuracy. <br><br><div class="spoiler">  <b class="spoiler_title">Examples of models</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model_conv_core</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model_input, embd_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">128</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> num_filters = <span class="hljs-number"><span class="hljs-number">128</span></span> X = Embedding(total_unique_words, DIM, input_length=max_words, weights=[embedding_matrix], trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, name=<span class="hljs-string"><span class="hljs-string">'Word2Vec'</span></span>)(model_input) X = Conv1D(num_filters, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(X) X = Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)(X) X = MaxPooling1D(<span class="hljs-number"><span class="hljs-number">2</span></span>)(X) X = Conv1D(num_filters, <span class="hljs-number"><span class="hljs-number">5</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(X) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">model_conv1d</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model_input, embd_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">128</span></span></span></span><span class="hljs-function"><span class="hljs-params">, num_filters = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">64</span></span></span></span><span class="hljs-function"><span class="hljs-params">, kernel_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> X = Embedding(total_unique_words, DIM, input_length=max_words, weights=[embedding_matrix], trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, name=<span class="hljs-string"><span class="hljs-string">'Word2Vec'</span></span>)(model_input) X = Conv1D(num_filters, kernel_size, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, strides=<span class="hljs-number"><span class="hljs-number">1</span></span>)(X) <span class="hljs-comment"><span class="hljs-comment"># X = Dropout(0.1)(X) X = MaxPooling1D(pool_size=2)(X) X = LSTM(256, kernel_regularizer=regularizers.l2(0.004))(X) X = Dropout(0.3)(X) X = Dense(128, kernel_regularizer=regularizers.l2(0.0004))(X) X = LeakyReLU()(X) X = BatchNormalization()(X) X = Dense(1, activation="sigmoid")(X) model = Model(model_input, X, name='w2v_conv1d') return model def model_gru(model_input, embd_size = 128): X = model_conv_core(model_input, embd_size) X = MaxPooling1D(2)(X) X = Dropout(0.2)(X) X = GRU(256, activation='relu', return_sequences=True, kernel_regularizer=regularizers.l2(0.004))(X) X = Dropout(0.5)(X) X = GRU(128, activation='relu', kernel_regularizer=regularizers.l2(0.0004))(X) X = Dropout(0.5)(X) X = BatchNormalization()(X) X = Dense(1, activation="sigmoid")(X) model = Model(model_input, X, name='w2v_gru') return model def model_conv2d(model_input, embd_size = 128): from keras.layers import MaxPool2D, Conv2D, Reshape num_filters = 256 filter_sizes = [3, 5, 7] X = Embedding(total_unique_words, DIM, input_length=max_words, weights=[embedding_matrix], trainable=False, name='Word2Vec')(model_input) reshape = Reshape((maxSequenceLength, embd_size, 1))(X) conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embd_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape) conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embd_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape) conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embd_size), padding='valid', kernel_initializer='normal', activation='relu')(reshape) maxpool_0 = MaxPool2D(pool_size=(maxSequenceLength - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0) maxpool_1 = MaxPool2D(pool_size=(maxSequenceLength - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1) maxpool_2 = MaxPool2D(pool_size=(maxSequenceLength - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2) X = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1) X = Dropout(0.2)(X) X = Flatten()(X) X = Dense(int(embd_size / 2.0), activation='relu', kernel_regularizer=regularizers.l2(0.004))(X) X = Dropout(0.5)(X) X = BatchNormalization()(X) X = Dense(1, activation="sigmoid")(X) model = Model(model_input, X, name='w2v_conv2d') return model</span></span></code> </pre><br></div></div><br>  and 6 more models in the <a href="https://github.com/xeonvs/dnn_comments">code</a> .  Part of the models was taken from the network, some was invented independently. <br><br>  It was noticed that different comments stood out on different models, which prompted the idea to use ensembles of models.  At first I assembled the ensemble manually, choosing the best pairs of models, then I made a generator.  In order to optimize brute force - he took the gray code as a basis. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gray_code</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gray_code_recurse</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g,n)</span></span></span><span class="hljs-function">:</span></span> k = len(g) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range (k<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>): char=<span class="hljs-string"><span class="hljs-string">'1'</span></span> + g[i] g.append(char) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range (k<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>): g[i]=<span class="hljs-string"><span class="hljs-string">'0'</span></span> + g[i] gray_code_recurse (g, n<span class="hljs-number"><span class="hljs-number">-1</span></span>) g = [<span class="hljs-string"><span class="hljs-string">'0'</span></span>,<span class="hljs-string"><span class="hljs-string">'1'</span></span>] gray_code_recurse(g, n<span class="hljs-number"><span class="hljs-number">-1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> g <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen_list</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(m)</span></span></span><span class="hljs-function">:</span></span> out = [] g = gray_code(len(m)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range (len(g)): mask_str = g[i] idx = <span class="hljs-number"><span class="hljs-number">0</span></span> v = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> list(mask_str): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> c == <span class="hljs-string"><span class="hljs-string">'1'</span></span>: v.append(m[idx]) idx += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(v) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>: out.append(v) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out</code> </pre> <br>  With the ensemble "life has become more fun" and the current percentage of accuracy of the model is kept at 86-87%, which is mainly due to the poor quality classification of some authors in the dataset. <br><br><img src="https://habrastorage.org/webt/q8/8s/zt/q88sztzfnzspm90oanbhll4bz8c.png"><br><br>  Problems encountered by me: <br><br><ol><li>  Unbalanced dataset.  The number of comments from the authors was significantly less than other commentators. <br></li><li>  Classes in the sample are in strict order.  The bottom line is that the beginning, middle and end differ significantly in the quality of classification.  This is clearly seen in the learning process on schedule f1-measures. <img src="https://habrastorage.org/webt/-f/mx/5e/-fmx5evtj0tsfch0y35sedqqezu.png"><br></li></ol><br>  For the decision was made his own bike for the separation of training and validation of the sample.  Although in practice, in most cases, the train_test_split procedure from the sklearn library will suffice. <br><br>  Current working model graph: <br><br><img src="https://habrastorage.org/webt/cc/8q/zl/cc8qzlyein_kblslui7tgnq5qpg.png"><br><br>  As a result, I received a model with a confident definition of the authors by short comments.  Further improvement will be associated with the purification and transfer of the results of the classification of real data to the training dataset. <br><br>  All code with additional explanations is laid out in the <a href="https://github.com/xeonvs/dnn_comments">repository</a> . <br><br>  As a postscript: if you need to classify large amounts of text, take a look at the ‚ÄúVery Deep Convolutional Neural Network‚Äù <a href="https://arxiv.org/abs/1606.01781">VDCNN model</a> ( <a href="https://github.com/zonetrooper32/VDCNN">implemented</a> on keras), this is the ResNet analog for texts. <br><br>  Used materials: <br><br>  ‚Ä¢ <a href="https://habr.com/ru/post/417209/">Overview of machine learning courses</a> <br>  ‚Ä¢ <a href="https://habr.com/ru/company/mailru/blog/417767/">Analysis of tonalities using convolutions</a> <br>  ‚Ä¢ <a href="https://habr.com/ru/company/ods/blog/353060/">Convolution networks in NLP</a> <br>  ‚Ä¢ <a href="https://habr.com/ru/company/ods/blog/328372/">Metrics in machine learning</a> <br>  <a href="https://ld86.github.io/ml-slides/unbalanced.html">https://ld86.github.io/ml-slides/unbalanced.html</a> <br>  ‚Ä¢ <a href="https://habr.com/ru/post/438972/">A look inside the model</a> </div><p>Source: <a href="https://habr.com/ru/post/441850/">https://habr.com/ru/post/441850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../441832/index.html">Who is the project manager according to the business owner and how to deal with it</a></li>
<li><a href="../441834/index.html">Do not hire. And what if it is you?</a></li>
<li><a href="../441840/index.html">Because of software bugs, Lime scooters sometimes block the front wheel at maximum speed.</a></li>
<li><a href="../441842/index.html">Practical Go: tips on writing supported programs in the real world</a></li>
<li><a href="../441844/index.html">iRobot Scooba: experience of using and solving common problems of a washing robot vacuum cleaner</a></li>
<li><a href="../441854/index.html">REST? Take a dumb JSON-RPC</a></li>
<li><a href="../441866/index.html">Everything (Well, almost) about video cards. Part 1</a></li>
<li><a href="../441868/index.html">Why the brain needs to be given a "break"</a></li>
<li><a href="../441876/index.html">The prototype of the Russian robosobaki moves at a speed of 6.5 km / h</a></li>
<li><a href="../441878/index.html">You as you like, and I did</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>