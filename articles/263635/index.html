<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How Microsoft Project Oxford Can Make Your Applications Smarter</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Thank you very much for preparing the article for Evgeny Grigorenko, Microsoft Student Partner, for helping to write this article. Our remaining Azure...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How Microsoft Project Oxford Can Make Your Applications Smarter</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  <em>Thank you very much for preparing the article for Evgeny Grigorenko, Microsoft Student Partner, for helping to write this article.</em>  <em>Our remaining Azure articles can be found on the <a href="http://habrahabr.ru/search/%3Fq%3D%255Bazureweek%255D%26target_type%3Dposts">azureweek</a> tag <a href="http://habrahabr.ru/search/%3Fq%3D%255Bazureweek%255D%26target_type%3Dposts">.</a></em> </blockquote><br>  Let me guess, you, like me, have been burning for a couple of months with the idea of ‚Äã‚Äãa brilliant application.  In addition to its basic functionality, in an ideal world, it is simply obliged to have many additional features, for example, to identify the user (or <a href="http://habrahabr.ru/post/262911/">cat</a> ) from his photo from the front camera or to understand the commands in natural language.  Or make a second how <a href="http://how-old.net/">-old</a> (which was made just at Oxford). <br><br>  But we all know the sad truth.  Much is possible only with the use of complex machine learning algorithms, which we absolutely do not have time to study.  And that is what stops the development, since without such innovations we will completely get lost among the analogs.  But there is a solution to this problem, and his name is Microsoft Project Oxford.  If you want to find out how Microsoft Project Oxford can simplify your life and make your applications truly intelligent, then welcome to cat. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/98a/f42/3a5/98af423a5e6d3ccad976405f6dc3a7b4.jpg"><br><a name="habracut"></a><br>  At the conference // BUILD in April 2015, Microsoft, among many other announcements, introduced a new service in the Microsoft Azure cloud services group.  They became a project with the code name <a href="https://www.projectoxford.ai/">Project Oxford</a> - a set of ready-made REST APIs that in an accessible form give developers the full power of machine vision algorithms, natural language analysis and voice recognition for use in their applications.  It is worth noting that the availability of services in the form of a REST API allows you to use it on absolutely any platform and using your favorite development technologies, not limited to those proposed by Microsoft. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The Oxford project itself expands the already existing <a href="https://gallery.azureml.net/">Azure Machine Learning Gallery</a> services gallery with new highly intelligent solutions.  The initial idea of ‚Äã‚Äãcreating the Azure ML Gallery a year ago was to try to gather in one place fairly simple to use machine learning services.  To use them, you do not need to be an expert mathematician; all that is needed is to call the API and not to think about complex mathematical aspects at all - internally the services will do everything on their own.  And Project Oxford, more than ever, perfectly responds to this idea. <br><br>  What does Project Oxford consist of?  The project consists of four groups of self-sufficient cloud APIs: Face APIs, Computer Vision APIs, Speech APIs, and while still in a state of closed beta Language Understanding Intelligent Services (LUIS). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7e/30a/90a/c7e30a90ac1578b707cf5f1eb14c2cdf.png"><br><br>  The <b>Face</b> <b>APIs</b> services include cloud-based algorithms for detecting and recognizing human faces in photos, namely: <br><ul><li>  detection of the boundaries of faces in the form of descriptive rectangles with the allocation of additional characteristics, such as the coordinates of parts of the face, the position of the head, sex and heuristic estimation of age; </li><li>  a wide range of recognition services, representing such opportunities as assessing the similarity of two faces, searching for similar faces on a series of photographs according to a given pattern, automatic grouping of photographs and identification (recognition) of people based on a previously prepared training sample. </li></ul>  In addition to the standard tasks of finding faces in photos and automatically categorizing a gallery of photos like the one presented in Apple iPhoto, the service can be used in many other scenarios.  Just remember the modern blockbusters.  Tracking the movement of people with the help of external surveillance cameras, automatic authorization when approaching a top-secret installation become possible and realizable using Microsoft Project Oxford Face API services. <br><br>  But even if you are not going to become a member of the spy drama, the proposed services may be no less useful: intelligent content targeting based on information about the field and the user's age, filtering photos by the image from the contact list - there are a lot of scenarios and by imagination. <br>  For all those interested, as well as those who are not yet so, I strongly advise you to familiarize yourself with the additional information on Face API on the <a href="https://www.projectoxford.ai/face">official website of the project</a> .  There, along with the <a href="https://www.projectoxford.ai/doc/face/overview">documentation</a> , several interesting <a href="https://www.projectoxford.ai/demo/face">demos are</a> presented, besides the visualization that give an idea of ‚Äã‚Äãthe API text response to requests, it is a great way to try out services and understand all their capabilities in a couple of minutes. <br><br>  The popularity of how-old.net immediately after its announcement and its recently announced colleague <a href="http://twinsornot.net/">twinsornot.net</a> according to the original plan were also created only as a Face API demo for the period of the conference // BUILD 2015. Read about the success story of the first service and try to transfer it on the history of your application <a href="http://blogs.technet.com/b/machinelearning/archive/2015/05/04/fun-with-ml-stream-analytics-and-powerbi-observing-virality-in-real-time.aspx">here</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/20e/449/d8a/20e449d8a54a172b7892ba5018dca055.png"><br><br>  The most intriguing part of the Oxford project is undoubtedly the <b>Language</b> <b>Understanding</b> <b>Intelligent</b> <b>Service</b> or <b>LUIS</b> .  LUIS gives developers the ability to build models of natural language understanding for convenient use in their applications. <br><br>  There may be several sources of such models.  Simple models can be built on the basis of existing and successfully used in projects such as Cortana or Bing.  Do you want your software solution to understand basic concepts like time, numbers or temperature and successfully respond to a query like ‚Äúremind me of training at 8 am‚Äù, standard models will be enough.  If it is necessary to respond to more complex queries like ‚Äústart tracking runs‚Äù or ‚Äúturn on the light‚Äù, then you will need to build your own models, which, in principle, is also achievable with the tools represented by LUIS. <br><br>  Further, these models can be published as REST API and used on any devices and operating systems capable of such calls.  The opportunities that LUIS can present are difficult to overestimate.  A couple of years ago, such virtual assistants as Cortana and Siri seemed complicated and unattainable, and now they are available to any developer.  More than ever, your decision can easily and naturally become truly intellectual and, perhaps, in the end, he will even succeed in successfully passing the Turing test. <br><br>  But, unfortunately, a project of this magnitude takes time to complete.  Unlike other Oxford project services, which are initially restricted for use, LUIS is in a state of closed testing.  Additional information about the project can be found on the <a href="https://www.projectoxford.ai/luis">official page</a> and video of <a href="http://www.luis.ai/home/video">one of the reports</a> from // BUILD 2015, and <a href="https://www.luis.ai/">here</a> you can register in the queue for access to the project.  Do not miss the opportunity to plunge into the world of natural language intellectual analysis and give these opportunities to your users first! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e27/017/371/e270173719f335e1b2cc1cd7467d30c7.png"><br><br>  The services of the <b>Computer</b> <b>Vision</b> <b>APIs</b> group continue the direction of visual analytics, but they do it in a completely different way.  They specialize in the analysis of arbitrary photos and provide the following wide range of features: <br><ul><li>  categorization of images, such as food, people, buildings and, of course, cats; </li><li>  searching for inappropriate sexual or racial content in photos; </li><li>  the definition of the dominant colors of the image, the facts that it is black and white, clip art or a line drawing; </li><li>  text recognition (OCR); </li><li>  thumbnail generation of images based on intelligent exposure analysis. </li></ul> Frankly, Computer Vision API services are my favorite by the number of features presented.  Dividing images into categories is probably one of the oldest tasks of machine vision, and you have probably come up with a dozen scenarios for using it in your project.  Not yet?  Just try it!  Did you ever want to implement OCR text recognition in your application, read checks, pointers to poles, or any other textual information that surrounds us everywhere in the real world, but thought it was difficult and expensive?  Now it is available and convenient to use as one of the Project Oxford Computer Vision APIs services. <br><br>  But, in addition to the well-known technologies described above, Computer Vision APIs provide many additional features.  For example, consider a purely technical task, such as generating thumbnail images, also known as thumbnails.  The task seems simple, until you encounter it in real life.  While maintaining the proportions, scaling is a simple task, but one has only to try to change them and bodies without heads, ‚Äúsky‚Äù instead of ‚Äúcat against the sky‚Äù and other problems of incorrect cropping of photos begin to crumble from the cornucopia.  And the Computer Vision API has a solution.  It not only hides the technical issues of scaling while maintaining the maximum quality of the sketch, but also tries to determine the significant elements of the exposure, which provides a more correct choice of the borders of cropping the image.  Such an approach in most cases allows to achieve maximum preservation of the content of the created sketch.  Just look at the example below, the service has not been informed of any additional information other than the image of the person on top of the mountain. <br><br>  All site owners, to which users can upload their images, are aware of the moderation problem.  And the ability of the Oxford project to detect sexual and racial content allows you to put this complex task on the shoulders of the machine.  All that is required when uploading a photo to your service is to make a parallel call in the direction of Computer Vision APIs and, based on the resulting level of image correspondence to groups of unwanted content, make a decision about additional human processing or a categorical ban on the user in a publication.  But, if such a solution is not enough and a more complex approach is required, then perhaps it makes sense to pay attention to a group of similar services that use Computer Vision APIs as the basis: <a href="https://www.microsoft.com/en-us/moderator">Microsoft Content Moderator</a> and <a href="https://www.microsoft.com/en-us/PhotoDNA">PhotoDNA Cloud Service</a> . <br><br>  All interested can find more information on the <a href="https://www.projectoxford.ai/vision">official site of the project</a> , where, as before, <a href="https://www.projectoxford.ai/doc/vision/visual-features">documentation</a> and convenient <a href="https://www.projectoxford.ai/demo/visions">demos</a> are also available. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2b8/154/80c/2b815480c74f481340130001da091abe.png"><br><br>  The <b>Speech</b> <b>APIs</b> services define algorithms for many years in a row that have been used in the voice services of the Bing search engine, recently introduced by Skype Translator, and recently entered into the natural form of Windows 10 in the form of the already well-known virtual assistant Cortana.  As it is easy to guess, the Speech API includes voice recognition services from an audio file into text and back. <br><br>  The described functionality does not require a special presentation, and therefore only discuss some additional features.  First of all, you need to talk about languages ‚Äã‚Äãand here everything is not in favor of Russian.  Voice recognition services currently only support English, German, Spanish, French, Italian and Chinese, but this list is constantly expanding.  The voice generation in the text pleases support of a number of additional languages, including Russian, and therefore can be actively used now.  It is also worth noting that recognition services support online processing with the possibility of returning preliminary results.  This allows you to significantly speed up the process of parsing the incoming stream and make the user interface as responsive as possible. <br><br>  In addition, the Speech API is the only Project Oxford service that does not require a permanent active Internet connection.  The corresponding algorithms are built into the Universal Windows Platform and can be used in your universal applications on all devices based on Windows 10 offline. <br><br>  If during the times of the victorious globalization, the lack of support for the Russian language is not an insurmountable limitation for you, or you are interested in finding out how the Speech API answers exactly your use case, then I advise you to visit the <a href="https://www.projectoxford.ai/speech">main page of the project</a> in search of additional information about the solution, <a href="https://www.projectoxford.ai/doc/speech/overview">technical documentation</a> and more than once recommended interactive <a href="https://www.projectoxford.ai/demo/speech">demos</a> . <br><br>  If you already have a mobile application or website, or you are only going to create something like this, think about how Project Oxford can be useful to you personally and I am sure that there will be something.  With it, your solution will become more modern and stand out positively from many others, and users will be satisfied with previously unprecedented usability and capabilities.  And most importantly, you will not need any analysis of complicated refractive mathematics, long development of a complex algorithm that is ready for the whole - no effort at all except a couple of lines of code to call the necessary service.  With Project Oxford, using machine learning services is easier than ever. </div><p>Source: <a href="https://habr.com/ru/post/263635/">https://habr.com/ru/post/263635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../263625/index.html">Idiom Land - an application for learning English idioms</a></li>
<li><a href="../263627/index.html">Moscow Android Devs Meetup August 5</a></li>
<li><a href="../263629/index.html">Storage of hierarchical structures. Symbiosis "Closure Table" and "Adjacency List"</a></li>
<li><a href="../263631/index.html">What is internal hakaton, or Rule of five "no"</a></li>
<li><a href="../263633/index.html">Oracle Exadata, or About the Use of Engineered Systems (Part 1)</a></li>
<li><a href="../263641/index.html">Multi-level information security in cloud CRM</a></li>
<li><a href="../263643/index.html">Load Balancing: Firebase + RabbitMQ</a></li>
<li><a href="../263645/index.html">Features of development for Xamarin.Forms</a></li>
<li><a href="../263647/index.html">TargetSummit - evening conference on analytics and promotion of mobile applications</a></li>
<li><a href="../263649/index.html">Crosswalk Project - replacement of Android WebView. Project Integration</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>