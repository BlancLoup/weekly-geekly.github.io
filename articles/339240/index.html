<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Generate short texts with limiting conditions - for advertising and other purposes.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In practice, the task is often encountered not just to write some text, but to fulfill certain conditions ‚Äî for example, to lay maximum keywords at a ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Generate short texts with limiting conditions - for advertising and other purposes.</h1><div class="post__text post__text-html js-mediator-article">  In practice, the task is often encountered not just to write some text, but to fulfill certain conditions ‚Äî for example, to lay maximum keywords at a given length and / or use / not use certain words and phrases.  This is important for business (when creating advertisements, including for contextual advertising, for SEO-optimization of sites), for educational purposes (automatic preparation of test questions) and in some other cases.  Such optimization tasks cause a lot of headaches, since it is relatively easy for people to write texts, but it is not so easy to write something that meets one or another of the ‚Äúoptimality‚Äù criteria.  On the other hand, computers do an excellent job with optimization tasks in other areas, but they do not understand natural language well, and therefore it is difficult for them to compose text.  In this article, we consider the well-known approaches to solving this problem and share our own experience a little. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/59/d3/a3/59d3a3ced7079841747802.png"></div><br><a name="habracut"></a><br>  As an example, consider the task of writing a sentence of a given length on a specific subject, which should include a certain number of keywords.  Let's say the words ‚Äúdoors, windows, quality, make‚Äù are given - you need to make a sentence like ‚ÄúWe make windows and doors with high quality!‚Äù. <br><br>  One of the first known approaches to solve this problem is the use of a statistical model of a language.  A language model is a distribution function of the probability of finding words in a particular sequence.  Those.  some function <i>P (S</i> ) - which allows, knowing the sequence of words <i>S</i> , to get the probability <i>P to</i> meet the words in this sequence.  Most often, the language model is based on the so-called n-grams, that is, counting the frequency of obtaining word combinations from n words in large arrays of texts.  The ratio of the number of occurrences of a given phrase to the number of analyzed phrases gives an approximation of the probability of the given phrase.  Since the probabilities of long n-grams are difficult to estimate (some combinations of words may occur very rarely), their probabilities are approximated in one way or another using frequencies of shorter sequences. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      With reference to our example, if we have, say the word "Qualitatively", then we can use the <i>P (S)</i> function to estimate the probabilities of all possible phrases of the initial keywords "Qualitatively windows", "Qualitatively doors", "Qualitatively manufacture".  Most likely the latter will have the highest probability.  Therefore, we add the word "make" to our line and repeat the operation, getting in the next step, "Make the windows quality" and then "Make the door windows qualitatively." <br><br>  Immediately visible cons of this approach.  First, he uses words only in the original cases and numbers, and therefore we can‚Äôt say that we prefer to use ‚Äúproduce‚Äù instead of ‚Äúproduce‚Äù.  Secondly, there is no possibility to use any other words besides the original ones, therefore, the wrong phrase ‚Äúwindow of the door‚Äù is obtained.  Of course, we can easily allow the use of any words included in the language model, for example, prepositions that will work in this case.  But if the key words are only ‚Äúhigh-quality windows of the door‚Äù, then the prepositions will not help and you will have to carefully select the words that the model can use ‚Äúfrom itself‚Äù. <br><br>  There will be other difficulties.  For example, in the described approach, the language model does not know anything about the keywords that it can use.  Therefore, if the beginning of ‚ÄúQualitatively manufacture doors for‚Äù is generated, then inevitably you will get ‚ÄúQualitatively manufacture doors for windows‚Äù, or if you use matching in the cases ‚ÄúQualitatively manufacture doors for windows‚Äù, which is still meaningless.  In part, this can be eliminated, if at each step to save the entire history of opportunities.  That is, when the phrase ‚Äúdoors for‚Äù was composed, there were other options, including ‚Äúdoors and‚Äù.  In the absence of a continuation, a ‚Äúdoor for‚Äù was chosen.  But if we have saved the previous versions and completed them too, then we will get several alternatives ‚Äúdoors and windows‚Äù, ‚Äúdoors for windows‚Äù, ‚Äúdoors under windows‚Äù and so on.  Of these options, we already choose the most likely - ‚Äúdoors and windows‚Äù. <br><br>  A more complex approach is described, for example, in [1]. Based on the same principle, it takes into account not only the probabilities of n-grams, but additional linguistic information, determining the dependencies between words.  Based on the list of keywords, this method searches in a large corpus of texts for the use of these words and, based on the analysis of dependencies, generates rules for their use.  Using these rules, candidate texts are created, from which the most plausible options are selected.  In addition to the complexity of implementation, the disadvantage of this method is a certain dependence on the language used, which complicates its portability, as well as the fact that it received a patent, the validity of which has not yet expired. <br><br>  The main efforts in the field of text generators were concentrated mainly on adding more and more linguistic features and hand-created rules, which led to the creation of rather powerful systems, but focused mainly on the English language. <br><br>  Recently, interest in learning systems of language generation has again increased, which is associated with the advent of neural language models (Neural language models).  There are neural network architectures capable of describing the content of pictures, and translating from one language to another.  In previous articles, we <a href="https://habrahabr.ru/post/256987/">considered a chat bot on neural networks</a> and a neural generator of product descriptions.  It is interesting to see how a neural network generator can solve this specific problem. <br><br><h2>  Our results </h2><br>  As a task, we chose the problem of generating headline ads ads from search queries, which is similar to the example we considered.  Taking a set of 15,000 training examples in one subject area, we applied a neural network with the architecture described earlier [2], having trained it to generate new headers.  The peculiarities of this architecture is that it can specify the required length of the generated text and keywords as input parameters.  For verification, we generated 200 headings and estimated how many of them turned out to be qualitative: <br><br>  The first results were quite modest: <br><table><tbody><tr><td>  Result </td><td>  Percentage of headings received </td></tr><tr><td>  Ideal headers </td><td>  34% </td></tr><tr><td>  Good headlines </td><td>  31% </td></tr><tr><td>  Bad headers </td><td>  36% </td></tr></tbody></table><br>  Total got 64% of usable headers.  Of the unsuitable 5% exceeded the desired length, 10% contained grammatical errors, and the rest changed the meaning using similar, but different words. <br><br>  After that, we introduced a number of modifications into the system and changed the neural network architecture.  The key factor for a good result is the ability to copy words from the source text to the target [3].  This is significant, since on a small sample of several tens of thousands of texts (instead of millions of sentences, such as, for example, in machine translation), the system cannot learn a lot of words. <br><table><tbody><tr><td>  Result </td><td>  Percentage of headings received </td></tr><tr><td>  Ideal headers </td><td>  60% </td></tr><tr><td>  Good headlines </td><td>  29% </td></tr><tr><td>  Bad headers </td><td>  eleven% </td></tr></tbody></table><br>  <b>A few examples:</b> <br><table><tbody><tr><td>  Keywords </td><td>  Text </td></tr><tr><td>  wholesale supplies of toys in china </td><td>  Wholesale toy from China.  Discounts </td></tr><tr><td>  toy talking ferb reviews </td><td>  talking toy, where to buy? </td></tr><tr><td>  child mats </td><td>  educational mats for children </td></tr><tr><td>  dolls monster high house overview </td><td>  all doll houses video reviews </td></tr></tbody></table><br>  Thus, suitable for use of headings became 89%, at the same time the headings which are generally distorting sense were gone.  Considering that among the headers compiled by people, the number of ‚Äúideal‚Äù reaches 68-77%, depending on the person‚Äôs qualifications, degree of tiredness, etc., it can be said that the possibilities of automatic generation make up about 80% of the person‚Äôs capabilities.  This is pretty good, and opens the way to practical applications of such systems, especially since the possibilities for improvement are far from exhausted. <br><br>  Literature <br><br>  1. <a href="https://dl.acm.org/citation.cfm%3Fid%3D1072292">Uchimoto, Kiyotaka, Hitoshi Isahara, and Satoshi Sekine.</a>  <a href="https://dl.acm.org/citation.cfm%3Fid%3D1072292">"Text generation from keywords." Proceedings of the 19th International Conference on Computational Linguistics-Volume 1. Association for Computational Linguistics, 2002.</a> <br><br>  2. <a href="http://www.meanotek.ru/files/TarasovDS(2)2015-Dialogue.pdf">Tarasov DS (2015) Neural Networks' Natural Language Generation, Paraphrasing and Summarization of User Reviews // Computational Linguistics and Intellectual Technologies: ‚ÄúInternational Dialogue‚Äù, Issue 14 (21), pp.</a>  <a href="http://www.meanotek.ru/files/TarasovDS(2)2015-Dialogue.pdf">571-579</a> <br><br>  3. <a href="http://papers.nips.cc/paper/5866-pointer-networks">Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly.</a>  <a href="http://papers.nips.cc/paper/5866-pointer-networks">"Pointer networks." Advances in Neural Information Processing Systems.</a>  <a href="http://papers.nips.cc/paper/5866-pointer-networks">2015</a> </div><p>Source: <a href="https://habr.com/ru/post/339240/">https://habr.com/ru/post/339240/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../339230/index.html">.NET Performance: The Real Jedi Tricks</a></li>
<li><a href="../339232/index.html">Rapid application development on Angular + Ag-Grid</a></li>
<li><a href="../339234/index.html">Announcement RamblerElixir # 4</a></li>
<li><a href="../339236/index.html">Do you have a fast site? And if I check?</a></li>
<li><a href="../339238/index.html">Squeeze all the juice from Chromium to Linux</a></li>
<li><a href="../339242/index.html">About traffic interception: 4-10% of encrypted HTTPS traffic is intercepted today</a></li>
<li><a href="../339246/index.html">Few prefab tasks on bash</a></li>
<li><a href="../339248/index.html">The first hackathon Skyeng: 15 working projects in two days</a></li>
<li><a href="../339250/index.html">Identify hidden data dependencies to improve the quality of the forecast in machine learning</a></li>
<li><a href="../339252/index.html">Octopus Deploy. Improving the world in a bloody enterprise</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>