<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Object Recognition with PowerAI Vision</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Software developers have been actively working with machine learning libraries for several years, solving problems of computer vision and object detec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Object Recognition with PowerAI Vision</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/d9/h9/fp/d9h9fpfkqpi3u_hduzxesribaii.jpeg"><br><br>  Software developers have been actively working with machine learning libraries for several years, solving problems of computer vision and object detection.  But the implementation of such tasks (and each machine learning model must be designed, deployed, properly trained, configured and installed) usually requires deep knowledge and skills.  With the new IBM PowerAI Vision product, you can avoid it.  This product provides an interface in which you can train, customize and test your own model, without going into the details of the implementation of machine learning. <br><br>  In this guide, I will explain how to use PowerAI Vision to train the system and create a ready-to-use REST API service that you can use to detect and recognize objects in your applications. <br><a name="habracut"></a><br><h2>  PowerAI Vision - Technology Preview </h2><br>  As of December 2017, PowerAI Vision is available for testing as a Technology Preview software product (available for free download on the <a href="https://developer.ibm.com/linuxonpower/deep-learning-powerai/technology-previews/powerai-vision/">developerWorks</a> page), which is installed on Power Systems servers.  If you don‚Äôt have such a server, you can test this product (completely free of charge!) In the SuperVessel cloud. <br>  <i>Note.</i>  <i>This manual describes how to work with PowerAI Vision Technology Preview version 3.0.</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Task </h2><br>  The purpose of this article is to explain the basics of using machine learning to detect objects, and also to show how such training can be implemented using the PowerAI Vision interface.  Here is what can be done with it: <br><br><ul><li>  Create and lay out datasets (datasets) for object detection </li><li>  Train and apply a trained model on a dataset </li><li>  Test models using REST services </li></ul><br>  The details of setting up frameworks, the connection and use of GPU graphics accelerators, the deployment and configuration of REST services is carried out automatically within the product.  However, some learning settings are available through the administration interface. <br>  The end result is a ready-to-use REST API for object detection. <br><br><h1>  What is needed for recognition? </h1><br><h2>  Sample Image Collection </h2><br>  You can create your own image collection based on the script you want to implement.  These are some of the questions that PowerAI Vision can help answer: <br><br><ul><li>  Where are the objects in the image? </li><li>  How many objects are in the image? </li></ul><br>  For example, take photos of bottles of Coca-Cola.  Our goal is to create an application that can find and count bottles in images or video clips. <br><br><h2>  Install PowerAI Vision on Power System </h2><br>  If you already have an IBM Power server with an Nvidia GPU installed, you can install PowerAI Vision for testing.  Follow the <a href="https://developer.ibm.com/linuxonpower/deep-learning-powerai/try-powerai/">link</a> and select "On Premise" - "Download Now".  Download PowerAI Vision and install it. <br><br><img src="https://habrastorage.org/webt/ny/63/cy/ny63cywgeehn2uxsyfmhrzbjcgy.png"><br>  <i>Note.</i>  <i>The examples in this article suggest that you use SuperVessel, a cloud-based service for testing PowerAI products.</i> <br><br><h2>  How long will it take? </h2><br>  The steps of preparing and deploying a model in the SuperVessel cloud will not take much time (less than an hour), but considering the model training, the whole process can take an hour and a half.  This time, of course, depends on the complexity of the data set and other factors. <br><br><h1>  Create and train a model </h1><br><h2>  We use cloud SuperVessel </h2><br>  Sign up for <a href="https://ny1.ptopenlab.com/AIVision/index.html">SuperVessel cloud service</a> (it's free). <br><br><h2>  Create a DataSet </h2><br>  PowerAI Vision supports two machine learning models: <br><br><ul><li>  Object Detection - detection and recognition of objects in the image </li><li>  Image Classification - classification of objects in the image </li></ul><br>  The model of object detection (PowerAI Vision Object Detection) will allow you to detect and recognize objects in an image, as well as count their number.  In this article, we consider the training of this particular model. <br><br>  Create a new data set to train the model: <br><br><ul><li>  In the ‚ÄúMy Data Sets‚Äù view, click the ‚ÄúAdd Dataset‚Äù button and then select ‚ÄúFor Object Detection‚Äù in the drop-down list: </li></ul><br><img src="https://habrastorage.org/webt/fx/2t/ow/fx2towjc_uqp6cbgghavzboh_q4.png"><br><br><ul><li>  Think up a name for your data set (for example, ‚ÄúCoke Bottles‚Äù) and click ‚ÄúAdd Dataset‚Äù: <br></li></ul><br><img src="https://habrastorage.org/webt/fx/2t/ow/fx2towjc_uqp6cbgghavzboh_q4.png"><br><br><ul><li>  Download one or more images by dragging them onto a gray rectangle, or click the ‚ÄúSelect some‚Äù button, and then select and download images from the local disk: </li></ul><br><img src="https://habrastorage.org/webt/4x/mj/pw/4xmjpwt9zinglngvrjqnfynn4pc.png"><br><ul><li>  You can upload multiple images simultaneously in a zip archive. </li></ul><br><img src="https://habrastorage.org/webt/wl/w4/mu/wlw4mu9em1w90uauvpjpplgtmx4.png"><br>  <i>Note.</i>  <i>If you downloaded a zip file and do not see the thumbnails of the files after the download, then the download failed.</i>  <i>Try to use lower case file names without special characters or spaces.</i>  <i>You can try downloading the files separately to determine which file caused the problem.</i> <br><br><h2>  Create tags and tag objects </h2><br><ul><li>  Create one or more tags by clicking the + icon to add a new one.  For each type of object to be recognized, you must create a separate tag. </li><li>  Mark the object in the image (let's call this process markup) - click first on the tag, and then on the image, around the corresponding object, with the result that a rectangle bounding it will appear.  Click Save when you have finished marking the object for the tag. </li><li>  Repeat this process first for all tags in the photo, and then for all images.  Here is an example of such a marked image: </li></ul><br><img src="https://habrastorage.org/webt/a8/5d/ia/a85diakbco3fl3pudzerjxdtndm.png"><br>  <i>Council</i>  <i>Use the option "Only Show Unlabeled Files" to not see the already marked photos.</i> <br><br><ul><li>  Click ‚ÄúExport As Zip File‚Äù to download the prepared Dataset.  Now that you have spent some time marking, this zip file will allow you not to lose the result of the work done. </li></ul><br><h2>  Creating DL (Deep Learning) tasks </h2><br><ul><li>  Click on <i>My DL</i> in the <i>My Workspace</i> section, and then click the <i>Create New Task</i> button, then <i>Object Detection</i> . <br></li><li>  Give the <i>Detector a</i> name and make sure you select the correct dataset, then click <i>Build Model</i> <i><br></i> <br></li></ul><br><img src="https://habrastorage.org/webt/dn/sw/g5/dnswg5_w8d1ijb3i70k0p2164rk.png"><br><br>  Deployment and Testing <br><ul><li>  After the model has been trained (the learning process can be controlled visually), click <i>Deploy and Test</i> . </li></ul><br><img src="https://habrastorage.org/webt/mt/sr/3y/mtsr3yzawvwl-drzlcj_gewmq8k.png"><br><ul><li>  Test the built model in the PowerAI Vision user interface: click <i>Select</i> to load the image for verification.  After loading, an image with found objects and an estimate of the recognition accuracy will be shown below.  In our example - three bottles of Coca-cola with an accuracy of 99.9% <br></li></ul><br><img src="https://habrastorage.org/webt/kz/om/qf/kzomqfbpagcol61osyzviz3oa3w.png"><br><br><ul><li>  From the command line you can test the program interface of the REST service using the curl command and an image file.  Notice that JSON found several bottles and indicated a tag and location for each one. <br></li></ul><br><pre><code class="bash hljs">$ curl --insecure -i -F files=@coke_bottle_23.png https://ny1.ptopenlab.com/AIVision/api/dlapis/9f9d6787-0183-4a1b-be49-751b6ca16724 HTTP/1.1 100 Continue HTTP/1.1 200 OK Server: nginx/1.9.13 Date: Thu, 14 Dec 2017 21:58:26 GMT Content-Type: application/json Content-Length: 508 Connection: keep-alive Access-Control-Allow-Origin: * Access-Control-Allow-Headers: origin, content-type, accept, authorization Access-Control-Allow-Credentials: <span class="hljs-literal"><span class="hljs-literal">true</span></span> Access-Control-Allow-Methods: GET, POST, PUT, DELETE, OPTIONS, HEAD Access-Control-Allow-Origin: * { <span class="hljs-string"><span class="hljs-string">"classified"</span></span> : [ { <span class="hljs-string"><span class="hljs-string">"confidence"</span></span> : 0.9986369013786316 , <span class="hljs-string"><span class="hljs-string">"ymax"</span></span> : 578 , <span class="hljs-string"><span class="hljs-string">"label"</span></span> : <span class="hljs-string"><span class="hljs-string">"coca-cola"</span></span> , <span class="hljs-string"><span class="hljs-string">"xmax"</span></span> : 755 , <span class="hljs-string"><span class="hljs-string">"xmin"</span></span> : 588 , <span class="hljs-string"><span class="hljs-string">"ymin"</span></span> : 29} , { <span class="hljs-string"><span class="hljs-string">"confidence"</span></span> : 0.9954010248184204 , <span class="hljs-string"><span class="hljs-string">"ymax"</span></span> : 592 , <span class="hljs-string"><span class="hljs-string">"label"</span></span> : <span class="hljs-string"><span class="hljs-string">"coca-cola"</span></span> , <span class="hljs-string"><span class="hljs-string">"xmax"</span></span> : 601 , <span class="hljs-string"><span class="hljs-string">"xmin"</span></span> : 437 , <span class="hljs-string"><span class="hljs-string">"ymin"</span></span> : 10} , { <span class="hljs-string"><span class="hljs-string">"confidence"</span></span> : 0.8161203265190125 , <span class="hljs-string"><span class="hljs-string">"ymax"</span></span> : 567 , <span class="hljs-string"><span class="hljs-string">"label"</span></span> : <span class="hljs-string"><span class="hljs-string">"coca-cola"</span></span> , <span class="hljs-string"><span class="hljs-string">"xmax"</span></span> : 426 , <span class="hljs-string"><span class="hljs-string">"xmin"</span></span> : 259 , <span class="hljs-string"><span class="hljs-string">"ymin"</span></span> : 17}] , <span class="hljs-string"><span class="hljs-string">"imageUrl"</span></span> : <span class="hljs-string"><span class="hljs-string">"http://ny1.ptopenlab.com:443/AIVision/temp/5a26dd3b-d8ba-4e01-8b93-5a43f28e97c7.png"</span></span> , <span class="hljs-string"><span class="hljs-string">"result"</span></span> : <span class="hljs-string"><span class="hljs-string">"success"</span></span>}</code> </pre> <br>  <i>The cloud free version limits the use of the REST API for 1 hour of operation after deployment.</i>  <i>After stopping the service, it can be restarted to resume operation.</i> <br><br><h2>  Brief summary </h2><br>  You have seen how machine learning can work with image samples and create object detection APIs.  Since the result is a fully-fledged REST API that returns results to JSON, it is easy to use in any application. <br>  PowerAI Vision is simple and fast to use, providing GPU capabilities to accelerate learning. <br><br>  The accuracy of the prediction will depend on the quality and size of the test sample.  If the data set used for the experiments is too small, then this may affect the quality of the results obtained ... The quality of training depends on time and data.  You can increase your data set and thus improve your results. <br><br><h1>  PS </h1><br>  You can see PowerAI Vision, try it in action, discuss interesting scenarios for using the platform with IBM experts at the IBM stand at the <a href="http://opentalks.ai/">Opentalks.AI</a> conference. <br><br>  In addition, employees of <a href="https://www.ibm.com/ibm/clientcenter/moscow/">the IBM Client Center in Moscow have</a> unique experience with PowerAI Vision, IBM Watson and cognitive technologies.  And they will be happy <a href="">to answer your questions</a> . <br><br><h1>  additional literature </h1><br>  <a href="https://developer.ibm.com/code/howtos/powerai-vision-object-detection">Original article</a> in English; <br>  <a href="https://en.wikipedia.org/wiki/Object_detection">Object Detection</a> : Object Detection on Wikipedia; <br>  <a href="https://developer.ibm.com/linuxonpower/deep-learning-powerai/technology-previews/powerai-vision/">PowerAI Vision</a> : Deep Learning and PowerAI Development <br>  <a href="https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html">TensorFlow Object Detection</a> : Supercharge your Computer Vision models with the TensorFlow Object Detection API <br>  <a href="https://www.entrepreneur.com/article/283990">AI Article</a> : Can Artificial Intelligence Identify Pictures Better than Humans? <br>  <a href="https://developer.ibm.com/linuxonpower/2017/08/30/ibm-powerai-vision-speeds-transfer-learning-greater-accuracy-real-world-example/">From the developers</a> : IBM PowerAI <br><br>  Several product videos: <br>  <a href="https://www.youtube.com/watch%3Fv%3D0F5w6q0ZpBI">www.youtube.com/watch?v=0F5w6q0ZpBI</a> <br>  <a href="https://www.youtube.com/watch%3Fv%3DnWft6tYVdrc">www.youtube.com/watch?v=nWft6tYVdrc</a> <br>  <a href="https://www.youtube.com/watch%3Fv%3DqHZRnswzqUI">www.youtube.com/watch?v=qHZRnswzqUI</a> </div><p>Source: <a href="https://habr.com/ru/post/348102/">https://habr.com/ru/post/348102/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../348092/index.html">Robots instead of the best employees: machine learning for expert answers</a></li>
<li><a href="../348094/index.html">Cisco ASA Firewall Critical Vulnerability Allows Remote Code Execution</a></li>
<li><a href="../348096/index.html">Orgi among programmers</a></li>
<li><a href="../348098/index.html">Why is it important to check that the malloc function returned</a></li>
<li><a href="../348100/index.html">Indian programmers, cookies from England and the Caucasus: the history of technical support department</a></li>
<li><a href="../348106/index.html">Office 365. An example of working with the Microsoft Graph API in Angular5 using ADAL JS. ADAL JS vs MSAL JS</a></li>
<li><a href="../348108/index.html">How to destroy the Internet?</a></li>
<li><a href="../348110/index.html">Visualization of data for moviegoers: scrap movie recommendations and make interactive graph</a></li>
<li><a href="../348112/index.html">Wolfram Language (Mathematica) Virtual Textbook, 5th Edition</a></li>
<li><a href="../348116/index.html">‚ÄúProgrammer pragmatist. The journey from the apprentice to the master ": briefly about the main thing (part one)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>