<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Multi-camera video analytics</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the first publication to the Chabroux community we want to tell about the most interesting direction of the work of the company ‚ÄúSynesis‚Äù - a multi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Multi-camera video analytics</h1><div class="post__text post__text-html js-mediator-article">  In the first publication to the Chabroux community we want to tell about the most interesting direction of the work of the <a href="http://synesis.ru/ru/home">company ‚ÄúSynesis‚Äù</a> - a multi-camera video analysis, more precisely, a multi-camera object tracking algorithm. <br><img src="https://habrastorage.org/storage/754f2847/34779e81/6b402e27/342bae6a.jpg" alt="Multicam man escort"><br>  Our team is engaged in applied research in the field of <a href="http://en.wikipedia.org/wiki/Video_analytics">video analytics</a> and develops high-speed machine vision algorithms for automatic classification of situations according to streaming video data.  We plan to highlight the most interesting results in the corporate blog.  We will be grateful for ideas and criticism. <br><br><a name="habracut"></a><br><h4>  Escort in sight of one camera </h4><br>  An integral component of almost any video analysis system is the tracking algorithm (tracking).  Why does he need a smart video surveillance system?  In general, tracking of objects is necessary for automatic recognition of situations by rules, for example, a person entered the control zone, stopped, left the subject, or without rules, in self-learning systems.  Disruption of tracking almost always leads either to a missed alarm situation, or to repeated triggers of video analytics. <br><br>  Habr has already talked about the maintenance of objects in articles about the development of <a href="http://habrahabr.ru/blogs/algorithm/116824/">Zdenek Kalal</a> and <a href="http://habrahabr.ru/blogs/artificial_intelligence/116393/">Microsoft Research</a> .  ‚ÄúSingle-chamber‚Äù support, for example, in <a href="http://magicbox.agrg.ru/">the MagicBox device</a> works as follows: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/ob21fM7pBDM%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700253,15700256,15700259&amp;usg=ALkJrhh78XoogJIsZ0TNKF6YTLKVsbBcpQ" frameborder="0" allowfullscreen=""></iframe><br><br>  The result of the <a href="http://synesis.ru/ru/surveillance/products/va-sct">‚Äúsingle-chamber‚Äù tracking algorithm</a> is a sequence of space-time coordinates of each object.  There may be breaks in the trajectories when the object leaves the field of view of the camera or when the object approaches the obstacle. <br><br><h4>  Support in the field of view of several cameras </h4><br>  The multi-chamber tracking algorithm, the subject of this publication, continuously compares data on the position of objects from different cameras, taking into account the relative position and linking of cameras to the terrain map.  The algorithm builds a generalized trajectory of the object when moving from camera to camera and projects this trajectory onto the map.  In this case, the object can be observed by several cameras simultaneously or be in a blind zone.  The multi-camera trajectory allows you to implement geovisual search tools, automatic angle selection and other security features that are often shown in science fiction films. <br><br><h5>  Spatial Camera Calibration </h5><br>  Before operating the system, the surveillance zone of each camera should be linked to the map of the controlled area.  Our calibration algorithm uses four points, the coordinates of which the user must specify simultaneously on the camera frame and on the map: <br><br><img src="https://habrastorage.org/storage/5cc6c7d3/a65cd3f6/f905d435/fe0c7fa8.jpg" alt="Calibration of the camera: four points on the frame are attached to the map, that is, they are assigned global coordinates"><br><br>  It is recommended to use the nodal points on the terrain, which are easy to identify visually from different angles, such as trees, corners of the house and fences.  Algorithms calculates the coordinate transformation matrix <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BD%25D0%25B0%25D0%25B8%25D0%25BC%25D0%25B5%25D0%25BD%25D1%258C%25D1%2588%25D0%25B8%25D1%2585_%25D0%25BA%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D0%25BE%25D0%25B2">by the method of least squares</a> : <br><br><img src="https://habrastorage.org/storage/4d8f8a66/57ca987c/99656604/fa503bfc.png"><br><br>  where <b><i>r</i></b> is the coordinates on the camera frame, <b><i>R</i></b> is the global coordinates on the map, <b><i>A</i></b> is the desired transformation matrix. <br><br>  Thus, the transformation matrix <b><i>A</i></b> allows mapping the two-dimensional coordinates of the object in the camera frame to its global coordinates on the map. <br><br><h5>  Step 1: Preprocessing </h5><br>  So, the stream of space-time coordinates of moving objects recorded by different cameras comes to the input of the multi-chamber tracking algorithm.  So the ‚Äúsingle-camera‚Äù video analysis is not synchronized in time, the initial coordinates are reduced to a single time scale using the <a href="http://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25B8%25D0%25BD%25D1%2582%25D0%25B5%25D1%2580%25D0%25BF%25D0%25BE%25D0%25BB%25D1%258F%25D1%2586%25D0%25B8%25D1%258F">linear interpolation</a> method.  The coordinates are then converted to a global coordinate system using the matrix <b><i>A.</i></b> <br><br>  This is how the object trajectories look after projection onto the map.  The illustration shows the coverage areas of nine cameras, five of which registered movement of the object.  ‚ÄúSingle-chamber‚Äù trajectories are highlighted in the same color as the corresponding cameras and their zones of action. <br><img src="https://habrastorage.org/storage/482488c2/dcf64bc7/26a361b8/b0895ca8.png" alt="The areas of operation of nine cameras, five of which registered the movement of an object, the trajectories are highlighted in the same color as the cameras and their areas of operation."><br><br><h5>  Step 2: Preselection of objects in the camera overlap area </h5><br>  The second step is a rough comparison of the global coordinates of the observed objects, which can potentially be observed by several cameras, but correspond to one physical object.  To do this, calculate the distance between the observed objects on the map for the current point in time.  If the distance is less than the selected threshold, for example, 1 meter, then we mark the objects for the next processing step. <br><br>  If there is no data for the camera for the considered time point (the object is outside the range of this camera), then the object location is predicted.  It is assumed that the speed of the object out of sight of the camera does not change. <br><br>  As a result of step 2, a list of observable objects and the corresponding ‚Äúsingle-chamber‚Äù trajectories are formed, which can correspond to a single physical object. <br><br><h5>  Step 3: Comparison of "single-chamber" trajectories </h5><br>  In the third step, we calculate <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D1%2580%25D1%2580%25D0%25B5%25D0%25BB%25D1%258F%25D1%2586%25D0%25B8%25D1%258F">the Pearson correlation coefficient</a> between the pairs of coordinates of two ‚Äúsingle-chamber‚Äù trajectories.  If the correlation coefficient lies in the selected interval of significance, then we assume that two trajectories belong to the same object. <br><br><h5>  Step 4 Summarizing Trajectories </h5><br>  In the fourth step, we unite the ‚Äúsingle-chamber‚Äù trajectories into ‚Äúmulti-chamber‚Äù ones.  In the area of ‚Äã‚Äãoverlap obtained in step 3, we calculate the average trajectory of the object.  If the areas of the cameras do not overlap, then the two paths are ‚Äústitched‚Äù, where the coordinates of the blind zone are interpolated according to the boundary coordinates observed in each camera. <br><br>  Below is a generalized trajectory of the object on a map using multi-camera video analytics. <br><img src="https://habrastorage.org/storage/5a99b91c/90423caa/7965f69f/1b8e11a4.png" alt="Generalized trajectory of the object on the map using multi-camera video analytics"><br><br><h5>  Conclusion </h5><br>  From a practical point of view, the developed multi-chamber tracking algorithm allows you to: <br><ol><li>  improve the accuracy of target detection and reduce the number of false positives due to the correlation of metadata of video analytics of adjacent television and thermal imaging cameras; </li><li>  to compare the image of the accompanied target, observed simultaneously on the television and thermal imaging cameras; </li><li>  exclude repeated triggered video analytics when a target moves from the observation area of ‚Äã‚Äãone camera to the surveillance area of ‚Äã‚Äãanother camera; </li><li>  display the whole trajectory of a person‚Äôs movement on the map of the protected object based on the results of the video analysis for all cameras at once; </li><li>  apply the rules to the multi-chamber trajectory on the map for more accurate recognition of human behavior and events; </li><li>  automatically select the optimal angle of observation of a person as he moves from camera to camera. </li></ol><br>  In the course of the research, an <a href="http://synesis.ru/ru/surveillance/articles/mct-case-study">experimental zone of multi-chamber tracking of 9 cameras was created</a> .  A generalized trajectory of the target is obtained according to several camera data.  The task of future research is to evaluate the effectiveness and accuracy of the developed algorithm. <br><br><h4>  Additional Information </h4><br>  See also the publication on the website "Synesis": <br><ol><li>  <a href="http://synesis.ru/ru/surveillance/articles/tracking-overview">Algorithms of target tracking in extended object security systems</a> </li><li>  <a href="http://synesis.ru/ru/surveillance/articles/multiple-camera-tracking">Algorithm of multi-camera tracking using data from a video camera and a thermal imager</a> </li><li>  <a href="http://synesis.ru/ru/surveillance/articles/occlusion-tracking">Maintenance of objects in the conditions of their shielding by moving and motionless obstacles</a> </li><li>  <a href="http://synesis.ru/ru/surveillance/articles/mctintro">The future of video surveillance systems: multi-camera support</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/117746/">https://habr.com/ru/post/117746/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../117739/index.html">A library for working with the Yandex.Money API and a demo Android application</a></li>
<li><a href="../117740/index.html">Yahoo is rolling back its policy on storing user information</a></li>
<li><a href="../117742/index.html">Colleagues! Friends! Request to those freelancers who live and work in Moscow and St. Petersburg</a></li>
<li><a href="../117743/index.html">Opera Startup Awards</a></li>
<li><a href="../117745/index.html">Apple sued Samsung for copying iPhone and iPad</a></li>
<li><a href="../117747/index.html">Do you use Habrastorage.org, and how if</a></li>
<li><a href="../117748/index.html">What do you think the HTTP status code should be issued when showing the stub technical work?</a></li>
<li><a href="../117749/index.html">The first sites appeared in the .xxx domain</a></li>
<li><a href="../117750/index.html">WTF?</a></li>
<li><a href="../117754/index.html">Video Course on Kohana 3.1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>