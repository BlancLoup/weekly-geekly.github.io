<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Retina authentication methods</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The first scanners of the retina appeared in the 80s of the last century. They are widely used in access control systems for highly sensitive objects,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Retina authentication methods</h1><div class="post__text post__text-html js-mediator-article">  The first scanners of the retina appeared in the 80s of the last century.  They are widely used in access control systems for highly sensitive objects, since they have one of the lowest percentages of denied access to registered users and there is practically no erroneous access authorization, but despite this, retinal scanners are not widely available from - for the high cost and complexity of the optical scanning system.  And until recently, everything remained the same, although the algorithms continued to evolve. <br><br>  To date, the technology of 3d printing has greatly reduced the price of retinal scanners.  <a href="https://www.ted.com/talks/andrew_bastawrous_get_your_next_eye_exam_on_a_smartphone%3Flanguage%3Den">Andrew Bastavrus</a> together with his team printed on the 3d printer a nozzle for a smartphone that allows you to observe the retina through the camera of the phone. <br><br>  This article is devoted to the description of algorithms for matching signs of the retina and is a continuation of the <a href="http://habrahabr.ru/post/259017/">article</a> on segmentation of blood vessels. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      An overview of biometric identification / authentication methods is provided <a href="http://habrahabr.ru/post/126144/">here</a> . <br><br><h1>  <b>Ways to compare signs of retina</b> </h1><br>  One of the most important problems when using the retina for recognition of personality is the movement of the head or the eye during scanning.  Because of these movements, displacement, rotation and scaling may occur relative to the sample from the database (Fig. 1). <br><br><img src="https://habrastorage.org/files/c3c/d4b/860/c3cd4b860d6b4bbd8fd87739667798f2.jpg" alt="image"><br>  <i>Fig.</i>  <i>1. Result of head and eye movement when scanning the retina.</i> <br><br>  The effect of zooming on the comparison of the retinas is not as critical as the effect of other parameters, since the position of the head and the eye is more or less fixed along the axis corresponding to the scale.  In the case when scaling is still there, it is so small that it has almost no effect on the comparison of retinas.  Thus, the main requirement for the algorithm is the resistance to rotation and displacement of the retina. <br><br>  Retinal authentication algorithms can be divided into two types: those that use segmentation algorithms (algorithm based on phase correlation method; algorithm based on searching for branching points) and those that extract signs directly from the retina image (algorithm, using the corners of Harris). <br><a name="habracut"></a><br><h3>  <b>1. Algorithm based on the phase correlation method</b> </h3><br>  The essence of the algorithm is that using the phase correlation method, the displacement and rotation of one image relative to another is estimated.  After that, the images are aligned and the similarity index is calculated. <br><br>  In the implementation, the phase correlation method works with binary images, however, it can also be used for images in 8-bit color space. <br><br>  Let be <img src="https://habrastorage.org/files/5e6/ac7/903/5e6ac7903fd34e6eb77c33928c7119f6.jpg" alt="image">  and <img src="https://habrastorage.org/files/ff7/9f7/d2d/ff79f7d2de96443abac23cf35fd3db56.jpg" alt="image">  - images, one of which is shifted to <img src="https://habrastorage.org/files/48b/822/0e4/48b8220e429f45218f6414705c6d539e.jpg" alt="image">  in relation to another, and <img src="https://habrastorage.org/files/fcb/e86/9b6/fcbe869b6a294de3b453b1489dde7037.jpg" alt="image">  and <img src="https://habrastorage.org/files/1ed/567/47d/1ed56747d9604981a2b5940f2d8aa5a1.jpg" alt="image">  - their Fourier transforms, then: <br><br><img src="https://habrastorage.org/files/4be/7b9/a48/4be7b9a488584fc280bbc3ec144fd881.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/b49/f83/e09/b49f83e09c124bdb9ff9aaa1b276234e.jpg" alt="image">  - cross spectrum; <br><img src="https://habrastorage.org/files/7d4/164/e8a/7d4164e8a0cf4957b8d082c3fa729062.jpg" alt="image">  - complex conjugate <img src="https://habrastorage.org/files/976/525/65a/97652565a9e44ffcbce64448ee38f85f.jpg" alt="image"><br><br>  Calculating the inverse Fourier transform of the cross-spectrum, we obtain the momentum function: <br><br><img src="https://habrastorage.org/files/265/37e/015/26537e015746422c8cdc9af716221da0.jpg" alt="image"><br><br>  Finding the maximum of this function, we find the desired offset. <br><br>  Now find the angle of rotation <img src="https://habrastorage.org/files/ac2/5f6/0a6/ac25f60a68e34688926423c431c5d5c1.jpg" alt="image">  with offset <img src="https://habrastorage.org/files/48b/822/0e4/48b8220e429f45218f6414705c6d539e.jpg" alt="image">  using polar coordinates: <br><br><img src="https://habrastorage.org/files/ba8/64c/1e0/ba864c1e029546c0bc87f641e7232849.jpg" alt="image"><br><br>  Next, the phase correlation method is applied, as in the previous case.  It can be noted that such a modification of the phase correlation allows you to find the scale of the parameter <img src="https://habrastorage.org/files/5d9/1f9/842/5d91f984246e44c1b0fc249fdc73bd42.jpg" alt="image"><br><br>  This technique does not always show good results in practice due to the presence of small noises and the fact that some of the vessels may be present on one image and absent on the other.  To eliminate this, several iterations of this algorithm are used, including changing the order in which images are supplied to a function and the order in which offset and rotation are removed.  At each iteration, the images are aligned, after which their similarity index is calculated, then the maximum similarity index is found, which will be the final result of the comparison. <br><br>  The similarity index is calculated as follows: <br><br><img src="https://habrastorage.org/files/853/311/5f3/8533115f3bfa4430a2a0b89a806189f4.jpg" alt="image"><br><br><h3>  <b>2. Algorithm using Harris angles</b> </h3><habracut><br>  This algorithm, unlike the previous one, does not require segmentation of the vessels, since it can determine the signs not only on the binary image. <br><br>  At the beginning, the images are aligned using the phase correlation method described in the previous section.  Then the images look for the corners of <a href="http://habrahabr.ru/post/244541/">Harris</a> (Fig. 2). <br><br><img src="https://habrastorage.org/files/6e1/d9d/be6/6e1d9dbe66084e18aaf4e5fa413a2d96.jpg" alt="image"><br>  <i>Fig.</i>  <i>2. Search result for Harris angles on retina images.</i> <br><br>  Let M + 1 point be found, then for each j-th point its Cartesian coordinates <img src="https://habrastorage.org/files/1b6/65f/415/1b665f41591f43018e59c8419483fd8c.jpg" alt="image">  converted to polar <img src="https://habrastorage.org/files/fd2/6a0/45c/fd26a045cde94d6d8da04cfb787421ae.jpg" alt="image">  and the feature vector is determined <img src="https://habrastorage.org/files/06e/328/834/06e328834fd7425696097a839b08cadf.jpg" alt="image">  Where <br><br><img src="https://habrastorage.org/files/d42/8e6/75b/d428e675b55e42a59aa3cae623b17e10.jpg" alt="image"><br><br>  Model of similarity between unknown vector <img src="https://habrastorage.org/files/a13/cf3/b85/a13cf3b85f844b089822610c283383ae.jpg" alt="image">  and feature vector <img src="https://habrastorage.org/files/386/f00/eb5/386f00eb5c484fc8897bb9c597f64c63.jpg" alt="image">  size N at j is defined as follows: <br><br><img src="https://habrastorage.org/files/eb9/6d9/71f/eb96d971fecc4323b30279a9e758ec10.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/b68/3eb/d04/b683ebd048e04bffb71ae713f01921fb.jpg" alt="image">  - constant, which is determined before the search for the corners of Harris. <br><br>  Function <img src="https://habrastorage.org/files/002/5dc/2a8/0025dc2a89d54996a3d702d161765f0a.jpg" alt="image">  describes the proximity and similarity of a vector <img src="https://habrastorage.org/files/a13/cf3/b85/a13cf3b85f844b089822610c283383ae.jpg" alt="image">  to all signs of j. <br><br>  Let the vector <img src="https://habrastorage.org/files/0b9/a5e/fb6/0b9a5efb68e9487f82d8c4f73a175215.jpg" alt="image">  Is the feature vector of the first image, where <img src="https://habrastorage.org/files/386/f00/eb5/386f00eb5c484fc8897bb9c597f64c63.jpg" alt="image">  K ‚Äì 1, and vector <img src="https://habrastorage.org/files/501/28b/f71/50128bf7131d41c7af05d9b7d96108c5.jpg" alt="image">  Is the feature vector of the second image, where <img src="https://habrastorage.org/files/182/a08/573/182a085735234b869dc97aebbafe8eb4.jpg" alt="image">  size J ‚Äì 1, then the figure of similarity of these images is calculated as follows: <br><br><img src="https://habrastorage.org/files/db4/47d/d5a/db447dd5aeb24297a1deb6ae4078abe6.jpg" alt="image"><br><br>  The normalization factor for similarity is <img src="https://habrastorage.org/files/369/680/1b1/3696801b17194713bb3cf9f6db4bf3df.jpg" alt="image"><br><br>  Coefficient <img src="https://habrastorage.org/files/b68/3eb/d04/b683ebd048e04bffb71ae713f01921fb.jpg" alt="image">  in the original article it is proposed to determine by the following criterion: if the difference between the histograms of images is less than a predetermined value, then <img src="https://habrastorage.org/files/b68/3eb/d04/b683ebd048e04bffb71ae713f01921fb.jpg" alt="image">  = 0.25, otherwise <img src="https://habrastorage.org/files/b68/3eb/d04/b683ebd048e04bffb71ae713f01921fb.jpg" alt="image">  = 1. <br><br><h3>  <b>3. Algorithm based on searching for branch points</b> </h3><habracut><br>  This algorithm, like the previous one, looks for branching points in the blood vessel system.  At the same time, it is more specialized in searching for bifurcation and intersection points (Fig. 3) and is much more resistant to noise, but it can only work on binary images. <br><br><img src="https://habrastorage.org/files/2d9/4da/571/2d94da5710af4000884163e90d144159.jpg" alt="image"><br>  <i>Fig.</i>  <i>3. Types of signs (on the left - the bifurcation point, on the right - the intersection point).</i> <br><br>  To search for points, as in Fig.  3, segmented vessels are compressed to a thickness of one pixel.  Thus, it is possible to classify each point of the vessels by the number of neighbors S: <br><ol><li>  if S = 1, then this is the end point; </li><li>  if S = 2, then this is an interior point; </li><li>  if S = 3, then this is a bifurcation point; </li><li>  if S = 4, then this is the intersection point. </li></ol><br><h5>  <b>3.1.</b>  <b>Vessel compression algorithm to the thickness of one pixel and the classification of branching points</b> </h5><br>  First, a pixel that is part of the vessel is searched from top to bottom, from left to right.  It is assumed that each pixel of the vessel can have no more than two adjacent pixels of the vessels (previous and next), in order to avoid ambiguity in subsequent calculations. <br><br>  Next, 4 neighboring pixels of the found point are analyzed, which have not yet been considered.  This leads to 16 possible configurations (Fig. 4).  If the pixel in the middle of the window does not have gray neighbors, as shown in fig.  4 (a), then it is discarded and another pixel of blood vessels is searched.  In other cases, it is either the end point or internal (not including bifurcation points and intersections). <br><br><img src="https://habrastorage.org/files/a43/e1c/047/a43e1c0473a343328acfff149fdd32e5.jpg" alt="image"><br>  <i>Fig.</i>  <i>4. 16 possible configurations of four neighboring pixels (white dots - background, gray - vessels).</i>  <i>The top 3 pixels and one on the left have already been analyzed, therefore ignored.</i>  <i>Gray pixels with a cross inside are also ignored.</i>  <i>The points with the arrow inside are the points that can become the next central pixel.</i>  <i>Pixels with a black dot inside are the end points.</i> <br><br>  At each step, the gray neighbor of the last pixel is marked as passed and selected by the next central pixel in the 3 x 3 window. The choice of such neighbor is determined by the following criterion: the best neighbor is the one with the largest number of unlabeled gray neighbors.  Such a heuristic is due to the idea of ‚Äã‚Äãmaintaining a single-pixel thickness in the middle of the vessel, where a greater number of neighbors are gray. <br><br>  From the above algorithm it follows that it leads to the separation of the vessels.  Also, vessels can be separated at the stage of segmentation.  Therefore it is necessary to connect them back. <br><br>  To restore the connection between two nearby endpoints, the corners are defined <img src="https://habrastorage.org/files/b68/3eb/d04/b683ebd048e04bffb71ae713f01921fb.jpg" alt="image">  and <img src="https://habrastorage.org/files/a38/617/2cf/a386172cf5fb4120b88d5c8abe0239e1.jpg" alt="image">  as in fig.  5, and if they are less than a predetermined angle <img src="https://habrastorage.org/files/1a0/c42/75f/1a0c4275ff274ce6b8126ab6e84d72de.jpg" alt="image">  then the end points are combined. <br><br><img src="https://habrastorage.org/files/a38/c11/883/a38c11883cf642d3a157c98283354c2a.jpg" alt="image"><br>  <i>Fig.</i>  <i>5. Combining end points after compression.</i> <br><br>  To restore the bifurcation and intersection points (Fig. 6) for each end point, its direction is calculated, after which the fixed-length segment is expanded. <img src="https://habrastorage.org/files/11f/349/a6c/11f349a6c3784de19bb1076a2cc3448c.jpg" alt="image">  If this extension intersects with another segment, then a bifurcation point or intersection is found. <br><br><img src="https://habrastorage.org/files/a2a/d1d/370/a2ad1d3705f64d17a90937d6ac0f21c1.jpg" alt="image"><br>  <i>Fig.</i>  <i>6. Restoring the bifurcation point.</i> <br><br>  The intersection point is two bifurcation points, therefore, to simplify the task, you can only search for bifurcation points.  To remove spurious surges caused by intersection points, you can discard points that are too close to another point found. <br><br>  To find the points of intersection, additional analysis is needed (Fig. 7). <br><br><img src="https://habrastorage.org/files/cfc/636/0a5/cfc6360a5cd94a46981bd030d909ad7d.jpg" alt="image"><br>  <i>Fig.</i>  <i>7. Classification of branch points by the number of intersections of vessels with a circle.</i>  <i>(a) Bifurcation point.</i>  <i>(b) Point of intersection.</i> <br><br>  As seen in fig.  7 (b), depending on the length of the radius, the circle centered at the branching point may intersect with the blood vessels in either three or four points.  Therefore, the branch point may not be correctly classified.  To get rid of this problem, use the voting system shown in Fig.  eight. <br><br><img src="https://habrastorage.org/files/13d/a57/331/13da573318d742d8b0b75c4cbe5d1e1a.jpg" alt="image"><br>  <i>Fig.</i>  <i>8. Scheme for the classification of bifurcation points and intersections.</i> <br><br>  In this voting system, the branch point <img src="https://habrastorage.org/files/d48/be7/599/d48be7599de0411cb19c527c2769e74c.jpg" alt="image">  classified for three different radii <img src="https://habrastorage.org/files/1b6/1dc/4ec/1b61dc4ec6264c6996e13dfd1cc7eaa7.jpg" alt="image">  by the number of intersections of a circle with blood vessels.  Radii are defined as: <img src="https://habrastorage.org/files/bb7/b36/372/bb7b3637279b40859dbc5d737dffdfb8.jpg" alt="image">  Where <img src="https://habrastorage.org/files/e9b/b53/1f7/e9bb531f705240a781d2afbef98b0b15.jpg" alt="image">  and <img src="https://habrastorage.org/files/27e/c75/759/27ec757596234cea91966835b41b76bb.jpg" alt="image">  take fixed values.  This calculates two values. <img src="https://habrastorage.org/files/a36/f71/564/a36f71564fe047e1991c786f0c20a28d.jpg" alt="image">  and <img src="https://habrastorage.org/files/876/b12/c3f/876b12c3fc0a40498a67ee4a9eadd605.jpg" alt="image">  signifying the number of votes for that point <img src="https://habrastorage.org/files/d48/be7/599/d48be7599de0411cb19c527c2769e74c.jpg" alt="image">  was classified as an intersection point and as a bifurcation point, respectively: <br><br><img src="https://habrastorage.org/files/a24/8ae/a43/a248aea438d74fd3b30097fbbc131f19.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/77b/521/94b/77b52194b8e34ceb93f58f38ab02dd06.jpg" alt="image">  and <img src="https://habrastorage.org/files/c43/434/6b1/c434346b1864410bbd1daedd25b81889.jpg" alt="image">  - binary values ‚Äã‚Äãindicating whether a point is identified <img src="https://habrastorage.org/files/d48/be7/599/d48be7599de0411cb19c527c2769e74c.jpg" alt="image">  using radius <img src="https://habrastorage.org/files/104/eef/c61/104eefc612504a1390bcc6da94946e97.jpg" alt="image">  as a point of intersection or as a point of bifurcation, respectively. <br><br>  If <img src="https://habrastorage.org/files/6dd/129/c07/6dd129c07d7042c6a8f810932c402d45.jpg" alt="image">  then point type <img src="https://habrastorage.org/files/d48/be7/599/d48be7599de0411cb19c527c2769e74c.jpg" alt="image">  not determined.  If the values ‚Äã‚Äãdiffer from each other, then <img src="https://habrastorage.org/files/64e/521/f37/64e521f372c040b1bb53eed7fd0f6df5.jpg" alt="image">  point <img src="https://habrastorage.org/files/d48/be7/599/d48be7599de0411cb19c527c2769e74c.jpg" alt="image">  classified as an intersection point, otherwise as a bifurcation point. <br><br><h5>  <b>3.2.</b>  <b>Search for similarity transformation and definition of similarity metrics</b> </h5><habracut><br>  After the points are found, it is necessary to find a similarity transformation.  This conversion is described by 4 parameters. <img src="https://habrastorage.org/files/61d/641/48a/61d64148aa334aa08041f7ef2f1ef8e8.jpg" alt="image">  - axis offset <img src="https://habrastorage.org/files/fec/697/79c/fec69779c70443f39eebfe1fc5e2afa3.jpg" alt="image">  and <img src="https://habrastorage.org/getpro/habr/post_images/c83/8e6/375/c838e6375ec77b88127efb24d612cd82.jpg" alt="image">  , scale and rotation respectively. <br><br>  The transformation itself is defined as: <br><br><img src="https://habrastorage.org/files/19f/333/8ee/19f3338ee08a4457a17a93172a447f41.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/393/fd0/6d4/393fd06d4e35475db714e569cf5c57e7.jpg" alt="image">  - coordinates of the point on the first image <img src="https://habrastorage.org/files/c70/cb6/341/c70cb6341565437abd77a6a2d7574a47.jpg" alt="image"><br><img src="https://habrastorage.org/files/9e0/6a7/b1d/9e06a7b1ded84c03be5d9b5ea199e9fd.jpg" alt="image">  - on the second image <img src="https://habrastorage.org/files/86d/d68/ffd/86dd68ffd2964ac080ca84481e93556b.jpg" alt="image"><br><br>  To find the similarity transformation, pairs of control points are used.  For example, points <img src="https://habrastorage.org/files/01f/455/d70/01f455d70a1344f3ad6b8c098fea5a65.jpg" alt="image">  define vector <img src="https://habrastorage.org/files/0c4/183/ec2/0c4183ec2e914a6c9f98a38779b1b5da.jpg" alt="image">  Where <img src="https://habrastorage.org/files/77a/bfa/ada/77abfaadabef4b479b105e18204160f3.jpg" alt="image">  - coordinates of the beginning of the vector, <img src="https://habrastorage.org/files/a66/8ee/4d4/a668ee4d47634bb1b94039d2deb94a13.jpg" alt="image">  - vector length and <img src="https://habrastorage.org/files/0a1/3ce/226/0a13ce22673c4d2fbc9f413bd20322a9.jpg" alt="image">  - vector direction.  In the same way is determined by the vector <img src="https://habrastorage.org/files/2a8/29a/b33/2a829ab332d846ff97f5a1aa3db1b59e.jpg" alt="image">  for points <img src="https://habrastorage.org/files/01b/5b0/13a/01b5b013a65d44b78ea6e43d8f4fd2c4.jpg" alt="image">  An example is shown in Fig.  9. <br><br><img src="https://habrastorage.org/files/762/828/128/7628281289334e9887800cd677f8c043.jpg" alt="image"><br>  <i>Fig.</i>  <i>9. An example of two pairs of control points.</i> <br><br>  Similarity transformation parameters are found from the following equalities: <br><br><img src="https://habrastorage.org/files/201/93e/c07/20193ec07d4d490e9adf86431b433857.jpg" alt="image"><br><br>  Let the number of points found on the first image be M, and on the second N, then the number of pairs of control points in the first image is <img src="https://habrastorage.org/files/b06/092/b35/b06092b35e75442380457b7bfc71d939.jpg" alt="image">  and on the second <img src="https://habrastorage.org/files/cd4/1c9/334/cd41c9334e5a4709b2ca78976a3ed29b.jpg" alt="image">  So we get <img src="https://habrastorage.org/files/b34/f69/8dc/b34f698dcddb47c7b35700ba63050ea5.jpg" alt="image">  possible transformations, among which the correct one selects the one in which the number of matched points is greatest. <br><br>  Since the value of the parameter S is close to unity, then T can be reduced by discarding pairs of points that do not satisfy the following inequality: <br><br><img src="https://habrastorage.org/files/839/68f/5fb/83968f5fb0cd4d05bb94a92bb9a6fa48.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/2eb/e51/549/2ebe5154933c48b6bf7853de1c26af20.jpg" alt="image">  Is the minimum threshold for the parameter <img src="https://habrastorage.org/files/307/fd3/84e/307fd384ec954407a9760e6d656a61b7.jpg" alt="image"><br><img src="https://habrastorage.org/files/61e/82c/bc6/61e82cbc6d814984a3910c49e0db703a.jpg" alt="image">  Is the maximum threshold for the parameter <img src="https://habrastorage.org/files/307/fd3/84e/307fd384ec954407a9760e6d656a61b7.jpg" alt="image"><br><img src="https://habrastorage.org/files/310/a77/294/310a772947f143bcb168a9a90c7ecff8.jpg" alt="image">  - a pair of control points from <img src="https://habrastorage.org/files/c70/cb6/341/c70cb6341565437abd77a6a2d7574a47.jpg" alt="image"><br><img src="https://habrastorage.org/files/8fb/8e1/f7b/8fb8e1f7bf0d4661ba13e1a4862ee17d.jpg" alt="image">  - a pair of control points from <img src="https://habrastorage.org/files/86d/d68/ffd/86dd68ffd2964ac080ca84481e93556b.jpg" alt="image"><br><br>  After applying one of the possible alignment options for points <img src="https://habrastorage.org/files/fc6/bb5/8f6/fc6bb58f6cea481ca3bcae37fbb2cb1f.jpg" alt="image">  and <img src="https://habrastorage.org/files/49f/e6e/941/49fe6e9416e04095aa0a88a4acc8510b.jpg" alt="image">  the similarity index is calculated: <br><br><img src="https://habrastorage.org/files/dcf/ff9/ab8/dcfff9ab8b0a4483946202011d8a78ec.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/2fb/d7b/126/2fbd7b12665947beb27a10db10b58fc5.jpg" alt="image">  - threshold maximum distance between points. <br>  If <img src="https://habrastorage.org/files/1c2/f40/174/1c2f40174d7c4ec49a516ec71a2e23b5.jpg" alt="image">  that <img src="https://habrastorage.org/files/744/fe6/e76/744fe6e76c854be181e1bfba7fdce6cc.jpg" alt="image"><br><br>  In some cases, both points <img src="https://habrastorage.org/files/0b4/dc7/532/0b4dc7532f3f45c48d088aa19655ab6b.jpg" alt="image">  may have a good point like value <img src="https://habrastorage.org/files/fc6/bb5/8f6/fc6bb58f6cea481ca3bcae37fbb2cb1f.jpg" alt="image">  .  It happens when <img src="https://habrastorage.org/files/f9f/89b/69c/f9f89b69c59c4e21aa7ee44e0ea7edf5.jpg" alt="image">  and <img src="https://habrastorage.org/files/dc0/2cd/d5d/dc02cdd5ddbe48a49413033250fb3e89.jpg" alt="image">  are close to each other.  To determine the most appropriate pair, the probability of similarity is calculated: <br><br><img src="https://habrastorage.org/files/fac/239/2f3/fac2392f32ce4515b6553137b86b8373.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/d76/058/c82/d76058c82b1c4ce9a096be014dc388c0.jpg" alt="image"><br><img src="https://habrastorage.org/files/473/134/f8e/473134f8ea734394818ea2caf4905410.jpg" alt="image"><br>  If a <img src="https://habrastorage.org/files/aad/a9e/671/aada9e67127c410dab092763c6872353.jpg" alt="image">  that <img src="https://habrastorage.org/files/533/5c1/207/5335c1207dab4b3793e93bac3e823309.jpg" alt="image"><br><br>  To find the number of matching points, a matrix Q of size M x N is constructed so that the i-th row and j-th column contains <img src="https://habrastorage.org/files/236/11e/411/23611e4112064dbcbc55bc52eaa8e257.jpg" alt="image"><br><br>  Then in the matrix Q a maximal nonzero element is sought.  Let this element be contained in <img src="https://habrastorage.org/files/670/348/425/6703484250a3425e9504ada509bf4714.jpg" alt="image">  line and <img src="https://habrastorage.org/files/378/cc7/a98/378cc7a9844148679c87f68f1f2180be.jpg" alt="image">  mth column then dots <img src="https://habrastorage.org/files/7a2/b06/25f/7a2b0625f1dc4781a65285c0bc8c25fd.jpg" alt="image">  and <img src="https://habrastorage.org/files/777/227/b24/777227b245694f008f56172c250b9329.jpg" alt="image">  defined as matched, and <img src="https://habrastorage.org/files/670/348/425/6703484250a3425e9504ada509bf4714.jpg" alt="image">  row and <img src="https://habrastorage.org/files/378/cc7/a98/378cc7a9844148679c87f68f1f2180be.jpg" alt="image">  column is reset.  Then again the maximum element is searched.  The search for such maxima is repeated until all the elements of the matrix Q are zero.  At the output of the algorithm, we obtain the number of matched points C. <br><br>  The metric of similarity of two retinas can be determined in several ways: <br><br><img src="https://habrastorage.org/files/deb/3c2/f5f/deb3c2f5f23944da8c400db347819216.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/93c/e96/2c6/93ce962c69584a64910f92708d6cf84a.jpg" alt="image">  - the parameter that is entered to adjust the effect of the number of matched points; <br>  f is selected by one of the following options: <br><br><img src="https://habrastorage.org/files/8a4/25c/841/8a425c8412cb4c1ab770f38ca252f8a2.jpg" alt="image"><br><br>  Metrics <img src="https://habrastorage.org/files/392/cc4/a7a/392cc4a7ab314205814a735ca0f920c0.jpg" alt="image">  normalized in one of two ways: <br><br><img src="https://habrastorage.org/files/395/68f/3c4/39568f3c4d8e46f083056df1a35256e9.jpg" alt="image"><br><br>  Where <img src="https://habrastorage.org/files/b49/f83/e09/b49f83e09c124bdb9ff9aaa1b276234e.jpg" alt="image">  and <img src="https://habrastorage.org/files/dad/ab4/4fc/dadab44fc0f249cdb16379024e9166d3.jpg" alt="image">  - some constants. <br><br><h5>  <b>3.3.</b>  <b>Additional algorithm complications</b> </h5><habracut><br>  The method based on searching for branch points can be complicated by adding additional features, such as angles, as in Fig.  ten. <br><br><img src="https://habrastorage.org/files/3b4/6bc/2ab/3b46bc2ab60a4b7397e358b1942ad049.jpg" alt="image"><br>  <i>Fig.</i>  <i>10. Angles formed by branching points as additional features.</i> <br><br>  You can also use the gamma code.  As is known, modulo-2 addition is an absolutely strong cipher when the key length is equal to the text length, and since the number of bifurcation points and intersections does not exceed about 100, but still greater than the length of regular passwords, a combination of password hashes can be used as a key.  This eliminates the need to store in the retina database and password hashes.  It is necessary to store only the coordinates, encrypted with an absolutely strong cipher. <br><br><h1>  <b>Conclusion</b> </h1><br>  Retina authentication does show accurate results.  The algorithm, based on the phase correlation method, did not make a single error when testing on the VARIA database.  The algorithm was also tested on the unallocated MESSIDOR base in order to test the algorithm for false positives.  All pairs of similar retinas found by the algorithm were checked manually.  They really are the same.  Comparing the blood vessels of two retinas from the VARIA base takes an average of 1.2 seconds on two cores of the Pentium Dual-CoreT4500 processor with a frequency of 2.30 GHz.  The execution time of the algorithm turned out to be quite large for identification, but it is acceptable for authentication. <br><br>  An attempt was also made to implement an algorithm that uses Harris angles, but failed to obtain satisfactory results.  As in the previous algorithm, a problem arose in eliminating rotation and displacement using the phase correlation method.  The second problem is related to the flaws in the Harris angle search algorithm.  With the same threshold for screening points, the number of points found may be either too large or too small. <br><br>  Future plans are to develop an algorithm based on the search for branch points.  It requires much less computational resources in comparison with the algorithm based on the phase correlation method.  In addition, there are opportunities for its complexity in order to minimize the likelihood of hacking the system. <br><br>  Another interesting direction in further research is the development of automatic systems for the early diagnosis of diseases such as glaucoma, diabetes, atherosclerosis, and many others. <br><br><div class="spoiler">  <b class="spoiler_title">List of used sources and literature</b> <div class="spoiler_text"><ul><li>  Reddy BS and Chatterji BN An FFT-Based Technique for Translation, Rotation, and Scale-Invariant Image Registration // IEEE Transactions on Image Processing.  1996. Vol.  5. No.  8. pp.  1266-1271. </li><li>  Human recognition based on retinal images and / / A. Dehghani [et al.] // EURASIP Journal on Image and Video Processing.  2013 </li><li>  Hortas MO Automatic pattern for personal authentication using the retinal vessel as biometric pattern.  PhD Thesis.  Universidade da Coru√±a.  La Coru√±a.  2009 </li><li>  <a href="http://www.varpa.es/varia.html">Varia database</a> </li><li>  <a href="http://messidor.crihan.fr/download-en.php">MESSIDOR database</a> </li></ul><br></div></div><br>  ps for a few requests I post a <a href="https://github.com/forcesh/authentication_based_on_retinal_images">link</a> to a project on a githaba. </habracut></habracut></habracut></habracut></div><p>Source: <a href="https://habr.com/ru/post/261309/">https://habr.com/ru/post/261309/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../261293/index.html">Effective logo design, part 1: symbols, metaphors and intuition capabilities</a></li>
<li><a href="../261295/index.html">Commercial VPN service in opensource</a></li>
<li><a href="../261301/index.html">SSL / TLS traffic analysis in Wireshark</a></li>
<li><a href="../261305/index.html">The digest of interesting materials for the mobile # 109 developer (June 22-28)</a></li>
<li><a href="../261307/index.html">Workers and shared workers</a></li>
<li><a href="../261311/index.html">Webinar "New Features of WebLogic 12c Application Server"</a></li>
<li><a href="../261313/index.html">2 in 1: the premiere of the "official" laptop at the opening of the official youtube channel</a></li>
<li><a href="../261323/index.html">OpenCL. How to start</a></li>
<li><a href="../261327/index.html">PHP Digest number 65 - interesting news, materials and tools (June 14 - 28, 2015)</a></li>
<li><a href="../261331/index.html">Black datamining archeology: what could be more effective than a dictionary attack?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>