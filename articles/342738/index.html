<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>RNN: Can a neural network write like Leo Tolstoy? (Spoiler: no)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="While studying Deep Learning technologies, I was faced with a lack of relatively simple examples, which can be relatively easy to practice and move on...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>RNN: Can a neural network write like Leo Tolstoy? (Spoiler: no)</h1><div class="post__text post__text-html js-mediator-article">  While studying Deep Learning technologies, I was faced with a lack of relatively simple examples, which can be relatively easy to practice and move on. <br><br>  In this example, we will construct a recurrent neural network, which, having received the text of Tolstoy‚Äôs novel Anna Karenina as an input, will generate its text, somewhat similar to the original, predicting what the next character should be. <br><br>  The structure of the presentation, I tried to do this so that you can repeat all the steps to a beginner, not even understanding in detail what exactly is happening inside this network.  Professionals of Deep Learning most likely will not find here anything interesting, and those who only study these technologies, I ask under kat. <br><a name="habracut"></a><br><h2>  Introduction </h2><br>  The basis of this mini-project were taken articles Andrej Karpathy (links below) and educational materials <a href="https://www.udacity.com/">udacity</a> . <br>  The easiest way to repeat everything described below: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  install <a href="https://www.anaconda.com/download/">anaconda</a> distribution with Python 3.6 on your PC </li><li>  create a working conda environment </li><li>  install tensorflow, numpy, jupyter libraries into this environment </li><li>  write and execute code in Jupyter Notebook, which gives us the necessary interactivity </li><li>  <a href="">Download the</a> text of the novel in txt format </li></ul><br>  In the case of anaconda installation on Windows, do the following: <br><br>  1. Create a folder in which we will work, copy the text there under the name "anna.txt" <br><br>  2. Run Anaconda Promt, go to the created folder, create the necessary environment ‚Äútolstoy‚Äù with the necessary libraries and activate it: <br><br><pre><code class="hljs tex">(C:<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">anaconda</span></span></span></span>3) C:<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">DL</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">rnn</span></span></span></span>-tolstoy&gt;conda create -n tolstoy ... (C:<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">anaconda</span></span></span></span>3) C:<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">DL</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">rnn</span></span></span></span>-tolstoy&gt;activate tolstoy (tolstoy) C:<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">DL</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">rnn</span></span></span></span>-tolstoy&gt;conda install numpy tensorflow jupyter ...</code> </pre> <br>  3. When all libraries are installed, run jupyter notebook, in which we will work: <br><br><pre> <code class="hljs tex">(tolstoy) C:<span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">DL</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">rnn</span></span></span></span>-tolstoy&gt;jupyter notebook</code> </pre> <br>  4. The notebook menu opens in the browser, we go there to ‚ÄúNew‚Äù and select Notebook -&gt; Python 3, as shown in the picture: <br><br><img src="https://habrastorage.org/webt/gi/ep/gx/giepgxqjhxbdqwlpythjajdmjkc.png" alt="image"><br><br>  Then the notebook itself opens, where we will drive in the code and admire the result of its work.  For example, having driven the code into the ‚ÄúIn‚Äù cell, we can execute it by pressing Shift + Enter and immediately get the result: <br><br><img src="https://habrastorage.org/webt/lw/jw/wq/lwjwwqj08grbshsavy1xgzolweg.png" alt="image"><br><br>  By this time we have dealt with the basic things, now we can proceed to the task itself. <br>  The following is a general recurrent neural network (RNN) architecture that predicts the next symbol (taken <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">from here</a> ): <br><br><img src="https://habrastorage.org/webt/cu/a9/fk/cua9fkl3d3dp3fccwbad6g8slxa.jpeg" alt="image"><br><br>  The diagram shows the key feature of RNN - information can be processed cyclically as it moves from input to output, providing (unlike traditional neural networks) a memory effect and allowing processing of related sequences. <br><br><h2>  We initialize and prepare data </h2><br>  Import the necessary libraries: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> namedtuple <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf</code> </pre> <br>  Load the text of the novel, create a vocabulary of symbols, dictionary objects for translation of the symbol -&gt; code, code -&gt; symbol and encode all the text of the novel (encoded array): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'anna.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: text=f.read() vocab = sorted(set(text)) vocab_to_int = {c: i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(vocab)} int_to_vocab = dict(enumerate(vocab)) encoded = np.array([vocab_to_int[c] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> text], dtype=np.int32)</code> </pre> <br>  Checking the beginning, the famous phrase in place, everything is in order: <br><br><pre> <code class="python hljs">text[:<span class="hljs-number"><span class="hljs-number">110</span></span>]</code> </pre> <br><pre> <code class="hljs tex">Out: ' <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">nI</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span></span><span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">n</span></span></span></span>      ,     -.'</code> </pre> <br>  We look, how it looks in the coded form (in this form the data will be processed in the network): <br><br><pre> <code class="python hljs">encoded[:<span class="hljs-number"><span class="hljs-number">110</span></span>]</code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">array</span></span>([ <span class="hljs-number"><span class="hljs-number">99</span></span>, <span class="hljs-number"><span class="hljs-number">77</span></span>, <span class="hljs-number"><span class="hljs-number">93</span></span>, <span class="hljs-number"><span class="hljs-number">94</span></span>, <span class="hljs-number"><span class="hljs-number">102</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">91</span></span>, <span class="hljs-number"><span class="hljs-number">82</span></span>, <span class="hljs-number"><span class="hljs-number">92</span></span>, <span class="hljs-number"><span class="hljs-number">79</span></span>, <span class="hljs-number"><span class="hljs-number">77</span></span>, <span class="hljs-number"><span class="hljs-number">105</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">79</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">129</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">124</span></span>, <span class="hljs-number"><span class="hljs-number">117</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">133</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">118</span></span>, <span class="hljs-number"><span class="hljs-number">134</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">121</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">127</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>, <span class="hljs-number"><span class="hljs-number">122</span></span>, <span class="hljs-number"><span class="hljs-number">125</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">119</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>, <span class="hljs-number"><span class="hljs-number">122</span></span>, <span class="hljs-number"><span class="hljs-number">125</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">116</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">137</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">119</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">129</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">124</span></span>, <span class="hljs-number"><span class="hljs-number">117</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">137</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">118</span></span>, <span class="hljs-number"><span class="hljs-number">134</span></span>, <span class="hljs-number"><span class="hljs-number">137</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">119</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">129</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">124</span></span>, <span class="hljs-number"><span class="hljs-number">117</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">121</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">123</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">118</span></span>, <span class="hljs-number"><span class="hljs-number">125</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>])</code> </pre> <br>  Since our network works with individual characters, we are dealing with a classification problem when we try to predict the next character from the previous text.  Dictionary length is essentially the number of classes from which our network will make a choice: <br><br><pre> <code class="python hljs">len(vocab)</code> </pre> <br> <code>Out: 140</code> <br> <br>  There are a lot of characters in the dictionary, but you need to take into account that upper and lower case letters are different characters, and we also remember a lot of French text, i.e.  we actually have two alphabets. <br><br><h2>  We divide data into packages </h2><br>  For effective training of our network it is necessary to break the data into packets (mini-batches).  First, it saves RAM.  If we try to drive all the data into the network at once, the memory may simply not be enough.  Secondly, when splitting data into packets, the network will be trained much faster - we can update the weights in the neural network after passing each data packet, as well as parallelize the loading of packets, as shown in the picture: <br><br><img src="https://habrastorage.org/webt/mo/3c/w5/mo3cw5cuidagmpzryil90me3rye.png" alt="image"><br><br>  Create a procedure for obtaining the source packet, which will be fed to the input of the neural network (feature) and the control package, with which the network prediction (target) will be compared: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_batches</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(arr, n_seqs, n_steps)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' ,     n_seqs x n_steps   arr.  --------- arr: ,     n_seqs: Batch size,     n_steps: Sequence length,  ""    '''</span></span> <span class="hljs-comment"><span class="hljs-comment">#        ,    characters_per_batch = n_seqs * n_steps n_batches = len(arr)//characters_per_batch #     ,       arr = arr[:n_batches * characters_per_batch] #  reshape 1D -&gt; 2D,  n_seqs   ,    arr = arr.reshape((n_seqs, -1)) for n in range(0, arr.shape[1], n_steps): #  ,       x = arr[:, n:n+n_steps] #  ,     ,   "x"     y = np.zeros_like(x) y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0] yield x, y</span></span></code> </pre> <br>  The function works as a <a href="https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/">generator</a> , each call to which allows you to get the following pair of "x" and "y", for example: <br><br><pre> <code class="python hljs">batches = get_batches(encoded, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>) x, y = next(batches) print(<span class="hljs-string"><span class="hljs-string">'x\n'</span></span>, x[:<span class="hljs-number"><span class="hljs-number">5</span></span>, :<span class="hljs-number"><span class="hljs-number">5</span></span>]) print(<span class="hljs-string"><span class="hljs-string">'\ny\n'</span></span>, y[:<span class="hljs-number"><span class="hljs-number">5</span></span>, :<span class="hljs-number"><span class="hljs-number">5</span></span>])</code> </pre> <br><pre> <code class="hljs lua">x <span class="hljs-string"><span class="hljs-string">[[ 99 77 93 94 102] [ 1 110 108 114 112] [ 79 120 124 1 120] [114 119 1 109 120] [106 108 111 110 117]]</span></span> y <span class="hljs-string"><span class="hljs-string">[[ 77 93 94 102 1] [110 108 114 112 111] [120 124 1 120 124] [119 1 109 120 108] [108 111 110 117 114]]</span></span></code> </pre> <br>  The output shows a shift of the packet ‚Äúy‚Äù relative to the packet ‚Äúx‚Äù. <br><br><h2>  Build a model </h2><br>  Below is a diagram of our RNN model: <br><br><img src="https://habrastorage.org/webt/x3/j6/ic/x3j6ick88iojvy9jsxvyvqdh39y.png"><br><br>  The main learning magic occurs in the LSTM (Long Short Term Memory) cell. <br>  Here is a wonderful article in which the logic of the work of such cells and neural networks based on LSTM is described in simple and understandable English. <br><br>  When building a model, we first define incoming parameters: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_inputs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(batch_size, num_steps)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''  placeholder'  ,  ,    drop out  --------- batch_size: Batch size,     num_steps: Sequence length,  ""    '''</span></span> <span class="hljs-comment"><span class="hljs-comment">#  placeholder' inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs') targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets') # Placeholder   drop out keep_prob = tf.placeholder(tf.float32, name='keep_prob') return inputs, targets, keep_prob</span></span></code> </pre> <br>  It must be recalled that the data in Tensorflow is stored in <a href="https://www.tensorflow.org/programmers_guide/tensors">tensors</a> . <br>  " <a href="https://www.tensorflow.org/versions/r0.12/api_docs/python/io_ops/placeholders">placeholders</a> " are the type of tensors that determine the type and format of data (for example, the dimension of the matrix), and the data itself will actually be loaded at the right time in the future. <br>  As for drop out, this is a mechanism to counteract the effect of "retraining" our network, when in the process we randomly exclude some of the vertices of our graph from the calculations: <br><br><img src="https://habrastorage.org/webt/4s/ei/ts/4seitskn-xeqf_b-fp6__cxu9_a.png"><br><br>  Next we build the structure of the LTSM cell. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_lstm</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(lstm_size, num_layers, batch_size, keep_prob)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''  LSTM .  --------- keep_prob:  (tf.placeholder)  dropout keep probability lstm_size:     LSTM  num_layers:  LSTM  batch_size: Batch size '''</span></span> <span class="hljs-comment"><span class="hljs-comment">###  LSTM  def build_cell(lstm_size, keep_prob): #    LSTM  lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size) #  dropout   drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob) return drop #   LSTM      deep learning cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)]) #    LTSM  initial_state = cell.zero_state(batch_size, tf.float32) return cell, initial_state</span></span></code> </pre> <br>  Next, we will build the output layer.  We are determined with the dimension. <br>  If the input data had the dimension <b>M</b> (batch size), <b>N</b> (sequence length) and passed through hidden layers of size <b>L</b> units, then at the output we get a 3D tensor of dimension <b>MxNxL</b> .  To simplify the problem, we make reshape 3D -&gt; 2D and reduce the tensor to the form <b>(M ‚àó N) √ó L.</b>  Thus, we will have one line for each sequence and each ‚Äústep‚Äù and the value of each line is the output from LSTM units. <br>  We multiply this matrix by the output level weights matrix and add the output level offset. <br><br>  At the same time, we initialize the weights with random variables with a truncated normal distribution (in the range of 2 standard deviations), and bias we initialize with zeros, which is a recommended practice in neural networks. <br><br>  The result of the output layer is passed through the softmax activation function (for more details on the activation functions <a href="https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0">here</a> ), using the result of this function as a predictor. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_output</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(lstm_output, in_size, out_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''  softmax      .  --------- x:   LSTM  in_size:   , (- LSTM   ) out_size:  softmax  ( ) '''</span></span> <span class="hljs-comment"><span class="hljs-comment">#    ,   3D -&gt; 2D seq_output = tf.concat(lstm_output, axis=1) x = tf.reshape(seq_output, [-1, in_size]) #   LTSM   softmax  with tf.variable_scope('softmax'): softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1)) softmax_b = tf.Variable(tf.zeros(out_size)) #  logit- logits = tf.matmul(x, softmax_w) + softmax_b #   softmax    out = tf.nn.softmax(logits, name='predictions') return out, logits</span></span></code> </pre> <br>  Next, we define the loss function (that is, we measure how wrong we are).  To do this, we compute softmax cross entropy between the values ‚Äã‚Äãof the logit function and the label (which in turn are target values ‚Äã‚Äãthat have passed through one-hot encoding). <br>  In deep learning, one-hot coding is often used to represent categorical variables in the form of binary vectors, so that they are more convenient to use in further calculations.  For example, the sequence of data: <br><br> <code>[red, yellow, green]</code> <br>  we can encode in integer (as we did above in the variable encoded) in: <br><br> <code>[0, 1, 2]</code> <br>  and after one-hot coding it will look like this: <br><br> <code>[[1, 0, 0], <br> [0, 1, 0], <br> [0, 0, 1]]</code> <br>  The function of loss in deep learning is considered in different ways.  For the tasks of classifying objects that belong to mutually exclusive classes (in our case, the next symbol cannot be both ‚Äúa‚Äù and ‚Äúb‚Äù), the loss function is <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits">calculated</a> through the <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits">softmax</a> function <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits">cross entropy with logits</a> and we return the average value of this function of all elements across all dimensions tensor. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(logits, targets, lstm_size, num_classes)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''       logit-   .  --------- logits:  logit- targets:  ,     lstm_size:    LSTM  num_classes:      ( ) '''</span></span> <span class="hljs-comment"><span class="hljs-comment">#  one-hot          logits y_one_hot = tf.one_hot(targets, num_classes) y_reshaped = tf.reshape(y_one_hot, logits.get_shape()) #     softmax cross entropy loss     loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped) loss = tf.reduce_mean(loss) return loss</span></span></code> </pre> <br>  Next, we build an optimizer, which is based on the gradient descent method.  In this case, we are protected from two problems (for more details, <a href="http://neuralnetworksanddeeplearning.com/chap5.html">click here</a> ): <br><br><ul><li>  "Disappearance" of the gradient (protection is built into the logic of the LSTM cells); </li><li>  Gradient ‚Äúexplosion‚Äù (for this we use gradient clipping here). </li></ul><br>  Adam optimizer is used as optimization function. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_optimizer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(loss, learning_rate, grad_clip)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''    ,   . Arguments: loss:    learning_rate:    '''</span></span> <span class="hljs-comment"><span class="hljs-comment">#   ,     ""  tvars = tf.trainable_variables() grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip) train_op = tf.train.AdamOptimizer(learning_rate) optimizer = train_op.apply_gradients(zip(grads, tvars)) return optimizer</span></span></code> </pre> <br>  Now we collect all the details of the puzzle together and build a class that describes our network.  The key operator that forms the RNN network is tf.nn.dynamic_rnn.  It returns the output of each LSTM cell at each step, for each sequence, in each packet (mini-batch).  In addition, it returns the final status of the LSTM cells, which we save and transfer to the input in the first LSTM cell when the next data packet is loaded.  At the input of tf.nn.dynamic_rnn, we give the cell (cell), the initial status, which we get from build_lstm and the input data sequence. <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CharRNN</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, num_classes, batch_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">64</span></span></span></span><span class="hljs-function"><span class="hljs-params">, num_steps=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">50</span></span></span></span><span class="hljs-function"><span class="hljs-params">, lstm_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">128</span></span></span></span><span class="hljs-function"><span class="hljs-params">, num_layers=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, learning_rate=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.001</span></span></span></span><span class="hljs-function"><span class="hljs-params">, grad_clip=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, sampling=False)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#         ( ), #           if sampling == True: batch_size, num_steps = 1, 1 else: batch_size, num_steps = batch_size, num_steps tf.reset_default_graph() #  input placeholder' self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps) #  LSTM  cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob) ###    RNN  #  one-hot    x_one_hot = tf.one_hot(self.inputs, num_classes) #    RNN    outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state) self.final_state = state #   (softmax)   logit- self.prediction, self.logits = build_output(outputs, lstm_size, num_classes) #     (  ) self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes) self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)</span></span></code> </pre> <br><h2>  We select hyper parameters </h2><br>  Next, we set the hyperparameters for our model.  There is a big space for creativity, because by changing these parameters you can ‚Äúsqueeze‚Äù more out of the network.  I will not dwell on the strategy of setting up, since this is a separate large topic, which is devoted to many articles and studies. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#   num_steps = 100 #    lstm_size = 512 #  LSTM     num_layers = 2 #  LSTM  learning_rate = 0.001 #   keep_prob = 0.5 # Dropout keep probability</span></span></code> </pre> <br><h2>  We teach the model </h2><br>  Now we start learning our model. <br>  We launch input and target data into the network, we launch optimization.  For each package (mini-batch) we keep the final LSTM status, which we give to the entrance to the network with the next package, ensuring continuity.  Periodically (determined by the save_every_n variable) we save the state of our model (with all variables, weights, etc.) in the <a href="https://www.tensorflow.org/programmers_guide/saved_model">checkpoint</a> .  There is another parameter here - the number of epochs (complete training cycles of the model).  It is also necessary to remind that all work with data in Tensorflow is carried out within an open session, which usually begins with the code <code>with tf.Session() as sess:</code> <br><br><pre> <code class="python hljs">epochs = <span class="hljs-number"><span class="hljs-number">20</span></span> <span class="hljs-comment"><span class="hljs-comment">#   N  save_every_n = 200 model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps, lstm_size=lstm_size, num_layers=num_layers, learning_rate=learning_rate) saver = tf.train.Saver(max_to_keep=100) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) #         checkpoint' #saver.restore(sess, 'checkpoints/______.ckpt') counter = 0 for e in range(epochs): #   new_state = sess.run(model.initial_state) loss = 0 for x, y in get_batches(encoded, batch_size, num_steps): counter += 1 start = time.time() feed = {model.inputs: x, model.targets: y, model.keep_prob: keep_prob, model.initial_state: new_state} batch_loss, new_state, _ = sess.run([model.loss, model.final_state, model.optimizer], feed_dict=feed) end = time.time() print('Epoch: {}/{}... '.format(e+1, epochs), 'Training Step: {}... '.format(counter), 'Training loss: {:.4f}... '.format(batch_loss), '{:.4f} sec/batch'.format((end-start))) if (counter % save_every_n == 0): saver.save(sess, "checkpoints/i{}_l{}.ckpt".format(counter, lstm_size)) saver.save(sess, "checkpoints/i{}_l{}.ckpt".format(counter, lstm_size))</span></span></code> </pre> <br>  Further we observe the learning process: <br><br><pre> <code class="hljs matlab">Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">20.</span></span>.. Training Step: <span class="hljs-number"><span class="hljs-number">1.</span></span>.. Training loss: <span class="hljs-number"><span class="hljs-number">4.9402</span></span>... <span class="hljs-number"><span class="hljs-number">7.7964</span></span> <span class="hljs-built_in"><span class="hljs-built_in">sec</span></span>/batch Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">20.</span></span>.. Training Step: <span class="hljs-number"><span class="hljs-number">2.</span></span>.. Training loss: <span class="hljs-number"><span class="hljs-number">4.8530</span></span>... <span class="hljs-number"><span class="hljs-number">7.1318</span></span> <span class="hljs-built_in"><span class="hljs-built_in">sec</span></span>/batch ... Epoch: <span class="hljs-number"><span class="hljs-number">20</span></span>/<span class="hljs-number"><span class="hljs-number">20.</span></span>.. Training Step: <span class="hljs-number"><span class="hljs-number">3400.</span></span>.. Training loss: <span class="hljs-number"><span class="hljs-number">1.4003</span></span>... <span class="hljs-number"><span class="hljs-number">6.6569</span></span> <span class="hljs-built_in"><span class="hljs-built_in">sec</span></span>/batch</code> </pre> <br>  We see a gradual decrease in training loss. <br><br>  On my PC, this learning process took about 6 hours.  If you have a machine with a good GPU, this period can be reduced by several times. <br><br>  Check our saved checkpoints: <br><br><pre> <code class="python hljs">tf.train.get_checkpoint_state(<span class="hljs-string"><span class="hljs-string">'checkpoints'</span></span>)</code> </pre> <br><pre> <code class="hljs objectivec">model_checkpoint_path: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i3400_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i200_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i400_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i600_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i800_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i1000_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i1200_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i1400_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i1600_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i1800_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i2000_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i2200_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i2400_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i2600_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i2800_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i3000_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i3200_l512.ckpt"</span></span> all_model_checkpoint_paths: <span class="hljs-string"><span class="hljs-string">"checkpoints\\i3400_l512.ckpt"</span></span></code> </pre> <br><h2>  Generate text </h2><br>  Now we can proceed to the sampling, that is, to generate text. <br>  The idea is that by feeding one character to the network input, we get the predicted character at the output, which we add to the generated text and feed it again to the network input at the next iteration, etc.  The exception is the text for ‚Äúwarming up‚Äù of the model, which is fed to the input in the prime parameter. <br><br>  The <code>pick_top_n</code> function <code>pick_top_n</code> used to reduce the ‚Äúnoise‚Äù of predictions, leaving only a specified number (default 5) of options for selection, discarding all other options. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pick_top_n</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(preds, vocab_size, top_n=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> p = np.squeeze(preds) p[np.argsort(p)[:-top_n]] = <span class="hljs-number"><span class="hljs-number">0</span></span> p = p / np.sum(p) c = np.random.choice(vocab_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, p=p)[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> c</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(checkpoint, n_samples, lstm_size, vocab_size, prime=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"     ."</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> samples = [c <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prime] model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) saver = tf.train.Saver() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: saver.restore(sess, checkpoint) new_state = sess.run(model.initial_state) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prime: x = np.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x[<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>] = vocab_to_int[c] feed = {model.inputs: x, model.keep_prob: <span class="hljs-number"><span class="hljs-number">1.</span></span>, model.initial_state: new_state} preds, new_state = sess.run([model.prediction, model.final_state], feed_dict=feed) c = pick_top_n(preds, len(vocab)) samples.append(int_to_vocab[c]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_samples): x[<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>] = c feed = {model.inputs: x, model.keep_prob: <span class="hljs-number"><span class="hljs-number">1.</span></span>, model.initial_state: new_state} preds, new_state = sess.run([model.prediction, model.final_state], feed_dict=feed) c = pick_top_n(preds, len(vocab)) samples.append(int_to_vocab[c]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">''</span></span>.join(samples)</code> </pre> <br>  Now we generate the text and see what happened. <br><br>  To begin with - an early state of the model (after 200 iterations). <br><br><pre> <code class="python hljs">checkpoint = <span class="hljs-string"><span class="hljs-string">'checkpoints/i200_l512.ckpt'</span></span> samp = sample(checkpoint, <span class="hljs-number"><span class="hljs-number">1000</span></span>, lstm_size, len(vocab)) print(samp)</code> </pre> <br><pre> <code class="hljs 1c">INFO:tensorflow:Restoring parameters from checkpoints/i200_l512.ckpt      . ‚Äì     ,,                               ,    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>   <span class="hljs-keyword"><span class="hljs-keyword"></span></span>  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>     ,  , ,    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>               ,       ,                      <span class="hljs-keyword"><span class="hljs-keyword"></span></span>  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>     ,              <span class="hljs-keyword"><span class="hljs-keyword"></span></span>         ,       , <span class="hljs-keyword"><span class="hljs-keyword"></span></span>     ,  ,         <span class="hljs-keyword"><span class="hljs-keyword"></span></span>                        ,.. ‚Äì         ,                 ,            ,             <span class="hljs-keyword"><span class="hljs-keyword"></span></span>    ,   </code> </pre> <br>  On the one hand, it turned out some nonsense.  On the other hand, we see that the neural network begins to form an understanding of words as a set of characters, separated by spaces, and even the use of some punctuation marks. <br><br>  Go ahead (after the 600th iteration). <br><br><pre> <code class="python hljs">checkpoint = <span class="hljs-string"><span class="hljs-string">'checkpoints/i600_l512.ckpt'</span></span> samp = sample(checkpoint, <span class="hljs-number"><span class="hljs-number">1000</span></span>, lstm_size, len(vocab)) print(samp)</code> </pre> <br><pre> <code class="hljs 1c">INFO:tensorflow:Restoring parameters from checkpoints/i600_l512.ckpt      . ,  ,   <span class="hljs-keyword"><span class="hljs-keyword"></span></span>     , -   <span class="hljs-keyword"><span class="hljs-keyword"></span></span>       ,       <span class="hljs-keyword"><span class="hljs-keyword"></span></span>      ,     <span class="hljs-keyword"><span class="hljs-keyword"></span></span>         <span class="hljs-keyword"><span class="hljs-keyword"></span></span>        ,       ,    ,  . ‚Äì        <span class="hljs-keyword"><span class="hljs-keyword"></span></span>          <span class="hljs-keyword"><span class="hljs-keyword"></span></span>             ,      ,      <span class="hljs-keyword"><span class="hljs-keyword"></span></span> .    <span class="hljs-keyword"><span class="hljs-keyword"></span></span> , ‚Äì  . ‚Äì ,  ,       ,      ,   ,     ,   ,   ,                <span class="hljs-keyword"><span class="hljs-keyword"></span></span>       ,  </code> </pre> <br>  Here we see and the ‚Äúwords‚Äù have become more authentic, some beginnings of dialogues have emerged.  At some point, the grid even cursed :) <br><br>  In general, the positive dynamics is evident. <br><br>  Well, the result of the last iteration. <br><br><pre> <code class="python hljs">checkpoint = tf.train.latest_checkpoint(<span class="hljs-string"><span class="hljs-string">'checkpoints'</span></span>) samp = sample(checkpoint, <span class="hljs-number"><span class="hljs-number">2000</span></span>, lstm_size, len(vocab)) print(samp)</code> </pre> <br><pre> <code class="hljs 1c">INFO:tensorflow:Restoring parameters from checkpoints\i3400_l512.ckpt      . ,     ,  ,   ,   <span class="hljs-keyword"><span class="hljs-keyword"></span></span> .   <span class="hljs-keyword"><span class="hljs-keyword"></span></span>     .    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>      ,    ,         . ‚Äì ,     , ‚Äì  , ‚Äì  ,     -  ,        ,        ,    <span class="hljs-keyword"><span class="hljs-keyword"></span></span> ,   ,  ,    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>     .   .     ,  ,   ,   <span class="hljs-keyword"><span class="hljs-keyword"></span></span> . ‚Äì      . ,  ,  ,     . ‚Äì ,    , ‚Äì   . ‚Äì ,  ,   ,    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>    .  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>  ,   <span class="hljs-keyword"><span class="hljs-keyword"></span></span>            ,  .   , ‚Äì  . ‚Äì      . ‚Äì ,  , ‚Äì      , ‚Äì  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>      ,   , ‚Äì  . ‚Äì    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>   ,   <span class="hljs-keyword"><span class="hljs-keyword"></span></span> , ‚Äì  , ‚Äì  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>  ,    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>  ,   ,      , ‚Äì         ,     , ‚Äì  . ¬´,  ,   . ,   <span class="hljs-keyword"><span class="hljs-keyword"></span></span> ,   , ‚Äì   ,                 , <span class="hljs-keyword"><span class="hljs-keyword"></span></span> , ‚Äì    <span class="hljs-keyword"><span class="hljs-keyword"></span></span>-     . ‚Äì ,  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>  .  <span class="hljs-keyword"><span class="hljs-keyword"></span></span>   .       , ‚Äì  ,       <span class="hljs-keyword"><span class="hljs-keyword"></span></span>   .        ,   </code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here we see that words are basically composed correctly of letters. </font><font style="vertical-align: inherit;">Dialogs are marked, punctuation marks are well placed, etc. </font><font style="vertical-align: inherit;">If you look from afar and do not read the text, it looks decent.</font></font><br><br><h2>  Conclusion </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obviously, our network has not yet learned how to write like Leo Tolstoy, but progress has been made as far as learning is concerned. </font><font style="vertical-align: inherit;">At the same time, in order to move towards greater meaningfulness, you need to use other methods (for example, word embedding), because with the help of char-wise RNN you can get a good grammar relatively easily, but it‚Äôs probably not easy to get meaning from the text. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nevertheless, this example illustrates what kind of magic can occur within a neural network, despite the fact that no rules, no grammar of the language are given to the input, and it has to be thought of before all this.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Of course, you can submit another text to the input (preferably not less voluminous), in any language, play with hyper parameters and get some other results. </font><font style="vertical-align: inherit;">I hope that even a simple repetition of the steps described can lead someone to figure out how things work out here and I guarantee that you will have many interesting discoveries along the way :)</font></font></div><p>Source: <a href="https://habr.com/ru/post/342738/">https://habr.com/ru/post/342738/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../342728/index.html">The chatbot, which is ‚Äújust like Siri, only cooler‚Äù on the naive Bayes classifier</a></li>
<li><a href="../342730/index.html">Dragon Glass or the story about the game editor Larian Studios</a></li>
<li><a href="../342732/index.html">Time bitcoin banks?</a></li>
<li><a href="../342734/index.html">Retrospective: Heroes of Might & Magic III</a></li>
<li><a href="../342736/index.html">Golang, PHP, Film Search and Telegraph - What unites them?</a></li>
<li><a href="../342740/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ289 (November 13 - 19, 2017)</a></li>
<li><a href="../342742/index.html">PHP Digest 120 (November 1 - 19, 2017)</a></li>
<li><a href="../342744/index.html">6 things on the Internet that people misunderstand</a></li>
<li><a href="../342748/index.html">Understanding MVC in ASP.NET MVC and more</a></li>
<li><a href="../342750/index.html">Quadratic arithmetic programs: from mud to riches (translation)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>