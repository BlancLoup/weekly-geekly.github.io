<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Overview of SLAM algorithms for depth cameras in ROS</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, dear readers! In the last article, I already wrote about the rtabmap SLAM algorithm in the context of visual odometry methods. In this...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Overview of SLAM algorithms for depth cameras in ROS</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, dear readers!  In the <a href="https://geektimes.ru/post/290295/">last article,</a> I already wrote about the rtabmap SLAM algorithm in the context of visual odometry methods.  In this article I will talk about this SLAM algorithm in more detail, and also provide an overview of another well-known SLAM algorithm designed for depth cameras - RGBDSLAM.  Anyone interested, please under the cat. <a name="habracut"></a><br><br><h2>  rtabmap </h2><br>  About the project can be read in detail on the <a href="http://introlab.github.io/rtabmap/">official page</a> . <br><br>  I described the rtabmap installation procedure in detail in a <a href="https://geektimes.ru/post/290295/">previous article</a> .  For example, on a Ubuntu 14.04 system, the installation will look like this: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre><code class="bash hljs">sudo apt-get install ros-indigo-rtabmap ros-indigo-rtabmap-ros</code> </pre> <br>  However, on Raspberry Pi 3 with the Kinetic ROS installed, this method will not work, since the rtabmap build is disabled in the Kinetic release for ARM due to a problem with libpcl-dev (for more information about the problem, read <a href="https://answers.ros.org/question/242666/sudo-apt-get-ros-kinetic-rtabmap-ros-e-unable-to-locate-package/">here</a> ).  Therefore, we compile it from source by following the <a href="https://github.com/introlab/rtabmap_ros">instructions</a> on the rtabmap page: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/introlab/rtabmap.git rtabmap <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> rtabmap/build cmake .. [&lt;---double dots included] make</code> </pre><br>  If swap is not available on the Raspberry Pi, then virtual memory may not be enough at compile time: <br><br><pre> <code class="bash hljs">virtual memory exhausted: Cannot allocate memory</code> </pre><br>  You need to add the swap memory according to the instructions <a href="https://www.digitalocean.com/community/tutorials/how-to-add-swap-space-on-ubuntu-16-04">from here</a> and re-run the compilation. <br>  The compilation should take about an hour.  After this, perform the installation: <br><br><pre> <code class="bash hljs">sudo make install</code> </pre><br>  Install the rtabmap_ros package in our catkin working directory: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/introlab/rtabmap_ros.git src/rtabmap_ros catkin_make -j1 <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> devel/setup.bash</code> </pre><br>  When running catkin_make, an error may occur due to the lack of the image_transportConfig.cmake file.  In this case, you need to compile the image_transport package in the working directory catkin_ws: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> src git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/ros-perception/image_common.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws catkin_make -j1 <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> devel/setup.bash</code> </pre><br>  In order to avoid errors with loading of dynamic libraries when starting the rtabmap_ros nodes, it is recommended to add the following line to ~ / .bashrc: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib'</span></span> &gt;&gt; ~/.bashrc</code> </pre><br><h2>  Using rtabmap to build a map </h2><br>  Run rtabmap: <br><br><pre> <code class="bash hljs">rtabmap</code> </pre><br><img src="https://habrastorage.org/web/159/080/a26/159080a26bdd462989c170992148b37b.png" alt="image"><br><br>  Create a new database: File ‚Üí New database: <br><br><img src="https://habrastorage.org/web/a41/eec/af6/a41eecaf6c7e4f08b8509af945b9583a.png" alt="image"><br><br>  For the Kinect camera, the default driver is OpenNI-PCL: <br><br><img src="https://habrastorage.org/web/f63/4be/ce6/f634bece693a44dd9deb69d0ba082727.png" alt="image"><br><br>  Let's start the map building procedure by clicking on the ‚ÄúStart‚Äù button: <br><br><img src="https://habrastorage.org/web/a69/aa2/463/a69aa246391c40dbb0f18f22659e5200.png" alt="image"><br><br>  rtabmap can also be used with rviz: <br><br><pre> <code class="bash hljs">roslaunch openni_launch openni.launch depth_registration:=<span class="hljs-literal"><span class="hljs-literal">true</span></span> roslaunch rtabmap_ros rtabmap.launch rtabmapviz:=<span class="hljs-literal"><span class="hljs-literal">false</span></span> rviz:=<span class="hljs-literal"><span class="hljs-literal">false</span></span> rtabmap_args:=<span class="hljs-string"><span class="hljs-string">"--delete_db_on_start"</span></span></code> </pre><br>  The rviz window opens: <br><br><img src="https://habrastorage.org/web/a59/2c6/773/a592c67732fe4d1080d3fe618d66e837.png" alt="image"><br><br>  Add an Odometry display and select the ‚Äú/ rtabmap / odom‚Äù topic.  After some camera movement in space, we get a similar picture in rviz: <br><br><img src="https://habrastorage.org/web/ca2/be3/a4c/ca2be3a4c66e49d0b5eb32c6fe265122.png" alt="image"><br><br>  After we complete the room with the camera, we get: <br><br><img src="https://habrastorage.org/web/d5c/9b2/5e6/d5c9b25e65594d618231204aecbba112.png" alt="image"><br><br>  If we move around the room slowly, smoothly moving the camera without sudden movements, then we can get a fairly accurate map: <br><br><img src="https://habrastorage.org/web/189/633/f5e/189633f5e362420cbae7d086df704237.png" alt="image"><br><br>  We can add an OccupancyGrid type Map display and select the ‚Äú/ rtabmap / proj_map‚Äù topic to visualize the flat map (as if we were using gmapping): <br><br><img src="https://habrastorage.org/web/b20/370/cf9/b20370cf94a14d46aadc115ccb51ec2d.png" alt="image"><br><br>  When you close the rviz window, the database and map are automatically saved to disk (the path is displayed in a string in the terminal). <br><br><h2>  Using rtabmap on Raspberry Pi 3 with ASUS Xtion Pro Live </h2><br>  Run rtabmap: <br><br><pre> <code class="bash hljs">rtabmap</code> </pre><br>  The window already familiar to us will open.  Create a database: File -&gt; New database: <br><br><img src="https://habrastorage.org/web/a41/eec/af6/a41eecaf6c7e4f08b8509af945b9583a.png" alt="image"><br><br>  Select the OpenNI2 driver for the Xtion Pro Live camera: <br><br><img src="https://habrastorage.org/web/71b/a66/1b9/71ba661b922c45d09761c901e7d06048.png" alt="image"><br><br>  Start the procedure of building a map with the Start button: <br><br><img src="https://habrastorage.org/web/a69/aa2/463/a69aa246391c40dbb0f18f22659e5200.png" alt="image"><br><br>  We get: <br><br><img src="https://habrastorage.org/web/7b9/ae2/eee/7b9ae2eeeb0d44c1a3585695e86e3e47.png" alt="image"><br><br>  After some time in the process of moving with the camera: <br><br><img src="https://habrastorage.org/web/d0d/2a8/6de/d0d2a86de6cf4b7db1b2b27da894231b.png" alt="image"><br><br>  On Raspberry Pi, the rtabmap process turned out to be quite resource-intensive (I used 250 - 300% CPU).  Sometimes the window darkened, once rtabmap fell with a Segmentation fault error. <br><br>  When using the default settings, rtabmap works extremely slowly on the Raspberry Pi, the frame rate is very low.  To work effectively, you need to adjust the input frame rate.  To do this, open Window ‚Üí Preferences ‚Üí General settings (GUI) in the top menu and press the ‚ÄúLoad settings ...‚Äù button.  Set the value of 30 Hz for ‚Äúinput rate‚Äù: <br><br><img src="https://habrastorage.org/web/bb8/eab/6c5/bb8eab6c5d784b778d60d542acf63f72.png" alt="image"><br><br>  About setting parameters in rtabmap you can read more <a href="https://github.com/introlab/rtabmap/wiki/Change-parameters">here</a> . <br><br>  Now the process of building a map is much faster: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/6ZwulbTr8as" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  The video shows how odometry data is lost once (there is a red background around the found Loop closure detection candidate) and I reset the odometry via Detection -&gt; Reset odometry.  Loss of odometry is often associated with an insufficient number of features found (for example, poorly textured surfaces) and too fast camera movement.  Our map is completely cleared and everything starts anew. <br><br><img src="https://habrastorage.org/web/9cd/fc2/757/9cdfc2757bbf4a4c8d03630075ca2414.png" alt="image"><br><br>  The map is almost ready: <br><br><img src="https://habrastorage.org/web/19d/ddf/18b/19dddf18b31446f98704a13e55b6f37e.png" alt="image"><br><br>  Our task here is to obtain a <a href="https://github.com/introlab/rtabmap/wiki/Kinect-mapping">successful</a> loop closure detection.  In case of successful detection of cycles, the candidate is highlighted with a green background. <br><br>  You can also show the result of loop detection in the ‚Äú3D loop closure‚Äù panel.  To do this, in the top menu, select: Window ‚Üí Show view ‚Üí 3D Loop closure.  Using the buttons with numbers from 1 to 5, we can change the format of the representation of point clouds (arbitrary colors, color gradient along the axes (axis oriented colors) or RGB): <br><br><img src="https://habrastorage.org/web/b41/257/52d/b4125752d6544d73b0f9aeea31e0c378.png" alt="image"><br><br>  We can press the Pause button to pause and click the Stop button to complete the process.  We can also exit the program and save our progress in the database.  When closing, the program will show a pop-up window with a suggestion to save the changes.  In the future, we can resume the process by running the program and selecting an existing database. <br><br><img src="https://habrastorage.org/web/c46/aac/0a7/c46aac0a75d8473d892158a4e0ce74e6.png" alt="image"><br><br>  We will be offered to download the map for the database. <br><br><img src="https://habrastorage.org/web/358/ef6/f79/358ef6f7976a4a0ab9a05a7c90e903f7.png" alt="image"><br><br>  I got this card (I rented part of the room): <br><br><img src="https://habrastorage.org/web/689/094/073/6890940736764603baa00d4d1334be4f.png" alt="image"><br><br>  In the rtabmap settings (in the top menu Window ‚Üí Preferences), you can select the odometry calculation algorithm (used descriptor of visual features).  To do this, in the settings, select: RTAB-Map Settings ‚Üí Memory ‚Üí Vocabulary near the Feature selection item and select an algorithm from the Visual word type drop-down list: <br><br><img src="https://habrastorage.org/web/a9b/c8d/4bc/a9bc8d4bc9ec460ca1baa3eaa7aa9e8b.png" alt="image"><br><br>  In my experiments, odometry with the GFTT + BRIEF visual dictionary works best, BRISK showed the worst result (it was not possible to get loop detection at all).  When using GFTT + BRIEF, the cycle detection was obtained immediately after a complete rotation with the camera around the room.  The ORB algorithm is used by default and gives not very good results. <br><br>  rtabmap supports a fairly wide range of cameras (RGB-D cameras, Intel RealSense, ASUS Xtion, Kinect v1 and v2, as well as stereo cameras Bumblebee2 and ZED camera) and several possible scenarios for building a map using various camera, lidar and IMU sensor combinations (tutorials can be see <a href="http://wiki.ros.org/rtabmap_ros/Tutorials/SetupOnYourRobot">here</a> ). <br><br><h2>  RGBDSLAM </h2><br><h3>  Installing RGBDSLAMv2 </h3><br>  You can read about RGBDSLAM in detail on the <a href="http://wiki.ros.org/rgbdslam/">official ROS page</a> and on <a href="https://github.com/felixendres/rgbdslam_v2">the github page</a> . <br><br>  Install RGBDSLAM from source: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws/src git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/felixendres/rgbdslam_v2.git</code> </pre><br>  Install the libg2o library: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-&lt;ros_version&gt;-libg2o</code> </pre><br>  where ros_version is the ROS version (hydro, indigo or kinetic). <br>  Compile RGBDSLAM in the catkin working directory: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws catkin_make <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> devel/setup.bash rosdep install rgbdslam</code> </pre><br>  I was not able to install RGBDSLAM on the Raspberry Pi due to a problem with Qt, so here I consider the operation of the algorithm only on ROS Indigo with the Microsoft Kinect camera. <br><br><h3>  Using RGBDSLAMv2 </h3><br>  Run rosmaster: <br><br><pre> <code class="bash hljs">roscore</code> </pre><br>  RGBDSLAMv2 can be run in two ways.  First, using the launch file: <br><br><pre> <code class="bash hljs">roslaunch rgbdslam openni+rgbdslam.launch</code> </pre><br>  Alternatively, openni_launch and the RGBDSLAMv2 node: <br><br><pre> <code class="bash hljs">roslaunch openni_launch openni.launch roslaunch rgbdslam rgbdslam.launch</code> </pre><br>  We will see a similar screen: <br><br><img src="https://habrastorage.org/web/0fa/472/4f8/0fa4724f8a29408d8389a9fe7ad656a7.png" alt="image"><br><br>  The construction of the map will begin immediately after the launch of the program.  RGBDSLAM is quite resource-intensive, my top command showed 155% of the processor load for the rgbdslam process. <br><br>  When the construction of the map is completed, it is necessary to stop processing the stream from the camera by unchecking the Processing checkbox in the Processing menu: <br><br><img src="https://habrastorage.org/web/540/4db/100/5404db100a074bb3b776f80b8ed9d0be.png" alt="image"><br><br>  Map construction completed: <br><br><img src="https://habrastorage.org/web/79c/6a0/57d/79c6a057d4274d5d8a6109d75fd909f9.png" alt="image"><br><br>  We can save the map.  You can also reset the current progress in the map building procedure by selecting Reset from the Processing menu: <br><br><img src="https://habrastorage.org/web/69e/07f/f13/69e07ff13b614f8f845603a0d9228d60.png" alt="image"><br><br>  Detailed instructions for using RGBDSLAM can be found on the <a href="http://felixendres.github.io/rgbdslam_v2/">official page</a> . <br><br>  Experiments have shown that these SLAM algorithms are quite suitable for use in ROS-based robotic projects with Microsoft Kinect RGBD cameras and result in a good map of the area.  Unfortunately, not all methods work on ARM platforms (at least on the Raspberry Pi).  The advantage of the rtabmap tool is the ability to flexibly adjust various parameters at will. <br><br>  Thus, we considered the two most well-known SLAM algorithms for RGBD cameras, which have their own implementation in ROS.  Those interested can get acquainted with the various scenarios of using these algorithms on the official pages (unfortunately, only in English) and apply them in their projects.  I wish everyone good luck in the experiments and will be happy to answer any of your questions in the comments.  See you again! </div><p>Source: <a href="https://habr.com/ru/post/373707/">https://habr.com/ru/post/373707/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../373695/index.html">Startup Ionic Materials invented a new polymer battery</a></li>
<li><a href="../373697/index.html">Money WannaCry brought in untraceable Monero cryptocurrency</a></li>
<li><a href="../373701/index.html">What is space?</a></li>
<li><a href="../373703/index.html">4 applications that help me save on basic expenses</a></li>
<li><a href="../373705/index.html">Not Roskomnadzor uniform</a></li>
<li><a href="../373709/index.html">Computer games affect the amount of gray matter in the hippocampus</a></li>
<li><a href="../373711/index.html">DataArt launched a gaming knowledge self-test platform for IT specialists</a></li>
<li><a href="../373713/index.html">Facebook secretly released an application in China through a front company</a></li>
<li><a href="../373715/index.html">Auto-refrigerators, or How to keep food away. Personal experience and tests for yourself</a></li>
<li><a href="../373717/index.html">Ask Ethan: Does the data on the 234th sun-like stars indicate the presence of extraterrestrial life?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>