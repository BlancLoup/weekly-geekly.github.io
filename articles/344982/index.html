<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Lectures of the Technosphere. Neural networks in machine learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We present to your attention the next portion of Tekhnosfera lectures. The course studies the use of neural network algorithms in various industries, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Lectures of the Technosphere. Neural networks in machine learning</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/qa/u6/24/qau624dsrmkmrtrkn0bnapuap5q.png"></p><br><p>  We present to your attention the next portion of Tekhnosfera lectures.  The course studies the use of neural network algorithms in various industries, as well as practicing all the studied methods on practical problems.  You will get acquainted with both classical and recently proposed, but already proven neural network algorithms.  Since the course is practice-oriented, you will gain experience in the implementation of image classifiers, style transfer systems and image generation using GAN.  You will learn how to implement neural networks both from scratch and based on the PyTorch library.  Learn how to make your chat bot, how to teach the neural network to play a computer game and generate human faces.  You will also gain experience reading scientific articles and independent research. </p><a name="habracut"></a><br><p>  List of lectures: </p><br><ol><li>  Fundamentals of neural networks. </li><li>  Details of learning neural networks. </li><li>  Libraries for deep learning. </li><li>  Convolutional neural networks. </li><li>  Improving the convergence of neural networks. </li><li>  Architecture deep networks. </li><li>  Optimization methods. </li><li>  Neural networks to reduce dimensions. </li><li>  Recurrent networks. </li><li>  Natural language processing. </li><li>  Competing network (GAN). </li><li>  Variational Encoders and Artistic Style. </li><li>  Training with reinforcements 1. </li><li>  Training with reinforcements 2. </li></ol><br><h2 id="lekciya-1-osnovy-neyronnyh-setey">  Lecture 1. Basics of Neural Networks </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Am82yvUSwRE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Neural networks.  The basic blocks of fully connected neural networks.  Error propagation algorithm. </p><br><h2 id="lekciya-2-podrobnosti-obucheniya-neyronnyh-setey">  Lecture 2. Details of learning neural networks </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AecF1N3e30o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Error propagation algorithm for branching structures.  Learning problems of neural networks.  Data pre-processing, augmentation, regularization.  Stochastic gradient descent.  Data preparation with PyTorch. </p><br><h2 id="lekciya-3-biblioteki-dlya-glubinnogo-obucheniya">  Lecture 3. Libraries for deep learning </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/6gcAZ-uHSQY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p> Calculation graphs in PyTorch.  Operations with tensors.  Automatic differentiation.  Fully connected networks.  Branching architecture.  Network behavior in teaching and prediction: <code>volatile</code> and <code>requires_grad</code> flags.  Save and load the model. </p><br><h2 id="lekciya-4-svyortochnye-neyronnye-seti">  Lecture 4. Convolutional neural networks </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/w8hO0Qp3PDg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Convolution.  Pulling  Light neural networks.  Examples of the use of convolutional networks.  Interpretation of the trained models. </p><br><h2 id="lekciya-5-uluchshenie-shodimosti-neyrosetey">  Lecture 5. Improving the convergence of neural networks </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/PjS2y8LBMLc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Scale initialization: He, Xavier.  Regularization: Dropout, DropConnect.  Normalization: batch normalization. </p><br><h2 id="lekciya-6-arhitektury-glubinnyh-setey">  Lecture 6. Depth networks architecture </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/jYdVCH26CUQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Modern architecture of convolution networks.  Network Inception and ResNet.  Transfer learning.  The use of neural networks for segmentation and localization. </p><br><h2 id="lekciya-7-metody-optimizacii">  Lecture 7. Optimization methods </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/USV-uNgUXz8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Optimization task.  SGD, Momentum, NAG, Adagrad, Adadelta, Adam. </p><br><h2 id="lekciya-8-neyronnye-seti-dlya-snizheniya-razmernostey">  Lecture 8. Neural networks to reduce dimensions </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/W5JLSKcuaQo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  The task of reducing the dimension.  MDS, Isomap.  Principal Component Method (PCA).  The derivation of the principal components and the proof of the Lagrange multipliers method.  Autocoders  Denoising and sparse autocoders. </p><br><h2 id="lekciya-9-rekurrentnye-seti">  Lecture 9. Recurrent Networks </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/MiXzBce-9zI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Recurrent networks.  Back propagation of error through time.  LSTM networks.  GRU network.  Multilayer recurrent architectures.  Modification of dropout and batch normalization for recurrent networks. </p><br><h2 id="lekciya-10-obrabotka-estestvennogo-yazyka">  Lecture 10. Natural language processing </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Wq414SDmOCM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Examples of tasks.  Training views: Word2Vec.  Acceleration of linear + softmax pair: hierarchical softmax, differentiated softmax.  Generate offers.  Model Seq2Seq.  Beam search for finding the best answer.  Techniques for increasing the diversity of responses. </p><br><h2 id="lekciya-11-sopernichayuschie-seti-gan">  Lecture 11. Competitive Networks (GAN) </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/hPux6TVtM58" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Generative and discriminative models.  Nash equilibrium.  Generative competing networks (GAN).  Generative autocoders (AAE).  Domain adaptation technique.  Domain adaptation for transferring images between domains.  Wasserstein gan. </p><br><h2 id="lekciya-12-variacionnye-kodirovschiki-i-artistic-style">  Lecture 12. Variational Encoders and Artistic Style </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UhKFE0s8uFU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Model variational auto encoder (VAE).  Interpretation of the trained models: Deep Dream.  Transferring style: Artistic style.  Accelerate styling. </p><br><h2 id="lekciya-13-obuchenie-s-podkrepleniem-1">  Lecture 13. Training with reinforcements 1 </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3EEdQP8QvTo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  The basic concepts of reinforcement learning: agent, environment, strategy, reward.  Value function and Q-function.  Bellman equations.  Algorithm Policy iteration. </p><br><h2 id="lekciya-14-obuchenie-s-podkrepleniem-2">  Lecture 14. Training with reinforcements 2 </h2><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Q5TCPPi-MWA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Q-learning algorithm.  Model approaches.  DQN algorithm.  Alpha Go. </p><br><p>  Playlist of all lectures is on the <a href="https://www.youtube.com/playlist%3Flist%3DPLrCZzMib1e9oOGNLh6_d65HyfdqlJwTQP">link</a> .  Recall that current lectures and master classes on programming from our IT specialists in Technopark, Technosphere and Tehnotrek projects are still published on Tekhnostrim channel. </p><br><p>  Other courses of Technosphere on Habr√©: </p><br><ul><li>  <a href="https://habrahabr.ru/company/mailru/blog/329072/">Lectures of the Technosphere.</a>  <a href="https://habrahabr.ru/company/mailru/blog/329072/">Infopoisk.</a>  <a href="https://habrahabr.ru/company/mailru/blog/329072/">Part 1 (Spring 2017)</a> </li><li>  <a href="https://habrahabr.ru/company/mailru/blog/329352/">Lectures of the Technosphere.</a>  <a href="https://habrahabr.ru/company/mailru/blog/329352/">Infopoisk.</a>  <a href="https://habrahabr.ru/company/mailru/blog/329352/">Part 2 (Spring 2017)</a> </li><li>  <a href="https://habrahabr.ru/company/mailru/blog/327966/">Lectures of the Technosphere: Programming on Go (Spring 2017)</a> </li></ul><br><p>  Information on all our educational projects can be found in a <a href="https://habrahabr.ru/company/mailru/blog/328912/">recent article</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/344982/">https://habr.com/ru/post/344982/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../344968/index.html">Translation - Maximum Usage APK Analyzer</a></li>
<li><a href="../344970/index.html">ChatScript Intelligent Chatbots: Development Practice and JavaScript Integration</a></li>
<li><a href="../344972/index.html">Found the largest database of stolen passwords: what you should know</a></li>
<li><a href="../344974/index.html">Solving the problem of class name CSS conflicts in a React application using a webpack loader</a></li>
<li><a href="../344980/index.html">Simplify user action log</a></li>
<li><a href="../344984/index.html">Automated correction of indentation in layout based on typographic styles and text metrics</a></li>
<li><a href="../344986/index.html">Dependency injection in .Net Mark Siman 3 - Cross-cutting aspects of the application, interception, decorator</a></li>
<li><a href="../344988/index.html">Seriously, games?</a></li>
<li><a href="../344990/index.html">Avito Product Analytics Meetup - video, photo, slides</a></li>
<li><a href="../344992/index.html">Stack: analyze parameter values</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>