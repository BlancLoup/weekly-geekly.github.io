<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A little introduction to parallel programming on R</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Let's talk about the use and benefits of parallel computing in R. 

 The reason why it is worth thinking about it: forcing the computer to work more (...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A little introduction to parallel programming on R</h1><div class="post__text post__text-html js-mediator-article">  Let's talk about the use and benefits of parallel computing in R. <br><br>  The reason why it is worth thinking about it: forcing the computer to work more (perform many calculations at the same time), we wait less time for the results of our experiments and can do more.  This is especially important for data analysis (R as a platform is usually used for this purpose), since it is often necessary to repeat variations of the same approach in order to find out something, to derive the values ‚Äã‚Äãof parameters, to assess the stability of the model. <br><br>  Usually, in order to make the computer work more, you first need to work for the analyst himself, the programmer or the creator of the library, in order to organize the calculations in a form convenient for parallelization.  At best, someone has already done it for you: <br><ul><li>  Good parallel libraries, such as multi-threaded BLAS / LAPACK, are included in the Revolution R Open (RRO, now <a href="https://mran.revolutionanalytics.com/open/">Microsoft R Open</a> ) (see <a href="https://mran.revolutionanalytics.com/documents/rro/multithread/">here</a> ). </li><li>  Specialized parallel extensions that provide their own high-performance implementations of important procedures, for example, <a href="http://www.revolutionanalytics.com/sites/default/files/data-step-white-paper.pdf">rx methods from RevoScaleR</a> or <a href="http://www.h2o.ai/">h2o methods from h2o.ai.</a> </li><li>  Abstract parallelization frameworks, for example, <a href="http://heather.cs.ucdavis.edu/~matloff/rth.html">Thrust / Rth</a> . </li><li>  The use of R application libraries related to parallelization (in particular, <a href="https://cran.r-project.org/package%3Dgbm">gbm</a> , <a href="https://cran.r-project.org/web/packages/boot/boot.pdf">boot,</a> and <a href="https://cran.r-project.org/package%3Dvtreat">vtreat</a> ).  (Some of these libraries do not use parallel operations until an environment for parallel execution is specified.) </li></ul><a name="habracut"></a><br>  In addition to the task prepared for parallelization, you need equipment that will support it.  For example: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  Your own computer.  Usually even laptops have four or more cores.  The potential advantage of the algorithm is four times faster - huge. </li><li>  Graphic processors (GPU).  Many maschiny have one or more powerful graphics cards.  For some computational tasks, these processors are 10-100 times faster than the central processing unit (CPU) commonly used for computing ( <a href="http://blogs.nvidia.com/blog/2010/06/23/gpus-are-only-up-to-14-times-faster-than-cpus-says-intel/">details</a> ). </li><li>  Computer clusters (for example, Amazon ec2, <a href="https://github.com/RevolutionAnalytics/RHadoop">Hadoop server</a> , etc.). </li></ul><br>  Obviously, <a href="https://cran.r-project.org/web/views/HighPerformanceComputing.html">parallel computing in R</a> is a vast and highly specialized topic.  It may seem impossible to quickly learn this magic ‚Äî how to make your calculations faster. <br><br>  In this article, we will show how you can speed up your calculations using the basic capabilities of R. <br><br>  For starters, there must be a task that can be parallelized.  The most obvious tasks of this kind contain repetitive actions (the intuitive term is ‚Äúnaturally parallel‚Äù): <br><br><ul><li>  Fitting model parameters by reapplying models (as is done in the <a href="http://topepo.github.io/caret/index.html">caret</a> package). </li><li>  Apply the transformation to a large number of different variables (as is done in the <a href="https://cran.r-project.org/package%3Dvtreat">vtreat</a> package). </li><li>  <a href="http://www.win-vector.com/blog/2015/09/isyourmodelgoingtowork/">Evaluation of the quality of the model</a> through cross-validation, bootstrap or other sampling techniques with repetitions. </li></ul><br>  We will assume that we already have a problem with a large number of simple repetitions.  Please note: this concept is not always easily achievable, but such a step is necessary so that the process can begin. <br><br>  Here is the task that we will use as an example: applying a predictive model for a small data set.  Load the dataset and some definitions into the workspace: <br><br><pre><code class="python hljs">d &lt;- iris <span class="hljs-comment"><span class="hljs-comment">#  "d"       R   vars &lt;- c('Sepal.Length','Sepal.Width','Petal.Length') yName &lt;- 'Species' yLevels &lt;- sort(unique(as.character(d[[yName]]))) print(yLevels)</span></span></code> </pre> <br><pre> <code class="diff hljs">## [1] "setosa" "versicolor" "virginica"</code> </pre><br>  (We will use the convention that any line starting with " <i>##</i> " is the output of the result of the previous R. command.) <br><br>  We are faced with a small modeling problem: the variable we are trying to predict has three levels.  The simulation technique we were going to use ( <code>glm(family='binomial')</code> ) does not know how to predict " <a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">polynomial results</a> " (although there are libraries designed for this).  We decided to approach this task using the <a href="https://en.wikipedia.org/wiki/Multiclass_classification">one-against-the-other</a> strategy and build a set of classifiers: each will separate one target variable from the others.  This task is an obvious candidate for parallelization.  Let's turn the function of building one output model to readability: <br><br><pre> <code class="python hljs">fitOneTargetModel &lt;- function(yName,yLevel,vars,data) { formula &lt;- paste(<span class="hljs-string"><span class="hljs-string">'('</span></span>,yName,<span class="hljs-string"><span class="hljs-string">'=="'</span></span>,yLevel,<span class="hljs-string"><span class="hljs-string">'") ~ '</span></span>, paste(vars,collapse=<span class="hljs-string"><span class="hljs-string">' + '</span></span>),sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) glm(<span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.formula(formula),family=binomial,data=data) }</code> </pre><br>  Then the usual "serial" way to build all the models will look like this: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(yLevel <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> yLevels) { print(<span class="hljs-string"><span class="hljs-string">"*****"</span></span>) print(yLevel) print(fitOneTargetModel(yName,yLevel,vars,d)) }</code> </pre><br>  Or you can wrap our procedure in a single-variable function (this pattern is called <a href="https://en.wikipedia.org/wiki/Currying">curring</a> ) and apply the elegant R- <code>lapply()</code> notation: <br><br><pre> <code class="python hljs">worker &lt;- function(yLevel) { fitOneTargetModel(yName,yLevel,vars,d) } models &lt;- lapply(yLevels,worker) names(models) &lt;- yLevels print(models)</code> </pre><br>  The advantage of the <code>lapply()</code> notation is that it emphasizes the independence of each computation, the kind of isolation that is needed to parallelize our computations.  Think of a for loop in the sense that it defines the calculation too accurately, setting an unnecessary order or sequence of operations. <br><br>  The reorganization of the calculation functionally prepared us for the application of the parallel library and the implementation of the calculation in parallel.  First, we deploy a parallel cluster: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    parallelCluster &lt;- parallel::makeCluster(parallel::detectCores()) print(parallelCluster)</span></span></code> </pre><br><pre> <code class="diff hljs">## socket cluster with 4 nodes on host 'localhost'</code> </pre><br>  Please note we have created a "cluster of sockets".  A socket cluster is a surprisingly flexible ‚Äúparallel-distributed‚Äù cluster in the first approximation.  A cluster of sockets is a rough approximation in the sense that it works relatively slowly (the work will be distributed "inaccurately"), but it is very flexible in implementation: many cores on one machine, many cores on several machines on the same network, on top of other systems, for example MPI cluster (message passing interface - message transfer protocol). <br><br>  At this point we assume that the code below will work ( <a href="http://www.win-vector.com/blog/2012/10/error-handling-in-r/">here</a> - details on <code>tryCatch</code> ). <br><br><pre> <code class="python hljs">tryCatch( models &lt;- parallel::parLapply(parallelCluster, yLevels,worker), error = function(e) print(e) )</code> </pre><br><pre> <code class="diff hljs">## &lt;simpleError in checkForRemoteErrors(val): ## 3 nodes produced errors; first error: ## could not find function "fitOneTargetModel"&gt;</code> </pre><br>  Instead of the results, we got the error " <code>could not find function "fitOneTargetModel"&gt;.</code> " <br><br>  Problem: in the cluster of sockets, the arguments <code>parallel::parLapply</code> copied to each processing node via a communication socket.  However, the integrity of the current <a href="http://adv-r.had.co.nz/Environments.html">environment</a> (in our case, the so-called ‚Äúglobal environment‚Äù) is not copied (only values ‚Äã‚Äãare returned).  Therefore, our <code>worker()</code> function, when migrating to parallel nodes, must have another <a href="http://adv-r.had.co.nz/Functions.html">closure</a> (since it cannot point to our execution environment), and it turns out that the new closure no longer contains references to the necessary values ‚Äã‚Äãof <code>yName</code> , <code>vars</code> , <code>d</code> and <code>fitOneTargetModel</code> .  This is sad, but it makes sense.  R uses all environments to implement the concept of closures, and R cannot know which values ‚Äã‚Äãin a given environment will actually require this function. <br><br>  So we know what is wrong.  How to fix it?  We will fix this by using an environment other than global to transfer the values ‚Äã‚Äãwe need there.  The easiest way to do this is to use your own closure.  To achieve this, we wrap the whole process into a function (and we will run it in a controlled environment).  The code below works: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    ,     mkWorker &lt;- function(yName,vars,d) { # ,      #     force(yName) force(vars) force(d) #   ,    #  worker    fitOneTargetModel &lt;- function(yName,yLevel,vars,data) { formula &lt;- paste('(',yName,'=="',yLevel,'") ~ ', paste(vars,collapse=' + '),sep='') glm(as.formula(formula),family=binomial,data=data) } # :      worker. # ""  worker # (    ) - #  / mkWorker, #    ,  . #    #   (    #   ). worker &lt;- function(yLevel) { fitOneTargetModel(yName,yLevel,vars,d) } return(worker) } models &lt;- parallel::parLapply(parallelCluster,yLevels, mkWorker(yName,vars,d)) names(models) &lt;- yLevels print(models)</span></span></code> </pre><br>  The code above works because we moved the values ‚Äã‚Äãwe needed to a new execution environment and defined the function we were going to use directly in that environment.  Obviously, redefining each function when we need it is cumbersome and expensive (although we could pass it into a wrapper, as was done with other values).  A more flexible pattern is this: use the auxiliary function " <code>bindToEnv</code> " to do some of the work.  With <code>bindToEnv</code> code looks like this. <br><br><pre> <code class="python hljs">source(<span class="hljs-string"><span class="hljs-string">'bindToEnv.R'</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  : http://winvector.github.io/Parallel/bindToEnv.R #    ,     mkWorker &lt;- function() { bindToEnv(objNames=c('yName','vars','d','fitOneTargetModel')) function(yLevel) { fitOneTargetModel(yName,yLevel,vars,d) } } models &lt;- parallel::parLapply(parallelCluster,yLevels, mkWorker()) names(models) &lt;- yLevels print(models)</span></span></code> </pre><br>  The pattern above is laconic and works well.  A few reservations to keep in mind: <br><br><ul><li>  Remember, every parallel worker is a remote environment.  Make sure the necessary libraries are defined on each remote machine. </li><li>  Non-core libraries loaded into the source environment are not necessarily loaded into the remote ones.  It makes sense to use notation with packages, for example, <code>stats::glm()</code> when calling functions from libraries (calling <code>library(...)</code> on each remote node is redundant). </li><li>  Our <code>bindToEnv</code> function itself changes the environment of the functions passed to it (so that they can refer to the values ‚Äã‚Äãthat we transfer).  This may cause additional problems with those environments to which the currying was applied.  <a href="http://winvector.github.io/Parallel/PExample.html">Here</a> are some ways to get around this problem. </li></ul><br>  This is worth thinking about.  However, I think you decide that adding eight lines of wrapping / stereotypical code is fully worth four or more accelerations. <br><br>  Also: upon completion of work, do not forget to remove the link to the cluster: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    if(!is.null(parallelCluster)) { parallel::stopCluster(parallelCluster) parallelCluster &lt;- c() }</span></span></code> </pre><br>  On it we will finish.  The next article will discuss how to build clusters of sockets on multiple machines and on Amazon ec2. <br><br>  The <code>bindToEnv</code> function itself is fairly simple: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#'           bindTargetEnv. #' #' http://winvector.github.io/Parallel/PExample.html -  . #' #' #'         ,    #' (    ).    #' ,  -worker     #' (    ,    ). #' #' @param bindTargetEnv - ,     #' @param objNames -  ,         #' @param doNotRebind -  ,      bindToEnv &lt;- function(bindTargetEnv=parent.frame(),objNames,doNotRebind=c()) { #     #        for(var in objNames) { val &lt;- get(var,envir=parent.frame()) if(is.function(val) &amp;&amp; (!(var %in% doNotRebind))) { #         () environment(val) &lt;- bindTargetEnv } #     ,     assign(var,val,envir=bindTargetEnv) } }</span></span></code> </pre><br>  It can also be downloaded <a href="">from here</a> . <br><br>  One of the drawbacks of using parallelization in this way is that you may always need another function or a given one.  One way around this is to use the R <code>ls()</code> to build a list of names that need to be passed.  It is especially efficient to save the results of <code>ls()</code> immediately after source files with functions and important global variables.  Without any strategy, adding items to lists is a pain. <br><br>  For large scale: not very detailed instructions for running multiple machine-R-servers on ec2 can be found <a href="https://github.com/JohnMount/ec2R">here</a> . </div><p>Source: <a href="https://habr.com/ru/post/307708/">https://habr.com/ru/post/307708/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../307698/index.html">In the wake of "spammer" or Oracle DB + UTL_SMTP + SSL / TLS</a></li>
<li><a href="../307700/index.html">The digest of interesting materials for the mobile # 166 developer (on August 8-14)</a></li>
<li><a href="../307702/index.html">How a variable may not equal its own value.</a></li>
<li><a href="../307704/index.html">New 3CX Client clients for Mac and iOS, and a tip for setting up a Gmail server for 3CX Phone System</a></li>
<li><a href="../307706/index.html">Puns typing functions in C</a></li>
<li><a href="../307710/index.html">The story ‚ÄúNIICHOSHI. Saday</a></li>
<li><a href="../307712/index.html">Passing infinity: do-it-yourself t-test</a></li>
<li><a href="../307714/index.html">Basics of computer networks. Subject number 2. Top level protocols</a></li>
<li><a href="../307718/index.html">PHP Digest number 90 - interesting news, materials and tools (August 1 - 14, 2016)</a></li>
<li><a href="../307720/index.html">Elixir: What does OOP look like in a functional language?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>