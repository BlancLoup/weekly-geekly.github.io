<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hallucinate like Trump, or mini-analysis of Recurrent Neural Networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I have been working on machine learning problems and deep architectures (neural networks) for a long time, and I had to do a mini-presentation of the ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hallucinate like Trump, or mini-analysis of Recurrent Neural Networks</h1><div class="post__text post__text-html js-mediator-article">  I have been working on machine learning problems and deep architectures (neural networks) for a long time, and I had to do a mini-presentation of the system that generates time series to emulate various processes.  Since it is better to talk on serious topics with humor, I decided to pick up some cheerful example so that the speech would be heard with smiles on their faces.  We are very lucky because we live at the same time as a great speaker, whose speeches make people's hearts beat faster.  I'm talking about Donald Trump.  Therefore, it would be quite natural to create a system that would <s>hallucinate</s> talk like Trump. <br><br><img src="https://habrastorage.org/files/1c4/463/7f0/1c44637f054d4b098f38395b629f19f5.jpg"><br><a name="habracut"></a><br><h4>  Recurrent Neural Networks </h4><br>  Recurrent Neural Networks are a type of artificial neural networks designed to recognize patterns in a data sequence, be it text, genome, handwriting, spoken words, or numeric sequences coming from sensors, the stock market, and government agencies.  The main difference of Recurrent Neural Networks (hereinafter TIN) from other architectures is the so-called memory availability.  TIN stores the previous values ‚Äã‚Äãin its state.  It can be said that TRN builds dynamic models, i.e.  models that change over time in such a way that they provide an opportunity to achieve sufficient accuracy, depending on the context of the examples that were provided. <br><br>  <a href="https://deeplearning4j.org/recurrentnetwork">A good tutorial about these architectures.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I would also like to recommend the excellent post of Andrei Karpatny, who is one of the leading researchers in Depth Education in the world, about the incredible effectiveness of the TRN. <br><br>  <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a> <br><br><h4>  Models and training </h4><br>  To build a model, I needed to find the corpus of Trump's speeches.  After a little search, I found Trump's speeches at the debates, plus a few interviews and statements on various topics.  I cleaned the files of dates, marks the behavior of the room (laughter, etc.), translated into lower case and merged everything into one file called <code>speeches.txt</code> <br><br>  The second important point is the choice of a framework for building models.  If desired, you can write a system from scratch, for example for Python there is a library CudaMat, to perform matrix calculations on graphics cards.  Since, in general, the passage through the Neural Network is a set of matrix multiplications using activation functions, various architectures can be implemented fairly quickly on the basis of CudaMat.  But I will not reinvent the wheel and take, as an example, two frameworks for Deep Learning systems. <br><br>  First, this is probably the most common and convenient framework for Torch based on Lua.  Lua is probably the fastest interpreted language, with a powerful native backend for graphics accelerators and a state-of-art JIT compiler.  <a href="https://www.quora.com/Why-is-Lua-so-fast">Why-is-Lua-so-fast</a> Lua is actively used in Deep Mind, just go to their <a href="http://github.com/deepmind">GitHub</a> . <br><br>  The second is DeepLearning4j - an open framework for building Neural Networks and distributed learning for the JVM of the world, actively supported by SkyMind.  The advantages of the framework include the ease of connecting visualizations, the presence of distributed learning (data-paralell), and a sense of comfort for Java developers.  In fact, my goal was to compare the speed of learning and the approaches of the two frameworks. <br><br>  I also want to note that the following was performed on my MacBook Pro laptop (2015), where there is no NVIDIA GPU, and therefore everything ran on the CPU, which limited me in choosing the size of the model and the time I could spend on preparing the presentation.  The difference between CPU and GPU is visible to the naked eye. <br><br>  GPU <br><iframe width="560" height="315" src="https://www.youtube.com/embed/VMs--7Tb5yU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  CPU <br><iframe width="560" height="315" src="https://www.youtube.com/embed/CT_j2gpp7mQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h4>  Torch-rnn </h4><br>  Let's start with the simplest and fastest.  You can install the system from here <a href="http://github.com/jcjohnson/torch-rnn">github.com/jcjohnson/torch-rnn</a> But if you put this system as it is on your car, the Mac owners will face the incompatibility problem of the new version of torch-hd5f with the other dependencies (and I think not only Macs, since DeepMind is this problem).  This problem is being overcome, and for this I am sending you <a href="http://www.asaduddin.com/2017/03/torch-rnn-macos-installation-guide-2017-average-joe-edition/">here</a> .  But the best and easiest way is to take the finished Docker image <a href="http://github.com/crisbal/docker-torch-rnn">from here</a> and launch the container. <br><br>  Throw the body of speeches in the folder torch / torch-rnn / data / under the name speeches.txt ( <a href="http://github.com/alextavgen/TrumpHallucinator/blob/master/trump-hallucinator/src/main/resources/speeches.txt">lies here</a> ). <br>  We start the container with the following command <br><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">docker</span></span> run -v /<span class="hljs-type"><span class="hljs-type">Users</span></span>/&lt;<span class="hljs-type"><span class="hljs-type">YOUR_USER_NAME</span></span>&gt;/torch/torch-rnn/<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class">:/</span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class"> </span><span class="hljs-comment"><span class="hljs-class"><span class="hljs-comment">--rm -ti crisbal/torch-rnn:base bash</span></span></span></span></code> </pre> <br>  The -v flag and the path after it mean that I want to map the path from my local file system to the Docker container (to the root system / data /), because during the training the model records intermediate results, I do not want to lose them after the container is destroyed.  Yes, and in subsequent launches, I can use the finished model, both to continue the training and to generate. <br><br>  The remaining commands are identical both for the container launch and for the launch in the native system. <br><br>  To begin with, it is necessary to do preliminary data processing.  Transfer to speech format with hd5f format.  File paths are written for the container version, change them to your directory. <br><br><pre> <code class="hljs kotlin"> python scripts/preprocess.py --input_txt /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/speeches.txt --output_h5 /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/speeches.h5 --output_json /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/speeches.json</code> </pre> <br>  We start training <br><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">th</span></span> train.lua -batch_size <span class="hljs-number"><span class="hljs-number">3</span></span> -seq_length <span class="hljs-number"><span class="hljs-number">50</span></span> -gpu <span class="hljs-number"><span class="hljs-number">-1</span></span> -input_h5 /<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class">/speeches.h5 -input_json /</span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class">/speeches.json</span></span></code> </pre> <br>  if you run on a system with a GPU, then the -gpu -0 flag, it is by default.  Since I do not have an accelerator, I indicated a limit on the size of the sequence to 50 characters.  The number of settings is quite large.  I chose the size of the PHN 128 layer, 2 layers, because otherwise my training could drag on very, very long.  I left the number of epochs and other parameters by default, since I needed some starting point. <br><br>  In the course of training, the model from time to time is discarded on the disk, and in the future you can continue training with these checkpoints.  The documentation describes this in detail.  Also, if you wish, you can display model samples in the course of training, that is, see how much the model is progressing in studying the structure of the Donald language.  I will show how the model is being trained using the example of DeepLearning4j. <br><br>  After a few hours, the training ends and a new cv directory appears in the data directory, where the model is located at various stages of the training. <br><br><img src="https://habrastorage.org/files/2af/42b/bcc/2af42bbcc13d41e78037253a70bc4486.png"><br><br>  To sample the sequence from the model, enter <br><br><pre> <code class="hljs pgsql">th sample.lua -gpu <span class="hljs-number"><span class="hljs-number">-1</span></span> -sample <span class="hljs-number"><span class="hljs-number">1</span></span> -<span class="hljs-keyword"><span class="hljs-keyword">verbose</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> -temperature <span class="hljs-number"><span class="hljs-number">0.9</span></span> -<span class="hljs-keyword"><span class="hljs-keyword">checkpoint</span></span> /data/cv/checkpoint_74900.t7 -length <span class="hljs-number"><span class="hljs-number">2000</span></span></code> </pre> <br>  The checkpoint flag shows where to get the model, I installed the last entry.  Temperature is quite an important parameter of the SoftMax function, it shows how determined the sequence is.  Higher values ‚Äã‚Äãgive a noisier and stochastic output, low ones can repeat the input with minor changes.  Valid values ‚Äã‚Äãare from 0 to 1. However, all this is also documented <a href="">here</a> . <br><br>  I will show the results of the model below. <br><br><h4>  DeepLearning4j </h4><br>  The <a href="https://deeplearning4j.org/">DeepLearning4j</a> framework <a href="https://deeplearning4j.org/">is</a> not as popular and famous as torch, at the same time it has a number of advantages.  It is based on ND4J arrays, or as they are called NumPy for Java.  These are arrays that are not on the heap, and work with them goes through native calls.  Also, DeepLearning4j has an excellent type system and it is quite intuitively possible to implement all the major architectures, the only thing that does not go beyond the knowledge of theory. <br><br>  I posted the code <a href="http://github.com/alextavgen/TrumpHallucinator">here</a> .  The code is based on the GravesLSTM Character model, I used the design of Alex Black.  To display the process of training the model, I connected the visualization of data.  Parameters of the model tried to pick up similar to the torch model.  But the differences exist, and below we will see what is happening in the process. <br><br>  According to Andrei Karpatny, learning neural networks is more art than science.  Learning parameters play a crucial role.  There are no universal rules, but only recommendations and a sense of intuition.  Each parameter must be chosen for a specific set of problems.  Even the initial initialization of the scales plays a role in whether the model converges or not.  As an example, Andrey's tweet <a href="http://twitter.com/karpathy/status/853054007668989953">a 20 layer model.</a>  <a href="http://twitter.com/karpathy/status/853054007668989953">weight init N (0,0.02): stuck completely.</a>  <a href="http://twitter.com/karpathy/status/853054007668989953">try weight init N (0, 0.05): optimizes right away.</a>  <a href="http://twitter.com/karpathy/status/853054007668989953">initialization matters a lot: \</a> <br><br>  I started training with different parameters of learning rate.  And that's what came out. <br><br>  First launch with learning rate 0.1 and initialization XAVIER <br><br><img src="https://habrastorage.org/files/cb4/527/4e6/cb45274e64fb44ed88d42a27cadaa49a.jpg"><br><br>  It can be seen that somewhere from step 3000, the model was stuck and the loss function started oscillating around the same values.  One of the possible reasons was that with a large training parameter, the parameters skip the optimum, and an oscillation is obtained, the gradient jumps.  In principle, this is not surprising, since the learning parameter 0.1 is quite large, it is recommended to test it in the interval from 0.1 to 0.001, or even less.  I started with more. <br><br>  I started the system with the parameter 0.01 and here is the result. <br><br><img src="https://habrastorage.org/files/8a6/5a0/760/8a65a07609cc4cc3826327f6947cb65b.jpg"><br><br>  It can be seen that the gradient descent has slowed down considerably, and that even though the gradient is strictly decreasing, it requires a lot of steps and I stopped learning, since it consumed my laptop power. <br><br>  The third launch of the system with a training parameter of 0.05. <br><br><img src="https://habrastorage.org/files/304/d16/fcf/304d16fcf0324590ba8798069fb6110d.jpg"><br><br>  The results show that the gradient descended faster, but again stuck at the end and began to oscillate, which is not surprising, since the value of 0.05 is not much less than 0.1 <br><br>  The best option is to set the reduction of the learning parameters in the process.  A striking example of this is the architecture of LeNet.  The principle is that we start with large parameters and decrease as we descend.  Here is a launch with such a schedule. <br><br><img src="https://habrastorage.org/files/d52/7ac/b7b/d527acb7bb0b4073a4b4ffe7f63faac2.jpg"><br><br>  The lower graph shows how at step 4000, the size of the update decreases, and at the same time the loss function breaks through the barrier and a further descent begins.  I didn‚Äôt finish the workout, because I needed my laptop for work, and I did this analysis literally a couple of days in my spare time.  In addition, there are many learning parameters, such as regularization, moment, and others.  In case of serious work, it is necessary to carefully select these parameters, since minor changes may be decisive for whether the model will converge, or whether it will be stuck at a local minimum. <br><br><h4>  results </h4><br>  And now the funniest and most interesting.  How she studied and what gave us a model.  On the example of DeepLearning4j logs. <br><br>  Since at the very beginning the Recurrent Neural Network does not know anything about the language or the data structure, we begin to feed the body of speech to it.  Here is the conclusion after several mini-batches (we sample the model with a random crop). <br><br><pre> <code class="hljs dos">----- Sample <span class="hljs-number"><span class="hljs-number">1</span></span> ----- L<span class="hljs-built_in"><span class="hljs-built_in">fs</span></span> mint alo she g tor, torink.han, aulb bollg rurr Atans ir'd ciI anlot, ade dos rhant eot taoscare werang he ca m hltayeu.,hare they Woy theaplir horet iul pe neaf it Yf therg. hhat anoy souk, thau <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> y RO Bury f <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>. haveyhaled Dhorlsy Ato thinanse rank fourile DaniOn Ttovele yhinl ans anu he B</code> </pre> <br>  It can be seen that the model already understands that words are separated by spaces.  Even some pronouns appear as he, they. <br><br><pre> <code class="hljs pgsql"><span class="hljs-comment"><span class="hljs-comment">----- Sample 2 ----- aly Eo, He, to bakk st I stire I'micgobbsh brond thet we sthe mikadionee bans. Whether job lyok,. Whon not I ouuk. Wewer they sas I dait ond we polntryoiggsiof, waoe have ithale. I bale bockuyte seemer I dant you I Fout whey We kuow Soush Wharay nestibigiof, You knik is you know, boxw staretho bad</span></span></code> </pre> <br>  It is evident that our Sharikov has already said his first abyrvalg.  The model correctly begins to capture the pronouns I, he, we, you.  Some simple words are also present, like bad, know. <br><br>  Go ahead. <br><br><pre> <code class="hljs vbscript">----- Sample <span class="hljs-number"><span class="hljs-number">3</span></span> ----- cy doing <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> whit stoll. Ho just <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> deed <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> was very minioned, <span class="hljs-built_in"><span class="hljs-built_in">now</span></span>, Fome <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a soild say <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> soudd <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">If</span></span> no want nonkouahvion. <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> you beeming thet take <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> our tough us iss could feor youlk <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> at Lend <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> we <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> toted <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> start <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> pasted <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> doind the we <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> it. I jind <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> I spongly stection Caread.</code> </pre> <br>  Already looks like English. <br><br>  Total after <br><br>  Completed 340 minibatches of size 32x1000 characters <br><br><pre> <code class="hljs pgsql"><span class="hljs-comment"><span class="hljs-comment">----- Sample 4 ----- Second. They left you asses, believe me, but I will have great people.I solling us some -- and you see something youve seen deterner to Mexico, we are building interest. 100,000. Im not going to be so bad. It was so proud of me. Incredible and or their cities which I kept the same wealthy. They dont want them, were the world companies. Yes, they get the fraud, except people deals 100. Its like never respaved us. Thats what were going to do an orfone thats seen this.</span></span></code> </pre> <br>  What a.  <b>Im not going to be so bad.</b>  <b>It was so proud of me.</b>  Familiar narcissistic intonation. <br><br>  And this?  <b>I will have great people.</b> <br>  Then, what we saw in Mexico and we are building, apparently wanted a wall, but there was interest. <br><br>  Note that the model began to issue such results very quickly, only after 340 mini-batches.  Since I did not bring the training to the end on DeepLearning4j, we will look at the results of the model using the example of Torch-RNN. <br><br><pre> <code class="hljs vbscript"> So we<span class="hljs-comment"><span class="hljs-comment">'re going to run. But I was going to have all the manufacturing things as you know what we're not going to be very soon to this country starting a president land the country. It's the committed to say the greatest state. You know, I like Iran is so badly. I said, "I'm not as you know what? Why aren't doing my sad by having any of the place so well, you look at 78%, I've done and they're coming in the Hispanics are so many. The different state and then I mean, it's not going to be these people that are politicians that they said, "You know, every poll said "We will bring it. I think we don't want to talk about the stupid new of this country. We love it of money. It's running the cary America great.</span></span></code> </pre> <br>  It can be seen as the network begins to hallucinate.  The size of the samples can be changed by specifying various parameters, there is also a difference in the indication of the temperature parameter.  Here is an example with a low temperature - 0.15. <br><br><pre> <code class="hljs pgsql"> I want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> take our country <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> they can be a great country <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> they want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> it. They want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> take a look at the world <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a lot <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> things are the worst thing that we have <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> it. We have <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> it. I mean, they want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> tell you that we will be the world <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a great country <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> they want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> be a great country <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> going <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> be a great people. I mean, I want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> be saying that we have <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> it. They don<span class="hljs-string"><span class="hljs-string">'t know what they don'</span></span>t want <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> say that we have <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> it.</code> </pre> <br><br>  It is seen that the network begins to speak.  Since Mr. Trump speaks rather simple language, the most likely state transitions in the network are reduced to simple constructions. <br><br>  The disadvantages of this model are visible to the naked eye. <br><br><ul><li>  The size of the data for the model is very small.  I did not aggregate all possible speeches and speeches, but collected what was convenient to quickly assemble.  For this kind of model, the size of the data plays the most important role, since neural networks are very data hungry. </li><li>  The size of the model is small (the number of layers), since I was limited in computing resources, and I had to do a small demonstration.  By increasing the model, you can get more interesting results. </li></ul><br>  This example is a little toy, and at the same time, it shows the main points in the training of Neural Networks.  If you have any questions, or this topic is of interest, then I can share information in the future.  My Twitter <a href="http://twitter.com/ATavgen">Feed</a> - <a href="http://twitter.com/ATavgen">@ATavgen</a> </div><p>Source: <a href="https://habr.com/ru/post/326966/">https://habr.com/ru/post/326966/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../326956/index.html">The uWSGI Spooler</a></li>
<li><a href="../326958/index.html">From weekly sysadmin: unpack NetApp FAS 9000</a></li>
<li><a href="../326960/index.html">Duck says ‚Äúquack-krya‚Äù, the cow says ‚Äúmu-mu‚Äù, ‚ÄúRunn Me!‚Äù - another PHP framework * tells us. Part 1</a></li>
<li><a href="../326962/index.html">Reactive applications with the RxPM pattern. Goodbye MVP and MVVM</a></li>
<li><a href="../326964/index.html">Mobile Device Manager Plus - long-awaited perfection or is it still not?</a></li>
<li><a href="../326968/index.html">Network Attacks with Kali Linux</a></li>
<li><a href="../326970/index.html">Domestic Linux distribution - ‚ÄúOS‚Äù for server and desktop systems: the new BolgenOS of the national scale?</a></li>
<li><a href="../326972/index.html">How to grow: 7 lessons, which gives the history of WeChat</a></li>
<li><a href="../326974/index.html">SAP Forum 2017: New Scenarios for the Future with the Internet of Things</a></li>
<li><a href="../326976/index.html">What we should build an application: the reasoning of the interface</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>