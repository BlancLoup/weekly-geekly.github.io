<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Lock-free data structures. Stack evolution</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In my previous notes, I described the basis on which the lock-free data structures are built, and the basic algorithms for controlling the lifetime of...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Lock-free data structures. Stack evolution</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/f8c/585/ccf/f8c585ccff8dc53d367cd6471284a350.jpg" align="right"><br>  In my <a href="http://habrahabr.ru/company/ifree/blog/216013/">previous</a> notes, I described the basis on which the lock-free data structures are built, and the basic algorithms for controlling the lifetime of the lock-free data structures.  It was a prelude to the description of the actual lock-free containers.  But then I ran into the problem: how to build a further story?  Just describe the algorithms I know?  It's pretty boring: a lot of [pseudo] code, an abundance of details that are important, of course, but very specific.  In the end, it is in the published works, to which I give references, and in a much more detailed and rigorous presentation.  I wanted to tell <i>interestingly</i> about interesting things, to show the development of approaches to the design of competitive containers. <br>  Well, - I thought, - then the method of presentation should be this: take some type of container - a queue, map, hash map, - and make an overview of the original algorithms for this type of container known today.  Where to begin?  And then I remembered the simplest data structure - the stack. <br><a name="habracut"></a><br>  It would seem, what can we say about the stack?  This is such a trivial data structure that there's nothing much to say. <br>  Indeed, the work on the implementation of the competitive stack is not so much.  But on the other hand, those that exist are more devoted to approaches than the actual stack.  That approaches me and interest. <br><br><h1>  Lock-free stack </h1><br>  The stack is probably the first data structure for which the lock-free algorithm was created.  It is believed that Treiber published it first in <a href="http://domino.research.ibm.com/library/cyberdig.nsf/0/58319a2ed2b1078985257003004617ef%3FOpenDocument">his</a> 1986 <a href="http://domino.research.ibm.com/library/cyberdig.nsf/0/58319a2ed2b1078985257003004617ef%3FOpenDocument">article</a> , although there is evidence that this algorithm was first described in the IBM / 360 system documentation. <br><div class="spoiler">  <b class="spoiler_title">Historical retreat</b> <div class="spoiler_text">  In general, the Treiber article is a kind of Old Testament, perhaps the first article on the lock-free data structure.  In any case, the earlier I do not know.  It is still very often mentioned in the reference lists of modern works, apparently, as a tribute to the ancestor of the lock-free approach. <br></div></div><br>  The algorithm is so simple that I will <a href="http://libcds.sourceforge.net/">provide</a> it with the adapted code from <a href="http://libcds.sourceforge.net/">libcds</a> (to whom it is interesting - this is the intrusive stack of <code>cds::intrusive::TreiberStack</code> ): <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// m_Top ‚Äì   bool push( value_type&amp; val ) { back_off bkoff; value_type * t = m_Top.load(std::memory_order_relaxed); while ( true ) { val.m_pNext.store( t, std::memory_order_relaxed ); if (m_Top.compare_exchange_weak(t, &amp;val, std::memory_order_release, std::memory_order_relaxed)) return true; bkoff(); } } value_type * pop() { back_off bkoff; typename gc::Guard guard; // Hazard pointer guard while ( true ) { value_type * t = guard.protect( m_Top ); if ( t == nullptr ) return nullptr ; // stack is empty value_type * pNext = t-&gt;m_pNext.load(std::memory_order_relaxed); if ( m_Top.compare_exchange_weak( t, pNext, std::memory_order_acquire, std::memory_order_relaxed )) return t; bkoff(); } }</span></span></code> </pre><br>  This algorithm is repeatedly parsed by the bones (for example, <a href="http://www.manning.com/williams/">here</a> ), so I will not repeat.  A brief description of the algorithm is reduced to the fact that we are using the atomic primitive CAS in <code>m_Top</code> until we get the desired result.  Simple and rather primitive. <br>  I note two interesting details: <br><ul><li>  Safe memory reclamation (SMR) is needed only in the <code>pop</code> method, since only there we read the <code>m_Top</code> fields.  In <code>push</code> no <code>m_Top</code> fields are readable (there is no appeal by the <code>m_Top</code> pointer), so nothing needs to be defended by the Hazard Pointer.  This is interesting because usually SMR is required in all methods of the container's lock-free class. </li><li>  The mysterious <code>bkoff</code> object and its <code>bkoff()</code> call if the CAS fails. </li></ul><br>  Here at this very <code>bkoff</code> I would like to dwell upon it. <br><br><h1>  Back-off strategy </h1><br><img src="https://habrastorage.org/getpro/habr/post_images/d63/e59/6ef/d63e596ef84a9bded93047a95ee926df.jpg" align="right"><br>  Why is CAS unsuccessful?  Obviously because between reading the current value of <code>m_Top</code> and trying to apply CAS, some other thread managed to change the value of <code>m_Top</code> .  That is, we have a typical example of competition.  In the case of a high load (high contention), when N threads perform <code>push</code> / <code>pop</code> , only one of them will win, the other N - 1 will waste CPU time and interfere with each other on the CAS (recall <a href="http://habrahabr.ru/company/ifree/blog/196548/">the MESI cache protocol</a> ). <br>  How to unload the processor when this situation is detected?  You can back off from the main task and do something useful or just wait.  This is exactly what the back-off strategies are for. <br>  Of course, in the general case ‚Äúwe cannot do something useful‚Äù because we have no idea about a specific task, so we can only wait.  How to wait?  The variant with <code>sleep()</code> discarded - few operating systems can provide us with such small wait timeouts, and the overhead of context switching is too great - more than the CAS execution time. <br>  In the academic environment, the <i>exponential</i> back-off strategy is popular.  The idea is very simple: <br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">exp_backoff</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> nInitial; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> nStep; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> nThreshold; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> nCurrent; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: exp_backoff( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> init=<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> step=<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> threshold=<span class="hljs-number"><span class="hljs-number">8000</span></span> ) : nInitial(init), nStep(step), nThreshold(threshold), nCurrent(init) {} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">operator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt; nCurrent; ++k ) nop(); nCurrent *= nStep; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( nCurrent &gt; nThreshold ) nCurrent = nThreshold; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">reset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ nCurrent = nInitial; } };</code> </pre><br>  That is, we execute <code>nop()</code> in a loop, each time increasing the cycle length.  Instead of <code>nop()</code> you can call something more useful, for example, to <s>calculate a bitcoin</s> hint instruction (if one exists) that tells the processor "you have time to do your internal affairs" (again, remember MESI - the processor does may be the sea). <br>  The problem with exponential back-off is simple - it is difficult to find good parameters <code>nInitial</code> , <code>nStep</code> , <code>nThreshold</code> .  These constants depend on the architecture and on the task.  In the above code, the default values ‚Äã‚Äãfor them are taken from the ceiling. <br>  Therefore, in practice, a fairly good choice for desktop processors and entry-level servers would be <code>yield()</code> back-off - switching to another thread.  Thus, we give our time to other, more successful streams, in the hope that they will do what they need and will not disturb us (and we - to them). <br>  Do u even use back-off strategies?  Experiments show that it‚Äôs <b>about</b> it: the right back-off strategy applied in the right bottleneck can give a performance benefit of the lock-free container at times. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The considered back-off strategies help to solve the problem with unsuccessful CAS, but in no way contribute to the implementation of the main task - stack operations.  Is it possible to somehow combine <code>push</code> / <code>pop</code> and back-off, so that the back-off strategy actively helps in performing the operation? <br><br><h1>  Elimination back-off </h1><br>  Consider the problem of unsuccessful CAS in <code>push</code> / <code>pop</code> on the other hand.  Why is CAS unsuccessful?  Because another thread has changed <code>m_Top</code> .  And what does this other thread do?  Performs <code>push()</code> or <code>pop()</code> .  Now note that the <code>push</code> and <code>pop</code> operations for the stack are complementary: if one thread performs <code>push()</code> and the other at the same time <code>pop()</code> , then in principle there is no point in <code>m_Top</code> to the top of the <code>m_Top</code> stack: the push stream could just transfer your data to a pop stream, while the main property of the stack - LIFO - is not violated.  It remains to figure out how to bring both these threads together, bypassing the top of the stack. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3bc/9f1/777/3bc9f1777d1a7c5cc104d496f63728a1.png" align="right"><br>  In 2004, Hendler, Shavit, and Yerushalmi <a href="http://www.cs.bgu.ac.il/~hendlerd/papers/scalable-stack.pdf">proposed a</a> modification of the Treiber algorithm, in which the task of transferring data between push and pop threads without the participation of the top of the stack is solved using a special back-off strategy that they called an <i>exclusion</i> back-off strategy (elimination back -off, I would translate as an <i>absorbing</i> back-off strategy). <br><br>  There is an elimination array of size N (N is a small number).  This array is a member of the stack class.  When CAS fails, going back-off, the thread creates a handle to its operation ( <code>push</code> or <code>pop</code> ) and randomly selects an arbitrary cell of this array.  If the cell is empty, it writes a pointer to it on its descriptor and performs the usual back-off, for example, exponential.  In this case, the stream can be called passive. <br>  If the selected cell already contains a pointer to the P handle of the operation of some other (passive) stream, then the stream (let's call it active) checks what kind of operation it is.  If the operations are complementary ‚Äî <code>push</code> and <code>pop</code> ‚Äî then they are mutually absorbed: <br><ul><li>  if the active thread performs <code>push</code> , then it writes its argument to the P descriptor, thus passing it to the <code>pop</code> operation of the passive stream; </li><li>  if the active thread performs <code>pop</code> , then it reads the argument of the complementary <code>push</code> operation from the P handle. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/a52/3a9/f9e/a523a9f9e344f45001e57a7d9d622694.png" align="right"><br>  Then, the active thread marks the entry in the elimination array cell as processed, so that the passive stream when exiting the back-off sees that someone has done his job magically.  As a result, the active and passive threads execute their operations <i>without referring to the top of the stack</i> . <br>  If, in the selected elimination array cell, the operation is the same (push-push or pop-pop situation), then there is no luck.  In this case, the active thread performs the usual back-off and then tries to perform its <code>push</code> / <code>pop</code> as usual, - CAS top of the stack. <br>  Passive stream, after finishing back-off, checks its descriptor in the elimination array.  If the descriptor has a mark that the operation is completed, that is, there is another thread with a complementary operation, then the passive stream successfully completes its <code>push</code> / <code>pop</code> . <br>  All the above actions are performed in a lock-free manner, without any locks, so the real algorithm is more complicated than the one described, but the meaning does not change. <br>  The handle contains the operation code ‚Äî <code>push</code> or <code>pop</code> , ‚Äîand the operation argument: in the case of <code>push</code> , a pointer to the element to be added, in the case of <code>pop</code> the pointer field remains empty ( <code>nullptr</code> ), if elimination succeeds, a pointer is written to the element of the <code>push</code> absorbing operation. <br>  Elimination back-off allows you to significantly unload the stack under high load, and at low, when the CAS top of the stack is almost always successful, this scheme does not introduce any overhead.  The algorithm requires fine tuning, which consists in choosing the optimal size of the elimination array, which depends on the task and the actual load.  You can also offer an adaptive version of the algorithm, when the size of the elimination array changes in small limits during operation, adapting to the load. <br>  In the case of imbalance, when the <code>push</code> and <code>pop</code> operations go in bursts - a lot of <code>push</code> without <code>pop</code> , then a lot of <code>pop</code> without <code>push</code> , the algorithm will not give any tangible gain, although there should not be any loss in performance compared to the classic Treiber algorithm . <br><br><h1>  Flat combining </h1><br>  So far we have been talking about the lock-free stack.  Consider now the usual lock-based stack: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">template</span></span> &lt;<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">T</span></span></span><span class="hljs-class">&gt; </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LockStack</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">stack</span></span>&lt;T *&gt; m_Stack; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::mutex m_Mutex; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">push</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( T&amp; v )</span></span></span><span class="hljs-function"> </span></span>{ m_Mutex.lock(); m_Stack.push( &amp;v ); m_Mutex.unlock(); } <span class="hljs-function"><span class="hljs-function">T * </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pop</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ m_Mutex.lock(); T * pv = m_Stack.top(); m_Stack.pop() m_Mutex.unlock(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pv; } };</code> </pre><br>  Obviously, with competing execution, its performance will be very low - all calls to the stack are serialized on the mutex, everything is performed strictly sequentially.  Is there any way to improve performance? <br>  If N threads are simultaneously accessing the stack, only one of them will capture the mutex, the rest will wait for it to be released.  But instead of waiting passively on a mutex, waiting threads could announce their operations, as in the elimination back-off, and the winning stream (owner of the mutex) could, in addition to its work, perform tasks from its fellows.  This idea formed the basis of the <a href="http://www.cs.bgu.ac.il/~hendlerd/papers/flat-combining.pdf">flat combining</a> approach, described in 2010 and developing to this day. <br><img src="https://habrastorage.org/getpro/habr/post_images/b92/0bd/319/b920bd319e28fd34f25e01ba4d460daf.png"><br>  The idea of ‚Äã‚Äãa flat combining approach can be described as follows.  Each data structure, in our case with a stack, is associated with a mutex and a list of announcements (publication list) in a size proportional to the number of threads working with the stack.  Each thread at the first access to the stack adds its entry to the list of announcements located in thread local storage (TLS).  When executing an operation, the thread publishes a request in its record ‚Äî an operation ( <code>push</code> or <code>pop</code> ) and its arguments ‚Äî and tries to capture the mutex.  If the mutex is captured, the stream becomes <b>a</b> comber (combiner, not to be confused with a combiner): it scans the list of announcements, collects all requests from it, performs them (in the case of the stack, the elimination considered earlier) writes the result to the elements of the announcement list and finally releases the mutex.  If an attempt to capture a mutex fails, the thread waits (spinning) on ‚Äã‚Äãits announcement when the combiner performs its request and places the result in the announcement record. <br>  The list of announcements is constructed in such a way as to reduce the overhead of its management.  The key point is that the list of announcements rarely changes, otherwise we will get a situation where the lock-free publication list is bolted to the stack, which is unlikely to speed up the stack itself.  Requests for the operation are made in the already existing list of announcements, which, recall, is the property of the streams and is located in TLS.  Some list entries may have the status of ‚Äúempty‚Äù, meaning that the corresponding thread does not currently perform any actions with the data structure (stack).  From time to time, the combiner punctures the list of announcements, eliminating long inactive entries (therefore, the list entries must have some timestamp), thereby reducing the time for viewing the list. <br>  In general, flat combining is a very general approach, which successfully extends to complex lock-free data structures and allows combining different algorithms, for example, adding an elimination back-off to the implementation of a flat combining stack.  Implementing flat combining in C ++ in a shared library is also a rather interesting task: the fact is that in research papers the list of announcements is usually an attribute of each container object, which can be too expensive in real life, since each container should have your tls entry.  I would like to have a more general implementation with a single publication list for all flat combining objects, but it‚Äôs important not to lose in speed. <br><div class="spoiler">  <b class="spoiler_title">The story develops in a spiral</b> <div class="spoiler_text">  Interestingly, the idea of ‚Äã‚Äãannouncing its operation prior to its execution goes back to the beginning of research on lock-free algorithms: in the early 1990s, attempts were made to build common methods for converting traditional lock-based data structures to lock-free.  From the point of view of theory, these attempts are successful, but in practice, slow heavy lock-free algorithms are obtained.  The idea of ‚Äã‚Äãthese common approaches was precisely to announce the operation before execution, so that competing streams could see it and help it to be executed.  In practice, such ‚Äúhelp‚Äù was more likely a hindrance: the flows performed the same operation simultaneously, pushing and interfering with each other. <br>  It took a little bit to shift the emphasis ‚Äî from active assistance to passive delegation of work to another, more successful stream ‚Äî and we got a quick flat combining method. <br></div></div><br><br><h1>  Conclusion </h1><br>  Surprisingly, such a simple data structure as a stack, where it seems to be nothing to write about, allowed us to demonstrate so many interesting approaches to developing competitive data structures! <br>  <i>Back-off strategies are</i> applicable everywhere when constructing lock-free algorithms: as a rule, each operation is enclosed in an infinite loop according to the principle ‚Äúwe do not succeed until it succeeds,‚Äù and at the end of the loop body, that is, when the iteration fails, it will not be superfluous put back-off, which can reduce the pressure on the critical data of the container under heavy load. <br>  <i>Elimination back-off</i> is a less general approach, applicable to the stack and, to a lesser extent, to the queue. <br>  Developed in recent years, <i>flat combining</i> is a special trend when building competitive containers - both lock-free and fine grained lock-based. <br>  I hope we will meet with these techniques in the future. <br><a name="Reference"></a><br><div class="spoiler">  <b class="spoiler_title">Lock-free data structures</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/ifree/blog/195770/">Start</a> <br>  Basics: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/195948/">Atomicity and atomic primitives</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/196548/">Where did the memory barriers go from</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/197520/">Memory model</a> </li></ul><br>  Inside: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/202190/">Memory management circuits</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/206984/">RCU</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/216013/">Stack evolution</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/219201/">Another treatise</a> </li><li>  <a href="http://habrahabr.ru/post/230349/">Queue dissection</a> </li><li>  <a href="http://habrahabr.ru/post/250383/">Concurrent maps: warm up</a> </li><li>  <a href="http://habrahabr.ru/post/250523/">Concurrent maps: rehash, no rebuild</a> </li><li>  <a href="http://habrahabr.ru/post/250815/">Concurrent maps: skip list</a> </li><li>  <a href="https://habrahabr.ru/post/251267/">Concurent maps: trees</a> </li><li>  <a href="https://habrahabr.ru/post/314948/">Iterators: multi-level array</a> </li><li>  <a href="https://habrahabr.ru/post/317882/">Iterable list</a> </li></ul><br>  Outside: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/196834/">Introduction to libcds</a> </li></ul><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/216013/">https://habr.com/ru/post/216013/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../216001/index.html">We ask Vkontakte remind pro dumplings</a></li>
<li><a href="../216003/index.html">SpeedReader - Qt library for speed reading</a></li>
<li><a href="../216005/index.html">Internet technology excellence or one life offline - a look from the past</a></li>
<li><a href="../216007/index.html">QEverCloud: Evernote SDK for Qt</a></li>
<li><a href="../216011/index.html">Smartwatch Sony Smartwatch 2 SW2</a></li>
<li><a href="../216019/index.html">RASW: Improving Viola-Jones Method</a></li>
<li><a href="../216021/index.html">Course on Ruby on Rails from Evil Martians</a></li>
<li><a href="../216023/index.html">Breaking the nooLite wireless light control</a></li>
<li><a href="../216025/index.html">The original concept of the Apollo spacecraft by North American Aviation, Inc.</a></li>
<li><a href="../216029/index.html">Debugging Arduino Code in Crystal</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>