<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apache NiFi: what it is and a brief overview of the features</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Today, on thematic foreign sites about Big Data, one can find the mention of such a relatively new tool for the Hadoop ecosystem as Apache NiFi. This ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apache NiFi: what it is and a brief overview of the features</h1><div class="post__text post__text-html js-mediator-article">  Today, on thematic foreign sites about Big Data, one can find the mention of such a relatively new tool for the Hadoop ecosystem as Apache NiFi.  This is a modern open source ETL tool.  Distributed architecture for fast parallel loading and processing of data, a large number of plug-ins for sources and transformations, versioning of configurations is only part of its advantages.  For all its power, NiFi remains fairly simple to use. <br><br><img src="https://habrastorage.org/webt/9b/zs/ri/9bzsrib2emb_rcdq1cj-d8nubbe.png" alt="image"><br><br>  At Rostelecom, we are striving to develop work with Hadoop, so we have already tried and appreciated the advantages of Apache NiFi compared to other solutions.  In this article I will tell you what attracted us to this tool and how we use it. <br><a name="habracut"></a><br><h2>  Prehistory </h2><br>  Not so long ago, we were faced with the choice of a solution for loading data from external sources into the Hadoop cluster.  A long time to solve such problems, we used <a href="https://flume.apache.org/">Apache Flume</a> .  To Flume as a whole, there were no complaints, except for a few moments that did not suit us. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>The first</i> thing that we, as administrators, did not like was that the writing of the Flume config to perform the next trivial download could not be trusted to a developer or analyst who was not immersed in the subtleties of this tool.  Connecting each new source required mandatory intervention from the team of administrators. <br>  <i>The second point</i> was fault tolerance and scaling.  For heavy downloads, for example, via syslog, it was necessary to configure several Flume agents and set up a balancer in front of them.  All this then needed to be somehow monitored and restored in the event of a failure. <br>  <i>Thirdly</i> , Flume did not allow downloading data from various DBMSs and working with some other protocols out of the box.  Of course, in the open spaces of the network, it was possible to find ways to make Flume work with Oracle or SFTP, but the support of such ‚Äúbikes‚Äù is not at all pleasant.  To download data from the same Oracle, we had to use one more tool - <a href="http://sqoop.apache.org/">Apache Sqoop</a> . <br>  Frankly, I am a lazy man by nature, and I didn‚Äôt want to support the zoo of decisions at all.  And I didn‚Äôt like that I had to do all this work myself. <br><br>  There are, of course, quite powerful solutions on the market for ETL tools that can work with Hadoop.  These include Informatica, IBM Datastage, SAS and Pentaho Data Integration.  These are the ones that can most often be heard from colleagues and those that come to mind first.  By the way, we use IBM DataStage for ETL on solutions of the Data Warehouse class.  But historically, our team had no opportunity to use DataStage for downloads to Hadoop.  Again, we did not need all the power of solutions of this level to perform fairly simple transformations and data downloads.  What we needed was a solution with good development dynamics, able to work with a variety of protocols and possessing a convenient and understandable interface that not only the administrator can understand, but also the developer with the analyst, who are often for us customers of the data itself. <br><br>  As you can see from the title, we solved the problems listed with Apache NiFi. <br><br><h2>  What is Apache NiFi? </h2><br>  The name NiFi comes from "Niagara Files".  The project was developed for eight years by the US National Security Agency, and in November 2014 its source code was opened and transferred to the Apache Software Foundation as part of the <a href="https://www.nsa.gov/what-we-do/research/technology-transfer/">NSA Technology Transfer Program</a> . <br><br>  NiFi is an open source ETL / ELT tool that can work with many systems, and not just the Big Data class and the Data Warehouse.  Here are some of them: HDFS, Hive, HBase, Solr, Cassandra, MongoDB, ElastcSearch, Kafka, RabbitMQ, Syslog, HTTPS, SFTP.  You can view the full list in the official <a href="https://nifi.apache.org/docs.html">documentation</a> . <br><br>  Work with a specific DBMS is implemented by adding the appropriate JDBC driver.  There is an API for writing your module as an additional receiver or data converter.  Examples can be found <a href="https://bryanbende.com/development/2015/02/04/custom-processors-for-apache-nifi">here</a> and <a href="https://medium.com/hashmapinc/creating-custom-processors-and-controllers-in-apache-nifi-e14148740ea">here</a> . <br><br><h2>  Main features </h2><br>  NiFi uses a web interface to create a dataflow.  The analyst, who recently started working with Hadoop, the developer, and the bearded admin will cope with it.  The latter two can interact not only with ‚Äúrectangles and arrows‚Äù, but also with the <a href="https://nifi.apache.org/docs/nifi-docs/rest-api/index.html">REST API</a> for collecting statistics, monitoring and managing DataFlow components. <br><br><img src="https://habrastorage.org/webt/zw/dx/iq/zwdxiqh9ovilvva4tak-stj5jpc.png" alt="image"><br>  <i>NiFi control web interface</i> <br><br>  Below, I will show a few DataFlow examples for performing some common operations. <br><br><img src="https://habrastorage.org/webt/jz/cw/v_/jzcwv_nu7infyyarte3skiwvayi.png" alt="image"><br>  <i>Example of uploading files from SFTP server to HDFS</i> <br><br>  In this example, the ListSFTP processor lists files on a remote server.  The result of this listing is used for parallel downloading of files by all the nodes of the cluster by the FetchSFTP processor.  After this, attributes are added to each file, obtained by parsing its name, which are then used by the PutHDFS processor when writing the file to the destination directory. <br><br><img src="https://habrastorage.org/webt/v-/ei/op/v-eiopqny5-jao0kaqlyexduvx0.png" alt="image"><br>  <i>Example of loading data on syslog in Kafka and HDFS</i> <br><br>  Here, using the ListenSyslog processor, we get the input message flow.  After that, each group of messages is added with attributes about the time of their arrival at NiFi and the name of the scheme in Avro Schema Registry.  Next, the first branch is sent to the input of the QueryRecord processor, which, based on the specified scheme, reads the data and parses it using SQL, and then sends it to Kafka.  The second branch is sent to the ‚ÄúMergeContent‚Äù processor, which aggregates the data for 10 minutes, then gives it to the next processor for conversion to the Parquet format and writing to HDFS. <br><br>  Here is an example of how you can still make DataFlow: <br><img src="https://habrastorage.org/webt/43/kd/2-/43kd2-43rovwudvvoi3sm8hdmuk.png" alt="image"><br>  <i>Downloading syslog data to Kafka and HDFS.</i>  <i>Clearing data in Hive</i> <br><br>  Now about data conversion.  NiFi allows you to parse data regularly, run SQL on it, filter and add fields, convert one data format to another.  It also has its own expression language, rich in various operators and built-in functions.  With it, you can add variables and attributes to the data, compare and calculate values, use them later in the formation of various parameters, such as the path to write to HDFS or the SQL query to Hive.  Read more <a href="https://nifi.apache.org/docs/nifi-docs/html/expression-language-guide.html">here</a> . <br><br><img src="https://habrastorage.org/webt/a4/7m/b_/a47mb_i_f2mzkfezluoq6qrt6-0.png" alt="image"><br>  <i>Example of using variables and functions in the UpdateAttribute processor</i> <br><br>  The user can track the full path of the data, watch for changes in their contents and attributes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a69/e09/44a/a69e0944abb4bb44f3863653994cd891.png"><br>  <i>DataFlow chain visualization</i> <br><br><img src="https://habrastorage.org/webt/sc/u3/ih/scu3ihzv1nwydvwfjc4ks9yvfoe.png" alt="image"><br>  <i>View content and data attributes</i> <br><br>  For versioning DataFlow there is a separate service <a href="https://nifi.apache.org/registry.html">NiFi Registry</a> .  By setting it up, you get the opportunity to manage change.  You can launch local changes, roll back or download any previous version. <br><br><img src="https://habrastorage.org/webt/ci/uz/ge/ciuzgeuazknrhqm5peopzmekiuo.png" alt="image"><br>  <i>Version Control menu</i> <br><br>  In NiFi, you can control access to the web interface and the separation of user rights.  The following authentication mechanisms are currently supported: <br><br><ul><li>  Based on certificates <br></li><li>  Based on username and password through LDAP and Kerberos <br></li><li>  Via <a href="https://knox.apache.org/">Apache Knox</a> <br></li><li>  Via <a href="https://openid.net/connect/">OpenID Connect</a> <br></li></ul><br>  Simultaneous use of several mechanisms at once is not supported.  For authorization of users in the system FileUserGroupProvider and LdapUserGroupProvider are used.  Read more about it <a href="https://nifi.apache.org/docs/nifi-docs/html/administration-guide.html">here</a> . <br><br>  As I said, NiFi can work in cluster mode.  This provides fault tolerance and makes it possible to scale the load horizontally.  There is no static fixed master node.  Instead, <a href="https://zookeeper.apache.org/">Apache Zookeeper</a> selects one node as the coordinator and one as the primary.  The coordinator receives information from other nodes about their status and is responsible for connecting and disconnecting them from the cluster. <br>  Primary-node is used to run isolated processors that should not run on all nodes at the same time. <br><br><img src="https://habrastorage.org/webt/1w/io/mv/1wiomvdhjbh_ewwa73dgl-yjitg.png" alt="image"><br>  <i>NiFi work in a cluster</i> <br><br><img src="https://habrastorage.org/webt/du/ty/ea/dutyeaditjnc6bq_qgta6xcexrk.png" alt="image"><br>  <i>Load distribution across cluster nodes using the example of PutHDFS processor</i> <br><br><h2>  A brief description of the architecture and components of NiFi </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/d68/920/1de/d689201de4c392c562e807fc279cd2ab.png"><br>  <i>NiFi Instance Architecture</i> <br><br>  NiFi is based on the concept of ‚ÄúFlow Based Programming‚Äù ( <a href="https://en.wikipedia.org/wiki/Flow-based_programming">FBP</a> ).  Here are the basic concepts and components that each user encounters: <br><br>  <b>FlowFile</b> - an entity that represents an object with content from zero and more bytes and corresponding attributes.  This can be either the data itself (for example, the Kafka message flow), or the result of the processor (PutSQL, for example), which does not contain the data as such, but only the attributes generated as a result of the query.  Attributes are FlowFile metadata. <br><br>  <b>FlowFile Processor</b> - this is the essence that performs the main work in NiFi.  The processor, as a rule, has one or several functions for working with FlowFile: create, read / write and change content, read / write / change attributes, and route.  For example, the processor "ListenSyslog" receives data on the syslog-protocol, creating FlowFile'y with the attributes syslog.version, syslog.hostname, syslog.sender and others at the output.  The RouteOnAttribute processor reads the attributes of the input FlowFile and decides whether to redirect it to the appropriate connection with another processor depending on the attribute values. <br><br>  <b>Connection</b> - connects and transfers FlowFile between different processors and some other NiFi entities.  Connection puts FlowFile in the queue, and then passes it further along the chain.  You can configure how FlowFiles are selected from the queue, their lifetime, the maximum number and maximum size of all objects in the queue. <br><br>  <b>Process Group</b> - a set of processors, their connections and other elements of DataFlow.  It is a mechanism for organizing multiple components into one logical structure.  Allows you to simplify the understanding of DataFlow.  Input / Output Ports are used to receive and send data from Process Groups.  Read more about their use <a href="https://community.hortonworks.com/articles/16461/nifi-understanding-how-to-use-process-groups-and-r.html">here</a> . <br><br>  <b>The FlowFile Repository</b> is where NiFi stores all the information it knows about every existing FlowFile in the system. <br><br>  <b>Content Repository</b> - the repository in which the contents of all FlowFile are located, i.e.  the data being transferred. <br><br>  <b>Provenance Repository</b> - contains a story about each FlowFile.  Each time a flow event occurs (create, modify, etc.), the corresponding information is entered into this repository. <br><br>  <b>Web Server</b> - provides a web interface and REST API. <br><br><h2>  Conclusion </h2><br>  With the help of NiFi, Rostelecom was able to improve the delivery mechanism of data to Data Lake on Hadoop.  In general, the whole process has become more convenient and reliable.  Today I can say with confidence that NiFi is great for doing downloads in Hadoop.  We have no problems with its operation. <br><br>  By the way, NiFi is included in the Hortonworks Data Flow distribution and is actively developed by Hortonworks itself.  And he also has an interesting Apache MiNiFi subproject, which allows you to collect data from various devices and integrate them into DataFlow inside NiFi. <br><br><h2>  Additional Info About NiFi </h2><br><ul><li>  Official project documentation <a href="https://nifi.apache.org/docs.html">page</a> <br></li><li>  Collection of <a href="https://pierrevillard.com/best-of-nifi">interesting articles</a> about NiFi from one of the project participants <br></li><li>  <a href="https://bryanbende.com/archive.html">NiFi</a> developer <a href="https://bryanbende.com/archive.html">blog</a> <br></li><li>  <a href="https://community.hortonworks.com/topics/Nifi.html%3Ftype%3Dkbentry%26sort%3Dactive">Articles</a> on the portal Hortonworks <br></li></ul><br>  Perhaps that's all.  Thank you all for your attention.  Write in the comments if you have questions.  I will answer them with pleasure. </div><p>Source: <a href="https://habr.com/ru/post/432166/">https://habr.com/ru/post/432166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../432154/index.html">Conditional Access as an access control mechanism</a></li>
<li><a href="../432156/index.html">New 2GIS - connect to public testing</a></li>
<li><a href="../432158/index.html">Using JIRA and Confluence in a large project</a></li>
<li><a href="../432160/index.html">Android Kolesa Mobile video: modular development, backend driven UI and continuous integration</a></li>
<li><a href="../432162/index.html">‚ÄúWe try to give real life stories‚Äù: about the Heisenbug 2018 Moscow program</a></li>
<li><a href="../432168/index.html">Chinese authorities are collecting information from electric vehicles of citizens of the country</a></li>
<li><a href="../432170/index.html">Carry data center in 14,400 seconds</a></li>
<li><a href="../432172/index.html">Dangerous invitation, or How does the combat load to a phishing email</a></li>
<li><a href="../432174/index.html">How to competently and effectively develop a software product</a></li>
<li><a href="../432176/index.html">How we doubled the speed of working with Float in Mono</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>