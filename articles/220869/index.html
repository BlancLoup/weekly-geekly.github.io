<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Capture meter readings on the phone, followed by recognition</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 It so happened that I live in a cottage village where there is no central heating, which means that everyone heats his apartment on his...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Capture meter readings on the phone, followed by recognition</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/5a1/9ab/1d0/5a19ab1d0f7c89e8b0da25a4cf69b146.jpg" align="right"><h4>  Introduction </h4><br>  It so happened that I live in a cottage village where there is no central heating, which means that everyone heats his apartment on his own.  Most often for these purposes gas boilers are used, the method is quite cheap, there is nothing to complain about, but there is one subtlety.  For the gas boiler to work correctly (suddenly) it is necessary to have gas in the pipe. <br><br>  Probably, not all boilers behave this way, but ours turns off even in case of a brief interruption in the gas supply and does not turn on again if the supply is restored.  If someone is at home, then this is not a problem, I pressed the button and the boiler heats further, but if it so happened that we decided to go on vacation with the whole family, and it was winter outside, good to -20 ¬∞ C, then the consequences can be deplorable. <br><br>  The solution is simple - leave the keys to relatives / friends / neighbors so that they can come and turn on the boiler, if some trouble happens.  Well, if there is a neighbor who will come every day and check whether everything is in order.  And if not?  Or will he also decide to go somewhere for the weekend? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So, I decided to adjust the reading of the meter somewhere on the Internet, so that I could periodically check whether gas is being spent somewhere on a long trip, and if I suddenly stop wasting, then I urgently call relatives / friends / neighbors (or whoever I‚Äôm left the keys) to come and press the button. <br><br>  Of course, after simply putting testimony on the Internet, I decided not to stop there and fouled up the recognition of indications and graphical representation, read about it in Part 2 of this topic. <br><a name="habracut"></a><br><h4>  Part 1. Taking readings from the meter and putting them on the Internet </h4><br>  Here it is necessary to make a reservation that the counters are completely different in nature, some of them have special buses and interfaces for automated reading.  If you have one, then you probably can not read further.  But I have the most common without such interfaces (at least, I did not find, maybe I looked badly), the GALLUS iV PSC model.  Therefore, there remains one option - a visual removal of evidence.  The network offers ready-made solutions, but they cost a lot of money, and most importantly, it is not at all sporty, so we will do everything ourselves. <br><br><h5>  What do we need? </h5><br>  To take readings from the meter and then send these readings to the Internet, we need any unnecessary android smartphone.  For example, I used the Samsung Galaxy S III (SCH-I535) for this purpose.  Yes, probably, not every reader has a third Galaxy lying around, but you need to understand that the requirements for a smartphone are not so great: <br><ul><li>  it should load </li><li>  the camera should work </li><li>  WiFi should work </li></ul><br>  That's all, the presence of a working screen, touch screen, microphone, speaker, etc.  absolutely not required.  This fact significantly reduces the cost. <br><br>  Having a hobby of buying various broken phones on ebay and collecting working ones, I easily found in my storeroom a sgs3 motherboard with a dead microphone (~ $ 10), as well as a used camera (~ $ 10) and a Chinese battery (~ 300r)  Also for the convenience of attaching the battery to the board used a frame with a broken display. <br><img src="https://habrastorage.org/getpro/habr/post_images/39f/92b/5df/39f92b5dfd6eb77f066feda2fdc0de4b.jpg"><br><br>  At first I thought to do only the motherboard and the camera, but it turned out that even when connected to charging, the board does not turn on without a battery, so I had to add a frame and a battery.  But even in this case, the budget turned out to be about $ 30; if you use sgs3 devices simpler, then you can keep within a smaller amount. <br><br>  True, such a solution has its drawbacks, a smartphone without a display and a touchscreen is not so convenient to configure, so I‚Äôll tell you a little about how this problem had to be solved. <br><br><h5>  Setup of the device </h5><br>  We will proceed from the worst case scenario.  Suppose that there is no display or touchscreen, there is no root on the smartphone, adb debugging is disabled, and the firmware is unknown. <br><br><h6>  Resuscitation </h6><br>  <b>Attention!</b>  Further instructions are suitable for the device Samsung Galaxy S III (SCH-I535), if you have another smartphone, then the actions may differ. <br><br>  It is assumed that you are familiar with such concepts as adb, firmware, etc. <br><br>  To bring the smartphone into a more or less known state, for starters, we will flash the stock firmware VRBMB1 <a href="http://forum.xda-developers.com/showthread.php%3Ft%3D1755386">from here</a> using <a href="http://androidp1.ru/odin-firmware-samsung/">Odin</a> .  I will not describe in detail how this is done, the Internet is full of instructions on how to use Odin.  Odin in our case is good because it is easy to work with it without using the smartphone screen, you only need to turn on the smartphone in boot mode (Vol Down + Home + Power - hold for a few seconds, then Vol Up, connect usb to Windows and that's all. Odin-a). <br><br>  After Odin flush the drain, the phone will boot the system, disconnect it from the usb and remove the battery so that it turns off.  This operation must be done every time after completing the Odin firmware, in order to start the next operation from the off state. <br><br>  Next, we sew CWM recovery and root according to the <a href="http://www.droidviews.com/root-and-install-cwmtwrp-recovery-on-verizon-galaxy-s3-sch-i535-android-4-1-14-1-2/">instructions</a> .  In short, as follows: <br><ul><li>  Through Odin, we <a href="http://d-h.st/4MU">flash the</a> custom VR <a href="http://d-h.st/4MU">bootbain VRALEC.bootchain.tar.md5</a> </li><li>  Through Odin we flash <a href="http://d-h.st/qnB">CWM recovery</a> </li><li> Through CWM recovery, we <a href="http://d-h.st/OXI">flash SuperSU_Bootloader_FIXED.zip</a> .  The manual says that zip should be thrown onto an sd card, but due to the lack of a screen, it is easier to do this through sideload: <br>  Turn on the body holding Vol Up + Home + Power - hold for a few seconds, then another 5 seconds loading, we get into the CWM-recovery mode. <br>  We check this by typing <code>adb devices</code> in the console in ubuntu (the body itself must be connected via usb and adb must be installed - <code>sudo apt-get install android-tools-adb</code> ): <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb devices List of devices attached 64cb5c59 recovery</code> </pre><br>  If we see the last line, it means everything is in order, click on the Vol Down, Vol Down, Power device - go to adb sideload mode (at least in the CWM version of the instructions, this is the second line from the top), you just have to type in ubuntu console: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb sideload SuperSU_Bootloader_FIXED.zip sending: <span class="hljs-string"><span class="hljs-string">'sideload'</span></span> 100%</code> </pre><br>  and root flies to the device, after which we do not forget to turn off the device by pulling out the battery from it. </li><li>  Through Odin, we are flashing the stock bootchain, corresponding to the stock firmware <a href="http://d-h.st/nyI">VRBMB1_Bootchain.tar.md5</a> supplied before that </li></ul><br><br>  Next, we need to enable usb debugging on the smartphone, for this we launch the smartphone in the CWM-recovery mode, check: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb devices List of devices attached 64cb5c59 recovery</code> </pre><br>  Mount the system: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell mount -o rw -t ext4 /dev/block/platform/msm_sdcc.1/by-name/system /system</code> </pre><br>  Add a line to /system/build.prop: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell <span class="hljs-string"><span class="hljs-string">"echo \"persist.service.adb.enable=1\" &gt;&gt; /system/build.prop"</span></span></code> </pre><br>  Reboot: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb reboot</code> </pre><br>  We are waiting for the download, check the adb status in the terminal: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb devices List of devices attached 64cb5c59 device</code> </pre><br>  Bingo!  Debugging is enabled, let's see what we have going on there on our smartphone, to do this, we launch <a href="">AndroidScreenCast</a> using Java Web Start and see: <br><img src="https://habrastorage.org/getpro/habr/post_images/1e1/d1c/065/1e1d1c06530e92242f59b1d594b02d86.png" height="574"><br><br>  This is the Verizon SIM card activation screen, I don‚Äôt have such a SIM, so I just skip the activation, following the instructions: <br><blockquote>  on the language selection screen, we consistently touch the lower left corner (above the emergency call button), lower right corner, lower left, lower right and volume + on the screen. </blockquote><br>  Namely: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input tap 10 1150 malefic@lepeshka:~$ adb shell input tap 710 1150 malefic@lepeshka:~$ adb shell input tap 10 1150 malefic@lepeshka:~$ adb shell input tap 710 1150</code> </pre><br>  then I press the Vol Up button on the smartphone, now we see: <br><img src="https://habrastorage.org/getpro/habr/post_images/c7b/76f/ff4/c7b76fff492c940484a92695a3b65ea1.png"><br><br>  Put a tick and click OK: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input tap 50 600 malefic@lepeshka:~$ adb shell input tap 650 600</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/a06/ae5/c2c/a06ae5c2c744bb5dcaefddae69027502.png"><br><br>  Swipe to unlock the screen: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input swipe 100 100 500 100</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/c06/b2f/c42/c06b2fc4281be1ee6500b2d0c29762c6.png"><br><br>  Now you need to put some vnc server for Android, for example, <a href="http://4pda.ru/forum/index.php%3Fshowtopic%3D183128">Android VNC Server</a> .  Install it on your smartphone: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb install droid+VNC+server+v1.1RC0.apk 4055 KB/s (2084419 bytes <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0.501s) pkg: /data/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/tmp/droid+VNC+server+v1.1RC0.apk Success</code> </pre><br>  We will wake up the smartphone, as it most likely fell asleep while we were installing the vnc server, and swipe to unlock the screen: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input keyevent 26 malefic@lepeshka:~$ adb shell input swipe 100 100 500 100</code> </pre><br>  We start the vnc server: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell am start -a android.intent.action.Main -n org.onaips.vnc/.MainActivity</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/274/da2/6fe/274da26fec538c8ae348378ae3fb2dca.png"><br><br>  Click OK: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input tap 50 900</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/da0/55c/2cd/da055c2cd091640f696c5084159043e2.png"><br><br>  Click Start: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input tap 350 300</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/e04/b98/0d0/e04b980d05a82f1bee318efce9002bfc.png"><br><br>  Click to provide access: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb shell input tap 600 1000</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/4cb/9d4/4e8/4cb9d44e8866c310db4c25b48f854163.png"><br><br>  Ok, now we forward ports through adb: <br><pre> <code class="bash hljs">malefic@lepeshka:~$ adb forward tcp:5801 tcp:5801 malefic@lepeshka:~$ adb forward tcp:5901 tcp:5901</code> </pre><br>  and go to the smartphone through a browser or a favorite vnc client. <br><img src="https://habrastorage.org/getpro/habr/post_images/2e3/5f4/0d6/2e35f40d6e61ccfbda0254578ec189ee.png"><br><br>  Then we work as with an ordinary Android phone, only through a computer, it is convenient to immediately set up a WiFi connection, then you can go over vnc via WiFi, and not keep the phone connected all the time to the computer (after all, the gas meter is not always located in the immediate vicinity of the computer). <br><br>  Now that the interaction with the device is fully established, you can proceed to setting up photographing and publishing data on the Internet. <br><br><h6>  Periodic photography </h6><br>  Install the <a href="http://4pda.ru/forum/index.php%3Fshowtopic%3D173935">Tasker</a> application, create a temporary profile in it from 00:00 to 23:59 every 30 minutes, perform an action - take a photo.  Shooting options select the most suitable for the location of the phone and counter.  I have a macro shot with a mandatory flash. <br><br>  So, actually, I placed my phone (top view): <br><img src="https://habrastorage.org/getpro/habr/post_images/95a/3eb/742/95a3eb742cbfc74062d06641cb72ac0e.jpg"><br><br>  A cardboard box tied to the counter with a string, a smartphone lives in it, an egg package is there to fix the smartphone in an upright position.  Then I also modified the design using scotch tape and cardboard so that the flash would not hit the dial directly, this gives serious glare that interferes with the recognition.  I covered everything from above with a cover so that it was dark inside, otherwise autofocus does not always work correctly in bright ambient light. <br><br>  In the settings of the smartphone in the developer‚Äôs tools, it is necessary to tick the smartphone so that the smartphone doesn‚Äôt fall asleep while charging is connected, otherwise at some point it stops taking pictures and continues only if it is disturbed. <br><img src="https://habrastorage.org/getpro/habr/post_images/894/e42/b64/894e42b641bb1218707ed212dd3300e6.png" height="574"><br><br><h6>  We spread on the Internet </h6><br>  To move the captured images of the counter to the Internet, I used the first available application - <a href="https://play.google.com/store/apps/details%3Fid%3Ddk.tacit.android.foldersync.lite">FolderSync Lite</a> .  It can synchronize a folder on a smartphone with a folder, for example, on a Google drive. <br><br>  Thus, I can now, from anywhere in the world where there is Internet, go to my Google Drive and check that the gas boiler is operating normally. <br><br><h4>  Part 2. Recognition of evidence </h4><br>  So, after sending the meter readings to the Internet, I was interested in the possibility of automatic recognition of readings.  This will allow: <br><ul><li>  perform a statistical analysis of gas consumption </li><li>  automatically track gas interruptions (with the possibility of a warning by e-mail or sms) </li></ul><br><br>  Python was chosen as the development language, the <a href="http://docs.opencv.org/trunk/doc/py_tutorials/py_tutorials.html">OpenCV</a> library was used for working with images. <br><br>  Here is the code of the main program, which runs on the crown once an hour: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> getImage, sess <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gdrive <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> getImagesFromGDrive, createImageFromGDriveObject <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: <span class="hljs-comment"><span class="hljs-comment">#        images, http = getImagesFromGDrive() #      for img_info in images: #   img = createImageFromGDriveObject (img_info, http) file_name = img_info['title'] #     try: dbimage = getImage(os.path.basename(file_name)) dbimage.img = img dbimage.download_url = img_info["downloadUrl"] dbimage.img_link = img_info['webContentLink'].replace('&amp;export=download','') except ValueError as e: print e continue #   dbimage.identifyDigits() #     sess.commit()</span></span></code> </pre><br>  Here functions are used, the code of which I post below: <br><ul><li>  <code>getImagesFromGDrive</code> - a function that returns a list of unrecognized images from Google Drive </li><li>  <code>createImageFromGDriveObject</code> - a function that downloads the image itself and converts it into the OpenCV format </li><li>  <code>getImage</code> - the function searches for an image record in the database, if there is none, it creates it </li><li>  <code>identifyDigits</code> is a method that recognizes readings on a given image </li><li>  <code>http</code> - an authorized client to access Google Drive, read in detail about access to the Disk API <a href="https://developers.google.com/drive/web/quickstart/quickstart-python">here</a> </li><li>  <code>sess</code> - database connection object, using <a href="http://www.sqlalchemy.org/">SQL Alchemy</a> library </li></ul><br><h5>  Work with Google Drive </h5><br>  The first thing we do is get a list of images from Google Drive: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tzinfo, timedelta, date <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> dateutil.relativedelta <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> relativedelta <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apiclient.discovery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> build <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> getLastRecognizedImage <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getImagesFromGDrive</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  id  Google ,     FOLDER_ID = '0B5mI3ROgk0mJcHJKTm95Ri1mbVU' #     http = getAuthorizedHttp() #    drive_service = build('drive', 'v2', http=http) #         ,      month_ago = date.today() + relativedelta( months = -1 ) q = "'%s' in parents and mimeType = 'image/jpeg' and trashed = false and modifiedDate&lt;'%s'" % (FOLDER_ID, month_ago.isoformat()) files = drive_service.files().list(q = q, maxResults=1000).execute() for image in files.get('items'): drive_service.files().trash(fileId=image['id']).execute() #     ,     last_image = getLastRecognizedImage() #     ,          page_size = 1000 result = [] pt = None #   API        1000 , #      1000       while True: q = "'%s' in parents and trashed = false and mimeType = 'image/jpeg' and modifiedDate&gt;'%s'" % (FOLDER_ID, last_image.check_time.replace(tzinfo=TZ()).isoformat('T')) files = drive_service.files().list(q = q, maxResults=page_size, pageToken=pt).execute() result.extend(files.get('items')) pt = files.get('nextPageToken') if not pt: break #  ,        result.reverse() return result, http</span></span></code> </pre><br>  An authorized Disk client is created as follows: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> httplib2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ConfigParser <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> oauth2client.client <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> OAuth2WebServerFlow <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> oauth2client.file <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Storage <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getAuthorizedHttp</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    config.ini   CLIENT_ID  CLIENT_SECRET config = ConfigParser.ConfigParser() config.read([os.path.dirname(__file__)+'/config.ini']) CLIENT_ID = config.get('gdrive','CLIENT_ID') CLIENT_SECRET = config.get('gdrive','CLIENT_SECRET') # OAuth 2.0 scope that will be authorized. # Check https://developers.google.com/drive/scopes for all available scopes. OAUTH_SCOPE = 'https://www.googleapis.com/auth/drive' # Redirect URI for installed apps REDIRECT_URI = 'urn:ietf:wg:oauth:2.0:oob' #   client_secrets.json    storage = Storage(os.path.dirname(__file__) + '/client_secrets.json') credentials = storage.get() #     ,     if not credentials: # Perform OAuth2.0 authorization flow. flow = OAuth2WebServerFlow(CLIENT_ID, CLIENT_SECRET, OAUTH_SCOPE, REDIRECT_URI) authorize_url = flow.step1_get_authorize_url() #    ,       print 'Go to the following link in your browser: ' + authorize_url #   code = raw_input('Enter verification code: ').strip() credentials = flow.step2_exchange(code) #   storage.put(credentials) #  http     http = httplib2.Http() credentials.authorize(http) return http</span></span></code> </pre><br>  To get the CLIENT_ID and CLIENT_SECRET in the <a href="https://console.developers.google.com/project">Google Developers Console,</a> you need to create a project and for this project in the <b>APIs &amp; auth</b> - <b>Credentials</b> - <b>OAuth</b> section, click <b>CREATE NEW CLIENT ID</b> , then select <b>Installed application</b> - <b>Other</b> : <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/bf2/125/d40bf21254e8bafa8815b79cce2ad256.jpg"><br><br>  When you first start the script, write the url on which you need to go to the console in order to get the token, paste it into the address bar of the browser, allow the application to access Google Drive, copy the verification code issued by Google from the browser and give it to the script.  After that, the script will save everything you need to the <code>client_secrets.json</code> file and will not ask anything on subsequent launches. <br><br>  The image download function is extremely simple: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">downloadImageFromGDrive</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(downloadUrl, http=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> http==<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: http = getAuthorizedHttp() <span class="hljs-comment"><span class="hljs-comment">#   resp, content = http.request(downloadUrl) #    OpenCV img_array = np.asarray(bytearray(content), dtype=np.uint8) return cv2.imdecode(img_array, cv2.IMREAD_COLOR) def createImageFromGDriveObject (img_info, http=None): return downloadImageFromGDrive(img_info['downloadUrl'], http)</span></span></code> </pre><br><br><h5>  Search for evidence on the photo </h5><br>  The first thing that needs to be done after we get a photo is to find numbers on it that we will recognize.  This is the <code>extractDigitsFromImage</code> method: <br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extractDigitsFromImage</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> img = self.img</code> </pre><br>  Initially, the photo looks like this: <br><img src="https://habrastorage.org/getpro/habr/post_images/01f/8e8/899/01f8e8899123d8c6bccb7916c07c9caa.png"><br><br>  Therefore, we first turn it so that it acquires the desired orientation. <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   90  h, w, k = img.shape M = cv2.getRotationMatrix2D((w/2,h/2),270,1) img = cv2.warpAffine(img,M,(w,h))</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/eb3/633/9e2eb3633779aa2167bbee3dcc678a6d.png"><br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   ,    img = img[0:h, (wh)/2:h+(wh)/2] h, w, k = img.shape</span></span></code> </pre><br>  Now consider a piece of the image, circled in red.  It is quite unique within the entire photo, you can use it to search for the dial.  I put it in the <code>sample.jpg</code> file and wrote the following code to find its coordinates: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#       sample = cv2.imread(os.path.dirname(__file__)+"/sample.jpg") sample_h, sample_w, sample_k = sample.shape #       res = cv2.matchTemplate(img,sample,cv2.TM_CCORR_NORMED) min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) #      x_center = max_loc[0] + sample_w/2 y_center = max_loc[1] + sample_h/2 #        ,      , #        if x_center&gt;w*0.6: img = img[0:h, 0.2*w:w] h, w, k = img.shape x_center = x_center-0.2*w</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/c9b/3ae/709/c9b3ae7092d1f9a6730f6375b015df8d.png"><br><br>  The point on the figure indicates the coordinates found, what we wanted.  Next, we launch the algorithm for searching for boundaries, having previously translated the image into gray tones.  100 and 200 are empirically matched threshold values. <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #    Canny edges = cv2.Canny(gray, 100, 200)</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/bc9/19c/740/bc919c74098c40e23314c55938b740bf.png"><br><br>  Now we run the algorithm for searching lines on the resulting image with borders.  In addition to the image itself, the <code>HoughLines</code> method also takes as parameters the magnitudes of the search steps for the distance and angle of rotation and the threshold value responsible for the minimum number of points that should form a line.  The smaller this threshold, the more lines the algorithm will find. <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/b71/563/da3/b71563da35183d7da87cb5d36eb31dec.png"><br><br>  Of all the lines found, we consider only more or less horizontal lines and find the two closest to the previously discovered center (one from the top, the other from the bottom). <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    rho_below = rho_above = np.sqrt(h*h+w*w) line_above = None line_below = None for line in lines: rho,theta = line[0] sin = np.sin(theta) cos = np.cos(theta) #     if (sin&lt;0.7): continue #       ,    ""  rho_center = x_center*cos + y_center*sin #      if rho_center&gt;rho and rho_center-rho&lt;rho_above: rho_above = rho_center-rho line_above = {"rho":rho, "theta":theta, "sin":sin, "cos":cos} #      if rho_center&lt;rho and rho-rho_center&lt;rho_below: rho_below = rho-rho_center line_below = {"rho":rho, "theta":theta, "sin":sin, "cos":cos} # ,      if line_below==None or line_above==None: mylogger.warn("No lines found") return False # ,           if rho_below/rho_above&gt;1.7 or rho_below/rho_above&lt;0.6: mylogger.warn("Wrong lines found: %f" % (rho_below/rho_above)) return False</span></span></code> </pre><br><img src="//habrastorage.org/files/768/a07/45e/768a0745ec0444ce8d96ce23c80ac4bd.png"><br><br>  Rotate the image so that the found lines become completely horizontal: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#  M = cv2.getRotationMatrix2D((0,(line_below["rho"]-line_above["rho"])/2+line_above["rho"]),line_above["theta"]/np.pi*180-90,1) img = cv2.warpAffine(img,M,(w,h))</span></span></code> </pre><br><img src="//habrastorage.org/files/e14/33d/f93/e1433df935bc4aee870663540e57724c.png"><br><br>  Now let's cut off everything that is behind the found lines: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#  img = img[line_above["rho"]:line_below["rho"], 0:w] h, w, k = img.shape</span></span></code> </pre><br><img src="//habrastorage.org/files/cc3/50e/14a/cc350e14aa344b97b9bb70a413a90ea0.png"><br><br>  Next, we need to find the left and right edges of the dial, translate the image in black and white: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) thres = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)</span></span></code> </pre><br><img src="//habrastorage.org/files/b8f/5fb/573/b8f5fb57326145e59d3508ff911e7800.png"><br><br>  We are looking for the right edge using the same technology as the ‚Äúcentral‚Äù point, the template is circled in red: <br><pre> <code class="python hljs"> sample_right = cv2.imread(os.path.dirname(__file__)+<span class="hljs-string"><span class="hljs-string">"/sample_right.jpg"</span></span>,cv2.IMREAD_GRAYSCALE) <span class="hljs-comment"><span class="hljs-comment">#      res = cv2.matchTemplate(thres,sample_right,cv2.TM_CCORR_NORMED) min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res) #    x_right = max_loc[0]-6</span></span></code> </pre><br>  To search for the left border, apply the closure transformation to remove noise: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   kernel = np.ones((7,7),np.uint8) thres = cv2.morphologyEx(thres, cv2.MORPH_CLOSE, kernel)</span></span></code> </pre><br><img src="//habrastorage.org/files/65b/712/8aa/65b7128aa1474caf915bb6ddc3d700a4.png"><br><br>  Next, we will go through all the pixels starting from the left, until we meet black, this will be the left edge: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    x_left=0 while x_left&lt;w : if thres[h/2,x_left]==0: break x_left+=1</span></span></code> </pre><br><img src="//habrastorage.org/files/49b/7b4/f9a/49b7b4f9aa86442fa74399085eb0e816.png"><br><br>  Cut the image on the left and right edge: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#     img = img[:, x_left:x_right] h, w, k = img.shape</span></span></code> </pre><br><img src="//habrastorage.org/files/aae/9d3/969/aae9d39698634dfaa51bc0e3cb3530b9.png"><br><br>  Let's make a small check that the image found by the aspect ratio corresponds to the dial: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    if float(w)/float(h)&lt;6.5 or float(w)/float(h)&gt;9.5: mylogger.warn("Image has bad ratio: %f" % (float(w)/float(h))) return False self.digits_img = img return True</span></span></code> </pre><br><br><h5>  Digitization </h5><br>  The <code>splitDigits</code> method is used to <code>splitDigits</code> dial-out function selected by the previous function into separate digits: <br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">splitDigits</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># ,     ,    if None == self.digits_img: if not self.extractDigitsFromImage(): return False img = self.digits_img h, w, k = img.shape</span></span></code> </pre><br>  To begin with, simply cut our dial into 8 equal parts: <br><img src="//habrastorage.org/files/480/b34/2d7/480b342d783c472ca447cec9f2ea7dfa.png"><br><br>  We will process only the first 7 parts, since the 8th digit is constantly spinning, it is useless to recognize it. <br>  Each part is translated into b / w color using the <code>adaptiveThreshold</code> method, the parameters are chosen empirically: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    8       for i in range(1,8): digit = img[0:h, (i-1)*w/8:i*w/8] dh, dw, dk = digit.shape #   / digit_gray = cv2.cvtColor(digit,cv2.COLOR_BGR2GRAY) digit_bin = cv2.adaptiveThreshold(digit_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 0)</span></span></code> </pre><br><img src="//habrastorage.org/files/af8/cdc/261/af8cdc261c044c998e9d3497db7f03bb.png"><br><br>  Slightly remove the noise using the opening transform (using a 2x2 core).  It could have been done without this, but sometimes it helps to cut off large white pieces from the figure connected by thin jumpers: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   kernel = np.ones((2,2),np.uint8) digit_bin = cv2.morphologyEx(digit_bin, cv2.MORPH_OPEN, kernel)</span></span></code> </pre><br><img src="//habrastorage.org/files/006/879/9cb/0068799cb6b84a0583a173c8bf3e0fe6.png"><br><br>  Run the contour search algorithm <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   other, contours, hierarhy = cv2.findContours(digit_bin.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)</span></span></code> </pre><br><img src="//habrastorage.org/files/d42/ca4/e83/d42ca4e836dd4e1490b60b155bb826a3.png"><br><br>  Next, we will throw out all too small contours and contours along the edges of the image, then we will find the largest contour of the remaining: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   biggest_contour = None biggest_contour_area = 0 for cnt in contours: M = cv2.moments(cnt) #       if cv2.contourArea(cnt)&lt;30: continue #       if cv2.arcLength(cnt,True)&lt;30: continue #     cx = M['m10']/M['m00'] cy = M['m01']/M['m00'] #  ,     -   if cx/dw&lt;0.3 or cx/dw&gt;0.7: continue #    if cv2.contourArea(cnt)&gt;biggest_contour_area: biggest_contour = cnt biggest_contour_area = cv2.contourArea(cnt) biggest_contour_cx = cx biggest_contour_cy = cy #       ,      if biggest_contour==None: digit = self.dbDigit(i, digit_bin) digit.markDigitForManualRecognize (use_for_training=False) mylogger.warn("Digit %d: no biggest contour found" % i) continue</span></span></code> </pre><br><img src="//habrastorage.org/files/706/a4b/27d/706a4b27dedd4c77a7ef2757bb3f6af6.png"><br><br>  The largest contour is our figure, we will throw away everything that lies outside of it by applying a mask: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#  ,        mask = np.zeros(digit_bin.shape,np.uint8) cv2.drawContours(mask,[biggest_contour],0,255,-1) digit_bin = cv2.bitwise_and(digit_bin,digit_bin,mask = mask)</span></span></code> </pre><br><img src="//habrastorage.org/files/204/4d7/1f0/2044d71f07ee4eaeac7ce6162fc63e40.png"><br><br>  Now we describe a rectangle of standard size around each digit with the center in the center of mass of the contour: <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#     rw = dw/2.0 rh = dh/1.4 # ,        if biggest_contour_cy-rh/2 &lt; 0: biggest_contour_cy = rh/2 if biggest_contour_cx-rw/2 &lt; 0: biggest_contour_cx = rw/2</span></span></code> </pre><br><img src="//habrastorage.org/files/0a0/695/570/0a069557023e491dba073f61d6884c7b.png"><br><br>  We cut the image in a rectangle and scale it to the specified size, for me it is <code>digit_base_h = 2</code> 4, <code>digit_base_w = 16</code> .  The result is saved in the database. <br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#   digit_bin = digit_bin[int(biggest_contour_cy-rh/2):int(biggest_contour_cy+rh/2), int(biggest_contour_cx-rw/2):int(biggest_contour_cx+rw/2)] #     digit_bin = cv2.resize(digit_bin,(digit_base_w, digit_base_h)) digit_bin = cv2.threshold(digit_bin, 128, 255, cv2.THRESH_BINARY)[1] #    digit = self.dbDigit(i, digit_bin) return True</span></span></code> </pre><br><img src="//habrastorage.org/files/688/a9e/86b/688a9e86b9924db691f7f2587e476772.png"><br><br><h5>  Number Recognition </h5><br>  Here is the <code>identifyDigits</code> method, which is called from the main program for each image: <br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">identifyDigits</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    ,     if self.result!='': return True #      if len(self.digits)==0: #    ,     if self.img == None: return False #   if not self.splitDigits(): return False #    ,      sess.commit() #     for digit in self.digits: digit.identifyDigit() #     str_digits = map(str,self.digits) #       ,        if '?' in str_digits: return False #       self.result = ''.join(str_digits) return True</span></span></code> </pre><br>  Everything is trivial, except for the <code>identifyDigit</code> method: <br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">identifyDigit</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    ,     if self.result!='?': return True if not KNN.recognize(self): #     ,       self.markDigitForManualRecognize() #   7- ,     "0",        ,   ,     if self.i==7: self.result = 0 return True return False else: self.use_for_training = True return True</span></span></code> </pre><br>  The <code>identifyDigit</code> method is also trivial, the recognition occurs in the <code>KNN.recognize</code> method, the algorithm for finding the nearest neighbors from OpenCV is used: <br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @staticmethod def recognize(dbdigit): # ,     if not KNN._trained: KNN.train() #   ,   ,     h,w = dbdigit.body.shape if h!=digit_base_h or w!=digit_base_w: dbdigit.markDigitForManualRecognize(use_for_training=False) mylogger.warn("Digit %d has bad resolution: %dx %d" % (dbdigit.i,h,w)) return False #        sample = dbdigit.body.reshape(digit_base_h*digit_base_w).astype(np.float32) test_data = np.array([sample]) #     , -  - 5 knn = KNN.getKNN() ret,result,neighbours,dist = knn.find_nearest(test_data,k=5) #     if result[0,0]!=neighbours[0,0]: #       dbdigit.markDigitForManualRecognize() return False if neighbours[0,1]!=neighbours[0,0] or neighbours[0,2]!=neighbours[0,0]: #         dbdigit.markDigitForManualRecognize() return False if dist[0,0]&gt;3000000 or dist[0,1]&gt;3500000 or dist[0,2]&gt;4000000: #         dbdigit.markDigitForManualRecognize() return False #    ,        dbdigit.result = str(int(ret)) return True</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Training is described in the method </font></font><code>KNN.train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @staticmethod def getKNN(): #      cv2.KNearest if KNN._knn==None: KNN._knn = cv2.KNearest() return KNN._knn @staticmethod def train(): knn = KNN.getKNN() #        train_digits = sess.query(Digit).filter(Digit.result!='?').filter_by(use_for_training=True).all() train_data = [] responses = [] for dbdigit in train_digits: h,w = dbdigit.body.shape #     if h*w != digit_base_h*digit_base_w: continue #     sample = dbdigit.body.reshape(digit_base_h*digit_base_w).astype(np.float32) train_data.append(sample) responses.append(int(dbdigit.result)) #  KNN knn.train(np.array(train_data), np.array(responses)) KNN._trained = True</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I cite an excerpt from the file </font></font><code>models.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, if the reader has questions about the work of some used, but not described functions.</font></font><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Missing descriptions of functions and methods in the article</font></font></b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Column, Integer, String, Text, Boolean, ForeignKey, DateTime, PickleType <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy.orm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> relationship <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy.ext.declarative <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> declarative_base <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_engine <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy.orm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sessionmaker <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> base64 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys dbengine = create_engine(<span class="hljs-string"><span class="hljs-string">'sqlite:///'</span></span> + os.path.dirname(__file__) + <span class="hljs-string"><span class="hljs-string">'/../db/images.db'</span></span>, echo=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) Session = sessionmaker(bind=dbengine) sess = Session() Base = declarative_base() <span class="hljs-comment"><span class="hljs-comment"># image class class Image(Base): __tablename__ = 'images' id = Column(Integer, primary_key=True) file_name = Column(String) img_link = Column(Text) download_url = Column(Text) check_time = Column(DateTime) result = Column(String(8)) digits = relationship("Digit", backref="image") img = None # source image digits_img = None # cropped source image def __init__(self, file_name): self.file_name = file_name self.check_time = datetime.datetime.strptime(file_name, "gaz.%Y-%m-%d.%H.%M.%S.jpg") self.result = "" def __repr__(self): return "&lt;Image ('%s','%s','%s')&gt;" % (self.id, self.file_name, self.result) def dbDigit(self, i, digit_img): digit = sess.query(Digit).filter_by(image_id=self.id).filter_by(i=i).first() if not digit: digit = Digit(self, i, digit_img) sess.add(digit) else: digit.body = digit_img return digit ##    # digit class class Digit(Base): __tablename__ = 'digits' id = Column(Integer, primary_key=True) image_id = Column(Integer, ForeignKey("images.id")) i = Column(Integer) body = Column(PickleType) result = Column(String(1)) use_for_training = Column(Boolean) def __init__(self, image, i, digit_img): self.image_id = image.id self.i = i self.body = digit_img self.markDigitForManualRecognize() def __repr__(self): return "%s" % self.result def markDigitForManualRecognize (self, use_for_training=False): self.result = '?' self.use_for_training = use_for_training def getEncodedBody (self): enc = cv2.imencode('.png',self.body)[1] b64 = base64.b64encode(enc) return b64 ##    Base.metadata.create_all(bind=dbengine) # function to get Image object by file_name and img def getImage(file_name): image = sess.query(Image).filter_by(file_name=file_name).first() if not image: image = Image(file_name) sess.add(image) # store image object to base sess.commit() image.digits_img = None return image def getLastRecognizedImage(): return sess.query(Image).filter(Image.result!='').order_by(Image.check_time.desc()).first() def dgDigitById(digit_id): digit = sess.query(Digit).get(digit_id) return digit</span></span></code> </pre></div></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For the analysis of indications and manual recognition, I also wrote a small web-interface on the </font></font><a href="http://ru.wikibooks.org/wiki/Flask"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Flask</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> framework </font><font style="vertical-align: inherit;">. I will not give the code here, who is interested, he can look at it, as well as the rest of the code on </font></font><a href="https://github.com/maleficxp/gaz-counter"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The interface has only two pages, one for viewing indications as a graph, for example, for a day or for a week: </font></font><br><img src="//habrastorage.org/files/30d/988/873/30d98887310b4152b6b3de8de643d707.png"><br><img src="//habrastorage.org/files/9c2/6f4/c83/9c26f4c831d444fa9051893d88954d23.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The second page for manual recognition of numbers. After I hammered the first 20-30 readings with my hands, the robot began to quite properly recognize the readings by itself. Occasionally, exceptions are still encountered and it is impossible to recognize the number, it is most often associated with the rotation of the dial: </font></font><br><img src="//habrastorage.org/files/fe1/f06/9a1/fe1f069a16354e3594fda28038e06939.png"><br><img src="//habrastorage.org/files/d2c/e4c/dbb/d2ce4cdbb5d04d8cb86fa0e655665512.png"><br><img src="//habrastorage.org/files/816/0aa/1fd/8160aa1fd053490eb9c29a5f0d53d558.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Then you have to enter the missing numbers with your hands:</font></font><br><img src="//habrastorage.org/files/52e/0d2/4aa/52e0d24aa915408da2ce4f15dbd47239.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Or you can simply ignore such readings, they will be skipped on the chart, and nothing bad will happen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are plans to further refine the script to send an e-mail if the last few readings match. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">That's all, what I wanted to tell you, thank you, if you have read to the end.</font></font></div><p>Source: <a href="https://habr.com/ru/post/220869/">https://habr.com/ru/post/220869/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../220853/index.html">Friday's announcement #FailOverConf. And buns to participants</a></li>
<li><a href="../220855/index.html">Mother's wisdom to guard your marketing</a></li>
<li><a href="../220859/index.html">New in the release of Kerio Control 8.3</a></li>
<li><a href="../220863/index.html">Extraction of data from the database 1C: problems with transfers</a></li>
<li><a href="../220865/index.html">A fistful of relays, or a computer on electromagnetic relays. Part 1 - ALU</a></li>
<li><a href="../220873/index.html">Homemade ring LED illuminator for video, photo and macro shooting</a></li>
<li><a href="../220875/index.html">Experience choosing and ordering iBeacon</a></li>
<li><a href="../220877/index.html">Qt 5.2, from desire to google play</a></li>
<li><a href="../220879/index.html">Addon for Overclock`a consciousness or flashback pro</a></li>
<li><a href="../220883/index.html">Practice refactoring. Envious features</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>