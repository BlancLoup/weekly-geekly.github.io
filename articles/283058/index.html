<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Meduza.io: what about the likes?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Once, while reading the news on Medusa, I noticed that different news has a different ratio of likes from Facebook and VKontakte. Some news is megapop...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Meduza.io: what about the likes?</h1><div class="post__text post__text-html js-mediator-article"><p>  Once, while reading the news on Medusa, I noticed that different news has a different ratio of likes from Facebook and VKontakte.  Some news is <a href="https://meduza.io/news/2016/04/11/umer-akter-albert-filozov">megapopular</a> on fb, and <a href="https://meduza.io/news/2016/04/09/demonstranty-v-londone-potrebovali-otstavki-premier-ministra-iz-za-ofshorov">other</a> people are shared only on VKontakte.  I wanted to look at this data, try to find interesting patterns in them.  Interested invite under the cat! </p><br><p><img src="https://habrastorage.org/files/1b4/6bb/ccf/1b46bbccf82b46abb3dd51f9f48976f1.png" alt="image"><a name="habracut"></a></p><br><h2>  Data scraping </h2><br><p>  The first thing you need to get data for analysis.  Anticipating the imminent release of Python + BeautifulSoup, I began to read the source code of the pages.  The disappointment waited pretty quickly: this data is not loaded immediately with html, but deferred.  Since I do not know how to javascript, I started looking for legs in the network connections of the page, and rather quickly came across a wonderful jellyfish API handle: </p><br><pre><code class="hljs ruby"><span class="hljs-symbol"><span class="hljs-symbol">https:</span></span>/<span class="hljs-regexp"><span class="hljs-regexp">/meduza.io/api</span></span><span class="hljs-regexp"><span class="hljs-regexp">/v3/social</span></span>?links=[<span class="hljs-string"><span class="hljs-string">"shapito/2016/05/03/poliem-vse-kislotoy-i-votknem-provod-v-rozetku"</span></span>]</code> </pre> <br><p>  The handle returns a nice looking json'ku: </p><br><p><img src="https://habrastorage.org/files/d2c/b02/4e1/d2cb024e129845bf9b4e4154dd7d96c5.png" alt="image"></p><br><p>  And of course, since <code>links</code> is an array, I immediately want to try to substitute several records there at once, and, hooray, we get the list of interest. </p><br><p>  I didn't even have to parse! </p><br><p>  Now I want to get information about the news itself.  Here I would like to thank the sirekanyan <a href="https://habrahabr.ru/users/sirekanyan/" class="user_link">barn</a> for his <a href="https://habrahabr.ru/post/259471/">article</a> , where he found another pen. </p><br><pre> <code class="hljs ruby"><span class="hljs-symbol"><span class="hljs-symbol">https:</span></span>/<span class="hljs-regexp"><span class="hljs-regexp">/meduza.io/api</span></span><span class="hljs-regexp"><span class="hljs-regexp">/v3/search</span></span>?chrono=news&amp;page=<span class="hljs-number"><span class="hljs-number">0</span></span>&amp;per_page=<span class="hljs-number"><span class="hljs-number">10</span></span>&amp;locale=ru</code> </pre> <br><p>  Experimentally it was possible to establish that the maximum value of the <code>per_page</code> parameter is 30, and about 752 <code>page</code> at the time of this writing.  An important test that the <code>social</code> handle will withstand all 30 documents, passed successfully. </p><br><p>  It remains only to unload!  I used a simple python script </p><br><pre> <code class="python hljs">stream = <span class="hljs-string"><span class="hljs-string">'https://meduza.io/api/v3/search?chrono=news&amp;page={page}&amp;per_page=30&amp;locale=ru'</span></span> social = <span class="hljs-string"><span class="hljs-string">'https://meduza.io/api/v3/social'</span></span> user_agent = <span class="hljs-string"><span class="hljs-string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.3411.123 YaBrowser/16.2.0.2314 Safari/537.36'</span></span> headers = {<span class="hljs-string"><span class="hljs-string">'User-Agent'</span></span> : user_agent } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_page_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(page)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#   ans = requests.get(stream.format(page = page), headers=headers).json() #     ans_social = requests.get(social, params = {'links' : json.dumps(ans['collection'])}, headers=headers).json() documents = ans['documents'] for url, data in documents.iteritems(): try: data['social'] = ans_social[url]['stats'] except KeyError: continue with open('res_dump/page{pagenum:03d}_{timestamp}.json'.format( pagenum = page, timestamp = int(time.time()) ), 'wb') as f: json.dump(documents, f, indent=2)</span></span></code> </pre> <br><p>  Just in case, I substituted a valid User-Agent, but everything works without it. </p><br><p>  Next, the script of my former colleague, <a href="https://habrahabr.ru/users/alexkuku/" class="user_link">alexkuku</a> , helped me to parallelize and visualize the process.  You can read more about the approach in his <a href="https://habrahabr.ru/post/277919/">post</a> , he allowed to do such monitoring here: </p><br><p><img src="https://habrastorage.org/files/7dc/3c4/c84/7dc3c4c84407472192cdd5fa191c7f67.gif" alt="image"></p><br><p>  The data was downloaded very quickly, in less than 10 minutes, no captcha or a noticeable slowdown.  Swung in 4 streams from one aypishnik, without any superstructures. </p><br><h2>  Data minining </h2><br><p>  So, at the output we got a big json'ka with data.  Now pound it in the pandas dataframe, and twist it in Jupyter. </p><br><p>  Load the necessary data: </p><br><pre> <code class="python hljs">df = pd.read_json(<span class="hljs-string"><span class="hljs-string">'database.json'</span></span>).T df = df.join(pd.DataFrame(df.social.to_dict()).T) df.pub_date = pd.DatetimeIndex(df.pub_date) df[<span class="hljs-string"><span class="hljs-string">'trust'</span></span>]=df.source.apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x.get(<span class="hljs-string"><span class="hljs-string">'trust'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> type(x) == dict <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)</code> </pre> <br><p>  Build a boxplot </p><br><pre> <code class="python hljs">df[[<span class="hljs-string"><span class="hljs-string">'fb'</span></span>, <span class="hljs-string"><span class="hljs-string">'tw'</span></span>,<span class="hljs-string"><span class="hljs-string">'vk'</span></span>]].plot.box(logy = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>);</code> </pre> <br><p><img src="https://habrastorage.org/files/8f2/8b2/f5d/8f28b2f5d8c64c85bbb1fcee8a445bb2.png" alt="image"></p><br><p>  Just a few conclusions: </p><br><ol><li>  Twitter has disabled the ability to watch the number of tweeted news.  :-( We'll have to do without it. </li><li>  Distribution, as expected, is extremely abnormal: there are very strong outliers, which are noticeable even on the log scale (hundreds of thousands of reposts). </li><li>  At the same time, the average number of reposts turned out to be quite close: the median is 24 and 17 (here and below, facebook and VKontakte, respectively), the distribution vk is somewhat more "smeared". </li></ol><br><p>  So who are the most super-repostnuyu news jellyfish?  Guess what? </p><br><p><img src="https://habrastorage.org/files/283/c3f/a2b/283c3fa2ba89495b8108d502be0b2570.jpg" alt="image"></p><br><div class="spoiler">  <b class="spoiler_title">Answer:</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/files/ab5/ccf/b7c/ab5ccfb7c7174f5f902f32e5c0d9876e.png" alt="image"></p><br><p>  Well, of course, the first is FB: there are foreign languages, Soviet newspapers, Serov.  And in the second 5nizza, "My orientation," the policy.  I do not know how for me, so everything is obvious! </p></div></div><br><p>  The only thing in which the preferences of the two social networks are similar: this is Irina Yarovaya, and yes Tsvetaeva with Guf. </p><br><p>  Now, I want to look at the scatter plot of two quantities: the data is expected to correlate well with each other. </p><br><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'logvk'</span></span>] = np.log10(df.vk) df[<span class="hljs-string"><span class="hljs-string">'logfb'</span></span>] = np.log10(df.fb) <span class="hljs-comment"><span class="hljs-comment">#      sns.regplot('logfb', 'logvk', data = df )</span></span></code> </pre> <br><p><img src="https://habrastorage.org/files/dbd/26e/7da/dbd26e7da13c4c8981645f3f1f3e6c43.png" alt="image"></p><br><pre> <code class="python hljs">sns.set(style=<span class="hljs-string"><span class="hljs-string">"ticks"</span></span>) sns.jointplot(<span class="hljs-string"><span class="hljs-string">'logfb'</span></span>, <span class="hljs-string"><span class="hljs-string">'logvk'</span></span>, data = df.replace([np.inf, -np.inf], np.nan).dropna(subset = [<span class="hljs-string"><span class="hljs-string">'logfb'</span></span>, <span class="hljs-string"><span class="hljs-string">'logvk'</span></span>]), kind=<span class="hljs-string"><span class="hljs-string">"hex"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/files/018/b8a/617/018b8a6179634523912a82887f03d32d.png" alt="image"></p><br><p>  It seems, you can see two clusters: one with the center in (2.3, 2.4), and the second one smeared around zero.  In general, there is no goal to analyze even low-frequency news (those that turned out to be uninteresting in social networks), so let's confine ourselves to recordings with more than 10 likes on both networks.  Do not forget to check that we got rid of a small number of observations. </p><br><pre> <code class="python hljs">stripped = df[(df.logfb &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>) &amp; (df.logvk &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>)] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">"Working with {0:.0%} of news, {1:.0%} of social network activity"</span></span>.format( float(len(stripped)) / len(df), float(stripped[[<span class="hljs-string"><span class="hljs-string">'vk'</span></span>, <span class="hljs-string"><span class="hljs-string">'fb'</span></span>]].sum().sum()) / df[[<span class="hljs-string"><span class="hljs-string">'vk'</span></span>, <span class="hljs-string"><span class="hljs-string">'fb'</span></span>]].sum().sum() ) <span class="hljs-comment"><span class="hljs-comment"># Working with 47% of news, 95% of social network activity</span></span></code> </pre> <br><p>  Density: </p><br><pre> <code class="python hljs">sns.jointplot(<span class="hljs-string"><span class="hljs-string">'logfb'</span></span>, <span class="hljs-string"><span class="hljs-string">'logvk'</span></span>, data = stripped, kind=<span class="hljs-string"><span class="hljs-string">"kde"</span></span>, size=<span class="hljs-number"><span class="hljs-number">7</span></span>, space=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/files/ada/417/6c8/ada4176c8d4c4b2da56be329d64c794a.png" alt="image"></p><br><h3>  findings </h3><br><ul><li>  Found a dense cluster of commenting ratios: 220 on facebook, 240 on VK. </li><li>  The cluster stretches out more on facebook: in this social network, people repost more range, as compared to VC, where the peak is quite ‚Äúnarrow‚Äù </li><li>  There is a mini cluster of facebook activity at 150 fb and about 70 vk, quite unusual </li></ul><br><p>  Now I want to look at this relationship in dynamics: perhaps it has changed. </p><br><pre> <code class="python hljs">by_month = stripped.set_index(<span class="hljs-string"><span class="hljs-string">'pub_date'</span></span>).groupby(pd.TimeGrouper(freq = <span class="hljs-string"><span class="hljs-string">'MS'</span></span>)).agg({<span class="hljs-string"><span class="hljs-string">'fb'</span></span>:sum, <span class="hljs-string"><span class="hljs-string">'vk'</span></span>:sum}) by_month.plot( kind = <span class="hljs-string"><span class="hljs-string">'area'</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/files/bad/b14/117/badb141172444fd1a9a2231b3ec4f9a6.png" alt="image"></p><br><p>  Interestingly, with a general increase in the volume of activity in social networks, Facebook is growing faster.  In addition, there is not visible some kind of explosive growth, which I would expect to see in Medusa.  The first months of activity was quite low, but by December 2014 the level had stabilized, the new growth began only a year later. </p><br><p>  Let's look at the dynamics of the density distribution of comments from two social networks: </p><br><p><img src="https://habrastorage.org/files/43e/08f/f0c/43e08ff0c8204e35ba4a3d36c7b5bcaf.gif" alt="image"></p><br><p>  Quite entertaining that the second cluster decreases with time, and rather is an artifact of the past. </p><br><p>  Finally, I want to check that the ratio of social networks does not change depending on the type of the document: Medusa has cards, stories, a tent, galleries, and also a training ground in addition to news. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">hexbin</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, color, **kwargs)</span></span></span><span class="hljs-function">:</span></span> cmap = sns.light_palette(color, as_cmap=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.hexbin(x, y, gridsize=<span class="hljs-number"><span class="hljs-number">20</span></span>, cmap=cmap, **kwargs) g = sns.FacetGrid(stripped.loc[::<span class="hljs-number"><span class="hljs-number">-1</span></span>], col=<span class="hljs-string"><span class="hljs-string">"document_type"</span></span>, margin_titles=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, size=<span class="hljs-number"><span class="hljs-number">5</span></span>, col_wrap = <span class="hljs-number"><span class="hljs-number">3</span></span>) g.map(hexbin, <span class="hljs-string"><span class="hljs-string">"logfb"</span></span>, <span class="hljs-string"><span class="hljs-string">"logvk"</span></span>, extent=[<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>]);</code> </pre> <br><p><img src="https://habrastorage.org/files/a1b/b4c/0fa/a1bb4c0faba94f348bbeeda44ad3dea2.png" alt="image"></p><br><p>  In general, it is clear that the data is quite homogeneous by classes, there are no noticeable distortions.  I would expect more social activity from the ‚Äútent‚Äù, but this effect is not observed. </p><br><p>  But, if you look at the breakdown by the <a href="https://www.facebook.com/AlShaburov/posts/10206190006647888">level of trust in the source</a> , it‚Äôs nice to see that an unreliable source is less popular on social networks, especially on Facebook: </p><br><p><img src="https://habrastorage.org/files/cb7/de5/0c5/cb7de50c54a64d5b834d240ada2d80f0.png" alt="image"></p><br><h2>  What's next? </h2><br><p>  On this my evening ended, and I went to sleep. </p><br><ul><li>  I tried to teach a simple Ridle regression on word2vec data from article headers.  You can look <a href="https://github.com/apetrin/meduza.io-parse-likes/blob/master/processing.ipynb">at the githaba</a> , there is no special predictive power there.  It seems that in order to predict the number of likes, it is worthwhile to at least train the model on the full news text. </li><li>  Based on these data, it is very good to catch the "bright" events that strongly stirred up the public.  In this case, the ratio fb / vk can be a good predictor for the type of news. </li><li>  Social media activity now seems to be just as important a KPI for a newsman as is attendance.  You can look at the authors / sources of popular posts, and on this base to evaluate the work.  The contrast in the credibility of the source speaks in favor of this idea: false news is less posted on facebook.  I think in one form or another this is already used in journalism. </li></ul><br><p>  <a href="https://github.com/apetrin/meduza.io-parse-likes">Github Code</a> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/283058/">https://habr.com/ru/post/283058/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../283046/index.html">Explanation of limitations of the demo version of PVS-Studio</a></li>
<li><a href="../283050/index.html">Creating RESTful services on Meteor</a></li>
<li><a href="../283052/index.html">How to hack Telegram and WhatsApp: special services are not needed</a></li>
<li><a href="../283054/index.html">Using the ES2015 standard in the Backbone.js library</a></li>
<li><a href="../283056/index.html">Data processing systems during penetration testing</a></li>
<li><a href="../283062/index.html">45 resources to help designers</a></li>
<li><a href="../283064/index.html">Birds and Unity3D, optimization attempt</a></li>
<li><a href="../283066/index.html">What does the CPU do when it has nothing to do</a></li>
<li><a href="../283070/index.html">The digest of news from the world of development on Unity</a></li>
<li><a href="../283072/index.html">JavaScript in Russian - pycckuu.js</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>