<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Kubernetes tips & tricks: speeding up the bootstrap of large databases</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="With this article we open a series of publications with practical instructions on how to make life easier for yourself (exploitation) and developers i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Kubernetes tips & tricks: speeding up the bootstrap of large databases</h1><div class="post__text post__text-html js-mediator-article">  With this article we open a series of publications with practical instructions on how to make life easier for yourself (exploitation) and developers in various situations that happen literally every day.  All of them are collected from real experience in solving problems from clients and have improved over time, but still do not pretend to be ideal - consider them rather as ideas and preparations. <br><br>  I will start with the ‚Äútrick‚Äù of preparing large database dumps like MySQL and PostgreSQL for their quick deployment for various needs - first of all, at the developer sites.  The context of the operations described below is our typical environment, which includes the working Kubernetes cluster and the use of GitLab (and <a href="https://github.com/flant/dapp">dapp</a> ) for CI / CD.  Go! <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The main pain in Kubernetes when using the feature branch is large databases when developers want to test / demonstrate their changes on a full (or almost complete) database from production.  For example: <br><br><ul><li>  There is an application with a database in MySQL for 1 TB and 10 developers who are developing their own features. </li><li>  Developers want individual test circuits and a couple more specific circuits for tests and / or demonstrations. </li><li>  In addition, there is a need to restore the night dump of the production-base in your test loop in a reasonable time - to reproduce the problem with the client or bug. </li><li>  Finally, there is an opportunity to lighten the size of the base by at least 150 GB - not so much, but still saving space.  Those.  we still need to somehow prepare the dump. </li></ul><br>  <i><b>Note</b> : Usually, we back up the database using MySQL using Percona innobackupex, which allows you to save all databases and users ... in short, everything that may be required.</i>  <i>It is this example that is discussed further in the article, although in general it makes absolutely no difference how exactly you make backups.</i> <br><br>  So, let's say we have a database backup.  What to do next? <br><br><h2>  Step 1: Preparing a new database from dump </h2><br>  First of all, we will create in Kubernetes <i>Deployment</i> , which will consist of two init-containers <i>(i.e., such <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers">special containers</a> that run up to the sweatsheets with the application and allow pre-configuration)</i> and one sweep. <br><br>  But where to place it?  We have a large database (1 TB) and we want to raise ten of its copies - we need a server with a large disk (10+ TB).  Order it separately for this task and mark the node with this server with a <code>dedicated: non-prod-db</code> <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">label</a> <code>dedicated: non-prod-db</code> .  At the same time, we use the same name <a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/"><i>taint</i></a> , who will say Kubernetes, that only applications that are resistant (have <i>tolerations</i> ) to it can roll to this node, that is, translating into the language Kubernetes, <code>dedicated Equal non-prod-db</code> . <br><br>  Using <code>nodeSelector</code> and <code>tolerations</code> select the required node (located on the server with a large disk): <br><br><pre> <code class="hljs cs"> nodeSelector: dedicated: non-prod-db tolerations: - key: <span class="hljs-string"><span class="hljs-string">"dedicated"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">operator</span></span>: <span class="hljs-string"><span class="hljs-string">"Equal"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">value</span></span>: <span class="hljs-string"><span class="hljs-string">"non-prod-db"</span></span> effect: <span class="hljs-string"><span class="hljs-string">"NoExecute"</span></span></code> </pre> <br>  ... and take a look at the contents of this site. <br><br><h3>  Init containers: get-bindump </h3><br>  We will call the first init-container <code>get-bindump</code> .  <code>emptyDir</code> is mounted to <code>emptyDir</code> (in <code>/var/lib/mysql</code> ), where the database dump received from the backup server will be added.  For this, the container has everything you need: SSH keys, backup server addresses.  This stage in our case takes about 2 hours. <br><br>  The description of this container in <i>Deployment is</i> as follows: <br><br><pre> <code class="hljs pgsql"> - <span class="hljs-type"><span class="hljs-type">name</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>-bindump image: db-dumps imagePullPolicy: <span class="hljs-keyword"><span class="hljs-keyword">Always</span></span> command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - <span class="hljs-type"><span class="hljs-type">name</span></span>: dump mountPath: /dump - <span class="hljs-type"><span class="hljs-type">name</span></span>: mysqlbindir mountPath: /var/lib/mysql - <span class="hljs-type"><span class="hljs-type">name</span></span>: id-rsa mountPath: /root/.ssh</code> </pre> <br>  The <code>get_bindump.sh</code> script used in the container: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3>  Init containers: prepare-bindump </h3><br>  After downloading the backup, the second init-container, <code>prepare-bindump</code> .  It runs <code>innobackupex --apply-log</code> (since the files are already available in <code>/var/lib/mysql</code> - thanks to <code>emptyDir</code> from <code>get-bindump</code> ) and the MySQL server starts. <br><br>  It is in this init-container that we do all the necessary conversions to the database, preparing it for the selected application: we clear the tables for which this is permissible, we change access within the database, etc.  Then turn off the MySQL server and simply archive the whole <code>/var/lib/mysql</code> to a tar.gz file.  As a result, the dump fits into a file with a size of 100 GB, which is already an order of magnitude smaller than the original 1 TB.  This stage takes about 5 hours. <br><br>  Description of the second init container in <i>Deployment</i> : <br><br><pre> <code class="hljs sql"> - name: <span class="hljs-keyword"><span class="hljs-keyword">prepare</span></span>-bindump image: db-dumps imagePullPolicy: <span class="hljs-keyword"><span class="hljs-keyword">Always</span></span> command: [ <span class="hljs-string"><span class="hljs-string">"/bin/sh"</span></span>, <span class="hljs-string"><span class="hljs-string">"-c"</span></span>, <span class="hljs-string"><span class="hljs-string">"/prepare_bindump.sh"</span></span> ] resources: limits: <span class="hljs-keyword"><span class="hljs-keyword">memory</span></span>: <span class="hljs-string"><span class="hljs-string">"5000Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"1"</span></span> requests: <span class="hljs-keyword"><span class="hljs-keyword">memory</span></span>: <span class="hljs-string"><span class="hljs-string">"5000Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"1"</span></span> volumeMounts: - <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>: dump mountPath: /dump - <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>: mysqlbindir mountPath: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/mysql - <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br>  The <code>prepare_bindump.sh</code> script used in it looks like this: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3>  Under </h3><br>  The final chord is the launch of the main flow, which occurs after the execution of the init containers.  In the pod we have a simple nginx, and through <code>emtpyDir</code> compressed and truncated dump of 100 GB is <code>emtpyDir</code> .  The function of this nginx is to give this dump. <br><br>  Configuration: <br><br><pre> <code class="hljs pgsql"> - <span class="hljs-type"><span class="hljs-type">name</span></span>: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: <span class="hljs-type"><span class="hljs-type">path</span></span>: /healthz port: <span class="hljs-number"><span class="hljs-number">80</span></span> scheme: HTTP timeoutSeconds: <span class="hljs-number"><span class="hljs-number">7</span></span> failureThreshold: <span class="hljs-number"><span class="hljs-number">5</span></span> volumeMounts: - <span class="hljs-type"><span class="hljs-type">name</span></span>: dump mountPath: /usr/<span class="hljs-keyword"><span class="hljs-keyword">share</span></span>/nginx/html - <span class="hljs-type"><span class="hljs-type">name</span></span>: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span> volumes: - <span class="hljs-type"><span class="hljs-type">name</span></span>: dump emptyDir: {} - <span class="hljs-type"><span class="hljs-type">name</span></span>: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">This is what the entire Deployment looks like with its initContainers ...</b> <div class="spoiler_text"><pre> <code class="hljs swift">--- apiVersion: apps/v1beta1 kind: <span class="hljs-type"><span class="hljs-type">Deployment</span></span> metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: <span class="hljs-number"><span class="hljs-number">0</span></span> revisionHistoryLimit: <span class="hljs-number"><span class="hljs-number">2</span></span> template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: <span class="hljs-string"><span class="hljs-string">"dedicated"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">operator</span></span>: <span class="hljs-string"><span class="hljs-string">"Equal"</span></span> value: <span class="hljs-string"><span class="hljs-string">"non-prod-db"</span></span> effect: <span class="hljs-string"><span class="hljs-string">"NoExecute"</span></span> initContainers: - name: <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>-bindump image: db-dumps imagePullPolicy: <span class="hljs-type"><span class="hljs-type">Always</span></span> command: [ <span class="hljs-string"><span class="hljs-string">"/bin/sh"</span></span>, <span class="hljs-string"><span class="hljs-string">"-c"</span></span>, <span class="hljs-string"><span class="hljs-string">"/get_bindump.sh"</span></span> ] resources: limits: memory: <span class="hljs-string"><span class="hljs-string">"5000Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"1"</span></span> requests: memory: <span class="hljs-string"><span class="hljs-string">"5000Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"1"</span></span> volumeMounts: - name: <span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> mountPath: /<span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> - name: mysqlbindir mountPath: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: <span class="hljs-type"><span class="hljs-type">Always</span></span> command: [ <span class="hljs-string"><span class="hljs-string">"/bin/sh"</span></span>, <span class="hljs-string"><span class="hljs-string">"-c"</span></span>, <span class="hljs-string"><span class="hljs-string">"/prepare_bindump.sh"</span></span> ] resources: limits: memory: <span class="hljs-string"><span class="hljs-string">"5000Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"1"</span></span> requests: memory: <span class="hljs-string"><span class="hljs-string">"5000Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"1"</span></span> volumeMounts: - name: <span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> mountPath: /<span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> - name: mysqlbindir mountPath: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/mysql - name: log mountPath: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: <span class="hljs-string"><span class="hljs-string">"1500Mi"</span></span> cpu: <span class="hljs-string"><span class="hljs-string">"400m"</span></span> lifecycle: preStop: exec: command: [<span class="hljs-string"><span class="hljs-string">"/usr/sbin/nginx"</span></span>, <span class="hljs-string"><span class="hljs-string">"-s"</span></span>, <span class="hljs-string"><span class="hljs-string">"quit"</span></span>] livenessProbe: httpGet: path: /healthz port: <span class="hljs-number"><span class="hljs-number">80</span></span> scheme: <span class="hljs-type"><span class="hljs-type">HTTP</span></span> timeoutSeconds: <span class="hljs-number"><span class="hljs-number">7</span></span> failureThreshold: <span class="hljs-number"><span class="hljs-number">5</span></span> volumeMounts: - name: <span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: <span class="hljs-literal"><span class="hljs-literal">false</span></span> volumes: - name: <span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: <span class="hljs-number"><span class="hljs-number">0600</span></span> secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: <span class="hljs-type"><span class="hljs-type">Service</span></span> metadata: name: somedb-db-<span class="hljs-built_in"><span class="hljs-built_in">dump</span></span> spec: clusterIP: <span class="hljs-type"><span class="hljs-type">None</span></span> selector: app: db-dumps ports: - name: http port: <span class="hljs-number"><span class="hljs-number">80</span></span></code> </pre> </div></div><br>  Additional notes: <br><br><ol><li>  In our case, <b>every night</b> we prepare a new dump using the scheduled job in GitLab.  Those.  every night we automatically roll out this <i>Deployment</i> , which pulls up a fresh dump and prepares it for distribution to all developers' test environments. </li><li>  Why do we also add volume <code>/dump</code> to init containers (and there is a check for existence of <code>/dump/version.txt</code> in the script)?  This is done in case the server is restarted, on which it runs under.  The containers will be restarted and without this check, the dump will begin to download again.  If we have already prepared a dump once, then the next start (in case of server reboot) the flag file <code>/dump/version.txt</code> will report this. </li><li>  What kind of image <code>db-dumps</code> ?  We collect it with a dapp and its <a href="https://habr.com/company/flant/blog/351838/"><code>Dappfile</code></a> looks like this: <br><br><pre> <code class="hljs sql">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "<span class="hljs-keyword"><span class="hljs-keyword">Install</span></span> percona repositories<span class="hljs-string"><span class="hljs-string">" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "</span></span><span class="hljs-keyword"><span class="hljs-keyword">Add</span></span> repository <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> borgbackup<span class="hljs-string"><span class="hljs-string">" apt_repository: repo="</span></span>ppa:costamagnagianfranco/borgbackup<span class="hljs-string"><span class="hljs-string">" codename="</span></span>xenial<span class="hljs-string"><span class="hljs-string">" update_cache=yes - name: "</span></span><span class="hljs-keyword"><span class="hljs-keyword">Add</span></span> repository <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> mysql <span class="hljs-number"><span class="hljs-number">5.6</span></span><span class="hljs-string"><span class="hljs-string">" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "</span></span><span class="hljs-keyword"><span class="hljs-keyword">Install</span></span> packages<span class="hljs-string"><span class="hljs-string">" apt: name: "</span></span>{{<span class="hljs-string"><span class="hljs-string">`{{ item }}`</span></span>}}<span class="hljs-string"><span class="hljs-string">" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "</span></span><span class="hljs-keyword"><span class="hljs-keyword">Add</span></span> get_bindump.sh<span class="hljs-string"><span class="hljs-string">" copy: content: | {{ .Files.Get "</span></span>.dappfiles/get_bindump.sh<span class="hljs-string"><span class="hljs-string">" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "</span></span><span class="hljs-keyword"><span class="hljs-keyword">Add</span></span> prepare_bindump.sh<span class="hljs-string"><span class="hljs-string">" copy: content: | {{ .Files.Get "</span></span>.dappfiles/prepare_bindump.sh<span class="hljs-string"><span class="hljs-string">" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</span></span></code> </pre> </li></ol><br><h2>  Step 2: Run the database in the developer's environment </h2><br>  When the MySQL database rolls out in the developer‚Äôs test environment, it has a button in GitLab that launches the Redundant <i>Deployment</i> 's with MySQL with the <code>RollingUpdate.maxUnavailable: 0</code> strategy: <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">How is this implemented?</b> <div class="spoiler_text">  In GitLab, when you click on <i>reload db</i> , <i>Deployment</i> deploys with this specification: <br><br><pre> <code class="hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br>  Those.  we say Kubernetes to update <i>Deployment</i> (create a new one under) and at the same time ensure that at least one of them is live.  Since, when creating a new one, it has init-containers, while they are working, the new one <b>does not</b> become the <i>Running</i> status, which means the old one continues to work.  And only at the moment that it started up itself under MySQL (and completed the readiness probe), the traffic switches to it, and the old one (with the old database) is deleted. <br><br>  Details of this scheme can be found in the following materials: <br><br><ul><li>  <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/">Performing a Rolling Update</a> <i>(Kubernetes documentation)</i> ; </li><li>  <a href="https://tachingchen.com/blog/kubernetes-rolling-update-with-deployment/">Rolling Updates with Kubernetes Deployments</a> <i>(Ta-Ching Chen)</i> ; </li><li>  <a href="https://container-solutions.com/kubernetes-deployment-strategies/">Kubernetes deployment strategies</a> <i>(Container Solutions)</i> . </li></ul></div></div><br>  The selected approach allows us to wait until the new dump is downloaded, unzipped and launched, and only after that the old one will be removed from MySQL.  Thus, while we are preparing a new dump, we are quietly working with the old base. <br><br>  The init container of this <i>Deployment</i> uses the following command: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br>  Those.  we download the compressed database dump, which was prepared in step 1, unzip it to <code>/var/lib/mysql</code> , and then start under <i>Deployment</i> , in which MySQL is started with the data already prepared.  All this takes about 2 hours. <br><br><div class="spoiler">  <b class="spoiler_title">And Deployment looks like this ...</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">apiVersion: apps/v1beta1 kind: Deployment metadata: <span class="hljs-type"><span class="hljs-type">name</span></span>: mysql spec: strategy: rollingUpdate: maxUnavailable: <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">template</span></span>: metadata: labels: service: mysql spec: imagePullSecrets: - <span class="hljs-type"><span class="hljs-type">name</span></span>: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" <span class="hljs-keyword"><span class="hljs-keyword">operator</span></span>: "Equal" <span class="hljs-keyword"><span class="hljs-keyword">value</span></span>: "non-prod-db" effect: "NoExecute" initContainers: - <span class="hljs-type"><span class="hljs-type">name</span></span>: getdump image: mysql-<span class="hljs-keyword"><span class="hljs-keyword">with</span></span>-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql <span class="hljs-type"><span class="hljs-type">name</span></span>: datadir - mountPath: /etc/mysql/debian.cnf <span class="hljs-type"><span class="hljs-type">name</span></span>: debian-cnf subPath: debian.cnf env: - <span class="hljs-type"><span class="hljs-type">name</span></span>: DUMP_URL <span class="hljs-keyword"><span class="hljs-keyword">value</span></span>: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - <span class="hljs-type"><span class="hljs-type">name</span></span>: mysql image: mysql:<span class="hljs-number"><span class="hljs-number">5.6</span></span> resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: <span class="hljs-number"><span class="hljs-number">3306</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span>: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql <span class="hljs-type"><span class="hljs-type">name</span></span>: datadir - mountPath: /etc/mysql/debian.cnf <span class="hljs-type"><span class="hljs-type">name</span></span>: debian-cnf subPath: debian.cnf env: - <span class="hljs-type"><span class="hljs-type">name</span></span>: MYSQL_ROOT_PASSWORD <span class="hljs-keyword"><span class="hljs-keyword">value</span></span>: "password" volumes: - <span class="hljs-type"><span class="hljs-type">name</span></span>: datadir emptyDir: {} - <span class="hljs-type"><span class="hljs-type">name</span></span>: debian-cnf configMap: <span class="hljs-type"><span class="hljs-type">name</span></span>: somedb-debian-cnf <span class="hljs-comment"><span class="hljs-comment">--- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</span></span></code> </pre> </div></div><br><h2>  Results </h2><br>  It turns out that we always have <i>Deployment</i> , which rolls out every night and does the following: <br><br><ul><li>  gets a fresh database dump; </li><li>  somehow it prepares for correct work in a test environment (for example, trancheytit some tables, replaces real user data, gets the necessary users, etc.); </li><li>  provides each developer with the opportunity to click on a button in CI to roll out such a prepared database into their namespace in <i>Deployment</i> - thanks to the <i>Service</i> available in it, the database will be available at <code>mysql</code> (for example, this may be the name of the service in namespace). </li></ul><br>  For the example we have considered, creating a dump from a real replica takes about 6 hours, preparing a ‚Äúbase image‚Äù takes 7 hours, and updating the database in the developer‚Äôs environment takes 2 hours.  Since the first two actions are performed ‚Äúin the background‚Äù and invisible to developers, in fact they can deploy a prod version of the database (with a size of 1 TB) <b>in the same 2 hours</b> . <br><br>  Questions, criticism and corrections to the proposed scheme and its components are welcome in the comments! <br><br>  PS Of course, we understand that in the case of VMware and some other tools, it would be possible to manage creating a virtual snapshot and launching a new virtual virus from snapshot (which is even faster), but this option does not include preparing the base, taking into account which time ... Not to mention the fact that not everyone has the opportunity or desire to use commercial products. <br><br><h2>  Pps </h2><br>  Other K8s series tips &amp; tricks: <br><br><ul><li>  " <a href="https://habr.com/company/flant/blog/417509/">Access to dev-sites</a> ". </li></ul><br>  Read also in our blog: <br><br><ul><li>  ‚Äú <a href="https://habr.com/company/flant/blog/345580/">Build and heat applications in Kubernetes using dapp and GitLab CI</a> ‚Äù; </li><li>  " <a href="https://habr.com/company/flant/blog/336212/">Practice with dapp.</a>  <a href="https://habr.com/company/flant/blog/336212/">Part 1: Build simple applications</a> "; </li><li>  " <a href="https://habr.com/company/flant/blog/336170/">Practice with dapp.</a>  <a href="https://habr.com/company/flant/blog/336170/">Part 2. Deploying Docker images in Kubernetes with the help of Helm</a> ‚Äù; </li><li>  ‚Äú <a href="https://habr.com/company/flant/blog/328756/">Orchestration of the CockroachDB DBMS at Kubernetes</a> ‚Äù; </li><li>  " <a href="https://habr.com/company/flant/blog/331188/">Our experience with Kubernetes in small projects</a> " <i>(video of the report, which includes an introduction to the technical device Kubernetes);</i> </li><li>  ‚Äú <a href="https://habr.com/company/flant/blog/330198/">Useful utilities when working with Kubernetes</a> ‚Äù. </li></ul></div><p>Source: <a href="https://habr.com/ru/post/417509/">https://habr.com/ru/post/417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../417499/index.html">"Yandex" began work on creating its own system of "smart home"</a></li>
<li><a href="../417501/index.html">Layfkhaki manufacturing double-layer boards (LUT)</a></li>
<li><a href="../417503/index.html">What a web developer should remember to do everything on SEO</a></li>
<li><a href="../417505/index.html">Intel has released fixes for new ME firmware vulnerabilities</a></li>
<li><a href="../417507/index.html">Tricks for linking and downloading Mach-O files</a></li>
<li><a href="../417511/index.html">Intel acquired eASIC - developer of "structural ASIC"</a></li>
<li><a href="../417513/index.html">Analogs in Python and JavaScript. Part two</a></li>
<li><a href="../417515/index.html">What I learned by creating 100 games in 5 years</a></li>
<li><a href="../417517/index.html">Intel history pages. Photo chronicle and quiz</a></li>
<li><a href="../417521/index.html">Validation of SSL certificates for revocation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>