<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Everything you know about word2vec is not true</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A classic explanation of word2vec as a Skip-gram architecture with a negative sample in the original scientific article and countless blog posts looks...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Everything you know about word2vec is not true</h1><div class="post__text post__text-html js-mediator-article">  A classic explanation of word2vec as a Skip-gram architecture with a negative sample in the original scientific article and countless blog posts looks like this: <br><br><pre><code class="plaintext hljs">while(1) { 1. vf = vector of focus word 2. vc = vector of focus word 3. train such that (vc . vf = 1) 4. for(0 &lt;= i &lt;= negative samples): vneg = vector of word *not* in context train such that (vf . vneg = 0) }</code> </pre> <br>  Indeed, if you google [word2vec skipgram], what we see: <br><br><ul><li>  <a href="https://en.wikipedia.org/wiki/Word2vec">A wikipedia page that describes a high-level algorithm</a> <br></li><li>  <a href="https://www.tensorflow.org/tutorials/representation/word2vec">Tensorflow page with the same explanation</a> <br></li><li>  <a href="https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b">Blog Towards Data Science c description of the same algorithm</a> , and the list goes on. </li></ul><br>  <b>But all these implementations are wrong</b> . <br><a name="habracut"></a><br>  The original implementation of word2vec on C works differently and <i>is completely different</i> from this.  Those who professionally introduce systems with word2 word attachments do one of the following: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  Directly call the original implementation of C. <br></li><li>  The <code>gensim</code> implementation is <code>gensim</code> , which is <i>transliterated</i> from C source to the extent that the variable names match. </li></ol><br>  Indeed, <code>gensim</code> is the <i>only true implementation known to me in C.</i> <br><br><h3>  C implementation </h3><br>  The C implementation actually supports <i>two vectors for each word</i> .  One vector for the word in focus, and the second for the word in context.  (Seems familiar? True, the GloVe developers borrowed the idea from word2vec, without mentioning this fact!) <br><br>  The implementation in code C is exceptionally literate: <br><br><ul><li>  The <code>syn0</code> array contains a vector word embedding, if it comes across as a word in focus.  Here is a <b>random initialization</b> . <br><br><pre> <code class="cpp hljs">https:<span class="hljs-comment"><span class="hljs-comment">//github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L369 for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) { next_random = next_random * (unsigned long long)25214903917 + 11; syn0[a * layer1_size + b] = (((next_random &amp; 0xFFFF) / (real)65536) - 0.5) / layer1_size; }</span></span></code> </pre> </li><li>  The other array, <code>syn1neg</code> , contains the word vector when it appears as a context word.  Here <b>initialization is zero</b> . <br></li><li>  During training (Skip-gram, a negative sample, although other cases are about the same), we first select the word focus.  It persists throughout the course of training in positive and negative examples.  The gradients of the focus vector accumulate in the buffer and are applied to the focal word after training both in positive and negative examples. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (negative &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (d = <span class="hljs-number"><span class="hljs-number">0</span></span>; d &lt; negative + <span class="hljs-number"><span class="hljs-number">1</span></span>; d++) { <span class="hljs-comment"><span class="hljs-comment">// if we are performing negative sampling, in the 1st iteration, // pick a word from the context and set the dot product target to 1 if (d == 0) { target = word; label = 1; } else { // for all other iterations, pick a word randomly and set the dot //product target to 0 next_random = next_random * (unsigned long long)25214903917 + 11; target = table[(next_random &gt;&gt; 16) % table_size]; if (target == 0) target = next_random % (vocab_size - 1) + 1; if (target == word) continue; label = 0; } l2 = target * layer1_size; f = 0; // find dot product of original vector with negative sample vector // store in f for (c = 0; c &lt; layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2]; // set g = sigmoid(f) (roughly, the actual formula is slightly more complex) if (f &gt; MAX_EXP) g = (label - 1) * alpha; else if (f &lt; -MAX_EXP) g = (label - 0) * alpha; else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]) * alpha; // 1. update the vector syn1neg, // 2. DO NOT UPDATE syn0 // 3. STORE THE syn0 gradient in a temporary buffer neu1e for (c = 0; c &lt; layer1_size; c++) neu1e[c] += g * syn1neg[c + l2]; for (c = 0; c &lt; layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1]; } // Finally, after all samples, update syn1 from neu1e https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L541 // Learn weights input -&gt; hidden for (c = 0; c &lt; layer1_size; c++) syn0[c + l1] += neu1e[c];</span></span></code> </pre> </li></ul><br><h3>  Why random and zero initialization? </h3><br>  Once again, since this is not at all explained in the original articles <i>and anywhere else on the Internet</i> , I can only guess. <br><br>  The hypothesis is that when negative samples come from the whole text and are not weighted by frequency, you can choose <i>any word</i> , and most often a word, the <i>vector of which is not trained at all</i> .  If this vector has a value, then it randomly shifts the really important word into focus. <br><br>  The point is to set all negative examples to zero, so that the representation of another vector will <i>be</i> affected <i>only by vectors that occur more or less frequently</i> . <br><br>  In fact, this is quite clever, and I have never thought about how important initialization strategies are. <br><br><h3>  Why am I writing this? </h3><br>  I spent two months of my life trying to reproduce word2vec as described in the original scientific publication and countless articles on the Internet, but it did not work out.  I could not achieve the same results as word2vec, although I tried my best. <br><br>  I could not imagine that the authors of the publication literally fabricated an algorithm that does not work, while the implementation does something completely different. <br><br>  In the end, I decided to study the source code.  For three days I was confident that I understood the code incorrectly, since literally everyone on the Internet was talking about a different implementation. <br><br>  I have no idea why the original publication and articles on the Internet do not say anything about the <i>real</i> work mechanism of word2vec, so I decided to publish this information myself. <br><br>  It also explains the radical choice of GloVe to set separate vectors for a negative context - they just did what word2vec does, but told people about it :). <br><br>  Is it a scientific hoax?  I don't know, hard question.  But honestly, I'm incredibly angry.  Probably, I will never be able to take seriously the explanation of algorithms in machine learning: the next time I will go <i>straight</i> to watch the source. </div><p>Source: <a href="https://habr.com/ru/post/454926/">https://habr.com/ru/post/454926/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../454914/index.html">Use Yii2. We write another CMS or an attempt to significantly speed up development with minimal overhead</a></li>
<li><a href="../454916/index.html">Neural network architecture for the implementation of the RL algorithm with the ability to specify simultaneously running actions</a></li>
<li><a href="../454918/index.html">How to combine backups of two retailers on SAP in 12 hours</a></li>
<li><a href="../454920/index.html">Frontend performance: parse important metrics</a></li>
<li><a href="../454922/index.html">Tales about foreign customers and their peculiarities of work in Russia after the law on PD</a></li>
<li><a href="../454928/index.html">A way to bypass the Windows lock screen on RDP sessions</a></li>
<li><a href="../454930/index.html">Garbage Collection in V8: How the New Orinoco GC Works</a></li>
<li><a href="../454936/index.html">Vivaldi: ad blocking should be user selectable</a></li>
<li><a href="../454938/index.html">Developing your own core for embedding into the FPGA processor system</a></li>
<li><a href="../45494/index.html">University tour Opera. Kiev</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>