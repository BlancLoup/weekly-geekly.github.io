<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Meet GStreamer: Output Devices</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello again, habrauser, which is interesting GStreamer! Today we will talk about the output devices (sink) of various media data, write a primitive pl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Meet GStreamer: Output Devices</h1><div class="post__text post__text-html js-mediator-article">  Hello again, habrauser, which is interesting GStreamer!  Today we will talk about the output devices (sink) of various media data, write a primitive player to listen to the radio and record the stream to a file, and learn a lot of new things. <br>  The output device (sink) is an element for outputting a signal somewhere, be it a sound card, a file, a video card, or a network interface.  At its core, an output device is the exact opposite of a data source, and, unlike data sources, output devices have only one pad - sink. <br>  Consider the output device in more detail. <br><a name="habracut"></a><br><h4>  Go </h4><br><h5>  1. fakesink </h5><br>  This device is similar in its meaning to fakesrc - it does nothing.  fakesink is used to output the signal "into the void". <br>  Honestly, I myself can not think of where it can be used, therefore, I do not find much usefulness in this device. <br>  Usage example: <br><pre><code class="bash hljs">gst-launch-1.0 fakesrc ! fakesink</code> </pre> <br><h5>  2. fdsink </h5><br>  The fdsink device is used to output a stream to a file descriptor; it, like fdsrc, has only one parameter ‚Äî fd, which must contain the file descriptor number.  By default, displays the stream in STDOUT.  Naturally, there is little benefit from this element, and there is little point in applying it in real projects. <br>  Usage example: <br><pre> <code class="bash hljs">gst-launch-1.0 filesrc location=/foo/bar.mp3 ! fdsink | gst-launch-1.0 fdsrc ! decodebin ! autoaudiosink</code> </pre><br><h5>  3. alsasink, pulsesink, oss4sink / osssink, jackaudiosink, autoaudiosink </h5><br>  These elements are used to output the stream to the sound card by using the necessary audio subsystem.  Of the parameters, you can only note the device - it must contain the ID of the sound card, which, in turn, will be displayed stream.  From the above list of modules, only autoaudiosink stands aside and has one feature - it automatically selects where and through which sound subsystem to output the stream, so it does not have the device parameter. <br>  Examples of using: <br><pre> <code class="bash hljs">gst-launch-1.0 filesrc location=/foo/bar.mp3 ! decodebin ! alsasink device=<span class="hljs-string"><span class="hljs-string">"hw:0"</span></span> gst-launch-1.0 filesrc location=/foo/bar.mp3 ! decodebin ! pulsesink gst-launch-1.0 filesrc location=/foo/bar.mp3 ! decodebin ! autoaudiosink</code> </pre><br><h5>  4. filesink </h5><br>  As you probably already guessed, this device is used to output a stream to a file.  It can be used for different purposes, for example: record a radio stream, record a video stream from a web-camera, and also an audio stream from a sound card.  Everything else, this device is simply necessary in the case of using GStreamer as a tool for converting files. <br>  We will not consider the properties of this element in detail, since they are similar to the properties of the filesrc element that we met in the last article.  One difference is that filesink has an append parameter.  The append parameter is used to append a stream to the end of an existing file instead of overwriting it from the beginning. <br>  Usage example: <br><pre> <code class="bash hljs">gst-launch-1.0 v4l2src num-buffers=1 ! jpegenc ! filesink location=/tmp/capture1.jpeg</code> </pre><br>  <i>This example illustrates the creation of a photo with the first device that supports v4l2, and then saving the snapshot to /tmp/capture1.jpeg.</i> <br><h5>  5. multifilesink </h5><br>  The multifilesink element is the exact opposite of the multifilesrc element that we met in the last article, and it is used to output the stream to different files.  The parameters of this element are similar to the parameters of multifilesrc, so we will not dwell on them. <br>  Usage example: <br><pre> <code class="bash hljs">gst-launch-1.0 v4l2src num-buffers=10 ! jpegenc ! multifilesink location=/tmp/capture%d.jpeg</code> </pre><br>  <i>This example illustrates creating 10 photos and saving them to files capture0.jpeg-capture9.jpeg.</i> <br><h5>  6. giosink </h5><br>  And this element is the exact opposite of the giosrc element ‚Äî it is used to output a stream to a file via GIO.  Like giosrc, giosink has a location parameter that contains the path to the file to which you want to record the stream. <br>  Usage example: <br><pre> <code class="bash hljs">gst-launch-1.0 location ! giosink location=file:///foo/bar.raw</code> </pre><br><h5>  7. ximagesink and xvimagesink </h5><br>  These elements are used to output the video signal via the X server.  These elements can be used both for viewing video ‚Äúin console‚Äù and for implementing video output in applications.  The difference between the elements is small, but there is, and it consists of two points - ximagesink uses only the X server for output, and xvimagesink uses libxv.  Also, xvimagesink has a bit more options.  Consider them: <br><h6>  display </h6><br>  The name of the X-display, for example: 0,: ‚Äã‚Äã1,: 2 ... <br><h6>  pixel-aspect-ratio </h6><br>  This parameter indicates the aspect ratio, for example 2/1.  The default is 1/1. <br><h6>  force-aspect-ratio </h6><br>  In some cases, explicitly specifying the pixel-aspect-ratio may not work (if the ‚Äúnegotiations‚Äù between the elements resulted in the need to leave the original pixel-apect-ratiio), and this property corrects this ‚Äúproblem‚Äù. <br><br>  <u>The following are properties that are only available from xvimagesink.</u> <br><h6>  brightness, contrast, hue, saturation </h6><br>  Having translated the names of these properties into Russian (‚Äúbrightness-contrast-hue-saturation), one can understand their purpose.  Values ‚Äã‚Äãcan range from -1000 to 1000. <br><h6>  device </h6><br>  The sequence number of the video card with which you want to display video. <br><h6>  double-buffer </h6><br>  This property turns on and off the use of <a href="http://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B2%25D0%25BE%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25B1%25D1%2583%25D1%2584%25D0%25B5%25D1%2580%25D0%25B8%25D0%25B7%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F">double buffering</a> . <br><h6>  colorkey, autopaint-colorkey </h6><br>  These properties are used to control the color of the overlay on which the video is drawn.  The colorkey must contain gint with the color code, and autopaint-colorkey includes a ‚Äúfill‚Äù overlay with this color. <br>  <b>Note:</b> <br>  There is no explanation in the documentation about what color is, but, most likely, the color is indicated in the RGB format, according to the formula (((RR &amp; 0xff) &lt;&lt; 16) |  ((GG &amp; 0xff) &lt;&lt; 8) |  (BB &amp; 0xff). <br><h6>  draw-borders </h6><br>  This property enables or disables drawing a black stroke in places where a ‚Äúvoid‚Äù has formed when using the force-aspect-ratio. <br>  Examples of using: <br><pre> <code class="bash hljs">gst-launch-1.0 videotestsrc ! ximagesink gst-launch-1.0 videotestsrc ! xvimagesink</code> </pre><br><h5>  8. aasink and cacasink </h5><br>  These elements are probably not relevant, and can be used either by oldfags or by those who want to show "what Linux can do," although I may be mistaken.  Both of these elements allow you to display video through the libaa and libcaca libraries, that is, display the video in the form of ASCII art.  There is only one difference between them: libaa displays black and white characters, and libcaca displays color. <br>  We will not dwell on the parameters of these elements, since there is no practical benefit from them (IMHO). <br>  Examples of using: <br><pre> <code class="bash hljs">gst-launch-1.0 videotestsrc ! aasink gst-launch-1.0 videotestsrc ! aacasink</code> </pre><br><h6>  9. gdkpixbufsink </h6><br>  This element outputs the video stream to the <a href="https://developer.gnome.org/gdk-pixbuf/unstable/gdk-pixbuf-The-GdkPixbuf-Structure.html">GdkPixbuf</a> object, which is accessible via the read-only last-pixbuf property.  For what it is needed - I can not even imagine. <br><br><h4>  Examples </h4><br>  As an example, we will use the player from the previous article, but with the addition of a new feature - writing the stream to a file. <br><div class="spoiler">  <b class="spoiler_title">example2.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#env python2 # coding=utf-8 import gi gi.require_version("Gst", "1.0") gi.require_version("Gtk", "3.0") from gi.repository import Gst from gi.repository import Gtk from gi.repository import GObject import os import signal import argparse Gst.init("") signal.signal(signal.SIGINT, signal.SIG_DFL) GObject.threads_init() def parse_args(): parser = argparse.ArgumentParser(prog='example1.py') parser.add_argument('--volume', help='  (0-100) (default: 100)', type=int, default=100) parser.add_argument('--output', help='        (default: /tmp/out.ogg)', type=str, default='/tmp/out.ogg') parser.add_argument('location') args = parser.parse_args() return args class RecorderBin(Gst.Bin): def __init__(self, name=None): super(RecorderBin, self).__init__(name=name) self.vorbisenc = Gst.ElementFactory.make("vorbisenc", "vorbisenc") self.oggmux = Gst.ElementFactory.make("oggmux", "oggmux") self.filesink = Gst.ElementFactory.make("filesink", "filesink") self.add(self.vorbisenc) self.add(self.oggmux) self.add(self.filesink) self.vorbisenc.link(self.oggmux) self.oggmux.link(self.filesink) self.sink_pad = Gst.GhostPad.new("sink", self.vorbisenc.get_static_pad("sink")) self.add_pad(self.sink_pad) def set_location(self, location): self.filesink.set_property("location", location) class Player(): def __init__(self, args): self.pipeline = self.create_pipeline(args) self.args = args ##       ##      message_bus = self.pipeline.get_bus() message_bus.add_signal_watch() message_bus.connect('message', self.message_handler) ##   self.pipeline.get_by_name('volume').set_property('volume', args.volume / 100.) def create_source(self, location): """create_source(str) -&gt; Gst.Element""" if not location.startswith('http') and not os.path.exists(location): raise IOError("File %s doesn't exists" % location) if location.startswith('http'): source = Gst.ElementFactory.make('souphttpsrc', 'source') else: source = Gst.ElementFactory.make('filesrc', 'source') source.set_property('location', location) return source def create_pipeline(self, args): """create_pipeline() -&gt; Gst.Pipeline""" pipeline = Gst.Pipeline() ##      source = self.create_source(args.location) decodebin = Gst.ElementFactory.make('decodebin', 'decodebin') audioconvert = Gst.ElementFactory.make('audioconvert', 'audioconvert') volume = Gst.ElementFactory.make('volume', 'volume') audiosink = Gst.ElementFactory.make('autoaudiosink', 'autoaudiosink') ##  tee     tee = Gst.ElementFactory.make('tee', 'tee') ## decodebin   pad',     ##   def on_pad_added(decodebin, pad): pad.link(audioconvert.get_static_pad('sink')) decodebin.connect('pad-added', on_pad_added) ##      pipeline elements = [source, decodebin, audioconvert, volume, audiosink, tee] [pipeline.add(k) for k in elements] ##      : ## +-&gt; volume -&gt; autoaudiosink ## *src* -&gt; (decodebin + audioconvert) -&gt; tee -&gt; | ## [ +-&gt; vorbisenc -&gt; oggmux -&gt; filesink ] source.link(decodebin) audioconvert.link_pads('src', tee, 'sink') tee.link_pads('src_0', volume, 'sink') volume.link(audiosink) return pipeline def play(self): self.pipeline.set_state(Gst.State.PLAYING) recorder = RecorderBin('recorder') self.pipeline.add(recorder) self.pipeline.get_by_name('tee').link_pads('src_1', recorder, 'sink') recorder.set_location(self.args.output) def message_handler(self, bus, message): """ """ struct = message.get_structure() if message.type == Gst.MessageType.EOS: print(' .') Gtk.main_quit() elif message.type == Gst.MessageType.TAG and message.parse_tag() and struct.has_field('taglist'): print('GStreamer    -') taglist = struct.get_value('taglist') for x in range(taglist.n_tags()): name = taglist.nth_tag_name(x) print(' %s: %s' % (name, taglist.get_string(name)[1])) else: pass if __name__ == "__main__": args = parse_args() player = Player(args) player.play() Gtk.main()</span></span></code> </pre><br></div></div><br>  <b>Note:</b> <br>  This example (like the example from the previous article) does not work in Ubuntu 13.10, falling from segfault (see <a href="https://bugs.launchpad.net/ubuntu/%2Bsource/rhythmbox/%2Bbug/1198375">lp: 1198375</a> ). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Consider what happens here.  For convenience and logical separation, we create the RecorderBin container, into which we place three elements - vorbisenc, oggmux and filesink.  The vorbisenc and oggmux elements are needed to encode a RAW stream into <a href="http://ru.wikipedia.org/wiki/Vorbis">vorbis</a> format and to wrap it in an <a href="http://ru.wikipedia.org/wiki/Ogg_(%25D0%25BA%25D0%25BE%25D0%25BD%25D1%2582%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B5%25D1%2580)">ogg</a> container, respectively.  Details on the containers (bin), we will not stop, just remind you that the containers are complete elements that perform any action in the pipeline. <br>  In RecorderBin, all three elements are linked to each other sequentially, according to the scheme: <br><br><pre> <code class="bash hljs">vorbisenc ‚Üí oggmux ‚Üí filesink</code> </pre><br>  Next, we create the tee element necessary for multiplexing the stream, since most of the elements, as you remember, often have only one input and one output, and the tee element solves the problem that occurs when you need to "divide" the signal and send it to two different points (sound card and file in our case). <br>  After that, we link the src_0 element tee with the sink input of the volume element, and in the play method, after setting the status to PLAYING, add our RecorderBin to the pipeline and link the src_1 output of the tee element with sink RecorderBin. <br>  Logically, it would be possible to link everything to create_pipeline, but for some reason GStreamer blocked the entire pipeline when adding another sink element before setting PLAYING status, and I could not find a solution to this problem. <br><br><h4>  Conclusion </h4><br>  Today we reviewed almost all available devices for stream output.  In subsequent articles, we will consider the so-called.  filters are elements that perform various work related to thread processing.  Filters include various encoders and decoders, de / multiplexers, various audio / video filters and other service elements. <br><br><h4>  Literature </h4><br><ol><li>  <a href="http://gstreamer.freedesktop.org/data/doc/gstreamer/head/manual/html/index.html">GStreamer Application Development Manual</a> </li><li>  <a href="http://gstreamer.freedesktop.org/data/doc/gstreamer/head/gstreamer-plugins/html/">GStreamer Core Plugins Reference Manual</a> </li><li>  <a href="http://gstreamer.freedesktop.org/data/doc/gstreamer/head/gst-plugins-base-plugins/html/">GStreamer Base Plugins Reference Manual</a> </li><li>  <a href="http://gstreamer.freedesktop.org/data/doc/gstreamer/head/gst-plugins-good-plugins/html/">GStreamer Good Plugins Reference Manual</a> </li></ol><br><br><div class="spoiler">  <b class="spoiler_title">PS</b> <div class="spoiler_text">  Dear colleagues, friends, and simple habrazhiteli, I apologize for the fact that he published the post in six months, and not a week, as promised.  I will not voice the exact timing of the publication of the next post this time.  I am afraid once again not to keep the promise, but I will try to prepare it in the near future. <br></div></div><br>  PPS: Sample sources are available on <a href="https://github.com/POPSuL/gst-examples">GitHub</a> . <br><br>  <a href="http://habrahabr.ru/post/179167/">Previous article</a> </div><p>Source: <a href="https://habr.com/ru/post/204014/">https://habr.com/ru/post/204014/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../204004/index.html">Graphics and typography of the new 2GIS</a></li>
<li><a href="../204006/index.html">Runetology (213): Stanislav Ustenko, general director of media holding C-Media</a></li>
<li><a href="../204008/index.html">Mining and how it works: materiel</a></li>
<li><a href="../204010/index.html">Subtotals of a stock exchange startup</a></li>
<li><a href="../204012/index.html">What is important for creating AI 2: ‚ÄúDependence. View from the neural network ¬ª</a></li>
<li><a href="../204016/index.html">What if successful startups were just lucky?</a></li>
<li><a href="../204018/index.html">Barnes & Noble readers and tablets sale</a></li>
<li><a href="../204020/index.html">Who got up earlier, that and ... 99 tickets for IDCEE 2014 for ‚Ç¨ 99!</a></li>
<li><a href="../204026/index.html">Example of circuit simulation in Cassandra 2.0 in CQL3</a></li>
<li><a href="../204028/index.html">Migrating photos or another queue on MySQL</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>