<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Open machine learning course. Theme 6. Construction and selection of signs</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The Open Data Science community welcomes course participants! 


 As part of the course, we already met several key machine learning algorithms. Howev...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Open machine learning course. Theme 6. Construction and selection of signs</h1><div class="post__text post__text-html js-mediator-article"><p>  The Open Data Science community welcomes course participants! </p><br><p>  As part of the course, we already met several key machine learning algorithms.  However, before moving on to more sophisticated algorithms and approaches, I would like to take a step aside and talk about preparing data for training the model.  The well-known principle of garbage in - garbage out is 100% applicable to any machine learning task;  Any experienced analyst can recall examples from practice when a simple model trained on well-prepared data performed better than a smart ensemble built on insufficiently pure data. </p><br><p>  <strong>UPD:</strong> now the course is in English under the brand <a href="http://mlcourse.ai/">mlcourse.ai</a> with <a href="https://medium.com/open-machine-learning-course">articles</a> on Medium, and materials on Kaggle ( <a href="https://www.kaggle.com/kashnitsky/mlcourse">Dataset</a> ) and on <a href="">GitHub</a> . </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/files/cd7/2d8/d16/cd72d8d16d8f409898546ba5d397240f.jpg"></div><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">List of articles series</b> <div class="spoiler_text"><ol><li>  <a href="https://habrahabr.ru/company/ods/blog/322626/">Primary data analysis with Pandas</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/323210/">Visual data analysis with Python</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/322534/">Classification, decision trees and the method of nearest neighbors</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/323890/">Linear classification and regression models</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/324402/">Compositions: bagging, random forest</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Construction and selection of signs</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325654/">Teaching without a teacher: PCA, clustering</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/326418/">Training in gigabytes with Vowpal Wabbit</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/327242/">Time Series Analysis with Python</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/327250/">Gradient boosting</a> </li></ol></div></div><br><p>  In today's article, I would like to briefly describe three similar, but different tasks: </p><br><ul><li>  feature extraction and feature engineering - turning data that is specific to the subject area into vectors that are understandable for the model; </li><li>  feature transformation - data transformation to improve the accuracy of the algorithm; </li><li>  feature selection - cutting off unnecessary features. </li></ul><br><p>  Separately, I note that in this article there will be almost no formulas, but there will be relatively a lot of code. </p><br><p> In some examples, datasets will be used from the company <a href="https://www.renthop.com/">Renthop</a> , used in the <a href="https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries">Two Sigma Connect: Rental Listing Inquires competition</a> on Kaggle.  In this problem, you need to predict the popularity of ads for real estate rental, i.e.  solve the problem of classification into three classes <code>['low', 'medium', 'high']</code> .  To evaluate the solution, the log loss metric is used (the smaller the better).  Those who do not have an account on Kaggle, will have to register;  also for downloading data you need to accept the rules of competition. </p><br><pre> <code class="hljs pgsql">#        train.json.zip  Kaggle    <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> <span class="hljs-type"><span class="hljs-type">json</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd #     Renthop <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">open</span></span>(<span class="hljs-string"><span class="hljs-string">'train.json'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> raw_data: data = <span class="hljs-type"><span class="hljs-type">json</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">load</span></span>(raw_data) df = pd.DataFrame(data)</code> </pre> <br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/files/58e/152/f83/58e152f8398743d6abca8f287a4c715f.jpg"></div><br><br><ul><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Feature Extraction</a> <br><ul><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Texts</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Images</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Geodata</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">date and time</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Time series, web and more</a> </li></ul></li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Feature transformations</a> <br><ul><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Normalization and distribution change</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Interactions</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Filling gaps</a> </li></ul></li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Feature Selection</a> <br><ul><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Statistical approaches</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Selection using models</a> </li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Bust</a> </li></ul></li><li>  <a href="https://habrahabr.ru/company/ods/blog/325422/">Homework</a> </li></ul><br><h2 id="izvlechenie-priznakov-feature-extraction">  Feature Extraction </h2><br><p>  In life, data rarely comes in the form of ready-made matrices, so any task begins with the extraction of signs.  Sometimes, of course, it is enough to read the csv file and convert it to <code>numpy.array</code> , but these are happy exceptions.  Let's look at some of the popular data types from which to extract attributes. </p><br><h3 id="teksty">  Texts </h3><br><p>  The text is the most obvious example of data in a free format;  There are enough methods of working with text so that they do not fit into one article.  Nevertheless, we‚Äôll go over the most popular ones. </p><br><p>  Before working with the text, it must be tokenized.  Tokenization involves splitting the text into tokens - in the simplest case, these are just words.  But, by making it too simple a regular schedule ("in the forehead"), we can lose some of the meaning: "Nizhny Novgorod" is not two tokens, but one.  But the call "steal, kill!"  can be divided into two tokens in vain.  There are ready tokenizers that take into account the peculiarities of the language, but they can be wrong, especially if you work with specific texts (professional vocabulary, jargon, typos). </p><br><p>  After tokenization in most cases, you need to think about reduction to normal form.  We are talking about stemming and / or lemmatization - these are similar processes used to process word forms.  You can read about the difference between them <a href="http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">here</a> . </p><br><p>  So, we turned the document into a sequence of words, you can begin to turn them into vectors.  The simplest approach is called Bag of Words: we create a vector with a length in the dictionary, for each word we count the number of entries in the text and substitute this number for the corresponding position in the vector.  In code, it looks even simpler than in words: </p><br><div class="spoiler">  <b class="spoiler_title">Bag of Words without extra libraries</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> reduce <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np texts = [[<span class="hljs-string"><span class="hljs-string">'i'</span></span>, <span class="hljs-string"><span class="hljs-string">'have'</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'cat'</span></span>], [<span class="hljs-string"><span class="hljs-string">'he'</span></span>, <span class="hljs-string"><span class="hljs-string">'have'</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'dog'</span></span>], [<span class="hljs-string"><span class="hljs-string">'he'</span></span>, <span class="hljs-string"><span class="hljs-string">'and'</span></span>, <span class="hljs-string"><span class="hljs-string">'i'</span></span>, <span class="hljs-string"><span class="hljs-string">'have'</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'cat'</span></span>, <span class="hljs-string"><span class="hljs-string">'and'</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'dog'</span></span>]] <span class="hljs-keyword"><span class="hljs-keyword">dictionary</span></span> = list(enumerate(<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(reduce(lambda x, y: x + y, texts)))) def vectorize(<span class="hljs-type"><span class="hljs-type">text</span></span>): vector = np.zeros(len(<span class="hljs-keyword"><span class="hljs-keyword">dictionary</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, word <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">dictionary</span></span>: num = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-type"><span class="hljs-type">text</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> w == word: num += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> num: vector[i] = num <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> vector <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> texts: print(vectorize(t))</code> </pre> </div></div><br><p>  Also, the idea is well illustrated with a picture: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/549/810/b75/549810b757f94e4784b6780d84a1112a.png"></div><br><p>  This is an extremely naive implementation.  In real life, you need to take care of the stop words, the maximum dictionary size, the effective data structure (usually text data is converted into sparse vectors) ... </p><br><p>  Using algorithms like Vag of Words, we lose the order of words in the text, which means that the texts "i have no cows" and "no, i have cows" will be identical after vectorization, although they are opposite semantically.  To avoid this problem, you can take a step back and change the approach to tokenization: for example, use N-grams (combinations of N consecutive terms). </p><br><div class="spoiler">  <b class="spoiler_title">Check in practice</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CountVectorizer <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect = CountVectorizer(ngram_range=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect.fit_transform([<span class="hljs-string"><span class="hljs-string">'no i have cows'</span></span>, <span class="hljs-string"><span class="hljs-string">'i have no cows'</span></span>]).toarray() <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">array</span></span>([[<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]], dtype=int64) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect.vocabulary_ <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: {<span class="hljs-string"><span class="hljs-string">'cows'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">'have'</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'no'</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect = CountVectorizer(ngram_range=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect.fit_transform([<span class="hljs-string"><span class="hljs-string">'no i have cows'</span></span>, <span class="hljs-string"><span class="hljs-string">'i have no cows'</span></span>]).toarray() <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">array</span></span>([[<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]], dtype=int64) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect.vocabulary_ <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: {<span class="hljs-string"><span class="hljs-string">'cows'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">'have'</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'have cows'</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'have no'</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">'no'</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-string"><span class="hljs-string">'no cows'</span></span>: <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-string"><span class="hljs-string">'no have'</span></span>: <span class="hljs-number"><span class="hljs-number">6</span></span>}</code> </pre> </div></div><br><p>  Also note that it is not necessary to operate with words: in some cases it is possible to generate N-grams from letters (for example, such an algorithm will take into account the similarity of related words or typos). </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.spatial.distance <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> euclidean <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : vect = CountVectorizer(ngram_range=(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), analyzer=<span class="hljs-string"><span class="hljs-string">'char_wb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : n1, n2, n3, n4 = vect.fit_transform([<span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]).toarray() <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : euclidean(n1, n2) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">3.1622776601683795</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : euclidean(n2, n3) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">2.8284271247461903</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : euclidean(n3, n4) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">3.4641016151377544</span></span></code> </pre> <br><p>  The development of the Bag of Words idea: words that are rarely found in the corpus (in all the documents considered in this dataset), but are present in this particular document, may turn out to be more important.  Then it makes sense to increase the weight of more specific words, in order to separate them from general topics.  This approach is called TF-IDF, you can‚Äôt write it in ten lines anymore, so those who are interested can get acquainted with the details in external sources like <a href="https://en.wikipedia.org/wiki/Tf%25E2%2580%2593idf">wiki</a> .  The default option is: </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>,</mo><mi>D</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>m</mi><mi>i</mi><mi>d</mi><mi>D</mi><mtext>&amp;#xA0;</mtext><mi>m</mi><mi>i</mi><mi>d</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>d</mi><mo>,</mo><mi>t</mi><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mn>1</mn></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="43.264ex" height="2.66ex" viewBox="0 -832 18627.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="345" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="869" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-28" x="1419" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="1809" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2C" x="2170" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-44" x="2615" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-29" x="3444" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-3D" x="4111" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6C" x="5417" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6F" x="5716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-67" x="6201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="6932" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-72" x="7482" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-61" x="7934" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-63" x="8463" y="0"></use><g transform="translate(8897,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="1128" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="1474" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-44" x="1997" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="3076" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="3954" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="4300" y="0"></use></g><g transform="translate(13720,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="523" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-28" x="1074" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="1463" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2C" x="1987" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="2432" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-29" x="2793" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2B" x="3405" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-31" x="4406" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>&nbsp;</mtext><mi>l</mi><mi>o</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>m</mi><mi>i</mi><mi>d</mi><mi>D</mi><mtext>&nbsp;</mtext><mi>m</mi><mi>i</mi><mi>d</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mi>f</mi><mo stretchy="false">(</mo><mi>d</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> idf (t, D) = \ log \ frac {\ mid D \ mid} {df (d, t) + 1} </script></p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>D</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mi>t</mi><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>,</mo><mi>D</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.729ex" height="2.66ex" viewBox="0 -832 16674.7 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="361" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="912" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="1257" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="1781" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-28" x="2331" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="2721" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2C" x="3082" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="3527" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2C" x="4051" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-44" x="4496" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-29" x="5324" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-3D" x="5992" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="7048" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="7409" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-28" x="7960" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="8349" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2C" x="8711" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="9156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-29" x="9680" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="10319" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="10681" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="11026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-65" x="11905" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-73" x="12371" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="12841" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-64" x="13186" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-66" x="13710" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-28" x="14260" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-74" x="14650" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2C" x="15011" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-44" x="15456" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-29" x="16285" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>d</mi><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> tfidf (t, d, D) = tf (t, d) \ times idf (t, D) </script></p><br><p>  Analogs of Bag of words can also be found outside of word problems: for example, bag of sites in a <a href="https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2">competition</a> that we hold is Catch Me If You Can.  You can search for other examples - <a href="https://www.kaggle.com/xiaoml/talkingdata-mobile-user-demographics/bag-of-app-id-python-2-27392">bag of apps</a> , <a href="http://www.interdigital.com/download/58540a46e3b9659c9f000372">bag of events</a> . </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/files/ec1/273/bc7/ec1273bc740145ec92e25991415b1644.jpg"></div><br><br><p>  Using such algorithms, you can get quite a working solution to a simple problem, such a baseline.  However, for non-lovers of the classics, there are newer approaches.  The most popular method of the new wave is Word2Vec, but there are also alternatives (Glove, Fasttext ...). </p><br><p>  Word2Vec is a special case of Word Embedding algorithms.  Using Word2Vec and similar models, we can not only vectorize words into a space of large dimension (usually several hundred), but also compare their semantic proximity.  A classic example of operations on vectorized views: king - man + woman = queen. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/158/230/d1a/158230d1ad839c517d1855ea005bd590.gif"></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>  It should be understood that this model, of course, does not have an understanding of words, but simply tries to place vectors in such a way that words used in the general context are located close to each other.  If this is not taken into account, then you can come up with many curiosities: for example, find the opposite of Hitler by multiplying the corresponding vector by -1. </p><br><p>  Such models should be trained on very large data sets so that the coordinates of the vectors truly reflect the semantics of the words.  To solve your problems, you can download a pre-trained model, for example, <a href="https://github.com/3Top/word2vec-api">here</a> . </p><br><p>  Similar methods, by the way, are used in other areas (for example, in bioinformatics).  From completely unexpected applications - <a href="https://jaan.io/food2vec-augmented-cooking-machine-intelligence/">food2vec</a> . </p><br><h3 id="izobrazheniya">  Images </h3><br><p>  In working with images, everything is both simpler and more complex at the same time.  Easier, because you can often not think at all and use one of the popular pre-trained networks;  more difficult, because if you still need to understand in detail, then this rabbit hole will be damn deep.  However, first things first. </p><br><p>  At a time when the GPU was weaker, and the "renaissance of neural networks" had not yet happened, the generation of features from the images was a separate complex area.  To work with pictures, it was necessary to work at a low level, defining, for example, angles, area boundaries, and so on.  Experienced computer vision specialists could draw many parallels between older approaches and the neural network hipsterism: in particular, convolutional layers in modern networks are very similar to <a href="https://habrahabr.ru/post/208092/">Haar cascades</a> .  Not being experienced in this matter, I will not even try to transfer knowledge from public sources, leave a couple of links to the <a href="http://scikit-image.org/docs/stable/api/skimage.feature.html">skimage</a> and <a href="http://simplecv.readthedocs.io/en/latest/SimpleCV.Features.html">SimpleCV libraries</a> and go straight to our days. </p><br><p>  Often, some convolution network is used for problems related to images.  You can not think of the architecture and not train the network from scratch, but take the pre-trained state of the art network, the weights of which can be downloaded from open sources.  To adapt it to their task, the date Cynthists practice the so-called.  fine tuning: the last fully connected layers of the network ‚Äúcome off‚Äù, new ones are added instead, selected for a specific task, and the network is trained on new data.  But if you want to simply vectorize the image for some of your purposes (for example, use some kind of non-network classifier) ‚Äã‚Äã- just tear off the last layers and use the output of the previous layers: </p><br><pre> <code class="hljs python"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ResNet50 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.misc <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> face <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np resnet_settings = {<span class="hljs-string"><span class="hljs-string">'include_top'</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, <span class="hljs-string"><span class="hljs-string">'weights'</span></span>: <span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>} resnet = ResNet50(**resnet_settings) img = image.array_to_img(face()) <span class="hljs-comment"><span class="hljs-comment">#   ! img = img.resize((224, 224)) #          x = image.img_to_array(img) x = np.expand_dims(x, axis=0) #   , ..        features = resnet.predict(x)</span></span></code> </pre> <br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/200/12a/d64/20012ad648ebf0f8519b6465d9e9bda7.png"></div><br>  <em>Classifier trained in one dataset and adapted for another by ‚Äútearing off‚Äù the last layer and adding a new one in return</em> <br><p>  However, you should not get hung up on neural network methods.  Some signs generated by hands may be useful even today: for example, predicting the popularity of renting an apartment, you can assume that bright apartments attract more attention, and make a sign "average pixel value".  You can get inspired by examples in the <a href="http://pillow.readthedocs.io/en/3.1.x/reference/ImageStat.html">documentation of the relevant libraries</a> . </p><br><p>  If a text is expected in a picture, it can also be read without unfolding a complex neural network with its own hands: for example, using <a href="https://github.com/madmaze/pytesseract">pytesseract</a> . </p><br><pre> <code class="hljs vhdl"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : import pytesseract <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from PIL import Image <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : import requests <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from io import BytesIO <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : img = <span class="hljs-symbol"><span class="hljs-symbol">'http</span></span>://ohscurrent.org/wp-content/uploads/<span class="hljs-number"><span class="hljs-number">2015</span></span>/<span class="hljs-number"><span class="hljs-number">09</span></span>/domus-<span class="hljs-number"><span class="hljs-number">01</span></span>-google.jpg' #      <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : img = requests.get(img) ...: img = Image.<span class="hljs-keyword"><span class="hljs-keyword">open</span></span>(BytesIO(img.content)) ...: <span class="hljs-literal"><span class="hljs-literal">text</span></span> = pytesseract.image_to_string(img) ...: <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-literal"><span class="hljs-literal">text</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-symbol"><span class="hljs-symbol">'Google</span></span>'</code> </pre> <br><p>  We must understand that pytesseract is far from a panacea: </p><br><pre> <code class="hljs vhdl">#       Renthop <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : img = requests.get(<span class="hljs-symbol"><span class="hljs-symbol">'https</span></span>://photos.renthop.com/<span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">8393298_6</span></span>acaf11f030217d05f3a5604b9a2f70f.jpg') ...: img = Image.<span class="hljs-keyword"><span class="hljs-keyword">open</span></span>(BytesIO(img.content)) ...: pytesseract.image_to_string(img) ...: <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-symbol"><span class="hljs-symbol">'Cunveztible</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span>}¬ª'</code> </pre> <br><p>  Another case where neural networks will not help is to extract traits from the meta-information.  But EXIF ‚Äã‚Äãcan store a lot of useful information: the manufacturer and model of the camera, the resolution, the use of flash, the geo-coordinates of the survey, the software used for processing and much more. </p><br><h3 id="geodannye">  Geodata </h3><br><p>  Geographic data is not so often encountered in tasks, but it is also useful to master the basic techniques for working with them, especially since there are also enough ready-made solutions in this area. </p><br><p>  Geodata are most often presented in the form of addresses or pairs "latitude + longitude", i.e.  points.  Depending on the task, you may need two operations opposite to each other: geocoding (recovery of a point from an address) and reverse geocoding (vice versa).  Both are possible with external APIs like Google Maps or OpenStreetMap.  Different geocoders have their own characteristics, the quality varies from region to region.  Fortunately, there are universal libraries like <a href="https://github.com/geopy/geopy">geopy</a> , which act as wrappers for many external services. </p><br><p>  If there is a lot of data, it is easy to rest against the limits of external APIs.  Yes, and receiving information via HTTP is not always the best solution for speed.  Therefore, it is worth bearing in mind the possibility of using the local version of OpenStreetMap. </p><br><p>  If there is little data, there is enough time, and there is no desire to extract the tricked signs, then you can not bother with OpenStreetMap and use <code>reverse_geocoder</code> : </p><br><pre> <code class="hljs delphi"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : import reverse_geocoder <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> revgc <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : revgc.search((df.latitude, df.longitude)) Loading formatted geocoded <span class="hljs-keyword"><span class="hljs-keyword">file</span></span>... <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: [OrderedDict([(<span class="hljs-string"><span class="hljs-string">'lat'</span></span>, <span class="hljs-string"><span class="hljs-string">'40.74482'</span></span>), (<span class="hljs-string"><span class="hljs-string">'lon'</span></span>, <span class="hljs-string"><span class="hljs-string">'-73.94875'</span></span>), (<span class="hljs-string"><span class="hljs-string">'name'</span></span>, <span class="hljs-string"><span class="hljs-string">'Long Island City'</span></span>), (<span class="hljs-string"><span class="hljs-string">'admin1'</span></span>, <span class="hljs-string"><span class="hljs-string">'New York'</span></span>), (<span class="hljs-string"><span class="hljs-string">'admin2'</span></span>, <span class="hljs-string"><span class="hljs-string">'Queens County'</span></span>), (<span class="hljs-string"><span class="hljs-string">'cc'</span></span>, <span class="hljs-string"><span class="hljs-string">'US'</span></span>)])]</code> </pre> <br><p>  Working with geocoding, we must not forget that the addresses may contain typos, respectively, it is worth spending time cleaning.  There is usually less typo in the coordinates, but not everything is good with them: GPS can ‚Äúmake noise‚Äù by the nature of data, and in some places (tunnels, blocks of skyscrapers ...) is pretty strong.  If the data source is a mobile device, it is worth considering that in some cases geolocation is not determined by GPS, but by WiFi networks in the area, which leads to holes in space and teleportation: one of Chicago may suddenly turn out to be a set of points describing a journey through Manhattan. . </p><br><div class="spoiler">  <b class="spoiler_title">Teleportation hypotheses</b> <div class="spoiler_text"><p>  WiFi location tracking is based on a combination of SSID and MAC addresses, which can coincide at completely different points (for example, the federal provider has standardized the firmware of routers to within the MAC address and places them in different cities).  There are more trivial reasons, like moving a company with their routers to another office. </p></div></div><br><p>  The point is usually not in the open field, but among the infrastructure - here you can give free rein to your imagination and begin to invent signs using life experience and knowledge of the domain area.  The proximity of the point to the metro, the number of floors of the building, the distance to the nearest store, the number of ATMs in a radius - within the framework of one task, you can come up with dozens of signs and extract them from various external sources.  For tasks outside the urban infrastructure, signs from more specific sources may be useful: for example, elevation above sea level. </p><br><p>  If two or more points are interconnected, it may be worthwhile to extract the signs from the route between them.  It will be useful and the distance (it is worth looking at the great circle distance, and the "fair" distance, calculated on the road graph), and the number of turns along with the ratio of left and right, and the number of traffic lights, junctions, bridges.  For example, in one of my tasks, a sign that I called ‚Äúroad complexity‚Äù showed itself quite well - the distance calculated by the graph and divided by GCD. </p><br><h3 id="data-i-vremya">  date and time </h3><br><p>  It would seem that work with the date and time should be standardized due to the prevalence of relevant signs, but the pitfalls remain. </p><br><p>  Let's start with the days of the week - they are easy to turn into 7 dummy variables using one-hot coding.  In addition, it is useful to select a separate sign for the weekend. </p><br><pre> <code class="hljs pgsql">df[<span class="hljs-string"><span class="hljs-string">'dow'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'created'</span></span>].apply(lambda x: x.date().weekday()) df[<span class="hljs-string"><span class="hljs-string">'is_weekend'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'created'</span></span>].apply(lambda x: <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.date().weekday() <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  In some tasks, additional calendar features may be needed: for example, cash withdrawal may be tied to the day of salary issuance, and the purchase of a travel card - by the beginning of the month.  And in a good way, working with time data, you need to have on hand a calendar with public holidays, abnormal weather conditions and other important events. </p><br><div class="spoiler">  <b class="spoiler_title">Professional unfamiliar humor</b> <div class="spoiler_text"><ul><li>  What do Chinese New Year, New York Marathon, Gay Pride Parade and Trump's inauguration have in common? </li><li>  They all need to make a calendar of potential anomalies. </li></ul></div></div><br><p>  But with an hour (minute, day of the month ...) everything is not so rosy.  If we use the hour as a real variable, we slightly contradict the nature of the data: 0 &lt;23, although 02.01 0:00:00&gt; 01.01 23:00:00.  For some tasks, this may be critical.  If you encode them as categorical variables, you can produce a bunch of signs and lose information about proximity: the difference between 22 and 23 will be the same as between 22 and 7. </p><br><p>  There are more esoteric approaches to such data.  For example, a projection on a circle with the subsequent use of two coordinates. </p><br><pre> <code class="hljs pgsql">def make_harmonic_features(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>, period=<span class="hljs-number"><span class="hljs-number">24</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> *= <span class="hljs-number"><span class="hljs-number">2</span></span> * np.pi / period <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.cos(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>), np.sin(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>)</code> </pre> <br><p>  This transformation preserves the distance between points, which is important for some algorithms based on distance (kNN, SVM, k-means ...) </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.spatial <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> distance <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : euclidean(make_harmonic_features(<span class="hljs-number"><span class="hljs-number">23</span></span>), make_harmonic_features(<span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">0.5176380902050424</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : euclidean(make_harmonic_features(<span class="hljs-number"><span class="hljs-number">9</span></span>), make_harmonic_features(<span class="hljs-number"><span class="hljs-number">11</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">0.5176380902050414</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : euclidean(make_harmonic_features(<span class="hljs-number"><span class="hljs-number">9</span></span>), make_harmonic_features(<span class="hljs-number"><span class="hljs-number">21</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">2.0</span></span></code> </pre> <br><p>  However, the difference between such coding methods can usually be caught only in the third decimal place in the metric, not earlier. </p><br><h3 id="vremennye-ryady-veb-i-prochee">  Time series, web and more </h3><br><p>  I did not have enough time to work with the time series, so I will leave a link to the <a href="https://github.com/blue-yonder/tsfresh">library to automatically generate the signs from the time series</a> and go on. </p><br><p>  If you work with the web, then you usually have information about the user's User Agent.  This is a storehouse of information. <br>  First, from there, first of all, you need to extract the operating system.  Second, make the sign <code>is_mobile</code> .  Third, look at the browser. </p><br><div class="spoiler">  <b class="spoiler_title">Example of extracting traits from user agent</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua = <span class="hljs-string"><span class="hljs-string">'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/56.0.2924.76 Chrome/ ...: 56.0.2924.76 Safari/537.36'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> user_agents <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua = user_agents.parse(ua) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.is_bot <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.is_mobile <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.is_pc <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.os.<span class="hljs-keyword"><span class="hljs-keyword">family</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-string"><span class="hljs-string">'Ubuntu'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.os.<span class="hljs-keyword"><span class="hljs-keyword">version</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: () <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.browser.<span class="hljs-keyword"><span class="hljs-keyword">family</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-string"><span class="hljs-string">'Chromium'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.os.<span class="hljs-keyword"><span class="hljs-keyword">version</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: () <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : ua.browser.<span class="hljs-keyword"><span class="hljs-keyword">version</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">2924</span></span>)</code> </pre> </div></div><br><p>  As in other domain domains, you can think up your own attributes based on conjectures about the nature of the data.  At the time of this writing, Chromium 56 was new, and after a while this version of the browser can only be saved by those who haven‚Äôt rebooted this browser for a long time.  Why, then, do not enter the sign "lagging behind the latest version of the browser"? </p><br><p>  In addition to the OS and browser, you can look at the referrer (not always available), <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Language">http_accept_language,</a> and other meta-information. </p><br><p>  The next most useful information is an IP address from which you can extract at least a country, and preferably another city, provider, connection type (mobile / landline).  You need to understand that there are a variety of proxies and outdated databases, so a sign may contain noise.  Network administration gurus may try to extract even more advanced features: for example, make assumptions about the <a href="https://habrahabr.ru/post/216295/">use of VPN</a> .  By the way, it‚Äôs nice to combine data from the IP address with http_accept_language: if the user sits at the Chilean proxy, and the browser locale is ru_RU, something here is unclean and worthy of one in the corresponding column in the table ( <code>is_traveler_or_proxy_user</code> ). </p><br><p>  In general, there are so many domain specificities in a particular area that it does not fit in one head.  Therefore, I urge dear readers to share their experiences and tell in comments about the extraction and generation of signs in their work. </p><br><h2 id="preobrazovaniya-priznakov-feature-transformations">  Feature transformations </h2><br><h3 id="normalizaciya-i-izmenenie-raspredeleniya">  Normalization and distribution change </h3><br><p>  Monotone conversion of features is critical for some algorithms and does not affect others. ,            ( ,  ) ‚Äì   /   ,       . </p><br><p>     : <code>np.log</code>       ,    <code>np.float64</code> .    ,  ;  -       .           ,      .       (  <a href="https://habrahabr.ru/company/ods/blog/323890/">   </a> ). </p><br><p> ,        :   <a href="https://habrahabr.ru/company/ods/blog/322534/">  </a>   ,   :            (-1, 1),    ‚Äì    . </p><br><p>  : ,          ‚Äì      .     5,              . </p><br><p>    ‚Äì  Standart Scaling (  Z-score normalization). </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mstyle mathsize=&quot;1.2em&quot;><mi>z</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>&amp;#x2013;</mo><mi>&amp;#x03BC;</mi></mrow><mi>&amp;#x03C3;</mi></mfrac></mstyle></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.164ex" height="5.431ex" viewBox="0 -1402.6 4806.9 2338.3" role="img" focusable="false" style="vertical-align: -2.173ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-7A" x="0" y="0"></use><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-3D" x="746" y="0"></use><g transform="translate(1829,0)"><g transform="translate(477,0)"><rect stroke="none" width="2355" height="72" x="0" y="264"></rect><g transform="translate(72,811)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2013" x="572" y="0"></use><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-3BC" x="1239" y="0"></use></g><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-3C3" x="695" y="-686"></use></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mstyle mathsize="1.2em"><mi>z</mi><mo>=</mo><mfrac><mrow><mi>x</mi><mo>‚Äì</mo><mi>Œº</mi></mrow><mi>œÉ</mi></mfrac></mstyle></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-3">\large z = \frac{x ‚Äì \mu}{\sigma}</script></p><br><p> StandartScaling          ... </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.stats <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> beta <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.stats <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shapiro <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : data = beta(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>).rvs(<span class="hljs-number"><span class="hljs-number">1000</span></span>).reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : shapiro(data) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">0.8783774375915527</span></span>, <span class="hljs-number"><span class="hljs-number">3.0409122263582326e-27</span></span>) #  , p-<span class="hljs-keyword"><span class="hljs-keyword">value</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : shapiro(StandardScaler().fit_transform(data)) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">0.8783774375915527</span></span>, <span class="hljs-number"><span class="hljs-number">3.0409122263582326e-27</span></span>) #   p-<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>       </code> </pre> <br><p> ‚Ä¶   -     </p><br><pre> <code class="hljs haskell"><span class="hljs-type"><span class="hljs-type">In</span></span> : <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class"> = np.array([1, 1, 0, -1, 2, 1, 2, 3, -2, 4, 100]).reshape(-1, 1).astype(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">np</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">float64</span></span></span><span class="hljs-class">) </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">In</span></span></span><span class="hljs-class"> : </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">StandardScaler</span></span></span><span class="hljs-class">().fit_transform(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">data</span></span></span><span class="hljs-class">) </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Out</span></span></span><span class="hljs-class">: array([[-0.31922662], [-0.31922662], [-0.35434155], [-0.38945648], [-0.28411169], [-0.31922662], [-0.28411169], [-0.24899676], [-0.42457141], [-0.21388184], [ 3.15715128]]) </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">In</span></span></span><span class="hljs-class"> : (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">data</span></span></span><span class="hljs-class"> ‚Äì </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">data</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mean</span></span></span><span class="hljs-class">()) / </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">data</span></span></span><span class="hljs-class">.std() </span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Out</span></span></span><span class="hljs-class">: array([[-0.31922662], [-0.31922662], [-0.35434155], [-0.38945648], [-0.28411169], [-0.31922662], [-0.28411169], [-0.24899676], [-0.42457141], [-0.21388184], [ 3.15715128]])</span></span></code> </pre> <br><p>     ‚Äì MinMax Scaling,        ( (0, 1)). </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mstyle mathsize=&quot;1.2em&quot;><msub><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mi>o</mi><mi>r</mi><mi>m</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>X</mi><mo>&amp;#x2013;</mo><msub><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mrow><msub><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>&amp;#x2212;</mo><msub><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfrac></mstyle></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.154ex" height="6.515ex" viewBox="0 -1713.8 12121.7 2805.2" role="img" focusable="false" style="vertical-align: -2.535ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-58" x="0" y="0"></use><g transform="translate(994,-180)"><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6E" x="0" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6F" x="600" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-72" x="1086" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="1537" y="0"></use></g><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-3D" x="2914" y="0"></use><g transform="translate(4431,0)"><g transform="translate(477,0)"><rect stroke="none" width="7068" height="72" x="0" y="264"></rect><g transform="translate(1291,811)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-58" x="0" y="0"></use><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2013" x="852" y="0"></use><g transform="translate(1823,0)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-58" x="0" y="0"></use><g transform="translate(994,-180)"><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="878" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6E" x="1223" y="0"></use></g></g></g><g transform="translate(72,-824)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-58" x="0" y="0"></use><g transform="translate(994,-180)"><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-61" x="878" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-78" x="1408" y="0"></use></g><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMAIN-2212" x="2551" y="0"></use><g transform="translate(4262,0)"><use transform="scale(1.2)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-58" x="0" y="0"></use><g transform="translate(994,-180)"><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-69" x="878" y="0"></use><use transform="scale(0.849)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/ods/blog/325422/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj2yW0YlCuapaqAoINe6lzXxCAMMQ#MJMATHI-6E" x="1223" y="0"></use></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mstyle mathsize="1.2em"><msub><mi>X</mi><mrow class="MJX-TeXAtom-ORD"><mi>n</mi><mi>o</mi><mi>r</mi><mi>m</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>X</mi><mo>‚Äì</mo><msub><mi>X</mi><mrow class="MJX-TeXAtom-ORD"><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mrow><msub><mi>X</mi><mrow class="MJX-TeXAtom-ORD"><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>‚àí</mo><msub><mi>X</mi><mrow class="MJX-TeXAtom-ORD"><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfrac></mstyle></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-4">\large X_{norm} = \frac{X ‚Äì X_{min}}{X_{max}-X_{min}}</script></p><br><pre> <code class="hljs lua">In : from sklearn.preprocessing import MinMaxScaler In : MinMaxScaler().fit_transform(data) Out: array(<span class="hljs-string"><span class="hljs-string">[[ 0.02941176], [ 0.02941176], [ 0.01960784], [ 0.00980392], [ 0.03921569], [ 0.02941176], [ 0.03921569], [ 0.04901961], [ 0. ], [ 0.05882353], [ 1. ]]</span></span>) In : (data ‚Äì data.<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>()) / (data.<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>() ‚Äì data.<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>()) Out: array(<span class="hljs-string"><span class="hljs-string">[[ 0.02941176], [ 0.02941176], [ 0.01960784], [ 0.00980392], [ 0.03921569], [ 0.02941176], [ 0.03921569], [ 0.04901961], [ 0. ], [ 0.05882353], [ 1. ]]</span></span>)</code> </pre> <br><p> StandartScaling  MinMax Scaling       - . ,         ,    ‚Äì StandartScaling.  MinMax Scaling   ,      (0, 255). </p><br><p>   ,      ,   <a href="https://ru.wikipedia.org/wiki/%25D0%259B%25D0%25BE%25D0%25B3%25D0%25BD%25D0%25BE%25D1%2580%25D0%25BC%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25BE%25D0%25B5_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D0%25B5%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5"> </a> ,        : </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.stats <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lognorm <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : data = lognorm(s=<span class="hljs-number"><span class="hljs-number">1</span></span>).rvs(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : shapiro(data) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">0.05714237689971924</span></span>, <span class="hljs-number"><span class="hljs-number">0.0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : shapiro(np.log(data)) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">0.9980740547180176</span></span>, <span class="hljs-number"><span class="hljs-number">0.3150389492511749</span></span>)</code> </pre> <br><p>      ,   ,  ,        .. ,            ‚Äì           .  ,       ,      ,      .     <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html"> -</a> ( ‚Äì     -)  <a href="https://gist.github.com/mesgarpour/f24769cd186e2db853957b10ff6b7a95"> -</a> ,      ;  ,        ‚Äì <code>np.log(x + const)</code> . </p><br><p>                -.      ,           ‚Äì <a href="https://en.wikipedia.org/wiki/Q%25E2%2580%2593Q_plot">QQ </a> .          ,     . </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/files/ad1/3bb/a14/ad13bba14dd541feac9e211ba94c9223.png"></div><br> <em>QQ    </em> <br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/files/f25/215/046/f25215046b8d4f67bea16b7b0faf5884.png"></div><br> <em>QQ       </em> <br><div class="spoiler"> <b class="spoiler_title">  !</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.api <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sm #   price   Renthop         <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : price = df.price[(df.price &lt;= <span class="hljs-number"><span class="hljs-number">20000</span></span>) &amp; (df.price &gt; <span class="hljs-number"><span class="hljs-number">500</span></span>)] <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : price_log = np.log(price) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : price_mm = MinMaxScaler().fit_transform(price.<span class="hljs-keyword"><span class="hljs-keyword">values</span></span>.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>).astype(np.float64)).flatten() #  ,  sklearn   <span class="hljs-built_in"><span class="hljs-built_in">warning</span></span>- <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : price_z = StandardScaler().fit_transform(price.<span class="hljs-keyword"><span class="hljs-keyword">values</span></span>.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>).astype(np.float64)).flatten() <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : sm.qqplot(price_log, loc=price_log.mean(), scale=price_log.std()).savefig(<span class="hljs-string"><span class="hljs-string">'qq_price_log.png'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : sm.qqplot(price_mm, loc=price_mm.mean(), scale=price_mm.std()).savefig(<span class="hljs-string"><span class="hljs-string">'qq_price_mm.png'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : sm.qqplot(price_z, loc=price_z.mean(), scale=price_z.std()).savefig(<span class="hljs-string"><span class="hljs-string">'qq_price_z.png'</span></span>)</code> </pre> </div></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9ce/9d3/1f6/9ce9d31f6d344e5a9036778cf18bfefb.png"></div><br><p> <em>QQ   </em> </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a28/bbf/93d/a28bbf93da474fb2b1417f837f460440.png"></div><br><p> <em>QQ    StandartScaler.   </em> </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/77b/b6e/fb6/77bb6efb62ba41d19d31f2402a2c4a5c.png"></div><br><p> <em>QQ    MinMaxScaler.   </em> </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/946/a83/18c/946a8318cbc9446f95074de39c37030f.png"></div><br><p> <em>QQ    .    !</em> </p><br><p>  ,    -   .   <a href="https://github.com/Yorko/mlcourse.ai/blob/master/jupyter_russian/topic06_features/demo.py"> </a> ,     Renthop,    ( -   ),          . </p><br><div class="spoiler"> <b class="spoiler_title">  </b> <div class="spoiler_text"><pre> <code class="hljs delphi"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from demo import get_data <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data, y_data = get_data() <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data.head(<span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: bathrooms bedrooms price dishwasher doorman pets \ <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">1.5</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">8.006368</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">10000</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">8.606119</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">100004</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">7.955074</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">100007</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">8.094073</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">100013</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">8.116716</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> air_conditioning parking balcony bike ... stainless \ <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">10000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">100004</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">100007</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">100013</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-number"><span class="hljs-number">0</span></span> simplex <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> num_photos num_features listing_age room_dif \ <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">278</span></span> <span class="hljs-number"><span class="hljs-number">1.5</span></span> <span class="hljs-number"><span class="hljs-number">10000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-number"><span class="hljs-number">57</span></span> <span class="hljs-number"><span class="hljs-number">290</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span> <span class="hljs-number"><span class="hljs-number">100004</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-number"><span class="hljs-number">72</span></span> <span class="hljs-number"><span class="hljs-number">346</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">100007</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">22</span></span> <span class="hljs-number"><span class="hljs-number">345</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">100013</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-number"><span class="hljs-number">335</span></span> <span class="hljs-number"><span class="hljs-number">3.0</span></span> room_sum price_per_room bedrooms_share <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">4.5</span></span> <span class="hljs-number"><span class="hljs-number">666.666667</span></span> <span class="hljs-number"><span class="hljs-number">0.666667</span></span> <span class="hljs-number"><span class="hljs-number">10000</span></span> <span class="hljs-number"><span class="hljs-number">3.0</span></span> <span class="hljs-number"><span class="hljs-number">1821.666667</span></span> <span class="hljs-number"><span class="hljs-number">0.666667</span></span> <span class="hljs-number"><span class="hljs-number">100004</span></span> <span class="hljs-number"><span class="hljs-number">2.0</span></span> <span class="hljs-number"><span class="hljs-number">1425.000000</span></span> <span class="hljs-number"><span class="hljs-number">0.500000</span></span> <span class="hljs-number"><span class="hljs-number">100007</span></span> <span class="hljs-number"><span class="hljs-number">2.0</span></span> <span class="hljs-number"><span class="hljs-number">1637.500000</span></span> <span class="hljs-number"><span class="hljs-number">0.500000</span></span> <span class="hljs-number"><span class="hljs-number">100013</span></span> <span class="hljs-number"><span class="hljs-number">5.0</span></span> <span class="hljs-number"><span class="hljs-number">670.000000</span></span> <span class="hljs-number"><span class="hljs-number">0.800000</span></span> [<span class="hljs-number"><span class="hljs-number">5</span></span> rows x <span class="hljs-number"><span class="hljs-number">46</span></span> columns] <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data = x_data.values <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from sklearn.linear_model import LogisticRegression <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from sklearn.ensemble import RandomForestClassifier <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from sklearn.model_selection import cross_val_score <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from sklearn.feature_selection import SelectFromModel <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : cross_val_score(LogisticRegression(), x_data, y_data, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean() /home/arseny/.pyenv/versions/<span class="hljs-number"><span class="hljs-number">3.6</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span>/lib/python3.<span class="hljs-number"><span class="hljs-number">6</span></span>/site-packages/sklearn/linear_model/base.py:<span class="hljs-number"><span class="hljs-number">352</span></span>: RuntimeWarning: overflow encountered <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> exp np.exp(prob, prob) # , -   ! -  ,    <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: -<span class="hljs-number"><span class="hljs-number">0.68715971821885724</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from sklearn.preprocessing import StandardScaler <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : cross_val_score(LogisticRegression(), StandardScaler().fit_transform(x_data), y_data, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean() /home/arseny/.pyenv/versions/<span class="hljs-number"><span class="hljs-number">3.6</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span>/lib/python3.<span class="hljs-number"><span class="hljs-number">6</span></span>/site-packages/sklearn/linear_model/base.py:<span class="hljs-number"><span class="hljs-number">352</span></span>: RuntimeWarning: overflow encountered <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> exp np.exp(prob, prob) <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: -<span class="hljs-number"><span class="hljs-number">0.66985167834479187</span></span> # !  ! <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : from sklearn.preprocessing import MinMaxScaler <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : cross_val_score(LogisticRegression(), MinMaxScaler().fit_transform(x_data), y_data, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean() ...: <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: -<span class="hljs-number"><span class="hljs-number">0.68522489913898188</span></span> # a    ‚Äì  :(</code> </pre> </div></div><br><h3 id="vzaimodeystviya-interactions">  (Interactions) </h3><br><p>      ,       ;      ,      . </p><br><p>     Two Sigma Connect: Rental Listing Inquires.           .   ,         ,    ‚Äì ,     . </p><br><pre> <code class="hljs objectivec">rooms = df[<span class="hljs-string"><span class="hljs-string">"bedrooms"</span></span>].apply(lambda x: max(x, <span class="hljs-number"><span class="hljs-number">.5</span></span>)) <span class="hljs-meta"><span class="hljs-meta">#    ; .5      df[</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"price_per_bedroom"</span></span></span><span class="hljs-meta">] = df[</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"price"</span></span></span><span class="hljs-meta">] / rooms</span></span></code> </pre> <br><p>    .     ,          ,    ,    .  ,         -  : , (    )[ <a href="https://habrahabr.ru/company/ods/blog/322076/">https://habrahabr.ru/company/ods/blog/322076/</a> ]   (. <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"><code>sklearn.preprocessing.PolynomialFeatures</code></a> )   . </p><br><h3 id="zapolnenie-propuskov">   </h3><br><p>         " ",        .  ,     ,       .      python      : <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html"><code>pandas.DataFrame.fillna</code></a>  <a href="http://scikit-learn.org/stable/modules/preprocessing.html"><code>sklearn.preprocessing.Imputer</code></a> . </p><br><p>         .          : </p><br><ul><li>      <code>"n/a"</code> (  ); </li><li>      (     ,    ); </li><li> ,  -   (   ,    , ..        ); </li><li>    (,  )     ‚Äì   . </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/files/4b3/f3d/229/4b3f3d229a8447f6aa2ea433d85c57e9.png"></div><br><p>        -  <code>df = df.fillna(0)</code>     .      :         ,    ;            . </p><br><h2 id="vybor-priznakov-feature-selection">   (Feature selection) </h2><br><p>      ? -     ,             .    :   ,    .      ,   ‚Äì   ,           .   ‚Äì     ( )  , . </p><br><h3 id="statisticheskie-podhody">   </h3><br><p>      ‚Äì ,    , ..     .       ,  ,     ,  .       ,     . </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> VarianceThreshold <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> make_classification <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data_generated, y_data_generated = make_classification() <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data_generated.shape <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : VarianceThreshold(<span class="hljs-number"><span class="hljs-number">.7</span></span>).fit_transform(x_data_generated).shape <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">19</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : VarianceThreshold(<span class="hljs-number"><span class="hljs-number">.8</span></span>).fit_transform(x_data_generated).shape <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">18</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : VarianceThreshold(<span class="hljs-number"><span class="hljs-number">.9</span></span>).fit_transform(x_data_generated).shape <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: (<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>)</code> </pre> <br><p>    ,  <a href="http://scikit-learn.org/stable/modules/feature_selection.html">   </a> . </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SelectKBest, f_classif <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data_kbest = SelectKBest(f_classif, k=<span class="hljs-number"><span class="hljs-number">5</span></span>).fit_transform(x_data_generated, y_data_generated) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : x_data_varth = VarianceThreshold(<span class="hljs-number"><span class="hljs-number">.9</span></span>).fit_transform(x_data_generated) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cross_val_score <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : cross_val_score(LogisticRegression(), x_data_generated, y_data_generated, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean() <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">-0.45367136377981693</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : cross_val_score(LogisticRegression(), x_data_kbest, y_data_generated, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean() <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">-0.35775228616521798</span></span> <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : cross_val_score(LogisticRegression(), x_data_varth, y_data_generated, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean() <span class="hljs-keyword"><span class="hljs-keyword">Out</span></span>: <span class="hljs-number"><span class="hljs-number">-0.44033042718359772</span></span></code> </pre> <br><p> ,      . ,    <em></em> ,   ,       . </p><br><h3 id="otbor-s-ispolzovaniem-modeley">     </h3><br><p>  :  - baseline    ,         .     : - ""  (, Random Forest)     Lasso ,     .   :       ,         . </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> make_classification from sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression from sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier from sklearn.feature_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SelectFromModel from sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cross_val_score from sklearn.pipeline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> make_pipeline x_data_generated, y_data_generated = make_classification() pipe = make_pipeline(<span class="hljs-type"><span class="hljs-type">SelectFromModel</span></span>(<span class="hljs-title"><span class="hljs-title">estimator</span></span>=<span class="hljs-type"><span class="hljs-type">RandomForestClassifier</span></span>()), LogisticRegression()) lr = LogisticRegression() rf = RandomForestClassifier() print(<span class="hljs-title"><span class="hljs-title">cross_val_score</span></span>(<span class="hljs-title"><span class="hljs-title">lr</span></span>, <span class="hljs-title"><span class="hljs-title">x_data_generated</span></span>, <span class="hljs-title"><span class="hljs-title">y_data_generated</span></span>, <span class="hljs-title"><span class="hljs-title">scoring</span></span>='<span class="hljs-title"><span class="hljs-title">neg_log_loss'</span></span>).mean()) print(<span class="hljs-title"><span class="hljs-title">cross_val_score</span></span>(<span class="hljs-title"><span class="hljs-title">rf</span></span>, <span class="hljs-title"><span class="hljs-title">x_data_generated</span></span>, <span class="hljs-title"><span class="hljs-title">y_data_generated</span></span>, <span class="hljs-title"><span class="hljs-title">scoring</span></span>='<span class="hljs-title"><span class="hljs-title">neg_log_loss'</span></span>).mean()) print(<span class="hljs-title"><span class="hljs-title">cross_val_score</span></span>(<span class="hljs-title"><span class="hljs-title">pipe</span></span>, <span class="hljs-title"><span class="hljs-title">x_data_generated</span></span>, <span class="hljs-title"><span class="hljs-title">y_data_generated</span></span>, <span class="hljs-title"><span class="hljs-title">scoring</span></span>='<span class="hljs-title"><span class="hljs-title">neg_log_loss'</span></span>).mean()) -0.184853179322 -0.235652626736 -0.158372952933</code> </pre> </div></div><br><p>  ,       ‚Äî    . </p><br><div class="spoiler"> <b class="spoiler_title">    Renthop.</b> <div class="spoiler_text"><pre> <code class="hljs perl">x_data, y_data = get_data() x_data = x_data.values pipe1 = make_pipeline(StandardScaler(), SelectFromModel(estimator=RandomForestClassifier()), LogisticRegression()) pipe2 = make_pipeline(StandardScaler(), LogisticRegression()) rf = RandomForestClassifier() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span>(<span class="hljs-string"><span class="hljs-string">'LR + selection: '</span></span>, cross_val_score(pipe1, x_data, y_data, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean()) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span>(<span class="hljs-string"><span class="hljs-string">'LR: '</span></span>, cross_val_score(pipe2, x_data, y_data, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean()) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span>(<span class="hljs-string"><span class="hljs-string">'RF: '</span></span>, cross_val_score(rf, x_data, y_data, scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>).mean()) LR + selection: -<span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">714208124619</span></span> LR: -<span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">669572736183</span></span> <span class="hljs-comment"><span class="hljs-comment">#   ! RF: -2.13486716798</span></span></code> </pre></div></div><br><h3 id="perebor">  </h3><br><p> ,  ,          :     "",  ,    ,   .    <a href="http://rasbt.github.io/mlxtend/user_guide/feature_selection/ExhaustiveFeatureSelector/">Exhaustive Feature Selection</a> . </p><br><p>    ‚Äì   ,       .    N,     N ,   ,     N+1  ,      ,     .    ,                .    <a href="http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/">Sequential Feature Selection</a> . </p><br><p>     :          ,             . </p><br><div class="spoiler"> <b class="spoiler_title">  !</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : selector = SequentialFeatureSelector(LogisticRegression(), scoring=<span class="hljs-string"><span class="hljs-string">'neg_log_loss'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">verbose</span></span>=<span class="hljs-number"><span class="hljs-number">2</span></span>, k_features=<span class="hljs-number"><span class="hljs-number">3</span></span>, forward=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">-1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : selector.fit(x_data_scaled, y_data) <span class="hljs-keyword"><span class="hljs-keyword">In</span></span> : selector.fit(x_data_scaled, y_data) [<span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-03</span></span><span class="hljs-number"><span class="hljs-number">-30</span></span> <span class="hljs-number"><span class="hljs-number">01</span></span>:<span class="hljs-number"><span class="hljs-number">42</span></span>:<span class="hljs-number"><span class="hljs-number">24</span></span>] Features: <span class="hljs-number"><span class="hljs-number">45</span></span>/<span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-comment"><span class="hljs-comment">-- score: -0.682830838803 [2017-03-30 01:44:40] Features: 44/3 -- score: -0.682779463265 [2017-03-30 01:46:47] Features: 43/3 -- score: -0.682727480522 [2017-03-30 01:48:54] Features: 42/3 -- score: -0.682680521828 [2017-03-30 01:50:52] Features: 41/3 -- score: -0.68264297879 [2017-03-30 01:52:46] Features: 40/3 -- score: -0.682607753617 [2017-03-30 01:54:37] Features: 39/3 -- score: -0.682570678346 [2017-03-30 01:56:21] Features: 38/3 -- score: -0.682536314625 [2017-03-30 01:58:02] Features: 37/3 -- score: -0.682520258804 [2017-03-30 01:59:39] Features: 36/3 -- score: -0.68250862986 [2017-03-30 02:01:17] Features: 35/3 -- score: -0.682498213174 # ".      ..." ... [2017-03-30 02:21:09] Features: 10/3 -- score: -0.68657335969 [2017-03-30 02:21:18] Features: 9/3 -- score: -0.688405548594 [2017-03-30 02:21:26] Features: 8/3 -- score: -0.690213724719 [2017-03-30 02:21:32] Features: 7/3 -- score: -0.692383588303 [2017-03-30 02:21:36] Features: 6/3 -- score: -0.695321584506 [2017-03-30 02:21:40] Features: 5/3 -- score: -0.698519960477 [2017-03-30 02:21:42] Features: 4/3 -- score: -0.704095390444 [2017-03-30 02:21:44] Features: 3/3 -- score: -0.713788301404 #      </span></span></code> </pre> </div></div><br><h2 id="domashnee-zadanie-6">   ‚Ññ6 </h2><br><p>         ,    <a href="https://vk.com/mlcourse"> </a>   <a href=""></a> . </p><br><p>       c        UCI     .     <a href="http://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_russian/assignments_demo/assignment06_regression_wine.ipynb">Jupyter notebook</a>     <a href="https://docs.google.com/forms/d/1gsNxgkd0VqidZp4lh9mnCQnJw3b0IFR1C4WBES86J40/edit">-</a> ,     . </p><br><h2 id="poleznye-istochniki">   </h2><br><ul><li> <a href="https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-6-feature-engineering-and-feature-selection-8b94f870706a">Open Machine Learning Course. Topic 6. Feature Engineering and Feature Selection</a> </li><li> <a href="https://www.kaggle.com/kernels">Kaggle Kernels</a> </li><li> <a href="https://github.com/alicezheng/feature-engineering-book">"Feature Engineering Book"</a> </li><li>    <a href="https://habrahabr.ru/company/mailru/blog/346942/">"Feature Engineering,    online-"</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/325422/">https://habr.com/ru/post/325422/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../325400/index.html">Pattern recognition</a></li>
<li><a href="../325404/index.html">CodePlex is closing</a></li>
<li><a href="../325410/index.html">More about the introduction of timezone in the long-lived project</a></li>
<li><a href="../325412/index.html">The first of April 2017 on the Internet</a></li>
<li><a href="../325416/index.html">Bayesian multi-armed gangsters against A / B tests</a></li>
<li><a href="../325426/index.html">Getting rid of ConcurrentModificationException</a></li>
<li><a href="../325428/index.html">Round Canvas Chart</a></li>
<li><a href="../325432/index.html">Deep Learning Libraries: Keras</a></li>
<li><a href="../325434/index.html">How I create a database for my applications</a></li>
<li><a href="../325436/index.html">How we did secure telephony for Wheely, a world-wide personal driver service.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>