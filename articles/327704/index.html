<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Computer vision on the example of an application for IKEA. Part 1</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I was preparing for the next hackathon, I decided to update my knowledge in the field of computer vision. Last time, the problem of recognizing auto n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Computer vision on the example of an application for IKEA. Part 1</h1><div class="post__text post__text-html js-mediator-article">  I was preparing for the next hackathon, I decided to update my knowledge in the field of computer vision.  Last time, the problem of recognizing auto numbers in a video stream I was not able to solve quickly "head on."  Now, on reflection, I decided to simplify the task a bit.  There were a lot of ideas, I looked through the pictures in the phone and came across a familiar case for everyone who visited the ikea store - a photo with a check, where the item number and its position in the self-service warehouse are listed. <br><br><img src="https://habrastorage.org/files/2a6/342/244/2a6342244a4146cabced7ddff55ec42c.jpg"><a name="habracut"></a><br><br>  Case, of course, with a stretch.  Having photos of checks in the phone is not at all necessary for the phone to recognize them, from the photo you can clearly see where and what you need to get.  On the other hand, we are interested in the example of the work of such software + we can simplify our lives by placing all the goods we need on the warehouse map.  Those.  Having 4-5 photos of checks, we can recognize them and build a map of the route of running around the self-service warehouse.  Well, one reason for the implementation of our ideas came up.  The second reason is colors.  Personally, I have repeatedly come across the fact that you check a check, for example, a black dresser, not paying attention to the fact that there is a white one next to you, which you need, whose check you wanted to take a picture of.  When recognizing a check, we can immediately show a preview to the user of the product that is on the check (and therefore on the spot in the self-service warehouse).  Great, the second reason behind the ears is found. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So what do we need to do? <br><br><ol><li>  Find the ikea check in the image. </li><li>  Identify the check and prepare the data from the check for recognition. </li><li>  Recognize the data. </li></ol><br>  We define the toolkit.  We will work with the image using <a href="http://opencv.org/"><img src="https://habrastorage.org/getpro/habr/post_images/54a/8a8/b50/54a8a8b503bef6d03cbf2b747533756d.png" width="16"></a>  <a href="http://opencv.org/">OpenCV</a> , trust recognition <a href="https://github.com/tesseract-ocr"><img src="https://habrastorage.org/getpro/habr/post_images/94d/4bb/d10/94d4bbd1085eafb4d97af089358aca18.png" width="16"></a>  <a href="https://github.com/tesseract-ocr">Tesseract</a> .  Shell write on <a href="https://nodejs.org/en/"><img src="https://habrastorage.org/getpro/habr/post_images/008/66c/316/00866c316c66dbd87dbb75b874e4ab43.png" width="16"></a>  <a href="https://nodejs.org/en/">NodeJS</a> . <br><br>  The choice of OpenCV is obvious.  Even the pros who can rewrite most of the image processing algorithms with their hands most often use OpenCV.  Not for nothing, this library stands for ‚Äú <i>Open Source Computer Vision Library</i> ‚Äù.  Although purely in theory, you can come up with a solution to our cases on gd + imagick.  But this is a perversion. <br><br>  OpenCV will be responsible for finding the check on camera + for preparing the check for recognition. <br>  At one time I used Tesseract to recognize captcha Yandex, Rambler, Google.  There is no doubt that this library will easily cope with the recognition of plain text.  Well, to be honest, being a "profane" in ocr, I just do not know anything else so powerful with open source. <br><br>  NodeJS is an exclusively personal choice.  At the moment I am doing a lot of things in JS and this language is just closer <i>syntactically</i> closer, if there is such a word at all. <br><br>  I do not pretend to the speed and quality of algorithms, and even more so to clean code, the task for me was to extremely quickly recall computer vision, update my knowledge and implement a project.  Therefore, any edits and criticisms are welcome, but please, without hysteria.  Well, I repeat, I share the practice for the same "old men" like myself, so as not to be a complete sucker among the party of young progres (where my 17 years old ...). <br><br>  They drove.  I created <a href="https://github.com/trin4ik/bender-vision-ikea"><img src="https://assets-cdn.github.com/favicon.ico" width="16"></a>  <a href="https://github.com/trin4ik/bender-vision-ikea">turnip on githaba</a> , all the code is actually there.  Let's understand a little more.  In the turnip in <a href="https://github.com/trin4ik/bender-vision-ikea/tree/master/public/images">/ public / images /</a> you will find 4 pictures of Ikeev's checks.  So it turned out that I had pictures from different angles, different sizes.  What you need for tests. <br><br><h3>  1. Detection of a check on the image. </h3><br>  The OpenCV library is very powerful and is far from being limited to those features that I will discuss in this article.  At first, I didn‚Äôt say for nothing that GD + IMagick can solve our problem.  In particular, the pros would most likely use the <a href="http://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/template_matching/template_matching.html">Template Matching</a> technique to detect a check, but we will go more simply.  Fortunately, ikea helps us a lot with this. <br><br>  The first thing we need to know is that the check with the info about the location of the goods is always red.  Well, from this we will make a start. <br><br><pre><code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// convert to HSV process.convertHSVscale(); // find only red process.inRange([0,100,100], [10,255,255]);</span></span></code> </pre> <br>  Convert our image (which in this case is read into the process variable) in HSV and look for the image between the specified channels.  I have little idea how it works, but in search of the opportunity to select a specific color from the image and its range I came across two materials, a <a href="https://solarianprogrammer.com/2015/05/08/detect-red-circles-image-using-opencv/">developer‚Äôs article</a> and <a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html">official documentation</a> .  From the code it is clear that I use the matrix between [0,100,100] and [10,255,255] in the HSV palette.  From the official documentation on color highlighting, it follows that the general rule is very simple.  We take [h-10, 100, 100] and [h + 10, 255,255], where h is the color we need.  I used the <a href="http://colorizer.org/">colorizer.org</a> service to get the indexes. <br>  Let's see what happened. <br><br><img src="https://habrastorage.org/files/237/446/ab8/237446ab837746e4b9f7db1794a171bb.jpg"><br><br>  Great, we've singled out red and its shades.  Total found a check, my hand and a red square on the carpet print.  Now, using the <a href="http://docs.opencv.org/2.4/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.html">findContour</a> method <a href="http://docs.opencv.org/2.4/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.html">,</a> we can easily separate flies from cutlets, i.e.  find the "borders" in our image. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> possibleContour = []; <span class="hljs-comment"><span class="hljs-comment">//         var contours = process.findContours(); for (var i = 0; i &lt; contours.size(); i++) { if (contours.area(i) &lt; 20000) continue; //    var arcLength = contours.arcLength(i, true); contours.approxPolyDP(i, 0.05 * arcLength, true); //   (¬´   ‚Ä¶¬ª) switch(contours.cornerCount(i)) { case 4: contourImg.drawContour(contours, i, [0,255,0]); //       4-      break; default: contourImg.drawContour(contours, i, [0,0,255]); //     } if (contours.cornerCount(i) ==4) { //      4-    .   ,  ,  . possibleContour.push(pointOrder(contours.points(i))); } }</span></span></code> </pre> <br><img src="https://habrastorage.org/files/578/133/e51/578133e51d3f47689add443fe53c974c.jpg"><br><br>  Pay attention to the line <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> arcLength = contours.arcLength(i, <span class="hljs-literal"><span class="hljs-literal">true</span></span>); contours.approxPolyDP(i, <span class="hljs-number"><span class="hljs-number">0.05</span></span> * arcLength, <span class="hljs-literal"><span class="hljs-literal">true</span></span>); <span class="hljs-comment"><span class="hljs-comment">//   (¬´   ‚Ä¶¬ª)</span></span></code> </pre> <br>  Using the approxPolyDP method, we ‚Äúsmooth the corners‚Äù of the contours found, eliminating ‚Äúnoise‚Äù.  More information can be found on the pages of <a href="http://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html">official documentation</a> . <br><br>  It is also worth noting that findContour does an excellent job with its task, but the order of the points found may be unpredictable.  It is important for us to keep the order of points in the format top-left, top-right, bottom-right, bottom-left for the correct perspective. <br><br><img src="https://habrastorage.org/files/431/a9e/399/431a9e3992244b2d86c28699f1804d02.png"><br><br>  It would seem that the task is simple, to find a top-left point and so on.  In practice, this has turned into a bunch of odds over arrays.  He started to google, came across an excellent blog on computer vision and opencv, including the <a href="http://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/">developer suggested the trick</a> to search for these very ‚Äúextremes‚Äù for the positions we need.  In particular, the minimum sum of x + y coordinates will always be equal to the top-left point, while the maximum sum will be equal to bottom-right.  Similarly, the maximum spacing xy will be equal to the top-right point and the minimum will be equal to the bottom-left point.  Get the pointOrder method <br><br><pre> <code class="javascript hljs">pointOrder: <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">point</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> ordered = []; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sum = []; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> point) { sum[x] = point[x].x+point[x].y; } ordered[<span class="hljs-number"><span class="hljs-number">0</span></span>] = point[sum.indexOf(_.min(sum))]; ordered[<span class="hljs-number"><span class="hljs-number">2</span></span>] = point[sum.indexOf(_.max(sum))]; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> diff = []; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> point) { diff[x] = point[x].x-point[x].y; } ordered[<span class="hljs-number"><span class="hljs-number">1</span></span>] = point[diff.indexOf(_.max(diff))]; ordered[<span class="hljs-number"><span class="hljs-number">3</span></span>] = point[diff.indexOf(_.min(diff))]; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ordered; }</code> </pre> <br>  The order we need for perception.  We know in advance the horizontal and vertical points (this is 0/0, maxWidth / 0, maxWidth / maxHeight and 0 / maxHeight) and in order not to turn the image, we need to transfer the points of our contour in that order. <br><br>  Prepared the contours, the next step aligns the perspective. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> warpImg = []; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> possibleContour) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> point = possibleContour[x]; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> maxWidth = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> maxHeight = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> tmp = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//    width/height if (pointWidth(point[0], point[1]) &gt;pointWidth(point[3], point[2])) { maxWidth = Math.round(pointWidth(point[0], point[1])); } else { maxWidth = Math.round(pointWidth(point[3], point[2])); } if (pointWidth(point[0], point[3]) &gt;pointWidth(point[1], point[2])) { maxHeight = Math.round(pointWidth(point[0], point[3])); } else { maxHeight = Math.round(pointWidth(point[1], point[2])); } //       var tmpWarpImg = img.copy(); var srcWarp = [point[0].x, point[0].y, point[1].x, point[1].y, point[2].x, point[2].y, point[3].x, point[3].y]; var dstWarp = [0, 0, maxWidth, 0, maxWidth, maxHeight, 0, maxHeight]; var perspective = tmpWarpImg.getPerspectiveTransform(srcWarp, dstWarp); tmpWarpImg.warpPerspective(perspective, maxWidth, maxHeight, [255, 255, 255]); warpImg.push(tmpWarpImg); }</span></span></code> </pre> <br><img src="https://habrastorage.org/files/398/55d/97d/39855d97d75d4eeab404d730f13321de.jpg"><br><br>  Find 2 contours, as can be seen from the image.  One we need, the second "noisy." <br><br><h3>  2. Identify the receipt and prepare the data. </h3><br>  First of all, we eliminate the "left" contours of the opposite, i.e.  immediately identify the check.  And what do we know about the check?  True, it is rectangular in shape, with text and 3 data rectangles.  From them, and we will build.  Already in the found images we look for contours by analogy, however this time we select only those found areas in which there are 3 rectangular contours. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// filter wrapped img var trueWarpImg = []; for (var x in warpImg) { var warpedImg = warpImg[x].copy(); // convert to HSV warpedImg.convertHSVscale(); // find only red warpedImg.inRange([0,100,100], imgProc.[10,255,255]); var possibleContour = []; var contourImg = warpImg[x].copy(); var contours = warpedImg.findContours(); for (var i = 0; i &lt; contours.size(); i++) { if (contours.area(i) &lt; 2000 || contours.area(i) &gt; 20000) continue; //        var arcLength = contours.arcLength(i, true); contours.approxPolyDP(i, 0.05 * arcLength, true); switch(contours.cornerCount(i)) { case 4: contourImg.drawContour(contours, i, [0,255,0]); break; default: contourImg.drawContour(contours, i, [0,0,255]); } if (contours.cornerCount(i) ==4) { possibleContour.push(pointOrder(contours.points(i))); } } //   ,   3 ,    if (possibleContour.length == 3) { var trueContour = []; var width = []; var tmpContour = _.cloneDeep(possibleContour); //   .   ,    . for (var x2 in tmpContour) { width.push(tmpContour[x2][1].x - tmpContour[x2][0].x); } var maxIndex = width.indexOf(_.max(width)); trueContour[0] = tmpContour[maxIndex]; var left = []; for (var x2 in tmpContour) { if (x2 == maxIndex) continue; left.push(tmpContour[x2][0].x); } trueContour[1] = tmpContour[left.indexOf(_.min(left))]; trueContour[2] = tmpContour[left.indexOf(_.max(left))]; trueWarpImg.push({img: warpImg[x], contour: trueContour}); } }</span></span></code> </pre> <br>  Oh, well, in general, I warned that the task was QUICKLY to consider an example, with the duplication of code, I did not particularly bother.  And I don‚Äôt like to do it when the project is not prepared for a pro.  And if to be frank, for many production projects in some places I leave code duplication to make it easier for beginners to read.  We pay attention that the contours can be found in a random order, it is important for us to know their order, where is the product code, where is the row, and where is the place. <br><br><img src="https://habrastorage.org/files/509/d9d/a06/509d9da06ca4478b9aff174332c45cd0.jpg"><br><br>  At the exit, we found an ikea check, made sure that it was he + who extracted the data for recognition. <br><br><h3>  3. Recognize the data. </h3><br>  In order to simplify the tesseract life, we will cut off our images, isolate the red (in order to make the image BW) and enlarge.  Increasing slightly slows down tesseract, but increases the% recognition by an order of magnitude. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// ocr img for (var x in labelImg) { var label = labelImg[x]; for (var x2 in label) { var labelLine = label[x2]; // convert to HSV labelLine.convertHSVscale(); // find only red labelLine.inRange([0,100,100], [10,255,255]); // labelLine.gaussianBlur([5,5]); //      ,      . labelLine.resize(labelLine.width()*3,labelLine.height()*3); Tesseract.recognize(labelLine.toBuffer(), { lang: 'eng', tessedit_char_whitelist: '0123456789.' }) .progress(function(msg){/*console.log('tesseract', msg)*/}) .catch(function(msg){/*console.log('tesseract', msg)*/}) .then(function(result){console.log('"', result.text.trim(), '"')}); } }</span></span></code> </pre> <br>  We get in the console <br><br><img src="https://habrastorage.org/files/a2b/2c9/b55/a2b2c9b5531542db800b87aef373b53f.png"><br><br>  It is not bad. <br><br>  In the following parts, we will transfer the code to mobile platforms and make a mobile cross platform.  Fill the application with storage cards, loading the ikea database and, of course, we‚Äôll make everything work offline. <br><br>  Well, duplicate link <a href="https://github.com/trin4ik/bender-vision-ikea"><img src="https://assets-cdn.github.com/favicon.ico" width="16"></a>  <a href="https://github.com/trin4ik/bender-vision-ikea">on the turnip project.</a> <br><br>  Material used: <br><br><ol><li>  <a href="https://solarianprogrammer.com/2015/05/08/detect-red-circles-image-using-opencv/">Excellent material on color detection in the image.</a> </li><li>  <a href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html">Official documentation on finding a specific color in an image</a> </li><li>  <a href="http://colorizer.org/">Convenient color manipulation service, including for working with HSV</a> </li><li>  <a href="http://docs.opencv.org/2.4/doc/tutorials/imgproc/shapedescriptors/find_contours/find_contours.html">Search contours in OpenCV</a> </li><li>  <a href="http://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html">Smooths the corners of the contours found, removing noise</a> </li><li>  <a href="http://www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/">Search top-left, top-right, bottom-right, bottom-left points of the specified</a> </li></ol><br>  Useful materials: <br><br><ol><li>  <a href="http://docs.opencv.org/">Official OpenCV documentation, somewhere not inferior to IMagick documentation</a> </li><li>  <a href="http://www.pyimagesearch.com/">A chic knowledge base on opencv computer vision, true in English and with a Python bias</a> </li><li>  <a href="http://robocraft.ru/blog/computervision/">Best in Russian language regarding computer vision that I found</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/327704/">https://habr.com/ru/post/327704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327692/index.html">Java, first cup</a></li>
<li><a href="../327694/index.html">Search in the Django REST Framework using Elasticsearch</a></li>
<li><a href="../327698/index.html">How to share the environment for building and running a service in Docker today and how to do it tomorrow</a></li>
<li><a href="../327700/index.html">SVG sprite with webpack in one line</a></li>
<li><a href="../327702/index.html">So why all the same need Refresh tokens in OAuth?</a></li>
<li><a href="../327706/index.html">Calculate the residence of passengers of the ship (with accuracy to the house)</a></li>
<li><a href="../327708/index.html">Release Rust 1.17</a></li>
<li><a href="../327710/index.html">GitLab 9.1 Released: Service Desk, Burndown Charts and Canary Deployments</a></li>
<li><a href="../327714/index.html">Training with reinforcements on the example of the game "tic-tac-toe"</a></li>
<li><a href="../327718/index.html">Speed ‚Äã‚Äãis everything! SSD only! Experience mClouds.ru</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>