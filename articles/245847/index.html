<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Replication slots in PostgreSQL</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Up to the ninth version in PostgreSQL, WAL archiving was used to create a ‚Äúwarm‚Äù backup server. Version 9.0 introduced streaming replication with the ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Replication slots in PostgreSQL</h1><div class="post__text post__text-html js-mediator-article">  Up to the ninth version in PostgreSQL, WAL archiving was used to create a ‚Äúwarm‚Äù backup server.  Version 9.0 introduced streaming replication with the ability to create a hot read-only server.  In the next version of PostgreSQL 9.4, a new functionality will appear to create streaming replication called replication slots. <a name="habracut"></a>  Consider what it is and how it differs from previous methods. <br>  To date, the first candidate for releases is available.  As a test bench, 2 virtual machines for Ubuntu 14.04 were selected.  The assembly and installation process is the same for the primary and backup servers.  We put from the source, pre-install the necessary packages: <br><br><pre><code class="bash hljs">sudo apt-get update &amp;&amp; sudo apt-get -y install make g++ checkinstall libreadline6-dev zlib1g-dev</code> </pre> <br>  Download and unpack the archive from the repository: <br><br><pre> <code class="bash hljs">wget https://ftp.postgresql.org/pub/<span class="hljs-built_in"><span class="hljs-built_in">source</span></span>/v9.4rc1/postgresql-9.4rc1.tar.gz tar xzf postgresql-9.4rc1.tar.gz</code> </pre><br>  We assemble and install the package: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> postgresql-9.4rc1/ ./configure make sudo checkinstall</code> </pre><br>  By default, binaries for working with DBMS are placed in / usr / local / pgsql /. <br>  Add a postgres user to the system: <br><br><pre> <code class="bash hljs">sudo useradd -M postgres</code> </pre><br>  Create a directory for the cluster: <br><br><pre> <code class="bash hljs">sudo mkdir -p /data/db sudo chown postgres:postgres /data/db sudo chmod 0700 /data/db</code> </pre><br>  Next, perform the actions on the main server.  Initialize the cluster: <br><br><pre> <code class="bash hljs">sudo -u postgres /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/initdb -D /data/db</code> </pre><br>  In addition to the cluster structure, initdb will create default configs.  Create a pg_log directory in a cluster where logs will be stored: <br><br><pre> <code class="bash hljs">sudo -u postgres mkdir /data/db/pg_log sudo -u postgres chmod 0700 /data/db/pg_log</code> </pre><br>  Add entries to pg_hba.conf for connecting users and so that the backup server can retrieve WAL logs from the main server: <br><br><pre> <code class="bash hljs">host all all 192.168.1.0/24 md5 host replication replica 192.168.1.108/32 md5</code> </pre><br>  In the postgresql.conf config, edit the parameters: <br>  listen_addresses = '*' - listen for incoming connections on all interfaces <br>  wal_level = hot_standby - the required format for WAL logs for replication <br>  max_wal_senders = 2 - the number of simultaneous connections for replication <br>  logging_collector = on - add logs to pg_log <br><br>  We start our cluster: <br><br><pre> <code class="bash hljs">sudo -u postgres /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/pg_ctl -D /data/db start</code> </pre><br>  Look at the state of the processes: <br><br><pre> <code class="cs hljs">ps aux | grep postgres postgres <span class="hljs-number"><span class="hljs-number">21295</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">23700</span></span> <span class="hljs-number"><span class="hljs-number">604</span></span> ? Ss <span class="hljs-number"><span class="hljs-number">13</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span> postgres: logger process postgres <span class="hljs-number"><span class="hljs-number">21297</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">13.6</span></span> <span class="hljs-number"><span class="hljs-number">170880</span></span> <span class="hljs-number"><span class="hljs-number">138408</span></span> ? Ss <span class="hljs-number"><span class="hljs-number">13</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">01</span></span> postgres: checkpointer process postgres <span class="hljs-number"><span class="hljs-number">21298</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">5.0</span></span> <span class="hljs-number"><span class="hljs-number">170784</span></span> <span class="hljs-number"><span class="hljs-number">51076</span></span> ? Ss <span class="hljs-number"><span class="hljs-number">13</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span> postgres: writer process postgres <span class="hljs-number"><span class="hljs-number">21299</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">0.5</span></span> <span class="hljs-number"><span class="hljs-number">170648</span></span> <span class="hljs-number"><span class="hljs-number">5148</span></span>? Ss <span class="hljs-number"><span class="hljs-number">13</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span> postgres: wal writer process postgres <span class="hljs-number"><span class="hljs-number">21300</span></span> <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-number"><span class="hljs-number">0.1</span></span> <span class="hljs-number"><span class="hljs-number">171052</span></span> <span class="hljs-number"><span class="hljs-number">1836</span></span> ? Ss <span class="hljs-number"><span class="hljs-number">13</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span> postgres: autovacuum launcher process postgres <span class="hljs-number"><span class="hljs-number">21301</span></span> <span class="hljs-number"><span class="hljs-number">0.2</span></span> <span class="hljs-number"><span class="hljs-number">0.1</span></span> <span class="hljs-number"><span class="hljs-number">25924</span></span> <span class="hljs-number"><span class="hljs-number">1060</span></span> ? Ss <span class="hljs-number"><span class="hljs-number">13</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">17</span></span> postgres: stats collector process</code> </pre><br>  Create a replica user with replication rights: <br><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/psql -U postgres -c <span class="hljs-string"><span class="hljs-string">"create user replica with replication encrypted password '123'"</span></span></code> </pre><br>  Create a test database with data: <br><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/createdb -U postgres testdb /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/psql -U postgres -d testdb -c <span class="hljs-string"><span class="hljs-string">"create table testtable (id serial, data text)"</span></span> /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/psql -U postgres -d testdb -c <span class="hljs-string"><span class="hljs-string">"insert into testtable select nextval('testtable_id_seq'::regclass), md5(generate_series(1,1000000)::text)"</span></span></code> </pre><br>  Set up a backup server. <br>  Create a directory for the cluster: <br><br><pre> <code class="bash hljs">sudo mkdir -p /data/db sudo chmod 0700 /data/db sudo chown postgres:postgres /data/db</code> </pre><br>  Using the pg_basebackup utility, we will make a backup copy of the main server: <br><br><pre> <code class="bash hljs">sudo -u postgres /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/pg_basebackup -h 192.168.1.103 -U replica -D /data/db -X s</code> </pre><br>  pg_basebackup copies the entire contents of the cluster, including configs, so we change the hot_standby parameter to the on state in postgresql.conf <br>  Create a recovery.conf file in the cluster directory, in which we specify the connection parameters to the main server: <br><br><pre> <code class="bash hljs">standby_mode=<span class="hljs-string"><span class="hljs-string">'on'</span></span> primary_conninfo=<span class="hljs-string"><span class="hljs-string">'host=192.168.1.103 port=5432 user=replica password=123'</span></span></code> </pre><br>  Run the cluster on the backup server: <br><br><pre> <code class="bash hljs">sudo -u postgres /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/pgsql/bin/pg_ctl -D /data/db start</code> </pre><br>  After that, the wal_sender process should start on the main server, and on the backup wal_receiver: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><pre> <code class="bash hljs">postgres 21295 0.0 0.0 23700 604 ? Ss 13:39 0:00 postgres: logger process postgres 21297 0.0 0.2 170756 2312 ? Ss 13:39 0:00 postgres: checkpointer process postgres 21298 0.0 0.2 170784 2252 ? Ss 13:39 0:00 postgres: writer process postgres 21299 0.0 0.5 170648 5148 ? Ss 13:39 0:00 postgres: wal writer process postgres 21300 0.0 0.1 171052 1804 ? Ss 13:39 0:00 postgres: autovacuum launcher process postgres 21301 0.0 0.1 25924 1060 ? Ss 13:39 0:00 postgres: stats collector process postgres 21323 0.0 0.2 171048 2108 ? Ss 13:46 0:00 postgres: wal sender process replica 192.168.1.108(56673) streaming 0/4E000210 postgres 15150 0.0 0.0 23700 612 ? Ss 13:46 0:00 postgres: logger process postgres 15151 0.0 0.1 170788 1496 ? Ss 13:46 0:00 postgres: startup process recovering 00000001000000000000004E postgres 15152 0.0 0.0 170680 944 ? Ss 13:46 0:00 postgres: checkpointer process postgres 15153 0.0 0.1 170680 1204 ? Ss 13:46 0:00 postgres: writer process postgres 15154 0.0 0.0 25792 648 ? Ss 13:46 0:00 postgres: stats collector process postgres 15155 0.6 0.1 174956 1660 ? Ss 13:46 0:00 postgres: wal receiver process streaming 0/4E000138</code> </pre><br></div></div><br>  You can view the status of replication through the pg_stat_replication view on the main server <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># select * from pg_stat_replication; -[ RECORD 1 ]----+------------------------------ pid | 21987 usesysid | 16384 usename | replica application_name | walreceiver client_addr | 192.168.1.108 client_hostname | client_port | 56674 backend_start | 2014-11-25 18:30:09.206434+03 backend_xmin | state | streaming sent_location | 0/5A2D8E60 write_location | 0/5A2D8E60 flush_location | 0/5A2D8E60 replay_location | 0/5A2D8E60 sync_priority | 0 sync_state | async</span></span></code> </pre><br>  It can be seen that the primary and backup servers are synchronized.  Now we will generate some more test data and immediately after that we will look at the status of replication. <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># insert into testtable select nextval('testtable_id_seq'::regclass), md5(generate_series(1,1000000)::text); INSERT 0 1000000 testdb=# select * from pg_stat_replication; -[ RECORD 1 ]----+------------------------------ pid | 21987 usesysid | 16384 usename | replica application_name | walreceiver client_addr | 192.168.1.108 client_hostname | client_port | 56674 backend_start | 2014-11-25 18:30:09.206434+03 backend_xmin | state | streaming sent_location | 0/63800000 write_location | 0/63680000 flush_location | 0/63680000 replay_location | 0/6136E160 sync_priority | 0 sync_state | async</span></span></code> </pre><br>  Here we observe that the backup server has taken all the WAL logs from the main server, but has not yet managed to apply them all, so it is behind the main one.  By default, in postgres replication occurs asynchronously using WAL logs, these are fixed-size binary files of 16 MB located in the pg_xlog directory.  Their number can be changed using the checkpoint_segments and wal_keep_segments parameters.  When the amount of changed data in the cluster exceeds the total size of WAL logs, the checkpointer process starts, which resets the WAL logs to the data files.  After this, WAL logs are recreated again.  In the current stable version of postgres, the primary server does not consider the state of the backup server.  Therefore, if the backup is too ‚Äúbehind‚Äù the main one, then the main WAL logs will be recreated before the backup takes them.  Let's try to simulate this situation. <br>  Temporarily prohibit the backup server from connecting to port 5432: <br><br><pre> <code class="bash hljs">sudo iptables -A OUTPUT -m tcp -p tcp ‚Äîdport 5432 -j DROP</code> </pre><br>  Generate more data on the main server: <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># insert into testtable select nextval('testtable_id_seq'::regclass), md5(generate_series(1,1000000)::text); INSERT 0 1000000</span></span></code> </pre><br>  Let's reset the iptables rule and see the logs of the backup server, in which we see such a nasty picture. <br><br><pre> <code class="bash hljs">LOG: started streaming WAL from primary at 0/78000000 on timeline 1 FATAL: could not receive data from WAL stream: ERROR: requested WAL segment 000000010000000000000078 has already been removed</code> </pre><br>  The main server deleted the WAL logs before the backup server managed to pick them up.  Now you have to re-backup the main server.  The problem is that the primary server does not take into account the status of the backup.  Therefore, if there are problems with the network or just a slow channel between servers, then with heavy load and / or data change on the main server, there is a risk of replication failure.  A partial solution is to increase the value of the <a href="http://www.postgresql.org/docs/9.4/static/runtime-config-replication.html">wal_keep_segments</a> parameter, and enable <a href="http://www.postgresql.org/docs/9.4/static/continuous-archiving.html">WAL archiving</a> .  But in version 9.4 replication slots will appear.  Consider how it works: <br>  On the main server, create a replication slot: <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># SELECT pg_create_physical_replication_slot('standby_slot'); -[ RECORD 1 ]-----------------------+---------------- pg_create_physical_replication_slot | (standby_slot,)</span></span></code> </pre><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># select * from pg_replication_slots; -[ RECORD 1 ]+------------- slot_name | standby_slot plugin | slot_type | physical datoid | database | active | f xmin | catalog_xmin | restart_lsn |</span></span></code> </pre><br>  On the backup, add to the existing contents of the file recovery.conf line <br>  primary_slot_name = 'standby_slot' <br><br>  After restarting the backup server, we will again disconnect it from the main server and generate test data on the main one that exceeds the amount of WAL logs: <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># insert into testtable select nextval('testtable_id_seq'::regclass), md5(generate_series(1,10000000)::text);</span></span></code> </pre><br>  Let's look at the parameters of WAL logs in the system, and then the actual number of log files in the pg_xlog directory: <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># show checkpoint_segments; -[ RECORD 1 ]-------+-- checkpoint_segments | 3</span></span></code> </pre><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment"># show wal_keep_segments; -[ RECORD 1 ]-----+-- wal_keep_segments | 0</span></span></code> </pre><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment">#\! ls /data/db/pg_xlog | wc -l 50</span></span></code> </pre><br>  To calculate the maximum number of WAL files in the system, use the <a href="http://www.postgresql.org/docs/9.4/static/wal-configuration.html">formula</a> : (2 + checkpoint_completion_target) * checkpoint_segments + 1. <br>  However, the current number of WAL logs in the system is much higher.  Replication slots store information about the number of WAL logs downloaded by each backup server.  Now WAL logs will accumulate until the last backup server picks them up or until the replication slot is removed.  As WAL logs are downloaded, the pg_xlog directory on the main server will decrease.  Having reset the iptables rule on the backup server, we see in the logs that replication has resumed. <br><br><pre> <code class="sql hljs">testdb=<span class="hljs-comment"><span class="hljs-comment">#\! tail -f /data/db/pg_log/postgresql-2014-11-27_191036.log Is the server running on host "192.168.1.103" and accepting TCP/IP connections on port 5432? LOG: started streaming WAL from primary at 0/A0000000 on timeline 1</span></span></code> </pre><br>  Replication slots is a great tool that improves the reliability and convenience of replication in PostgreSQL. <br><br>  Description replication slots on the official website of PostgreSQL: <a href="http://www.postgresql.org/docs/9.4/static/warm-standby.html">www.postgresql.org/docs/9.4/static/warm-standby.html#STREAMING-REPLICATION-SLOTS</a> </div><p>Source: <a href="https://habr.com/ru/post/245847/">https://habr.com/ru/post/245847/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../245833/index.html">HeadHunter Public Test</a></li>
<li><a href="../245835/index.html">The future of parametric CAD</a></li>
<li><a href="../245837/index.html">Concurrency structure in .net. ConcurrentQueue from the inside</a></li>
<li><a href="../245841/index.html">5 errors in user feedback</a></li>
<li><a href="../245845/index.html">Overview of App Annie features for Windows and Windows Phone developers</a></li>
<li><a href="../245849/index.html">Dagaz: Again about XSLT</a></li>
<li><a href="../245851/index.html">MyLifeOrganized: folders vs contexts</a></li>
<li><a href="../245853/index.html">Business is not childish - Or how did an eighth-grader deliver fruit?</a></li>
<li><a href="../245857/index.html">Installing BIND9 DNS on CentOS</a></li>
<li><a href="../245859/index.html">IOMeter2 v1.1.0</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>