<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Experience using WebRTC. Yandex lecture</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="What is better to use when developing software - native or web technologies? Holivar about this will not end soon, but few people will argue that the ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Experience using WebRTC. Yandex lecture</h1><div class="post__text post__text-html js-mediator-article">  What is better to use when developing software - native or web technologies?  Holivar about this will not end soon, but few people will argue that the native functions are useful to duplicate for use in browsers or WebView.  And if once the application for calls existed only separately from the browser, now they are easy to implement and on the web.  Developer Grigory Kuznetsov explained how to use WebRTC technology for P2P connections. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_Jvdi--GtOg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - As you all know, quite a few applications have recently been appearing, which are based on direct data exchange between two browsers, that is, P2P.  These are all kinds of messengers, chat rooms, dialers, video conferencing.  It can also be applications that perform some kind of distributed computing.  The limits of fantasy are not limited. <br><a name="habracut"></a><br>  How do we make such a technology?  Imagine that we want to make a call from one browser to another.  And let's fantasize what steps we need to achieve this goal.  First of all, it seems that the call is our picture, our voice, the image, and you need to get access to media devices connected to the computer: to the camera and to the microphone.  After you get access, you need your two browsers, two clients, each other to find.  We need to help them somehow connect, reach out, pass on meta-information. <br><br>  When you reach out, you need to start transferring data in P2P mode, that is, to ensure the transmission of media streams.  We have all the necessary items, we are ready to realize our cool new bike.  But this is a joke, we are engineers and we understand that this is expensive, unjustified and risky.  Therefore, as classic engineers, let's first think about what solutions already exist. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      First of all - the old dying technology Adobe Flash.  She‚Äôs really dying, and Adobe will stop supporting her by 2020.  The technology will really allow you to access your media devices, inside it you can implement all the necessary mechanics to help browsers connect, so that they start transmitting P2P information, but you will reinvent your bike again, because there is no single standard, unified approach to implementing this method data transmission. <br><br>  You can write a plugin for your browser.  This is how Skype works for browsers that do not support more advanced technologies.  You will have to sell your bike, because there is no single standard, and this is bad for users, because the user will have to install a plugin in the browser, perform additional actions.  Users do not like and do not want to do this. <br><br>  And there is WebRTC technology - Google Hangouts, Facebook Messenger work with it.  Voximplant uses it so you can make your calls.  Let's dwell on it in more detail.  This is a new developing technology, it appeared in 2011 and continues to evolve.  What does she allow to do?  Get access to the camera and microphone.  Establish a P2P connection between two computers and two browsers.  Naturally, it allows you to transfer media streams in real time.  In addition, it allows you to transfer information, that is, any binary date you can also transfer P2P, you can make your distributed computing system. <br><br>  Important point: WebRTC does not provide browsers with a way to find each other.  We can form all the necessary meta-information about us loved ones, but how can one browser know about the existence of another?  How to connect them?  Consider an example. <br><br><img src="https://habrastorage.org/webt/8l/dc/lu/8ldclukfmmhiyusud1ftwkmvmi0.png"><br><br>  There are two customers.  The first client wishes to make a call to the second client.  WebRTC gives all the necessary information to identify themselves.  But the question remains, how can one browser find another, how to send this meta information, how to initialize the call.  This is given to developers, we can use absolutely any method, take this meta-information, print it on paper, send it by courier, another one will use it, and everything will work. <br><br>  And we can come up with some kind of signaling mechanism.  In this case, it is a third-party mechanism that will allow us, if we know about our customers, to ensure the transfer between them of some information that is necessary to establish a connection. <br><br>  Consider an example using a signal server.  There is a signaling server that keeps a constant connection with our clients, for example, over web sockets or using HTTP.  The first client generates meta-information and sends it to the signaling server using web sockets or HTTP.  It also sends some part of the information with whom it is he who wants to connect, for example, a nickname or some other information. <br><br>  The signal server by this identifier determines which client exactly needs to redirect our meta information, and forwards it.  The second client takes it, uses it, sets it up for himself, forms the answer, and sends it to the signaling server using the signaling mechanism, which in turn relays it to the first client.  Thus, both clients currently have all the necessary date and meta information to establish a P2P connection.  Is done. <br><br>  Let's take a closer look at what exactly the clients exchange, they exchange the SDP datagram, Session Description Protocol. <br><br><img src="https://habrastorage.org/webt/zl/e-/ok/zle-oknfv3cz36cwgdbt00ldc4q.png"><br><br>  It is, in fact, a text file that contains all the necessary information to establish a connection.  There is information about the IP-address, the ports that are used, what kind of information is chased between clients, what it is - audio, video, what codecs are used.  Everything we need is there. <br><br>  Pay attention to the second line.  There is the client's IP address, 192.168.0.15.  Obviously, this is the IP address of a computer that is located on a local network.  If we have two computers, each of which is on the local network, each of which knows its IP address within this network, they want to call.  Will they be able to do this with such a datagram?  Obviously not, they do not know the external IP addresses.  How to be? <br><br><img src="https://habrastorage.org/webt/6j/ol/xu/6jolxumekywnyr1txfh6vdhjk-a.png"><br><br>  Let's step aside and see how NAT works.  On the Internet, many computers are hidden behind routers.  There are local networks within which computers know their addresses, there is a router that has an external IP address, and outside all these computers stick with the IP address of this router.  When a packet from a computer on the local network goes to the router, the router looks to where it needs to be redirected.  If it is on another local network, then it simply relays it, and if you need to send it outside, to the Internet, then a routing table is created. <br><br><img src="https://habrastorage.org/webt/0c/w3/vj/0cw3vj67zemxzrbjwe5cr0bfzvc.png"><br><br>  We fill in the internal IP address of the computer that wishes to forward the packet, its port, set the external IP address, the IP address of the router, and do the port substitution as well.  What is it for?  Imagine that two computers are accessing the same resource, and we need to correctly route the response packets.  We will identify them by port, the port will be unique for each of the computers, while the external IP address will be the same. <br><br>  How to live if there is NAT, if computers stick out under one IP-address, and inside they know about each other through others? <br><br>  ICE - Internet Connectivity Establishment comes to the rescue.  It describes how to bypass NAT, how to establish a connection if we have NAT. <br><br>  This framework uses the attribution of a so-called STUN server. <br><br><img src="https://habrastorage.org/webt/59/zv/am/59zvamcoxdislwvhlj3qkn2k_cq.png"><br><br>  This is such a special server, referring to which, you can find out your external IP-address.  Thus, in the process of establishing P2P connections, each client must make an inquiry to this STUN server in order to find out its IP address, and form additional information, IceCandidate, and by means of a signaling mechanism also this IceCandidate to exchange.  Then customers will know each other with the correct IP addresses, and will be able to establish a P2P connection. <br><br>  However, there are more complex cases.  For example, when a computer is hidden behind a double NAT.  In this case, the ICE framework prescribes the use of a TURN server. <br><br><img src="https://habrastorage.org/webt/yd/0r/j3/yd0rj3j5touybbu9ji2yxajvu0w.png"><br><br>  This is such a special server that turns the client-client connection, P2P, into a client-server-client connection, that is, it acts as a repeater.  The good news for developers is that regardless of which of the three scenarios the connection was set up for, whether we are on the local network, whether you need to contact a STUN or TURN server, the API technology will be identical for us.  We simply specify the configuration of ICE and TURN servers at the beginning, indicate how to access them, and after that the technology does everything for us under the hood. <br><br><img src="https://habrastorage.org/webt/u5/gm/d3/u5gmd3hsoofg6zt_-gnop6nx0zs.png"><br><br>  A brief summary.  To establish a connection, you need to select and implement some kind of signaling mechanism, a certain intermediary, that will help us send meta information.  WebRTC will give us all the necessary meta for this. <br><br>  We have to fight with NAT, this is our main enemy at this stage.  But to get around it, we use the STUN server to find out our external IP address, and we use the TURN server as a repeater. <br><br>  What exactly are we transmitting?  About media streams. <br><br><img src="https://habrastorage.org/webt/qd/5n/sh/qd5nsho7njp_zbptyvvgxzgyeyk.png"><br><br>  Media streams are channels that contain tracks within themselves.  Tracks within the media stream are synchronized.  Audio and video will not diverge, they will come with a single timing.  You can make any number of tracks inside the media stream, the tracks can be managed separately, for example, you can mute the audio, leaving only the picture.  You can also transfer any number of media streams, which allows you, for example, to implement a conference. <br><br>  How to access media from a browser?  Let's talk about the API. <br><br><img src="https://habrastorage.org/webt/xd/li/lw/xdlilwqq1hvfwsmpzbo2abyu22i.png"><br><br>  There is a getUserMedia method that accepts a set of constraints as input.  This is a special object where you specify which particular devices you want to access, which particular camera, which microphone.  Specify the characteristics you want to have, exactly what resolution, and there are also two arguments - successCallback and errorCallback, which is called in case of success or failure.  In more modern implementations of technology, promises are used. <br><br>  There is also a convenient method enumerateDevices, which returns a list of all media devices connected to your computer, which gives you the opportunity to show them to the user, draw some kind of selector so that the user can choose which particular camera he wants to use. <br><br><img src="https://habrastorage.org/webt/ga/vp/uo/gavpuolkqqbou4mgkr5nkgyn_ga.png"><br><br>  The central object in the API is the RTCPeerConnection.  When we perform a connection, we take the class RTCPeerConnection, which returns a peerConnection object.  As a configuration, we specify a set of ICE servers, that is, STUN and TURN servers, which we will contact during the installation process.  And there is an important onicecandidate event that triggers every time we need the help of our alarm mechanism.  That is, the WebRTC technology made a request, for example, to the STUN server, we learned our external IP address, a new formed ICECandidate appeared, and we need to send it using a third-party mechanism, the event was triggered. <br><br><img src="https://habrastorage.org/webt/ou/lu/zp/ouluzpi6ahoovtpo1acf01pblbe.png"><br><br>  When we establish a connection and want to initialize the call, we use the createOffer () method to form the initial SDP, offer SDP, the same meta information that needs to be sent to the partner. <br><br>  To set it in PeerConnection, we use the setLocalDescription () method.  The interlocutor receives this information using the signaling mechanism, sets it with the help of the setRemoteDescription () method and generates a response using the createAnswer () method, which is also sent to the first client using the signaling mechanism. <br><br><img src="https://habrastorage.org/webt/-z/tt/ns/-zttnspmlmdyfjgvn6koame5duw.png"><br><br>  When we got access to the media, got the media stream, we transmit it to our P2P connection using the addStream method, and our interlocutor finds out about it, the onaddstream event is cleared from it.  He will receive our stream and be able to display it. <br><br><img src="https://habrastorage.org/webt/e5/4m/ot/e54mot_c6nmcg60na7bj-k7kbro.png"><br><br>  You can also work with data streams.  Very similar to the formation of the usual peerConnection, just specify RtpDataChannels: true and call the createDataChannel () method.  I will not dwell on this in detail, because this kind of work is very similar to working with web sockets. <br><br>  A few words about security.  WebRTC works only on HTTPS, your site must be signed with a certificate.  Media streams are also encrypted, using DTLS.  The technology does not require installing anything extra, no plug-ins, and this is good.  And it will not be possible to make a spy application, the site will not eavesdrop or spy on the user, he will show the user a special promt, request access from him and get it only if the user allows access to the audio and media devices. <br><br><img src="https://habrastorage.org/webt/4d/pf/mp/4dpfmps0b2axjq2kyrshvgf-xaa.png"><br><br>  As for browser support, IE remains and will remain red.  At the end of last year, support for Safari was added, that is, all modern browsers already know how to work with this technology and we can safely use it. <br><br>  I want to share a set of all kinds of utilities that will help you if you want to work with WebRTC.  First of all it is <a href="https://github.com/webrtc/adapter">adapter</a> .  Technologies are evolving all the time, and there is a difference in browser APIs.  The adapter library eliminates this difference and makes work easier.  Convenient library for working with data streams - <a href="https://github.com/peers/peerjs">Peerjs</a> .  You can also look at the open implementations of the <a href="https://github.com/jselbie/stunserver">STUN</a> and <a href="https://github.com/jitsi/turnserver">TURN servers</a> .  A large set of tutorials, examples, articles is on the page <a href="https://github.com/openrtc-io/awesome-webrtc">awesome-webrtc</a> , I highly recommend. <br><br>  Last useful when debag utility - webrtc-internals.  During development, you can type a special command in the address bar - for example, in Chrome browser, this is Chrome: // webrtc-internals.  You will see a page with all the information about your current WebRTC connection.  There will be both call sequences in the methods, and all the datagrams exchanged between browsers and graphs that somehow characterize your connection.  In general, there will be all the information that will be needed during debugging and development.  Thanks for attention. </div><p>Source: <a href="https://habr.com/ru/post/419951/">https://habr.com/ru/post/419951/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../419941/index.html">Photo tour of the office "Audiomania": Part One</a></li>
<li><a href="../419943/index.html">What we read in July: how to find time to read, five books for a timlid and some fresh articles</a></li>
<li><a href="../419945/index.html">How to prepare for an interview in Google and not pass it. Twice</a></li>
<li><a href="../419947/index.html">Connection to PiZeroW with Raspbian Stretch Lite, without additional adapters and monitor</a></li>
<li><a href="../419949/index.html">What video codecs (do not) use browsers for video calls</a></li>
<li><a href="../419953/index.html">I am writing a book about the first ‚Äúour‚Äù startup that has conquered the world: help</a></li>
<li><a href="../419955/index.html">UART FIFO Buffer Features in ESP32</a></li>
<li><a href="../419961/index.html">The digest of interesting materials for the mobile developer # 265 (August 6 ‚Äî August 12)</a></li>
<li><a href="../419963/index.html">Making a smart controller for an air conditioner on an ESP8266</a></li>
<li><a href="../419965/index.html">Features of ExtremeXOS Switch Configuration</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>