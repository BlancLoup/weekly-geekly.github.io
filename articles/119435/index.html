<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>CUDA: performance aspects in solving typical problems</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Before starting to transfer the implementation of the computational algorithm to a video card, it is worth considering whether we will get the desired...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>CUDA: performance aspects in solving typical problems</h1><div class="post__text post__text-html js-mediator-article"><img align="right" src="https://habrastorage.org/getpro/habr/post_images/912/44f/63e/91244f63e5b08b65adc47b63d36ac8df.jpg">  Before starting to transfer the implementation of the computational algorithm to a video card, it is worth considering whether we will get the desired performance gain or just lose time.  And despite the manufacturers' promises about hundreds of GFLOPS, the current generation of cards has its own problems, which are better known in advance.  I will not go deep into the theory and consider a few significant practical points and draw some useful conclusions. <br><a name="habracut"></a><br>  We will assume that you have <a href="http://habrahabr.ru/blogs/CUDA/54707/">figured out about</a> how CUDA works and have already downloaded a stable version of the <a href="http://developer.nvidia.com/cuda-toolkit-32-downloads">CUDA Toolkit</a> . <br><br>  I will torment the middle-end <a href="http://www.nvidia.ru/object/product-geforce-gtx-460-oem-ru.html">GTX460</a> graphics card on the Core Duo E8400. <br><br><h5>  Function call </h5><br>  Yes, if we want to count something, then we cannot do without calling a function performed on the card.  To do this, we write the simplest test function: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <blockquote><code><font color="black">__global__ <font color="#0000ff">void</font> stubCUDA( <font color="#0000ff">unsigned short</font> * output) <br> { <br> <font color="#008000">// the most valid function: yep, does nothing.</font> <br> }</font></code> </blockquote> <br>  Let me remind you that the __global__ specifier allows you to perform a function on the GPU by calling it from the CPU: <br><blockquote> <code><font color="black">cudaThreadSynchronize(); <br> stubCUDA&lt;&lt;&lt;GRID, THREADS&gt;&gt;&gt;(0); <br> cudaThreadSynchronize();</font></code> </blockquote> <br>  All function calls are asynchronous by default, so calls to cudaThreadSynchronize () are necessary to wait for the completion of the called function. <br><br>  Let's try to run such a block in a cycle: we get about <b>15,000</b> calls per second for GRID = 160, THREADS = 96. <br><br>  Let's just say not at all thick.  Even the simplest function that does nothing cannot be executed faster than 0.7 ms. <br><br>  The first assumption is that most of the time is spent on synchronization of threads and asynchronous calls would work much faster (although they can be applied more specifically to specific tasks). <br><br>  Check it out.  Without synchronization, it was possible to start the function <b>73100</b> times per second.  The result, it should be noted, is not at all impressive. <br><br>  And the last test, we run the function with GRID = THREADS = 1, it would seem that this should eliminate the overhead of creating a pile of threads inside the card.  But this is not the case, we get the same <b>73000-73500</b> calls per second. <br><br>  So, the moral: <br><ul><li>  It is absolutely pointless to run on the card those tasks that on the CPU are considered to be milliseconds. </li><li>  Synchronization of threads after a call reduces performance only slightly on average tasks. </li><li>  The number of threads and the size of the grid does not affect the total number of calls per second (of course, this is not so for ‚Äúuseful‚Äù functions that do something). </li></ul><br><h5>  Memory access from outside </h5><br>  In order to consider something useful, we need input and output data.  To do this, you need to understand how fast the data is transferred from / to the video card.  We use the following function: <br><blockquote> <code><font color="black">cudaMemcpy(data_cuda, image, data_cuda_size, cudaMemcpyHostToDevice);</font></code> </blockquote> <br>  Yes, CUDA offers us the means of asynchronous data transfer, but their performance, running ahead, does not differ from the synchronous function. <br><br>  We copy large blocks: as in the direction of cudaMemcpyHostToDevice, and cudaMemcpyDeviceToHost, we get a performance of about <b>2 GB / s</b> on large blocks (more than 100 megabytes).  In general, it is very good. <br><br>  Much worse is the situation with very small structures.  Transmitting by <b>4 bytes,</b> we receive no more than <b>22,000</b> calls per second, i.e.  <b>88 kb / s</b> . <br><br>  Morality: <br><ul><li>  It is advisable to group the data into large blocks and transfer them with a single call to the cudaMemcpy function. </li></ul><br><h5>  Memory access from the inside </h5><br>  After we have transferred the data to the card, you can begin to work with them.  I would like to evaluate the approximate speed of access to the video memory.  To do this, we write the following function: <br><blockquote> <code><font color="black">__global__ <font color="#0000ff">void</font> accessTestCUDA(unsigned <font color="#0000ff">short</font> * output, unsigned <font color="#0000ff">short</font> * data, <font color="#0000ff">int</font> blockcount, <font color="#0000ff">int</font> blocksize) <br> { <br> <font color="#008000">// just for test of max access speed: does nothing useful</font> <br> unsigned <font color="#0000ff">short</font> temp; <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> i = blockIdx.x; i &lt; blockcount; i += gridDim.x) <br> { <br> <font color="#0000ff">int</font> vectorBase = i * blocksize; <br> <font color="#0000ff">int</font> vectorEnd = vectorBase + blocksize; <br> <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> j = vectorBase + threadIdx.x; j &lt; vectorEnd; j += blockDim.x) <br> { <br> temp = data[j]; <br> } <br> } <br> output[0] = temp; <br> }</font> <br></code> </blockquote><br>  Here, the GRID and THREADS parameters are already used, until I explain why, but believe me - everything is as it should.  Picky ones will say that the result is spelled incorrectly due to the lack of synchronization, but we don‚Äôt need it. <br><br>  So, we get about <b>42 GB / c</b> for random reading.  This is not bad at all. <br><br>  Now we modify the function so that it copies the input data to the output.  It makes no sense, but allows us to estimate the recording speed in the video memory (since the change is quite simple, I will not duplicate the code). <br><br>  We get about <b>30 GB / s</b> for I / O.  It's not bad too. <br><br>  It is necessary to make an amendment to the fact that in fact we used sequential (with some deviations) memory access.  For an arbitrary number can worsen up to two times - but then, and this is not a problem? <br><br>  Morality: <br><ul><li>  Due to the very high speed of access to the memory on the cards, it is efficient to implement algorithms that use it intensively. </li></ul><br><h5>  Arithmetic operations </h5><br>  Quite simple examples will be omitted and we will do something useful.  Namely - image normalization (pixel [t]: = (pixel [t] -sub) * factor).  Actually code: <br><blockquote> <code><font color="black">__global__ <font color="#0000ff">void</font> normalizeCUDA(unsigned <font color="#0000ff">short</font> * data, <font color="#0000ff">int</font> blockcount, <font color="#0000ff">int</font> blocksize, <font color="#0000ff">float</font> sub, <font color="#0000ff">float</font> factor) <br> { <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> i = blockIdx.x; i &lt; blockcount; i += gridDim.x) <br> { <br> <font color="#0000ff">int</font> vectorBase = i * blocksize; <br> <font color="#0000ff">int</font> vectorEnd = vectorBase + blocksize; <br> <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> j = vectorBase + threadIdx.x; j &lt; vectorEnd; j += blockDim.x) <br> { <br> register <font color="#0000ff">float</font> d = ( <font color="#0000ff">float</font> )data[j]; <br> d = (d - sub) * factor; <br> data[j] = (unsigned <font color="#0000ff">short</font> )d; <br> } <br> } <br> }</font> <br></code> </blockquote><br>  Here three seemingly costly computational procedures are used: reduction to real numbers, ADDMUL and reduction to integers.  The forums scare that casting whole-material works very badly.  Maybe this was true for older generations of cards, but now it is not. <br><br>  Total processing speed: <b>26 GB / s</b> .  Three operations worsened performance relative to direct I / O by only 13%. <br><br>  If you look closely at the code, it normalizes it is not quite right.  Before writing to integers, the real must be rounded, for example, by the function round ().  But do not do it, and try to never use it! <br><br>  round (d): <b>20 GB / s</b> , another minus 23%. <br>  (unsigned short) (d + 0.5): <b>26 GB / s</b> , the time itself did not even change within the measurement error. <br><br>  Morality: <br><ul><li>  Arithmetic operations work really fast! </li><li>  For the simplest image processing algorithms, you can count on a speed of 10-20 GB / s. </li><li>  It is better to avoid using the round () function. </li></ul><br><h5>  Logical operations </h5><br>  Let's try to estimate the speed of logical operations, and at the same time we will do one more good deed: we will find the minimum and maximum values ‚Äã‚Äãin the array.  This stage usually precedes normalization (and it was for this purpose that it was written), but everything will be the opposite for us - because  it's harder.  Here is the working code: <br><blockquote> <code><font color="black">__global__ <font color="#0000ff">void</font> getMinMaxCUDA(unsigned <font color="#0000ff">short</font> * output, unsigned <font color="#0000ff">short</font> * data, <font color="#0000ff">int</font> blockcount, <font color="#0000ff">int</font> blocksize) <br> { <br> __shared__ unsigned <font color="#0000ff">short</font> sMins[MAX_THREADS]; <br> __shared__ unsigned <font color="#0000ff">short</font> sMaxs[MAX_THREADS]; <br> <br> sMins[threadIdx.x] = data[0]; <br> sMaxs[threadIdx.x] = data[0]; <br> <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> i = blockIdx.x; i &lt; blockcount; i += gridDim.x) <br> { <br> <font color="#0000ff">int</font> vectorBase = i * blocksize; <br> <font color="#0000ff">int</font> vectorEnd = vectorBase + blocksize; <br> <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> j = vectorBase + threadIdx.x; j &lt; vectorEnd; j += blockDim.x) <br> { <br> register unsigned <font color="#0000ff">short</font> d = data[j]; <br> <font color="#0000ff">if</font> (d &lt; sMins[threadIdx.x]) <br> sMins[threadIdx.x] = d; <br> <font color="#0000ff">if</font> (d &gt; sMaxs[threadIdx.x]) <br> sMaxs[threadIdx.x] = d; <br> } <br> } <br> <br> __syncthreads(); <br> <br> <font color="#0000ff">if</font> (threadIdx.x == 0) <br> { <br> register unsigned <font color="#0000ff">short</font> min = sMins[0]; <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> j = 1; j &lt; blockDim.x; j++) <br> <font color="#0000ff">if</font> (sMins[j] &lt; min) <br> min = sMins[j]; <br> <font color="#0000ff">if</font> (min &lt; output[0]) <br> output[0] = min; <br> } <br> <br> <font color="#0000ff">if</font> (threadIdx.x == 1) <br> { <br> register unsigned <font color="#0000ff">short</font> max = sMaxs[0]; <br> <font color="#0000ff">for</font> ( <font color="#0000ff">int</font> j = 1; j &lt; blockDim.x; j++) <br> <font color="#0000ff">if</font> (sMaxs[j] &gt; max) <br> max = sMaxs[j]; <br> <font color="#0000ff">if</font> (max &gt; output[1]) <br> output[1] = max; <br> } <br> <br> __syncthreads(); <br> } <br></font> <br></code> </blockquote><br>  There is no way without synchronization of threads and <a href="http://habrahabr.ru/blogs/CUDA/100363/">shared memory</a> . <br><br>  Final speed: <b>29 GB / s</b> , even faster normalization. <br><br>  Why I combined the code of minimum and maximum - both are usually needed, and the calls separately lose time (see the first paragraph). <br><br>  In general, throw a stone at someone who said that on video cards it‚Äôs bad with conditional operations: artificially it was possible to slow down this fragment almost 2 times, but for this it was necessary to increase the depth of conditions right up to 4!  if () if () if () if () else if () ... <br><br>  Morality: <br><ul><li>  On modern cards, in general, it is not so bad with logic, but a large depth of nested conditions should be avoided. </li></ul><br><h5>  Complex data structures </h5><br>  Guided by the idea that the algorithms and data structures are strongly related (at least to recall N. Wirth), you should check how things are with some complex data structures. <br><br>  This is where the problem arises, when transferring data to a function, we can use only two types of objects - constant integral types (numbers) and links to video memory blocks. <br><br>  The idea to build for example trees based on links is covered immediately: <br><ul><li>  we cannot allocate memory from the function running on the card; </li><li>  Any selection and copying of a small amount of data is very slow (see Section 2). </li></ul><br>  Thus, complex data structures remain to be represented as a solid block of memory and an array of references to the elements of this block.  So you can easily submit a hash table, tree, and index structure over any data array. <br><br>  Payback for such tricks is the need to use double indexing: <br><blockquote> <code><font color="black"><font color="#0000ff">for</font> ( <font color="#0000ff">int</font> j = vectorBase + threadIdx.x; j &lt; vectorEnd; j += blockDim.x) <br> { <br> temp = data[index[j]+i]; <br> }</font></code> </blockquote> <br>  This fragment works with a speed of <b>10 to 30 GB / s</b> , depending on the content and size of the index and data.  Memory usage can be attempted to be <a href="http://habrahabr.ru/blogs/CUDA/56514/">optimized,</a> but even at best, we lose 25% access speed.  Triple indexes behave even worse, losing 40% -60% of performance. <br><br><h5>  Today we understood a lot </h5><br>  With proper use of the capabilities of the video card, you can get unprecedented performance in tasks, say image processing, sound, video - everywhere where there are large amounts of data, the need for clever arithmetic and the absence of complex data structures. <br><br>  <i>If you like the topic, I‚Äôll tell you how to calculate several useful objects on a video card: Distance Map, image morphology and search indexes and show some interesting data structures that run fast enough and do not create unnecessary synchronization problems</i> . </div><p>Source: <a href="https://habr.com/ru/post/119435/">https://habr.com/ru/post/119435/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../119429/index.html">[Graphic editor on Canvas] Brush for sketches</a></li>
<li><a href="../119430/index.html">We canceled the last commission</a></li>
<li><a href="../119431/index.html">"In a circle of friends" on Habr√©</a></li>
<li><a href="../119433/index.html">Dropbox as Git repository</a></li>
<li><a href="../119434/index.html">Droider Chart 52. Hit parade of Android applications</a></li>
<li><a href="../119436/index.html">Color man or how to decorate echo output</a></li>
<li><a href="../119438/index.html">Sync notes. Deadlock</a></li>
<li><a href="../119439/index.html">What do people study in Russian schools?</a></li>
<li><a href="../119440/index.html">Bryansk Web Day 2011 Program</a></li>
<li><a href="../119441/index.html">The pirates helped the book to rise to the first position in popularity on Amazon before it went on sale</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>