<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Memory management of the guest machine in the cloud</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="One of the first problems you encounter when you decide to make ‚Äúunlimited memory‚Äù in the cloud is that modern operating systems are not ready for ‚Äúun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Memory management of the guest machine in the cloud</h1><div class="post__text post__text-html js-mediator-article">  One of the first problems you encounter when you decide to make ‚Äúunlimited memory‚Äù in the cloud is that modern operating systems are not ready for ‚Äúunlimited memory‚Äù.  This is due to disk cache. <br><br>  The kernel takes all the free memory for the cache.  If there are disk operations and there is free memory, the cache will grow.  In the case of a server with solely usable memory, this is good, however, if we say that all megabytes are paid, we don‚Äôt feel like paying for a disk cache of 10-20GB. <br><br>  I tried to find an opportunity to limit the size of the disk cache for Linux, but all that I found was a strange patch of 2003 (which, of course, was not taken to the main branch). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It turns out that the more the guest works, the more his kernel takes to itself memory from (unlimited) volume.  The result - if you don‚Äôt limit the system at all, it grows in a very short time either to the size of the disk devices (thanks, the disk cache is larger than the disk size does not happen), or to the maximum available memory on the platform.  Note that in these conditions, all technologies fail ‚Äî both memory compression and deduplication of memory pages (each VM has its own cache).  This problem faces any virtualization system.  Below are described the solutions with an eye on the Xen Cloud Platform. <br><br><a name="habracut"></a><br><br><h1>  Solutions </h1><br>  I see three solutions to the problem: <br><br><ol><li>  The xenballoon mechanism used in Xen.  In the kernel, a special driver when accessing it from within the system itself, reserves memory from the operating system and gives it to the hypervisor (‚Äúfrees up‚Äù).  If necessary, he is asked to "take back" - and he takes (ie, returns to the system).  In fact, the used balloon memory is busy from the point of view of the guest and freedom from the point of view of the hypervisor.  When the memory is taken from the hypervisor, it becomes free for the guest and busy for the hypervisor. </li><li>  External mechanism for the regulation of available memory.  It differs from baluning only in that the decision to allocate / delete memory is taken not by the application that is jerking the xenballloon, but by the external control system.  Zen has long allowed on the go to change the amount of available memory for guest machines (as you put, so much will be).  Up to a funny situation, when the memory gives less than busy now.  In this case, oom_killer comes to the rescue inside the guest system (and it‚Äôs better not to do so) </li><li>  Writing a patch to the kernel, which would limit the size of the disk cache to a certain fixed value. </li></ol><br><br><h1>  Read more </h1><br>  The third option is probably the most interesting.  But, requiring significant changes in the kernel code, and, perhaps, a revision of the entire mechanism of working with memory.  For me, this path is ... somewhat thorny. <br><br>  The first and second - really working now.  However, they have one major drawback: with such a system, the addition / deletion of free memory occurs asynchronously with requests.  Roughly speaking, if the guest system has 200 MB of free memory, the application asked for 500, then it will be denied allocation.  Because the kernel has no extra 300MB.  A daemon (or external monitor) will know about this problem after working out a request for memory allocation. <br><br>  ... It would seem that the obvious solution: let the kernel, when it is asked for free memory, pull the interface.  However, in this situation, the same core will infinitely have all the available memory for disk caches, since  no memory request will remain unanswered ... <br><br>  However, the situation is not hopeless.  First, applications usually do not eat memory in such chunks.  Usually, this is a gradual (more precisely, rather fast, but in smaller pieces) memory allocation for different applications as the load increases.  In this situation, every time there is too little memory left in the guest system, a daemon in the guest system or an external monitor can throw more memory. <br><br><h1>  Swapping </h1><br>  Secondly, there is a swap file.  If the application asked for 500 free 200 MB, then it will be given 200 megabytes of free memory, and 300 MB of little-used data will be thrown into a swap and the required will be returned.  And then the same monitor, seeing the lack of memory, will throw another 500 MB to the guest system, so that it can continue to work quietly.  Since the most irrelevant data will be thrown out in the swap, there is a high probability that access to them will be very, very rare (or never will happen at all).  Thanks to the ‚Äúdamper‚Äù in the form of a paging file, it is possible to objectively provide memory without situations oom (out of memory), but without a voracious cache of tens of gigabytes. <br><br>  The final scheme looks like this: For the guest system, a certain amount of free memory is allocated, larger than the amount of occupied memory.  This memory is used as a disk cache of a reasonable size (it is still needed, even on guest virtual machines, since it is they who know best about which disk pages are more important).  Regardless of how much the application uses memory, the free area remains always the same (minus minor fluctuations due to the asynchronous allocation of memory to applications and memory allocation of the guest OS). <br><br><h1>  Free memory </h1><br>  A separate task is the task of determining the free memory of the guest.  How can we do it "outside"?  Immediately I say - no way (if you do not consider the options of dirty digging in the brains of the guest kernel with the rough fingers of the hypervisor).  There is no way to understand that page ‚Äúa‚Äù is clean (free), and page ‚Äúb‚Äù is dirty (busy). <br><br>  In the XCP (Xen Cloud Platform), the only method for determining free memory is the agent (daemon), which tells the hypervisor how much memory is free.  Based on this information, the hypervisor decides how much memory to add and remove in the guest. <br><br>  What does this look like from the guest side?  She runs a simple script that, at intervals, writes to the xenstore (the communication channel between the hypervisor and the guest system) free memory data (at the same time, it writes the current IP address, OS version).  The cloud management system looks at this information and adds / removes guest memory. <br><br>  From the point of view of the guest, the amount of free memory almost always remains the same, regardless of how much memory the applications occupied, this memory is used for the disk cache.  In the case of some spontaneous bumps (request 1GB at a time - this is not very typical behavior) there are short moments of swapping, however, at the moment (testing has not started yet) I believe that these cases will be isolated and uncharacteristic.  From the point of view of the hypervisor, the guest machine changes the amount of memory used, and it varies depending on how much memory is actually used in the guest. <br><br>  What happens if a guest decides to ‚Äúgossip‚Äù and changes the code of the daemon reporting free memory, or simply turns it off?  For the hoster - nothing wrong.  It will simply cease to receive information about free memory (and will cease to regulate it).  If the data is written incorrectly, it will either take a lot of memory from the guest (the guest could have achieved this himself by nailing extra applications), or would give him a lot of memory - but the guest pays for consumption ... So I don‚Äôt think that anyone product decides to seriously bully with this service. <br><br>  I still doubt which memory management mechanism is better ‚Äî by means of a guest daemon (xenballooning) or by means of an external monitor. </div><p>Source: <a href="https://habr.com/ru/post/97998/">https://habr.com/ru/post/97998/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../97987/index.html">VikiGid - Android Encyclopedia of Sights of Ukraine</a></li>
<li><a href="../97988/index.html">Compaq Armada 1530</a></li>
<li><a href="../97992/index.html">Settling in a technopark (photo report)</a></li>
<li><a href="../97993/index.html">Coffeescript. And again about him. A summary of the amenities</a></li>
<li><a href="../97996/index.html">I2P - Creating your site</a></li>
<li><a href="../97999/index.html">New Kindle DX for $ 379</a></li>
<li><a href="../98000/index.html">From July 1 - duty-free import of goods up to 1000 euros (it was: 5-10 thousand rubles)</a></li>
<li><a href="../98001/index.html">Supercomputer problems in the middle lane</a></li>
<li><a href="../98003/index.html">Alan.Platform Tutorial (Part 1)</a></li>
<li><a href="../98005/index.html">Connecting a rotary encoder to a computer via USB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>