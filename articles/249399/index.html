<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we did the multitouch table</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi Habr. 
 Being engaged in Computer Vision, I was interested in Natural interfaces, communicated with people who design tables for bars with touch in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we did the multitouch table</h1><div class="post__text post__text-html js-mediator-article">  Hi Habr. <br>  Being engaged in Computer Vision, I was interested in Natural interfaces, communicated with people who design tables for bars with touch interfaces.  And I had an idea to make my own.  Cheap, angry, but the main thing is that everything works.  That is, it is important to test and test.  And here, my friend <a href="https://soundcloud.com/triophonix">Alexander Zhedelev</a> , a musical producer of the Russian Drama Theater of Estonia, suggested making some new musical instrument for performing at the Tallinn Music Week festival.  There was little time, and we started. <br><a name="habracut"></a><br>  In general, there are several approaches to the creation of this type of tables.  I will try to describe three of them. <br>  The general principle of the construction of such systems is as follows.  The image that the projector gives out is displayed on the glass behind which there is a coating, as which you can even take baking paper.  Touching reflects any part of the radiation back; you can put a camera under glass and detect touches.  In the figure below you can also see that in addition to the projector, the hand from the bottom is illuminated by infrared sources (this is one of the ways to build such systems). <br><img src="https://habrastorage.org/files/0ac/a3a/1bb/0aca3a1bb5e9420abf9dcdb14f742994.png" alt="image"><br>  Since we need to catch only touch gestures, not a picture from the projector, we need a way so that one does not affect the other.  For this purpose, cameras configured to receive only an infrared image are used.  The usual sensor matrix camera responds to both the visible and the infrared part of the spectrum.  In the video below, you can see how the camera of the Sony Xperia phone responds to the infrared beam of a remote Sharp sensor.  The eye does not see this beam, and for us the sensor in the operating mode is perceived as dark. <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/cWfX_BDZr0o%3Ffeature%3Doembed&amp;xid=25657,15700002,15700023,15700186,15700190,15700253&amp;usg=ALkJrhhgisBzmR_P7bzgq9-1xhPVDoZDHw" frameborder="0" allowfullscreen=""></iframe><br>  Typically, the camera is a filter that cuts off the infrared and transmits only the visible spectrum.  For our purposes, we need to redo all the way around.  That is, remove the lens, remove from there a filter that only allows visible light to pass through, and install a filter that only allows infrared radiation to pass through, since we will recognize gestures using this part of the spectrum.  Generally any webcam will do.  I took the good old PS3 Eye, because it gives the best result in price / quality.  Removing the filter itself is also not difficult.  <a href="https://codelaboratories.com/research/view/ps3-eye-disassembly">Like this.</a> <br>  In order to cut off the visible light, it is necessary to assemble the camera and put in front of the lens a filter that passes only infrared radiation.  It can be bought at the radio store.  It looks like dark red glass.  Now we have a camera that perceives IR radiation.  You can test it immediately, the image from the projector should look like a gray monotonous background. <br>  Now about the approaches themselves. <br><br>  The first is an expensive, but reliable enough, it is to hold on the sides of the table frame, immediately under the glass, a chain of infrared LEDs that will highlight the hands.  Pros - a very clear image of the reflection of the fingers, which is achieved due to the proximity of the emitting LEDs.  Cons - additional difficulties in the installation of the diodes and the general scheme of their power.  As a rule, this scheme is used in commercial approaches. <br><img src="https://habrastorage.org/files/a51/978/b27/a51978b277c745b1aa821bc8b4469a49.jpg" alt="image"><br><br>  The second is to put additional sources of infrared radiation under the glass next to the projector, as in the figure at the very beginning.  I tried this approach, but revealed a few flaws.  The radiation must be sufficiently scattered, otherwise some parts will be illuminated more than others.  And there is the problem of glare.  I experienced a bunch of IR LEDs, but they gave a very strong directional radiation, which was glare.  No diffuse filters helped, the glass partially reflected the flow, and the camera fixed a permanently present spot.  In general, this is an unfortunate approach, and I would not recommend it.  Uniform lighting is difficult to obtain. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The third one that I used is the easiest and most effective.  In fact, we do not need a separate light.  The fact is that the projector lamp emits a fairly wide spectrum of radiation, including infrared.  It is enough to look through our modified camera on the projection, and we will see a uniform gray background.  Bingo. <br><br>  The frame itself was assembled from wood.  Plexiglas planted on it.  The camera was directly under the glass. <br>  This is the AudioKinetic plan.  Below you can see the table layout drawn with a marker. <br><img src="https://habrastorage.org/files/75f/099/a30/75f099a30b0b47d6a9addf96d4e35682.jpg" alt="image"><br><br>  But the table itself. <br><img src="https://habrastorage.org/files/f03/570/7e0/f035707e08974f7187864de629571b8c.jpg"><br><br>  To recognize the BLOB (these are the reflections that the camera sees), I used Community Core Vision, CCV.  This is a ready-made solution that relays the recognition and transmits the results via the TUIO protocol.  TUIO is an open framework that defines the protocol and API for building multitouch interfaces.  In principle, if there was more time, I would write my BLOB detector on OpenCV, since there is nothing particularly difficult for this task.  The spots are well seen, and on OpenCV it would look like this - we get a picture, remove the noise, build a bitmap card, skip the Canny algorithm, find the contours and then translate their coordinates to TUIO objects by specification.  It would take a calibration module to set the coordinates.  CCV uses the subtraction of the background image from the resulting image, there is also an adaptive mode, which takes into account the slow background changes.  At OpenCV, this can be implemented using the codebook and connected components. <br>  Now we have a system that translates TUIO objects, and we can use everything that accepts these objects, or write to the client.  For example, in Java this is done quite easily, there are many examples on the net. <br><br>  CCV settings. <br><img src="https://habrastorage.org/files/bc0/a43/999/bc0a439999a5486d860e2d48bd6a3b82.png" alt="image"><br><br>  Further, since it was planned to use this table to control sound synthesis, the TUIO module for Ableton was used, which allows you to attach gestures to sound generation parameters, instruments, and so on.  After that, Alexander Zhedelev worked on setting the key, pairing with other records, and generally experimented as he wanted.  At the end of the video is shown about how and what. <br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/JpnMUTiYvOQ%3Ffeature%3Doembed&amp;xid=25657,15700002,15700023,15700186,15700190,15700253&amp;usg=ALkJrhgjSvGWI8Sy3y4GOb7_T5VwhS47wQ" frameborder="0" allowfullscreen=""></iframe><br><br>  And here is the edited version.  Look in the headphones. <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/oqkImBtrxog%3Ffeature%3Doembed&amp;xid=25657,15700002,15700023,15700186,15700190,15700253&amp;usg=ALkJrhj1s5I2_Uf16L-zJKhJtpgzML4mZQ" frameborder="0" allowfullscreen=""></iframe><br><br>  As you can see in the video, we have already played, put paper on glass and painted on it.  Received playing drawing. <br><br>  One observation.  It is not necessary to touch the glass. Already at some distance from it a reflection occurs, and the camera captures it.  There is space for the game with the settings, and as a result, you can make an air-touch screen. <br>  There is one disadvantage associated with the TUIO protocol, its objects need to be relayed.  I.e;  if I want to run beautiful visuals and sound synthesis in parallel, then I need a repeater, because if the interface module accepts a TUIO object, then let's say Flash visuals can no longer see this object. <br><br>  I want to say thanks to all the people who participated, especially <a href="https://soundcloud.com/triophonix">Alexander Zhedelev</a> , Sergey Dragunov, Krista Koester. <br>  <a href="https://www.facebook.com/AudioKinetica%3Ffref%3Dts">Audiokinetica</a> </div><p>Source: <a href="https://habr.com/ru/post/249399/">https://habr.com/ru/post/249399/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../249389/index.html">Music as big data. Why, instead of sound quality, you need to think about convenience</a></li>
<li><a href="../249391/index.html">Mod USB-COM adapter, which will save your nerves when flashing the Arduino Pro Mini and not only</a></li>
<li><a href="../249393/index.html">React Native Announcement</a></li>
<li><a href="../249395/index.html">STM32 and FreeRTOS. 4. Step toward HAL</a></li>
<li><a href="../249397/index.html">Shopkeeper 3.0 for MODX Revolution Review</a></li>
<li><a href="../249401/index.html">Robotics programming with Arduino and ROS</a></li>
<li><a href="../249403/index.html">We write the load tester on Node.js</a></li>
<li><a href="../249405/index.html">Forensic system administration</a></li>
<li><a href="../249407/index.html">Browser Vivaldi - the latest news and announcements</a></li>
<li><a href="../249409/index.html">Reverse engineering of Parktronic protocol. Dance of little bits</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>