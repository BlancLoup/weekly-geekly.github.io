<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to teach your neural network to analyze morphology</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, we talked about the generator of poetry . One of the features of the language model underlying it was the use of morphological markup to obt...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to teach your neural network to analyze morphology</h1><div class="post__text post__text-html js-mediator-article"><p>  Recently, we talked about the <a href="https://habrahabr.ru/post/334046/">generator of poetry</a> .  One of the features of the language model underlying it was the use of morphological markup to obtain better consistency between words.  However, the morphometry used had one fatal flaw: it was obtained using a ‚Äúclosed‚Äù model that was not available for general use.  More specifically, the sample on which we were trained was marked up with a model created for <a href="http://www.dialog-21.ru/">Dialogue 2017</a> and based on ABBYY dictionaries and dictionaries. </p><br><p>  I really wanted to save the generator from such restrictions.  For this it was necessary to build your own morphological analyzer.  At first I made it part of the generator, but in the end it turned into a separate project, which, obviously, can be used not only for generating poetry. </p><br><p>  Instead of the morphological engine ABBYY, I used the widely known <a href="https://github.com/kmike/pymorphy2">pymorphy2</a> .  What is the result?  Spoiler - turned out well. </p><a name="habracut"></a><br><h2 id="zadacha">  Task </h2><br><p>  I suspect everyone in the school was engaged in morphological analysis: they determined, say, the case of nouns, the face of verbs, and even tried to distinguish between adjectives with participles.  As a result, we received tests like this: </p><br><img src="https://habrastorage.org/webt/59/df/3e/59df3e63cd5e5357965574.png" width="50%"><br><p>  It uses the <a href="http://universaldependencies.org/">Universal Dependencies</a> markup notation, which is gradually becoming the standard in the world of computational linguistics for most languages. </p><br><p>  Despite the fact that morphoanalysis is a very school task, it is not so easy to teach a computer to solve it. </p><br><p>  One of the difficulties on this path is our language itself.  He is very homonymous.  Nouns, for example, very often coincide in different cases: compare, I see a table and a table standing.  The forms of completely different words coincide - like, say, the well-known "steel" and "glass".  Usually, seeing the context is not at all difficult to distinguish between them.  Actually, all systems of morphological analysis are based on the proper use of the context. </p><br><p>  There is, unfortunately, another difficulty: the lack of a real standardization of morpho-marking.  Different systems may have different opinions on the number of cases in the Russian language or on whether participles with text imprints are independent parts of speech or, for example, verbs.  This makes it very difficult to compare different morpho parsers for the Russian language, and therefore the choice of the best. </p><br><p>  This year, the <a href="http://www.dialog-21.ru/evaluation/2017/morphology/">MorphoRuEval-2017</a> morphological analysis track was held at the Dialogue conference, whose goal was to achieve this standardization.  It is unlikely that the organizers managed to fully achieve their goal, but they still released training material and a sample to compare their results with the results of the teams participating in the competition.  Therefore, I made my morphological analyzer based on the results of this track, and especially on the results of one of its participants, Daniil Anastasyev, who regularly consulted me. </p><br><p>  I will try to briefly describe the essence of the track, for details, it is better to refer to the original <a href="http://www.dialog-21.ru/media/3951/sorokinaetal.pdf">article</a> and <a href="https://github.com/dialogue-evaluation/morphoRuEval-2017">materials</a> . </p><br><h3 id="postanovka-zadachi-v-sorevnovanii">  Task setting in competition </h3><br><p>  An offer is given.  For each word in a sentence, it is necessary to determine the part of speech and grammatical meaning, and also (this was taken into account separately) to predict the word lemma.  For example: </p><br><p><img src="https://habrastorage.org/webt/59/df/3f/59df3fc003491439640169.png"></p><br><p>  Here, the first column contains the numbers of words, the second column contains the initial version of the token, the third contains the lemma (initial form) words, the fourth column contains part of speech (NOUN is a noun, VERB is a verb, ADJ is an adjective, etc.) column - the rest of the grammatical meaning, a set of realizing gramme for the appropriate grammatical categories. </p><br><p>  It is worth explaining here: for each part of speech there is a set of grammatical categories, each category is a set of mutually exclusive grammes.  Within a specific word form, each category can be realized uniquely. </p><br><p>  For example, for nouns there is a category of number (Number).  A number can be either singular (Sing) or plural (Plur).  In the text above, the word form of the program has a singular (but it could be plural - because homonymy!).  In addition, she is inanimate (Animacy = Inan), in the genitive case (Case = Gen) and feminine (Gender = Fem). </p><br><p>  Thus, Animacy, Case, Gender and Number are the categories into which the grammatical meaning of the noun is broken, and the inanimate, genitive, feminine gender, the only number is the vector of grammes realized for them. </p><br><p>  As part of the competition, it was proposed to predict a somewhat trimmed set of possible grammatical meanings.  In total, about 250 values ‚Äã‚Äãwere chosen as predicted. </p><br><p>  The path was divided into 2 parts: open and closed.  In the framework of the open part, it was allowed to use any training samples, in the framework of the closed only provided by the organizers (in this case, as far as I understand, the use of external dictionaries was allowed in the closed part). </p><br><p>  Daniel only participated in the open track, because he used the company's internal building. </p><br><h3 id="dannye">  Data </h3><br><p>  The organizers <a href="https://github.com/dialogue-evaluation/morphoRuEval-2017">suggested the</a> following as labeled corps: </p><br><ul><li>  GIKRYA UD - about 1 million tokens </li><li>  NCRD UD - about 1.2 million words </li><li>  Open UD case - approximately 400 thousand tokens </li><li>  SynTagRus - approximately 900 thousand tokens </li></ul><br><p>  Testing was conducted on subsamples of multi-genre buildings: </p><br><ul><li>  news corps (from Lenta) </li><li>  fiction corps </li><li>  Corps texts from VK </li></ul><br><p>  Marked corps are quite different from each other.  This is primarily due to the conversion errors and the specificity of the markup: the inconsistency of the markup that was already mentioned was attempted to be solved by automatic processing of the cases, but failed to completely reduce them to one format.  As a result, at the competition itself, participants used only the GIKRYA corps for training, because adding others only reduced quality.  In addition, there are errors in the cases themselves (I noticed this while I was doing the analysis of the errors of my algorithm).  Example: </p><br><p><img src="https://habrastorage.org/webt/59/df/40/59df402324ac7805217355.png"></p><br><h3 id="rezultaty-dorozhki">  Track results </h3><br><p>  A total of 11 teams participated in the closed track and 5 in the open.  The final results are laid out in a <a href="https://docs.google.com/spreadsheets/d/1npLGIvfxtjRiLRuQjd1rkbnr-nlKBWC_yKd_0nRYTnE/edit">separate table</a> .  Accuracy was considered by the grammatical meanings of individual tokens, accuracy immediately by complete sentences, accuracy taking into account lemmatization by tokens, accuracy taking into account lemmatization by sentences. </p><br><p>  I took as a basis the model that ranked first in the open track.  It was suggested that it was not only the case of ABBYY and corporate morphology, which was later fully justified. </p><br><h2 id="bazovaya-model">  Basic model </h2><br><h4 id="anastasyev-d-g-andrianov-a-i-indenbom-e-m-part-of-speech-tagging-with-rich-language-descriptionhttpwwwdialog-21rumedia3895anastasyevdgetalpdf">  Anastasyev DG, Andrianov AI, Indenbom EM, <a href="http://www.dialog-21.ru/media/3895/anastasyevdgetal.pdf">Part-of-Speech Tagging with Rich Language Description</a> </h4><br><p>  The following signs were used for the word: <br>  embedding words </p><br><ul><li>  vector of grammatical meanings </li><li>  class probability vector </li><li>  presence of punctuation in the context of specific positions </li><li>  capitalization </li><li>  the presence of frequency suffixes </li></ul><br><p>  The most useful thing here is a vector of grammatical meanings (and for it corporate dictionaries were needed).  The vectors of grammatical meanings were obtained from the probabilities of each possible grammatical analysis.  These probabilities are simply probabilities of word forms, calculated from the marked corps.  In ABBYY, they are rated for huge enclosures, marked up with Compreno. </p><br><p>  From several vectors of grammatical meanings with different probabilities, one is obtained as follows: the probabilities of each gramme are taken separately and are normalized to the total probability for a category.  For example, for the word chair, the probability of the nominative form is 1.03 ¬∑ 10 ^ (- 6), and the accusative case is 8.15 ¬∑ 10 ^ (- 7).  Then in the common vector in the cell that corresponds to the accusative case 8.15 ¬∑ 10 ^ (- 7) / (8.15 ¬∑ 10 ^ (- 7) + 1.03 ¬∑ 10 ^ (- 6)) = 0.4417 will be written. </p><br><p>  Embeddings of words were taken unprepared, uniformly initialized - the use of pre-trained did not give an increase in accuracy. </p><br><p>  The neural network itself is a two-level bidirectional LSTM with an additional fully connected layer: </p><br><img src="https://habrastorage.org/webt/59/df/40/59df40b691943842703804.png" width="80%"><br><br><p> Quite original in this work is the pre-training on the large internal building of the company with markings that do not correspond to the markings of the competition, and then the additional training on the relatively small building of GIKRYa.  This is somewhat reminiscent of standard methods for solving a large class of problems in image analysis: we take a network trained on ImageNet and learn more on our sample. </p><br><h2 id="moyo-reshenie">  My decision </h2><br><h4 id="pymoprhy2">  pymoprhy2 </h4><br><p>  First of all, I needed a replacement of the corporate analyzer, which would give out possible variants of the analysis of word forms.  There were not so many options for Python, and besides, on the basis of pymorphy2 there was already a <a href="https://github.com/kmike/dialog2017">solution</a> that, for reasons unknown to me, did not get into the competition.  The CRF baseline from there to check turned out to be better than almost all solutions from the track. </p><br><h4 id="model">  Model </h4><br><p>  Initially, I left word signs with word embeddings and vectors of grammatical meanings.  In my model, the vectors are already collected on the basis of the options that pymorphy2 returns.  The architecture of the model was exactly the same as the original.  It turned out about 94% on the benchmark, which is pretty good, considering that I used a much smaller number of scales. </p><br><p>  Not satisfied with the quality of the results, I began to think how, first, to shrink the model so that it weighed less and worked a little faster, and secondly, how to accurately take information from the symbolic level.  In one of the <a href="https://arxiv.org/abs/1604.05529">articles,</a> I saw the solution of both problems at once - to make LSTM RNN above the symbolic level of individual words, and use the output of these grids on words as part of the input vector for the main two-layer network.  Testing has shown that the symbolic representation even wins over word embeddings. </p><br><p><img src="https://habrastorage.org/webt/59/df/41/59df4102bf102495949930.png"></p><br><p>  As for lemmatization, I did not reinvent my own bicycle.  Among the options given by pymorphy2, the lemma of the one that best matches grammes is chosen.  If there are none at all, a coincidence in terms of speech will come down.  If nothing is the same in terms of speech, we simply take the lemma of the frequency analysis itself. </p><br><p>  To get good quality at the competition, however, I had to add additional logic for processing the lemmas.  For example, the initial form of participles is defined in the corpus and in pymorphy2 in different ways. </p><br><p>  The results of my model on the test sample are presented below. </p><br><p>  News: </p><br><ul><li>  Quality by tags: <br><ul><li>  3999 tags out of 4179, accuracy 95.69% </li><li>  264 sentences from 358, accuracy 73.74% </li></ul></li><li>  Full parsing quality: <br><ul><li>  3865 words from 4179, accuracy 92.49% </li><li>  180 offers from 358, accuracy 50.28% </li></ul></li></ul><br><p>  VK: </p><br><ul><li>  Quality by tags: <br><ul><li>  3674 tags out of 3877, accuracy 94.76% </li><li>  418 sentences from 568, accuracy 73.59% </li></ul></li><li>  Full parsing quality: <br><ul><li>  3551 words from 3877, accuracy 91.59% </li><li>  341 sentences of 568, accuracy 60.04% </li></ul></li></ul><br><p>  Hood  literature: </p><br><ul><li>  Quality by tags: <br><ul><li>  3879 tags out of 4042, accuracy 95.97% </li><li>  288 sentences from 394, accuracy 73.10% </li></ul></li><li>  Full parsing quality: <br><ul><li>  3659 words from 4042, accuracy 90.52% </li><li>  172 sentences from 394, accuracy 43.65% </li></ul></li></ul><br><p>  If you look at the <a href="https://docs.google.com/spreadsheets/d/1npLGIvfxtjRiLRuQjd1rkbnr-nlKBWC_yKd_0nRYTnE/edit">results table</a> , you can see that my model bypasses all other models from the closed track in terms of the quality of tag definition, and with a margin, but inferior to some in the quality of lemmatization. </p><br><p>  On sentences with syntactic homonymy, such as ‚ÄúMowed oblique oblique oblique‚Äù, the model honestly messes up.  Moreover, it is unstable, at different stages of training (short-medium-long sentences) in different ways. </p><br><p>  Unfortunately, there were no benchmarks on the speed of work within the track.  If such were, my model probably sagged pretty badly.  On my home laptop, it processes approximately 100 to 500 words per second, which, of course, is not suitable for an industrial solution.  Our needs for marking the text for the generator of poems are completely satisfied. </p><br><p>  As for the space occupied, the whole model weighs about 3MB, so it is even included in the PyPi package.  Here I am satisfied. </p><br><p>  There is an assumption that the additional training on other buildings may slightly increase the quality of the model, as well as an increase in the number of scales.  But, again, I generally like the current version. </p><br><h2 id="primery-raboty">  Work examples </h2><br><h3 id="udachnye-razbory">  Successful parsing </h3><br><img src="https://habrastorage.org/webt/59/df/41/59df416d15611795792559.png" width="100%"><br><br><img src="https://habrastorage.org/webt/59/df/41/59df4173ea134232179576.png" width="80%">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/59/df/41/59df417ad13a8274754868.png" width="100%"><br><br><img src="https://habrastorage.org/webt/59/df/41/59df41860d0c5902763350.png" width="100%"><br><br><h3 id="neudachnye-razbory">  Unsuccessful parsing </h3><br><img src="https://habrastorage.org/webt/59/df/41/59df4197894ac592200887.png" width="60%"><br><br><img src="https://habrastorage.org/webt/59/df/41/59df41a119b70668643795.png" width="80%"><br><br><h2 id="ssylki">  Links </h2><br><ul><li>  <a href="https://github.com/IlyaGusev/rnnmorph">Repository</a> </li><li>  <a href="https://pypi.python.org/pypi/rnnmorph">Package in pypi</a> </li><li>  <a href="http://www.dialog-21.ru/media/3951/sorokinaetal.pdf">MorphoRuEval-2017: an Evaluation Track for the Automatic Morphological Analysis Methods for Russian</a> </li><li>  <a href="http://www.dialog-21.ru/media/3895/anastasyevdgetal.pdf">Part-of-speech Tagging with Rich Language Description</a> </li><li>  <a href="http://www.ltl.uni-due.de/wp-content/uploads/horsmannZesch_emnlp2017.pdf">Do LSTMs really work so well for PoS tagging?</a>  <a href="http://www.ltl.uni-due.de/wp-content/uploads/horsmannZesch_emnlp2017.pdf">- A replication study</a> </li><li>  <a href="https://arxiv.org/abs/1604.05529">Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss</a> </li></ul><br><p>  The post was written in collaboration with Daniel Anastasiev (@DanAnastasyev).  Many thanks to Nadia Karatsapova for reading the article. </p></div><p>Source: <a href="https://habr.com/ru/post/339954/">https://habr.com/ru/post/339954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../339938/index.html">We play APK golf. Reduce the size of Android APK files by 99.9%</a></li>
<li><a href="../339940/index.html">A minute of Black Magic</a></li>
<li><a href="../339942/index.html">SuperJob Meetup. System business analysis. Live broadcast</a></li>
<li><a href="../339950/index.html">Dow Jones Financial Information Agency mistakenly reported merging Apple and Google</a></li>
<li><a href="../339952/index.html">Dynamic analysis of iOS applications without Jailbreak</a></li>
<li><a href="../339956/index.html">Data Science Week 2017. Review of the second and third day</a></li>
<li><a href="../339958/index.html">Total exhaustion, or is there life after IPv4</a></li>
<li><a href="../339960/index.html">ServiceNow-conference "Knowledge17"</a></li>
<li><a href="../339962/index.html">[CppCon 2017] Matt Godbolt: What did my compiler do for me?</a></li>
<li><a href="../339966/index.html">Five stages of the evolution of CRM users</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>