<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Use of automated verification tools for software testing in accordance with the standards DO-178B / C (–ö–¢-178–í), EN 50126, IEC 61508, ISO 26262, FDA, IEC 62304</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction from the author of the post 

 Having experience in software development for critical systems for more than 8 years, I want to acquaint t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Use of automated verification tools for software testing in accordance with the standards DO-178B / C (–ö–¢-178–í), EN 50126, IEC 61508, ISO 26262, FDA, IEC 62304</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction from the author of the post </h4><br><br>  Having experience in software development for critical systems for more than 8 years, I want to acquaint the community with some materials related to software development and verification for critical systems (aerospace, medicine, transport, and industry).  Having consented to the translation and adaptation of a number of interesting articles from foreign colleagues, I decided to use this resource.  I would be glad if the article will interest our community.  The article uses materials from the company Vector Software, Inc.  and an example of using the VectorCAST automated verification toolkit is considered. <br>  In this article, we focus on the standards DO-178B / C (-178), but this article is also relevant for use in accordance with the standards: EN 50126, IEC 61508, ISO 26262, FDA, IEC 62304. <br>  I will answer questions in comments or in a pm. <br><br><h4>  Introduction </h4><br>  In this article, we will look at how the VectorCAST firmware testing platform can be used to achieve the objectives of the software verification process defined in Section 6.0 of the DO-178B and DO-178C (KT-178B) standards. equipment and systems for the certification of aviation equipment ".  The document also highlights the differences between the two standards in part 12 of the Process of qualifying instrumental software. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><br><h4>  What are the standards DO-178B and DO-178C </h4><br>  DO-178B was first published in December 1992 by RTCA, Inc.  The document outlined the basic principles applied by organizations that develop onboard equipment and certification bodies, such as the FAA, EASA, TransportCanada.  The development of DO-178B was the result of the joint efforts of RTCA and EUROCAE, the latter published a document called ED-12B.  Software development teams at certification authorities (CAST) developed clarifying documentation after initial publication. <br><br>  DO-178C will replace DO-178B as the main document, according to which certification authorities approve all commercial aerospace systems that have software in their composition.  DO-178C revises DO-178B in the light of experience and information gathered in the light of avionics software development.  A new document called DO-178C (ED-12C) was prepared in November 2011, approved by RTCA in December 2011, and became available for use in January 2012. <br><br>  Both the DO-178B and DO-178C (DO-178B / C) both govern the process to be followed when developing onboard systems.  One of the key requirements in the software verification process in accordance with the DO-178B / C standard is to achieve a structural code coverage in conjunction with testing high and low level software requirements. <br><br>  Based on the assessment of the safety of the system, categories of failure states were established.  These categories determine the level of software integrity required for safe operation in the avionics industry.  Document DO-178B / C classifies software into 5 levels of criticality depending on its impact on the functioning of the entire system.  The table below demonstrates the relationship between the category of the abandoned state and the goal of structural coverage in accordance with DO-178B / C. <br><table><tbody><tr><th>  Level </th><th>  Determination of the failure state </th><th>  Type of structure coating </th></tr><tr><td>  A </td><td>  Software can lead to a catastrophic failure condition of the system and the aircraft </td><td>  Modified coverage of conditions and branches;  Coating of branches; <br>  Cover instructions; <br></td></tr><tr><td>  B </td><td>  The software may lead to an emergency failure condition of the system and the aircraft </td><td>  Coating of branches; <br>  Cover instructions; <br></td></tr><tr><td>  C </td><td>  The software can lead to a complex failure condition of the system and the aircraft </td><td>  Cover instructions; </td></tr><tr><td>  D </td><td>  The software can lead to a failure condition of the type ‚Äúcomplication of flight conditions‚Äù of the aircraft </td><td>  Not required </td></tr><tr><td>  E </td><td>  The software may lead to a failure condition without affecting the operational capabilities of the aircraft. </td><td>  Not required </td></tr></tbody></table><br><br><h4>  What is VectorCAST? </h4><br>  The VectorCAST toolbar supports information gathering and reporting on structural code coverage at all levels specified in DO-178B / C, including level A, and the creation of all the test artifacts required for testing using DO-178B / C.  The VectorCAST product line consists of five complementary technologies: <br><ul><li>  <i>VectorCAST / C ++ / Ada</i> - These tools automate the process of testing source modules written in C, <br>  C ++ or Ada - for both unit and integration testing.  Coverage data can be combined with VectorCAST / Cover data to achieve 100% coverage. </li><li>  <i>VectorCAST / Cover</i> - Designed to create code coverage artifacts during the execution of a functional and / or system test for C, C ++ and Ada. </li><li>  <i>VectorCAST / RGW</i> - Provides a link between requirements and VectorCAST test scenarios. </li><li>  <i>VectorCAST / RSP</i> - Expands <i>VectorCAST /</i> C ++ or VectorCAST / Ada, providing the ability to test real-time applications on target platforms and / or in a simulation environment. </li><li>  <i>VectorCAST / Manage</i> - Used to automate activities in regression testing for unit and integration testing. </li></ul><br>  The tools also support the creation and management of test scripts to confirm the fact of testing low-level software requirements. <br><br><h4>  How does VectorCAST support DO-178B / C </h4><br>  The objectives of the software verification process are defined in Section 6.0 of the DO-178B / C standard. <br><br><h5>  Section 6.4 - Software Testing </h5><br>  This section establishes three types of testing: <br><br>  <b>Hardware / Software Integration Testing</b> <br>  This type of testing is used to meet high-level requirements and is performed on the target hardware using a full-fledged image of the executable program.  In this type of testing, VectorCAST / Cover is used, which registers code coverage during the execution of system and / or functional test procedures. <br><br>  <b>Software Integration Testing</b> <br>  Integration software testing confirms interconnectedness of elements.  Testing at this level is performed using VectorCAST / C ++ or VectorCAST / Ada to test multiple software components at a time.  A fully-fledged test program is automatically generated to support this type of testing, and software requirements can be flagged in separate test scenarios to ensure that all requirements are tested. <br><br>  <b>Low level testing</b> <br>  It is used to test low-level requirements and is usually performed by a series of unit tests that allow you to isolate a single module of source code.  During this phase of testing, VectorCAST / C ++ and VectorCAST / Ada are used. <br><br><h5>  Section 6.4.1 - ‚ÄúTest Environment‚Äù </h5><br>  This section states that more than one test environment may be required to achieve software testing goals.  While testing the application on the target platform will be considered an ‚Äúideal‚Äù environment, it may not be feasible to build and collect demand-oriented coverage and structural coverage in a fully integrated environment.  You may need to perform testing on small isolated components in a simulated environment. <br><br>  VectorCAST fully supports testing on the target platform or using its simulator, usually provided by the compiler vendor.  The structural coverage of the isolated components tested can be combined with the coating collected during the full integration testing to demonstrate the cumulative presentation of the coverage metrics. <br><br>  VectorCAST test scripts are supported regardless of the source code for the DDT testing approach.  This technique allows you to perform tests on the developer's machine, in the simulator, or directly on the target platform in a fully automatic mode. <br><img src="https://habrastorage.org/storage2/c7f/53c/057/c7f53c05743e6df86a2b23d495ef1883.png" alt="image"><br><br><h5>  Section 6.4.2 - ‚ÄúSelection of test cases based on requirements‚Äù </h5><br>  DO-178B /  indicates that software verification should be based on requirements, as opposed to source-based verification.  Requirements-based tests require testers or developers to create input data to execute code that first take into account requirements.  This type of test takes two forms: test cases in the allowable input range and robust tests. <br><br><h5>  Section 6.4.2.1 - ‚ÄúTest Examples in the Allowable Range‚Äù </h5><br>  The purpose of testing the normal range of values ‚Äã‚Äãis to demonstrate the ability of the software to respond to normal input data and operating modes.  More precisely, the real and integer values ‚Äã‚Äãof the input data should be checked.  VectorCAST provides the ability to set these values ‚Äã‚Äãusing the GUI or using a script, as shown in the figure below: <br><img src="https://habrastorage.org/storage2/196/b05/26d/196b0526d9a575e8c3f777ff40f3603d.png" alt="image"><br>  For functions related to time, repeated iterations of the code should be performed to ensure the correctness of the characteristics of the function being tested. <br><br>  VectorCAST provides a simple and convenient way to iterate tests over time.  This feature is called "compound testing."  It allows the tester to perform an individual test many times or multiple tests over a period of time, so that the data remains constant during execution. <br><br>  For requirements expressed by a logical equation, you may need to perform MC / DC.  VectorCAST provides for MC / DC-level coverage and equivalence matrices. <br><br><h5>  Section 6.4.2.2 - ‚ÄúRobust Test Examples‚Äù </h5><br>  The goal of robust test scenarios is to demonstrate the ability of the software to respond to values ‚Äã‚Äãand conditions outside a specified range.  VectorCAST supports testing "out of range" values ‚Äã‚Äãor abnormal values ‚Äã‚Äãof any type.  To do this, use the option to disable the normal range checking.  The following figure shows an example of setting the value ‚Äúout of range‚Äù. <br><img src="https://habrastorage.org/storage2/14d/7e4/788/14d7e4788434830dd25f05b66dac2e30.png" alt="image"><br><br><h5>  Section 6.4.3 - ‚ÄúTest Methods Based on Requirements‚Äù </h5><br>  Test methods (tests) based on requirements consist of: <br><ul><li>  Integration testing of hardware / software </li><li>  Integration Software Testing </li><li>  Low level testing </li></ul><br>  VectorCAST supports all three levels of testing.  For integration testing of hardware / software, VectorCAST provides structural coverage capabilities for projects developed to levels A, B and C. This testing can be performed on a target platform or using a target platform simulator. <br><br>  For software integration and low-level testing, VectorCAST allows you to construct a test program that is executed automatically, providing testing of individual components or a combination of components.  During these testing phases, a structural coating is assembled, which is combined into one unit to assess the completeness of testing. <br><br><h5>  Section 6.4.4 - ‚ÄúTest Coverage Analysis‚Äù </h5><br>  Test coverage analysis includes verification of structural coverage and coverage analysis based on requirements.  The first step is to analyze the test scenario to confirm that all requirements are related to a specific / specified test scenario.  The next step is to check the execution of tests based on the requirements. <br><br>  VectorCAST code coverage analysis determines which source code lines (instructions), which source code branches (branch), or which equivalent pairs (MC / DC) were executed by a series of test scenario data.  Reports show you the completeness of your test suite.  After analyzing the untested code, you can easily go back and develop scripts to test these parts of the code. <br><br><h5>  Section 6.4.4.1 - ‚ÄúAnalysis of Test Coatings Based on Requirements‚Äù </h5><br>  <i>VectorCAST / RGW (RequirementsGateway)</i> allows you to track the association of software requirements with test scenarios to meet the requirements of coverage analysis. <br><br>  <i>VectorCAST / RGW (RequirementsGateway)</i> allows you to create a data flow between requirements management tools and the VectorCAST testing tool.  Using a simple and intuitive interface, developers can quickly link requirements to VectorCAST test scripts. <br><br>  If test scripts were run at least once, traceability metrics can be viewed from VectorCAST or the requirements management tool.  The user has full control over which attributes VectorCAST will give back to the requirements database.  Data such as ‚Äútest name‚Äù, ‚Äútest result‚Äù (success / failure / no result) can be associated with the database attribute of the requirements selected by the user. <br><br><h5>  Section 6.4.4.2 - ‚ÄúStructural Coverage Analysis‚Äù </h5><br>  The purpose of this analysis is to determine which part of the code was not executed during the tests based on the requirements. <br><br>  VectorCAST allows you to calculate the effectiveness of your testing efforts and determine which parts of the application were performed during testing based on testing.  This is a handy tool for analyzing the completeness of your tests, excluding the possibility of releasing an application with code that has not been tested.  VectorCAST allows you to analyze any part of your application or the application as a whole.  For each analyzed file, VectorCAST creates a source code viewer that includes the following information: <br><ul><li>  A coverage summary is a color-coded view of your source code, which determines whether the code is fully, partially covered, or uncovered. </li><li>  The metrics summary provides a list of source code complexity (McCabe) and the current source code coverage status for each subroutine. </li><li>  The conditional coverage analysis shows all control paths for each subroutine. </li><li>  MC / DC is designed for the RTCA DO-178B / C standard for software level A. </li></ul><br>  The MC / DC analysis states that each sub-condition can independently act on the result of the whole condition.  To confirm this, you must be able to record the values ‚Äã‚Äãof the result of the condition, as well as the values ‚Äã‚Äãof each of the sub-conditions.  VectorCAST / Cover collects this information in two formats: a commentary-listed listing of source code and pairwise comparison matrices for each logical condition. <br><img src="https://habrastorage.org/storage2/e06/5b1/f2e/e065b1f2e668485e2a1152af028fd598.png" alt="image"><br><br><h5>  Differences in structural coverage for level A </h5><br>  There is a significant difference between the standards DO-178B and DO-178C, which refers to the structural coverage of software at level A. In all cases not related to level A, the analysis of structural coverage is performed on the source code.  For level A, if the compiler creates an object code that is not traced directly to source code operators, additional verification should be performed to ensure the correctness of such code. <br><br>  The meaning of the phrase ‚Äúadditional verification must be performed‚Äù differs in DO-178B and DO-178C.  DO-178B states that additional verification should be performed on the object code.  DO-178C removed this requirement and simply states that additional verification must be performed. <br><br><h5>  Section 12.1.3 - ‚ÄúChanging the Terms of Use or Development Environment‚Äù </h5><br>  The use and modification of a previously developed application may include a new development environment, a compiler, a target processor, or integration with software different from the one used in the original. <br><br>  When using different compilers or different sets of compiler options, as a result we will get different object code, and the results of the verification activities of the previous software may be unsuitable for the new application. <br><br><h4>  Target processor or compiler changes </h4><br>  It is important to note that all tests developed with VectorCAST should be considered as independent of the target platform.  VectorCAST tests correspond to the data used by the application, but not by the target processor itself.  When an application is transferred to a new target processor, VectorCAST tests can simply be re-executed in a new target environment. <br><br>  The same approach applies when a new compiler is used.  The mechanism of the regression test in VectorCAST will rebuild all running test programs using the new cross-compiler, and all existing tests will be re-executed to verify the test results in the new environment.  For new target processors or a compiler environment, it may be necessary to re-qualify the VectorCAST tools for the new environment. <br><br><h4>  Tooling qualification </h4><br>  Although the overall tool qualification process has remained unchanged, there are several differences between DO-178B and DO-178C in describing the tool qualification process. <br><br>  Both standards establish that the software verification tool qualification is necessary when the verification process defined in the documents is ignored, truncated or automated using a software tool with unconfirmed output. <br><br>  VectorCAST refers to automating the verification process as defined in DO-178B and DO-178C.  The qualification of the software tool is approved by section 12.2 of the DO-178B and DO-178C standards. <br><br>  Section 12.2.1 of DO-178C states: ‚ÄúThe tool is qualified only for use in specific systems where the intentions to use the tool are approved in the Program Aspect Certification Plan (PSAC) supporting the system.  If a tool that previously qualified for one system is intended to be used on another system, it must be re-qualified within the context of another system. ‚Äù <br><br><h4>  Difference between standards in tool qualification </h4><br>  The tool qualification guide for verification software in accordance with DO-178B is quite simple.  The supplier of the instrument is required to have two documents: operational requirements for the instrument (TOR) and data on the qualification of the instrument (TQD).  These documents define software requirements in normal operating conditions and software-related tests and test results. <br><br>  For DO-178C, the tool qualification level (TQL) must first be determined to assess the impact of the tool in the software life cycle.  Section 12.2.2 establishes ‚Äúcriteria levels‚Äù defining the effect of the instrument.  Three levels of criteria are defined: <br><ul><li>  <i>Criterion 1:</i> A tool whose output is part of the on-board software and, therefore, it may introduce an error; </li><li>  <i>Criterion 2:</i> A tool that automates the verification process (s) that may not detect errors and whose output is used to confirm the exception or truncation: <br><ul><li>  Verification process (s) with the exception of automated software tools, or </li><li>  Development process (s) that may affect on-board software. </li></ul></li><li>  <i>Criterion 3:</i> A tool that, within its intended purpose, may not reveal an error. </li></ul><br>  Based on these criteria levels and software levels (from A to D), you can set the skill level (TQL) that is defined in the table below: <br><img src="https://habrastorage.org/storage2/6e8/7cf/56e/6e87cf56e1e9c585804e7eebceb28941.png" alt="image"><br>  Responsibility for qualifying software verification tools (such as VectorCAST) is usually divided between the main counterparty and the tool supplier.  Based on the assessment of the safety of the system, categories of failure states were identified.  These categories establish the level of software integrity necessary for the safe operation of on-board electronic equipment. <br><br>  To further guide the process of qualification of instruments, an RTCA DO-330 document, ‚ÄúRecommendations on the qualification of a software tool,‚Äù was developed, interrelated with DO-178C. <br><br><h4>  VectorCAST tool qualifications </h4><br>  To qualify VectorCAST as a software verification tool, Vector Software publishes the following information for each project that uses the tool: <br><br><h5>  Performance requirements for the tool </h5><br>  The Instrument of Operational Requirements for a Tool (TOR) includes: <br><ul><li>  Description of the functionality of the tool in verifiable requirements </li><li>  Project operating conditions </li><li>  Configuration management process </li><li>  The method of achieving verification, according to which VectorCAST has satisfied testing for the requirements </li></ul><br><br><h5>  Instrument qualification data </h5><br>  Instrument qualification (TQD) data includes: <br><ul><li>  Test data and tool test results </li></ul><br><br>  The tool qualification process usually involves interaction with both the qualifying user and the appropriate certification authority and / or DER. <br><br><h4>  VectorCAST tool qualification process </h4><br>  VectorCAST delivers a preliminary version of qualification materials to the customer.  Additionally, a test suite is transferred so that a qualified user can execute them in the same environment as their project.  Vector Software includes changes to documentation and tests, if appropriate.  Vector Software sends version 1.0 TQD for final approval. </div><p>Source: <a href="https://habr.com/ru/post/182564/">https://habr.com/ru/post/182564/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../182548/index.html">Reading the official data on the number of municipalities with text formatting options using the xlrd library</a></li>
<li><a href="../182554/index.html">Larry Page about the PRISM program: "What the ...?"</a></li>
<li><a href="../182556/index.html">Create Awesome Apps on AngularJS</a></li>
<li><a href="../182558/index.html">IFXmanager - infrastructure management system</a></li>
<li><a href="../182560/index.html">IPv6 - one year later</a></li>
<li><a href="../182566/index.html">Curiosity on the way to the top</a></li>
<li><a href="../182574/index.html">Comment or not comment?</a></li>
<li><a href="../182576/index.html">Holy Grail Dynamic Dispatch</a></li>
<li><a href="../182578/index.html">Interview with Mark McClain, OpenStack Networking Project Leader</a></li>
<li><a href="../182580/index.html">Prism Developer Guide - Part 9, the interaction between loosely coupled components</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>