<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neurobiological methods, and cool things you can do with them: part 1</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neurobiological methods are similar to the unsung heroes of scientific journalism. Periodically, the media are illuminated with phrases like ‚Äúbrain-gu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neurobiological methods, and cool things you can do with them: part 1</h1><div class="post__text post__text-html js-mediator-article">  Neurobiological methods are similar to the unsung heroes of scientific journalism.  Periodically, the media are illuminated with phrases like ‚Äúbrain-guided machines‚Äù and ‚Äúmind reading‚Äù (‚Äúscientists finally learned to read your DIRTY THOUGHT !!! 11‚Äù).  But how is this done?  And since we have already started talking about this, what methods are used to achieve such futuristic projects as managing virtual reality with the help of our eyes or determining whether a suspect was present at the crime scene?  Questions, some questions.  The answers are in this post. <br><br><h4>  Eye tracking and virtual reality </h4><br>  By definition, eye movement tracking (EDC) measures the activity of your eyes.  When and how often do you blink?  Why are the pupils constricted?  Does your gaze stay longer on her gorgeous breasts or on her beautiful eyes?  Answering such questions, tracking eye movements helps you find out if a person is concentrated, or is relaxed and tired, if your website is convenient for users, if the patient has autism - this technology is applicable in various areas, the number of which continues to increase. <br><a name="habracut"></a><br> <a href=""><img src="https://habrastorage.org/files/308/d74/1b6/308d741b66e14941a895bed1dc0dcaba.jpg" align="left" title="How eye tracking works"></a>  In contrast to the 1890s, today's technology does not require the immobilization of the eyes using cocaine.  Today, a common method of measuring the behavior of the eyes is the light from the near-infrared part of the spectrum to the center of the eye and a comparison of the position of its reflection with the position of the pupil (the position of the reflected light remains in place, and the pupil shifts relative to it).  Combining the data with the position of the head, you can extrapolate them to get the direction of the gaze and calculate which points the person is looking at.  Typical measurements include fixations (where the gaze lingered on something that caught your attention), their duration, and the time it takes to look at them;  saccades (sequential movement of the eyes from one detail of the object under consideration to another);  the final way of looking (what you looked at, in what order and for how long).  All this can be measured in two ways: by remote devices, and devices fixed on the head.  The former usually join the computer screen.  The latter are installed on the human head and look like Lady Gaga's futuristic outfit.  Such devices allow a person to move freely. <br><br>  Eye movement tracking is universal technology.  Its applications range from marketing research (product development, product placement, packaging) to neurobiology (early diagnosis of Alzheimer's disease, attention and memory research, etc.).  But there is one really futuristic idea that should tickle your geek's mind: virtual reality (VR).  EDC is becoming more and more popular in the BP community, since it can help create a deep immersion on not the most powerful devices, and also allow the player to influence the virtual world with the help of his eyes alone. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Let us look at how BP and EDC lead to improved user experience.  The eye has a fovea - a small cavity in the very center of the pupil, which is responsible for sharp eyesight.  When we look at something, we see only a small part of our environment in detail (the one that is in the foveal field of vision).  Our peripheral vision sees only color and movement, but in a rather blurry and not detailed form.  To create the impression that we see much more details of our environment, the brain simply uses our experience and memory, filling in the blanks.  If a blurry watermelon is in the field of your peripheral vision, your brain will simply substitute a focused image in its place, taking it from memory - and now it is clearer.  And so, the developers of BP are working to create the technology of ‚Äúfoveal rendering‚Äù [foveated rendering], designed to significantly reduce the computational load of the computer.  She must use our knowledge of brain function and interpretation of the world around.  First, EDC informs the program where a person is looking.  Foveal rendering, using this information, generates a picture located on the sides of the field of view, with much lower resolution and detail, and directs all computational power to increase clarity and realism when rendering the foveal region.  Virtuality is updated according to the movements of your eyes so that the area of ‚Äã‚Äãyour vision always remains clear.  In a way similar to vision in the real world, your brain will create the illusion of a clear vision everywhere based on your experience.  And although it all looks very cool, this technology is at the beginning of development, since it is rather difficult to create both an inexpensive and small device for EDC. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Qq09BTmjzRs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>How it works</i> <br><br>  Technogiants did not postpone their implementation of the new approach: quite recently Google acquired one of the main startups, EDC.  They are said to be working on wireless VR glasses mixing augmented reality and VR.  Select a menu item, keeping your eyes on it!  Look at something a little longer and enlarge the image!  Stroll through the Louvre, and get information about the picture, blinking 4 times!  Use the eyes instead of the mouse!  Hail our new sovereign and savior, tracking eye movements!  What began in 1879 as tracking the eyes while reading, has gone a way long enough to change our view of reality. <br><br><h4>  Functional magnetic resonance imaging (fMRI) and mind reading </h4><br>  fMRI is similar to modern art.  All heard of him, but no one understands how it should be.  Do not worry, soon everything will become clear.  In fact, fMRI is based on the fact that blood with a high oxygen content behaves in a magnetic field differently than blood with a low oxygen content.  At the same time, the more actively the brain area behaves, the more oxygen it consumes.  And the more oxygen is required, the more blood enters this area.  fMRI can monitor an increase in blood flow and oxygen consumption to find the active region of the brain.  This type of imaging is called image formation based on <a href="https://en.wikipedia.org/wiki/Blood-oxygen-level_dependent">blood oxygenation level dependent</a> (BOLD).  The method is non-invasive, you only need to lie in the very loudly working tube of the scanner, and it gives a good spatial resolution of the images (the temporal resolution is worse because there is a delay of 3-6 seconds between the activation of the brain area and the oxygen demand).  This tool is used in a huge variety of studies. <br><br>  fMRI can be used in two ways: it either helps to see brain activation when performing a simple task (for example, in experience periods of idleness change with periods of performing tasks for memory / visual recognition / moral judgments, in general, tasks like ‚Äúerotica or ice cream‚Äù), or it is used to analyze the work of the brain at that moment when we are not busy with a specific task (let‚Äôs say, when we dream, looking absently out of the bus window, or smiling and nodding to our colleagues, pretending to listen to their babble about children).  The first option, called fMRI, in a state of rest showed that a lot of things happen in the brain even at those moments when we are not busy: he identified several networks that control the brain and allowed us to see how the links between brain regions change in psychiatric diseases. or in different states of consciousness. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/adb/57c/1f4/adb57c1f42e87569be78996c2582dec3.png"><br>  Our fMRI study showed that subjects undergoing simple memorization tasks had activity in parts of the brain associated with loud sounds, claustrophobia and loss of jewels. <br><br>  When we got an idea of ‚Äã‚Äãhow this works [1], what can we do about it?  I resist the temptation to declare ‚Äúreading thoughts‚Äù (and hand over a foil cap to you), so I‚Äôd rather use a more scientific term, ‚Äúdecoding thoughts based on brain activity‚Äù. <br><br>  Decoding technology is not just looking for an area that responds to, say, a face.  They recognize the whole brain activation pattern that matches the recognition of a particular face.  Then, by setting up activation schemes for the dofigilliard of images, the algorithm of the ‚Äúclassification of schemes‚Äù processes them together with the associated images.  As a result, the classifier learns about the connection between images and brain activity at the moment of their recognition and understands what activation scheme a certain picture is likely to cause - say, a photo of a cat or baby.  The program, having processed enough examples, can begin studying fMRI scans and try to decode what exactly the person was looking at or thinking about at the time of the scan.  The first experiments were simple - in early works, scientists could recognize only the category of objects that the subjects looked at at that time (shoes, boots, scissors, etc.) [2]. <br><br>  Soon after, the decoding mechanisms stepped far forward.  At first they were used to determine which of the 120 images people look at [3] - the task is far more complicated than defining a broad category of objects.  Then the researchers developed a classifier capable of producing primitive films based on the film viewed by the subject [4].  Since then, the technology has already been used for anything ‚Äî building visual scenes [5], memory work (what do I think about?) [6] and recognition of intentions [7] (which button do I want to press?).  But the classification of intentions is a more difficult task than image recognition.  Objects are grouped by color or shape, but how to assign categories to intentions?  Another problem is the possibility of generalization.  So far, all decoders are working with selected brains, and the development of a standard device for reading thoughts, which can be used to fight crime, should not be expected in the next couple of years.  At the current stage, as John-Dylan Haynes (a person working hard on classifier research, as well as my professor (I brag)), says, "The best way to find out someone's intentions is to ask." <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2e8/915/53d/2e891553d0cf9f6b2d3c23f5d5bf1cfa.jpg" alt="image"><br>  <i>How decoding works</i> <br><br><h4>  Sources </h4><br>  1. <a href="http://www.psy.vanderbilt.edu/tonglab/sonia/Personal/fMRI_Basics.html">www.psy.vanderbilt.edu/tonglab/sonia/Personal/fMRI_Basics.html</a> <br>  2. <a href="http://dx.doi.org/10.1016/S1053-8119">dx.doi.org/10.1016/S1053-8119</a> (03) 00049-1 <br>  3. <a href="http://gallantlab.org/_downloads/2008a.Kay.etal.pdf">gallantlab.org/_downloads/2008a.Kay.etal.pdf</a> <br>  4. <a href="https://www.ncbi.nlm.nih.gov/pubmed/21945275%3Fdopt%3DAbstract%26holding%3Dnpg">www.ncbi.nlm.nih.gov/pubmed/21945275?dopt=Abstract&amp;holding=npg</a> <br>  5. <a href="http://journal.frontiersin.org/article/10.3389/fnhum.2014.00059/full">journal.frontiersin.org/article/10.3389/fnhum.2014.00059/full</a> <br>  6. <a href="http://www.jneurosci.org/content/32/38/12983%3Fijkey%3D3b948eedde2b0698790b3d2f0d7ea14f66079dee%26keytype2%3Dtf_ipsecsha">www.jneurosci.org/content/32/38/12983?ijkey=3b948eedde2b0698790b3d2f0d7ea14f66079dee&amp;keytype2=tf_ipsecsha</a> <br>  7. <a href="https://www.ncbi.nlm.nih.gov/pubmed/21486293">www.ncbi.nlm.nih.gov/pubmed/21486293</a> </div><p>Source: <a href="https://habr.com/ru/post/399273/">https://habr.com/ru/post/399273/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../399263/index.html">Calculator for com. Kosygin</a></li>
<li><a href="../399265/index.html">How to connect a semiconductor laser with a power of more than 1 W (1000 mW) to a 3D printer, CNC machine, coordinate table</a></li>
<li><a href="../399267/index.html">Benchmark Premium from South Korea: a review of the new line of BlackVue DVRs</a></li>
<li><a href="../399269/index.html">Around the World for money signs: a selection of interesting coins from around the world</a></li>
<li><a href="../399271/index.html">3D printing in dentistry on the example of NextDent</a></li>
<li><a href="../399275/index.html">Review of PocketBook 840-2 Ink Pad 2: a new large-format E Ink reader with an ultra-high resolution screen</a></li>
<li><a href="../399277/index.html">Amateur old-school gaming consoles creates a game for the Sega Mega Drive</a></li>
<li><a href="../399279/index.html">Great chain of confidence: how blockchain and trust change the world</a></li>
<li><a href="../399281/index.html">What are the Japanese made of</a></li>
<li><a href="../399285/index.html">Post-horror: how technology tickles nerves</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>