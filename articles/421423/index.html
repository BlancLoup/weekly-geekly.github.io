<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Enterprise DevOps: as in the big company collect microservices</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! 


 For many years, Netracker has been developing and delivering enterprise applications for the global telecom operator market. The developmen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Enterprise DevOps: as in the big company collect microservices</h1><div class="post__text post__text-html js-mediator-article"><p>  Hello! </p><br><p>  For many years, Netracker has been developing and delivering enterprise applications for the global telecom operator market.  The development of such solutions is quite complex: hundreds of people participate in projects, and the number of active projects is in the tens. </p><br><p>  Previously, the products were monolithic, but now we are confidently moving in the direction of microservice applications.  DevOps faced a rather ambitious task - to ensure this technological leap. </p><br><p>  As a result, we got a good assembly concept, which we want to share as a best practice.  The description of the implementation with the technical details will be quite voluminous, in this article we will not do that. </p><a name="habracut"></a><br><p>  <i>In the general case, an assembly is the transformation of some artifacts into others.</i> <i><br></i> </p><br><h2>  Who it will be interesting </h2><br><p>  Those companies that supply complete software completely third-party organizations and get paid for it. </p><br><p>  Here is what a development without external delivery might look like: </p><br><ul><li>  The IT department at the plant develops software for its enterprise. </li><li>  The company is engaged in outsourcing for a foreign customer.  The customer independently compiles and exploits this code on his own web server. </li><li>  The company supplies software to external customers, but under an open source license.  Most of the responsibility is thus lifted. </li></ul><br><p>  If you are not confronted with an external delivery, then a lot written below will seem superfluous or even paranoid. </p><br><p>  In practice, everything must be done in compliance with international requirements for licenses and encryption used, otherwise there will be at least legal consequences. </p><br><p>  An example of a violation is to take code from a library with a GPL3 license and embed it in a commercial application. </p><br><h2>  The emergence of microservices requires changes </h2><br><p>  We have a lot of experience in assembling and supplying monolithic applications. </p><br><p>  Several Jenkins servers, thousands of CI jobs, several fully automated Jenkins-based assembly lines, dozens of dedicated release-engineers, and their own configuration management expert group. </p><br><p>  Historically, the approach in the company was as follows: the source code is written by the developers, and the configuration of the build system is devised and written by DevOps. </p><br><p>  As a result, we had two or three typical assembly configurations designed for operation in the corporate ecosystem.  Schematically it looks like this: </p><br><img src="https://habrastorage.org/webt/pr/hi/rm/prhirmtpwufl-vfhheebwfaujpg.png"><br><p>  As an assembly tool, ant or maven is usually used, and something is implemented by publicly available plug-ins, something is written on its own.  This works well when a company uses a narrow set of technologies. </p><br><p>  <i>Microservices are different from monolithic applications in the first place a variety of technologies.</i> </p><br><p>  It turns out a lot of assembly configurations for at least each programming language.  Centralized control becomes impossible. </p><br><p>  It is required to simplify the build scripts as much as possible and give developers the opportunity to edit them themselves. </p><br><p>  In addition to simple compilation and packaging (in the diagram in <font color="green">green</font> ), these scripts contain a lot of code for integration with the corporate ecosystem (in the diagram in <font color="red">red</font> ). </p><br><p>  Therefore, it was decided to perceive the assembly as a ‚Äúblack box‚Äù, in which the ‚Äúsmart‚Äù assembly environment can solve all the tasks, except for the compilation and packaging itself. </p><br><p>  At the beginning of the work it was not clear how to get such a system.  The adoption of architectural solutions for DevOps tasks requires experience and knowledge.  How to get them?  The options below are: </p><br><ul><li>  Search for information on the Internet. </li><li>  DevOps-team own experience and knowledge.  To do this, it is good to compile this team of programmers with diverse experience. </li><li>  Experience and knowledge gained outside the DevOps team.  Many developers in the company have good ideas - you need to hear them.  Communication is helpful. </li><li>  We invent and experiment! </li></ul><br><h2>  Do you need automation? </h2><br><p>  To answer this question, you need to understand at what stage of evolution our approaches to assemblies are located.  In general, the task passes the following levels. </p><br><ol><li>  The level of "unconscious" <br><br><img width="150" src="https://habrastorage.org/webt/an/e2/uv/ane2uvhcdznwqj-bncv49oo58p8.jpeg"><br><br><p>  We need to produce one assembly per week, our guys do an excellent job.  It is natural, why talk about it? </p></li><li>  The level of "artisan", with time transformed into the level of "trickster" 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img width="150" src="https://habrastorage.org/webt/ck/mc/-a/ckmc-a4-76nvtsanjjwf4ilsf-i.gif"><br><br><p>  It is necessary to produce two assemblies per day stable and without errors.  We have Vasya, he does it coolly, and no one, except him, spends time on it. </p></li><li>  The level of "manufactory" <br><br><img width="150" src="https://habrastorage.org/webt/hw/_x/57/hw_x572z1bstsfv4gcp9ntekdho.jpeg"><br><br><p>  Things went far.  You need 20 assemblies per day, Vasya does not cope, and now a team of ten people is sitting.  They have a boss, plans, vacations, sick leave, motivation, teambuilding, training, traditions and rules.  This is a specialization, their work must be learned. <br></p><br><p>  At this level, the task is separated from the specific executor and thus becomes a process. </p><br><p>  The result will be a clear, worked out, run-in and corrected text description of the process hundreds of times. </p></li><li>  Level "automated production" <br><br><img width="150" src="https://habrastorage.org/webt/mw/2c/pt/mw2cptkfee3fmatsj6aw-21eka4.jpeg"><br><br><p>  Modern requirements for assemblies are growing: everything must be fast, trouble-free, 800 assemblies must be provided per day.  This is critical, because without such volumes the company will lose competitive advantages. </p><br><p>  There is costly automation, and already a couple of qualified DevOps can keep the process running.  Further scaling is no longer a problem. </p></li></ol><br><p>  <i>Not every task should go to the last stage of automation.</i> </p><br><p>  Often, one team-maker will solve problems easily and efficiently. </p><br><p>  Automation "freezes" the process, reduces the cost of operation and increases the cost of change. </p><br><p>  Immediately you can go to the auto assemblies, but the system will be inconvenient, will not keep pace with the requirements of the business and as a result will become morally obsolete. </p><br><h2>  What are the assembly and why the problem is not solved ready assembly systems <br></h2><br><img src="https://habrastorage.org/webt/0s/s1/dk/0ss1dkrnmpubpcllntnzuuwofw0.png"><br><p>  We use the following classification to determine the aggregation levels of assemblies. <br><br></p><ul><li><p>  L1.  A small independent part of a large application.  This can be a single component, microservice, or one auxiliary library.  L1 assembly is a solution of linear technical problems: compilation, packaging, work with dependencies.  Maven, gradle, npm, grunt and other build systems do an excellent job with this.  There are hundreds of them. </p><p>  <i>L1 assembly needs to be done using ready-made third-party tools.</i> </p></li><li><p>  L2 +.  Integration entities.  L1 entities are combined into larger formations, for example, into full-fledged microservice applications.  Several such applications can be bundled as a single solution.  We use the ‚Äú+‚Äù sign, because, depending on the aggregation level of the assembly, L3 or even L4 can be assigned. </p><br><p>  An example of such assemblies in the third-party world is the preparation of Linux distributions.  Metapacks there. </p><br><p>  In addition to fairly complex technical tasks (such as this: <a href="https://ru.wikipedia.org/wiki/Dependency_hell">ru.wikipedia.org/wiki/Dependency_hell</a> ).  L2 + assemblies are often the final product and therefore have many process requirements: a system of rights, securing responsible people, the absence of legal errors, the supply of various documents. </p><br><p>  <i>At the L2 + level, process requirements take precedence over automation.</i> </p><br><p>  If the automatic solution does not work as it is convenient to interested people, it will not be implemented. </p><br><p>  L2 + assemblies will most likely be performed by a proprietary tool, sharpened specifically for the company's processes.  What do you think, package managers in Linux just come up with it? </p></li></ul><br><br><h2>  Our best practices </h2><br><h3>  Infrastructure </h3><br><h4>  Permanent iron availability </h4><br><p>  The entire assembly infrastructure is located on closed servers within the corporate network.  In some cases, commercial cloud services are possible. <br></p><br><h4>  Autonomy </h4><br><p>  In all CI processes, the Internet is not available.  All necessary resources are mirrored and cached within the company.  Partially even github.com (thank you, npm!) Most of these issues are solved by Artifactory. </p><br><p>  Therefore, we are calm when removing artifacts from the maven central or closing popular repositories.  There is an example: <a href="https://community.oracle.com/community/java/javanet-forge-sunset">community.oracle.com/community/java/javanet-forge-sunset</a> . </p><br><p>  Mirroring significantly reduces assembly time, frees the corporate Internet channel.  Fewer critical network resources increase assembly stability. </p><br><h4>  Three repositories for each artifact type </h4><br><ol><li>  Dev is a repository in which everyone can publish artifacts of any origin.  Here you can experiment with fundamentally new approaches, not adapting them to corporate standards from day one. </li><li>  Staging is a repository filled only with an assembly line. </li><li>  Release - single assembly, ready for external delivery.  Filled with a special transfer operation with manual confirmation. </li></ol><br><h4>  30 day rule <br></h4><br><p>  From the Dev and Staging repositories we delete everything that is older than 30 days.  This helps ensure equal publishing opportunities for all, at the cost of a finite amount of server disks. </p><br><p>  Release is stored forever, if necessary, archiving is done. </p><br><h4>  Clean build environment <br></h4><br><p>  Often after assemblies in the system there are auxiliary files that may affect other assembly processes.  Typical examples: </p><br><ul><li>  the most common problem is a cache corrupted by one incorrect build (how to deal with caches, described below); </li><li>  some utilities, for example npm, leave service files in the $ HOME-directory, which affect all further launches of these utilities; </li><li>  a specific assembly can spend all disk space in a / tmp partition, which will lead to a general inaccessibility of the environment. </li></ul><br><p> Therefore, it is better to abandon a single environment in favor of docker containers.  Containers should contain only what is necessary for a specific build of software with fixed versions. </p><br><p>  DevOps maintains a collection of docker build images that is constantly updated.  At first there were about six of them, then it was under 30, then we set up automatic generation of the image according to the software list.  Now we simply specify the requirements of the require ('maven 3.3.9', 'python') type - and the environment is ready. </p><br><h4>  Self test </h4><br><p>  It is necessary not only to organize user support for appeals, it is necessary to analyze the behavior of your own system.  Constantly we collect logs, we look for in them the keywords showing problems. </p><br><p>  It is enough to write 20-30 regular expressions on the ‚Äúlive‚Äù system so that for each assembly you can tell the reason for its fall at the level: </p><br><ul><li>  git server failure; </li><li>  there is no more disk space; </li><li>  Build error due to developer‚Äôs fault; </li><li>  known bug in docker. </li></ul><br><p>  If something fell, but no known problem was found - this is the reason for replenishing the collection of masks. </p><br><p>  Then we go to the user and say that his build is falling and this can be fixed in this way. </p><br><p>  You will be surprised how many problems users do not report in support.  It is better to repair them in advance and at a convenient time.  Often, a minor publication error is ignored for two weeks, and on Friday evening it turns out that this blocks the external issue. </p><br><h4>  Carefully choose which systems the assembly depends on. <br></h4><br><p>  Ideally, to ensure complete autonomy of the assembly, but most often it is impossible.  For java-based builds, at least Artifactory is needed for mirroring - see above about autonomy.  Each integrated system increases the risk of failure.  It is desirable that all systems work in decent HA mode. </p><br><h3>  Assembly line interface </h3><br><h4>  Unified interface to call assembly </h4><br><p>  We produce any type of assembly with one system.  Assemblies of all levels (L1, L2 +) are described by the program code and called up through one Jenkins job. </p><br><p>  However, this approach is not perfect.  It is better to use Jenkins autogeneration job mechanisms: for example, 1 job = 1 git repository or 1 job = 1 git branch.  This will achieve the following: </p><br><ul><li>  logs from different types of assemblies are not confused in one story on the Jenkins job page; </li><li>  in fact, they get comfortable selected jobs for a team or a developer;  the feeling of comfort can be enhanced by adjusting the graphs of the results of junit, cobertura, sonar. </li></ul><br><h4>  Freedom of choice of technology <br></h4><br><p>  Running the build is a call to the bash script "./build.sh".  And further - any assembly systems, programming languages ‚Äã‚Äãand everything else needed to complete a business task.  This provides an approach to assembly as a ‚Äúblack box‚Äù. </p><br><h4>  Smart publishing </h4><br><p>  The assembly pipeline intercepts publications from the ‚Äúblack box‚Äù and puts them into the corporate repository.  For this, boring questions such as generating names of docker images, choosing the right repository for publication are automatically solved. </p><br><p>  Staging and release repositories are always in order.  It is required to support the specifics of publications of different types: maven, npm, file, docker. </p><br><h4>  Assembly descriptor <br></h4><br><p>  Build.sh describes how to build code, but this is not enough for an assembly container. </p><br><p>  It is also necessary to know: </p><br><ol><li>  which build environment to use; </li><li>  environment variables available in build.sh; </li><li>  what publications will be executed; </li><li>  other specific options. </li></ol><br><p>  We chose a convenient way to describe this information in the form of a yaml file, remotely resembling .gitlab-ci.yaml. </p><br><h4>  Build Parameterization <br></h4><br><p>  The user can specify arbitrary parameters without executing the ‚Äúgit commit‚Äù command right at the start of the assembly. </p><br><p>  We have this implemented through the definition of environment variables directly from the Jenkins job interface. </p><br><p>  For example, we bring in the version of the dependent library to such an assembly parameter and in some cases we redefine this version to some experimental one.  Without such a mechanism, the user would have to execute the git commit command every time. </p><br><h4>  System portability <br></h4><br><p>  It is necessary to be able to reproduce the assembly process not only on the main CI server, but also on the developer‚Äôs computer.  This helps in debugging complex build scripts.  In addition, instead of Jenkins, it will sometimes be more convenient to use Gitlab CI.  Therefore, the build system should be an independent java-application.  We implemented it as a gradle plugin. </p><br><h4>  One artifact can be published under different names. <br></h4><br><p>  There are two opposite requirements for publication that may arise at the same time. </p><br><p>  On the one hand, for long-term storage and release management, it is necessary to ensure the uniqueness of the names of published artifacts.  This will at least protect artifacts from being overwritten. </p><br><p>  On the other hand, it is sometimes convenient to have one actual artifact with a fixed name like latest.  For example, the developer does not need to know the exact version of the dependency each time; you can simply work with the latest one. </p><br><p>  The artifact in this case is published under two or more names, to whom it is convenient. </p><br><p>  For example: </p><br><ol><li>  unique name with a time stamp or UUID - for those who need accuracy; </li><li>  the name "latest" - for their developers, who always pick up the latest code; </li><li>  the name ‚Äú&lt;major version&gt; .x-latest‚Äù is for the neighboring team, which is ready to pick up the latest versions, but only within a certain major version. </li></ol><br><p>  Something like maven does in its approach to SNAPSHOT. </p><br><h4>  Less security restrictions <br></h4><br><p>  Assembly can run everyone.  This will not harm anyone, since the assembly only creates artifacts. </p><br><h3>  Compliance with legal requirements </h3><br><h4>  Control of external interactions of the assembly process </h4><br><p>  The assembly can not use anything prohibited in its work. </p><br><p>  For this purpose, recording of network traffic and access to file caches is implemented.  We get the network activity log of the assembly as a list of url with sha256 hashes of the received data.  Then each url is validated: </p><br><ol><li>  static whitelist; </li><li>  dynamic base of permissible artifacts (for example, for maven, rpm, npm dependencies).  Each dependency is considered individually.  An automatic resolution or a ban on use may work, a long discussion with lawyers may also begin. </li></ol><br><h4>  Transparent content of published artifacts <br></h4><br><p>  Sometimes a task comes in - to provide a list of third-party software inside an assembly.  To do this, they made a simple composition analyzer that analyzes all files and archives in the assembly, identifies third-parties by hashes and makes a report. </p><br><h4>  Source code issued cannot be removed from GIT <br></h4><br><p>  Sometimes it may be necessary to find the source code, looking at a binary artifact collected two years ago.  To do this, you need to assign tags to Git automatically upon external issuance, as well as to prohibit their removal. </p><br><h3>  Logistics and accounting <br></h3><br><h4>  All assemblies are stored in a database. </h4><br><p>  We use the file repository in Artifactory for this purpose.  There is all the supporting information: who launched, what were the results of the checks, what artifacts were published, what git-hash was used, etc. </p><br><h4>  We know how to reproduce the assembly as accurately as possible. </h4><br><p>  According to the results of the assembly, we store the following information: </p><br><ul><li>  the exact status of the code that was collected; </li><li>  with what parameters the launch was made; </li><li>  what commands were called; </li><li>  what appeals to external resources occurred; </li><li>  used build environment. </li></ul><br><p>  If necessary, we can fairly accurately answer the question of how it was collected. </p><br><h4>  Two-way connection of the assembly with the JIRA ticket <br></h4><br><p>  Be sure to be able to solve the following tasks: </p><br><ol><li>  to build a list of JIRA tickets included in it; </li><li>  write in JIRA ticket, in which assembly it is included. </li></ol><br><p>  A strong two-way connection of the assembly with git commit is provided.  And then from the text of the comments you can already find out about all the links to JIRA. </p><br><h3>  Speed </h3><br><h4>  Caches for assembly systems </h4><br><p>  The absence of a maven cache can increase the build time by an hour. </p><br><p>  The cache breaks the isolation of the build environment and the cleanliness of the build.  This problem can be solved by determining its origin for each cached artifact.  We have every cache file associated with an https-link, on which it was once downloaded.  Further we process cache reading as network access. </p><br><h4>  Network resource caches </h4><br><p>  The growth of the company geographically leads to the need to transfer files of 300 MB between the continents.  It takes a lot of time, especially if you have to do it often. </p><br><p>  Git-repositories, docker-images of build environments, file storages - everything must be carefully cached.  And, of course, periodically clean. </p><br><h4>  Build - as fast as possible, everything else - then </h4><br><p>  The first stage: we do the assembly and immediately, without unnecessary gestures, give the result. </p><br><p>  The second stage: validation, analysis, accounting and other bureaucracy.  This can be done already in a separate Jenkins job without any strict time limits. </p><br><h2>  What is the result </h2><br><ol><li>  The main thing - the <i>assembly has become clear to developers</i> , they themselves can develop and optimize it. </li><li>  A foundation has been created for building business processes that depend on an assembly: installation, issuance management, testing, release management, etc. </li><li>  The DevOps team no longer writes build scripts: the developers do it. </li><li>  Complex corporate requirements turned into a transparent report with a final list of checks. </li><li>  Anyone can build any repository by simply calling build.sh through a single interface.  It is enough for it to simply specify the git-coordinates of the source code.  This person can be a team manager, QA / IT engineer, etc. </li></ol><br><p>  And some numbers </p><br><ol><li>  Time costs  An extra 15 seconds is needed from calling the Jenkins job to the immediate build.sh operation.  In these 15 seconds, the docker build container starts, network monitors are turned on, and caches are prepared.  The remaining time costs are even less noticeable.  Typical assembly takes about three minutes. </li><li>  The number of assemblies.  Confidently approaches an average of one thousand per day.  On some days it reached 2,200 units.  Most are on-commit assemblies. </li><li>  About 300 git repositories are currently being processed, and their number is constantly growing. </li><li>  An average of 30 GB of unique artifacts is published per day, most of which (25 GB) is a docker. </li><li>  Below is a list of technologies and assembly tools that we use today: <br><ol><li>  glide, golang, promu; </li><li>  maven, gradle; </li><li>  python &amp; pip; </li><li>  ruby; </li><li>  nodejs &amp; npm; </li><li>  docker; </li><li>  rpm build tools &amp; gcc; </li><li>  build Android with ADT; </li><li>  commercial utilities; </li><li>  utilities for our legacy products; </li><li>  homemade build scripts. </li></ol><br></li></ol></div><p>Source: <a href="https://habr.com/ru/post/421423/">https://habr.com/ru/post/421423/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../421413/index.html">Proper access to default methods of interfaces through reflection in Java 8, 9, 10</a></li>
<li><a href="../421415/index.html">Magic Leap - sad trash</a></li>
<li><a href="../421417/index.html">Coffee machine for coffee independent or Wacaco mobile coffee machine</a></li>
<li><a href="../421419/index.html">An ode to ‚Äúfoamed‚Äù nickel, non-existent sapphires and the Soviet deputy minister: the iconic OTTO SX-P1 in Japan, the USA and the USSR</a></li>
<li><a href="../421421/index.html">LAppS: Half a million 1KB-WebSocket messages per second with TLS on one CPU</a></li>
<li><a href="../421425/index.html">Tame and Consolidate: The Story of Moving to the Oracle Supercluster</a></li>
<li><a href="../421429/index.html">Dynamic Pricing Based on LSTM - ANN in the Home Retail</a></li>
<li><a href="../421431/index.html">Time Management, or Effective Chaos Management</a></li>
<li><a href="../421433/index.html">There are exactly a day left before the server starts</a></li>
<li><a href="../421435/index.html">‚ÄúWhy are we doing all this?‚Äù - the creator of Prisma and the former leader of VK projects about his new secret project</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>