<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How fast is R for productive?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="There is such a popular class of tasks in which it is required to conduct a sufficiently deep analysis of the entire volume of work chains recorded by...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How fast is R for productive?</h1><div class="post__text post__text-html js-mediator-article"><p>  There is such a popular class of tasks in which it is required to conduct a sufficiently deep analysis of the entire volume of work chains recorded by some information system (IS).  Document management, desktops, bugtrackers, e-journals, inventory accounting, etc. can be used as IPs. The nuances are manifested in data models, APIs, data volumes, and other aspects, but the principles for solving such problems are about the same.  And the rake, which can be stepped on, is also very similar. </p><br><p>  To solve this class of problems, R fits perfectly.  But, in order not to let go of disappointed hands, that R may be good, but oh, very slow, it is important to pay attention to the performance of the chosen data processing methods. </p><br><p>  It is a continuation of <a href="https://habrahabr.ru/users/i_shutov/posts/">previous publications</a> . <a name="habracut"></a></p><br><p> Usually, a head-on approach is not the most effective.  99% of the tasks associated with the analysis and processing of data begin with their import.  In this brief essay, we will look at the problems that arise at the basic stage of importing data with data in <code>json</code> format, using the example of a typical ‚Äúin-depth‚Äù analysis of Jira installation data as an example.  <code>json</code> supports a complex object model, in contrast to <code>csv</code> , so its parsing in the case of complex structures can become very difficult and long. </p><br><h1 id="postanovka-zadachi">  Formulation of the problem </h1><br><p>  Given: </p><br><ul><li>  jira is implemented and used in the software development process as a task management system and bugtracker. </li><li>  There is no direct access to the jira database, the interaction is carried out through the REST API (galvanic isolation). </li><li>  Pickup json files have a very complex tree structure with nested tuples required to upload the entire history of actions.  To calculate the same metrics, a relatively small number of parameters are needed, scattered across different levels of the hierarchy. </li></ul><br><p>  An example of a regular jira json in the figure. </p><br><p><img src="https://habrastorage.org/webt/g1/me/t7/g1met7plll0ltss2wzho4bxzbcs.png"></p><br><p>  Required: </p><br><ul><li>  Based on jira data, it is necessary to find the bottlenecks and points of possible growth in the efficiency of development processes and improve the quality of the resulting product based on the analysis of all recorded activities. </li></ul><br><h1 id="reshenie">  Decision </h1><br><p>  Theoretically, in R there are several different packages for downloading json and converting them into <code>data.frame</code> .  The most convenient is the <code>jsonlite</code> package.  However, the direct transformation of the json hierarchy in <code>data.frame</code> difficult due to the multi-level nesting and strong parametrization of the record structure.  Linking specific parameters related, for example, to the history of actions, may require various add.  checks and cycles.  Those.  The task can be solved, but for a json file with a size of 32 tasks (includes all artifacts and the entire history of tasks), such non-linear analysis using jsonlite and tidyverse takes ~ 10 seconds on an average performance laptop. </p><br><p>  By themselves, 10 seconds is a bit.  But just until the moment these files become too many.  Estimation of the sample parsing and loading of such a "direct" method ~ 4000 files (~ 4 GB) gave 8-9 hours of work. </p><br><p>  Such a large number of files appeared for a reason.  First, jira has a time limit on the REST session, it‚Äôs impossible to pull out all the bulk.  Secondly, being embedded in the production contour, the daily upload of data on the updated tasks is expected.  Thirdly, and this will be mentioned later, the task is very good for linear scaling and you need to think about parallelization from the very first step. </p><br><p>  Even 10‚Äì15 iterations at the stage of data analysis, identifying the required minimum set of parameters, detecting exceptional or erroneous situations, and developing post-processing algorithms result in costs of 2‚Äì3 weeks (only counting time). <br>  Naturally, such a ‚Äúperformance‚Äù is not suitable for operational analytics embedded in the productive contour, and is very ineffective at the stage of the initial data analysis and development of the prototype. </p><br><p>  Skipping all intermediate details, I immediately turn to the answer.  We recall Donald Knuth, roll up our sleeves and begin to engage in microbenchmarking of all key operations mercilessly cutting off everything that is possible. </p><br><p>  The resulting solution is reduced to the following 10 lines (this is a common skeleton, without a subsequent non-functional body kit): </p><br><pre> <code class="plaintext hljs">library(tidyverse) library(jsonlite) library(readtext) fnames &lt;- fs::dir_ls(here::here("input_data"), glob = "*.txt") ff &lt;- function(fname){ json_vec &lt;- readtext(fname, text_field = "texts", encoding = "UTF-8") %&gt;% .$text %&gt;% jqr::jq('[. | {issues: .issues}[] | .[]', '{id: .id, key: .key, created: .fields.created, type: .fields.issuetype.name, summary: .fields.summary, descr: .fields.description}]') jsonlite::fromJSON(json_vec, flatten = TRUE) } tictoc::tic("Loading with jqr-jsonlite single-threaded technique") issues_df &lt;- fnames %&gt;% purrr::map(ff) %&gt;% data.table::rbindlist(use.names = FALSE) tictoc::toc() system.time({fst::write_fst(issues_df, here::here("data", "issues.fst"))})</code> </pre> <br><p>  What is interesting here? </p><br><ol><li>  To speed up the boot process, it is good to use specialized profiled packages, such as <code>readtext</code> . </li><li>  The use of the stream parser <a href="https://stedolan.github.io/jq/"><code>jq</code></a> allows <a href="https://stedolan.github.io/jq/"><code>jq</code></a> to translate all the hooking of the necessary attributes into a functional language, drop it to the CPP level and minimize manual manipulation of nested lists or lists in the <code>data.frame</code> . </li><li>  A very promising <a href="https://github.com/r-lib/bench"><code>bench</code></a> package for microbench marks appeared.  It allows you to study not only the execution time of operations, but also memory manipulations.  It's no secret that you can lose a lot on copying data in memory. </li><li>  For large amounts of data and simple processing, it is often necessary in the final decision to abandon the <code>tidyverse</code> and translate labor-intensive parts to <code>data.table</code> , in particular, it is here that the tables are merged by means of <code>data.table</code> .  As well as all the transformations at the post-processing stage (which are included in the cycle using the <code>ff</code> function are also made by <code>data.table</code> with the approach of changing data by reference, or by packages built using <code>Rcpp</code> , for example, <code>anytime</code> package for working with dates and time. </li><li>  The <code>fst</code> package is very good for resetting data to a file and subsequent reading.  In particular, it only takes a fraction of a second to save all analytics of jira history for 4 years, and the data is saved as data types R, which is good for later reuse. </li></ol><br><p>  During the solution, an approach using the <code>rjson</code> package was <code>rjson</code> .  The <code>jsonlite::fromJSON</code> about 2 times slower than <code>rjson = rjson::fromJSON(json_vec)</code> , but we had to leave it exactly, because NULL values ‚Äã‚Äãare in the data, and at the stage of converting <code>NULL</code> to <code>NA</code> in the lists issued by <code>rjson</code> we lose advantage, and the code is heavier. </p><br><h1 id="zaklyuchenie">  Conclusion </h1><br><ol><li>  Similar refactoring led to a change in the processing time of all json files in single-threaded mode on the same laptop from 8-9 hours to 10 minutes. </li><li>  Adding task parallelization by means of <code>foreach</code> practically did not make the code (+ 5 lines) but reduced the execution time to 5 minutes. </li><li>  Transferring the solution to a weak linux server (only 4 cores), but running on an SSD in multi-threaded mode reduced the execution time to 40 seconds. </li><li>  The publication on the productive contour (20 cores, 3 GHz, SSD) reduced the execution time to 6-8 seconds, which is more than acceptable for operational analytics tasks. </li></ol><br><p>  Total, staying within the framework of the R platform, we managed to achieve a simple refactoring of the code by reducing the execution time from ~ 9 hours to ~ 9 seconds. </p><br><p>  Solutions on R can be quite fast.  If something goes wrong with you, try to look at it from a different angle and using fresh techniques. </p><br><p>  Previous publication - <a href="https://habr.com/post/416673/">"Analytical Plan for Manager</a> . <a href="https://habr.com/post/416673/">"</a> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/429938/">https://habr.com/ru/post/429938/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../429926/index.html">Roskomnadzor: Google confirms willingness to comply with Russian legislation</a></li>
<li><a href="../429928/index.html">Everything you need to know about stress and strong emotions.</a></li>
<li><a href="../429930/index.html">Splunk. Easy Troubleshooting application work</a></li>
<li><a href="../429934/index.html">How is that?</a></li>
<li><a href="../429936/index.html">Should I wait for Android on iOS from Parallels?</a></li>
<li><a href="../429940/index.html">Why do plants need machine learning</a></li>
<li><a href="../429942/index.html">We get Vk music through a third-party API</a></li>
<li><a href="../429946/index.html">The Madness and Success of Oracle Database Code</a></li>
<li><a href="../429948/index.html">Why do we need product managers in fintech</a></li>
<li><a href="../429950/index.html">How to maintain healthy communication habits of remote teams</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>