<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Learn OpenGL. Lesson 4.5 - Framebuffer</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Frame buffer 
 To date, we have already managed to use several types of screen buffers: a color buffer, in which the color values ‚Äã‚Äãof the fragments a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Learn OpenGL. Lesson 4.5 - Framebuffer</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="Ogl3" align="left" width="300"><h1>  Frame buffer </h1><br>  To date, we have already managed to use several types of screen buffers: a color buffer, in which the color values ‚Äã‚Äãof the fragments are stored;  depth buffer storing information about the depth of the fragments;  stencil buffer, allowing you to drop some fragments according to a specific condition.  The combination of these three buffers is called the frame buffer (framebuffer) and is stored in a specific area of ‚Äã‚Äãmemory.  OpenGL is flexible enough to allow us to create our own frame buffers ourselves, by defining our own color buffers and, optionally, depth and stencil buffers. <br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Content</b> <div class="spoiler_text">  Part 1. Start <br><br><ol><li>  <a href="https://habrahabr.ru/post/310790/">Opengl</a> </li><li>  <a href="https://habrahabr.ru/post/311198/">Creating a window</a> </li><li>  <a href="https://habrahabr.ru/post/311234/">Hello window</a> </li><li>  <a href="https://habrahabr.ru/post/311808/">Hello triangle</a> </li><li>  <a href="https://habrahabr.ru/post/313380/">Shaders</a> </li><li>  <a href="https://habrahabr.ru/post/315294/">Textures</a> </li><li>  <a href="https://habrahabr.ru/post/319144/">Transformations</a> </li><li>  <a href="https://habrahabr.ru/post/324968/">Coordinate systems</a> </li><li>  <a href="https://habrahabr.ru/post/327604/">Camera</a> </li></ol><br>  Part 2. Basic lighting <br><br><ol><li>  <a href="https://habrahabr.ru/post/329592/">Colors</a> </li><li>  <a href="https://habrahabr.ru/post/333932/">Lighting Basics</a> </li><li>  <a href="https://habrahabr.ru/post/336166/">Materials</a> </li><li>  <a href="https://habrahabr.ru/post/337550/">Texture Cards</a> </li><li>  <a href="https://habrahabr.ru/post/337642/">Sources of light</a> </li><li>  <a href="https://habrahabr.ru/post/338254/">Multiple light sources</a> </li></ol><br>  Part 3. Loading 3D Models 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  <a href="https://habrahabr.ru/post/338436/">Assimp library</a> </li><li>  <a href="https://habrahabr.ru/post/338436/">Mesh mesh class</a> </li><li>  <a href="https://habrahabr.ru/post/338998/">Model class</a> </li></ol><br>  Part 4. OpenGL advanced features <br><br><ol><li>  <a href="https://habrahabr.ru/post/342610/">Depth test</a> </li><li>  <a href="https://habrahabr.ru/post/344238/">Stencil test</a> </li><li>  <a href="https://habrahabr.ru/post/343096/">Mixing colors</a> </li><li>  <a href="https://habrahabr.ru/post/346964/">Face clipping</a> </li></ol></div></div><br>  All the rendering operations that we have performed so far have been executed within the framework of buffers attached to the basic frame buffer.  The base frame buffer is created and configured when the application window is created (GLFW does the hard work for us).  By creating our own framebuffer, we get additional space where we can direct the render. <br><br>  At first glance, it may not seem obvious how to use your own frame buffers, but displaying an image in an additional buffer allows at least creating mirror effects or post-processing.  But first, we will understand how the frame buffer is arranged, and then we will consider the implementation of some interesting post-processing effects. <br><br><h3>  Create frame buffer </h3><br>  Like any other object in OpenGL, the framebuffer object (abbreviated <i>FBO</i> from <i>FrameBuffer Object</i> ) using the following call: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> fbo; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;fbo);</code> </pre> <br>  We already have a familiar and dozens of times applied approach to the creation and use of objects of the OpenGL library: create a frame buffer object, bind it as the current active frame buffer, perform the necessary operations, and untie the frame buffer.  Binding is as follows: <br><br><pre> <code class="cpp hljs">glBindFramebuffer(GL_FRAMEBUFFER, fbo);</code> </pre> <br>  After binding our frame buffer to the <i>GL_FRAMEBUFFER</i> bind <i>point,</i> all subsequent read and write operations for the frame buffer will use it.  It is also possible to bind a frame buffer for read-only or write-only by binding to special anchor points <i>GL_READ_FRAMEBUFFER</i> or <i>GL_DRAW_FRAMEBUFFER,</i> respectively.  The buffer bound to <i>GL_READ_FRAMEBUFFER</i> will be used as the source for all read operations of type <i>glReadPixels</i> .  And the buffer associated with <i>GL_DRAW_FRAMEBUFFER</i> will be the receiver of all render operations, buffer cleaning and other write operations.  However, for the most part you do not have to use these anchor points by applying the <i>GL_FRAMEBUFFER</i> anchor <i>point</i> . <br><br>  Unfortunately, we are not yet ready to use the frame buffer for us, since it is not complete.  To become complete, the frame buffer must meet the following requirements: <br><br><ul><li>  At least one buffer must be connected (color, depth, or stencil). </li><li>  There must be at least one color attachment. </li><li>  All connections must also be completed (provided with dedicated memory). </li><li>  Each buffer must have the same number of samples. </li></ul><br>  Do not worry so far about what samples are - this will be discussed in the next lesson. <br>  So, from the list of requirements it is clear that we have to create some ‚Äúattachments‚Äù and connect them to the frame buffer.  If we have fulfilled all the requirements, we can check the completion status of the frame buffer by calling <i>glCheckFramebufferStatus</i> with the parameter <i>GL_FRAMEBUFFER</i> .  The procedure checks the current associated frame buffer for completeness and returns one of the values ‚Äã‚Äãspecified in the <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/glCheckFramebufferStatus.xhtml">specification</a> .  If <i>GL_FRAMEBUFFER_COMPLETE is</i> returned, then work can continue: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (glCheckFramebufferStatus(GL_FRAMEBUFFER) == GL_FRAMEBUFFER_COMPLETE) { <span class="hljs-comment"><span class="hljs-comment">//  ,   ! }</span></span></code> </pre> <br>  All subsequent rendering operations will output to the frame buffer connections currently attached.  Since our frame buffer is not basic, the output to it will not have any effect on what is displayed in the window of your application.  That is why the render in its own personnel buffer is called an off-screen renderer.  In order for output commands to take effect again on the output window of the application, we need to screw in the basic frame buffer to the active place: <br><br><pre> <code class="cpp hljs">glBindFramebuffer(GL_FRAMEBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  It is transmission <b>0</b> as the frame buffer identifier that indicates to bind the base buffer as active.  After completing all the necessary actions with the created frame buffer, remember to delete its object: <br><br><pre> <code class="cpp hljs">glDeleteFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;fbo);</code> </pre> <br>  So, let's go back a step to check the buffer completeness: you need to create and connect at least one attachment to our personnel buffer.  An attachment is an area in memory that can act as a receiver buffer for a frame buffer, making it easier to imagine it as an image.  When creating an attachment, we have a choice: use textures or a render buffer. <br><br><h4>  Texture Attachments </h4><br>  After connecting the texture to the frame buffer, the result of all subsequent commands will be written into this texture as if it is a normal color, depth or stencil buffer. <br><br>  The advantage of using a texture object is that the results of the render operations will be saved in a texture format, making them easily accessible for processing in shaders. <br><br>  The process of creating a texture for use in the frame buffer roughly coincides with that for a regular texture object: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> texture; glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, <span class="hljs-number"><span class="hljs-number">800</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_UNSIGNED_BYTE, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</code> </pre> <br>  The main difference is that texture sizes are set equal to the screen size (although this is not necessary), and instead of a pointer to an array of texture values, <i>NULL</i> is passed.  Here we only allocate memory for the texture, but do not fill it with something, since the filling will occur by itself when the render is directly called into this frame buffer.  Also note the lack of texture repeat mode settings and mipmapping settings, since in most cases the use of offscreen buffers is not required. <br><br><blockquote>  If you want to render the entire screen into a smaller or larger texture, you must additionally call <i>glViewport</i> before directly <i>rendering it</i> , and transfer the dimensions of the used texture to it.  Otherwise, only a fragment of the screen image gets into the frame buffer, or the frame buffer texture will be filled with the screen image only partially. </blockquote><br>  Having created a texture object, you need to attach it to the frame buffer: <br><br><pre> <code class="cpp hljs">glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texture, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  The function takes the following parameters: <br><br><ul><li>  <i>target</i> - the type of the frame object to which the texture is connected (read only, write only, read / write). </li><li>  <i>attachment</i> - the type of attachment that we plan to connect.  In this case, we connect the color attachment.  Note the 0 at the end of the attachment identifier - its presence implies the ability to connect more than one attachment to the buffer.  More this moment is considered later. </li><li>  <i>textarget</i> is the type of texture you plan to mount. </li><li>  <i>texture</i> is the <i>texture</i> object itself. </li><li>  <i>level</i> - used for outputting the MIP-level. </li></ul><br>  In addition to the color attachments, we can also connect the depth and stencil textures to the frame buffer object.  To attach a depth, we set the attachment type <i>GL_DEPTH_ATTACHMENT</i> .  Do not forget that the <i>format</i> and <i>internalformat</i> parameters of the texture object must take the value <i>GL_DEPTH_COMPONENT</i> to be able to store the depth values ‚Äã‚Äãin the appropriate format.  To attach a stencil, the type is set to <i>GL_STENCIL_ATTACHMENT</i> , and the texture format parameters are set to <i>GL_STENCIL_INDEX</i> . <br><br>  It is also possible to connect both the depth buffer and the stencil simultaneously using only one texture.  For this configuration, each 32-bit texture value consists of a 24-bit depth value and 8 bits of stencil information.  To connect the depth buffer and the stencil as a single texture, the attachment type <i>GL_DEPTH_STENCIL_ATTACHMENT is used</i> , and the texture format is configured to store the combined depth and stencil values.  An example of connecting the depth buffer and stencil in the form of a single texture is shown below: <br><br><pre> <code class="cpp hljs">glTexImage2D( GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_DEPTH24_STENCIL8, <span class="hljs-number"><span class="hljs-number">800</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_DEPTH_STENCIL, GL_UNSIGNED_INT_24_8, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, texture, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br><h4>  Rendered Buffer Attachments </h4><br>  Chronologically, the rendered buffer objects as another type of frame buffer attachments were added to the library later than textural ones, which were the only option for working with offscreen buffers in ancient days.  Like the texture, the renderbuffer object is a real buffer in memory, i.e.  an array of bytes, integers, pixels, or something else. <br><br>  However, it has an additional advantage - the data in the render buffer is stored in a special, comprehensible library format, which makes it optimized for an off-screen render. <br><br>  Render objects save the render data directly, without additional transformations into specific texture data formats, which ultimately gives a significant advantage in speed during writing to the buffer.  Unfortunately, in a general sense, the render buffer is write-only.  You can read something from it only indirectly, through a call to <i>glReadPixels</i> , and then this will return the pixel data of the currently used frame buffer, and not the renderbuffer itself. <br><br>  Since data is stored in an internal library format, renderbuffers are very fast when writing to them or when copying their data to other buffers.  Buffer switching operations are also quite fast when using renderboover objects.  So, the function <i>glfwSwapBuffers</i> , which we used at the end of each render cycle, can also be implemented using renderboover objects: write to one buffer, then switch to another after rendering is completed.  In such tasks, the renderbuffer is clearly on horseback. <br><br>  Creating a renderbuffer object is quite similar to creating a frame buffer object: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> rbo; glGenRenderbuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;rbo);</code> </pre> <br>  Expectedly, we need to bind the renderboover object so that subsequent rendering operations direct the results to it: <br><br><pre> <code class="cpp hljs">glBindRenderbuffer(GL_RENDERBUFFER, rbo);</code> </pre> <br>  Since the render buffer objects are generally not available for reading, they are often used to store depth and stencil data - for the most part we don‚Äôt often need specific values ‚Äã‚Äãof these buffers, but in general we need their functions.  More precisely, we need a depth buffer and a stencil for the corresponding tests, but we do not plan to make a sample of them.  In cases where the selection of buffers is not planned, the render buffer is an excellent choice, because the bonus is also a great performance. <br><br>  Creating a Render Buffer for Depth and Stencil: <br><br><pre> <code class="cpp hljs">glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, <span class="hljs-number"><span class="hljs-number">800</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>);</code> </pre> <br>  Creating a renderboover object is similar to texture objects.  The only difference is that the renderbuffer was designed for direct storage of the image, unlike the general purpose buffer, which is a texture object.  Here we specify the internal format of the buffer <i>GL_DEPTH24_STENCIL8</i> , which corresponds to 24 bits per depth value and 8 bits per stencil. <br><br>  Do not forget that the object must be connected to the frame buffer: <br><br><pre> <code class="cpp hljs">glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo);</code> </pre> <br>  Using a render buffer can give some performance benefit to processes using offscreen buffers, but it is important to understand when to use them and when to use textures.  The general principle is this: if you never plan to make selections from the buffer, then use the renderboover object for it.  If at least sometimes you need to make a selection from the buffer, such as, for example, the color or depth of a fragment, then you should refer to the texture attachments.  In the end, the performance gain will not be huge. <br><br><h3>  Render texture </h3><br>  So, armed with the knowledge of how (in general) the personnel buffers work, we begin to use them directly.  Let's try to render the scene in the texture attachment of the frame buffer, and then draw one full-screen quad using this texture.  Yes, we will not see any differences - the result will be the same as without the use of a frame buffer.  What is the profit of such a venture?  Wait for the next section and find out. <br><br>  To begin, create a frame buffer object and tie it right there: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> framebuffer; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;framebuffer); glBindFramebuffer(GL_FRAMEBUFFER, framebuffer);</code> </pre> <br>  Next, we will create a texture object, which we will attach to attaching the frame buffer color.  Again, we set texture sizes equal to the size of the application window, and leave a pointer to the data empty: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    unsigned int texColorBuffer; glGenTextures(1, &amp;texColorBuffer); glBindTexture(GL_TEXTURE_2D, texColorBuffer); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glBindTexture(GL_TEXTURE_2D, 0); //        glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0);</span></span></code> </pre> <br>  We would also like to be able to conduct a depth test (and a stencil test, if you need it), so let's not forget about the task of attaching a depth (and stencil) to our personnel buffer.  Since we plan to make only samples from the color buffer, we can use the render buffer as a data carrier for depth and stencil. <br><br>  Creating a renderbuffer object is trivial.  It is worth remembering only that we are going to create a combined depth and stencil buffer.  Therefore, we expose the internal format of the renderboover object in <i>GL_DEPTH24_STENCIL8</i> .  For our tasks, 24-bit depth accuracy is enough. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> rbo; glGenRenderbuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;rbo); glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, <span class="hljs-number"><span class="hljs-number">800</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>); glBindRenderbuffer(GL_RENDERBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  As soon as we have requested a memory for an object, we can untie it. <br>  Then we attach the renderbuffer object to the combined point of attachment of the depth and stencil of the frame buffer: <br><br><pre> <code class="cpp hljs">glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo);</code> </pre> <br>  The final chord is to check the frame buffer for completeness with a debug message, if it is not: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">cout</span></span> &lt;&lt; <span class="hljs-string"><span class="hljs-string">"ERROR::FRAMEBUFFER:: Framebuffer is not complete!"</span></span> &lt;&lt; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">endl</span></span>; glBindFramebuffer(GL_FRAMEBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  Do not forget to unbind the frame buffer object at the end in order not to accidentally start the render in the wrong direction. <br><br>  Well, we have a frame buffer object, fully prepared for rendering into it, instead of the default frame buffer.  All that remains to be done is to bind our buffer and all subsequent render commands will affect the bound frame buffer.  All operations with the depth and stencil buffers will also use the appropriate attachments of the currently attached frame buffer (if you have, of course, created such).  If, for example, you forgot to add a depth buffer to the frame buffer, then the depth test will no longer work, since there will simply be no source data for it in the frame buffer. <br><br>  So, we list the steps required to output a scene to the texture: <br><br>  1. Bind our frame buffer object as current and output the scene in the usual way. <br>  2. Bind the frame buffer to the default. <br>  3. Display a full-screen quad with texture overlay from the color buffer of our frame buffer object. <br><br>  We will draw the scene taken from the <a href="https://learnopengl.com/">lesson</a> about the depth test, but this time using the familiar <a href="">texture of the</a> container. <br><br>  To display full-screen quad, we will create a new set of trivial shaders.  There will not be any intricate matrix transformations, since we will immediately transfer the coordinates of the vertices to them in the form of normalized device coordinates ( <i>NDC</i> ).  Let me remind you that in this form they can be immediately transferred to the output of the fragment shader: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core layout (location = 0) in vec2 aPos; layout (location = 1) in vec2 aTexCoords; out vec2 TexCoords; void main() { gl_Position = vec4(aPos.x, aPos.y, 0.0, 1.0); TexCoords = aTexCoords; }</span></span></code> </pre> <br>  Nothing fancy, is it?  The fragment shader will be even simpler, since all that he does is fetching from the texture: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D screenTexture; void main() { FragColor = texture(screenTexture, TexCoords); }</span></span></code> </pre> <br>  The code responsible for creating and configuring VAO for the quad itself remains on your conscience.  The iteration of the render has the following structure: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//   glBindFramebuffer(GL_FRAMEBUFFER, framebuffer); glClearColor(0.1f, 0.1f, 0.1f, 1.0f); glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); //     glEnable(GL_DEPTH_TEST); DrawScene(); //   glBindFramebuffer(GL_FRAMEBUFFER, 0); //      glClearColor(1.0f, 1.0f, 1.0f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); screenShader.use(); glBindVertexArray(quadVAO); glDisable(GL_DEPTH_TEST); glBindTexture(GL_TEXTURE_2D, textureColorbuffer); glDrawArrays(GL_TRIANGLES, 0, 6);</span></span></code> </pre> <br>  A few comments.  First, since the created frame buffer object has its own set of buffers, it is necessary to clear each of them by setting the appropriate flags for the <i>glClear</i> function.  Secondly, in the derivation of quad, we disable the depth test, since it is redundant when rendering a simple pair of triangles.  However, the test should be enabled when directly rendering the scene itself. <br><br>  Phew!  Decent stages of work in which it is easy to make a mistake.  If your program does not display anything - try to debug where it is possible, and also re-read the relevant parts of this lesson.  If everything worked successfully, the output will be similar to this result: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/d6/c5/1w/d6c51wr3cemrwhgxkd9vd9utqqg.png"></div><br>  On the left, the result is identical to the image from the <a href="https://learnopengl.com/">lesson</a> on the depth test, but this image is displayed on a full-screen quad.  If you switch the render mode to skeleton (glPolygonMode (GL_FRONT_AND_BACK, GL_LINE) - enter the mode, glPolygonMode (GL_FRONT_AND_BACK, GL_FILL)), you can see that a pair of triangles is drawn into the frame buffer by default . <br>  The source code of the example is <a href="https://learnopengl.com/code_viewer_gh.php%3Fcode%3Dsrc/4.advanced_opengl/5.1.framebuffers/framebuffers.cpp">here</a> . <br><br>  Well, what is the use of all this?  Since we now have a texture with the contents of the finished frame, we can easily access the value of each pixel and implement many intricate effects in the fragment shader!  Collectively, this approach is called <b>post-processing</b> or <b>post</b> <b>-processing</b> . <br><br><h3>  Post processing </h3><br>  Having a texture that contains an image of the entire frame, we can implement a variety of effects using simple operations with texture data.  In this section, some common postprocessing techniques will be demonstrated, as well as ideas on how to make your effect with a little imagination. <br><br>  Let's start with the simplest effect. <br><br><h4>  Color inversion </h4><br>  Since we have full access to the color data of the final frame, in a fragmentary shader, it is easy to get the color value opposite to the original one.  To do this, take a sample of color from the texture and subtract from the unit: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ FragColor = vec4(vec3(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - texture(screenTexture, TexCoords)), <span class="hljs-number"><span class="hljs-number">1.0</span></span>); }</code> </pre> <br>  Inversions of color, despite the simplicity of the effect, can bring quite entertaining results: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/d8/20/kf/d820kfuyxgze81_k1itdrb3z5ug.png"></div><br>  All the colors in the scene were inverted with just a single line of code in the shader, not bad, huh? <br><br><h4>  Grayscale translation </h4><br>  Another interesting effect is the removal of all color information with the image being converted to grayscale.  A naive solution is obvious; it is enough to sum up the brightness values ‚Äã‚Äãof each color channel and average it, replacing the original values ‚Äã‚Äãwith the average: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ FragColor = texture(screenTexture, TexCoords); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> average = (FragColor.r + FragColor.g + FragColor.b) / <span class="hljs-number"><span class="hljs-number">3.0</span></span>; FragColor = vec4(average, average, average, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); }</code> </pre> <br>  The results of this approach are quite acceptable, but the nature of the human eye implies greater sensitivity to the green part of the spectrum and less to the blue.  So a more physically correct reduction to grayscale uses color averaging with weighting factors for individual channels: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ FragColor = texture(screenTexture, TexCoords); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> average = <span class="hljs-number"><span class="hljs-number">0.2126</span></span> * FragColor.r + <span class="hljs-number"><span class="hljs-number">0.7152</span></span> * FragColor.g + <span class="hljs-number"><span class="hljs-number">0.0722</span></span> * FragColor.b; FragColor = vec4(average, average, average, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); }</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ho/ni/0g/honi0gnkk5se7q8ieyj2or6d1uq.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> At first glance, the difference is not obvious, but in more saturated scenes weighted reduction to grayscale gives a better result. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Application of convolutional core </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another advantage of post-processing using a texture map is the fact that we can access any part of the texture. </font><font style="vertical-align: inherit;">For example, take a small area around the current texture coordinate and sample values ‚Äã‚Äãaround the current texel. </font><font style="vertical-align: inherit;">And combining the values ‚Äã‚Äãof these samples is easy to create certain special effects.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A convolutional core (convolution matrix) is a small array of magnitudes like a matrix, the central element of which corresponds to the current pixel being processed, and its surrounding elements to adjacent texture texels. </font><font style="vertical-align: inherit;">During processing, the core values ‚Äã‚Äãsurrounding the central one are multiplied by the values ‚Äã‚Äãof the samples of adjacent texels, and then everything is added together and written into the current (central) texel. </font><font style="vertical-align: inherit;">By and large, we simply add a small offset of the texture coordinates in all directions from the current texel and calculate the final result using values ‚Äã‚Äãfrom the core. </font><font style="vertical-align: inherit;">Take, for example, the following convolution kernel:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow><mo>[</mo><mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;><mtr><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mo>&amp;#x2212;</mo><mn>15</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.946ex" height="9.166ex" viewBox="0 -2232.6 6435 3946.4" role="img" focusable="false" style="vertical-align: -3.981ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(0,2150)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A1" x="0" y="-1155"></use><g transform="translate(0,-2048.5066225165565) scale(1,0.49337748344370863)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A2"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A3" x="0" y="-3155"></use></g><g transform="translate(834,0)"><g transform="translate(-15,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-1450"></use></g><g transform="translate(1486,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="639" y="1350"></use><g transform="translate(0,-50)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-2212" x="0" y="0"></use><g transform="translate(778,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-35" x="500" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="639" y="-1450"></use></g><g transform="translate(4265,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-1450"></use></g></g><g transform="translate(5767,2150)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A4" x="0" y="-1155"></use><g transform="translate(0,-2048.5066225165565) scale(1,0.49337748344370863)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A5"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A6" x="0" y="-3155"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mo>‚àí</mo><mn>15</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>2</mn></mtd></mtr></mtable><mo>]</mo></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1">\begin{bmatrix}2 & 2 & 2 \\ 2 & -15 & 2 \\ 2 & 2 & 2 \end{bmatrix}</script></p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This core multiplies the values ‚Äã‚Äãof neighboring texels by 2, and the current texel by -15. </font><font style="vertical-align: inherit;">In other words, the kernel multiplies all neighboring values ‚Äã‚Äãby the weighting factor stored in the kernel, and ‚Äúequalizes‚Äù this operation by multiplying the value of the current texel by the large negative weighting factor.</font></font><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Most convolutional matrices that you find in the network will have the sum of all coefficients equal to 1. If this is not the case, then the image after processing will either become brighter or darker than the original. </font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Convolutional kernels are an incredibly useful tool for creating post-processing effects, as they are fairly simple to implement, easy to experiment with, and many ready-made examples are already available on the net. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To support the convolutional kernel, we will have to modify the fragment shader code a little. We assume that only 3x3 kernels will be used (most of the known kernels do have this dimension):</font></font><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> offset = <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">300.0</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ vec2 offsets[<span class="hljs-number"><span class="hljs-number">9</span></span>] = vec2[]( vec2(-offset, offset), <span class="hljs-comment"><span class="hljs-comment">// top-left vec2( 0.0f, offset), // top-center vec2( offset, offset), // top-right vec2(-offset, 0.0f), // center-left vec2( 0.0f, 0.0f), // center-center vec2( offset, 0.0f), // center-right vec2(-offset, -offset), // bottom-left vec2( 0.0f, -offset), // bottom-center vec2( offset, -offset) // bottom-right ); float kernel[9] = float[]( -1, -1, -1, -1, 9, -1, -1, -1, -1 ); vec3 sampleTex[9]; for(int i = 0; i &lt; 9; i++) { sampleTex[i] = vec3(texture(screenTexture, TexCoords.st + offsets[i])); } vec3 col = vec3(0.0); for(int i = 0; i &lt; 9; i++) col += sampleTex[i] * kernel[i]; FragColor = vec4(col, 1.0); }</span></span></code> </pre> <br>       9  <i>vec2</i> ,         .     ,      .    ,        .     ,        . , ,   ,     . <br>       : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4p/se/4f/4pse4frctettczf7ygcictmob4s.png"></div><br>     ,      . <br><br><h4>  </h4><br> ,       <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow><mo>[</mo><mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>/</mo></mrow><mn>16</mn></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.85ex" height="9.166ex" viewBox="0 -2232.6 6824.2 3946.4" role="img" focusable="false" style="vertical-align: -3.981ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(0,2150)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A1" x="0" y="-1155"></use><g transform="translate(0,-2048.5066225165565) scale(1,0.49337748344370863)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A2"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A3" x="0" y="-3155"></use></g><g transform="translate(834,0)"><g transform="translate(-15,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="-1450"></use></g><g transform="translate(1486,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-34" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-1450"></use></g><g transform="translate(2986,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-32" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="-1450"></use></g></g><g transform="translate(4488,2150)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A4" x="0" y="-1155"></use><g transform="translate(0,-2048.5066225165565) scale(1,0.49337748344370863)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A5"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A6" x="0" y="-3155"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-2F" x="5322" y="0"></use><g transform="translate(5823,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-36" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>16</mn></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2">\begin{bmatrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{bmatrix} / 16</script></p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the total amount of elements is equal to 16, it is necessary to divide the result by 16 to avoid an extreme increase in brightness. </font><font style="vertical-align: inherit;">Kernel Definition:</font></font><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> kernel[<span class="hljs-number"><span class="hljs-number">9</span></span>] = <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[]( <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">2.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">2.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">4.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">2.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">2.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">16</span></span> );</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Changing the elements of the array of numbers representing the core itself led to a complete transformation of the image: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-5/ui/ev/-5uievrvm4mt9wd9sz4dlylkdh0.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The blur effect has ample opportunities to apply. </font><font style="vertical-align: inherit;">For example, you can change the amount of blur over time to simulate the intoxication of the character, or lift up the amount of blur in scenes where the hero forgot to wear glasses. </font><font style="vertical-align: inherit;">Also, blurring allows you to make color transitions smooth, which will be useful in subsequent lessons. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I think it is already clear that by preparing the code for using the convolution kernel, you can easily and quickly create new post-processing effects. </font><font style="vertical-align: inherit;">In conclusion, we will deal with the last of the most popular convolutional effects.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Definition of boundaries </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Below is the core to identify the boundaries: </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow><mo>[</mo><mtable rowspacing=&quot;4pt&quot; columnspacing=&quot;1em&quot;><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mo>&amp;#x2212;</mo><mn>8</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.784ex" height="9.166ex" viewBox="0 -2232.6 5934.5 3946.4" role="img" focusable="false" style="vertical-align: -3.981ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(0,2150)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A1" x="0" y="-1155"></use><g transform="translate(0,-2048.5066225165565) scale(1,0.49337748344370863)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A2"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A3" x="0" y="-3155"></use></g><g transform="translate(834,0)"><g transform="translate(-15,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="-1450"></use></g><g transform="translate(1486,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="389" y="1350"></use><g transform="translate(0,-50)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-2212" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-38" x="778" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="389" y="-1450"></use></g><g transform="translate(3765,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="1350"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="-50"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJMAIN-31" x="0" y="-1450"></use></g></g><g transform="translate(5267,2150)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A4" x="0" y="-1155"></use><g transform="translate(0,-2048.5066225165565) scale(1,0.49337748344370863)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A5"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/347354/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhBVchOQUvG7fTiJWQipPS8H2GqOw#MJSZ4-23A6" x="0" y="-3155"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mo>[</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mo>‚àí</mo><mn>8</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-3">\begin{bmatrix} 1 & 1 & 1 \\ 1 & -8 & 1 \\ 1 & 1 & 1 \end{bmatrix}</script></p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It resembles the core for sharpening, but in this case highlights all the borders in the image, while shading the rest of the parts. It is very useful if you are only interested in borders in the image:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ja/67/2x/ja672xtdu2z_khposb4pxt8zoyc.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I think you will not be surprised by the fact that convolutional kernels are used in image processing programs and filters, such as Adobe Photoshop. </font><font style="vertical-align: inherit;">Pixel-based modification of images in real time becomes quite accessible due to the outstanding speed of parallel processing of fragments. </font><font style="vertical-align: inherit;">That is why lately graphic packages are increasingly using the capabilities of video cards in the field of image processing. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> From comments to the original: an excellent </font></font><a href="http://setosa.io/ev/image-kernels/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">interactive demonstration of</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> various bundles. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : We have a </font></font><a href="https://t.me/joinchat/Cpb05A46UPpMWdNVVCb4Vg"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">telegram-konf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to coordinate transfers. </font><font style="vertical-align: inherit;">If there is a desire to fit into the cycle, then you are welcome!</font></font></div><p>Source: <a href="https://habr.com/ru/post/347354/">https://habr.com/ru/post/347354/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../347344/index.html">Features of industrial aerial photography. Part I. Preparatory rake</a></li>
<li><a href="../347346/index.html">How to use all the features of mobile OS in React Native</a></li>
<li><a href="../347348/index.html">LittleFS is a compact and economical file system for ARM microcontrollers comprising mbed os. Fast start</a></li>
<li><a href="../347350/index.html">Style Tips. How to write a readable React code</a></li>
<li><a href="../347352/index.html">Interaction of C # and C ++ cross-platform</a></li>
<li><a href="../347358/index.html">Unit tests. Quick start - effective result (with examples in C ++)</a></li>
<li><a href="../347360/index.html">How we built the data infrastructure in Wish</a></li>
<li><a href="../347362/index.html">Avito in the Russian-speaking PostgreSQL community: open 2018, remember 2017</a></li>
<li><a href="../347364/index.html">The book "Angular and TypeScript. Website building for professionals ¬ª</a></li>
<li><a href="../347366/index.html">The third invasion of the Martians</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>