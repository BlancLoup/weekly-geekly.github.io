<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>DICOM Viewer from the inside. Functionality</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day, habrasoobschestvo. I would like to continue to consider aspects of the implementation of DICOM Viewer, and today we will talk about the func...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>DICOM Viewer from the inside. Functionality</h1><div class="post__text post__text-html js-mediator-article">  Good day, habrasoobschestvo.  I would like to continue to consider aspects of the implementation of DICOM Viewer, and today we will talk about the functionality. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6f2/047/85d/6f204785def84f6ebc5a8ae42f86206a.png"></div><br>  So let's go. <br><a name="habracut"></a><br><h4>  <b>2D toolbox</b> </h4><br><h5>  Multiplanar Reconstruction (MPR) </h5><br>  Multiplanar reconstruction allows you to create images from the original plane to the axial, frontal, sagittal or arbitrary plane.  In order to build MPR, it is necessary to build a 3D volume model and ‚Äúcut‚Äù it in the required planes.  As a rule, the best quality of the MPR is obtained with computed tomography (CT), because in the case of CT, you can create a 3D model with a resolution that is the same in all planes.  Therefore, the output MPR is obtained with the same resolution as the original images obtained from CT.  Although there are MRI with good resolution.  Here is an example of multiplanar reconstruction: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/945/373/bc0/945373bc07864137b37f441d414ba23c.png"></div><br>  Green - axial plane (upper left); <br>  Red - frontal plane (top right); <br>  Blue - sagittal plane (lower left); <br>  Yellow - an arbitrary plane (lower right). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The position of the lower right image is determined by the yellow line in the side view (upper left).  This is the image obtained by ‚Äúcutting‚Äù the 3D model with an inclined plane.  To obtain the density value at a specific point of the plane, trilinear interpolation is used. <br><br><h5>  Multiplanar reconstruction on an arbitrary curve (curved MPR) </h5><br><div style="text-align:center;"><img src="https://habrastorage.org/files/2d5/4e7/14c/2d54e714c0c741eb9a21fbfeb5604aa0.png"></div><br>  Same as MPR, but instead of an arbitrary plane you can take a curve, as shown in the figure.  Used, for example, in dentistry for a panoramic picture of the teeth. <br><br>  Each point on the curve defines the starting point of the trace, and the normal to the curve at this point corresponds to the direction of the Y-axis in the two-dimensional image for this point.  The X axis of the image corresponds to the curve itself.  That is, at each point of the two-dimensional image, the direction of the X axis is the tangent to the curve at the corresponding point on the curve. <br><br><h5>  The projection of the minimum / average / maximum intensity (MIP) </h5><br>  The minimum intensity values ‚Äã‚Äãindicate soft tissue.  Whereas the values ‚Äã‚Äãof maximum intensity correspond to the brightest areas of a three-dimensional object ‚Äî these are either the most dense tissues or organs saturated with contrast material.  The minimum / average / maximum intensity value is taken in the range (as shown in the figure by the dotted lines).  The minimum value throughout the model will take the air. <br><br>  The MIP calculation algorithm is very simple: choose a plane on the 3D model - let it be the XY plane.  Then we go along the Z axis and select the maximum intensity value on the specified range and display it on the 2D plane: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/81e/c59/4c7/81ec594c7e30449fb24de139fa8555e9.png"></div><br>  The image obtained by the projection of medium intensity is close to the usual X-ray image: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ceb/ecc/67e/cebecc67e3144e629c978cdb7740dd65.png"></div><br>  Some types of radiological studies do not give the desired effect without the use of a contrast agent, because they do not reflect certain types of tissues and organs.  This is due to the fact that in the human body there are tissues whose density is about the same.  To distinguish these tissues from each other, use a contrast agent, which gives the blood more intensity.  Also, a contrast agent is used to visualize the vessels during angiography. <br><br><h5>  DSA mode for angiography </h5><br>  Angiography is a technique that allows visualization of the bloodstream systems (veins and vessels) of various organs.  For this purpose, a contrast agent is used, which is injected into the test organ, and an X-ray machine, which creates images during the injection of a contrast agent.  Thus, at the output of the apparatus, a set of images with different degrees of visualization of blood flow is obtained: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ccc/cd3/8b2/ccccd38b26e343b9a8dc250e2912f878.png"></div><br>  However, along with the veins and vessels in the pictures visible tissue of other organs, such as the skull.  <a href="http://en.wikipedia.org/wiki/Digital_subtraction_angiography">DSA</a> (Digital subtraction angiography) mode allows you to visualize only the blood flow without any other tissue.  How it works?  We take the image of a series in which the blood flow has not yet been visualized by a contrast agent.  As a rule, this is the first image of the series, the so-called mask: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/2e5/6d9/d48/2e56d9d483be4f199bd2275f97daf095.png"></div><br>  Then we subtract this image from all other images in the series.  We get the following image: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9e1/aa4/273/9e1aa42732d04e9e8883b41e041435b4.png"></div><br>  In this image, blood flow is clearly visible and almost no other tissue is visible, which allows for more accurate diagnosis. <br><br><h4>  <b>3D toolkit</b> </h4><br><h5>  Clipping Box tool </h5><br>  The Clipping Box tool allows you to see the bones and anatomical tissues in the section, as well as show the internal organs from the inside.  The tool is implemented at the renderer level, simply limiting the area of ‚Äã‚Äãraytracing. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/de2/ca7/034/de2ca70344a94afd8fb6012535ecdcbc.png"></div><br>  In the implementation of the region of raytracing is limited to planes with normals directed in the direction of clipping.  That is, the cube is represented by six planes. <br><br><h5>  Volume Editing Tools - Polygon Cut </h5><br>  The tool is similar to the previous one and allows you to delete a volume fragment under an arbitrary polygon: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/140/a87/55e/140a8755ee8c43f99b52077e686eb072.png"></div><br>  By cutting, one should understand voxel vanishing in a 3D model trapped in a polygon region. <br>  Also there is a tool "Scissors", which allow you to remove parts of the 3D-model on the principle of connectivity.  Implementation: when an object is selected, a cyclic search for nearby connected voxels occurs until all nearby voxels are scanned.  Then all scanned voxels are deleted. <br><br><h5>  Ruler in 3D </h5><br>  In 3D, organs can be measured at any angle, which is impossible in some cases in 2D. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/57a/794/289/57a79428940b4ce28cee39ac6ec70e4b.png"></div><br>  In 3D mode, you can also use a polygonal ruler: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/661/404/4dd/6614044ddef943cc88d5271bcec5d48c.png"></div><br><h4>  <b>4d toolkit</b> </h4><br><h5>  Combination of several tomographic series in 3D (Fusion PET-CT) </h5><br>  PET-CT (eng. PET-CT) is a relatively new technology, which is a research method of nuclear medicine.  Is a method of multimodal tomography.  The fourth dimension in this case is modality (PET and CT).  Intended mainly for detecting cancerous tumors. <br><br>  CT helps to get the anatomical structure of the human body: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/dc6/028/756/dc602875646240f58cd92802dcf8490d.png"></div><br>  and PET shows certain areas of concentration of a radioactive substance, which is directly related to the intensity of blood supply to a given area. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c27/4ca/121/c274ca121ba74841ad2b75401f90ae7f.png"></div><br>  PET gets a picture of biochemical activity by detecting radioactive isotopes in the human body.  The radioactive substance accumulates in organs saturated with blood.  Then the radioactive substance undergoes positron beta decay.  The resulting positrons are further annihilated with electrons from the surrounding tissue, resulting in the emission of gamma-ray pairs, which are detected by the device, and then a 3D image is constructed based on the information obtained. <br><br>  The selection of a radioactive isotope determines the biological process that one wishes to track in the research process.  The process may be metabolism, transport of substances, etc. Behavior of the process, in turn, is the key to the correct diagnosis of the disease.  The image above shows a tumor in the liver area. <br><br>  But based on PET, it is difficult to understand in which part of the body the area with the maximum concentration of the radioactive substance is located.  By combining body geometry (CT) and areas saturated with blood with a high concentration of radioactive substance (PET), we get: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/5dd/b33/611/5ddb336115e0443586633b168cb46843.png"></div><br>  Radioactive isotopes with different half-lives are used as a radioactive substance for PET.  Fluorine-18 (fluorodeoxyglucose) is used to form all kinds of malignant tumors, iodine-124 is used to diagnose thyroid cancer, and gallium-68 is used to detect neuroendocrine tumors. <br><br>  The Fusion functionality forms a new series in which the images of both modalities (both PET and CT) are combined.  In the implementation, the images of both modalities are mixed, and then sorted along the Z axis (we assume that X and Y are the image axes).  In fact, it turns out that the images in the series alternate (PET, CT, PET, CT ...).  This series is further used to draw 2D fusion and 3D fusion.  In the case of 2D fusion, images are drawn in pairs (PET-CT) in ascending order of Z: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ead/dcc/14a/eaddcc14abce4b0496e0e5b68c6ea6f0.png"></div><br>  In this case, the CT image was first drawn, then the PET. <br><br>  3D fusion is implemented for a video card on CUDA.  Both 3D-models - PET and CT are drawn on the video card at the same time and a real multimodal fusion is obtained.  On the processor, the fusion also works, but it works a little differently.  The fact is that on the processor both models are represented in memory as separate octo-trees.  Therefore, when drawing it is necessary to trace two trees and synchronize the skipping of transparent voxels.  And this would significantly reduce the speed of work.  Therefore, it was decided to simply overlay the result of rendering one 3D-model on top of another. <br><br><h5>  4D CardiacCT </h5><br>  Cardiac CT technology is used to diagnose various disorders of the heart, including coronary heart disease, pulmonary thromboembolism and other diseases. <br><br>  4D Cardiac CT is a 3D in time.  Those.  It turns out a small video, which we will call a film loop, in which each frame will be a 3D object.  The source data is a set of dicom-images for all frames of a film loop at once.  In order to convert a set of images into a film loop, you must first group the source images into frames, and then create 3D for each frame.  Building a 3D object at the frame level is the same as for any series of dicom images.  We use heuristic image sorting to group by frame, using the position of the image on the Z axis (assuming that X and Y are image axes).  We believe that after grouping by frames, the same number of images is obtained in each frame.  Switching the frame actually comes down to switching the 3D model. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/iZlIqnaTURw%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhVMlHI2Y57I_3WTulWraWwwmV2nA" frameborder="0" allowfullscreen=""></iframe><br><br><h5>  5D Fusion Pet - CardiacCT </h5><br>  5D Fusion Pet - CardiacCT is a 4D Cardiac CT with the addition of fusion with PET as the fifth dimension.  In the implementation, we first create two film loops: with CardiacCT and with PET.  Then we make fuision of the corresponding frames of the movie band, which gives us a separate series.  Then we build the resulting 3D series.  It looks like this: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/nnVwEU4cgJc%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjL5sHo7QESXhGUV96iQUo8mNcs3A" frameborder="0" allowfullscreen=""></iframe><br><br><h5>  Virtual endoscopy </h5><br>  As an example of virtual endoscopy, we will consider virtual colonoscopy, since it is the most common type of virtual endoscopy.  Virtual colonoscopy allows to construct a volumetric reconstruction of the abdominal cavity area on the basis of CT data and to make a diagnosis using this 3D reconstruction.  In the viewer there is a fly-through camera tool with MPR navigation: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/481/2a8/b7f/4812a8b7fd5b4a4a9c03d5d41b85fcfb.png"></div><br>  which also allows you to automatically follow the anatomical structure.  In particular, it allows you to view the intraintestinal region automatically.  Here's what it looks like: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/ioLWHIYDIUo%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjOuKus6vAqCGqOdWuayXU4jJWHPA" frameborder="0" allowfullscreen=""></iframe><br><br>  The flight of the camera represents a series of consecutive movements in the intraintestinal region.  For each step, the vector of camera movement to the next part of the anatomical structure is calculated.  The calculation is based on transparent voxels in the next part of the anatomical structure.  In fact, a certain voxel is calculated among transparent ones.  The initial displacement vector is defined by the camera vector.  In the Camera Flight tool, an exclusively perspective projection is used <br><br>  There is also a functional for automatic intestinal segmentation, i.e.  functionality to separate the intestinal region from the rest of the anatomy: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e08/4b1/baa/e084b1baa5604c10bc03a16a4861a5e9.png"></div><br>  It is also possible to navigate through a segmented 3D model (the Show camera orientation button), which, by a mouse click on the 3D model, moves the camera to the appropriate position in the original anatomy. <br>  Segmentation is implemented using a <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC_%25D0%259B%25D0%25B8">wave algorithm</a> .  It is believed that the anatomy is closed in the sense that it is not in contact with other organs and external space. <br><br><h5>  ECG Viewer (Waveform) </h5><br>  A separate module in the viewer implements data reading from the Waveform and its drawing.  DICOM ECG Waveform is a special format for storing data from electrocardiogram leads defined by the DICOM standard.  These electrocardiograms are twelve leads - 3 standard, 3 reinforced and 6 chest.  The data of each lead is a sequence of measurements of the electrical voltage on the surface of the body.  In order to draw the voltage, you need to know the scale vertically in mm / mV and the horizontal scale in mm / s: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e1a/fd4/f1b/e1afd4f1bfc045f5bba814b17990e9ec.png"></div><br>  As auxiliary attributes, the grid is also drawn for ease of measuring distances and a scale in the upper left corner.  Scale options are selected taking into account medical practice: 10 and 20 mm / mV vertically, 25 and 50 mm / sec horizontally.  Also implemented tools for measuring the distance horizontally and vertically. <br><br><h5>  DICOM-Viewer as a DICOM client </h5><br>  DICOM-Viewer, among other things, is a full-fledged DICOM client.  It is possible to search on the PACS server, retrieve data from it, etc. The functions of the DICOM client are implemented using the open DCMTK library.  Consider a typical use-case of the DICOM client on the example of the viewer.  Perform a search for stages on a remote PACS server: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/be5/162/3dc/be51623dc066486b9f014aeeff1de8b5.png"></div><br>  When a stage is selected, the series for the selected stage and the number of images in them are displayed at the bottom.  The PACS server on which the search will be performed is indicated on the top right.  The search can be parameterized by refining the search criteria: PID, study date, patient name, etc. The client search is performed by the C-FIND SCU command using the DCMTK library, which operates at one of the levels: STUDY, SERIES and IMAGE. <br><br>  Next, images of the selected series can be downloaded using the C-GET-SCU and C-MOVE-SCU commands.  The DICOM protocol obliges the parties to the connection, i.e.  client and server, agree in advance what type of data they are going to transfer through this connection.  A data type is a combination of the values ‚Äã‚Äãof the SOPClassUID and TransferSyntax parameters.  SOPClassUID determines the type of operation that is scheduled to be performed through this connection.  The most commonly used SOPClassUIDs are: Verification SOP Class (ping server), Storage Service Class (image saving), Printer Sop Class (printing on a DICOM printer), CT Image Storage (saving CT images), MR Image Storage (saving image MRI) and others.  TransferSyntax determines the format of a binary file.  Popular TransferSyntaxs: Little Endian Explicit, Big Endian Implicit, JPEG Lossless Nonhierarchical (Processes 14).  That is, in order to transfer MRI images in the Little Endian Implicit format, then MR Image Storage - Little Endian Explicit must be added to the connection. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/aa4/298/c00/aa4298c00d18468cb4a0944451a54829.png"></div><br>  Downloaded images are saved to the local storage and, when re-viewed, are downloaded from it, which allows to increase the performance of the viewer.  Saved series are marked with a yellow icon in the upper left corner of the first image of the series. <br><br>  Also, DicomViewer as a DICOM client can burn discs with studies in the DICOMDIR format.  The DICOMDIR format is implemented as a binary file that contains relative paths to all DICOM files that are written to disk.  Implemented using the DCMTK library.  When reading a disc, the paths to all files from DICOMDIR are read and then loaded.  To add stages and series to DICOMDIR, the following interface was developed: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c37/64d/ef0/c3764def04934a62b4005efe86b6b57f.png"></div><br>  That's all that I wanted to tell you about the functionality of DicomViewer.  As always, feedback from qualified professionals is very welcome. <br><br>  Viewer Link: <br>  <a href="">DICOM Viewer x86</a> <br>  <a href="">DICOM Viewer x64</a> <br><br>  Data examples: <br>  <a href="">MANIX</a> - for common examples (MPR, 2D, 3D, etc.) <br>  <a href="">COLONIX</a> - for virtual colonoscopy <br>  <a href="">FIVIX</a> - 4D CARDIAC-CT <br>  <a href="">CEREBRIX</a> - Fusion PET-CT </div><p>Source: <a href="https://habr.com/ru/post/258621/">https://habr.com/ru/post/258621/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../258607/index.html">Krovi: Big Data - as dream. 9th series: Why IBM was forced to buy "Alchemists" for $ 100 million</a></li>
<li><a href="../258611/index.html">An example of a vector implementation of a neural network using Python</a></li>
<li><a href="../258613/index.html">Wing IDE Protection Study</a></li>
<li><a href="../258615/index.html">Pulse sensor device Part 2 - Sensors</a></li>
<li><a href="../258619/index.html">Homemade control unit for diesel engine</a></li>
<li><a href="../258625/index.html">Top 10 non-cash countries of the world</a></li>
<li><a href="../258627/index.html">The digest of interesting materials for the mobile developer # 104 (on May 18-24)</a></li>
<li><a href="../258629/index.html">Refactoring database schemas</a></li>
<li><a href="../258635/index.html">ISO 9241-210. Planning and Implementing Human-Centered Design</a></li>
<li><a href="../258641/index.html">JDK 7 code statistics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>