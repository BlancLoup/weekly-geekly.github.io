<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Pacemaker / corosync cluster without validol</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Imagine the situation. Saturday evening. You are the PostgreSQL administrator, after a hard working week you left for the dacha 200 km from your favor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Pacemaker / corosync cluster without validol</h1><div class="post__text post__text-html js-mediator-article">  Imagine the situation.  Saturday evening.  You are the <b>PostgreSQL</b> administrator, after a hard working week you left for the dacha 200 km from your favorite job and you feel great ... As long as your peace does not disturb the SMS from the <b>Zabbix</b> monitoring system.  There was a failure on the DBMS server, the database is currently unavailable.  To solve the problem is given a short time.  And you have no choice but to saddle a service scooter with your heart and rush to work.  Alas! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/i_/z9/7q/i_z97qr6zimdry1k9hbruykmgkw.jpeg"></div><br>  But it could be different.  You receive an SMS from the monitoring system that a failure occurred on one of the servers.  But the DBMS continues to work, since the PostgreSQL failover cluster has completed the loss of one node and continues to function.  There is no need to urgently go to work and restore the database server.  Clarification of the causes of failure and recovery work quietly transferred to the working Monday. <br><br>  Anyway, it is worth thinking about technologies of fault-tolerant clusters with PostgreSQL DBMS.  We will talk about building a PostgreSQL database failover cluster using Pacemaker &amp; Corosync software. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><h3>  Failover Cluster PostgreSQL DBMS Based on Pacemaker </h3><br>  Today, in IT systems of the ‚Äúbusiness critical‚Äù level, the demand for broad functionality is becoming secondary.  In the first place comes the demand for reliability of IT systems  For fault tolerance, it is necessary to introduce redundancy of system components.  They are managed by special software. <br><br>  An example of such software is Pacemaker, a solution from <a href="http://clusterlabs.org/"><b>ClusterLabs</b></a> , which allows you to organize a fault-tolerant cluster (OAK).  Pacemaker runs under a wide range of operating <b>Unix</b> systems - <b>RHEL, CentOS, Debian, Ubuntu</b> . <br><br>  This software was not created specifically to work with PostgreSQL or other DBMS.  The scope of Pacemaker &amp; Corosync is much wider.  There are specialized solutions sharpened for PostgreSQL, for example <b>multimaster</b> , part of Postgres Pro Enterprise (Postgres Professional), or <b>Patroni</b> ( <b>Zalando</b> ).  But the PostgreSQL cluster based on Pacemaker / Corosync, considered in the article, is quite popular and is suitable for a considerable number of situations in terms of simplicity and reliability to the cost of ownership.  It all depends on the specific tasks.  Comparing solutions is beyond the scope of this article. <br><br>  So: Pacemaker is a brain and part-time cluster resource manager.  His main task is to achieve maximum availability of the resources he manages and protect them from failures. <br><br>  During the operation of the cluster, various events occur - failure, joining of nodes, resources, transition of nodes to service mode, and others.  Pacemaker responds to these events in a cluster by performing actions it is programmed for, such as stopping resources, moving resources, and others. <br><br>  In order to make it clear how Pacemaker works and works, let's consider what is inside and what it consists of. <br><br>  So, let's go to the Pacemaker entities. <br><br><img src="https://habrastorage.org/webt/tu/9x/rq/tu9xrqpsrm_bkmw6igktrxai12o.gif"><br><br>  <i>Figure 1. The pacemaker entities - cluster nodes</i> <i><br><br></i>  The first and most important entity is the <b>nodes of the</b> cluster.  A node ( <code>node</code> ) of a cluster is a physical server or virtual machine with Pacemaker installed. <br><br>  Nodes intended to provide the same services should have the same software configuration.  That is, if the postgresql resource is supposed to run on <code>node1, node2</code> , and it is located in non-standard installation paths, then these nodes should have the same configuration files, PostgreSQL installation paths, and of course, the same PostgreSQL version. <br><br>  The next important Pacemaker entity group is <b>cluster resources</b> .  In general, for Pacemaker, a resource is a script written in any language.  Usually these scripts are written in <code>bash</code> , but nothing prevents you from writing them in <code>Perl, Python, C</code> or even <code>PHP</code> .  The script controls the services in the operating system.  The main requirement for scripts is to be able to perform 3 actions: <b>start, stop, monitor</b> and share some meta-information. <br><br>  However, in our case, the PostgreSQL cluster, <b>we</b> add <b>promote</b> , <b>demote,</b> and other PostgreSQL-specific commands to these actions. <br>  Examples of resources: <ul><li>  IP address; </li><li>  service launched in the operating system; </li><li>  block device </li><li>  file system; </li><li>  others. </li></ul><br>  Resources have many attributes that are stored in Pacemaker‚Äôs XML configuration file.  The most interesting of them are: <b>priority, resource-stickiness, migration-threshold, failure-timeout, multiple-active.</b> <br>  Consider them in more detail. <br><br>  The <b>priority</b> attribute is the resource priority, which is taken into account if the node has reached the limit on the number of active resources (default is 0).  If the cluster nodes are not equal in performance or availability, then you can increase the priority of one of the nodes so that it is always active when it is running. <br><br>  The <b>resource-</b> stickiness attribute is <b>resource</b> stickiness (default is 0).  Stickiness (stickiness) indicates how resource "wants" to remain where it is now.  For example, after a node fails, its resources are transferred to other nodes (more precisely, they start on other nodes), and after the failed node recovers, the resources may return to it or not, and this behavior is described by the stickiness parameter. <br><br>  In other words, stickiness shows how desirable or not desirable the resource is to return to the node restored after the failure. <br><br>  Since the default stickiness of all resources is 0, then Pacemaker itself allocates resources on the nodes "optimally" at its discretion. <br><br>  But this may not always be optimal from an administrator‚Äôs point of view.  For example, in the case when the nodes in the failover cluster have unequal performance, the administrator will want to start the services on the node with higher performance. <br><br>  Pacemaker also allows you to set different stickiness of a resource depending on the time of day and day of the week, which allows, for example, to ensure that the resource is transferred to the original node during off-hours. <br><br>  The <b>migration-threshold</b> attribute ‚Äî how many failures must occur for Pacemaker to decide that a node is unsuitable for this resource and transfer (migrate) it to another node.  By default, this parameter is also 0, that is, with any number of failures, automatic transfer of resources will not occur. <br><br>  But, in terms of fault tolerance, set this parameter correctly to 1, so that at the first failure Pacemaker moves the resource to another node. <br><br>  The <b>failure-timeout</b> attribute is the number of seconds after a failure, before the expiration of which Pacemaker believes that a failure did not occur, and does not do anything, in particular, does not move resources.  The default is 0. <br><br>  The attribute <b>multiple-active</b> - instructs Pacemaker what to do with the resource if it is running on more than one node.  It can take the following values: <ul><li>  <b>block</b> - set the <b>unmanaged</b> option, that is, deactivate </li><li>  <b>stop_only</b> - stop on all nodes </li><li>  <b>stop_start</b> - stop on all nodes and run only on one (default value). </li></ul><br>  By default, the cluster does not monitor after startup whether the resource is alive.  To enable resource tracking, you need to add a <code>monitor</code> operation when creating a resource, then the cluster will monitor the state of the resource.  The <code>interval</code> parameter of this operation is the interval with which to do the check. <br><br>  When a failure occurs on the primary node, Pacemaker ‚Äúmoves‚Äù resources to another node (in fact, Pacemaker stops resources on the failed node and starts resources on another).  The process of "moving" resources to another node is quick and transparent to the end client. <br><br><br><h3>  Resource groups </h3><br>  Resources can be grouped together ‚Äî lists of resources that must be started in a specific order, stopped in the reverse order and executed on one node. All group resources are started on one node and started sequentially according to the order in the group.  But keep in mind that if one of the group's resources fails, the whole group will move to another node. <br><br>  When you turn off any resource group, all subsequent resources of the group also turn off.  For example, a <b>PostgreSQL</b> resource of type <b>pgsql</b> and a <b>Virtual-IP</b> resource of type <b>IPaddr2</b> can be combined into a group. <br><br>  The startup sequence in this group is as follows: PostgreSQL is first launched, and when it is successfully launched, the Virtual-IP resource is launched after it. <br><br><h3>  Quorum (quorum) </h3><br>  What is quorum?  It is said that a cluster has a quorum with a sufficient number of ‚Äúlive‚Äù cluster nodes.  The sufficiency of the number of "live" nodes is determined by the formula below. <br>  <b>n&gt; N / 2</b> , where n is the number of living nodes, N is the total number of nodes in the cluster. <br><br>  As can be seen from a simple formula, a cluster with a quorum is when the number of ‚Äúlive‚Äù nodes is more than half the total number of nodes in the cluster. <br><br><img src="https://habrastorage.org/webt/e1/h6/so/e1h6soohua_fsrgovwzrb5hul7w.gif"><br><br>  <i>Figure 2 - Failover Cluster with Quorum</i> <br><br>  As you probably understand, in a cluster consisting of two nodes, if one of the 2 nodes fails, there will be no quorum.  By default, if there is no quorum, Pacemaker stops resources. <br><br>  To avoid this, when setting up Pacemaker, you need to tell it so that the presence or absence of a quorum is not taken into account.  This is done using the <b>no-quorum-policy = ignore</b> option. <br><br><h3>  Pacemaker architecture </h3><br>  The architecture of Pacemaker consists of three levels: <br><br><img src="https://habrastorage.org/webt/w0/of/lk/w0oflkblsrcbifajgpa_vbeibpu.jpeg"><br><br>  <i>Figure 3 - Pacemaker Levels</i> <br><br><ul><li>  <b>Cluster-independent level</b> - resources and agents.  At this level are the resources themselves and their scripts.  The figure is indicated in green. </li><li>  <b>The resource manager</b> (Pacemaker) is the ‚Äúbrain‚Äù of the cluster.  It responds to events occurring in a cluster: failure or connection of nodes, resources, transition of nodes to service mode, and other administrative actions.  The figure is marked in blue. </li><li>  <b>Information level (Corosync</b> ) - at this level the network interaction of nodes is carried out, i.e.  transfer of service commands (start / stop of resources, nodes, etc.), exchange of information on the completeness of the cluster ( <code>quorum</code> ), etc.  In the figure it is indicated in red. </li></ul><br><h3>  What do you need to work Pacemaker? </h3><br>  For a failover cluster to function properly, the following requirements must be met: <ul><li>  Time synchronization between nodes in a cluster </li><li>  Resolving node names in a cluster </li><li>  Network Connection Stability </li><li>  The presence of cluster power management / reboot functions using IPMI (ILO) for the organization of "fencing" (fencing - isolation) node. </li><li>  Allow traffic through protocols and ports </li></ul><br>  Consider these requirements in more detail. <br><br>  <b>Time synchronization</b> - it is necessary that all nodes have the same time, usually this is done by installing a time server in the local network ( <code>ntpd</code> ). <br><br>  <b>Name resolution</b> is implemented by installing a DNS server in the local network.  If you cannot install a DNS server, you need to make entries on the / etc / hosts file with host names and IP addresses on all nodes of the cluster. <br><br>  <b>Stability of network connections</b> .  It is necessary to get rid of false positives.  Imagine that you have an unstable local network in which every 5-10 seconds there is a loss of link between the cluster nodes and the switch.  In this case, Pacemaker will consider link failure to disappear for more than 5 seconds.  Missing link, your resources "moved."  Then the link was restored.  But Pacemaker already considers the node in the cluster ‚Äúfailed‚Äù, it has already ‚Äútransferred‚Äù resources to another node.  At the next failure, Pacemaker will ‚Äútransfer‚Äù resources to the next node, and so on, until all the nodes have run out and a denial of service occurs.  Thus, due to false positives, the entire cluster may cease to function. <br><br>  <b>The presence of cluster power management functions / reboot using IPMI (ILO) for the organization of "fensing</b> . <b>"</b>  It is necessary in order to isolate it from the remaining nodes when a node fails.  "Fensing" eliminates the situation of a split-brain (when there are simultaneously two nodes that perform the role of the PostgreSQL DBMS). <br><br>  <b>Allow traffic through protocols and ports</b> .  This is an important requirement, because in various organizations, security services often place restrictions on the passage of traffic between subnets or restrictions at the switch level. <br><br>  The table below lists the protocols and ports that are required for a failover cluster to function. <br><br><img src="https://habrastorage.org/webt/ak/5f/qc/ak5fqcjiboahitovxdmft3389eg.gif"><br><br>  <i>Table 1 - The list of protocols and ports required for the operation of the OAK</i> <br><br>  The table shows the data for the case of a failover cluster of 3 nodes - <code>node1, node2, node3</code> .  It also implies that cluster nodes and node power management interfaces (IPMI) are on different subnets. <br><br>  As the table shows, it is necessary to ensure not only the availability of neighboring nodes in the local network, but also the availability of nodes in the IPMI network. <br><br><h3>  Features of use of virtual computers for OAK </h3><br>  When using virtual machines to build fault-tolerant clusters, the following features should be considered. <ul><li>  <b>fsync.</b>  Fault tolerance PostgreSQL DBMS is very strongly tied to the ability to synchronize the recording in the permanent storage (disk) and the correct functioning of this mechanism.  Different hypervisors implement caching of disk operations in different ways, some do not provide timely data dumping from the cache to the storage system. </li><li>  <b>realtime corosync.</b>  The corosync process in a Pacemaker based PDA is responsible for detecting cluster node failures.  In order for it to function correctly, it is necessary that the OS is guaranteed to schedule its execution on the processor (the OS allocates processor time).  In this regard, this process has the priority of RT ( <code>realtime</code> ).  In a virtualized OS, there is no way to guarantee such process planning, which leads to false positives of cluster software. </li><li>  <b>fensing</b>  In a virtualized environment, the <code>fencing</code> mechanism becomes more complex and multi-layered: at the first level, you need to turn off the virtual machine through the hypervisor, and at the second level, turn off the entire hypervisor (the second level works when the first fensing level did not work correctly).  Unfortunately, some hypervisors do not have fencing.  We recommend not using virtual machines when building an OAK. </li></ul><br><h3>  Features of using PostgreSQL for OAK </h3><br>  When using PostgreSQL in failover clusters, the following features should be considered: <ul><li>  Pacemaker when starting a cluster with PostgreSQL places the lock file LOCK.PSQL on the node with the DBMS master.  Usually this file is located in the <code>/var/lib/pgsql/tmp</code> .  This is done with the intention of preventing the automatic launch of PostgreSQL in the event of a failure on the Wizard.  Thus, after a failure on the wizard, the intervention of the DBA is always required to eliminate the causes of the failure. </li><li>  Since a standard PostgreSQL Master-Slave scheme is used in OAK, with certain failures the situation of two Masters is possible - the so-called.  <b>split-brain</b> .  For example, failure <i>The loss of network connectivity between any of the nodes and the other nodes</i> (for all types of failures, see below).  In order to avoid this situation, it is necessary to fulfill two important conditions when building fault-tolerant clusters: <ul><li>  <b>availability of quorum in OAK</b> .  This means that there must be at least 3 nodes in the cluster.  Moreover, it is not necessary to have all three nodes with a DBMS, it is enough to have a Master and a Replica on two nodes, and the third node acts as a ‚Äúvoter‚Äù. </li><li>  <b>The presence of fensing devices on the nodes with the database</b> .  In the event of a failure, the fensing devices isolate the failed node by sending a command to turn off the power or reboot ( <code>poweroff</code> or <code>hard-reset</code> ). </li></ul></li><li>  WAL archives are recommended to be placed on <code>shared</code> storage devices available to both the Wizard and the Replica.  This will simplify the process of restoring the Master after a failure and transfer it to <code>Slave</code> mode. </li><li>  To manage PostgreSQL DBMS, when setting up a cluster, you need to create a resource of type pgsql.  When creating a resource, specific features of PostgreSQL are taken into account, such as the path to the data (for example, <code>pgdata="/var/lib/pgsql/9.6/data/")</code> , the path to the command files ( <code>psql="/usr/pgsql-9.6/bin/psql"</code> and <code>pgctl="/usr/pgsql-9.6/bin/pg_ctl"</code> ), replica type ( <code>rep_mode="sync"</code> ), virtual ip-address for the Master ( <code>master_ip="10.3.3.3"</code> ), and also some parameters which are added to the <code>recovery.conf</code> file on the replica ( <code>restore_command="cp /var/lib/pgsql/9.6/pg_archive/%f %p"</code> and <code>primary_conninfo_opt="keepalives_idle=60 keepalives_interval=5 keepalives_count=5"</code> ). <br>  An example of creating a PostgreSQL resource of type pgsql in a cluster of three nodes: pgsql01, pgsql02, pgsql03: <pre> <code class="hljs perl">sudo pcs resource create PostgreSQL pgsql pgctl=<span class="hljs-string"><span class="hljs-string">"/usr/pgsql-9.6/bin/pg_ctl"</span></span> \ psql=<span class="hljs-string"><span class="hljs-string">"/usr/pgsql-9.6/bin/psql"</span></span> pgdata=<span class="hljs-string"><span class="hljs-string">"/var/lib/pgsql/9.6/data/"</span></span> \ rep_mode=<span class="hljs-string"><span class="hljs-string">"sync"</span></span> node_list=<span class="hljs-string"><span class="hljs-string">" pgsql01 pgsql02 pgsql03"</span></span> restore_command=<span class="hljs-string"><span class="hljs-string">"cp /var/lib/pgsql/9.6/pg_archive/%f %p"</span></span> \ primary_conninfo_opt=<span class="hljs-string"><span class="hljs-string">"keepalives_idle=60 keepalives_interval=5 keepalives_count=5"</span></span> master_ip=<span class="hljs-string"><span class="hljs-string">"10.3.3.3"</span></span> restart_on_promote=<span class="hljs-string"><span class="hljs-string">'false'</span></span></code> </pre> </li></ul><h3>  Pacemaker Management Commands </h3><br>  Here are some interesting Pacemaker management commands (all commands require the rights of the OS superuser). The main cluster management utility is <b>pcs</b> .  Before setting up and first launching the cluster, you need to authorize the nodes in the cluster once. <ul><li>  sudo pcs cluster auth node1 node2 node3 -u hacluster -p 'password' </li><li>  Running the cluster on all nodes </li><li>  sudo pcs cluster start --all </li></ul><br>  Start / stop on one node: <ul><li>  sudo pcs cluster start </li><li>  sudo pcs cluster stop </li></ul><br>  Viewing Cluster Status with Corosync Monitor: <ul><li>  sudo crm_mon -Afr </li></ul><br>  Crash counters clearing: <ul><li>  sudo pcs resource cleanup </li></ul>  The failure counters should be cleared when we have eliminated the cause of the failure and want to return the node to the cluster.  Otherwise, if the cause of the failure has not been eliminated, PostgreSQL may not start and this node for the cluster will be in the HS: alone or DISCONNECT state (for more details on the node states in the cluster below). <br><br><h3>  Cluster state monitoring with crm_mon </h3><br>  Pacemaker has a built-in cluster status monitoring utility.  The system administrator can use it to see what is happening in the cluster, what resources on which nodes are currently located. <br><br>  Using the crm_mon command, you can monitor the state of the PDM. <ul><li>  sudo crm_mon ‚ÄìAfr </li></ul><br>  The screenshot shows a cluster status report. <br><br><img src="https://habrastorage.org/webt/yt/k7/0a/ytk70abuifl22xzhl5uehoeyhmq.jpeg"><br><br>  <i>Figure 4 - Monitoring the status of the cluster using the crm_mon command</i> <br><br>  <b>pgsql-status</b> <br>  <code>PRI</code> - master status <br>  <code>HS:sync</code> - synchronous replica <br>  <code>HS:async</code> - asynchronous replica <br>  <code>HS:alone</code> - the replica can not connect to the master <br>  <code>STOP</code> - PostgreSQL stopped <br>  <b>pgsql-data-status</b> <br>  <code>LATEST</code> - a state inherent to the master.  This node is a master. <br>  <code>STREAMING:SYNC/ASYNC</code> - shows replication status and replication type <code>(SYNC/ASYNC)</code> <br>  <code>DISCONNECT</code> - replica can not connect to the master.  This usually happens when there is no connection from the replica to the master. <br>  <b>pgsql-master-baseline</b> <br>  Shows the time line.  The time line changes every time after the <b>promote</b> command on a node replica.  After this, the DBMS starts a new countdown. <br><br><h3>  Types of failures on cluster nodes </h3><br>  What kinds of failures does a fail-safe cluster based on Pacemaker protect against? <ul><li>  <b>Power failure on the current master or replica.</b>  A power failure occurs when the power goes out and the server shuts down.  This can be either a Master or one of the Replicas. </li><li>  <b>PostgreSQL process crash</b> .  Primary PostgreSQL process crash - the system may terminate the postgres process for various reasons, such as low memory, insufficient file descriptors, or the maximum number of open files exceeded. </li><li>  <b>Loss of network connectivity between any of the nodes and the rest of the nodes</b> .  This is the network unavailability of any site.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> For example, it could be caused by the failure of a network card or a switch port. </font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Failure of the Pacemaker / Corosync process</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The failure of the Corosync / pacemaker process is similar to the failure of the PostgreSQL process.</font></font></li></ul><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kinds of scheduled maintenance </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> To carry out maintenance work, it is necessary to periodically remove from the cluster the individual nodes: </font></font><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The decommissioning of the Master or the Replica for the planned work is necessary in the following cases: </font></font><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> replacement of failed equipment (which did not lead to failure); </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> equipment upgrade; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> software update; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> other cases. </font></font></li></ul></li><li>     .    , ,       . ,        ,     PostgreSQL,   ,   .             .  ,                 . </li></ul><br><br>  <i><b>Important!</b></i> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Before changing roles or decommissioning the Master, it is necessary to </font><font style="vertical-align: inherit;">make sure that there is a synchronous replica in the cluster </font><font style="vertical-align: inherit;">using the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">#crm_mon ‚ÄìAfr</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> command </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">And the role of the Master is always assigned to a synchronous replica. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the purpose of this not so short article is to introduce you to one of the resiliency solutions of the PostgreSQL DBMS, the installation, configuration and configuration commands of the failover cluster are not considered. </font></font><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The author of the article is </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Igor Kosenkov</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Postgres Professional engineer. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Drawing - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Natalia Lyovshina</font></font></b></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></div><p>Source: <a href="https://habr.com/ru/post/359230/">https://habr.com/ru/post/359230/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../359220/index.html">Economy of semiconductor production in Russia: we are analyzing one news</a></li>
<li><a href="../359222/index.html">Weak HTTPS. Part 1</a></li>
<li><a href="../359224/index.html">How does PandaDoc work effectively with lead scoring?</a></li>
<li><a href="../359226/index.html">How to properly optimize and legalize the organization's IT infrastructure</a></li>
<li><a href="../359228/index.html">Microsoft Office Security: Automation</a></li>
<li><a href="../359232/index.html">Using the KOMPAS-3D API ‚Üí Lesson 9 ‚Üí Reading the caption cells</a></li>
<li><a href="../359234/index.html">How artificial intelligence and machine learning help employees improve their skills</a></li>
<li><a href="../359238/index.html">Bad tips: how to turn the automation of UI tests into a nightmare</a></li>
<li><a href="../359240/index.html">How I did my finance accounting for android with blackjack, SMS and FTS</a></li>
<li><a href="../359242/index.html">Avito Playbook: initial commit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>