<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>KDD 2018, the fifth and final day</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="That ended the fifth, the last day of KDD. It was possible to hear some interesting reports from Facebook and Google AI, to remember football tactics ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>KDD 2018, the fifth and final day</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/jp/t5/qw/jpt5qwcq654mx9itaawqiyas7u0.jpeg"><br><br>  That ended the fifth, the last day of KDD.  It was possible to hear some interesting reports from Facebook and Google AI, to remember football tactics and to generate some chemicals.  This and not only - under the cut.  See you next year in Anchorage, the capital of Alaska! <br><a name="habracut"></a><br><h2>  On Big Data Learning for Small Data Problems </h2><br>  The morning report from the <a href="http://www.kdd.org/kdd2018/keynotes/view/yee-whye-teh">Chinese professor</a> was hard.  The speaker was clearly a freebie in preparation, often lost, began to skip slides, and instead of talking for life he tried to load sleepy brain with mathematics. <br><br>  The general outline of the story revolved around the idea that there is not always a lot of data.  There are, for example, a long tail with many different examples.  There are datasets with a large number of classes, which, although large, are in themselves, but there are only a few entries for each class.  He cited <a href="https://github.com/brendenlake/omniglot">Omniglot</a> as an example of such <a href="https://github.com/brendenlake/omniglot">datasets</a> - handwritten characters from 50 alphabets, 1623 classes and 20 pictures per class on average.  But in fact, in this perspective, datasets of recommendation tasks can also be considered, when we have a lot of users and not so many ratings for each of them individually. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      What can be done to make life easier for ML in this situation?  Firstly.  try to bring into it the knowledge of the subject area.  This can be done in different forms: this is engineering of features, and specific regularizations, and refinement of the network architecture.  Another common solution is transfer learning, I think almost everyone who worked with pictures started with additional training of some ImageNet on their data.  In the case of Omniglot, the natural donor for the transfer will be <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> . <br><br>  One of the forms of transfer can be <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> , about which we have already spoken several times on KDD.  The development of MTL can be considered the <a href="https://en.wikipedia.org/wiki/Meta_learning_(computer_science)">meta learning</a> approach - by teaching the algorithm to sample from a multitude of tasks, we can LEARN not only parameters, but also hyper parameters (of course, only if our procedure is differentiable). <br><br>  Continuing the topic of multi-task, you can come to the concept of lifelong continuous learning, which can be most clearly shown on the example of robotics.  The robot must be able to solve different tasks, and use the previous experience when learning a new task.  But you can consider this approach on the example of Omniglot: having learned one of the symbols, you can proceed to learning the next one, using the experience gained.  True, on this path we face a dangerous problem of <a href="http://standoutpublishing.com/g/catastrophic-forgetting.html">catastrophic forgetting</a> , when the algorithm begins to forget what he learned before (to combat this, he recommends regularization of <a href="https://arxiv.org/pdf/1612.00796">EWC</a> ). <br><br>  In addition, the speaker spoke about several of his works in this direction. <br>  <a href="https://arxiv.org/abs/1807.01622">Neural Processes</a> (Gaussian process analogy for neural networks) and <a href="https://arxiv.org/pdf/1707.04175.pdf">Distil and Transfer Learning</a> (transfer learning optimization for the case when we do not take a previously trained model as a basis, but teach our own in multi-task mode). <br><br><img src="https://habrastorage.org/webt/aa/or/9x/aaor9xdtekpetkiyc0gi9wjedso.png"><br><br><h2>  Images And Texts </h2><br>  Today I decided to walk on the application reports, in the morning about working with texts, images and video. <br><br><h4>  Corpus Conversion Service </h4><br>  The frequency of publications is growing very quickly, it is difficult to work with this, especially considering that almost the entire search is conducted according to the text.  IBM <a href="https://arxiv.org/pdf/1805.09687.pdf">offers</a> its services for the marking of buildings Scientific knowledge 3.0.  The main workflow looks like this: <br><br><ul><li>  Parsim PDF, recognize the text in the pictures. </li><li>  We check if there is a model for the given form of the text, if there is - we make a semantic extract with its help. </li><li>  If there is no model, we send for annotation and train. </li></ul><br><img src="https://habrastorage.org/webt/pe/ss/o_/pesso_sigiskpc3in474wfi5-jg.png"><br><br>  To train models, we start with clustering by structure.  Within the cluster using crowdsourcing we mark several pages.  It turns out to achieve accuracy&gt; 98% when training on the markup of 200-300 documents.  There is a strong class imbalance in the markup (almost everything is marked up as text), so you need to look at the accuracy of all classes and the confusion matrix. <br><br>  Models have a hierarchical structure.  For example, one model recognizes a table, and another cuts into rows / columns / headers (and yes, a table can be nested in a table).  A convolutional network is used as a model. <br><br>  For all this, we assembled a pipeline on Docker with Kubernetes and are ready for a reasonable fee to load your body of texts.  They can work not only with text PDF, but also with scans, they support oriental languages.  In addition to simply pulling out the text, they are working on extracting the knowledge graph, promising to give details on the next KDD. <br><br><h4>  Rare Query Expansion Through Generative Adversarial Networks in Search Advertising </h4><br>  Search engines earn the most money from advertising, and advertising is shown depending on what the user was looking for.  But the comparison is not always obvious.  For example, at the request of airline tickets, displaying cheap bus tickets advertising is not very correct, but expedia will go well, but you cannot understand this by keywords.  Machine learning models can help, but they do not work well with rare queries. <br><br>  To solve this problem for expanding the search query, <a href="http://www.kdd.org/kdd2018/accepted-papers/view/rare-query-expansion-through-generative-adversarial-networks-in-search-adve">we will train the</a> Conditional GAN ‚Äã‚Äãon the sequence-to-sequence model.  We use recurrent networks (2-layer GRU) as architecture.  We modify the min-max from GAN, trying to aim it at adding keywords for which there were clicks on advertising. <br><br><img src="https://habrastorage.org/webt/4g/ig/2m/4gig2mrpnohiogkfd8pk6jmburm.png"><br><br>  Dataset for training on 14 million requests and 4 million advertising keywords.  The proposed model works best on the long tail of the query, for which it was done.  But in my head the performance is not higher. <br><br><h4>  Collaborative Deep Metric Learning for Video Understanding </h4><br>  <a href="http://www.joonseok.net/papers/cdml.pdf">The work is</a> presented by guys from Google AI.  They want to build good embeddings for video, so that they can be used in similar videos, recommendations, automatic annotations, etc.  Works as follows: <br><br><ul><li>  From the video, sample frames are a picture and a piece of audio track. </li><li>  From the images we extract features that Inception has previously learned. </li><li>  We do the same with the audio fragment (the specific network architecture was not shown).  On the received signs we hang fully connected grids with a frame pooling.  Normalized to L2. </li><li>  Next interesting point - we are trying to ensure that similar videos are close to the point of view of collaborative similarity.  To do this, we use triplet loss in training (we take an object, sample it similar and different, ensure that embeddings of the unlike are farther from the original than the similar).  Do not forget that you need to use negative mining. </li></ul><br><img src="https://habrastorage.org/webt/0x/jg/2c/0xjg2ctmcudwjoas0fuo_jkufbg.png"><br><br>  They are used for cold start in similar videos, but there are a couple of problems: by visual similarity, you can find video in another language or video on another topic (especially relevant for board and lecturer video).  It is advised to use additional meta-information about the video. <br><br>  There is a problem with recommendations: you need to match your browsing history and 5 billion videos from Youtube.  To speed up the work, we predict for the user the vector of average embedding of viewed videos.  Checked on <a href="https://grouplens.org/datasets/movielens/latest/">movielens</a> , <a href="https://grouplens.org/datasets/movielens/latest/">dragged</a> trailers from Youtube for analysis.  It was shown that for users with a small number of ratings it works better. <br><br>  In the task of annotating a video, the <a href="https://en.wikipedia.org/wiki/Mixture_of_experts">mixture of experts</a> approach is used: they teach logreg on embedding for each possible annotation.  Checked on <a href="https://research.google.com/youtube8m/">Youtube-8</a> and showed a very good result. <br><br><h4>  Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </h4><br>  <a href="https://www.aminer.cn/">AMiner</a> is a graph for the academy that provides various services for working with literature.  One of the problems is the collision of authors' names and entities.  For the solution <a href="http://keg.cs.tsinghua.edu.cn/jietang/publications/kdd18_yutao-AMiner-Name-Disambiguation.pdf">, an</a> automatic algorithm is <a href="http://keg.cs.tsinghua.edu.cn/jietang/publications/kdd18_yutao-AMiner-Name-Disambiguation.pdf">proposed</a> with some form of active additional training. <br><br>  The process consists of three stages: using text search, we collect candidates (documents with similar names of authors), cluster (with automatic determination of the number of clusters) and build profiles. <br><br><img src="https://habrastorage.org/webt/pt/zu/vz/ptzuvzseixdmvfh6pgoq6onvu8u.png"><br><br>  To consider the similarity in clustering, you need some kind of representation (emuding).  It can be obtained using the global model (across the whole graph) or local (for those candidates that were sampled).  Global catches patterns that can be transferred to new documents, and local helps to take into account individual features - we will combine.  For global embeddings, they also use a Siamese network trained in triplet loss, and for local ones, they use a graph autoencoder (they left pictures in the article for the sake of space). <br><br>  The most painful question is how many clusters to do?  The <a href="http://citeseerx.ist.psu.edu/viewdoc/summary%3Fdoi%3D10.1.1.19.3377">X-means</a> approach does not scale to a large number of clusters, RNN is used to predict their number: from the marked-up set, K clusters are first sampled, then N examples from these clusters.  Train the network to reveal the original number of clusters. <br><br><img src="https://habrastorage.org/webt/bo/72/rb/bo72rbvzsryebqez8fx1ssefmma.png"><br><br>  The data arrive fairly quickly, 500 thousand per month, but the sweep of the entire model takes weeks.  Used for quick initialization of the selection of candidates for text search and CNN for global embedding.  An important point: the process of learning includes people who mark what should and what should not get into the cluster.  The model is retrained on this data. <br><br><h4>  Rosetta: Large scale system </h4><br>  The guys from FB <a href="http://www.kdd.org/kdd2018/accepted-papers/view/rosetta-large-scale-system-for-text-detection-and-recognition-in-images">will present</a> their decision to extract texts from pictures.  The model works in two stages: the first network determines the text, the second recognizes it.  <a href="https://arxiv.org/pdf/1506.01497.pdf">Faster-RCNN was</a> used as a detector with the replacement of ResNet by <a href="https://arxiv.org/pdf/1707.01083.pdf">SuffleNet</a> to speed up the work.  ResNet18 was used for recognition and trained with <a href="http://citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.75.6306%26rep%3Drep1%26type%3Dpdf">CTC loss</a> . <br><br><img src="https://habrastorage.org/webt/c9/tr/vw/c9trvwaucyv6dzacvcb-jgamjt0.png"><br><br>  To improve the convergence used several tricks: <br><br><ul><li>  When training, a little noise was introduced into the detector result. </li><li>  Spread the text horizontally by 20%. </li><li>  Used curriculum learning - gradually complicate the examples (by the number of characters). </li></ul><br><h2>  Natural science </h2><br>  The last content section at the conference was devoted to the ‚Äúnatural sciences‚Äù.  A little chemistry, football and more. <br><br><h4>  False Discovery Rate Control </h4><br>  <a href="https://arxiv.org/pdf/1808.04904.pdf">Very interesting work</a> on the analysis of A / B tests.  The problem with most analysis systems is that they look at the average effect, whereas in reality, some users most often react positively to the change, and some negatively, and more can be achieved if you understand who has come in and who not. <br><br><img src="https://habrastorage.org/webt/hk/jc/7w/hkjc7wewtxjptgjho_i05mxkgvo.png"><br>  It is possible to divide users into cohorts in advance and evaluate the effect by them, but as the number of cohorts increases, the number of false positives increases (you can try to reduce them using the <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferoni</a> method, but it is too conservative).  In addition, you need to know the cohorts in advance.  The guys propose to use a combination of several approaches: to combine a mechanism for detecting a heterogeneous effect (HTE) with methods of filtering false positives. <br><br>  To detect a heterogeneous effect, a matrix is ‚Äã‚Äãtransformed with <code>x=0/1</code> <code>0/1</code> (in a group or not) and an effect into a matrix, in which instead of <code>0/1</code> lies the number <code>(x ‚Äî p)/p(1-p)</code> , where <code>p</code> is the probability of inclusion in test.  Next, the model predicts the effect of <code>x</code> (linear or lasso regression).  Those users for whom the result is significantly different from the forecast are candidates for selection in the "heterogeneous" effect. <br><br>  Next, for the false positives filter, we tried two methods: <a href="http://engr.case.edu/ray_soumya/mlrg/controlling_fdr_benjamini95.pdf">Benjamini-Hochberg</a> and <a href="https://arxiv.org/pdf/1404.5609.pdf">Knockoffs</a> .  The first is much easier to implement, but the second is more flexible and showed more interesting results. <br><br><h4>  Winner's Curse: Online Controlled Experiments </h4><br>  The guys from AirBnB talked a little about how they improved the system of analysis of experiments.  The main problem is that when experimenting a lot of bias, in this paper we considered selection bias - we select experiments with the best <b>observable</b> result, but this means that we will more often select experiments in which the observed result is overestimated relative to the real one. <br><br>  As a result, when combining experiments, the final effect is less than the sum of the effects of the experiments.  But knowing this bias, you can try to estimate and subtract it using a statistical apparatus (assuming that the difference between the real and observed effects is normally distributed).  In short, something like this: <br><br><img src="https://habrastorage.org/webt/1t/36/oo/1t36oopelx-pspivaz17nzgdxp0.png"><br><br>  And if you add a <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrap</a> , you can even build confidence intervals for an unbiased estimate of the effect. <br><br><h4>  Automatic Discovery of Tactics in Spatio-Temporal Soccer Match Data </h4><br>  <a href="https://people.cs.kuleuven.be/~jesse.davis/decroos-kdd18.pdf">Interesting work</a> on the disclosure of football teams tactics.  Match data is available in the form of sequences of actions (pass / touch / hit, etc.), about 2000 actions per match.  Combine continuous (coordinates / time) and discrete (player) attributes.  It is important to expand the data using knowledge of the subject area (add a player‚Äôs role and pass type, for example), but this does not always work.  In addition, different types of users are interested in different types of patterns: the coach is successful, the attacker is protective, the journalist is unique. <br><br>  The proposed method is as follows: <br><br><ul><li>  We divide the flow into phases according to the transition of the ball between the teams. </li><li>  We cluster the phases as a distance using <a href="https://en.wikipedia.org/wiki/Dynamic_time_warping">dynamic time warping</a> .  How to determine the number of clusters is not told. </li><li>  We rank the clusters according to the goal (for whom we are looking for tactics). </li><li>  Mine patterns inside the cluster (sequential pattern mining <a href="https://www.philippe-fournier-viger.com/spmf/CM-SPADE.php">CM-SPADE</a> ), disperse the coordinates on the field segments (left / right flank, middle, penalties). </li><li>  We rank the patterns again. </li></ul><br><h4>  Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for Transferable Chemical Property P </h4><br>  <a href="https://arxiv.org/pdf/1712.02734.pdf">Work</a> for situations where there is no big data, but there are theoretical models with hierarchical rules.  Using theory, we build an "expert" neural network.  Apply to the task of developing chemical compounds with desired properties. <br><br>  I would like by analogy with pictures to get a network in which the layers will correspond to different levels of abstraction: atoms / functional groups / fragments / molecules.  In the past, there were approaches for large tagged datasets, for example, SMILE2Vect: use <a href="https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system">SMILE</a> to translate a formula into text, and then apply embedding techniques for texts. <br><br>  But what to do if there is no big marked dataset?  We learn ChemNet with the help of <a href="https://www.rdkit.org/">RDKit</a> for the goals that it can predict, and then do transfer learning to solve the necessary problem.  We show that we can compete with models that are trained on labeled data.  You can learn in layers, and thus achieve the goal - to divide the layers into levels of abstraction. <br><br><img src="https://habrastorage.org/webt/47/io/er/47ioerzoquenjoepitoesybdtbg.png"><br><br><h4>  PrePeP - A Tool for the Identification of Pan Assay Interference Compounds </h4><br>  <a href="http://www.kdd.org/kdd2018/accepted-papers/view/prepep-a-tool-for-the-identification-and-characterization-of-pan-assay-inte">We develop drugs</a> , use data science to select candidates.  There are molecules that react with many substances.  They can not be used as drugs, but often float in the initial stages of the test.  Such <a href="https://en.wikipedia.org/wiki/Pan-assay_interference_compounds">PAINS</a> molecules will be filtered. <br><br>  There are difficulties: the data are sparse and arrogant (107 thousand), the classes are unbalanced (positives 0.5%), and chemists want to get an interpretable model.  Combining data from graph structure ( <a href="https://www.cs.ucsb.edu/~xyan/software/gSpan.htm">gSpan</a> ) molecules and chemical fingerprints.  They struggled with balance using baging with undersampling negatives, taught trees, forecasts aggregated by a majority vote. </div><p>Source: <a href="https://habr.com/ru/post/421041/">https://habr.com/ru/post/421041/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../421031/index.html">Random.org - a story length of 20 years</a></li>
<li><a href="../421033/index.html">Smart book - where the evolution of digital printing will lead</a></li>
<li><a href="../421035/index.html">New 3D stars of social networks, and why they can be dangerous for us</a></li>
<li><a href="../421037/index.html">What is an ‚Äúintuitive interface‚Äù in chatbots, virtual assistants, avatars and social robots?</a></li>
<li><a href="../421039/index.html">Monitor UPS workstations in Windows with Network UPS Tools</a></li>
<li><a href="../421043/index.html">Mitap about writing applications on Lua using the Corona engine</a></li>
<li><a href="../421047/index.html">Analogs in the "Nomenclature". Another way to save wisely. Part 1</a></li>
<li><a href="../421049/index.html">Designing application screens: from planning to design layout</a></li>
<li><a href="../421051/index.html">How I launched my first SaaS project by being employed all day</a></li>
<li><a href="../421055/index.html">Custom web development: how to scale on an ever-growing project</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>