<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Simple metasearch algorithm in Python</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lyrical digression 
 As part of the research work at the university, I was faced with the task of classifying textual information. In fact, I had to c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Simple metasearch algorithm in Python</h1><div class="post__text post__text-html js-mediator-article"><h4>  Lyrical digression </h4><br>  As part of the research work at the university, I was faced with the task of classifying textual information.  In fact, I had to create an algorithm that, processing a certain text document at the entrance, would return an array to me, each element of which would be a measure of the belonging of this text (probability or degree of confidence) to one of the specified topics. <br><br>  This article is not about solving the classification problem specifically, but about trying to automate the most boring stage in the development of a rubricator ‚Äî the creation of a training set. <br><br><h4>  When too lazy to work with your hands </h4><br>  The first and most obvious thought for me is to write a simple metasearch algorithm in Python.  In other words, all automation comes down to the use of issuing another search engine (Google Search) in the absence of its databases.  Immediately make a reservation, there are already ready libraries that solve a similar problem, for example pygoogle. <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Closer to the point </h4><br>  For HTTP requests, I used requests, and to extract links from the search results ‚Äî the library for parsing BeautifulSoup.  Here's what happened: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests query = input(<span class="hljs-string"><span class="hljs-string">'What are you searching for?: '</span></span> ) url =<span class="hljs-string"><span class="hljs-string">'http://www.google.com/search?q='</span></span> page = requests.get(url + query) soup = BeautifulSoup(page.text) h3 = soup.find_all(<span class="hljs-string"><span class="hljs-string">"h3"</span></span>,class_=<span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> elem <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> h3: elem=elem.contents[<span class="hljs-number"><span class="hljs-number">0</span></span>] link=(<span class="hljs-string"><span class="hljs-string">"https://www.google.com"</span></span> + elem[<span class="hljs-string"><span class="hljs-string">"href"</span></span>]) print(link)</code> </pre> <br>  I pulled only links to sites that are on the Chrome search results page inside tags {h3 class = "r"}. <br><br>  Well, great, now let's try to pick up links, bypassing several pages of the browser: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests query = input(<span class="hljs-string"><span class="hljs-string">'What are you searching for?: '</span></span> ) number = input(<span class="hljs-string"><span class="hljs-string">'How many pages: '</span></span> ) url =<span class="hljs-string"><span class="hljs-string">'http://www.google.com/search?q='</span></span> page = requests.get(url + query) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> index <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(int(number)): soup = BeautifulSoup(page.text) next_page=soup.find(<span class="hljs-string"><span class="hljs-string">"a"</span></span>,class_=<span class="hljs-string"><span class="hljs-string">"fl"</span></span>) next_link=(<span class="hljs-string"><span class="hljs-string">"https://www.google.com"</span></span>+next_page[<span class="hljs-string"><span class="hljs-string">"href"</span></span>]) h3 = soup.find_all(<span class="hljs-string"><span class="hljs-string">"h3"</span></span>,class_=<span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> elem <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> h3: elem=elem.contents[<span class="hljs-number"><span class="hljs-number">0</span></span>] link=(<span class="hljs-string"><span class="hljs-string">"https://www.google.com"</span></span> + elem[<span class="hljs-string"><span class="hljs-string">"href"</span></span>]) print(link) page = requests.get(next_link)</code> </pre><br>  The address of the next page Chrome stores in the tag {a class = "fl"}. <br><br>  And finally, we will try to get information from any page and make a dictionary of it for a future rubricator.  We will collect the necessary information from the same Wikipedia: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests dict=<span class="hljs-string"><span class="hljs-string">""</span></span> query = input(<span class="hljs-string"><span class="hljs-string">'What are you searching for?: '</span></span> ) url =<span class="hljs-string"><span class="hljs-string">'http://www.google.com/search?q='</span></span> page = requests.get(url + query) soup = BeautifulSoup(page.text) h3 = soup.find_all(<span class="hljs-string"><span class="hljs-string">"h3"</span></span>,class_=<span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> elem <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> h3: elem=elem.contents[<span class="hljs-number"><span class="hljs-number">0</span></span>] elem = elem[<span class="hljs-string"><span class="hljs-string">"href"</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">"wikipedia"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> elem: link=(<span class="hljs-string"><span class="hljs-string">"https://www.google.com"</span></span> + elem) <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> page = requests.get(link) soup = BeautifulSoup(page.text) text = soup.find(id=<span class="hljs-string"><span class="hljs-string">"mw-content-text"</span></span>) p= text.find(<span class="hljs-string"><span class="hljs-string">"p"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> p != <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: dict+=p.get_text()+<span class="hljs-string"><span class="hljs-string">"\n"</span></span> p = p.find_next(<span class="hljs-string"><span class="hljs-string">"p"</span></span>) dict=dict.split()</code> </pre><br>  For the query ‚Äúgod,‚Äù a good vocabulary of 3,500 terms is obtained, which, in truth, will have to be edited with a file, removing punctuation marks, links, stop words, and other garbage. <br><br><h4>  Conclusion </h4><br>  Summing up the work done, it should be noted that the vocabulary of course turned out to be ‚Äúraw‚Äù and ‚Äúdragging‚Äù the parser to a specific resource requires time to study its structure.  This suggests a simple idea - the generation of a training set should be carried out on its own, or use ready-made databases. <br><br>  On the other hand, with proper care to write the parser (clearing the html markup from unnecessary tags is not difficult) and a large number of classes, some degree of automation can add the necessary flexibility to the rubricator. <br><br><h4>  Links to tools used </h4><br>  BeautifulSoup: <a href="http://www.crummy.com/software/BeautifulSoup/">www.crummy.com/software/BeautifulSoup</a> <br>  Requests: <a href="http://docs.python-requests.org/en/latest/">docs.python-requests.org/en/latest</a> </div><p>Source: <a href="https://habr.com/ru/post/272711/">https://habr.com/ru/post/272711/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../272701/index.html">How to graze cats. The history of building a system of control and accounting of working time for an IT company</a></li>
<li><a href="../272703/index.html">The WikiLeaks Revolution: The Digest of Mishaps</a></li>
<li><a href="../272705/index.html">Record and video processing on Android</a></li>
<li><a href="../272707/index.html">Bit magic: getting the next lexicographic combination</a></li>
<li><a href="../272709/index.html">Site navigation - burping a bygone era</a></li>
<li><a href="../272713/index.html">Monte Carlo simulation in Mathcad Express</a></li>
<li><a href="../272715/index.html">Speak at CodeFest</a></li>
<li><a href="../272717/index.html">Samsung launched production of TSV DDR4 128 Gb memory modules for servers</a></li>
<li><a href="../272719/index.html">Seminar ‚ÄúBackup any objects based on CommVault Simpana‚Äù, December 10, OST data center (Moscow)</a></li>
<li><a href="../272721/index.html">Simple Blender. Part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>