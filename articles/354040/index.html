<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We apply the Deep Watershed Transform in the Kaggle Data Science Bowl 2018 competition.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We apply the Deep Watershed Transform in the Kaggle Data Science Bowl 2018 competition. 


 We present you the translation of the article by reference...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We apply the Deep Watershed Transform in the Kaggle Data Science Bowl 2018 competition.</h1><div class="post__text post__text-html js-mediator-article"><h1 id="primenyaem-deep-watershed-transform-v-sorevnovanii-kaggle-data-science-bowl-2018">  We apply the Deep Watershed Transform in the Kaggle Data Science Bowl 2018 competition. </h1><br><p>  We present you the translation of the article by <a href="https://spark-in.me/post/playing-with-dwt-and-ds-bowl-2018">reference</a> and the original dokerized <a href="https://github.com/snakers4/ds_bowl_2018">code</a> .  This solution allows you to get about the top 100 on a private leaderboard at the second stage of the competition among the total number of participants in the area of ‚Äã‚Äãseveral thousand, using only one model on one fold without ensembles and without additional post-processing.  Given the instability of the target metric in the competition, I believe that adding a few chips described below in principle can also greatly improve this result if you want to use this solution for your tasks. </p><br><p><img src="https://habrastorage.org/webt/1u/db/r_/1udbr_prwjycsz-8zg10a4mviji.png"><br>  <em>solution pipeline description</em> </p><a name="habracut"></a><br><h2 id="tldr">  Tldr </h2><br><p>  ( <strong>Translator‚Äôs note</strong> - some terms are left as they are, that is, I‚Äôm not at all sure that there are adequate analogues in Russian. If you know of those, write in a comment - we‚Äôll make some changes). </p><br><p>  Each year, Caggle launches the Data Science Bowl competition.  Last year <a href="https://www.kaggle.com/c/data-science-bowl-2017">it was</a> pretty cool: </p><br><ul><li>  New interesting topic in the form of 3D-images </li><li>  A worthy task is lung cancer; </li><li>  Big dataset - 50 + GB; </li><li>  Seductive prize; </li></ul><br><p>  Unfortunately, when last year the competition started, I was not yet ready to take part in it.  This year, after Google bought Kaggl, I began to notice some of the first "alarm bells" (a couple of "notes in the margins" - <a href="https://t.me/snakers4/1706">here</a> and <a href="https://t.me/snakers4/1888">there</a> ).  Briefly - before the machine learning competition seemed to me mutually beneficial for both the community and the organizers of the competition, but now I am seeing some strange trend for the worse - it feels like the competitions turn into data marking exercises and / or awards become unattractive regarding the amount of effort that must be applied to participate normally (sort out / get to the top or give prizes / pump over). </p><br><h3 id="pochemu-mne-ne-ponravilas-organizaciya-etogo-sorevnovaniya">  Why I didn‚Äôt like the organization of this competition: </h3><br><ul><li>  Small dataset (600 images for training and 65 for validation) at the first stage of the competition along with many times larger at the second stage of the competition (3000 pictures for the test only); </li><li>  The distribution of data in the second stage had nothing to do with the first (put a bold exclamation mark here); </li><li>  Kaggl is also notorious for not particularly suppressing cheating - in this particular competition, for example, it was possible to re-train the model after the release of data from the second stage; </li><li>  If you don't believe me - ask around for the community members who participated; </li><li>  (In order not to be unfounded, towards the end it will be described how to avoid such problems); </li><li>  Also, the target <a href="https://www.kaggle.com/c/data-science-bowl-2018">metric</a> - the average mAP at several levels of accuracy (from 0.5 to 0.95) - behaves very unstable.  Judging by the choice of such a metric, the organizers were clearly confident in the "ideality" of their markup, but in practice this was certainly not the case.  For example, if you take the markup, shift it 1 pixel to the side, then the speed drops from 1 to 0.6; </li></ul><br><p> At first, when I opened the data, I generally did not want to participate, because  their volume in megabytes did not inspire confidence at all.  But then I examined them more closely and realized that the task here was in <code>instance segmentation</code> , which was a novelty for me.  The task itself - <code>instance segmentation</code> is very interesting, despite the small size of the dataset.  It is expected that you will not only create an exact binary mask of cells, as well as divide adherent cells (sorry, maybe there are nuclei, not cells, but judging by the markup, the organizers themselves are not sure about this either).  On the other hand, the size of the dataset and the quality of the markup seemed a bit inadequate, especially considering the fact that the organizers of the competition, among other things, reported that some companies have similar datasets with <a href="https://www.kaggle.com/c/data-science-bowl-2018/discussion/52766">terabytes of data</a> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/1f3/390/070/1f3390070fca90575f0b4a0d246aee6f.png"><br>  <em>Basic computer vision tasks.</em>  <em>Here in the list, in theory, there should also be a classification of objects (the classic task is to find cats and dogs in the photo)</em> </p><br><p>  In this post, I will explain my approach to solving this problem.  I will also share my <a href="https://github.com/snakers4/ds_bowl_2018">pipeline</a> inspired article <a href="https://arxiv.org/abs/1611.08303">Deep Watershed Transform for Instance Segmentation</a> and tell you about other hikes and solutions, and also share my opinion on how such competitions should ideally be organized. </p><br><h2 id="eda-ili-pochemu-ml-eto-ne-magiya">  EDA or why ML is not magic </h2><br><p>  The training dataset contained about 600 images and the validation dataset - 65. The deferred test dataset from the second stage contained ~ 3000 images. <br>  The images from the first stage had different resolutions - which in itself was a challenge - how would you build a universal pipeline for all of them? </p><br><pre> <code class="hljs">256x256 358 256x320 112 520x696 96 360x360 91 512x640 21 1024x1024 16 260x347 9 512x680 8 603x1272 6 524x348 4 519x253 4 520x348 4 519x162 2 519x161 2 1040x1388 1 390x239 1</code> </pre> <br><p>  There were about three clusters among the training data that are easy to find with K-means: </p><br><ul><li>  Images with black background; </li><li>  Images with dye; </li><li>  Images with white background; </li></ul><br><p>  This was the main reason why converting RGB images to black and white helped on a public leaderboard. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c12/fdb/457/c12fdb4579e512a2fcb2471f1fbce8fc.png"><br>  <em>Black images</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/238/206/369/2382063691ac86d2cf0daa5a4d9357ed.png"><br>  <em>Different variations of cores in shape, color, size</em> </p><br><p>  Visual viewing of a test dataset with three thousand pictures showed that 50 +% of these pictures have nothing to do with the training dataset, which caused a lot of controversy and resentment from the community.  So you participate in the competition for "thank you", spend time, optimize the model, and bang and get 3000 pictures that do not look like training data?  It is clear that the goals may be different (including preventing manual marking on between the stages of the competition) - but this can be done much less clumsy. </p><br><h3 id="nekotorye-primechatelnye-fayly-iz-testovogo-dataseta">  Some noteworthy files from the test dataset: </h3><br><p><img src="https://habrastorage.org/getpro/habr/post_images/84b/d08/10c/84bd0810c68f31f229d57b66df0eb079.png"><br>  <em>I would suggest that the little thing in the background is the core</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/86b/faa/3be/86bfaa3beb47a98f6eb4017e4ce20b36.png"><br>  <em>Honestly no idea what's</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/447/952/de4/447952de44c28448a86b52661589c63d.png"><br>  <em>Looks like muscle.</em>  <em>Once again, are these white pieces cores or what?</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/fc5/1da/9bc/fc51da9bc3e65f34a82a03d5507f396f.png"><br>  <em>Night sky ... Is it a core or just noise?</em> </p><br><h3 id="deep-watershed-transform">  Deep watershed transform </h3><br><p>  If you do not know what it is, then go <a href="http://cmm.ensmp.fr/~beucher/wtshed.html">here</a> .  Intuitively, the watershed method is fairly simple - it turns your image into a negative "mountain landscape" (height = intensity of pixels / masks) and fills the pools of the markers of your choice with water until the pools connect.  You can find a bunch of tutorials with <code>OpenCV</code> or <code>skimage</code> , but all of them usually ask questions like this: </p><br><ul><li>  How should we choose labels where water will flow from? </li><li>  How should we define the boundaries of the watershed? </li><li>  How should we determine the height of the landscape? </li></ul><br><p>  <a href="https://arxiv.org/abs/1611.08303">Deep Watershed Transform</a> (DWT) will help us solve some of these problems. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3bf/f42/eff/3bff42effaa648635bcf4aa116e1bfe5.jpg"><br>  <em>The main motivation of the original work</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/654/d6b/e91/654d6be915e4751bd412f36332961cca.jpg"><br>  <em>The idea is for CNN to take into account two things - single vectors indicating the boundaries and energy level (height of the mountains)</em> </p><br><p>  In practice, if you simply apply a <code>WT</code> (Watershed Transform), you will most likely get a very parcel segmentation.  The intuition behind DWT is such - we must teach CNN to find the "mountain landscape" for us. </p><br><p>  The authors of the original article used 2 separate CNG VGG-type to obtain: </p><br><ul><li>  Energy (or landscape heights); </li><li>  Unit vectors directed to the boundaries of objects or from the boundaries, to then help CNN to learn the energy and boundaries of objects; </li></ul><br><p>  In practice, you can use one network or just train several smaller end-to-end <a href="https://www.kaggle.com/c/data-science-bowl-2018/discussion/55118">networks</a> .  In my case, I played with networks that gave out: </p><br><ul><li>  Binary cell mask; </li><li>  Several masks with different levels of erosion (1.5.7 pixels); </li><li>  The centers of the nuclei (not really helped in my case); </li><li>  Unit vectors (slightly helped, locally); </li><li>  Borders (slightly helped, locally); </li></ul><br><p>  Then you need a little magic to combine it all and voila, you have the "energy".  I didn‚Äôt experiment a lot with architecture, but Dmitro (the author of the solution above) then told me that he didn‚Äôt get better results when adding the second CNN. </p><br><p>  For me, the best <a href="https://github.com/snakers4/ds_bowl_2018/blob/master/src/utils/watershed.py">post processing</a> ( <code>energy_baseline</code> function by reference) was the following algorithm: </p><br><ul><li>  Summarize the predicted mask and the three levels of the predicted erosion masks; </li><li>  Apply a threshold of 0.4 to separate cell centers; </li><li>  We use the found centers as markers for the fill; </li><li>  We use the distance to the border of the masks as a measure of the "height of the landscape"; </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/0b1/ca1/71c/0b1ca171cc5c52aec7a165b3b7b55094.png"><br>  <em>One of the best examples - the net was able to clearly separate the stuck cores</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/5e3/937/a9a/5e3937a9a2a4b99ca52136917f7c2e4f.png"><br>  <em>The gradients learned are not suitable for use as a watershed.</em> </p><br><p>  Sometimes a direct search for nucleus centers also worked, but overall, this did not help improve speed. </p><br><h2 id="drugie-podhody">  Other approaches </h2><br><p>  Personally, I would divide the possible approaches of this task into 4 categories: </p><br><ul><li>  UNet-style approaches (UNet + pre-trained Resnet34, UNet + pre-trained VGG16, etc.) + Deep Watershed Transform post-processing.  <a href="https://arxiv.org/abs/1505.04597">UNet</a> (its cousin, <a href="https://codeac29.github.io/projects/linknet/">LinkNet</a> ) is known as universal and simple tools when it is necessary to solve semantic segmentation problems; </li><li>  Recurrent architectures.  I found only <a href="https://arxiv.org/abs/1712.00617">this</a> less relevant work (even with the availability of ready <a href="https://imatge-upc.github.io/rsis/">code</a> on PyTorch, I did not have time to try it); </li><li>  Proposal based model type <a href="http://arxiv.org/abs/1703.06870">Mask-RCNN</a> .  Although they are quite difficult to use (and there is no suitable implementation on PyTorch), it was reported that the approach initially yields better results, but with almost no options, then they will be improved; </li><li>  Others are a little "adventurous" (read - the author himself writes that they do not seem to work very well) the approaches described <a href="https://medium.com/%40barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1">here</a> ; </li></ul><br><p>  For me, in favor of choosing DWT + UNet, this is a solution, where you don‚Äôt have to bother too much, because it is simple (you can simply feed layers of energy as additional channels for the mask) and then easily shift the work to other tasks.  I also really like the recurrent extension UNet, but I didn‚Äôt have enough time to try it. </p><br><p>  In the case of recurrent UNet, there are three new components in essence compared to regular UNet: </p><br><ul><li>  ConvLSTM layer; </li><li>  A loss function component that penalizes CNN for learning too many cores; </li><li>  Using the <a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B5%25D0%25BD%25D0%25B3%25D0%25B5%25D1%2580%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B0%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC">Hungarian algorithm for</a> optimally combining predicted objects with markup; </li></ul><br><p>  It all seems stunning at first, but I will definitely try it in the future.  Although, this method combines two memory-hungry architectures ‚Äî the RNN and the encoder-decoder network ‚Äî which may not be practical in actual use outside of small datasets and permissions. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a31/d63/729/a31d637298a246a8acc5e395eb3b6434.jpg"><br>  <em>ConvLSTM Layer Description</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9c5/e10/960/9c5e1096013923c832d56b1dc24ff5bd.jpg"><br>  <em>Recurrent Unet Architecture</em> </p><br><h2 id="moy-payplayn">  My pipeline </h2><br><p>  You can find the details <a href="https://github.com/snakers4/ds_bowl_2018/">here</a> , but my approach is as follows: </p><br><ul><li>  Unet with VGG16 encoder (there are many different encoders in the repository); </li><li>  Deep Watershed; </li><li>  Many small hacks, including converting to black and white pictures and <code>transfer learning</code> ; </li><li>  Training the model on 256x256 random crocs; </li><li>  Prediction on resize images (for image sizes to be shared by 64) ( <strong>this may be a bad choice</strong> ); </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/5ed/317/5cd/5ed3175cdfb989b530bb91d5d7b84ef7.png"><br>  <em>Whole pipeline</em> </p><br><p>  If you want to greatly improve the result of this pipeline, then you need to replace the <code>VGG-16</code> encoder with <code>Resnet152</code> - according to the participants of the competition, this encoder behaved much more stable on delayed validation.  Also replacing <code>softmax</code> with <code>sigmoid</code> as the last activation function gives less blurred borders. </p><br><h2 id="a-teper-pro-to-kak-nado-po-idee-takie-sorevnovaniya-organizovyvat">  And now about how, in theory, such competitions should be organized </h2><br><p>  In short, <a href="https://habrahabr.ru/post/349068/">SpaceNet</a> from this point of view was almost perfect if you discount the annoying moments of the TopCoder platform: </p><br><ul><li>  Large dataset with a balanced training sample and test sample; </li><li>  Clear restrictions on external data; </li><li>  Decrease and freeze the code for verification by the organizers </li><li>  No additional training of models between the first and second stage; </li><li>  Reproducible results; </li></ul><br><h2 id="blagodarnosti">  Thanks </h2><br><p>  As always, many thanks to <a href="https://www.kaggle.com/dmytropoplavskiy">Dmytro</a> for fruitful conversations and tips! </p><br><h2 id="ssylki">  References: </h2><br><ul><li>  <a href="https://www.kaggle.com/c/data-science-bowl-2018">Kaggle Competition Page</a> </li><li>  <a href="https://github.com/snakers4/ds_bowl_2018">Github decision code</a> </li><li>  <a href="https://arxiv.org/abs/1611.08303">Deep Watershed Transform for Instance Segmentation</a> </li><li>  <a href="http://cmm.ensmp.fr/~beucher/wtshed.html">IMAGE SEGMENTATION AND MATHEMATICAL MORPHOLOGY</a> </li><li>  <a href="https://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a> </li><li>  <a href="https://codeac29.github.io/projects/linknet/">Feature Forwarding: Exploiting Encoder Representations for Efficient Semantic Segmentation</a> </li><li>  <a href="https://arxiv.org/abs/1712.00617">From Pixels to Object Sequences: Recurrent Semantic Instance Segmentation</a> and <a href="https://imatge-upc.github.io/rsis/">Project Page</a> </li><li>  <a href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> </li><li>  <a href="https://medium.com/%40barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1">Instance Embedding: Segmentation Without Proposals</a> </li><li>  <a href="https://arxiv.org/abs/1511.08250">Recurrent Instance Segmentation (onvLSTM)</a> </li><li>  <a href="https://github.com/ternaus/TernausNet">TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation</a> </li><li>  <a href="https://www.kaggle.com/c/data-science-bowl-2018/discussion/54426">Nuclei mosaic</a> </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/354040/">https://habr.com/ru/post/354040/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../354030/index.html">Mobile application in Python with kivy / buildozer. Lecture in Yandex</a></li>
<li><a href="../354032/index.html">Fuzzy search in relational databases</a></li>
<li><a href="../354034/index.html">Reindexer site search is easy. Or how to make an "instant search" throughout the Habrahabr</a></li>
<li><a href="../354036/index.html">20 Eloquent ORM tricks</a></li>
<li><a href="../354038/index.html">Top VSCode Extensions That Speed ‚Äã‚ÄãUp Your JavaScript Development</a></li>
<li><a href="../354044/index.html">Next generation video: introducing AV1</a></li>
<li><a href="../354046/index.html">Inheritance, composition, aggregation</a></li>
<li><a href="../354048/index.html">Atlassian Jira Software functionality in Jira plugin</a></li>
<li><a href="../354050/index.html">Designing a Schemaless Uber Engineering data warehouse using MySQL</a></li>
<li><a href="../354052/index.html">Configuring Let's Encrypt wildcard certificates on CentOS 7 with validation via CloudFlare API</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>