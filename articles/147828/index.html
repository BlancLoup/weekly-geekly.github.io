<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Restore defocused and blurred images. Practice</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Not so long ago, I published on Habr√© the first part of an article on the recovery of defocused and blurred images , where the theoretical part was de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Restore defocused and blurred images. Practice</h1><div class="post__text post__text-html js-mediator-article">  Not so long ago, I published on Habr√© the <a href="http://habrahabr.ru/post/136853/">first part of an article on the recovery of defocused and blurred images</a> , where the theoretical part was described.  Judging by the comments, this topic caused a lot of interest and I decided to continue this direction and show you what problems appear in the practical implementation of seemingly simple formulas. <br><br>  In addition to this, I wrote a demo program that implements the basic algorithms for eliminating defocus and blurring.  The program is laid out on GitHub along with the sources and distributions. <br><br>  Below is the result of processing a real blurred image (not with synthetic blur).  The original image was taken by a Canon 500D camera with an EF 85mm / 1.8 lens.  Focus was set manually to get a blur.  As you can see, the text is completely unreadable, only the Windows 7 dialog box is guessed. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/3ca/5ce/da0/3ca5ceda07d41d58574075ddea1a73ad.jpg"><br><br>  And here is the result of processing: <br><br><img src="https://habrastorage.org/storage2/4f0/7dd/2f2/4f07dd2f275dab113d7230f14e8acda0.jpg"><br><br>  Almost the entire text reads quite well, although some characteristic distortions appeared. <br><br>  Under the cat a detailed description of the problems of deconvolution, ways to solve them, as well as many examples and comparisons.  Careful, a lot of pictures! <br><a name="habracut"></a><br><h2>  Recall the theory </h2><br>  A detailed description of the theory was in the first part, but I will remind you briefly of the main points.  In the process of distortion, some spot is obtained from each pixel of the original image in the case of defocusing and a segment for the case of ordinary blurring.  All this is superimposed on each other and as a result we get a distorted image - this is called image convolution or convolution.  That, according to what law one pixel is smeared and called the distortion function.  Other synonyms are PSF (Point spread function, i.e. point distribution function), the core of the distorting operator, kernel, and others. <br><br>  To restore the original image, we need to somehow reverse the convolution, while not forgetting the noise.  But it is not so easy - if you act, as they say, ‚Äúhead on,‚Äù you will get a huge system of equations that cannot be solved in a reasonable time. <br><br>  But to our aid comes the Fourier transform and the convolution theorem, which states that the convolution operation in the spatial domain is equivalent to the usual multiplication in the frequency domain (and the multiplication is element-wise, not matrix).  Accordingly, the inverse convolution operation is equivalent to division in the frequency domain.  Therefore, the distortion process can be rewritten as follows: <br><br><img src="https://habrastorage.org/storage2/a67/78d/f30/a6778df306742b54222c62b97a73ba83.png" alt="image">  (one), <br>  where all elements are Fourier images of the corresponding functions: <br>  G (u, v) is the result of the distortion, i.e.  what we see as a result (blurred or defocused image) <br>  H (u, v) is a distorting function, PSF <br>  F (u, v) - the original undistorted image <br>  N (u, v) - additive noise <br><br>  So, we need to restore the maximum approximation to the original image F (u, v).  Simply dividing the right and left parts of H (u, v) does not work, because  if there is even a very small noise (and it is always on real images), the term N (u, v) / H (u, v) will dominate, which will lead to the fact that the original image will be completely hidden under the noise. <br><br>  To solve this problem, more robust methods were developed, one of which is the Wiener filter.  He considers the image and noise as random processes and finds such an estimate f ‚Ä≤ for the undistorted image f, so that the standard deviation of these values ‚Äã‚Äãis minimal: <br><br><img src="https://habrastorage.org/storage2/168/e0e/8d2/168e0e8d2e2755fd412bf5af8e51051a.png" alt="image">  (2) <br><br>  The function S here denotes the energy spectra of the noise and the original image, respectively - since these quantities are rarely known, the fraction S <sub>n</sub> / S <sub>f is</sub> replaced by some constant K, which can be approximately characterized as a signal-to-noise ratio. <br><br><h2>  Ways to get PSF </h2><br>  So, let's take the Wiener filter described as a starting point - in general, there are many other approaches, but they all give roughly the same results.  So everything described below will be valid for the rest of the deconvolution methods. <br><br>  The main task is to obtain an estimate of the point distribution function (PSF).  This can be done in several ways: <br>  <b>1. Modeling.</b>  It is very difficult and time consuming, because  modern lenses consist of a dozen, different different lenses and optical elements, some of which have an aspherical shape, each type of glass has its own unique characteristics of the refraction of rays with a particular wavelength.  As a result, the task of correctly calculating the propagation of light in such a complex optical system, taking into account the influence of the diaphragm, the reflections, etc.  becomes almost impossible.  And its solution, perhaps, is available only to developers of modern lenses. <br>  <b>2. Direct observation.</b>  Recall that PSF is what each point in the image turns into.  Those.  if we form a black background and a single white dot on it, and then take a photo of it with the desired defocus value, we will get the PSF view directly.  It seems simple, but there are many nuances and subtleties. <br>  <b>3. Calculation or indirect observation.</b>  Let us look at the formula (1) of the distortion process and think about how to get H (u, v)?  The solution comes right away - you need to have the original F (u, v) and distorted image G (u, v).  Then by dividing the Fourier transform of the distorted image into the Fourier transform of the original image, we get the required PSF. <br><br><h2>  About bokeh </h2><br>  Before we get into the details, I‚Äôll tell you a little bit of the theory of defocus as applied to optics.  The ideal lens has a PSF in the form of a circle, respectively, each point turns into a circle of a certain diameter.  By the way, this is a surprise for many people.  at first glance it seems that the defocus just blends the whole image.  The same explains why the Photoshop Blur of Gauss is not at all like the background image (also called bokeh) that we see in lenses.  In fact, these are two different types of blurring - according to Gauss, each point turns into a fuzzy spot (Gauss bell), and defocus turns every point into a circle.  Accordingly, different results. <br><br>  But we don‚Äôt have ideal lenses and in reality we get this or that deviation from the ideal circle.  This is what forms the unique bokeh pattern of each lens, forcing photographers to spend a lot of money on lenses with beautiful bokeh :) Bokeh can be divided into three types: <br>  - Neutral.  This is the maximum approximation to the circle. <br>  - soft.  When edges are less bright than center <br>  - Hard.  When the edges have greater brightness than the center. <br><br>  The figure below illustrates this: <br><br><img src="https://habrastorage.org/storage2/fd3/6e3/8f0/fd36e38f0cd10307364c59366731b9c9.png"><br><br>  Moreover, the type of bokeh - soft or hard depends also on whether it is focus or back focus.  Those.  the camera is focused in front of or behind the object.  For example, if the lens has a soft bokeh pattern in the front focus (when, say, the focus is on the face, and the background is blurred), then in the back focus the bokeh of the same lens will be hard.  And vice versa.  Only neutral bokeh does not change the type of focus. <br><br>  But this is not all yet - since some geometrical distortions are inherent in each lens, the PSF view also depends on the position.  In the center - close to the circle, on the edges - ellipses and other oblate figures.  This is clearly seen in the following photo - note the lower right corner: <br><br><img src="https://habrastorage.org/storage2/ebe/cbf/cc9/ebecbfcc99de17b67e55020b496eca39.jpg"><br><br>  And now let's take a closer look at the last two methods for obtaining PSF. <br><br><h2>  PSF - Direct observation </h2><br>  As mentioned above, it is necessary to form a black background and a white dot.  But simply printing a single point on the printer is not enough.  A much greater difference is needed in the brightness of the black background and the white point, since  one point will be blurred in a large circle - respectively, must have greater brightness in order to be visible after blurring. <br><br>  To do this, I printed Malevich‚Äôs black square (yes, the toner went away a lot, but what can't you do for the sake of science!), Put a foil on the other side, because  a sheet of paper still shines through well and pierced a small hole with a needle.  Then he built a simple design of a 200-watt lamp and a sandwich of black sheet and foil.  It looked like this: <br><br><img src="https://habrastorage.org/storage2/a3c/576/7c2/a3c5767c23b32a7a7ff76b4851edd41b.jpg"><br><br>  Then he turned on the lamp, covered it with a sheet, turned off the general light, and took some photos using two lenses - the whale Canon EF 18-55 and the portrait Canon EF 85mm / 1.8.  From the resulting photos, I cut out the PSF and then plotted the profiles. <br>  Here's what happened for the whale lens: <br><br><img src="https://habrastorage.org/storage2/f23/f18/b81/f23f18b81c0b797098d55e2f2e3f1462.png"><br><br>  And for the portrait Canon EF 85mm / 1.8: <br><br><img src="https://habrastorage.org/storage2/966/7c9/8a1/9667c98a1fe90384feb53c53aaee28f0.png"><br><br>  It is clearly seen how the nature of the bokeh changes from soft to soft for the same lens in the case of front and back focus.  You can also see what a difficult form PSF has - it is very far from a perfect circle.  For the portrait painter, large <a href="http://ru.wikipedia.org/wiki/%25D0%25A5%25D1%2580%25D0%25BE%25D0%25BC%25D0%25B0%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25B0%25D0%25B1%25D0%25B5%25D1%2580%25D1%2580%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F">chromatic aberrations</a> are also visible due to the large aperture of the lens and the small aperture 1.8. <br><br>  And here is another pair of shots with aperture 14 - it shows how the shape has changed from a circle to a regular hexagon: <br><br><img src="https://habrastorage.org/storage2/d70/ee6/d46/d70ee6d46517ea3e7438f398441dcdd5.png"><br><br><h2>  PSF - Computation or Indirect Observation </h2><br>  The next approach is indirect observation.  To do this, as stated above, we need to have the original F (u, v) and the distorted G (u, v) image.  How to get them?  Very simple - you need to put the camera on a tripod and make one sharp and one blurry shot of the same image.  Further, by dividing the Fourier transform of the distorted image into the Fourier transform of the original image, we obtain the Fourier transform of our target PSF.  Then, applying the inverse Fourier transform, we obtain the PSF in the direct form. <br>  I took two pictures: <br><br><img src="https://habrastorage.org/storage2/b91/670/7ac/b916707acc1e666cbf76111da1b6f645.jpg"><br><br><img src="https://habrastorage.org/storage2/822/03f/736/82203f736ada1ae6bbca3a9ab9b4a8f8.jpg"><br><br>  And as a result I received just such a PSF: <br><br><img src="https://habrastorage.org/storage2/e55/36b/755/e5536b7558a7a7f2652d4b45573dd404.png"><br><br>  Do not pay attention to the horizontal line, this is an artifact after the Fourier transform in the matlab.  The result is, let's say, mediocre - a lot of noise and the details of the PSF are not so visible.  However, the method has the right to exist. <br><br>  The described methods can and should be used to build a PSF when restoring blurry images.  Because  the quality of restoration of the original image directly depends on how close this function is to the real one.  If the assumed and real PSFs do not match, numerous artifacts will be observed in the form of ‚Äúringing‚Äù, halos and a decrease in clarity.  In most cases, the shape of a PSF is assumed to be a circle, however, to achieve the maximum degree of recovery, it is recommended to play around with the shape of this function by trying several options from common lenses - as we have seen, the shape of the PSF can vary greatly depending on the aperture, lens and other conditions. <br><br><h2>  Edge effects </h2><br>  The next problem is that if we directly apply the Wiener filter, then at the edges of the image there will be a kind of ‚Äúringing‚Äù.  Its reason, if explained on the fingers, is as follows: when deconvolution is done for those points that are located at the edges, then the assembly lacks the pixels that are beyond the edges of the image and they are taken either equal to zero or are taken from the opposite side (depends from the implementation of the Wiener filter and the Fourier transform).  It looks like this: <br><br><img src="https://habrastorage.org/storage2/5fa/27c/c7a/5fa27cc7a5fe2ac7b031a96fe2464aee.jpg"><br><br>  One solution to avoid this is to pre-process the edges of the image.  They are blurred with the same PSF.  In practice, this is implemented as follows: the input image F (x, y) is taken, blurred with PSF and F '(x, y) is obtained, then the final input image F' '(x, y) is formed by summing F (x, y ) and F '(x, y) using the weight function, which at the edges takes the value 1 (the point is taken entirely from the blurred F' (x, y)), and at a distance equal to or greater than the radius PSF from the edge of the image takes the value 0. The result is this - the ringing at the edges disappeared: <br><br><img src="https://habrastorage.org/storage2/98d/599/5cc/98d5995cca1c0287df5d88ff13e331d6.jpg"><br><br><h2>  Practical implementation </h2><br>  I made a program that demonstrates the recovery of blurred and defocused images.  It is written in C ++ using Qt.  As the implementation of the Fourier transform, I chose the <a href="http://fftw.org/">FFTW</a> library as the fastest of open-source implementations.  My program is called SmartDeblur, you can download it at <a href="https://github.com/Y-Vladimir/SmartDeblur">github.com/Y-Vladimir/SmartDeblur</a> , all sources are open under the GPL v3 license. <br>  Screenshot of the main window: <br><br><img src="https://habrastorage.org/storage2/e89/018/5e6/e890185e602c43db9ffd95a49a8408b7.png"><br><br>  Main functions: <br>  - High speed.  Processing an image of 2048 * 1500 pixels in size takes about 300ms in the Preview mode (when the settings sliders are moved) and 1.5 seconds in the fine mode (when the settings sliders are released). <br>  - Selection of parameters in Real-time mode.  There is no need to press the Preview buttons, everything is done automatically, you just need to move the sliders of the distortion settings <br>  - All processing goes for the image in full resolution.  Those.  There is no small preview window and Apply buttons. <br>  - Supports recovery of blurred and defocused images <br>  - Ability to adjust the type of PSF <br><br>  The main emphasis in the development was on speed.  As a result, it turned out to be such that it exceeds commercial counterparts dozens of times.  All processing is done in an adult, in a separate thread.  For 300 ms, the program manages to generate a new PSF, make 3 Fourier transforms, make a Winer deconvolution, and display the result - all of this for an image of 2048 * 1500 pixels.  In the finishing mode, 12 Fourier transforms are made (3 for each channel, plus one for each channel to suppress edge effects) - this takes about 1.5 seconds.  All times are for a Core i7 processor. <br><br>  While the program has a number of bugs and features - for example, with some settings, the image is covered in ripples.  It was not possible to find out the exact reason, but presumably the features of the FFTW library. <br><br>  Well, in general, the development process had to circumvent many hidden problems as in FFTW (for example, images with an odd size of one of the sides, such as 423 * 440.) Are not supported.  There were problems with Qt - it turned out that rendering the line with Antialiasing turned on does not work exactly.  At some angles, the line jumped to fractions of a pixel, which produced artifacts in the form of strong ripples.  To work around this problem, add the lines: <br><br><pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// Workarround to have high accuracy, otherwise drawLine method has some micro-mistakes in the rendering QPen pen = kernelPainter.pen(); pen.setWidthF(1.01); kernelPainter.setPen(pen);</span></span></code> </pre> <br><br><h2>  Comparison </h2><br>  It remains to compare the quality of processing with commercial counterparts. <br>  I chose the 2 most famous programs. <br>  1. Topaz InFocus - <a href="http://www.topazlabs.com/infocus/">www.topazlabs.com/infocus</a> <br>  2. Focus Magic - <a href="http://www.focusmagic.com/">www.focusmagic.com</a> <br><br>  For the purity of the experiment, we will take those advertising images that are shown on the official websites - it is so guaranteed that the parameters of those programs are chosen optimal (because I think the developers carefully selected the images and selected the parameters before publishing them on the website). <br>  So, let's go - restoration of lubrication: <br>  Take a cue from Topaz InFocus: <br><br>  <a href="">www.topazlabs.com/infocus/_images/licenseplate_compare.jpg</a> <br><img src="https://habrastorage.org/storage2/507/78b/66d/50778b66dbdc2a976de4ac9cf42672a9.png"><br><br>  We process with such parameters: <br><br><img src="https://habrastorage.org/storage2/89c/5a2/e20/89c5a2e20f322359299f349c4bc36a19.png"><br>  and we get the following result: <br><img src="https://habrastorage.org/storage2/50d/a2f/2b2/50da2f2b2d223899120aebec6a3b9a45.png"><br><br>  Result from Topaz InFocus: <br><br><img src="https://habrastorage.org/storage2/22b/3c6/b7a/22b3c6b7a088a59931cab3037d15aea7.png"><br><br>  The result is very similar, it says that the basis of Topaz InFocus uses a similar deconvolution algorithm, plus post-processing in the form of smoothing, removing noise and underlining contours. <br><br>  Examples of strongly defocusing on the site of this program could not be found, and it is not intended for this (the maximum blur radius is only a few pixels). <br>  It is possible to note one more thing - the tilt angle turned out to be exactly 45 degrees, and the length of the blurring is 10 pixels.  This suggests that the image is artificially blurred.  This fact is also in favor of the fact that the quality of the recovery is very good. <br><br>  Example number two is defocus recovery.  To do this, take an example from the site of Focus Magic: <a href="http://www.focusmagic.com/focusing-examples.htm">www.focusmagic.com/focusing-examples.htm</a> <br><br><img src="https://habrastorage.org/storage2/f2d/346/b9a/f2d346b9a7f3abc70c91f4fb924a1da8.jpg"><br><br>  We got the following result: <br><br><table><tbody><tr><td><img src="https://habrastorage.org/storage2/bac/62d/541/bac62d5416c60da07563560ca1c86172.png"></td><td><img src="https://habrastorage.org/storage2/d4f/43e/004/d4f43e00464a5627c4e0c3dd561596bf.jpg"></td></tr><tr><td>  SmartDeblur Result </td><td>  Focus Magic Result </td></tr></tbody></table><br>  There is no longer so obvious that better. <br><br><h2>  Conclusion </h2><br>  At this point I would like to finish this article.  Although I still wanted to write a lot of other things, I already had a long text.  I would be very grateful if you try to download SmartDeblur and test it on real images - unfortunately, I don‚Äôt have so many defocused and blurred images, I‚Äôve deleted everything. <br>  And I would be especially grateful if you send me (there is soap in the profile) your feedback and examples of successful / unsuccessful restorations.  Well, please report all bugs, comments, suggestions - because  The app is still damp and a bit unstable in some places. <br>  PS The source is not very clean in terms of style - there is still a lot of memory leaks, it has not yet been transferred to smart pointers, so after a few images it can stop opening files.  But in general it works. <br><br>  Link to SmartDeblur: <a href="https://github.com/Y-Vladimir/SmartDeblur">github.com/Y-Vladimir/SmartDeblur</a> <br><br>  <b>UPD:</b> <a href="http://habrahabr.ru/post/152885/">Continuation</a> Link <br><br> <code>--</code> <br>  Vladimir Yuzhikov </div><p>Source: <a href="https://habr.com/ru/post/147828/">https://habr.com/ru/post/147828/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../147822/index.html">Nexus 7: Unboxing</a></li>
<li><a href="../147824/index.html">Create extensions for Google Chrome</a></li>
<li><a href="../147825/index.html">Valve continues to hire Linux developers</a></li>
<li><a href="../147826/index.html">Are you ready to run through the desert to a better life?</a></li>
<li><a href="../147827/index.html">Data attraction formula</a></li>
<li><a href="../147829/index.html">Picture Factory - how does it work? Part 1</a></li>
<li><a href="../147831/index.html">Vim</a></li>
<li><a href="../147832/index.html">The Mango project is nearing completion.</a></li>
<li><a href="../147834/index.html">God object. Analysis of complex projects</a></li>
<li><a href="../147836/index.html">Nokia DC-16 - backup charger</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>