<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The logic of thinking. Part 3. Perceptron, convolutional networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the first part, we described the properties of neurons. In the second talked about the basic properties associated with their training. Already in ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The logic of thinking. Part 3. Perceptron, convolutional networks</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/36b/e1b/adf/36be1badfb3fb4168c9d4a988d48f65a.png"><br><br>  In the <a href="http://habrahabr.ru/post/214109/">first part,</a> we described the properties of neurons.  <a href="http://habrahabr.ru/post/214241/">In the second</a> talked about the basic properties associated with their training.  Already in the next part we will proceed to the description of how the real brain works.  But before that we need to make the last effort and take a little more theory.  Now it most likely will seem not especially interesting.  Perhaps I myself would have zaminusoval such an educational post.  But all this ‚Äúalphabet‚Äù will greatly help us to understand further. <br><br><h2>  Perceptron </h2><br>  In machine learning there are two main approaches: learning with a teacher and learning without a teacher.  The previously described methods for isolating the main components are learning without a teacher.  The neural network does not receive any explanation for what is given to it at the entrance.  It simply highlights the statistical patterns that are present in the input data stream.  In contrast, learning with a teacher assumes that for a portion of the input images, called the training set, we know what output we want to get.  Accordingly, the task is to configure the neural network in such a way as to capture the patterns that link the input and output data. <br><a name="habracut"></a><br>  In 1958, Frank Rosenblatt described a design called by him a perceptron (Rosenblatt, 1958), which is capable of learning from a teacher (see KDPV). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      According to Rosenblatt, a perceptron consists of three layers of neurons.  The first layer is the sensory elements that define what we have at the entrance.  The second layer is associative elements.  Their connections to the sensory layer are rigidly defined and define the transition to a more general description than on the sensory layer. <br><br>  Perceptron training is carried out by changing the weights of the neurons of the third reacting layer.  The purpose of training is to force the perceptron to properly classify the submitted images. <br><br>  The neurons of the third layer work as threshold adders.  Accordingly, the weights of each of them determine the parameters of a certain hyperplane.  If there are linearly separable input signals, then the output neurons can act as their classifiers. <br><br>  If a <img src="https://habrastorage.org/getpro/habr/post_images/8b3/33e/5c7/8b333e5c7761510e7c4d9fdc77f461e9.gif">  Is the vector of the real output of perceptron a, <img src="https://habrastorage.org/getpro/habr/post_images/3cc/d8b/acc/3ccd8baccb670262b168e34027625cb5.gif">  - the vector that we expect to receive, then the error vector says about the quality of the neural network operation: <br><img src="https://habrastorage.org/getpro/habr/post_images/095/edd/fcf/095eddfcf9b152315f0048af779d16bb.gif"><br><br>  If we aim at minimizing the root-mean-square error, then we can derive the so-called delta rule for weighting modification: <br><img src="https://habrastorage.org/getpro/geektimes/post_images/bd2/42f/9fa/bd242f9faa84faacf7bbe6f20352cdf2.gif"><br><br>  In this case, the initial approximation can be zero weights. <br>  This rule is nothing more than the Hebbian rule applied to the perceptron case. <br>  If we place one or more reactive layers behind the output layer and abandon the associative layer, which was introduced by Rosenblatt more for biological certainty than because of computational necessity, then we will get a multilayer perceptron the same as shown in the figure below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed5/427/6bb/ed54276bb247441a8db98a629c2afe61.png"><br>  <i>Multilayer perceptron with two hidden layers (Heikin, 2006)</i> <br><br>  If the neurons of the reacting layers were simple linear adders, then there would be little point in such complication.  The output, regardless of the number of hidden layers, would still remain a linear combination of input signals.  But since threshold adders are used in hidden layers, each such new layer breaks the chain of linearity and can carry its interesting description. <br><br>  For a long time it was not clear how a multilayer perceptron can be trained.  The main method - the method of back propagation of error was described only in 1974. .I.  Galushkin both independently and simultaneously by Paul J. Verbos.  It was then rediscovered and widely known in 1986 (David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams, 1986). <br><br>  The method consists of two passes: direct and reverse.  With a direct pass, a training signal is given and the activity of all network nodes, including the activity of the output layer, is calculated.  By subtracting the resulting activity from what was required to receive, an error signal is determined.  During the back pass, the error signal propagates in the opposite direction, from the output to the input.  At the same time, synaptic weights are adjusted in order to minimize this error.  A detailed description of the method can be found in a variety of sources (for example, Heikin, 2006). <br><br>  It is important for us to pay attention to the fact that in a multilayer perceptron information is processed from level to level.  In addition, each layer identifies its own set of features characteristic of the input signal.  This creates certain analogies with how information is transformed between the areas of the cerebral cortex. <br><br><h2>  Convolution networks.  Neocognitron </h2><br>  Comparison of multilayer perceptron and real brain is very arbitrary.  The general is that, ascending from zone to zone in the cortex or from layer to layer in a perceptron, the information acquires an increasingly generalized description.  However, the structure of the site of the cortex is much more complicated than the organization of the layer of neurons in the perceptron.  Studies of the visual system of D. Hubel and T. Wiesel allowed a better understanding of the structure of the visual cortex and prompted the use of this knowledge in neural networks.  The main ideas that have been used are the localization of the zones of perception and the division of neurons by functions within one layer. <br><br>  The locality of perception is already familiar to us, it means that the neuron receiving the information does not follow the entire input space of signals, but only its part.  Earlier we said that this tracking area is called the receptive field of a neuron. <br><br>  The concept of a receptive field requires separate clarification.  Traditionally, the receptive field of a neuron is called the receptor space, which affects the work of the neuron.  Receptors here are neurons that directly perceive external signals.  Imagine a neural network consisting of two layers, where the first layer is the receptor layer, and the second layer is the neurons connected to the receptors.  For each neuron of the second layer, those receptors that have contact with it are its receptive field. <br><br>  Now take a complex multi-layer network.  The further we go from the entrance, the more difficult it will be to indicate which receptors and how the neurons in the depth affect the activity.  From a certain point, it may turn out that for a neuron all existing receptors can be called its receptive field.  In such a situation, only those neurons with which it has direct synaptic contact would be desirable to name the receptive field of a neuron.  To separate these concepts, we will call the space of input receptors - the original receptive field.  And the neuronal space that interacts with the neuron directly - a local receptive field or simply a receptive field, without further clarification. <br><br>  The division of neurons into functions is associated with the discovery in the primary visual cortex of two main types of neurons.  Simple (simple) neurons respond to a stimulus located at a specific place in their original receptive field.  Complex (complex) neurons are active on the stimulus, regardless of its position. <br><br>  For example, the figure below shows variants of how the sensitivity pictures of the initial receptive fields of simple cells may look.  Positive areas activate such a neuron, negative ones suppress.  For each simple neuron there is a stimulus that is most suitable for it and, accordingly, causes maximum activity.  But it is important that this stimulus is rigidly tied to the position on the initial receptive field.  The same stimulus, but shifted to the side, will not cause the reaction of a simple neuron. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6a3/494/c01/6a3494c017fccf6314b4277468e52d9c.png"><br>  <i>The original receptive fields of a simple cell (Nicholls J., Martin R., Wallace B., Fuchs P.)</i> <br><br>  Complex neurons also have their preferred stimulus, but they are able to recognize this stimulus regardless of its position on the initial receptive field. <br><br>  From these two ideas, the corresponding neural network models were born.  The first such network was created by Kunikhik Fukushima.  She received the name cognitron.  Later he created a more advanced network - neocognitron (Fukushima, 1980).  Neocognitron is a multi-layer design.  Each layer consists of simple (s) and complex (c) neurons. <br><br>  The task of a simple neuron is to follow its receptive field and recognize the image for which it is trained.  Simple neurons are collected in groups (planes).  Within one group, simple neurons are tuned to the same stimulus, but each neuron watches its fragment of the receptive field.  Together, they look through all the possible positions of this image (figure below).  All simple neurons of the same plane have the same weight, but different receptive fields.  You can imagine the situation in a different way, that this is one neuron that knows how to try on its image at once to all positions of the original image.  All this allows you to recognize the same image regardless of its position. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6df/2dd/e19/6df2dde19c51d811a63c60d8af2e1697.png"><br>  <i>Receptive fields of simple cells that are configured to search for the selected pattern in different positions (Fukushima K., 2013)</i> <br><br>  Each complex neuron monitors its plane of simple neurons and is triggered if at least one of the simple neurons is active in its plane (figure below).  The activity of a simple neuron suggests that he recognized a characteristic stimulus in that particular place, which is his receptive field.  The activity of a complex neuron means that the same image is generally found on a layer followed by simple neurons. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/778/326/8ae/7783268aefb7aeaf4458c897fd49a06e.gif"><br>  <i>Neocognitron Planes</i> <br><br>  Each layer after the input has its input picture, formed by complex neurons of the previous layer.  From layer to layer, an increasing generalization of information occurs, which as a result leads to the recognition of specific images regardless of their location in the original image and some transformation. <br><br>  When applied to image analysis, this means that the first level recognizes lines at a certain angle, passing through small receptive fields.  It is able to detect all possible directions anywhere in the image.  The next level detects possible combinations of elementary features, defining more complex forms.  And so on until such time as it is possible to determine the desired image (figure below). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4d9/5d3/6be/4d95d36be48974372d8196e48d763cf0.png"><br>  <i>Neocognitron recognition process</i> <br><br>  When used for handwriting recognition, such a design is resistant to the way of writing.  Recognition success is not affected by movement on the surface or rotation, or deformation (stretching or compression). <br><br>  The most significant difference between a neocognitron and a fully-connected multilayer perceptron is a significantly smaller number of weights used with the same number of neurons.  This is due to the ‚Äútrick‚Äù that allows the neocognitron to determine the images regardless of their position.  The plane of simple cells is essentially one neuron, the weights of which define the core of convolution.  This core is applied to the previous layer, running it in all possible positions.  Actually, the neurons of each plane and define with their connections the coordinates of these positions.  This leads to the fact that all the neurons of the simple cell layer monitor whether the image corresponding to the nucleus does not appear in their receptive field.  That is, if such an image occurs anywhere in the input signal for this layer, it will be detected by at least one simple neuron and will cause the activity of the corresponding complex neuron.  This trick allows you to find the characteristic image in any place, wherever it appeared.  But we must remember that this is precisely a trick and it does not particularly correspond to the work of the real crust. <br><br>  Neocognitron learning occurs without a teacher.  It corresponds to the procedure previously described for isolating a complete set of factors.  When real images are fed to the input of the neocognitron, the neurons have no choice but to isolate the components inherent in these images.  So, if you give handwritten numbers to the input, then the small receptive fields of simple neurons of the first layer will see lines, angles, and conjugations.  The size of the competition zones determines how many different factors can stand out in each spatial area.  The most significant components are highlighted first.  For handwritten numerals, these will be lines at different angles.  If free factors remain, then more complex elements can stand out. <br><br>  From layer to layer, the general principle of learning is preserved - the factors characteristic of many input signals are highlighted.  By handing the handwritten numbers to the first layer, at a certain level, we get the factors corresponding to these numbers.  Each digit will be a combination of a stable set of features that stand out as a separate factor.  The last layer of the neocognitron contains as many neurons as there are images to be detected.  The activity of one of the neurons of this layer indicates recognition of the corresponding image (figure below) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e0/815/554/9e0815554f18cb9d9407f328752e3148.gif"><br>  <i>Neocognitron Recognition (Fukushima K., Neocognitron, 2007)</i> <br><br>  The video below provides a visual representation of the neocognitron. <br><br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/Qil4kmvm2Sw%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700190,15700253&amp;usg=ALkJrhjd3tLkMxqBP7HtMMlA7NC-kMcvCg" frameborder="0" allowfullscreen=""></iframe><br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/oVYCjL54qoY%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700190,15700253&amp;usg=ALkJrhhkTaVI2S38ZDMBx7ivJVRMfC1-ew" frameborder="0" allowfullscreen=""></iframe><br><br>  An alternative to learning without a teacher is learning with a teacher.  So, in the example with figures, we can not wait until the network itself selects statistically stable forms, but tell it what kind of figure it is presented to it, and require appropriate training.  The most significant results in such training of convolutional networks were achieved by Yan LeKun (Y. LeCun and Y. Bengio, 1995).  He showed how you can use the back-propagation error method to train networks, whose architecture, like that of a neocognitron, remotely resembles the structure of the cerebral cortex. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c27/563/d51/c27563d51d195ee2f633cecb2b3e95b4.png"><br>  <i>Convolution network for handwriting recognition (Y. LeCun and Y. Bengio, 1995)</i> <br><br>  At this point, we will assume that the minimal initial information is recalled and you can move on to things that are more interesting and surprising. <br><br>  <a href="http://habrahabr.ru/post/214525/">Continuation</a> <br><br>  Previous parts: <br>  <a href="http://habrahabr.ru/post/214109/">Part 1. Neuron</a> <br>  <a href="http://habrahabr.ru/post/214241/">Part 2. Factors</a> </div><p>Source: <a href="https://habr.com/ru/post/214317/">https://habr.com/ru/post/214317/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../214297/index.html">Ministry of Education and Science: programming cannot be taught exclusively remotely</a></li>
<li><a href="../214299/index.html">Simple Science - Experience Digest # 29</a></li>
<li><a href="../214301/index.html">Bing in Russia out of beta?</a></li>
<li><a href="../214313/index.html">Fastening the tablet to a vertical surface with your own hands</a></li>
<li><a href="../214315/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ98 (February 23 - March 1, 2014)</a></li>
<li><a href="../214319/index.html">Some interesting and useful things for web developer # 12</a></li>
<li><a href="../214321/index.html">11 wearable devices presented on # MWC2014</a></li>
<li><a href="../214323/index.html">Wireless Tech Field Day 6 - video</a></li>
<li><a href="../214325/index.html">The concept of the "correct" definition of a random winner</a></li>
<li><a href="../214327/index.html">IOS 7 keylogger</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>