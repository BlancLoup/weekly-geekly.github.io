<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neurorevolution in heads and villages</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, more and more often you hear the opinion that a technological revolution is taking place now. Argued that the world is changing rapidly. 


...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neurorevolution in heads and villages</h1><div class="post__text post__text-html js-mediator-article">  Recently, <a href="https://www.youtube.com/watch%3Fv%3DY6fdQYQ95Js%26feature%3Dyoutu.be">more</a> and <a href="https://habrahabr.ru/company/it-grad/blog/276299/">more often</a> you hear the opinion that a technological revolution is taking place now.  Argued that the world is changing rapidly. <br><br><img width="500" src="https://habrastorage.org/files/fb8/4b3/123/fb84b31238484b38b469eff0518848b6.jpg"><br><br>  In my opinion this is really happening.  And one of the main driving forces is the new learning algorithms that allow processing large amounts of information.  Modern developments in the field of computer vision and machine learning algorithms can quickly make decisions with accuracy no worse than professionals. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I work in the field of image analysis.  This is one of the areas that new ideas have touched the most.  One of these ideas is convolutional neural networks.  Four years ago, with their help, they first started winning image processing contests.  Victory did not go unnoticed.  Tens of thousands of followers began to engage and use neural networks, which until then had been on the sidelines.  As a result, a boom a year or two ago began, which gave rise to many ideas, algorithms, and articles. <br><br>  In my story, I will review the ideas that have appeared over the past couple of years and have hooked my subject.  Why is happening - the revolution and what to expect from it. <br><br>  Who will lose ten jobs in the coming years, and who will have new promising vacancies. <br><a name="habracut"></a><br><br><h4>  Neural networks </h4><br>  At the head of the ongoing revolution are several types of algorithms.  The flagships are neural networks.  About them there will be a speech. <br><br><img src="https://habrastorage.org/files/12c/6c5/f01/12c6c5f01cc44d2ea3e2403f5cf4e43a.png"><br><br>  Neural networks have appeared long ago.  Back in the forties.  The idea is simple: the best decision-making machine is the human brain.  Let's emulate it.  The idea is really awesome and simple.  That's just all stumbles on the implementation.  Neurons in the human brain ... Ghm.  Lot.  And the architecture is confusing. <br><br>  Starting in the forties, every couple of years another breakthrough came in computing technology or in understanding the brain.  And immediately the wave was rising: " <i>Finally, neural networks will work!</i> ".  But after a couple of years, the wave went into decline. <br>  When I was studying at senior courses (2007-2010), the generally accepted opinion was: " <i>Yes, you got your neural networks! They do not work! They checked them ten times already. Take SVM, Random Forest or Adaboost! Easier, clearer, more accurate</i> ."  In a special honor were purely mathematical solutions of problems, when everything could be painted through a likelihood formula (such a solution, of course, cannot be surpassed). <br><br>  What happened that by 2012 the neural networks were able to scatter and break all the Olympus?  In my opinion the answer is simple.  Nothing.  Powerful enough video cards on which you can program by the time were already 8-9 years old.  The ideas that made the breakthrough were sown in the late 80s and early 90s.  CUDA appeared, but there were tools before it. <br><br><img src="https://habrastorage.org/files/607/7f2/d6c/6077f2d6c7854d9cb4a74e8c48ece233.png"><img width="350" src="https://habrastorage.org/files/b24/b00/6c2/b24b006c2378417da0665948097afd0a.jpg"><br><br>  Just there was a systematic increase.  Ideas that ate too much computing power in the 90s became real.  Writing under the video card has become easier.  Word by word, article by article, eye for eye.  And suddenly, in 2012, the <b>ImageNet</b> contest <a href="https://habrahabr.ru/post/183380/">wins the</a> <b>convolutional neural network</b> .  It does not just win, but with a separation from the nearest pursuer twice. <br><br><img src="https://habrastorage.org/files/e33/282/7e7/e332827e7fec4fd896a24dec3a45a7a5.png"><br><br><h4>  What is <a href="http://image-net.org/">ImageNet</a> </h4><br>  This is such a big, big <a href="http://image-net.org/explore.php">base of</a> words and pictures attached to them.  Consisting of everything: objects, structures, creatures.  Pictures can be a dozen, and maybe thousands.  Depending on the complexity and prevalence of the concept: <br><br><img src="https://habrastorage.org/files/0cb/a2a/db1/0cba2adb106640a193346ca036639277.jpg"><img width="180" src="https://habrastorage.org/files/213/c79/207/213c79207cd8473d92b272862b78dbd0.jpg"><img height="180" src="https://habrastorage.org/files/17c/262/fd3/17c262fd3e944aeaad950231214d8886.jpg"><br><br>  Every year a competition is held on it.  What percentage of concepts can the system recognize.  <a href="https://habrahabr.ru/company/nordavind/blog/206342/">The terms of the</a> contest vary slightly, but the idea remains the same. <br><br>  You, for certain, saw pictures with recognized objects from this base: <br><br><img width="600" src="https://habrastorage.org/files/035/947/865/035947865b38497e9d2e454f0b3e741b.PNG"><br><br><h4>  What is a convolutional network? </h4><br>  The topic is long.  If interested - the best read articles: <a href="http://habrahabr.ru/company/nordavind/blog/253859/">1</a> , <a href="http://www.aboutbrain.ru/2014/02/27/%25D1%2581%25D0%25B2%25D0%25B5%25D1%2580%25D1%2582%25D0%25BE%25D1%2587%25D0%25BD%25D1%258B%25D0%25B5-%25D1%2581%25D0%25B5%25D1%2582%25D0%25B8-%25D0%25BD%25D0%25B5%25D0%25BE%25D0%25BA%25D0%25BE%25D0%25B3%25D0%25BD%25D0%25B8%25D1%2582%25D1%2580%25D0%25BE%25D0%25BD/">2</a> , <a href="http://mechanoid.kiev.ua/ml-lenet.html">3</a> . <br><br>  In short.  Convolutional networks, these are neural networks, where "convolutions" are the main element of learning.  Convolutions are small pictures: 3 * 3, 5 * 5, 20 * 20.  And at every level of the network dozens of them are trained.  Besides them, nothing is learned.  We teach the network to find such "convolutions" that maximize information about the image.  This is the structure of such a network: <br><br><img src="https://habrastorage.org/files/774/02b/497/77402b49736e477da3ec50024f036304.png"><br><br>  At the same time, such convolutions start working as cool feature detectors at once on many levels of depth and meaning.  They can find both small features, and big, global.  After filtering it looks something like this: <br><br><img src="https://habrastorage.org/files/8db/44d/e83/8db44de834044e3dad1c001dba695113.PNG"><br><br>  The convolutions themselves will, for example, be: <br><br><img src="https://habrastorage.org/files/53b/73f/1a8/53b73f1a8bec4779b8eefaac2476be42.PNG"><br><br>  Or such: <br><br><img width="700" src="https://habrastorage.org/files/5ac/d72/67c/5acd7267c9854af884c00a1bad5b535b.png"><br><br>  And in dynamics the process will look like this: <br><br><img src="https://habrastorage.org/files/449/34b/b52/44934bb52be74d658f04d1173b34f3cc.gif"><br><br><h4>  Criticism </h4><br>  Good criticism is in the <a href="https://habrahabr.ru/post/259191/">article</a> <a href="https://habrahabr.ru/users/rocknrollnerd/" class="user_link">rocknrollnerd</a> .  Or <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf">here</a> . <br>  In short.  What the network sees is we do not know.  She does not ‚Äúunderstand‚Äù, she ‚Äúfinds patterns‚Äù.  No matter how insane they are.  It is easy to deceive her, if these patterns are revealed.  For example, these are the numbers 1-2-3-4-5-6-7-8-9 with a probability of 99.9%: <br><br><img src="https://habrastorage.org/files/eaf/c4d/468/eafc4d4680e44921b37b5c539c3d8c91.PNG"><br><img src="https://habrastorage.org/files/4b4/e45/261/4b4e45261e6442c7b23b5937e8489938.PNG"><br><br>  Does not look like it?  Convolution networks are considered otherwise. <br><br><h4>  Breakthrough </h4><br>  All that was above is the introduction to the article.  And now the promised revolution.  Where did the breakthrough happen and what does it lead to. <br><br><img width="400" src="https://habrastorage.org/files/cfc/b4e/e7e/cfcb4ee7e6e7446997b8ba06f4666111.jpg"><br><br>  The breakthrough is that people began to analyze and understand what these "convolutional networks" are.  As a result - ask them the right questions. <br><br>  Consider the ‚Äúoutdated algorithms‚Äù (it‚Äôs ridiculous to say this about ideas that are often ten years old), which have been searching for objects in the image.  For example, a person (HOG), a person (Haar), or some more unique objects (SIFT, SURF, ORB): <br><br><img width="700" src="https://habrastorage.org/files/bbf/805/0a7/bbf8050a785342dcab4970ef0718fd39.jpg"><br><br>  In essence, the selection of primitives characteristic of the object in question, which we analyze, is used.  The analysis can be made by some kind of automatic decision making system (SVM, AdaBoost), or by the person himself, by setting simple rules (via SIFT, SURF).  Here is a good <a href="https://www.youtube.com/watch%3Fv%3DQk4SqF9FT-M">lecture by</a> LeKun (the author of convolutional networks). <br><br>  The first time after the appearance of the convolutional networks, they worked this way: the region was taken, its analysis was carried out, the decision was made whether there was a desired object in this region (for example, like <a href="http://arxiv.org/pdf/1312.6229.pdf">this</a> ).  Convolution networks allocate more generalized primitives, and by them we have already looked at the object: <br><br><img src="https://habrastorage.org/files/e10/876/1c0/e108761c0a814854a6fdf03da4047769.PNG"><br><br>  It turned out quite slowly + write a lot of logic. <br><br>  But can not the convolution network find an object for us?  Why bother with logic, with windows, with analysis? <br><br>  It turns out it can.  And in my opinion it is VERY cool.  As an example, I like <a href="http://arxiv.org/pdf/1506.02640v4.pdf">this</a> article.  In it, the neural network is trained to issue an x, y, w, h object.  Simple and tasteful.  One run of the network - all objects in the frame are found and marked.  No need to run the network in different areas.  And really, what's the difference: to train to issue an object class, or to teach to issue a class + parameters?  The main thing is for each class to have a place in the output neurons, where one could put an answer: <br><br><img width="900" src="https://habrastorage.org/files/d96/159/aa6/d96159aa684f4b3fa0212e6985296cc9.PNG"><br><br>  At the output of the network, the volume of the size ((Number of classes) * 2 + 5 * 2) * 7 * 7.  If there are 10 classes, then the volume is 30 * 7 * 7.  Here 7 * 7 is the spatial coordinate.  In fact, such a reduced image.  For example, the 4 * 4 point is the center of the picture.  At each such point we have 30 quantities.  10 of them to designate an object that is located at a point (the class of this object has a value of 1, the rest is 0).  4 more values ‚Äã‚Äã- x, y, w, h of the rectangle at the point that determines the size of the object, if it is there.  Another one is the confidence coefficient.  The remaining 15 is a repetition of all that in case there was a center of two objects in one segment.  Total is obtained: <br><br><img src="https://habrastorage.org/files/443/1ec/399/4431ec39937e4d168f9ae1dcfc1f0628.PNG"><br><br>  On <a href="http://pjreddie.com/darknet/yolo/">the</a> project <a href="http://pjreddie.com/darknet/yolo/">site</a> you can watch a lot of interesting videos: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/K9a6mGNmhbc%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhht635YqfzsKQ-rd_K8pFCOdrVMew" frameborder="0" allowfullscreen=""></iframe><br><br>  Is it possible to submit to the network input a priori information different from the image?  Of course!  The main thing is to choose the network architecture, for <a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf">example</a> : <br><br><img src="https://habrastorage.org/files/dd3/e43/744/dd3e4374429a4846a75e07987f142c1c.PNG"><br><br>  Here at the entrance of the network serves the image, as well as the approximate area where the interesting object is located.  The network is learning to produce accurate crop + segment object.  Now your network eats a priori data, determining for itself what it is and what to do with it. <br><br>  In my opinion, these ideas are a breakthrough that allows you to completely get away from the old ideology of algorithms.  Previously, everything was separate: logical data, images, connections.  And now everything can be thrown into a common pot without much thought ( <s>yes, I lie, I lie, I need to think a lot - over the formation of the base, for example</s> ).  The main thing is to understand the sufficiency of the data.  No need to understand at what stage of the algorithm is optimal what to combine.  The network itself optimizes the interaction of data streams. <br><br><h4>  Network as a filter </h4><br>  But this is not all that has become clear in the last two or three years.  The second conceptual observation is that the network is a non-linear filter.  Yes, it was known forty years ago.  But only now it became clear what this means and what it leads to.  The network can filter the input data and output both logic and an image at the output (or all at the same time). <br>  The resulting logic or images can be input to other algorithms.  Or at the entrance of the person.) <br><br>  Let's start with the last <a href="http://mi.eng.cam.ac.uk/projects/segnet/">job</a> , which even seemed to skip the news.  The network makes video markup from the DVR according to the type of object: ‚Äúroad‚Äù, ‚Äúpedestrians‚Äù, ‚Äúsigns‚Äù, ‚Äúmarking‚Äù, etc. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/e9bHTlYFwhg%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhgbN6ju9u5-XyglfGzggggT3scutg" frameborder="0" allowfullscreen=""></iframe><br><br>  Data that is so received can be submitted to the vehicle orientation input.  This is a fundamentally new solution. Until now, object classification systems for automatic cars have been fundamentally different.  They demanded lidars or at least a stereo camera. <br><br>  Do you think this system is complex and monstrous?  No, just a few trained layers, set up in a couple of days: <br><br><img src="https://habrastorage.org/files/4e4/6b2/20a/4e46b220a6c147d8ad60c630a0ebd7a7.png"><br><br>  Direct conversion of data in response.  Frames are processed quickly.  On a laptop four years ago about a second per frame.  On a more or less adequate computer - realtime. <br><br>  There are several other networks that solve similar problems with a slightly different architecture (many of them were earlier than SegNet, but on the whole they worked worse): <a href="http://arxiv.org/pdf/1506.04924.pdf">1</a> , <a href="http://arxiv.org/pdf/1512.07928.pdf">2</a> , <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Sharma_Deep_Hierarchical_Parsing_2015_CVPR_paper.pdf">3</a> <br><br><img src="https://habrastorage.org/files/77e/bdd/c74/77ebddc74fff40ce83493e8fe013f475.PNG"><br><img src="https://habrastorage.org/files/6df/fb0/efa/6dffb0efadc84d269f9887b27e097a7c.PNG"><br><img src="https://habrastorage.org/files/508/187/a1a/508187a1a29f486da3b612fa957f2cfd.PNG"><br><img src="https://habrastorage.org/files/230/10d/bd5/23010dbd5edb45c78f69b39ddfe05622.PNG"><br><br>  Now neural networks solve problems and tasks that five years ago required a huge amount of power and were the result of the work of entire groups of scientists. <br><br><h4>  Stereo match </h4><br>  Surely many of you know that with two cameras you can restore the three-dimensional image.  Teach the network to <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zbontar_Computing_the_Stereo_2015_CVPR_paper.pdf">build it</a> ? <br><br><img src="https://habrastorage.org/files/d7b/5dd/76e/d7b5dd76eacb42caa9f89805159da047.PNG"><br><br>  This approach is good because the network itself will guess in which situations it is better to approximate by plane, and in what situations it is better not necessary.  Yes, and to teach such a network is simple.  Take a walk a couple of days with a stereo camera, dial a video.  And the grid is not much more complicated than the ones above: <br><br><img src="https://habrastorage.org/files/d93/9be/903/d939be903a4044bab7b9767267c33fb5.PNG"><br><br><h4>  Optical stream </h4><br>  Optical stream is almost the same stereo match, right?  Only now <a href="http://arxiv.org/pdf/1504.06852.pdf">they decided to</a> train with computer games: <br><br><img src="https://habrastorage.org/files/8dc/c19/c1b/8dcc19c1b7f8494898a92d300abf92d0.PNG"><br><br>  I do not know how this works in practice, but the idea is cool. <br><br><h4>  Filtration </h4><br>  Have you ever used Canny filtering in OpenCV?  Surely you know that it is very difficult to choose its sensitivity so that it is the borders that stand out, and not any noise? <br><br><img width="250" src="https://habrastorage.org/files/94b/223/d8a/94b223d8a26c40189b2162cfd9d373bf.jpg"><img width="250" src="https://habrastorage.org/files/eb1/f87/f19/eb1f87f190e2433698f8e7b01f13356f.jpg"><img width="250" src="https://habrastorage.org/files/c00/5e2/ba1/c005e2ba101145e8a359ae77b8c6618d.jpg"><br><br>  Here are three articles on how to do it differently, so that the result was the same and did not confuse you: <a href="http://arxiv.org/pdf/1504.06375.pdf">1</a> , <a href="http://arxiv.org/pdf/1412.1123.pdf">2</a> , <a href="http://mc.eistar.net/UpLoadFiles/Papers/DeepContour_cvpr15.pdf">3</a> <br><br><img width="900" src="https://habrastorage.org/files/687/7fa/b46/6877fab464864158925ccfb251580767.PNG"><br><br><h4>  Paint it </h4><br>  Well, yes, where do without it.  A couple of weeks ago, a <a href="http://tinyclouds.org/colorize/">network</a> for coloring old B &amp; W films was slipping: <br><br><img src="https://habrastorage.org/files/cf7/57d/209/cf757d20909e4cb3b62cf11446e55c3b.png"><br><br>  Not perfect, but funny. <br><br><h4>  Supersolution </h4><br>  It seems to me that soon Photoshop will acquire a number of new plug-ins ... <br><br><img src="https://habrastorage.org/files/52a/4e2/3c4/52a4e23c4b964834a3993e73ecd49b7d.PNG"><br><br><h4>  Others from the world of convolutional networks </h4><br>  This is only a small number of networks and ideas.  Their number is growing every day.  Now there is a total breakthrough in medicine.  Have you seen kaggle contests?  How does the retina recognize <a href="https://www.kaggle.com/c/diabetic-retinopathy-detection">diseases</a> ?  And what happens behind the scenes is generally scary.  We have done knee photofluorography recognition in a week.  Let it be bad, but it works.  And here still the <a href="http://blogs.nvidia.com/blog/2016/02/09/deep-learning-3/">project</a> raises the people.  They assure that they can recognize everything medical, if only the base was. <br><br>  And the number of Just For Fun applications will grow astronomically.  Remember the application that the photos determine how old you are?  Or your attraction?  Wangju app appearances in the style of "look at yourself with a beard" or "turn me into Zeus." <br><br>  In general, the convolutional networks and image analysis wherever there is.  Even <a href="http://arxiv.org/pdf/1511.06410v2.pdf">AlphaGo</a> on their base analyzes the position in Go. <br><br><h4>  Future </h4><br>  Do you really think that cars will not replace you?  What is your area unique?  Deep Mind system appeared in 10 year.  A couple of years later, they began to address the ‚ÄúGO game‚Äù task.  Four years later, they decided and are now challenging the world champion.  For four years, even a child in Go will not be taught to play.  Do you really think your profession is safe?  What singularity is not here yet? <br><br>  Everyone loves to joke about the fact that in a couple of years, as soon as the autopilot appears for cars, taxi drivers will start to burn cars, robots, like today they are burning ‚ÄúUber‚Äù cars.  Understand that many things will happen before that.  Translators and legal assistants.  Secretaries.  Is your profession to decipher images?  Radiologist?  Cartographer?  Will a video analytics specialist be needed in a couple of years, or will Google replace them with their <a href="http://cloudacademy.com/blog/google-vision-api-image-analysis/">services</a> ? <br><br>  Of course, the best translators will remain.  As well as the best secretaries.  Yes, and good radiologists, of course, will be needed (there must be someone to verify the diagnosis).  Will remain all, whose specialty - the work of hands.  For the time being, the mechanic is far from completely replacing surgeons and massage therapists (I think even 20-30 years will not even reach plumbers!).  There will be professions that will manage robots and complexes from robots.  There will be more people who will train the systems and support them.  But medium and bad programmers, in my opinion, already in 5-10 years will begin to crowd the system of automatic programming. <br><br>  In any case, we have to live in interesting times.  And yes, while you slept the singularity is already here. <br>  <s>Well, I'm a little thicker, but in general, everything is fine, it will do for Friday.</s> <br><br><h4>  Little basement </h4><br>  If suddenly the topic is interested, then I advise a couple of places where information is much more than on a habr and is replenished regularly. <br>  First, I like this <a href="https://vk.com/deeplearning">community</a> in contact.  Yes, a lot of garbage, but practical things are almost never missed. <br><br>  Secondly, about half of the above I took <a href="https://github.com/kjw0612/awesome-deep-vision">from here</a> .  There is much less information here, but they don‚Äôt miss the most valuable and interesting.  Plus well structured. <br><br>  Thirdly, <a href="https://habrahabr.ru/users/skolotienko/" class="user_link">SKolotienko</a> also threw a good <a href="http://www.reddit.com/r/MachineLearning">reference</a> to the reddit. <br><br>  And further.  In order not to be unsubstantiated, my friend and I took one of the networks indicated here and tortured for a couple of weeks, forcing us to recognize what was coming to hand (since there were a lot of bases).  Within a week, he will post an article with a bunch of sources and manuals.  So watch out for <a href="https://habrahabr.ru/users/nikkolo/" class="user_link">Nikkolo</a> .  And <a href="https://habrahabr.ru/users/vasyutka/" class="user_link">Vasyutka</a> for a couple of weeks wanted to publish some thoughts from the area where the neural networks intersect with sound logic. </div><p>Source: <a href="https://habr.com/ru/post/277069/">https://habr.com/ru/post/277069/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../277051/index.html">Report from Tarantool Meetup January 28</a></li>
<li><a href="../277053/index.html">What does DEFAULT TRACE conceal in itself?</a></li>
<li><a href="../277055/index.html">Getting rid of Visual Basic</a></li>
<li><a href="../277057/index.html">Golden App 2016 mobile app competition has started</a></li>
<li><a href="../277067/index.html">Reverse engineering and slowdown "Kazakov"</a></li>
<li><a href="../277077/index.html">Near-architecture arguments or the results of a single dispute</a></li>
<li><a href="../277079/index.html">We send messages to Telegram from C #</a></li>
<li><a href="../277081/index.html">From FineReader to data entry solutions: how the direction of DataCapture in ABBYY began</a></li>
<li><a href="../277085/index.html">CodingFuture + Puppet. Part I: network and network filter (cfnetwork + cffirehol)</a></li>
<li><a href="../277087/index.html">Angular 1.5: Components</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>