<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>OpenCV and image processing</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good morning, ladies and gentlemen. Attentive readers noticed that translated books on the topic of computer vision had once again appeared on the Rus...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>OpenCV and image processing</h1><div class="post__text post__text-html js-mediator-article">  Good morning, ladies and gentlemen.  Attentive readers noticed that translated books on the topic of computer vision had once again appeared on the Russian market.  We also could not but be interested in the following book: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e29/93d/399/e2993d3990554b53af76379d3017ad9c.jpg"></div><br>  Since computer vision technologies are largely tied to both Python and C ++, we picked up an article with task analysis and code in both languages.  In addition, we sincerely hope that you will like the girl under the cut. <br><a name="habracut"></a><br>  This article will explain how to generate averaged face image using the OpenCV library (C ++ / Python). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/8f4/12b/e77/8f412be77466463e911c857190ea34a0.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">one</font></em> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The woman shown in Fig.  1, most readers will find it pretty.  But can you guess her nationality?  Why does she have such a smooth skin?  That's right - this woman does not exist.  But you can not say that this is a completely virtual image.  This is the average portrait of all employees of my company Sight Commerce Inc.  as of about 2011.  Her nationality is difficult to determine, since we have girls with European, Latin American, East Asian and Indian roots! <br><br>  The history of averaging faces is just fascinating. <br><br>  It all started with the research of Francis Galton (cousin Charles Darwin), who in 1878 invented a new photographic technique: he learned how to combine faces and make the first identikits.  He believed that by combining the faces of criminals, one could model the ‚Äúprototypical‚Äù face of a felon and subsequently recognize potential criminals by their features.  It turned out that this hypothesis is erroneous: after examining someone else's photo, it is impossible to determine his tendency to crimes. <br><br>  However, Galton noticed that the average face always looks more attractive than all the "components" of his faces.  In one <a href="http://www.uni-regensburg.de/Fakultaeten/phil_Fak_II/Psychologie/Psy_II/beautycheck/english/missgermany/missgermany.htm">striking experiment, the</a> researchers "laid down" the faces of all 22 finalists of the Miss Germany 2002 contest.  The respondents rated the resulting portrait higher than any of the contestants, even higher than ‚ÄúMiss Berlin‚Äù, which then turned out to be the winner.  Phew!  It turns out that Jessica Alba is so pretty precisely because her face is close to the average. <br><br>  Is it possible to equate "average" to "mediocre"?  Why does the average face seem attractive to us?  According to an evolutionary hypothesis called ‚Äúcoinophilia,‚Äù individuals in active reproductive age are looking for partners with averaged features, since deviations from the mean may indicate harmful mutations.  In addition, the middle face is symmetrical, since the variations in the left and right sides of the face are mutually smoothed out. <br>  How to generate averaged face in OpenCV? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c78/3f6/059/c783f60599ed404c88c12e8bbcf5840f.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">2: The average face of US presidents from Carter to Obama</font></em> <br><br>  The code and images for the article can be downloaded <a href="">here</a> . <br><br>  The following is a step-by-step description of how to generate an average face, having the above set of images.  In this case, we do not take into account the size of the images themselves or the size of the face on each portrait. <br><br><h3>  Stage 1: Detection of facial features </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/files/95c/dee/065/95cdee06500a48a8bf7a3ebc1ac8c9cd.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">3: Facial feature detection example</font></em> <br><br>  For each portrait, we calculate 68 ‚Äúcontrol points‚Äù using the dlib library.  How to install and use dlib, I tell in detail in another post <a href="http://www.learnopencv.com/facial-landmark-detection/">Facial Feature Detection</a> .  The portrait of Obama has 68 control points. <br><br><h3>  Stage 2: Coordinate Transformation </h3><br>  At the entrance, the size of face images can be very different.  Therefore, we will have to normalize them and lead to a single reference system.  To do this, we deform all face images to size 600 √ó 600 so that the left corner of the left eye is at the point with coordinates (180, 200), and the right corner of the right eye is at the point (420, 200).  Let's call this reference system the <b>‚Äúfinal coordinate system,‚Äù</b> and the coordinates of the original images, the <b>‚Äúinitial coordinate system</b> . <b>‚Äù</b> <br><br>  How do I choose the points above?  I wanted to ensure that these points would be located on the same horizontal line, and this line would run approximately a third of the way from the top to the bottom edge of the picture.  So, I ensured that the tips of the sockets were located at points with coordinates (0.3 x width, height / 3) and (0.7 x width, height / 3). <br><br>  We also know where the corners of the eyes are on the source images, respectively, at control points 36 and 45. Then we can calculate the similarity transformation (rotation, translation, scaling) and translate the points from the initial coordinate system to the final one. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/983/2a1/062/9832a1062f60434fae08d43262e1c610.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">4: Similarity conversion is used to transform an original 3000 √ó 2300 image into a final image of 600 √ó 600.</font></em> <br><br>  What is similarity conversion?  The similarity transformation is a 2 √ó 3 matrix that allows you to change the location of the points (x, y) or the whole image.  The first two columns of this matrix encode rotation and scaling, and the last one is the translation (i.e. offset).  Suppose you transform (move) the four corners of a square in such a way that the square is scaled in the x and y directions s <sub>x</sub> and s <sub>y</sub> times, respectively.  At the same time, it rotates through an angle Œ∏ and is transferred (moved) by t <sub>x</sub> and t <sub>y</sub> in the x and y directions.  The similarity transformation can be written as follows: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ffe/d35/baf/ffed35bafc424351808af7edd1a0038e.png"></div><br><br>  Based on the point (x, y), the similarity transformation described above transfers this point to (x <sub>t</sub> , y <sub>t</sub> ) according to the following equation: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ab4/801/444/ab480144441d4a5c981bb06873c3221e.png"></div><br><br>  Similarity transformation can be performed using <code>estimateRigidTransform</code> <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// C++ // inPts  outPts ‚Äì  ,    //   ,       , //     cv::estimateRigidTransform(inPts, outPts, false);</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Python # inPts  outPts -      numpy #   ,       , #     cv2.estimateRigidTransform(inPts, outPts, False);</span></span></code> </pre><br>  However, there is one small problem.  OpenCV requires that you specify at least three pairs of points.  This is stupid, since the similarity transformation can be done with just two points.  Therefore, you can simply imagine the third point, so that it and the two known points form an equilateral triangle.  Then use the <code>estimateRigidTransform</code> as if we have three pairs of points. <br><br>  By calculating the similarity transformation, you can use it to transform the original image and its control points into final coordinates.  The image is transformed with <code>warpAffine</code> , and the points with the help of <code>transform</code> . <br><br><h3>  Stage 3: Face Alignment </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/files/680/f73/80b/680f7380ba404b68b53d0f2c1d8a5d19.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">5: Simplified face averaging result</font></em> <br><br>  At the previous stage, we were able to convert all the images and control points to the coordinates of the final image.  Now all our images are the same size, the corners of the eyes are aligned.  Perhaps it would be tempting to try to get an average image by taking the average pixel values ‚Äã‚Äãof these aligned images.  However, in this case, you get such a picture, as in Fig.  5. Yes, eyes are aligned, and all other facial features are located at random. <br><br>  If we knew which point from one source image corresponded to which point from another source image, we could ideally superimpose two images on each other.  But we have no such information.  We only know the position of the 68 corresponding points on each of the original images.  Focusing on these points, we will divide each image into triangular areas, and first we will align these areas, and then we will average pixel values. <br><br>  This process is described in more detail in my post <a href="http://www.learnopencv.com/face-morph-using-opencv-cpp-python/">Face Morphing</a> , and in general terms - below. <br><br>  <b>Calculate the average front points</b> <br><br>  To calculate how the average face will look, all the features of which are aligned, first you need to calculate the average of all the converted control points in the final image.  To do this, we simply average the x and y values ‚Äã‚Äãof all control points in the coordinates of the final image. <br><br>  <b>Delaunay Triangulation Calculation</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/481/c7d/5a2/481c7d5a288240ea8116892224695220.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">6: Calculation of the Delaunay triangulation for the average control points.</font></em> <br><br>  At the previous stage, we obtained the positions of the control points for the average face in the final coordinates.  You can use these 68 points (shown in blue in Figure 6) and 8 points on the border of the final image (shown in green) to calculate the Delaunay triangulation (shown in red).  More details Delone triangulation is described <a href="http://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/">here</a> . <br><br>  Delaunay triangulation allows you to split the image into triangles.  As a result of this triangulation, we obtain a list of triangles represented as an array of indices of 76 points (68 points on the face + 8 boundary points).  In the triangulation example shown below, it is noticeable that the control points 62, 68 and 60 form a triangle, 32, 50 and 49 form another triangle, etc. <br><br>  <b>Deformation of triangles</b> <br><br>  <i>Triangulation example</i> <br><br><pre> <code class="hljs json">[ <span class="hljs-number"><span class="hljs-number">62</span></span> <span class="hljs-number"><span class="hljs-number">68</span></span> <span class="hljs-number"><span class="hljs-number">60</span></span> <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">49</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-number"><span class="hljs-number">72</span></span> <span class="hljs-number"><span class="hljs-number">9</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span> <span class="hljs-number"><span class="hljs-number">58</span></span> <span class="hljs-number"><span class="hljs-number">53</span></span> <span class="hljs-number"><span class="hljs-number">35</span></span> <span class="hljs-number"><span class="hljs-number">36</span></span> ‚Ä¶ ]</code> </pre><br>  At the previous stage, we calculated the average location of control points on the face and, based on this data, performed the Delaunay triangulation to divide the image into triangles.  In fig.  7 we can see the Delone triangles superimposed on the transformed original image, and on the image that is in the middle, the triangulation of the averaged control points is shown.  Note that triangle 1 in the image on the left corresponds to triangle 1 in the middle image.  Knowing the three vertices of the triangle 1 located on the left image and the corresponding three vertices of the triangle from the middle image, we can calculate the affine transformation.  Repeating this procedure for each of the triangles from the left image, we get the right image.  So, the right image is the result of the deformation of the left to the state of the averaged face. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/83d/7b8/33a/83d7b833a33c4e71bb7472cc3cdc00c3.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">7: Deformation of the image based on the Delaunay triangulation</font></em> <br><br><h3>  Stage 4: Facial Averaging </h3><br>  Applying the manipulations from the previous stage to all the source images, we obtain the final images, which are deformed in such a way that the result coincides with the averaged end points.  To calculate the average image, you can simply add the pixel intensity values ‚Äã‚Äãof all the deformed images and divide this amount by the number of images.  In fig.  2 shows the result of such averaging.  It looks much better than the ‚Äúaverage‚Äù that was in fig.  five. <br>  What do you think the ‚Äúaverage‚Äù US president looks like?  In my opinion - fatherly and cute. <br><br>  <b>Face averaging results</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9fb/0c8/78b/9fb0c878b5934f1aa1888b355281a24a.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">8: The average face of Mark Zuckerberg, Larry Page, Ilona Mask and Jeff Bezos</font></em> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/f28/0fe/dea/f280fedea8fe448a905350a0129f5241.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">9: Average face of Bree Larson, Julianne Moore, Cate Blanchett and Jennifer Lawrence</font></em> <br><br>  What is the average leading entrepreneur technician?  In fig.  Figure 8 shows the average face of Mark Zuckerberg, Larry Page, Ilon Mask and Jeff Bezos.  I can not say about this "average entrepreneur" anything special except that he still can see the hair (despite the negative contribution of Jeff Bezos). <br><br>  What is the average Oscar-winning actress?  In fig.  Figure 9 shows the average face of Bree Larson, Julianne Moore, Cate Blanchett and Jennifer Lawrence.  So, the average movie star is very pretty.  And her teeth are better than those of a successful entrepreneur.  No wonder. <br><br>  You can also make a symmetrical face by averaging it with a mirror image.  An example is shown below. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a1e/cda/de2/a1ecdade26cd4ee5b294eae797baf19a.jpg"></div><br>  <em><font color="#999999">Fig.</font></em>  <em><font color="#999999">10: Symmetrical President Obama (center) obtained by averaging his photo (left) with his own mirror image (right).</font></em> </div><p>Source: <a href="https://habr.com/ru/post/308720/">https://habr.com/ru/post/308720/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../308698/index.html">The digest of fresh materials from the world of the frontend for the last week No. 225 (August 22 - 28, 2016)</a></li>
<li><a href="../308700/index.html">The results of the selection of the school Android-developers in Kazan</a></li>
<li><a href="../308702/index.html">PHP Digest number 91 - interesting news, materials and tools (August 15 - 28, 2016)</a></li>
<li><a href="../308714/index.html">How I tried to make money on Pokemon Go</a></li>
<li><a href="../308718/index.html">Distributing unpublished Windows 10 apps to the Store</a></li>
<li><a href="../308726/index.html">Interview with the first speaker of Moscow Python</a></li>
<li><a href="../308728/index.html">‚ÄúMy life through the prism of technology ...‚Äù - Stephen Wolfram</a></li>
<li><a href="../308730/index.html">Digital Help: 14 useful business bots for Telegram</a></li>
<li><a href="../308732/index.html">Why shadow copies do not save most encryptors</a></li>
<li><a href="../308734/index.html">Rewriting Clojure test scripts in 24 hours</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>