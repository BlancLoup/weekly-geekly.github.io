<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Big Data: Backup can not be done without it</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="During my work as a database administrator, I developed for myself one rule that many DBAs adhere to. This is the ‚Äúgolden rule‚Äù of all database admini...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Big Data: Backup can not be done without it</h1><div class="post__text post__text-html js-mediator-article">  During my work as a database administrator, I developed for myself one rule that many DBAs adhere to.  This is the ‚Äúgolden rule‚Äù of all database administrators - do not do anything serious with the database if you do not have a backup.  If you are going to seriously change the parameters of the database, carry out operations for the maintenance of the database, etc.  - you should always perform a backup operation before this.  This principle worked for a long time and justified itself, and even in several cases helped to restore the database to a specific point in time. <br><a name="habracut"></a><br>  Recently, we were assigned the task of developing a procedure for backing up a data warehouse with a size of 20 Terabytes.  Using the established practices of backup, I tried to develop such a procedure and at the same time fit into the framework of RPO (recovery point objective) and RTO (recovery time objective).  Both of these characteristics are measured in time and are as follows: RPO is the allowable amount of possible data loss, RTO is the allowable downtime or how long the database should recover.  It was here that the most interesting thing began - no matter how much I wondered and didn‚Äôt expect it, but the backup procedure developed didn‚Äôt want to fit into this framework - too much data had to be backed up.  In the best case, with numerous reservations and conditions, the database was restored in a few hours, but such a business could not afford.  In the usual situation, when no serious restrictions and conditions were imposed on the database, recovery would take several days.  This was aggravated by the fact that it was impossible to ‚Äúremove‚Äù a backup in a reasonable time - it also took several days and created a heavy load on the database.  At once I will make a reservation that this database does not support incremental backup in the current version.  Perhaps if we could get incrementality, then the game would have cost a candle, and the traditional backup procedure would have the right to life in this case. <br><br>  Realizing that the backup procedure is not viable here, I began to search for existing solutions to this problem.  It was quickly discovered that no one backed up such volumes of information head-on.  There are several approaches that allow you to have a backup of a database of this size, more or less relevant in time. <br><br><h4>  Incrementality </h4><br>  If the database supports incremental backup and the size of the permanent changes in the database is relatively small, then you can try performing an incremental backup procedure at certain intervals.  However, this method is not suitable for everyone and is rather inconvenient in the sense that this backup must be constantly ‚Äúrolled‚Äù onto the second instance of the database.  Here the incremental backup plays the role of the most likely last resort, and the incrementality allows you to remove the extra load on the database and back up only the changed data.  However, with a number of conditions, this decision has the right to life, although it is not the best in my opinion. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Replication </h4><br>  One of the most common solutions is to replicate new and changed data to one or more copies of the database.  There are many technologies that allow such replication, both at the transaction level and at the file system level, it can be both synchronous and asynchronous.  The advantages of such replication are that you will have an almost exact copy of the database.  The mechanisms for catching errors during replication make it possible to quickly and painlessly understand their cause and, as a result, to fix it quickly.  The biggest drawback is the heavy load and high cost of these technologies.  However, in the absence of the ability to keep a backup copy of the database up to date using other means, replication has been and will be one of the most used solutions for extra-large data. <br><br><h4>  "Double" ETL </h4><br>  As a rule, before entering the data warehouse, the data passes through an ETL or ELT procedure.  The abbreviation ETL itself tells us that the data is transformed appropriately before it enters the data warehouse, and the extra data is truncated.  This process can be parallelized - i.e.  do not load data into one data warehouse, but into two or several.  Thus, we will have as many copies of the data warehouse as we need.  But despite this, this approach has a significant drawback - often the copies are not identical, since errors and inconsistencies occur during the data loading process.  It is not always clear which of the copies is more correct.  Maybe some business may allow such a discrepancy, but if we are talking about financial companies, then such an assumption does not have a right to exist.  You can develop a complex procedure of verification and correction of errors, but, as a rule, this only complicates and slows down the whole process.  Summarizing this approach, we can say that it is applicable in a limited number of cases. <br><br>  As it has already become clear, the practice of recovering such volumes from backups is not used anywhere - it takes a few days, or even weeks.  The main method of restoring functionality in the event of the fall of the main database is to switch to a working copy of the database.  To maintain the relevance of this copy, a number of methods are used, some of which I have listed above.  Traditional approaches to backup, which consists in preserving a copy of the database and restoring it in case of failure, do not work with databases of very large volumes ‚Äî you don‚Äôt have to go far for examples.  Summarizing all the above, I want to put a comma in the title at the right place - <b>backup cannot be done, work without it.</b> </div><p>Source: <a href="https://habr.com/ru/post/147944/">https://habr.com/ru/post/147944/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../147939/index.html">Craftsman opens handcuffs enhanced security keys from a 3D printer</a></li>
<li><a href="../147940/index.html">Control of several servos with high accuracy on ATmega16 MK</a></li>
<li><a href="../147941/index.html">‚ÄúPenguins with a penny,‚Äù or Valve talk about their plans for Linux</a></li>
<li><a href="../147942/index.html">Yet another factory</a></li>
<li><a href="../147943/index.html">Obuchalka. The story of the iPhone manual</a></li>
<li><a href="../147945/index.html">We are looking for Milnera - Durova not to offer</a></li>
<li><a href="../147946/index.html">Subscriber safety - the work of the subscribers themselves, even for money?</a></li>
<li><a href="../147947/index.html">First steps in robocode</a></li>
<li><a href="../147950/index.html">Access to the French Internet alternative has been closed: Minitel has fizzled out</a></li>
<li><a href="../147951/index.html">Israel invites you to get acquainted with the industry of innovation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>