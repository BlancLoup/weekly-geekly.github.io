<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>True implementation of a neural network from scratch. Part 2. Recognition of numbers</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dispute about eternal 


 I cordially greet all Habravchan! Since the release of the first part of the "True implementation" (I recommend to get acqua...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>True implementation of a neural network from scratch. Part 2. Recognition of numbers</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/9x/5r/u5/9x5ru502js9cusciz2hns9hvtya.jpeg" alt="image"><br>  <em>Dispute about eternal</em> </p><br><p>  I cordially greet all Habravchan!  Since the release of the first part of the "True implementation" (I <a href="https://habrahabr.ru/post/335052/">recommend to get acquainted</a> ) a lot of time has passed.  There were no intelligible tutorial articles, so I decided to give you the opportunity to learn from A to Z how to write a program for recognizing numbers, due to the fact that my knowledge in this area has increased markedly.  Like last time, I warn you that this article is aimed at those who understand the basics of neural networks, but do not understand how to create their ‚Äúlow-level‚Äù, true implementation.  I invite you under the cat to familiarize yourself with the creation of those who are tired of poor XOR implementations, the general theory, the use of Tensor Flow, and others. Characters: Sharpei, last year's Visual Studio, homemade Data Collection, The embodiment of pure reason and your humble servant ... </p><a name="habracut"></a><br><h2 id="dataset-v-kustarnyh-usloviyah">  DATASET IN HANDLING CONDITIONS </h2><br><p>  So, the choice of the machine learning task is made: pattern recognition, which will be the figure on the 3 by 5 pixel image.  Therefore, the first obvious step is to create a data set even at home.  Having played a little with imagination, I drew on paper a training sample of 100 elements and a test sample of 10, and then transferred it to a digital form using Photoshop.  The GIF shows all the elements of the training sample in order.  It turned out a kind of MNIST on the minimum salary. </p><br><p><img src="https://habrastorage.org/webt/7a/cx/_2/7acx_2ththp6mn10odgvb6bzsam.gif" alt="image"><br>  <em>Going through the whole mothafvckn training set</em> </p><br><p><img src="https://habrastorage.org/webt/_k/8r/qp/_k8rqpx1z1tulont-xckvopg0hm.gif" alt="image"><br>  <em>Going through the whole mothafvckn test set</em> </p><br><h2 id="model">  MODEL </h2><br><p>  And now is the time to create "artificial intelligence".  By tradition, I show a diagram of a multilayer perceptron with an indication of some of its parameters. </p><br><p><img src="https://habrastorage.org/webt/wu/f6/na/wuf6nadxl2ub5nmvl9o8xpgyetw.jpeg" alt="image"></p><br><ul><li><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>f</mi><mi>u</mi><mi>n</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>o</mi><mi>f</mi><mi>n</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="59.279ex" height="2.66ex" viewBox="0 -832 25523 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-28" x="550" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-29" x="1512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="2152" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="2513" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="2980" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="3552" y="0"></use><g transform="translate(3914,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-2212" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="778" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-63" x="1308" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="1741" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-76" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="2934" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="3463" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="3825" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="4170" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="4656" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-66" x="5256" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-75" x="5807" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="6379" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-63" x="6980" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="7413" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="7775" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="8120" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="8606" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="9206" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-66" x="9692" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="10242" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="10843" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-75" x="11309" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-72" x="11882" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="12333" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="12819" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-73" x="13419" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="13889" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-66" x="14374" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="14925" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-68" x="15286" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="15863" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-68" x="16329" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="16906" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-64" x="17251" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-64" x="17775" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="18298" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="18765" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6C" x="19365" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="19664" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-79" x="20193" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="20691" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-72" x="21157" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mo>‚àí</mo><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>f</mi><mi>u</mi><mi>n</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>o</mi><mi>f</mi><mi>n</mi><mi>e</mi><mi>u</mi><mi>r</mi><mi>o</mi><mi>n</mi><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>h</mi><mi>i</mi><mi>d</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-1"> f (x) \ text {- activation function of neurons of the hidden layer} </script></li><li><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>m</mi><mi>u</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mi>l</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.838ex" height="2.419ex" viewBox="0 -780.1 10694 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6D" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-75" x="1128" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="1951" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="2312" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="2779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="3351" y="0"></use><g transform="translate(3713,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-2212" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6C" x="778" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="1077" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="1543" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-72" x="2073" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="2524" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="3125" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="3470" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-67" x="4071" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-73" x="4551" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-70" x="5021" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="5524" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="5991" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-64" x="6457" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>m</mi><mi>u</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mo>‚àí</mo><mi>l</mi><mi>e</mi><mi>a</mi><mi>r</mi><mi>n</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>s</mi><mi>p</mi><mi>e</mi><mi>e</mi><mi>d</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-2"> \ mu \ text {- learning speed} </script></li><li><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>a</mi><mi>l</mi><mi>p</mi><mi>h</mi><mi>a</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mi>m</mi><mi>o</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>o</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>a</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="30.857ex" height="2.419ex" viewBox="0 -780.1 13285.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-70" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-68" x="1581" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="2158" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="2937" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="3299" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="3765" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="4338" y="0"></use><g transform="translate(4699,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-2212" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6D" x="778" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="1657" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6D" x="2142" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="3021" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="3487" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="4088" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6F" x="4449" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-66" x="4935" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="5485" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6E" x="5831" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-65" x="6431" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-72" x="6898" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-74" x="7349" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-69" x="7711" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="8056" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>a</mi><mi>l</mi><mi>p</mi><mi>h</mi><mi>a</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mo>‚àí</mo><mi>m</mi><mi>o</mi><mi>m</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>o</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>a</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ alpha \ text {- moment of inertia} </script></li></ul><br><p>  Naturally, there are 15 inputs, since there are as many pixels in the image.  The output data vector is a set of probabilities that a digit belongs to a particular class, that is, the number of the neuron with the maximum output (when counting from zero) will be the digit drawn in the picture.  For this data format, an activation function, proudly referred to as softmax, is used in the output layer.  At the input it takes a vector, at the output it gives the vector, and its derivative is generally a matrix, but this is NOT IMPORTANT.  Why?  Because there is a <a href="https://www.ics.uci.edu/~pjsadows/notes.pdf">pruflink</a> (see page 3), which I recommend to read.  The activation function of the hidden layer neurons, as can be seen from the figure above, is a leaky rectified linear unit.  I want to talk about it, a little more, since it is almost the best activation function at all.  It is given by the following formula: </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=&quot;false&quot;>(</mo><mi>a</mi><mo>&amp;#x2217;</mo><mi>x</mi><mo>,</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.043ex" height="2.66ex" viewBox="0 -832 9060.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-28" x="550" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-29" x="1512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-3D" x="2179" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-6D" x="3236" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="4114" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="4644" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-28" x="5216" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-61" x="5606" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-2217" x="6357" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="7080" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-2C" x="7653" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMATHI-78" x="8098" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/352632/&amp;xid=17259,15700022,15700186,15700190,15700248,15700253&amp;usg=ALkJrhj69JaFmgjiNdiDK2PrGROvFhWjzA#MJMAIN-29" x="8670" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>a</mi><mo>‚àó</mo><mi>x</mi><mo>,</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-4"> f (x) = max (a * x, x) </script></p><br><p>  And it looks like this: </p><br><p><img src="https://habrastorage.org/webt/fv/kh/be/fvkhbetncfc6ue-miot_jyifmzy.png" alt="image"></p><br><p>  This leads to some thoughts. </p><br><p><img src="https://habrastorage.org/webt/r-/3r/t1/r-3rt1u0zwk-cz4x4s8t5thryyc.jpeg" alt="image"><br>  <em>That is how Xzibit pimped identity activation function</em> </p><br><p>  In fact, it is good for several reasons: </p><br><ul><li>  lack of neuronal overload during training; </li><li>  easy computability for the computer; </li><li>  maximum similarity of behavior with a biological neuron; </li><li>  the fact that the perceptron converges with it faster; </li><li>  unlike the ancestor, ReLU does not "kill" neurons during training. </li></ul><br><h2 id="kod">  CODE </h2><br><p>  Here, dear habrudruzya, you and doberpili to dessert.  And now we program!  More precisely, I will sort out the source code of the perceptron in C # 7 by bone. The namespace for it is called demoapp.Model, and you will find out why the name is such a bit later. </p><br><h3 id="modelenumscs">  ModelEnums.cs </h3><br><pre><code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> MemoryMode<span class="hljs-comment"><span class="hljs-comment">//   { GET, SET } enum NeuronType//  { Hidden, Output } enum NetworkMode//   { Train,// Test,// Demo// } }</span></span></code> </pre> <br><p>  There are several enumerations in this file: the first for accessing XML files for writing / reading weights, the second for determining the type of calculations inside the neuron depending on the type of layer it belongs to, the third for overriding the network. </p><br><h3 id="neuroncs">  Neuron.cs </h3><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> System.Math; <span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Neuron</span></span> { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Neuron</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] inputs, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] weights, NeuronType type</span></span></span><span class="hljs-function">)</span></span> { _type = type; _weights = weights; _inputs = inputs; } <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> NeuronType _type;<span class="hljs-comment"><span class="hljs-comment">//  private double[] _weights;//  private double[] _inputs;//  private double _output;//  private double _derivative; //    private double a = 0.01d; public double[] Weights { get =&gt; _weights; set =&gt; _weights = value; } public double[] Inputs { get =&gt; _inputs; set =&gt; _inputs = value; } public double Output { get =&gt; _output; } public double Derivative { get =&gt; _derivative; } public void Activator(double[] i, double[] w)//  { double sum = w[0];//   ( ) for (int l = 0; l &lt; i.Length; ++l) sum += i[l] * w[l + 1];//  switch (_type) { case NeuronType.Hidden://    _output = LeakyReLU(sum); _derivative = LeakyReLU_Derivativator(sum); break; case NeuronType.Output://    _output = Exp(sum); break; } } private double LeakyReLU(double sum) =&gt; (sum &gt;= 0) ? sum : a * sum; private double LeakyReLU_Derivativator(double sum) =&gt; (sum &gt;= 0) ? 1 : a; } }</span></span></code> </pre> <br><p>  The most important class, as it implements the computing unit of the network, due to which all the "magic" occurs.  The neuron was created according to the McCulloch-Pitts model, with the inclusion of offsets for affine transformations within the activation function.  If the neuron is in the output layer, then an exponential function of the adder is sought as the output.  This is done to implement the softmax function, which is already considered in the layer itself. </p><br><h3 id="inputlayercs">  InputLayer.cs </h3><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">InputLayer</span></span> { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">InputLayer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkMode nm</span></span></span><span class="hljs-function">)</span></span> { System.Drawing.Bitmap bitmap; <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> (nm) { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> NetworkMode.Train: bitmap = Properties.Resources.trainset; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = <span class="hljs-number"><span class="hljs-number">0</span></span>; y &lt; bitmap.Height / <span class="hljs-number"><span class="hljs-number">5</span></span>; ++y) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> x = <span class="hljs-number"><span class="hljs-number">0</span></span>; x &lt; bitmap.Width / <span class="hljs-number"><span class="hljs-number">3</span></span>; ++x) { _trainset[x + y * (bitmap.Width / <span class="hljs-number"><span class="hljs-number">3</span></span>)].Item2 = (<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>)y; _trainset[x + y * (bitmap.Width / <span class="hljs-number"><span class="hljs-number">3</span></span>)].Item1 = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[<span class="hljs-number"><span class="hljs-number">3</span></span> * <span class="hljs-number"><span class="hljs-number">5</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> m = <span class="hljs-number"><span class="hljs-number">0</span></span>; m &lt; <span class="hljs-number"><span class="hljs-number">5</span></span>; ++m) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> n = <span class="hljs-number"><span class="hljs-number">0</span></span>; n &lt; <span class="hljs-number"><span class="hljs-number">3</span></span>; ++n) { _trainset[x + y * (bitmap.Width / <span class="hljs-number"><span class="hljs-number">3</span></span>)].Item1[n + <span class="hljs-number"><span class="hljs-number">3</span></span> * m] = (bitmap.GetPixel(n + <span class="hljs-number"><span class="hljs-number">3</span></span> * x, m + <span class="hljs-number"><span class="hljs-number">5</span></span> * y).R + bitmap.GetPixel(n + <span class="hljs-number"><span class="hljs-number">3</span></span> * x, m + <span class="hljs-number"><span class="hljs-number">5</span></span> * y).G + bitmap.GetPixel(n + <span class="hljs-number"><span class="hljs-number">3</span></span> * x, m + <span class="hljs-number"><span class="hljs-number">5</span></span> * y).B) / (<span class="hljs-number"><span class="hljs-number">765.0</span></span>d); } } <span class="hljs-comment"><span class="hljs-comment">//    - for (int n = Trainset.Length - 1; n &gt;= 1; --n) { int j = random.Next(n + 1); (double[], byte) temp = _trainset[n]; _trainset[n] = _trainset[j]; _trainset[j] = temp; } break; case NetworkMode.Test: bitmap = Properties.Resources.testset; for (int y = 0; y &lt; bitmap.Height / 5; ++y) for (int x = 0; x &lt; bitmap.Width / 3; ++x) { _testset[x + y * (bitmap.Width / 3)] = new double[3 * 5]; for (int m = 0; m &lt; 5; ++m) for (int n = 0; n &lt; 3; ++n) { _trainset[x + y * (bitmap.Width / 3)].Item1[n + 3 * m] = (bitmap.GetPixel(n + 3 * x, m + 5 * y).R + bitmap.GetPixel(n + 3 * x, m + 5 * y).G + bitmap.GetPixel(n + 3 * x, m + 5 * y).B) / (765.0d); } } break; } } private System.Random random = new System.Random(); private (double[], byte)[] _trainset = new(double[], byte)[100];//100     public (double[], byte)[] Trainset { get =&gt; _trainset; } private double[][] _testset = new double[10][];//10     public double[][] Testset { get =&gt; _testset; } } }</span></span></code> </pre> <br><p>  This code reads the pixels of images with training and test samples.  The mixing of the training set occurs to improve the quality of training, since the examples are initially arranged in order from 0 to 9. </p><br><h3 id="layercs">  Layer.cs </h3><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> System.Xml; <span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">abstract</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Layer</span></span><span class="hljs-comment"><span class="hljs-comment">// protected       {//type          protected Layer(int non, int nopn, NeuronType nt, string type) {//   WeightInitialize numofneurons = non; numofprevneurons = nopn; Neurons = new Neuron[non]; double[,] Weights = WeightInitialize(MemoryMode.GET, type); lastdeltaweights = Weights; for (int i = 0; i &lt; non; ++i) { double[] temp_weights = new double[nopn + 1]; for (int j = 0; j &lt; nopn + 1; ++j) temp_weights[j] = Weights[i, j]; Neurons[i] = new Neuron(null, temp_weights, nt);//  null    } } protected int numofneurons;//    protected int numofprevneurons;//    protected const double learningrate = 0.005d;//  protected const double momentum = 0.03d;//  protected double[,] lastdeltaweights;//    Neuron[] _neurons;//    public Neuron[] Neurons { get =&gt; _neurons; set =&gt; _neurons = value; } public double[] Data//  null   ,   {//     set//(, , etc.) {//  input'     , for (int i = 0; i &lt; Neurons.Length; ++i) { Neurons[i].Inputs = value; Neurons[i].Activator(Neurons[i].Inputs, Neurons[i].Weights); } }//       } public double[,] WeightInitialize(MemoryMode mm, string type) { double[,] _weights = new double[numofneurons, numofprevneurons + 1]; XmlDocument memory_doc = new XmlDocument(); memory_doc.Load(System.IO.Path.Combine("Resources", $"{type}_memory.xml")); XmlElement memory_el = memory_doc.DocumentElement; switch (mm) { case MemoryMode.GET: for (int l = 0; l &lt; _weights.GetLength(0); ++l) for (int k = 0; k &lt; _weights.GetLength(1); ++k) _weights[l, k] = double.Parse(memory_el.ChildNodes.Item(k + _weights.GetLength(1) * l).InnerText.Replace(',', '.'), System.Globalization.CultureInfo.InvariantCulture);//parsing stuff break; case MemoryMode.SET: for (int l = 0; l &lt; numofneurons; ++l) for (int k = 0; k &lt; numofprevneurons + 1; ++k) memory_el.ChildNodes.Item(k + (numofprevneurons + 1) * l).InnerText = Neurons[l].Weights[k].ToString(); break; } memory_doc.Save(System.IO.Path.Combine("Resources", $"{type}_memory.xml")); return _weights; } abstract public void Recognize(Network net, Layer nextLayer);//   abstract public double[] BackwardPass(double[] stuff);//  } }</span></span></code> </pre> <br><p>  This class is engaged in the initialization of network layers.  Since the writing of the previous article has not changed. </p><br><h3 id="hiddenlayercs">  HiddenLayer.cs </h3><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">HiddenLayer</span></span> : <span class="hljs-title"><span class="hljs-title">Layer</span></span> { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">HiddenLayer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> non, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> nopn, NeuronType nt, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> type</span></span></span><span class="hljs-function">) : </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">base</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">non, nopn, nt, type</span></span></span><span class="hljs-function">)</span></span> { } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Recognize</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Network net, Layer nextLayer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[] hidden_out = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[Neurons.Length]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; Neurons.Length; ++i) hidden_out[i] = Neurons[i].Output; nextLayer.Data = hidden_out; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">double</span></span></span><span class="hljs-function">[] </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">BackwardPass</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] gr_sums</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[] gr_sum = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[numofprevneurons]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; gr_sum.Length; ++j) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> sum = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> k = <span class="hljs-number"><span class="hljs-number">0</span></span>; k &lt; Neurons.Length; ++k) sum += Neurons[k].Weights[j] * Neurons[k].Derivative * gr_sums[k];<span class="hljs-comment"><span class="hljs-comment">//     gr_sum[j] = sum; } for (int i = 0; i &lt; numofneurons; ++i) for (int n = 0; n &lt; numofprevneurons + 1; ++n) { double deltaw = (n == 0) ? (momentum * lastdeltaweights[i, 0] + learningrate * Neurons[i].Derivative * gr_sums[i]) : (momentum * lastdeltaweights[i, n] + learningrate * Neurons[i].Inputs[n - 1] * Neurons[i].Derivative * gr_sums[i]); lastdeltaweights[i, n] = deltaw; Neurons[i].Weights[n] += deltaw;//  } return gr_sum; } } }</span></span></code> </pre> <br><p>  Regarding the previous project, the innovation is the inclusion of the moment of inertia in the correction of weights.  Also, due to the difference in unit sizes of the arrays of the inputs and weights of the neuron, caused by the appearance of offsets, the separation of the synapse update and offset through the ternary operator is written. </p><br><h3 id="outputlayercs">  OutputLayer.cs </h3><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">OutputLayer</span></span> : <span class="hljs-title"><span class="hljs-title">Layer</span></span> { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OutputLayer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> non, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> nopn, NeuronType nt, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> type</span></span></span><span class="hljs-function">) : </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">base</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">non, nopn, nt, type</span></span></span><span class="hljs-function">)</span></span> { } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Recognize</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Network net, Layer nextLayer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> e_sum = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; Neurons.Length; ++i) e_sum += Neurons[i].Output; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; Neurons.Length; ++i) net.fact[i] = Neurons[i].Output / e_sum; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">double</span></span></span><span class="hljs-function">[] </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">BackwardPass</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] errors</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[] gr_sum = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[numofprevneurons + <span class="hljs-number"><span class="hljs-number">1</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; gr_sum.Length; ++j)<span class="hljs-comment"><span class="hljs-comment">//     { double sum = 0; for (int k = 0; k &lt; Neurons.Length; ++k) sum += Neurons[k].Weights[j] * errors[k]; gr_sum[j] = sum; } for (int i = 0; i &lt; numofneurons; ++i) for (int n = 0; n &lt; numofprevneurons + 1; ++n) { double deltaw = (n == 0) ? (momentum * lastdeltaweights[i, 0] + learningrate * errors[i]) : (momentum * lastdeltaweights[i, n] + learningrate * Neurons[i].Inputs[n - 1] * errors[i]); lastdeltaweights[i, n] = deltaw; Neurons[i].Weights[n] += deltaw;//  } return gr_sum; } } }</span></span></code> </pre> <br><p>  From the listing it is clear that softmax is considered in the Recognize method, and quite elegantly due to the fact that the values ‚Äã‚Äãof the exponential functions were already counted in neurons.  You can also see the feature of calculating the gradient of neurons, which lies in its simplicity, since it is equal to the difference between the desired response and the actual one.  This is caused by the use of softmax as an activation function of the neurons of the output layer. </p><br><h3 id="networkcs">  Network.cs </h3><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> <span class="hljs-title"><span class="hljs-title">demoapp.Model</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Network</span></span> { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Network</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkMode nm</span></span></span><span class="hljs-function">)</span></span> =&gt; input_layer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> InputLayer(nm); <span class="hljs-comment"><span class="hljs-comment">//   private InputLayer input_layer = null; public HiddenLayer hidden_layer1 = new HiddenLayer(70, 15, NeuronType.Hidden, nameof(hidden_layer1)); public HiddenLayer hidden_layer2 = new HiddenLayer(30, 70, NeuronType.Hidden, nameof(hidden_layer2)); public OutputLayer output_layer = new OutputLayer(10, 30, NeuronType.Output, nameof(output_layer)); //     public double[] fact = new double[10]; //  public void Train(Network net)//backpropagation method { int epoches = 1200; for (int k = 0; k &lt; epoches; ++k) { for (int i = 0; i &lt; net.input_layer.Trainset.Length; ++i) { //  ForwardPass(net, net.input_layer.Trainset[i].Item1); //    double[] errors = new double[net.fact.Length]; for (int x = 0; x &lt; errors.Length; ++x) { errors[x] = (x == net.input_layer.Trainset[i].Item2) ? -(net.fact[x] - 1.0d) : -net.fact[x]; } //     double[] temp_gsums1 = net.output_layer.BackwardPass(errors); double[] temp_gsums2 = net.hidden_layer2.BackwardPass(temp_gsums1); net.hidden_layer1.BackwardPass(temp_gsums2); } } //    "" net.hidden_layer1.WeightInitialize(MemoryMode.SET, nameof(hidden_layer1)); net.hidden_layer2.WeightInitialize(MemoryMode.SET, nameof(hidden_layer2)); net.output_layer.WeightInitialize(MemoryMode.SET, nameof(output_layer)); } //  public void Test(Network net) { for (int i = 0; i &lt; net.input_layer.Testset.Length; ++i) ForwardPass(net, net.input_layer.Testset[i]); } public void ForwardPass(Network net, double[] netInput) { net.hidden_layer1.Data = netInput; net.hidden_layer1.Recognize(null, net.hidden_layer2); net.hidden_layer2.Recognize(null, net.output_layer); net.output_layer.Recognize(net, null); } } }</span></span></code> </pre> <br><p>  The class is the "constructor" of the network, because it gathers all the layers together and is engaged in its training and testing.  At this time, learning stops at the achievement of the final era.  By the way, the input of the network constructor is its mode of operation in order to determine whether to initialize the input layer or not, since initialization is not required for the demonstration mode of operation. </p><br><h3 id="sobiraem-vse-komponenty-vse-vmeste">  Putting it all together </h3><br><p>  Initially, I coached the network in a console application for debugging some of its parameters, then to demonstrate the operation I threw in a simple MVP WinForms application with the ability to draw my figure, where I used the weights written in XML.  All the perceptron code for beauty is divided according to the principle "one file == one class" and placed in the Model folder, hence the name namespace'a - demoapp.Model.  As a result, I received such nyashnost: </p><br><p><img src="https://habrastorage.org/webt/sr/cw/zp/srcwzp1vqck-m5em0jn6iecrs0q.png" alt="image"></p><br><p>  The MessageBox displays the sequence number of the neuron of the output layer with the maximum output value by the next line using the LINQ methods in the application's View component: </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[] NetOutput { <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> =&gt; MessageBox.Show(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.ToList().IndexOf(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.Max()).ToString()); }</code> </pre> <br><h2 id="itog">  Total </h2><br><p>  Today, thanks to me, you have dealt with another "Hello World" from the world of machine learning at the lowest level of implementation.  It was an interesting experience for me and, I hope, for you.  In the next article for this kid I will screw OpenCL so that everything will fly at all!  So thank you for your attention!  Wait for the next article from the educational cycle "True implementation of a neural network from scratch." </p><br><h3 id="ps">  PS </h3><br><p>  For those who want more communication with this code, leave a <a href="https://github.com/Stepami/Recognitor">link to Github</a> . </p><br><h3 id="pps">  Pps </h3><br><p>  I declare a contest for the reader's attention.  Anyone who writes in the comments what critical error I made while programming the neural network from the previous article (although it worked, but it was pure luck) will get a nice bun. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/352632/">https://habr.com/ru/post/352632/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../352622/index.html">Performance analysis of the drive Intel Optane SSD 750GB</a></li>
<li><a href="../352624/index.html">The Metrix has you ...</a></li>
<li><a href="../352626/index.html">Storage options for cryptographic keys</a></li>
<li><a href="../352628/index.html">Rumors about the cancellation of the Kotelnikov theorem are greatly exaggerated</a></li>
<li><a href="../352630/index.html">As Google Adwords experts helped me to throw away 150,000 UAH (about $ 6000) per month or why I will not ...</a></li>
<li><a href="../352634/index.html">Network Optimization for Unreal Engine 4</a></li>
<li><a href="../352636/index.html">20 modules for Node.js, which is useful to know</a></li>
<li><a href="../352640/index.html">The golden rule of git rebase</a></li>
<li><a href="../352644/index.html">GitLab 10.6 released: CI / CD for GitHub and in-depth integration with Kubernetes</a></li>
<li><a href="../352646/index.html">3CX voice application development: an introduction for beginners</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>