<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Meet loop fracking</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The purpose of this work is to designate another cycle optimization technique. At the same time there is no task to focus on any existing architecture...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Meet loop fracking</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/d49/877/7f4/d498777f45d14639b27612b3911c5b51.png" alt="image"><br><br>  The purpose of this work is to designate another cycle optimization technique.  At the same time there is no task to focus on any existing architecture, but, on the contrary, we will try to act as abstract as possible, relying mainly on common sense. <br><br>  The author called this technique ‚Äúloops fracking‚Äù by analogy with, for example, ‚Äú <a href="https://en.wikipedia.org/wiki/Loop_unrolling">loops unrolling</a> ‚Äù or <a href="https://en.wikipedia.org/wiki/Loop_nest_optimization">‚Äúloops nesting</a> ‚Äù.  Moreover, the term reflects the meaning and is not busy. <br><a name="habracut"></a><br>  Cycles are the main object for optimization; it is in cycles that most programs spend most of their time.  There are a sufficient number of optimization techniques, you can read them <a href="https://en.wikipedia.org/wiki/Loop_optimization">here</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  Key resources for optimization </h3><br><ol><li>  Savings on the logic of the end of the cycle.  Checking the end of cycle criteria leads to branching, branching ‚Äúbreaks the conveyor‚Äù, let's check less often.  As a result, <a href="https://en.wikipedia.org/wiki/Duff%2527s_device">nice</a> code samples appear, for example, <a href="https://en.wikipedia.org/wiki/Duff%2527s_device">Duf's device</a> . <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *to, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *from, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> n = (count + <span class="hljs-number"><span class="hljs-number">7</span></span>) / <span class="hljs-number"><span class="hljs-number">8</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span> (count % <span class="hljs-number"><span class="hljs-number">8</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span>: *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span>: *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span>: *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span>: *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span>: *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span>: *to = *from++; <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>: *to = *from++; } <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (--n &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>); } }</code> </pre> <br>  At the moment, <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">predictors of transitions</a> (where they are) in processors have made this optimization ineffective. <br></li><li>  Carrying out loop invariants for brackets ( <a href="http://www.compileroptimizations.com/category/hoisting.htm">hoisting</a> ). <br></li><li>  Optimization of work with memory for more efficient operation of the memory cache.  If there are references in the cycle to the amount of memory that is known to exceed the amount of cache memory, it becomes important in what order these calls go.  Apart from obvious cases, it is difficult for the compiler to deal with this, sometimes another algorithm is actually written to achieve the effect.  Therefore, this optimization falls on the shoulders of application programmers.  A compiler / profiler can provide statistics, give hints ... feedback. <br></li><li>  Use of (explicit or implicit) processor parallelism.  Modern processors are able to execute code in parallel. <br><br>  In the case of an explicitly parallel architecture ( <a href="https://en.wikipedia.org/wiki/Explicitly_parallel_instruction_computing">EPIC</a> , <a href="https://en.wikipedia.org/wiki/Very_long_instruction_word">VLIW</a> ), one instruction may contain several instructions (which will be executed in parallel) affecting different functional blocks. <br><br>  <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">Superscalar</a> processors independently parse the flow of instructions, seek out concurrency and use it whenever possible. <br><br><img src="https://habrastorage.org/storage2/ba5/d7d/cf3/ba5d7dcf3d2118971c1c248934ea2b59.gif" alt="image"><br>  <i><a href="http://habrahabr.ru/company/intel/blog/147108/">Schematic diagram of superscalar command execution</a></i> <br><br>  Another option is vector operations, <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">SIMD</a> . <br></li></ol><br>  Now we are just looking for a way to maximize the use of processor parallelism (s). <br><br><h3>  What we have </h3><br>  To begin with, let's take a look at a few simple examples, using MSVS-2013 (x64) on an <a href="http://www.ixbt.com/cpu/sandy-bridge-1.shtml">Intel Core-i7 2600 processor</a> for the experiments.  By the way, GCC is able to do the same and not worse, at least with such simple examples. <br><br>  The simplest loop is calculating the sum of an integer array. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> data[<span class="hljs-number"><span class="hljs-number">100000</span></span>]; ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> sum = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> val : data) { sum += val; }</code> </pre><br>  This is what makes the compiler out of it: <br><br><pre> <code class="cpp hljs"> lea rsi,[data] mov ebp,<span class="hljs-number"><span class="hljs-number">186</span></span>A0h ;<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">000</span></span> mov r14d,ebp ... xor edi,edi mov edx,edi nop dword ptr [rax+rax] ;  loop_start: add rdx,qword ptr [rsi] lea rsi,[rsi+<span class="hljs-number"><span class="hljs-number">8</span></span>] dec rbp jne loop_start</code> </pre><br>  The same, but with doubles (AVX, <a href="https://msdn.microsoft.com/en-us/library/e7s85ffb.aspx">/ fp: precise</a> &amp; / fp: strict - ANSI compatibility): <br><br><pre> <code class="cpp hljs"> vxorps xmm1,xmm1,xmm1 lea rax,[data] mov ecx,<span class="hljs-number"><span class="hljs-number">186</span></span>A0h nop dword ptr [rax+rax] loop_start: vaddsd xmm1,xmm1,mmword ptr [rax] lea rax,[rax+<span class="hljs-number"><span class="hljs-number">8</span></span>] dec rcx jne loop_start</code> </pre><br>  A million times this code is executed in 85 seconds. <br><br>  No work of the compiler to identify parallelism is visible here, although it would seem that it is evident in the problem.  The compiler found a dependency in the data and could not bypass it. <br><br>  The same, but (AVX, / fp: fast - without ANSI - compatibility): <br><br><pre> <code class="cpp hljs"> vxorps ymm2,ymm0,ymm0 lea rax,[data] mov ecx,<span class="hljs-number"><span class="hljs-number">30</span></span>D4h ; <span class="hljs-number"><span class="hljs-number">12500</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">8</span></span> vmovupd ymm3,ymm2 loop_start: vaddpd ymm1,ymm3,ymmword ptr [rax+<span class="hljs-number"><span class="hljs-number">20</span></span>h] ; SIMD vaddpd ymm2,ymm2,ymmword ptr [rax] lea rax,[rax+<span class="hljs-number"><span class="hljs-number">40</span></span>h] vmovupd ymm3,ymm1 dec rcx jne loop_start vaddpd ymm0,ymm1,ymm2 vhaddpd ymm2,ymm0,ymm0 vmovupd ymm0,ymm2 vextractf128 xmm4,ymm2,<span class="hljs-number"><span class="hljs-number">1</span></span> vaddpd xmm0,xmm4,xmm0 vzeroupper</code> </pre><br>  It takes 26 seconds, using vector operations. <br><br>  The same cycle, but in the traditional C style: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">100000</span></span>; i ++) { sum += data[i]; }</code> </pre><br>  We get unexpectedly for (/ fp: precise): <br><br><pre> <code class="cpp hljs"> vxorps xmm4,xmm4,xmm4 lea rax,[data+<span class="hljs-number"><span class="hljs-number">8</span></span>h] lea rcx,[piecewise_construct+<span class="hljs-number"><span class="hljs-number">2</span></span>h] vmovups xmm0,xmm4 nop word ptr [rax+rax] loop_start: vaddsd xmm0,xmm0,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-8</span></span>] add rax,<span class="hljs-number"><span class="hljs-number">50</span></span>h vaddsd xmm1,xmm0,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-50</span></span>h] vaddsd xmm2,xmm1,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-48</span></span>h] vaddsd xmm3,xmm2,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-40</span></span>h] vaddsd xmm0,xmm3,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-38</span></span>h] vaddsd xmm1,xmm0,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-30</span></span>h] vaddsd xmm2,xmm1,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-28</span></span>h] vaddsd xmm3,xmm2,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-20</span></span>h] vaddsd xmm0,xmm3,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-18</span></span>h] vaddsd xmm0,xmm0,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-10</span></span>h] cmp rax,rcx jl loop_start</code> </pre><br>  There is no parallelism, just an attempt to save on maintenance cycle.  This code is executed 87 seconds.  For / fp: fast, the code has not changed. <br><br>  Let's tell the compiler using <a href="https://en.wikipedia.org/wiki/Loop_nest_optimization">loop nesting</a> . <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> data[<span class="hljs-number"><span class="hljs-number">100000</span></span>]; ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> sum = <span class="hljs-number"><span class="hljs-number">0</span></span>, sum1 = <span class="hljs-number"><span class="hljs-number">0</span></span>, sum2 = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ix = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">100000</span></span>; i+=<span class="hljs-number"><span class="hljs-number">2</span></span>) { sum1 += data[i]; sum2 += data[i+<span class="hljs-number"><span class="hljs-number">1</span></span>]; } sum = sum1 + sum2;</code> </pre><br>  We get exactly what we asked for, and the code is the same for the / fp: fast &amp; / fp: precise options.  <a href="http://felixcloutier.com/x86/ADDSD.html">Vaddsd</a> operations on some processors (AMD bulldozer) can be performed in parallel. <br><br><pre> <code class="cpp hljs"> vxorps xmm0,xmm0,xmm0 vmovups xmm1,xmm0 lea rax,[data+<span class="hljs-number"><span class="hljs-number">8</span></span>h] lea rcx,[piecewise_construct+<span class="hljs-number"><span class="hljs-number">2</span></span>h] nop dword ptr [rax] nop word ptr [rax+rax] loop_start: vaddsd xmm0,xmm0,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-8</span></span>] vaddsd xmm1,xmm1,mmword ptr [rax] add rax,<span class="hljs-number"><span class="hljs-number">10</span></span>h cmp rax,rcx jl loop_start</code> </pre><br>  A million times this code is executed in 43 seconds, twice as fast as the ‚Äúnaive and accurate‚Äù approach. <br><br>  At a step of 4 elements, the code looks like this (again, the same for the / fp: fast &amp; / fp: precise compiler options) <br><br><pre> <code class="cpp hljs"> vxorps xmm0,xmm0,xmm0 vmovups xmm1,xmm0 vmovups xmm2,xmm0 vmovups xmm3,xmm0 lea rax,[data+<span class="hljs-number"><span class="hljs-number">8</span></span>h] lea rcx,[piecewise_construct+<span class="hljs-number"><span class="hljs-number">2</span></span>h] nop dword ptr [rax] loop_start: vaddsd xmm0,xmm0,mmword ptr [rax<span class="hljs-number"><span class="hljs-number">-8</span></span>] vaddsd xmm1,xmm1,mmword ptr [rax] vaddsd xmm2,xmm2,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">8</span></span>] vaddsd xmm3,xmm3,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">10</span></span>h] add rax,<span class="hljs-number"><span class="hljs-number">20</span></span>h cmp rax,rcx jl loop_start vaddsd xmm0,xmm1,xmm0 vaddsd xmm1,xmm0,xmm2 vaddsd xmm1,xmm1,xmm3</code> </pre><br>  This code is executed a million times in 34 seconds.  In order to guarantee vector calculations, you will have to resort to different tricks, like this: <br><br><ol><li>  write pragma compiler hints: <a href="https://software.intel.com/en-us/node/583414">#pragma ivdep</a> ( <a href="https://msdn.microsoft.com/ru-ru/library/vstudio/hh923901(v%3Dvs.120).aspx">#pragma loop (ivdep)</a> , # <a href="https://gcc.gnu.org/onlinedocs/gcc-4.9.2/gcc/Loop-Specific-Pragmas.html">pragma GCC ivdep</a> ), #pragma vector always, #pragma omp simd ... and hope that the compiler will not ignore them <br></li><li>  use <a href="https://msdn.microsoft.com/en-us/library/hh977022.aspx">intrinsic</a> 'and - instructions to the compiler, what instructions to use, for example, the summation of two arrays might look like <a href="http://habrahabr.ru/company/intel/blog/205552/">this</a> : <br></li></ol><br>  As if all this is not very fit with the bright image of ‚Äúhigh-level language‚Äù. <br><br>  On the one hand, if necessary, to obtain a result, the indicated optimization is not at all a burden.  On the other hand, the problem of portability arises.  Suppose a program was written and debugged for a processor with four adders.  Then, when trying to execute it on a processor version with 6 adders, we will not get the expected gain. <br><br>  And on the version with three - we get a slowdown by 2 times, and not by a quarter, as we would like. <br><br>  Finally, let's calculate the sum of squares (/ fp: precise): <br><br><pre> <code class="cpp hljs"> vxorps xmm2,xmm2,xmm2 lea rax,[data+<span class="hljs-number"><span class="hljs-number">8</span></span>h] ; pdata = &amp;data[<span class="hljs-number"><span class="hljs-number">1</span></span>] mov ecx,<span class="hljs-number"><span class="hljs-number">2710</span></span>h ; <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">000</span></span> nop dword ptr [rax+rax] loop_start: vmovsd xmm0,qword ptr [rax<span class="hljs-number"><span class="hljs-number">-8</span></span>] ; xmm0 = pdata[<span class="hljs-number"><span class="hljs-number">-1</span></span>] vmulsd xmm1,xmm0,xmm0 ; xmm1 = pdata[<span class="hljs-number"><span class="hljs-number">-1</span></span>] ** <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm3,xmm2,xmm1 ; xmm3 = <span class="hljs-number"><span class="hljs-number">0</span></span> + pdata[<span class="hljs-number"><span class="hljs-number">-1</span></span>] ** <span class="hljs-number"><span class="hljs-number">2</span></span> ; sum vmovsd xmm2,qword ptr [rax] ; xmm2 = pdata[<span class="hljs-number"><span class="hljs-number">0</span></span>] vmulsd xmm0,xmm2,xmm2 ; xmm0 = pdata[<span class="hljs-number"><span class="hljs-number">0</span></span>] ** <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm4,xmm3,xmm0 ; xmm4 = sum + pdata[<span class="hljs-number"><span class="hljs-number">0</span></span>] ** <span class="hljs-number"><span class="hljs-number">2</span></span> ; sum vmovsd xmm1,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">8</span></span>] ; xmm1 = pdata[<span class="hljs-number"><span class="hljs-number">1</span></span>] vmulsd xmm2,xmm1,xmm1 ; xmm2 = pdata[<span class="hljs-number"><span class="hljs-number">1</span></span>] ** <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm3,xmm4,xmm2 ; xmm3 = sum + pdata[<span class="hljs-number"><span class="hljs-number">1</span></span>] ** <span class="hljs-number"><span class="hljs-number">2</span></span> ; sum vmovsd xmm0,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">10</span></span>h] ; ... vmulsd xmm1,xmm0,xmm0 vaddsd xmm4,xmm3,xmm1 vmovsd xmm2,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">18</span></span>h] vmulsd xmm0,xmm2,xmm2 vaddsd xmm3,xmm4,xmm0 vmovsd xmm1,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">20</span></span>h] vmulsd xmm2,xmm1,xmm1 vaddsd xmm4,xmm3,xmm2 vmovsd xmm0,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">28</span></span>h] vmulsd xmm1,xmm0,xmm0 vaddsd xmm3,xmm4,xmm1 vmovsd xmm2,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">30</span></span>h] vmulsd xmm0,xmm2,xmm2 vaddsd xmm4,xmm3,xmm0 vmovsd xmm1,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">38</span></span>h] vmulsd xmm2,xmm1,xmm1 vaddsd xmm3,xmm4,xmm2 vmovsd xmm0,qword ptr [rax+<span class="hljs-number"><span class="hljs-number">40</span></span>h] vmulsd xmm1,xmm0,xmm0 vaddsd xmm2,xmm3,xmm1 ; xmm2 = sum; lea rax,[rax+<span class="hljs-number"><span class="hljs-number">50</span></span>h] dec rcx jne loop_start</code> </pre><br>  The compiler again cuts the cycle into pieces of 10 elements in order to save on the logic of the cycle, while it costs 5 registers - one for the sum and a pair for each of the two parallel branches of multiplications. <br><br>  Or like this for / fp: fast: <br><br><pre> <code class="cpp hljs"> vxorps ymm4,ymm0,ymm0 lea rax,[data] mov ecx,<span class="hljs-number"><span class="hljs-number">30</span></span>D4h ;<span class="hljs-number"><span class="hljs-number">12500</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">8</span></span> loop_start: vmovupd ymm0,ymmword ptr [rax] lea rax,[rax+<span class="hljs-number"><span class="hljs-number">40</span></span>h] vmulpd ymm2,ymm0,ymm0 ; SIMD vmovupd ymm0,ymmword ptr [rax<span class="hljs-number"><span class="hljs-number">-20</span></span>h] vaddpd ymm4,ymm2,ymm4 vmulpd ymm2,ymm0,ymm0 vaddpd ymm3,ymm2,ymm5 vmovupd ymm5,ymm3 dec rcx jne loop_start vaddpd ymm0,ymm3,ymm4 vhaddpd ymm2,ymm0,ymm0 vmovupd ymm0,ymm2 vextractf128 xmm4,ymm2,<span class="hljs-number"><span class="hljs-number">1</span></span> vaddpd xmm0,xmm4,xmm0 vzeroupper</code> </pre><br>  Summary table: <br><br><table><tbody><tr><td></td><td>  MSVC, / fp: strict, / fp: precise, sec </td><td>  MSVC, / fp: fast, sec </td></tr><tr><td>  foreach </td><td>  85 </td><td>  26 </td></tr><tr><td>  C style cycle </td><td>  87 </td><td>  26 </td></tr><tr><td>  C style nesting X2 </td><td>  43 </td><td>  43 </td></tr><tr><td>  C style nesting X4 </td><td>  34 </td><td>  34 </td></tr></tbody></table><br>  How to explain these numbers? <br><br>  It is worth noting that only the developers of the processor know the true picture of what is happening, we can only make guesses. <br><br>  The first thought that the acceleration takes place at the expense of several independent adders seems to be wrong.  The i7-2600 processor has one vector adder that cannot perform independent scalar operations. <br><br>  Processor clock frequency - up to 3.8 GHz.  85 sec of a simple cycle gives us (a million times 100,000 additions) ~ 3 clocks per iteration.  This is in good agreement with the data ( <a href="">1</a> , <a href="http://agner.org/optimize/instruction_tables.pdf">2</a> ) about 3 cycles for the execution of the vector instruction vaddpd (even if we add scalars).  Since there is a data dependency, it is impossible to perform an iteration faster than 3 cycles. <br><br>  In the case of nesting (X2) there is no dependence on the data inside the iteration and it is possible to load the adder's conveyor with a difference in time.  But in the next iteration, data dependencies also arise with a difference in tact, as a result, we have an acceleration of 2 times. <br><br>  In the case of nesting (X4), the adder's conveyor is also loaded in increments of time, but acceleration 3 times (due to the length of the conveyor) does not occur, an additional factor interferes.  For example, the loop iteration no longer fits in the <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">L0m</a> cache <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">line</a> and gets the penalty time (s). <br><br>  <b>So:</b> <br><br><ul><li>  With the compilation model / fp: fast, the simplest source code gives the fastest version of the code, which is logical because  we are dealing with high level language. </li><li>  manual optimizations in the spirit of nesting give a good result for the model / fp: precise, but only hinder the compiler when using / fp: fast </li><li>  manual optimizations are more portable than vectorized code </li></ul><br><h3>  A little bit about compilers </h3><br>  Register architectures provide a simple and versatile way to get acceptable code from portable text in high-level languages.  Compilation can be divided into several steps: <br><br><ol><li>  Syntax analysis.  At this stage, a syntactically controlled translation is performed, static checks are performed.  At the output, we have a tree ( <a href="https://ru.wikipedia.org/wiki/%25D0%259D%25D0%25B0%25D0%25BF%25D1%2580%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B0%25D1%2586%25D0%25B8%25D0%25BA%25D0%25BB%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584">DAG</a> ) parsing. <br></li><li>  Generate intermediate code.  If desired, the generation of intermediate code can be combined with the syntax analysis. <br>  Moreover, when using <a href="https://en.wikipedia.org/wiki/Three-address_code">three-address</a> instructions as an intermediate code, this step becomes trivial because "the <a href="http://dic.academic.ru/dic.nsf/ruwiki/971665">three-address code is a linearized representation of a syntax tree or a dag, in which explicit names correspond to the internal nodes of the graph</a> ". <br><br>  In essence, the three-address code is intended for a virtual processor with an infinite number of registers. <br><br></li><li>  Code generation  The result of this step is a program for the target architecture.  Since the real number of registers is limited and small, at this stage we must determine which temporary variables will be in the registers at each moment, and distribute them to specific registers.  Even in its pure form, this task is NP-complete; in addition, the matter is complicated by the fact that there are usually various restrictions on the use of registers.  However, acceptable heuristics have been developed to solve this problem.  In addition, the three-address (or its equivalents) code gives us a formal apparatus for analyzing data flows, optimizing, removing useless code, ... <br></li></ol><br>  Problems appear: <br><br><ol><li>  To solve the NP-complete <a href="https://en.wikipedia.org/wiki/Register_allocation">register allocation</a> problem, heuristics are used and this gives an acceptable quality code.  These heuristics do not like additional restrictions on the use of memory or registers.  For example, split (interlaced) memory, implicit use of registers by instructions, vector operations, register rings ... They do not like the fact that heuristics can stop working and building close to optimal code ceases to be a problem solved in a universal way. <br><br>  As a result, the (vector?) Capabilities of the processor can only be used when the compiler has recognized a typical situation from the set that it has been taught. <br></li><li>  Scaling problem.  The allocation of registers is done statically, if we try to execute the compiled code on a processor with the same instruction set, but with a large number of registers, there will be no gain. <br><br>  This also applies to <a href="https://en.wikipedia.org/wiki/SPARC">SPARC</a> with its register window stack, for which a greater number of registers leads only to the fact that a larger number of call frames fit into the register pool, which reduces the frequency of memory accesses. <br><br>  <a href="https://ru.wikipedia.org/wiki/EPIC_(%25D0%25B0%25D1%2580%25D1%2585%25D0%25B8%25D1%2582%25D0%25B5%25D0%25BA%25D1%2582%25D1%2583%25D1%2580%25D0%25B0_%25D0%25BC%25D0%25B8%25D0%25BA%25D1%2580%25D0%25BE%25D0%25BF%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581%25D0%25BE%25D1%2580%25D0%25B0)">EPIC</a> - an attempt was made in the direction of scaling - ‚ÄúEach group of several instructions is called a bundle.  Each bundle may have a stop bit, indicating that the next group depends on the results of the work of this.  Such a bit allows you to create future generations of architecture with the ability to run multiple bundles in parallel.  Dependency information is computed by the compiler, and therefore the hardware will not have to perform additional verification of the operand independence. ‚ÄùIt was assumed that independent bundles can be executed in parallel, and the more executing devices in the system, the more extensive the internal program parallelism can be used.  On the other hand, such features do not always give a gain, in any case, for the summation of the array, this seems to the author to be useless. <br><br>  Superscalar processors solve a problem by introducing ‚Äúregisters for us‚Äù and ‚Äúregisters in themselves‚Äù.  The compiler focuses on the number of the first ones when it writes (allocates) registers.  The number of the second can be any, usually several times more than the first.  In the decoding process, the superscalar processor re-paints the registers based on their actual number within the window in the program body.  The window size is determined by the complexity of the logic that the processor can afford.  In addition to the number of registers, of course, functional devices are subject to scaling. <br></li><li>  Compatibility issue.  Of particular note are the X84-64 and the technology line - <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">SSE</a> - SSE2 - SSE3 - SSSE3 - SSE4 - AVX - AVX2 - AVX512 - ... <br><br>  Compatibility from top to bottom (i.e., the code is compiled for older technology, and I want to execute on lower processors) can be provided in one way - by generating code for each mentioned technology and choosing the right branch for execution in runtime.  It does not sound very attractive. <br><br>  Bottom-up compatibility is provided by the processor.  This compatibility ensures that the code is executable, but does not promise its effective execution.  For example, if the code is compiled for technology with two independent adders, and is executed on a processor with 4, only two of them will actually be used.  Generating several branches of code for different technologies does not solve the problems of future technologies, planned or not. <br></li></ol><br><h3>  A look at the cycles </h3><br>  Consider the same task, the summation of the array.  Imagine this summation as the calculation of a single expression.  Since we use binary addition, the expression can be represented as a binary tree, and due to the associativity of summation, there are many such trees. <br><br>  The calculation is performed when going around the tree to the left from the left to the right.  Normal summation looks like a left-growing tree degenerate to the list: <br><br><img src="https://habrastorage.org/files/635/535/ac5/635535ac51764f58bfb84f6944c24403.png" alt="image"><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> data[N]; ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> sum = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N; i++) { sum += data[i]; }</code> </pre><br>  The maximum stack depth (bypassing depth implies postfix summation, i.e. a stack), which can be required here - 2 elements.  No parallelism is assumed; each summation (except the first) should wait for the results of the previous summation, i.e.  There is a dependency on the data. <br><br>  But we need only 3 registers (the sum and two for the emulation of the top of the stack) to sum up an array of any size. <br><br>  Nesting cycle in two streams looks like this: <br><br><img src="https://habrastorage.org/files/d9c/3a4/c15/d9c3a4c151454790b19cb809f7d00fcf.png" alt="image"><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> data[N]; ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> sum = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> sum1 = <span class="hljs-number"><span class="hljs-number">0</span></span>, sum2 = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N/<span class="hljs-number"><span class="hljs-number">2</span></span>; i+=<span class="hljs-number"><span class="hljs-number">2</span></span>) { sum1 += data[i]; sum2 += data[i + <span class="hljs-number"><span class="hljs-number">1</span></span>]; } sum = sum1 + sum2;</code> </pre><br>  For calculations, you need twice as many resources, 5 registers for everything, but now part of the summations can be done in parallel. <br><br>  From the computational point of view, the most terrible option is a right-growing tree degenerate to the list, for its calculation an array-size stack is needed in the absence of parallelism. <br><br>  Which version of the tree will give maximum parallelism?  Obviously, a balanced (within the limits of the possible) tree, where the source data can only be accessed in leaf summing nodes. <br><br><img src="https://habrastorage.org/files/cd5/e00/918/cd5e009181e04f609a071ab988e99927.png" alt="image"><br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    : double data[N]; for (unsigned ix = 0; ix &lt; N; ix++) { unsigned lix = ix; push(data[ix]); while (lix &amp; 1) { popadd(); lix &gt;&gt;= 1; } } for (unsigned ix = 1; ix &lt; bit_count(N+1); ix++) { popadd(); }</span></span></code> </pre><br>  This pseudo-code uses the following functions: <br><br><ol><li>  <i>push</i> (val) - pushes the value to the top of the stack, increases the stack.  It is assumed that the stack is organized in a register pool. <br></li><li>  <i>popadd</i> () - summarizes the two items at the top of the stack, puts the result in the second one from the top, and deletes the top item. <br></li><li>  <i>bit_count</i> (val) - counts the number of bits in an integer value <br></li></ol>  After the operation of this pseudo-code, a single element remains in the stack, which is equal to the required sum. <br><br>  How it works?  Note that the number of the element in the binary representation encodes the path to it from the top of the expression tree (from the high-order bits to the low-order ones).  At the same time 0 means movement to the left, 1 - to the right (similar <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25B4_%25D0%25A5%25D0%25B0%25D1%2584%25D1%2584%25D0%25BC%25D0%25B0%25D0%25BD%25D0%25B0">to the Huffman code</a> ). <br><br>  Note that the number of continuously running low bits is equal to the number of summations that must be done to process the current element.  And the total number of coded bits in the number means the number of items in the stack at the time before working with this item. <br><br>  What you should pay attention to: <br><br><ul><li>  Stack size ie  The required number of registers for it is log2 of the size of the data.  On the one hand, this is not very convenient.  the size of the data can be calculated, and the size of the stack would be desirable to determine when compiling.  On the other hand, no one prevents the compiler from cutting data into tiles, the size of which is determined based on the number of available registers. <br></li><li>  <i>Such an interpretation of the problem is sufficient parallelism to automatically use any number of available independent adders.</i>  Loading elements from an array can be done independently and in parallel.  Summations of the same level are also performed in parallel. <br></li><li>  There are problems with concurrency.  Suppose that at the time of compilation we had N adders.  In order to work effectively with a number other than N (for which purpose everything was started), you will have to use hardware support. <br><ul><li>  for architectures with explicit parallelism, everything is not easy.  It would help the pool of adders and the resolution to execute in parallel several independent ‚Äúwide‚Äù instructions.  For summation, not the specific adder is taken, but the first one in the queue.  If a wide instruction attempts to perform three summations, three adders will be demanded from the pool.  If there is no such number of free adders, the instruction will be blocked until their release. </li><li>  superscalar architectures require you to monitor stack status.  There are unary (ex: sign changes) and binary operations (Ex: popadd) with a stack.  As well as leaf operations without dependencies (Ex: push).  With the latter the easiest way, they can be put on execution at any time.  But if the operation has an argument (s), it must wait for the readiness of its arguments before executing. <br>  So, both values ‚Äã‚Äãfor the popadd operation should be at the top of the stack.  But by the time the turn to sum them up approaches, they may not be at the top of the stack at all.  It may happen that they are physically located and not in a row. <br>  The output will be placement (allocation) of the corresponding register from the stack pool at the moment of setting the instruction for execution and not at the moment when the result is ready and must be placed. <br>  push(data[i]) ,           .           .    . <br>   popadd           , ,    .       ,     popadd ,        . <br>                 . <br>              .     /     .     . </li></ul><br></li><li>   <a href="https://msdn.microsoft.com/en-us/library/e7s85ffb.aspx">ANSI </a> -       double'     .    /fp:fast,    .            ,    ( )  ,      . <br></li><li>        ,    ? ,    .      , , 64        .        2  64 ‚Äî    .    ,  . <br><br><pre> <code class="cpp hljs">lea rax,[data] vxorps xmm6,xmm6,xmm6 ;    <span class="hljs-number"><span class="hljs-number">0</span></span> vaddsd xmm0,xmm6,mmword ptr [rax] ; <span class="hljs-number"><span class="hljs-number">0</span></span> vaddsd xmm1,xmm0,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">8</span></span>] ; <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm0,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">10</span></span>h] ; <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> vaddsd xmm2,xmm0,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">18</span></span>h] ; <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm0,xmm1,xmm2 ; <span class="hljs-number"><span class="hljs-number">0</span></span> vaddsd xmm1,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">20</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm2,xmm1,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">28</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm1,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">30</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm3,xmm1,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">38</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> vaddsd xmm1,xmm2,xmm3 ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm0,xmm0,xmm1 ; <span class="hljs-number"><span class="hljs-number">0</span></span> vaddsd xmm1,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">40</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm2,xmm1,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">48</span></span>] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm1,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">50</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm3,xmm1,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">58</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> vaddsd xmm1,xmm2,xmm3 ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> vaddsd xmm2,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">60</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm3,xmm2,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">68</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> vaddsd xmm2,xmm6,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">70</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm4,xmm2,mmword ptr [rax+<span class="hljs-number"><span class="hljs-number">78</span></span>h] ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> vaddsd xmm2,xmm4,xmm3 ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> vaddsd xmm3,xmm1,xmm2 ; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> vaddsd xmm1,xmm0,xmm3 ; <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre><br>      16 - . <br></li></ul><br><h3>  What's next? </h3><br>      ‚Äî   .  - . <br><br><ul><li>  .   ,   ,           . <br></li><li>   . ,          . <br></li><li>  .               . <br></li><li> <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BC%25D0%25BD%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25BC%25D0%25B0%25D1%2582%25D1%2580%25D0%25B8%25D1%2586"> </a> .   AB        -  A  -  B. <br><ul><li>     ,     . . <br></li><li> <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC_%25D0%25A8%25D1%2582%25D1%2580%25D0%25B0%25D1%2581%25D1%2581%25D0%25B5%25D0%25BD%25D0%25B0"> </a>    22,   ,  7   8.     ,       (&lt; 32 ...128),     .   <img src="https://upload.wikimedia.org/math/d/2/d/d2d58d7a0716cbcf45e9f2f5a1fde024.png" alt="image">   . <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The best </font></font><a href="http://theory.stanford.edu/~virgi/matrixmult-f.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">result</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is </font><font style="vertical-align: inherit;">achieved </font><font style="vertical-align: inherit;">- </font></font><img src="https://upload.wikimedia.org/math/a/e/3/ae3ac3039454e39d7b4da2e22c000625.png" alt="image"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and it is also recursive. </font><font style="vertical-align: inherit;">However, this is a purely theoretical result without prospects for real use.</font></font><br></li></ul></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Naive </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B2%25D1%2591%25D1%2580%25D1%2582%25D0%25BA%25D0%25B0_%25D0%25BF%25D0%25BE%25D1%2581%25D0%25BB%25D0%25B5%25D0%25B4%25D0%25BE%25D0%25B2%25D0%25B0%25D1%2582%25D0%25B5%25D0%25BB%25D1%258C%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25B5%25D0%25B9"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">convolution</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N; i++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; M; j++) { result[i + j] += x[i] * h[M - <span class="hljs-number"><span class="hljs-number">1</span></span> - j]; } }</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We are able to work with the internal cycle, it is better to do general optimization through the DFT. </font></font><br></li><li> <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D0%25BA%25D1%2580%25D0%25B5%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DFT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">In the naive form is not used. </font><font style="vertical-align: inherit;">The </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%2591%25D1%258B%25D1%2581%25D1%2582%25D1%2580%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A4%25D1%2583%25D1%2580%25D1%258C%25D0%25B5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FFT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> algorithm is </font><font style="vertical-align: inherit;">again based on recursion. </font><font style="vertical-align: inherit;">For example, the data-flow diagram for the popular Cooley-Tukey algorithm (Cooley ‚Äì Tukey) with base 2 looks like </font></font><a href="http://www.math.tamu.edu/~rojas/furerfastmult.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">this</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (16-point): </font></font><br><br><img src="https://habrastorage.org/files/649/932/e8f/649932e8f63f40f1843553d7c27435ff.png" alt="image"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here there is enough natural parallelism to resort to special efforts.</font></font><br></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The last example is quite indicative. </font><font style="vertical-align: inherit;">In order to optimize, recursion is usually translated into iteration, with the result that a typical text (main loop) looks like this:</font></font><br><br><pre> <code class="cpp hljs"> nn = N &gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span>; ie = N; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (n=<span class="hljs-number"><span class="hljs-number">1</span></span>; n&lt;=LogN; n++) { rw = Rcoef[LogN - n]; iw = Icoef[LogN - n]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(Ft_Flag == FT_INVERSE) iw = -iw; in = ie &gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span>; ru = <span class="hljs-number"><span class="hljs-number">1.0</span></span>; iu = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (j=<span class="hljs-number"><span class="hljs-number">0</span></span>; j&lt;in; j++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i=j; i&lt;N; i+=ie) { io = i + in; rtp = Rdat[i] + Rdat[io]; itp = Idat[i] + Idat[io]; rtq = Rdat[i] - Rdat[io]; itq = Idat[i] - Idat[io]; Rdat[io] = rtq * ru - itq * iu; Idat[io] = itq * ru + rtq * iu; Rdat[i] = rtp; Idat[i] = itp; } sr = ru; ru = ru * rw - iu * iw; iu = iu * rw + sr * iw; } ie &gt;&gt;= <span class="hljs-number"><span class="hljs-number">1</span></span>; }</code> </pre><br>  What can be done in this case?     , ,  .        ,  . ,     . <br><br> PS:   <a href="http://forum.ixbt.com/users.cgi%3Fid%3Dinfo:Felid">  (Felid)</a>    SIMD   . <br><br> PPS:        King Crimson ‚Äî Fracture ‚Äî Live in Boston 1974. </div><p>Source: <a href="https://habr.com/ru/post/271905/">https://habr.com/ru/post/271905/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../271895/index.html">Why email will never die</a></li>
<li><a href="../271897/index.html">Creating unique themes for ExtJS 6 applications</a></li>
<li><a href="../271899/index.html">Writing a tactical game about numbers for Android</a></li>
<li><a href="../271901/index.html">Is it possible to develop on the iPad?</a></li>
<li><a href="../271903/index.html">AltegroSIM: we are upgrading the mobile communication service delivery</a></li>
<li><a href="../271909/index.html">QCTF Starter: computer security for four or how we made a tournament for beginners in 19 cities simultaneously</a></li>
<li><a href="../271911/index.html">Equivalent transformations of Maxwell equations (ps)</a></li>
<li><a href="../271913/index.html">We test the quality of VoIP passing through common channels (Windows)</a></li>
<li><a href="../271915/index.html">.NET-hardcore in Moscow</a></li>
<li><a href="../271919/index.html">The digest of interesting materials for the mobile developer # 131 (November 23-29)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>