<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Lock-free data structures. 1 - Start</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I hope that this article will be the beginning of a cycle of notes about lock-free data structures. I want to share with the community about my experi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Lock-free data structures. 1 - Start</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage3/164/b7f/0d6/164b7f0d6398bcfaab421f7d957a9acf.jpg" align="right"><br>  I hope that this article will be the beginning of a cycle of notes about lock-free data structures.  I want to share with the community about my experience, observations and reflections on what lock-free data structures are, how to implement them, whether the concepts of containers of the standard STL standard library are suitable for lock-free containers, and when it is worth (and is it worth it at all) to use lock -free data structures. <br><br><a name="habracut"></a><br><br>  Talking about lock-free data structures is meaningless without covering topics such as atomic operations, the memory model implemented in a particular programming language (unless, of course, the language is old enough to think about your memory model), safe memory release, compilers and the optimizations they use, the modern processor architectures ‚Äî all of these topics will be more or less covered in this cycle.  I take the liberty to tell about all these things, although I do not consider myself an absolute expert in any of them.  On the other hand, having no idea about them, I could not write and develop the library <a href="http://libcds.sourceforge.net/">libcds</a> , - open source C ++ library of lock-free containers and safe memory reclamation algorithms.  Cds is the abbreviation of Concurrent Data Structure, and the prefix ‚Äúlib‚Äù is, oddly enough, ‚Äúlibrary‚Äù. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I will begin with the history of the library.  It was back in 2006. <br><div class="spoiler">  <b class="spoiler_title">2006</b> <div class="spoiler_text"><img src="https://habrastorage.org/storage3/ca0/158/bda/ca0158bda7da023178fdd27eff376b67.jpg"><br></div></div><br>  Then I worked in a rather large company writing software for one telecommunication operator from the Big Three.  We developed quite complex server applications for the zoo of hardware platforms, in which the first place was (and always will be) the problem of performance.  It was solved, among other things, by paralleling data processing.  As usual, parallelization led to the emergence of common (shared) data, access to which was required to synchronize.  Somehow, in one of the discussions, my colleague asked in passing: ‚Äúhave you heard anything about the lock-free queues?‚Äù At that time I did not know anything about it.  But, having asked Google, I found several articles in which the pseudo code of the lock-free queue was given.  After reading them several times, I did not understand.  More precisely, I switched to the state of ‚Äúdid not understand anything‚Äù after having rolled up my sleeves and said ‚Äúright now!‚Äù To the whole world (they say, you are all fools, I‚Äôm the only one smart), I tried to ‚Äúsimplify‚Äù the algorithms by matching them with common sense.  After a month of dealing with the segmentation fault, my common sense gave up.  That's when I ‚Äúunderstood nothing‚Äù.  I did not understand how IT works at all, and even if IT somehow works, how it can be implemented in C ++.  But somehow it should work, otherwise smart people would not write these articles, and other smart people would not refer to them (the articles were scientific, and at the end of each, lists of references were cited).  Following these links, over the year I have read several tens of megabytes of useful and not very information, ranging from the software developer guide on processor architectures and ending with overview articles on general approaches to the implementation of lock-free algorithms.  Along the way, I wrote something (in C ++, of course) on this topic, implementing certain primitives.  It should be noted that at this time (year 2006‚Äì2007) the C ++ 11 standard was still optimistically called C ++ 0x, the STL did not yet have atomic primitives, and the interface was still only outlined, and the compilers sometimes were capricious at my atomic primitives and issued a non-working code on particularly critical areas.  By 2008, I began to outline the hazy contours of the libcds library.  The first tests on different platforms gave encouraging, sometimes stunning (‚Äúit became 50 times faster !!!‚Äù), the results, and I completely plunged into the world of lock-free.  In 2010, I posted the first (0.5.0) version of the library on SourceForge.  Today, the latest version of the library is 1.4.0, work is under way on version 1.5.0. <br><br>  Let me turn to the general overview of lock-free data structures.  So, the main task of a programmer in designing and developing complex software projects, especially server-based, is to most effectively use all available resources of the target platform.  A modern computer, even a smartphone or tablet, is a multiprocessor hardware, so program parallelization is one of the ways to improve performance.  Parallel threads (threads) process some shared data (shared data);  Therefore, our main task is to organize parallel access to such shared data. <br><br><img src="https://habrastorage.org/storage3/e4a/b16/0ce/e4ab160cefac1784b378f1a3b76b118a.jpg" align="right"><br>  In the 80s of the last century, so-called structured programming was popularized, positioned as a method of writing good programs.  An apologist for structured programming was Nicholas Wirth, author of the Pascal language, who wrote the bestseller ‚ÄúAlgorithms + Data Structures = Programs‚Äù.  Interestingly, this old formula points out the weak point of modern APIs like pthreads, Win32 APIs offered by operating systems: APIs provide a means for building parallel programs (this means for threads, threads), but they do not provide means for building parallel data structures that provide shared access.  Instead, the API provides a means of <i>restricting</i> access to data in the form of synchronization primitives.  However, synchronization is a bottleneck of parallel programs.  At its core, synchronization is the opposite of parallelism: parallelizing algorithms, we work with sequential data structures, ensuring their operation by synchronization primitives ‚Äî critical sections, mutexes (mutex), conditional variables (condvar);  as a result, we line up all our threads to access the data structure, thereby killing parallelism.  Synchronization primitives are sometimes objects of the OS kernel; therefore, calling such an object can be very expensive: context switching may be required, switching to the OS kernel level, supporting waiting queues for access to the synchronization protected primitive, etc. And all this, perhaps, only for In order to change the value of one single pointer in the data, that is, to execute one or two assembly instructions.  Overhead costs can be (in fact and there is) very high.  In addition, you should not forget that the OS kernel object is a resource limited in quantity. <br><br>  Another disadvantage of synchronization is weak scalability.  As the number of threads increases, synchronized data access becomes the bottleneck of the program;  Often with an increase in the degree of parallelism instead of a proportional increase in productivity, we get its deterioration under high load conditions (high contention). <br><br>  Guided by the Wirth formula ‚ÄúAlgorithms + data structures = programs‚Äù, in my work on libcds I focused only on data structures: you will not find parallel sorting algorithms or parallel for-each in the library.  The library contains only competitive data structures - a queue, a list, a map, a set, etc., - and the necessary lock-free data support algorithms, first of all, safe memory reclamation algorithms.  Often this or that data structure is represented by several implementations.  It was originally intended: as a rule, there are several interesting algorithms that implement a queue or map, and I don‚Äôt know in general which one is ‚Äúbetter‚Äù: first, the concept of ‚Äúbetter‚Äù or ‚Äúworse‚Äù is relative and depends on the specific hardware and a specific task, secondly, until you implement the algorithm and compare it with others, you will not understand whether it is better or not.  Well, if the algorithm is implemented and debugged, then why should it not take its place in the library (and provide a hard choice to the user)? .. <br><div class="spoiler">  <b class="spoiler_title">Lyrical digression</b> <div class="spoiler_text">  By the way, in this regard, I have a claim to STL: why, for example, the map in all implementations of STL known to me is made as a red-black tree?  There are many other data structures suitable for the implementation of the map, for example, AVL tree, which is the same binary tree, but with a stronger balance criterion (besides, our development).  Apparently, not only I am tormented by such questions: I met articles that compared the implementation of the red-black tree and AVL tree, and the conclusions in these articles were not uniquely in favor of the red-black tree: in many problems (and on many architectures) AVL tree was faster. <br></div></div><br><br><img src="https://habrastorage.org/storage3/5f1/833/885/5f18338855598374617bffdca89a9972.jpeg" align="right"><br>  In the academic environment, the study of ways to implement competitive data structures that provide simultaneous access to shared data has led to the creation of several main areas: <br><ul><li>  Lock-free data structures; </li><li>  Fine-grained algorithms; </li><li>  Transactional memory </li></ul><br><br>  There are no implementations based on transactional memory in libcds.  Transactional memory is a vast area of ‚Äã‚Äãresearch focused mainly on the future.  Algorithms based on transactional memory imply, roughly speaking, that memory supports atomic transactions that can be atomically accepted (commit) or rejected (rollback).  Obviously, such a memory must be implemented in hardware;  existing software implementations, as acknowledged by the researchers themselves, do not have sufficient performance.  For the sake of justice, it is worth noting that Intel's Haswell architecture processors already have transactional support in their instruction set, so it should be expected that the flourishing of algorithms built on the principles of transactional memory is not far off. <br><br>  Fine-grained algorithms are sophisticated synchronization methods, as a rule, not built on the use of synchronization primitives provided by OC, but on the use of ‚Äúlight‚Äù atomic primitives, for example, on spin-lock.  Based on such primitives, data structures are constructed that allow parallel reading or even parallel writing, in which synchronization is performed at the node (page) or page (page, bucket) level of the data structure and is embedded in the algorithms of operations on this structure themselves.  Often fine-grained containers show performance comparable to that of lock-free containers with a relatively small load.  The libcds library does not shy away from such data structures. <br><br>  Lock-free data structures I will call data structures that do not require <i>external</i> access synchronization.  This is an informal, purely technical definition, reflecting the internal structure of the container and operations on it.  The word ‚Äúexternal‚Äù here is deliberately highlighted: it must be understood that, without the use of special processor support of the lock-free data structure, it is most likely not possible to build a data structure.  But support of this kind in lock-free containers is not provided by synchronization of <i>access to consecutive</i> container <i>methods</i> , but by an <i>atomic modification</i> mechanism, wired inside container methods, or by internal synchronization at the level of container components (nodes, buckets, pages). <br><br>  The formal definition of a lock-free object sounds like [Her91]: a shared object is called a lock-free object (non-blocking, non-blocking object) if it ensures that <i>some</i> stream finishes the operation on the object in a finite number of steps, regardless of the result of the work of others flows (even if these other threads ended in failure).  A more rigorous concept of a wait-free object is: an object is a wait-free if <i>each</i> thread completes an operation on an object in a finite number of steps.  The lock-free condition guarantees the advancement of at least one thread, while a stronger wait-free condition guarantees successful execution for all threads.  In the theory of competitive data structures, there is also the concept of linearizability [Her90], which plays an important role in the formal proofs of the correctness of lock-free algorithms.  Roughly speaking, an algorithm is linearizable if its result is visible at the end of the algorithm.  For example, the result of insertion into the list is visible at the end of the insertion function.  It sounds idiotic, but it is possible to come up with an algorithm that inserts into the list and is not linearizable.  For example, any kind of buffering can violate this property: instead of inserting, we can put a new element in a buffer, give another thread a command to ‚Äúinsert an element from the buffer into the list‚Äù and not wait for the element to be inserted;  or we will insert only when a sufficient number of elements have accumulated in the buffer.  Then at the end of the insert function in the list, we cannot guarantee that the item is in the list;  all we can guarantee is that the element will certainly <i>be</i> (future time!) inserted into the list now or later. <br><br>  These concepts are widely used in research papers;  My article does not claim to be a research project, so I will use the term lock-free in the ‚Äúphilistine‚Äù sense to designate a class of competitive containers built without the use of traditional synchronization patterns, or not requiring external synchronization. <br><br><div class="spoiler">  <b class="spoiler_title">Lyrical digression 2 - About time</b> <div class="spoiler_text">  It should be noted that the concept of time (cause-effect relationships) is somehow blurred in lock-free data structures.  In the traditional approach, we act like this: we block access to the container, do something with it (for example, add an item), unblock it.  At the time of unlocking, we know that the inserted element is in the container.  In a lock-free container, everything is wrong.  We do not need to block access, we simply call the add method.  If it returns true, then the insert was successful.  But this does not mean that the element is in the container - it can already be removed by a competing stream.  This demonstrates the important difference between lock-free containers and traditional a la STL, - we cannot pull the insides of the container outwards;  for example, the concept of iterators, widely used in STL, is not applicable to competitive data structures.  I hope to discuss in detail the construction of interfaces for classes of competitive containers in one of the following articles. <br></div></div><br><br><img src="https://habrastorage.org/storage3/4f6/f3a/bc3/4f6f3abc3faf14554489fbecca63ea6a.jpg"><br>  What characterizes lock-free algorithms?  Perhaps the first thing that catches your eye is their complexity.  Can you imagine what a regular queue is like that implemented on a single-linked list?  Very simple code: <br><div class="spoiler">  <b class="spoiler_title">Show very simple code</b> <div class="spoiler_text"><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Node</span></span></span><span class="hljs-class"> {</span></span> Node * m_pNext ; }; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">queue</span></span></span><span class="hljs-class"> {</span></span> Node * m_pHead ; Node * m_pTail ; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">queue</span></span>(): m_pHead( <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ), m_pTail( <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ) {} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">enqueue</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( Node * p )</span></span></span><span class="hljs-function"> </span></span>{ p-&gt;m_pNext = m_pTail ; m_pTail = p ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( !m_pHead ) m_pHead = p ; } <span class="hljs-function"><span class="hljs-function">Node * </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dequeue</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( !m_pHead ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ; Node * p = m_pHead ; m_pHead = p-&gt;m_pNext ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( !m_pHead ) m_pTail = <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> p ; } };</code> </pre> <br></div></div><br>  You can write and even shorter.  And this is what the enqueue / dequeue methods (synonyms of push / pop) implement the classic lock-free algorithm of Michael &amp; Scott's queue ([Mic96], the code is taken with minimal abbreviations from the <code>cds::intrusive::MSQueue</code> class of the <code>cds::intrusive::MSQueue</code> library): <br><div class="spoiler">  <b class="spoiler_title">Show the same, but written very cumbersome</b> <div class="spoiler_text"><pre> <code class="hljs ruby">bool enqueue( value_type&amp; val ) { node_type * pNew = node_traits::to_node_ptr( val ) ; typename gc::Guard guard ; back_off bkoff ; node_type * t ; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ( <span class="hljs-literal"><span class="hljs-literal">true</span></span> ) { t = guard.protect( m_pTail, node_to_value() ) ; node_type * pNext = t-&gt;m_pNext.load(memory_model::memory_order_acquire) ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( pNext != null_ptr&lt;node_type *&gt;() ) { <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> Tail is misplaced, advance it m_pTail.compare_exchange_weak( t, pNext, memory_model::memory_order_release, CDS_ATOMIC::memory_order_relaxed ) ; continue ; } node_type * tmp = null_ptr&lt;node_type *&gt;() ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( t-&gt;m_pNext.compare_exchange_strong( tmp, pNew, memory_model::memory_order_release, CDS_ATOMIC::memory_order_relaxed )) { <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> ; } bkoff() ; } ++m_ItemCounter ; m_pTail.compare_exchange_strong( t, pNew, memory_model::memory_order_acq_rel, CDS_ATOMIC::memory_order_relaxed ); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">true</span></span> ; } value_type * dequeue() { node_type * pNext ; back_off bkoff ; typename gc::template GuardArray&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt; guards ; node_type * h ; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ( <span class="hljs-literal"><span class="hljs-literal">true</span></span> ) { h = guards.protect( <span class="hljs-number"><span class="hljs-number">0</span></span>, m_pHead, node_to_value() ) ; pNext = guards.protect( <span class="hljs-number"><span class="hljs-number">1</span></span>, h-&gt;m_pNext, node_to_value() ) ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( m_pHead.load(memory_model::memory_order_relaxed) != h ) continue ; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( pNext == null_ptr&lt;node_type *&gt;() ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> NULL ; <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> empty queue node_type * t = m_pTail.load(memory_model::memory_order_acquire); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( h == t ) { <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> It is needed to help enqueue m_pTail.compare_exchange_strong( t, pNext, memory_model::memory_order_release, CDS_ATOMIC::memory_order_relaxed ) ; continue ; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( m_pHead.compare_exchange_strong( h, pNext, memory_model::memory_order_release, CDS_ATOMIC::memory_order_relaxed )) { <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> ; } bkoff() ; } --m_ItemCounter ; dispose_node( h ) ; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pNext ; }</code> </pre><br></div></div><br><br>  The algorithm is complicated.  The same singly-connected list, but even a simple visual comparison of the usual and lock-free queue already says something.  In the lock-free queue, we see: <br><ul><li>  infinite loop - we try to perform the operation until we succeed.  This is a typical pattern of using the atomic operation <code>compare_exchange</code> ; </li><li>  protection of local variables ( <code>guards</code> ) using one of the safe methods of working with memory (pointers) in lock-free algorithms, in this case it is the Hazard Pointers method; </li><li>  use of atomic primitives C ++ 11 - <code>load, compare_exchange</code> , memory barriers <code>memory_order_xxx</code> ; </li><li>  helping is a very common technique in lock-free algorithms, when one thread helps another to do its work; </li><li>  use of back-off strategies ( <code>bkoff</code> functor), which are not mandatory, but allow in some cases to significantly unload the processor under heavy load conditions, when many threads turn to the queue at the same time </li></ul><br><br>  Now I will not explain anything, since all these things are very extensive and require a separate conversation.  Let the intrigue remain.  I hope to cover these topics in future articles. <br><br>  The next article will be devoted to the cornerstone concept on which all lock-free data structures are based ‚Äî atomicity and atomic primitives. <br><br><img src="https://habrastorage.org/storage3/497/ebc/d54/497ebcd5463f69256df68eba2ccd58bf.jpeg" align="right"><br>  And finally - useful books (not articles), which, from my point of view, most fully covered the issues of competitive programming. <br>  At the moment, I know two good work: <br><br>  1. Nir Shavit, Maurice Herlihy <a href="http://www.amazon.com/The-Multiprocessor-Programming-Maurice-Herlihy/dp/0123705916">The Art of Multiprocessor programming</a> .  Translation into Russian, as far as I know, no.  The book is very famous in the world of lock-free authors describes many parallel algorithms and ways to build them.  All the examples are in Java, so the authors did not have to worry about freeing the memory, the C ++ memory model (the Java memory model is more strict), and other things that are embedded in the language in Java, and in C ++ you have to write all this yourself.  Despite this, the book is very useful. <br><br>  2. Anthony Williams <a href="http://www.manning.com/williams/">C ++ Concurrency in Action</a> (there is a <a href="http://www.ozon.ru/context/detail/id/17636939/">Russian translation</a> ).  The book known in the world of C ++ author is devoted to the issues of multithread programming in C ++, it describes the new standard C ++ 11 and the new features provided by the standard for the implementation of parallel algorithms.  Strongly recommended reading. <br><br>  References: <br><br>  [Her90] M. Herlihy, JM Wing <a href="http://courses.cs.vt.edu/~cs5204/fall07-kafura/Papers/TransactionalMemory/Linearizability.pdf">Linearizability: A Correcting Condition for Concurrent Objects</a> , ACM Transactions on Programming Languages ‚Äã‚Äãand Systems, 1990 <br><br>  [Her91] M. Herlihy <a href="http://www.hpl.hp.com/techreports/Compaq-DEC/CRL-91-10.pdf">A Methodology for Implementing Highly Concurrent Data Object</a> , 1991 <br><br>  [Mic96] M. Michael, M. Scott <a href="http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf">Simple, Fast, and Practical Non-Blocking and Concurrent Queue Algorithms</a> <br><br><div class="spoiler">  <b class="spoiler_title">Lock-free data structures</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/ifree/blog/195770/">Start</a> <br>  Basics: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/195948/">Atomicity and atomic primitives</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/196548/">Where did the memory barriers go from</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/197520/">Memory model</a> </li></ul><br>  Inside: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/202190/">Memory management circuits</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/206984/">RCU</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/216013/">Stack evolution</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/219201/">Another treatise</a> </li><li>  <a href="http://habrahabr.ru/post/230349/">Queue dissection</a> </li><li>  <a href="http://habrahabr.ru/post/250383/">Concurrent maps: warm up</a> </li><li>  <a href="http://habrahabr.ru/post/250523/">Concurrent maps: rehash, no rebuild</a> </li><li>  <a href="http://habrahabr.ru/post/250815/">Concurrent maps: skip list</a> </li><li>  <a href="https://habrahabr.ru/post/251267/">Concurent maps: trees</a> </li><li>  <a href="https://habrahabr.ru/post/314948/">Iterators: multi-level array</a> </li><li>  <a href="https://habrahabr.ru/post/317882/">Iterable list</a> </li></ul><br>  Outside: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/196834/">Introduction to libcds</a> </li></ul><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/195770/">https://habr.com/ru/post/195770/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../195758/index.html">Sony Xperia Z Ultra: personal impressions and the opening of one of the biggest smart cards</a></li>
<li><a href="../195760/index.html">Windows Phone 8: Create an application. Matrix. Part 2</a></li>
<li><a href="../195762/index.html">Cloud from scratch using XenServer</a></li>
<li><a href="../195764/index.html">Mobile applications in the service of the city authorities</a></li>
<li><a href="../195766/index.html">FlameStower - charging the phone from the fire</a></li>
<li><a href="../195772/index.html">Overview of the trading platform TetraMall</a></li>
<li><a href="../195778/index.html">Smart BLF and Digium D40 IP Phone Comparison</a></li>
<li><a href="../195784/index.html">YAC-2013: a round table on the problems of DDoS-attacks in the networks of large operators</a></li>
<li><a href="../195788/index.html">RCE in Android applications through third-party services</a></li>
<li><a href="../195792/index.html">Poll: A new life to a "spoiled" / outdated smartphone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>