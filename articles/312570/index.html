<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Elimination of perspective distortions and extension of curved lines in photos of book spreads</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Last time, in the article ‚ÄúSearching the spine line in photos of book spreads,‚Äù we promised to talk about what happens with a photo of a book spread a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Elimination of perspective distortions and extension of curved lines in photos of book spreads</h1><div class="post__text post__text-html js-mediator-article"> Last time, in the article <a href="https://habrahabr.ru/company/abbyy/blog/283264/">‚ÄúSearching the spine line in photos of book spreads,‚Äù</a> we promised to talk about what happens with a photo of a book spread after this, namely, about eliminating perspective distortions and unbending curved lines of text.  Without this, getting quality OCR results is almost impossible. <br><br>  So, we believe that we have already found the line of the spine in the photo, we will use this knowledge to determine the vanish points for the <a href="https://en.wikipedia.org/wiki/Vanishing_point">vanishing point</a> pages.  Vanish points are the points of convergence of parallel lines in the perspective projection of the book onto the image plane.  Both of them should be located on the continuation of this line, but for each of the pages the position of the point may be different.  This is schematically shown in the following illustration (in fact, it is a log for debugging).  The root line is highlighted in red, the lines intersecting at the Vanish points are green. <br><br><img src="https://habrastorage.org/files/6bc/9be/e50/6bc9bee50c0847b39af78db476291ed5.jpg"><br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As a rule, the Vanish points of two pages are not far from each other, but the given example shows that this is not always the case: for the left page of this reversal, the green lines converge very weakly and the Vanish point lies far below, and for the right page it is up close to the edge of the image. <br><br><img src="https://habrastorage.org/files/84d/26d/320/84d26d320493445f959948f985d97fad.png"><br><br>  How can I find these lines in the image?  Again, the <a href="https://en.wikipedia.org/wiki/Hough_transform">Hough transform</a> comes to the rescue, only the image we have to prepare accordingly.  We will try to highlight the boundaries of the text blocks in the image as simple as possible.  To do this, perform the following simple steps: <br><br>  1) Binarization; <br>  2) Normalization of the image size, for example, up to 800 pixels on the long side; <br>  3) Morphological build-up (dilation, r = 6); <br>  4) Morphological gradient (r = 1). <br><br><img src="https://habrastorage.org/files/2fe/134/94b/2fe13494bfd443528f6c8b18cf30e01e.jpg"><br><br><img src="https://habrastorage.org/files/dab/f88/5dd/dabf885ddb2e4511808f3f1379e15f82.jpg"><br><br><img src="https://habrastorage.org/files/347/1be/ed9/3471beed9da04c13af5a103ca51bff76.jpg"><br><br>  If we apply the fast Hough transform to the resulting image, we get: <br><br><img src="https://habrastorage.org/files/fee/a04/631/feea0463132447e2b7c8a3e89e7b2b21.jpg"><img src="https://habrastorage.org/files/649/3da/6d0/6493da6d05f3411f9a31a3ccba598f1b.jpg"><br><br>  On it, several local maxima are clearly distinguishable, corresponding to the borders of pages and text blocks.  The root line divides these sets into two (let's call them ‚Äúleft‚Äù and ‚Äúright‚Äù, respectively), and each of them is well described by a line in the Hough space.  As you know, the lines in the Hough space correspond to points in the image space.  These are the desired Vanish points. <br><br>  To search for lines in Hough space, it is proposed to first select local maxima using the <a href="https://pdfs.semanticscholar.org/52ca/4ed04d1d9dba3e6ae30717898276735e0b79.pdf">non-maximum suppression</a> algorithm.  We reject all maxima weaker than 0.2 of the highest.  In principle, the noise can be filtered in a different way; here it is important to leave only the points corresponding to sufficiently long contours in the gradient image.  The group of maxima from the neighborhood of the point corresponding to the line of the root (in the figure at the beginning of the article it is highlighted in red), we average and add the center of this cluster to the ‚Äúleft‚Äù and ‚Äúright‚Äù sets of points with increased weight.  We use the least squares method ( <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BD%25D0%25B0%25D0%25B8%25D0%25BC%25D0%25B5%25D0%25BD%25D1%258C%25D1%2588%25D0%25B8%25D1%2585_%25D0%25BA%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D0%25BE%25D0%25B2">OLS</a> ) to search for lines that describe our sets of points (in the figure they are highlighted in green).  Thus, we have obtained Vanish points in the space of the original image.  Unfortunately, depicting them on it will not work, since they lie far beyond its borders.  Knowing the positions of these points, we drew virtual lines intersecting in them - we look again at the first picture, they are highlighted in green there. <br><br>  Now we can straighten the original image, correcting the vertical perspective on it.  We construct virtual quadrangles of pages on the original image.  We need to somehow set the coordinates of the four corners of the document, according to which we can construct a projective transformation.  It is worth noting that such a construction is not unique, based on the nature of the observed things, we chose the following option: we consider that our quadrilaterals are trapeziums, their bases are perpendicular to the spine line, which is one of the lateral sides, and the other lateral side passes through the vanish point. and the middle of the side of the image.  So, on the one hand, we do not cut off too much from the picture, and on the other hand, we do not make our quadrilaterals too large.  Here, for example, another picture, but the principle does not change: <br><br><img src="https://habrastorage.org/files/179/cd3/e04/179cd3e045af4d699442d47416890c3d.png"><br><br>  Of course, it is possible to set the bases of the trapezoids higher or lower, to move the outer sides outwards or inwards and to obtain other projective transformations, but at this stage it is only important for us that the spine becomes vertical and the lines are of the same length.  We apply the obtained projective transformations independently for each of the pages, we get: <br><br><img src="https://habrastorage.org/files/33c/e2b/cab/33ce2bcab15540978e7a94a406291811.jpg"><img src="https://habrastorage.org/files/79e/220/c4d/79e220c4d71745a9bf2b1d517b96c2bd.jpg"><br><br>  The vertical perspective can be considered corrected.  We now turn to the extension of the curved lines. <br><br>  We select oblique "fragments" of words in the image (and for this, the picture is binarized, connected components stand out on it, a graph is constructed describing their mutual position, the words are pre-assembled).  The color shows the angle of the fragment: if &lt;0 is green, if&gt; 0 is red, equal to 0 (rounded to 1 degree), blue. <br><br><img src="https://habrastorage.org/files/b7a/6b1/4d8/b7a6b14d87904ff5b42d12566dc0628a.jpg"><br><br>  By "fragment" we mean here "connected in a word" connected components.  It can correspond to both the word as a whole, and some fragment of the word, it is only the result of a preliminary analysis, not claiming to be true.  You can see that far from all the words have stood out, but for building a page model this will be enough. <br><br>  Use the following page model: <br><br><img src="https://habrastorage.org/files/515/68e/134/51568e13441c433fa93c19e61276307e.png"><br><br>  What does this formula tell us?  The tangent of the local angle of the rows is a third-degree polynomial horizontally and one degree vertically (here and below we use the usual Cartesian coordinates on the plane).  In fact, if we assume that page distortions in space are cylindrical (the sheet bending radius depends only on the x coordinate), then the dependence of the angle of inclination along the vertical when projected onto the image plane will be linear.  In the horizontal direction, we believe that a third-degree polynomial will describe the varying angle of inclination with sufficient accuracy.  Of course, we tried polynomials of smaller and larger degrees.  In general, the choice of model is somewhat arbitrary, it is important that it describes the observed angles well enough.  Where do we get them from?  Of those very oblique fragments of words.  We have a sample of data on the local angles of inclination of the lines for a page; each fragment has its center coordinates and the value of the angle of inclination, which we determine from a set of glued connected components. <br><br>  We use the usual OLS to find the vector of parameters <img src="https://habrastorage.org/files/54e/e72/6e9/54ee726e91b647658796d9ad628ee7a6.png">  .  Next, we will filter out the emissions, because we could, by mistake instead of a word fragment, select somewhere else (we had a rough, preliminary analysis). <br><br><img src="https://habrastorage.org/files/d35/4d3/ef3/d354d3ef36ac402b86cf132451b961e6.png"><br><br>  Here <img src="https://habrastorage.org/files/1ef/443/836/1ef4438364264b3ab5a04e64e63af101.png">  - the angle value calculated by the model at a point with the coordinates of the center of the <i>i</i> -th fragment, <img src="https://habrastorage.org/files/d8e/31a/082/d8e31a0828c24164aed9e2242c411dcb.png">  - the value of the angle of inclination of the fragment itself (initial data), the values ‚Äã‚Äãof the angles are given in radians.  If, as a result of filtering, we still have a sufficient number of fragments described by the model with a given error, we can refine it by applying the OLS to the remaining data.  Thus we get a preliminary model of the page.  It describes quite well the curved lines in those parts of the image where we had allocated a sufficient number of word fragments, but in the spine area the solution is inaccurate.  If we use it to straighten lines, this area will be distorted. <br><br>  Let's try using our model to ‚Äútrace‚Äù the lines to the end.  The centers of the word fragments will serve as priming for the tracking algorithm. <br><br>  Prepare an image for tracing curved lines: <br><br>  - binarization <br>  - horizontal closure (row assembly), <br>  - horizontal opening (getting rid of the title, remote elements), <br>  - Gaussian anti-aliasing (slightly blur the lines vertically). <br><br>  Closing and opening is performed with a window of width <i>R = w / 100</i> , where <i>w</i> is the width of the image.  Smoothing is performed with <i>œÉ = h / 400</i> , where <i>h</i> is the height of the image. <br><br>  We trace the lines, starting from the center of each fragment of the word in both directions. <br><br><img src="https://habrastorage.org/files/30f/d16/bb8/30fd16bb813548f58f5280bc17f22ec1.png"><br><br>  Each time we shift by a fixed step <i>R</i> horizontally and <img src="https://habrastorage.org/files/fcd/c71/797/fcdc717973f14f24aa9004818405b00c.png">  vertically.  The angle is determined by the model.  Make a local maximum search in a vertical column with a height of ¬± 3 pixels.  We continue the process from the revised position.  The stopping criterion is the absence of a local maximum or the maximum value does not exceed the noise threshold <i>(T = 30)</i> . <br><br><img src="https://habrastorage.org/files/eb0/88c/719/eb088c71961d4e8b8e0fe1dfc8cabae2.jpg"><br><br>  As a result of tracking, we get much more data - segments with a refined value of the angle of inclination.  We specify our model using this data. <br><br>  Using the map of angles obtained from the model, we construct a map of local displacements.  We take into account the angle of the horizontal perspective at the current point: <br><br><img src="https://habrastorage.org/files/ef1/deb/48c/ef1deb48c70b4c3d85571e084081c2b8.png"><br><br>  Offset at any point multiplied by <img src="https://habrastorage.org/files/44c/a27/989/44ca27989b7743cb81c73d525f5c8912.png">  .  This allows you to "stretch" the letters in the spine. <br><br><img src="https://habrastorage.org/files/182/2f8/bce/1822f8bceb1a4f19a7957ca7f60f2bf9.jpg">  ‚ñ∫ ‚ñ∫ ‚ñ∫ <img src="https://habrastorage.org/files/834/00b/a19/83400ba19edb4244b42a697283ed6ff7.jpg"><br><br>  We receive the image which can already be submitted on input of OCR.  To build a pleasing to the eye pictures will have to work.  We would like to get something like this: <br><br><img src="https://habrastorage.org/files/383/924/5d7/3839245d70924bd08f186e29f82fb2c6.jpg"><br><br>  How to do this (of course, automatically), we offer to reflect on the readers.  In conclusion, we note that this algorithm has already found application in the <a href="http://qrs.ly/3n5c012">ABBYY FineScanner</a> mobile application, which is now able to process photos of book spreads. </div><p>Source: <a href="https://habr.com/ru/post/312570/">https://habr.com/ru/post/312570/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312558/index.html">node-direct - one NodeJS server for several sites</a></li>
<li><a href="../312560/index.html">Monitoring agent: simple thing or not?</a></li>
<li><a href="../312562/index.html">"Any technical change should answer the question" why? "- Classmates about Java and not only</a></li>
<li><a href="../312564/index.html">readRss - local rss reader as browser extension</a></li>
<li><a href="../312568/index.html">A site containing a database of numbers and addresses of subscribers appeared</a></li>
<li><a href="../312572/index.html">Quality content is not so bad as it is painted.</a></li>
<li><a href="../312574/index.html">Quantum communication: prospects</a></li>
<li><a href="../312578/index.html">Standard algorithms in practice. Calculation of chains. Part 1</a></li>
<li><a href="../312580/index.html">Not a single gap: how we created a wireless network for 3000 devices</a></li>
<li><a href="../312582/index.html">‚ÄúWe did microservices before it became mainstream‚Äù: Sberbank-Technologies on development</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>