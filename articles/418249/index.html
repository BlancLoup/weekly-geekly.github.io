<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>New Google Compute Engine VM Images for Deep Learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Co-author: Mike Cheng 


 The Google Cloud Platform now has virtual machine images in its portfolio designed specifically for those involved in Deep L...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>New Google Compute Engine VM Images for Deep Learning</h1><div class="post__text post__text-html js-mediator-article"><p>  <em>Co-author: Mike Cheng</em> </p><br><p>  The Google Cloud Platform now has virtual machine images in its portfolio designed specifically for those involved in Deep Learning.  Today we will talk about what these images are, what advantages they give developers and researchers, and of course how to create a virtual machine based on them. </p><a name="habracut"></a><br><p>  Lyrical digression: at the time of this writing, the product was still in Beta, accordingly, no SLAs apply to it. </p><br><h2 id="chto-eto-za-zver-takoy-obrazy-virtualnyh-mashin-dlya-deep-learning-ot-google">  What kind of beast is this, virtual machine images for Google's Deep Learning? </h2><br><p>  Google's Deep Learning VMs are images of Debian 9, which are out of the box and have everything you need for Deep Learning.  Currently, there are versions of images with TensorFlow, PyTorch and general purpose images.  Each version is edited for CPU-only and GPU instances.  In order to understand a little better what image you need, I drew a small cheat sheet: </p><br><p><img src="https://habrastorage.org/webt/b-/ji/gp/b-jigplxvmb8yju_pt53sw8xjfa.png"></p><br><p>  As shown on the cheat sheet, there are 8 different families of images.  As already mentioned, they are all based on Debian 9. </p><br><h2 id="chto-zhe-imenno-predustanovleno-na-obrazy">  What exactly is pre-installed on the images? </h2><br><p>  All images have Python 2.7 / 3.5 with the following pre-installed packages: </p><br><ul><li>  numpy </li><li>  sklearn </li><li>  scipy </li><li>  pandas </li><li>  nltk </li><li>  pillow </li><li>  Jupyter environments (Lab and Notebook) </li><li>  and much more. </li></ul><br><p>  Configured stack from Nvidia (only in GPU images): </p><br><ul><li>  CUDA 9. * </li><li>  CuDNN 7.1 </li><li>  NCCL 2. * </li><li>  latest nvidia driver </li></ul><br><p>  The list is constantly updated, so stay tuned <a href="https://cloud.google.com/deep-learning-vm/docs/release-notes">to the official page</a> . </p><br><h2 id="a-zachem-sobstvenno-eti-obrazy-nuzhny">  And why actually these images are needed? </h2><br><p>  Let's assume that you need to train a neural network model with Keras (with TensorFlow).  You need learning speed and you decide to use a GPU.  To use a GPU, you will need to install and configure the Nvidia stack (Nvidia driver + CUDA + CuDNN + NCCL).  Not only is this process quite complex in itself (especially if you are not a systems engineer, but a researcher), it also complicates the fact that you need to take into account the binary dependencies of your version of the TensorFlow library.  For example, the official TensorFlow 1.9 distribution is compiled with CUDA 9.0 and it will not work if you have a stack that has CUDA 9.1 or 9.2 installed.  Setting up this stack can be a "fun" process, I think no one will argue with that (especially those who have done this). </p><br><p>  Now suppose that after several sleepless nights everything is set up and working.  Question: This configuration, which you were able to configure, is it optimal for your hardware?  For example, is it true that the installed CUDA 9.0 and the official binary package TensorFlow 1.9 shows the fastest speed on an instance with a SkyLake processor and one Volta V100 GPU? </p><br><p>  It is almost impossible to answer without performing testing with other versions of CUDA.  To answer for sure, you need to manually reassemble TensorFlow in different configurations and get rid of your tests.  All this should be carried out on the expensive iron on which it is planned to train the model later.  And finally, all these measurements can be thrown out as soon as the new version of TensorFlow or the stack from Nvidia comes out.  We can safely say that most researchers simply will not do this and will simply use the standard TensorFlow assembly, having not the optimal speed. </p><br><p>  This is where images of Deep Learning by Google appear on the scene.  For example, images with TensorFlow have their own build TensorFlow, which is optimized for hardware, which is on the Google Cloud Engine.  They are tested with different configurations of the Nvidia stack and are based on the one that showed the greatest performance (spoiler: this is not always the newest).  And most importantly - almost everything that is needed for research is already preinstalled! </p><br><h2 id="kak-mozhno-sozdat-instans-na-baze-odnogo-iz-obrazov">  How can I create an instance based on one of the images? </h2><br><p>  There are two options to create a new instance based on these images: </p><br><ul><li>  Using Google Cloud Marketplace Web UI </li><li>  Using gcloud </li></ul><br><p>  So, as I am a big fan of the terminal and CLI utilities, in this article I will talk about this version.  Moreover, if you like the UI, there is pretty good <a href="https://console.cloud.google.com/marketplace/details/click-to-deploy-images/deeplearning">documentation describing how to create an instance using the Web UI</a> . </p><br><p>  Before continuing, install (if not already installed) the gcloud <a href="https://cloud.google.com/sdk/install">tool</a> .  Optionally, you can use <a href="https://cloud.google.com/shell/docs/">Google Cloud Shell</a> , but note that the <a href="https://cloud.google.com/shell/docs/using-web-preview">WebPreview</a> function in Google Cloud Shell is currently not supported and therefore you cannot use <a href="http://jupyterlab.readthedocs.io/en/stable/">Jupyter Lab</a> or Notebook there. </p><br><p>  The next step is to select a family of images.  Allow me to bring the cheat sheet again with the choice of a family of images. </p><br><p><img src="https://habrastorage.org/webt/b-/ji/gp/b-jigplxvmb8yju_pt53sw8xjfa.png"></p><br><p>  For an example, we will assume that your choice fell on tf-latest-cu92, we will use it later in the text. </p><br><h3 id="pogodite-no-chto-esli-mne-nuzhna-konkretnaya-versiya-tensorflow-a-ne-poslednyaya">  Wait a minute, but what if I need a specific version of TensorFlow, not the ‚Äúlast‚Äù one? </h3><br><p>  Suppose we have a project that requires TensorFlow 1.8, but at the same time 1.9 has already been released and the images in the tf-latest family already have 1.9.  For this case, we have a family of images that always has a specific version of the framework (in our case, tf-1-8-cpu and tf-1-8-cu92).  These image families will be updated, but the TensorFlow version will not change in them. </p><br><p>  <em>Since this is only Beta release, now we support only TensorFlow 1.8 / 1.9 and PyTorch 0.4.</em>  <em>We plan to support subsequent releases, but at the current stage we cannot clearly answer the question of how long the old versions will be supported.</em> </p><br><h3 id="chto-esli-ya-hochu-sozdat-klaster-ili-ispolzovat-odin-i-tot-zhe-obraz">  What if I want to create a cluster or use the same image? </h3><br><p>  Indeed, there may be many cases in which it is necessary to reuse the same image again and again (and not the family of images).  Strictly speaking, using images directly is almost always the preferred option.  Well, for example, if you start a cluster with several instances, it is not recommended in this case to specify the family of images in your scripts directly, since if the family is updated at the time the script is running, it is likely that different cluster instances will be created from different images (and may have different versions of libraries!).  In such cases, it is preferable to first obtain the specific name of the image of their family, and only then use the specific name. </p><br><p>  <em>If you are interested in this topic, you can look at my article <a href="https://blog.kovalevskyi.com/gce-image-families-how-to-use-them-right-4ed9805860c5">‚ÄúHow to use family of images correctly‚Äù.</a></em> </p><br><p>  You can see the name of the last image in the family with a simple command: </p><br><pre><code class="bash hljs">gcloud compute images describe-from-family tf-latest-cu92 \ --project deeplearning-platform-release</code> </pre> <br><p>  Assume that the name of a particular image is tf-latest-cu92‚Äì1529452792, you can use it anywhere: </p><br><h2 id="vremya-sozdat-nash-pervyy-instans">  Time to create our first instance! </h2><br><p>  To create an instance from the family of images, it is enough to run one simple command: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> IMAGE_FAMILY=<span class="hljs-string"><span class="hljs-string">"tf-latest-cu92"</span></span> <span class="hljs-comment"><span class="hljs-comment">#     export ZONE="us-west1-b" export INSTANCE_NAME="my-instance" gcloud compute instances create $INSTANCE_NAME \ --zone=$ZONE \ --image-family=$IMAGE_FAMILY \ --image-project=deeplearning-platform-release \ --maintenance-policy=TERMINATE \ --accelerator='type=nvidia-tesla-v100,count=8' \ --metadata='install-nvidia-driver=True'</span></span></code> </pre> <br><p>  If you use the image name, not the image family, you need to replace ‚Äú- image-family = $ IMAGE_FAMILY‚Äù with ‚Äú- image = $ IMAGE-NAME‚Äù. </p><br><p>  If you are using an instance with a GPU, then you need to pay attention to the following circumstances: </p><br><p>  <strong>You need to select the correct zone</strong> .  If you create an instance with a specific GPU, you need to make sure that this type of GPU is available in the zone in which you create the instance.  Here you can find the corresponding zones for the types of GPUs.  As you can see, us-west1-b is the only zone in which there are all 3 possible types of GPUs (K80 / P100 / V100). </p><br><p>  <strong>Make sure you have enough quotas to create an instance with the GPU</strong> .  Even if you have chosen the right region, this does not mean that you have a quota for creating an instance with a GPU in this region.  By default, the quota on the GPU is set to zero in all regions, so all attempts to create an instance with a GPU will fail.  A good explanation of how to increase the quota can be found <a href="https://cloud.google.com/compute/quotas">here</a> . </p><br><p>  <strong>Make sure there is enough GPU in the zone to satisfy your request</strong> .  Even if you have chosen the right region and you have a quota for the GPU in this region, this does not mean that the GPU you are interested in is in this zone.  Unfortunately, I do not know how else you can check the availability of the GPU, except as an attempt to create an instance and see what happens =) </p><br><p>  <strong>Choose the correct amount of GPU (depending on the type of GPU)</strong> .  The fact is that the ‚Äúaccelerator‚Äù flag in our team is responsible for the type and number of GPUs that will be available to the instance: i.e.  ‚Äú- accelerator = 'type = nvidia-tesla-v100, count = 8'‚Äù will create an instance with eight available Nvidia Tesla V100 (Volta) GPUs.  Each type of GPU has a valid list of count values.  Here is the list for each type of GPU: </p><br><ul><li>  nvidia-tesla-k80, can have counts: 1, 2, 4, 8 </li><li>  nvidia-tesla-p100, can have counts: 1, 2, 4 </li><li>  nvidia-tesla-v100, can have counts: 1, 8 </li></ul><br><p>  <strong>Give Google Cloud permission to install the Nvidia driver on your behalf at the time of the instance launch</strong> .  The driver from Nvidia is a mandatory component.  For reasons beyond the scope of this article, the images do not have a pre-installed Nvidia driver.  However, you can give Google Cloud the right to install it on your behalf when you first start the instance.  This is done by adding the ‚Äú- metadata = 'install-nvidia-driver = True'‚Äù flag.  If you do not specify this flag, then when you first connect via SSH you will be asked to install the driver. </p><br><p>  Unfortunately, the driver installation process takes time when first loading, since it needs to download and install this very driver (and this also leads to an instance reboot).  In total, this should not take more than 5 minutes.  We'll talk a little later on how to reduce the time of the first boot. </p><br><h2 id="podklyuchenie-k-instansu-po-ssh">  Connecting to an SSH instance </h2><br><p>  It is simpler than a steamy turnip and can be done with one command: </p><br><pre> <code class="bash hljs">gcloud compute ssh <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span></code> </pre> <br><p>  gcloud will create a pair of keys and automatically upload them to the newly created instance, and also create your user on it.  If you want to make this process even simpler, you can use the function that simplifies this: </p><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gssh</span></span></span></span>() { gcloud compute ssh <span class="hljs-variable"><span class="hljs-variable">$@</span></span> } gssh <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span></code> </pre> <br><p>  By the way, you can find all my gcloud bash functions <a href="">right here</a> .  Well, before we get to the question of how fast these images are, well, or what can be done with them, let me clarify the problem with the speed of launching instances. </p><br><h2 id="kak-mozhno-umenshit-vremya-pervogo-zapuska">  How can I reduce the time of the first run? </h2><br><p>  Technically, the time of the very first run - no way.  But you can: </p><br><ul><li>  create the cheapest n1-standard-1 instance with one K80; </li><li>  wait until the first download is over; </li><li>  check that the Nvidia driver is installed (this can be done by running ‚Äúnvidia-smi‚Äù); </li><li>  stop instance; </li><li>  create your own image from a stopped instance; </li><li>  Profit - all instances created from your derivative image will have a legendary 15 second launch time. </li></ul><br><p>  So, from this list, we already know how to create a new instance and connect to it, we also know how to check the drivers for operability.  It remains only to talk about how to stop the instance and create an image from it. </p><br><p>  To stop the instance, run the following command: </p><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ginstance_stop</span></span></span></span>() { gcloud compute instances stop - quiet <span class="hljs-variable"><span class="hljs-variable">$@</span></span> } ginstance_stop <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span></code> </pre> <br><p>  And here is the image creation command: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> IMAGE_NAME=<span class="hljs-string"><span class="hljs-string">"my-awesome-image"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> IMAGE_FAMILY=<span class="hljs-string"><span class="hljs-string">"family1"</span></span> gcloud compute images create <span class="hljs-variable"><span class="hljs-variable">$IMAGE_NAME</span></span> \ --<span class="hljs-built_in"><span class="hljs-built_in">source</span></span>-disk <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span> \ --<span class="hljs-built_in"><span class="hljs-built_in">source</span></span>-disk-zone <span class="hljs-variable"><span class="hljs-variable">$ZONE</span></span> \ --family <span class="hljs-variable"><span class="hljs-variable">$IMAGE_FAMILY</span></span></code> </pre> <br><p>  Congratulations, you now have your image with Nvidia installed drivers. </p><br><h2 id="kak-naschet-jupyter-lab">  What about Jupyter Lab? </h2><br><p>  Once your instance is working, the next logical step would be to launch Jupyter Lab to do business directly :) With new images, this is very simple.  Jupyter Lab is already running since the instance was launched.  All you need to do is connect to the instance with the port forwarding on which Jupyter Lab is listening.  And this is port 8080. This is done by the following command: </p><br><pre> <code class="bash hljs">gssh <span class="hljs-variable"><span class="hljs-variable">$INSTANCE_NAME</span></span> -- -L 8080:localhost:8080</code> </pre> <br><p>  Everything is ready, now you can simply open your favorite browser and go to <a href="http://localhost:8080/">http: // localhost: 8080</a> </p><br><h2 id="naskolko-bystree-tensorflow-iz-obrazov">  How much faster is TensorFlow from images? </h2><br><p>  A very important question, since the speed of training the model is real money.  However, the full answer to this question will be the longest that is already written in this article.  So you have to wait for the next article :) </p><br><p>  In the meantime, I'll indulge you with some numbers obtained on my little personal experiment.  So, the speed of training on ImageNet was 6100 images per second (ResNet-50 network).  My personal budget did not allow me to complete the training of the model completely, however, at this speed, I suppose that it is possible to achieve 75% accuracy in 5 hours and a little. </p><br><h2 id="gde-poluchit-pomosch">  Where to get help? </h2><br><p>  If you need any information regarding new images you can: </p><br><ul><li>  ask a question on stackoverflow, with a google-dl-platform tag; </li><li>  write to the open <a href="https://groups.google.com/forum/">Google Group</a> ; </li><li>  You can email me or <a href="http://twitter.com/b0noi">twitter</a> . </li></ul><br><p>  Your feedback is very important, if you have something to say about the images, please feel free to contact me in any way convenient for you or leave a comment under this article. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/418249/">https://habr.com/ru/post/418249/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../418239/index.html">48 megapixel for smartphone</a></li>
<li><a href="../418241/index.html">Why gauss? (100 ways to solve an equation system)</a></li>
<li><a href="../418243/index.html">The popular history of astronomy is wrong</a></li>
<li><a href="../418245/index.html">How not to develop a project on Bitrix</a></li>
<li><a href="../418247/index.html">Accelerating the multiplication of float 4x4 matrices using SIMD</a></li>
<li><a href="../418251/index.html">Computer vision: how AI is watching us</a></li>
<li><a href="../418253/index.html">There could be water, atmosphere and life on the early moon</a></li>
<li><a href="../418255/index.html">How traffic exchanges resell autosurfing and where from the network millions of bots</a></li>
<li><a href="../418257/index.html">Github.com refuses to use jQuery and switches to pure JavaScript</a></li>
<li><a href="../418261/index.html">The self-made glove stun gun is a weapon for the boom</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>