<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Connectivity components in a dynamic graph in one pass</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="People meet, people quarrel, add and remove friends in social networks. This post is about mathematics and algorithms, beautiful theory, love and hate...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Connectivity components in a dynamic graph in one pass</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/39c/f3b/938/39cf3b938b5442399e34fb75f359aea8.png" align="left"><br>  People meet, people quarrel, add and remove friends in social networks.  This post is about mathematics and algorithms, beautiful theory, love and hate in this unstable world.  This post is about searching for connected components in dynamic graphs. <br><br>  The big world generates big data.  So a big graph fell on our head.  So big that we can keep in memory its vertices, but not edges.  In addition, there are updates regarding the graph - which edge to add, which one to delete.  We can say that every such update we see for the first and last time.  In such conditions it is necessary to find the components of the connectivity <br><br>  Search in depth / width here will not pass simply because the entire graph in the memory does not hold.  A system of disjoint sets could greatly help if the edges in the graph were added.  What to do in the general case? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><br>  <em><strong><em>Task</em></strong> .</em>  <em>Dan undirected graph</em> <em><img src="http://tex.s2cms.ru/svg/G" alt="G"></em>  <em>on</em> <em><img src="http://tex.s2cms.ru/svg/n" alt="n"></em>  <em>tops.</em>  <em>Initially, the graph is empty.</em>  <em>The algorithm comes a sequence of updates.</em> <em><img src="http://tex.s2cms.ru/svg/p_1%2C%20p_2%2C%20%5Cdots%2C%20p_m" alt="p_1, p_2, \ dots, p_m"></em>  <em>, which can be read in a given order exactly once.</em>  <em>Each update is a command to remove or add an edge between a pair of vertices.</em> <em><img src="http://tex.s2cms.ru/svg/u_i" alt="u_i"></em>  <em>and</em> <em><img src="http://tex.s2cms.ru/svg/v_i" alt="v_i"></em>  <em>.</em>  <em>It is guaranteed that at any point in time between a pair of vertices more edges than they are will not be deleted.</em>  <em>After reading the sequence, the algorithm should output all connected components with a probability of success.</em> <em><img src="http://tex.s2cms.ru/svg/0.99" alt="0.99"></em>  <em>.</em>  <em>Permitted to use</em> <em><img src="http://tex.s2cms.ru/svg/O(n%20%5Clog%5Ec%20n)" alt="O (n \ log ^ c n)"></em>  <em>memory where</em> <em><img src="http://tex.s2cms.ru/svg/c" alt="c"></em>  <em>- some constant.</em> <br><br>  The solution of the problem consists of three ingredients. <br><ul><li>  Incidence matrix as a representation. </li><li>  The method as an algorithm. </li><li><img src="http://tex.s2cms.ru/svg/L_0" alt="L_0">  Sampling as optimization. </li></ul><br>  You can see the implementation on the githaba: <a href="https://github.com/vsevolod-oparin/stream-dynamic-components">link</a> . <br><br><h2>  Incidence Matrix as Representation </h2><br>  The first data structure for the storage of the graph will be extremely non-optimal.  We will take the incidence matrix <img src="http://tex.s2cms.ru/svg/A" alt="A">  size <img src="http://tex.s2cms.ru/svg/n%20%5Ctimes%20%5Cbinom%7Bn%7D%7B2%7D" alt="n \ times \ binom {n} {2}">  , which will mostly be zeros.  Each row in the matrix corresponds to a vertex, and a column corresponds to a possible edge.  Let be <img src="http://tex.s2cms.ru/svg/u%20%3C%20v" alt="u &amp; lt; v">  .  For a pair of vertices <img src="http://tex.s2cms.ru/svg/u%2C%20v" alt="u, v">  connected by an edge, we define <br><img src="http://tex.s2cms.ru/svg/A_%7Bu%2C%20(u%2C%20v)%7D%20%3D%201" alt="A_ {u, (u, v)} = 1">  and <img src="http://tex.s2cms.ru/svg/A_%7Bv%2C%20(u%2C%20v)%7D%20%3D%20-1" alt="A_ {v, (u, v)} = -1">  , otherwise the values ‚Äã‚Äãare zero. <br><br>  As an example, look at the graph in the picture below. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/1b2/14b/9b9/1b214b9b9834403cb918e8d4ec5e5b52.png"></div><br>  For him, the incidence matrix will look like this. <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0A%5Cbegin%7Barray%7D%7Br%7Cccccccccccccccc%7D%0AA%20%26%20(1%2C%202)%20%26%20(1%2C%203)%20%26%20(1%2C%204)%20%26%20(1%2C%205)%20%26%20(1%2C%206)%20%26%20(2%2C%203)%20%26%20(2%2C%204)%20%26%20(2%2C%205)%20%26%20(2%2C%206)%20%26%20(3%2C%204)%20%26%20(3%2C%205)%20%26%20(3%2C%206)%20%26%20(4%2C%205)%20%26%20(4%2C%206)%20%26%20(5%2C%206)%20%5C%5C%0A%5Chline%0A1%20%26%20%2B1%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%5C%5C%0A2%20%26%20-1%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20%2B1%20%26%20%2B1%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%5C%5C%0A3%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20-1%20%26%200%20%26%200%20%26%200%20%26%20%2B1%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%5C%5C%0A4%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20-1%20%26%200%20%26%200%20%26%20-1%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%5C%5C%0A5%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20%2B1%20%5C%5C%0A6%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20-1%20%5C%5C%0A%5Cend%7Barray%7D%0A" alt="\ begin {array} {r | ccccccccccccccc} A &amp; amp; (1, 2) &amp; amp; (1, 3) &amp; amp; (1, 4) &amp; amp; (1, 5) &amp; amp; (1, 6) &amp; amp; (2, 3) &amp; amp; (2, 4) &amp; amp; (2, 5) &amp; amp; (2, 6) &amp; amp; (3, 4) &amp; amp; (3, 5) &amp; amp; (3, 6) &amp; amp; (4, 5) &amp; amp; (4, 6) &amp; amp; (5, 6) \\ hline 1 &amp; amp; +1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 \\ 2 &amp; amp; -1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; +1 &amp; amp; +1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 \\ 3 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; -1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; +1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 \\ 4 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; -1 &amp; amp; 0 &amp; amp; 0 &amp; amp; -1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 \\ 5 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; +1 \\ 6 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; -1 \\ \ end {array}"></div><br>  The naked eye can see that this view has a serious drawback - the size <img src="http://tex.s2cms.ru/svg/O(n%5E3)" alt="O (n ^ 3)">  .  We optimize it, but later. <br><br>  There is also an implicit advantage.  If you take a lot of vertices <img src="http://tex.s2cms.ru/svg/S" alt="S">  and add all matrix row vectors <img src="http://tex.s2cms.ru/svg/A" alt="A">  that match <img src="http://tex.s2cms.ru/svg/S" alt="S">  , then the edges between the vertices <img src="http://tex.s2cms.ru/svg/S" alt="S">  only those connecting will be reduced <img src="http://tex.s2cms.ru/svg/S" alt="S">  and <img src="http://tex.s2cms.ru/svg/V%20%5Cbackslash%20S" alt="V \ backslash s">  . <br><br>  For example, if you take a lot <img src="http://tex.s2cms.ru/svg/S%20%3D%20%5C%7B3%2C%204%2C%205%5C%7D" alt="S = \ {3, 4, 5 \}">  and put the corresponding vectors, we get <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0A%5Cbegin%7Barray%7D%7Br%7Cccccccccccccccc%7D%0AA%20%26%20(1%2C%202)%20%26%20(1%2C%203)%20%26%20(1%2C%204)%20%26%20(1%2C%205)%20%26%20(1%2C%206)%20%26%20(2%2C%203)%20%26%20(2%2C%204)%20%26%20(2%2C%205)%20%26%20(2%2C%206)%20%26%20(3%2C%204)%20%26%20(3%2C%205)%20%26%20(3%2C%206)%20%26%20(4%2C%205)%20%26%20(4%2C%206)%20%26%20(5%2C%206)%20%5C%5C%0A%5Chline%0A3%2C%204%2C%205%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20-1%20%26%20-1%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%200%20%26%20%2B1%0A%5Cend%7Barray%7D%0A" alt="\ begin {array} {r | ccccccccccccccc} A &amp; amp; (1, 2) &amp; amp; (1, 3) &amp; amp; (1, 4) &amp; amp; (1, 5) &amp; amp; (1, 6) &amp; amp; (2, 3) &amp; amp; (2, 4) &amp; amp; (2, 5) &amp; amp; (2, 6) &amp; amp; (3, 4) &amp; amp; (3, 5) &amp; amp; (3, 6) &amp; amp; (4, 5) &amp; amp; (4, 6) &amp; amp; (5, 6) \\ hline 3, 4, 5 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; -1 &amp; amp; -1 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; 0 &amp; amp; +1 \ end {array}"></div><br>  Non-zero values ‚Äã‚Äãare at the edges <img src="http://tex.s2cms.ru/svg/(2%2C%203)" alt="(2, 3)">  , <img src="http://tex.s2cms.ru/svg/(2%2C%204)" alt="(2, 4)">  and <img src="http://tex.s2cms.ru/svg/(5%2C%206)" alt="(5, 6)">  . <br><br><h2>  Shrinking the graph as an algorithm </h2><br>  Understand what a rib is.  Here we have two peaks <img src="http://tex.s2cms.ru/svg/u" alt="u">  and <img src="http://tex.s2cms.ru/svg/v" alt="v">  there is a rib between them.  Of <img src="http://tex.s2cms.ru/svg/u" alt="u">  and <img src="http://tex.s2cms.ru/svg/v" alt="v">  there may be other edges.  Stiffen rib <img src="http://tex.s2cms.ru/svg/(u%2C%20v)" alt="(u, v)">  this is the procedure when we merge the vertices <img src="http://tex.s2cms.ru/svg/u" alt="u">  and <img src="http://tex.s2cms.ru/svg/v" alt="v">  in one let's say <img src="http://tex.s2cms.ru/svg/w" alt="w">  , rib <img src="http://tex.s2cms.ru/svg/(u%2C%20v)" alt="(u, v)">  we delete, and all remaining edges, incident <img src="http://tex.s2cms.ru/svg/u" alt="u">  and <img src="http://tex.s2cms.ru/svg/v" alt="v">  , we lead to the new peak <img src="http://tex.s2cms.ru/svg/w" alt="w">  . <br><br>  An interesting feature: in terms of the matrix of incidence, to tighten the edge <img src="http://tex.s2cms.ru/svg/(u%2C%20v)" alt="(u, v)">  it is enough to add the corresponding row vectors.  Edge itself <img src="http://tex.s2cms.ru/svg/(u%2C%20v)" alt="(u, v)">  shrink, only those that go outside will remain. <br><br>  Now the algorithm.  Take a graph and for each non-isolated vertex we choose a neighbor. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/a4e/7e6/0af/a4e7e60afc2649c88f35f68d94496d00.png"></div><br>  We pull the corresponding edges. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/616/ce9/773/616ce9773b0b48e0add10fa521d74c91.png"></div><br>  Repeat iteration <img src="http://tex.s2cms.ru/svg/%5Clog%20n" alt="\ log n">  time. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/734/b2f/444/734b2f444c27498d954b510fbc74de7c.png"></div><br><br>  Note that after each iteration of the connection of the connected components of the new graph are one-to-one mapped to the components of the old.  We can even mark which vertices have been merged into the resulting vertices, in order to restore the answer later. <br><br>  Note also that after each iteration, any connected component of at least two vertices is reduced at least two times.  This is natural, since at least two vertices of the old one were merged into each vertex of the new component.  So after <img src="http://tex.s2cms.ru/svg/%5Clog%20n" alt="\ log n">  iterations in the graph will remain only isolated vertices. <br><br>  We search through all isolated vertices and restore the answer in the history of mergers. <br><br><h2><img src="http://tex.s2cms.ru/svg/L_0" alt="L_0">  -sampling as optimization </h2><br>  Everything would be great, but the above algorithm works in terms of time and memory. <img src="http://tex.s2cms.ru/svg/O(n%5E3)" alt="O (n ^ 3)">  .  To optimize it, we will construct a sketch - a special data structure for a compact representation of row vectors. <br><br>  From the sketch you need three properties. <br><br>  First, compactness.  If we build a sketch for a vector <img src="http://tex.s2cms.ru/svg/a" alt="a">  size <img src="http://tex.s2cms.ru/svg/O(n)" alt="O (n)">  then the sketch itself <img src="http://tex.s2cms.ru/svg/%5Csigma(a)" alt="\ sigma (a)">  must be sized <img src="http://tex.s2cms.ru/svg/O(%5Clog%5Ec%20n)" alt="O (\ log ^ c n)">  . <br><br>  Secondly, sampling.  At each iteration of the algorithm, we need to choose a neighbor.  We want a way to get the index of at least one non-zero element, if there is one. <br><br>  Third, linearity.  If we built for two vectors <img src="http://tex.s2cms.ru/svg/a" alt="a">  and <img src="http://tex.s2cms.ru/svg/b" alt="b">  sketches <img src="http://tex.s2cms.ru/svg/%5Csigma(a)" alt="\ sigma (a)">  and <img src="http://tex.s2cms.ru/svg/%5Csigma(b)" alt="\ sigma (b)">  .  Must be an effective method, get a sketch <img src="http://tex.s2cms.ru/svg/%5Csigma(a%20%2B%20b)%20%3D%20f(%5Csigma(a)%2C%20%5Csigma(b))" alt="\ sigma (a + b) = f (\ sigma (a), \ sigma (b))">  .  This will help tighten the ribs. <br><br>  We will use the solution of the problem. <img src="http://tex.s2cms.ru/svg/L_0" alt="L_0">  -sampling. <br><br>  <em><strong><em>Task.</em></strong></em>  <em>Dan vector zero vector</em> <em><img src="http://tex.s2cms.ru/svg/a%20%3D%20%5Clangle%20a_1%2C%20a_2%2C%20%5Cdots%2C%20a_n%20%5Crangle" alt="a = \ langle a_1, a_2, \ dots, a_n \ rangle"></em>  <em>dimensions</em> <em><img src="http://tex.s2cms.ru/svg/n" alt="n"></em>  <em>.</em>  <em>Algorithm sequence comes from</em> <em><img src="http://tex.s2cms.ru/svg/m" alt="m"></em>  <em>view updates</em> <em><img src="http://tex.s2cms.ru/svg/(i%2C%20%5CDelta)" alt="(i, \ Delta)"></em>  <em>: add</em> <em><img src="http://tex.s2cms.ru/svg/%5CDelta" alt="\ Delta"></em>  <em>to value</em> <em><img src="http://tex.s2cms.ru/svg/a_i" alt="a_i"></em>  <em>.</em> <em><img src="http://tex.s2cms.ru/svg/%5CDelta" alt="\ Delta"></em>  <em>can be either positive or negative integer.</em>  <em>The resulting vector at some positions may have non-zero values.</em>  <em>These positions are denoted by</em> <em><img src="http://tex.s2cms.ru/svg/I" alt="I"></em>  <em>.</em>  <em>It is required to issue any position from</em> <em><img src="http://tex.s2cms.ru/svg/I" alt="I"></em>  <em>equally likely.</em>  <em>All updates need to be processed in one pass, you can use</em> <em><img src="http://tex.s2cms.ru/svg/O(%5Clog%5Ec%20n)" alt="O (\ log ^ c n)"></em>  <em>of memory.</em>  <em>It is guaranteed that the maximum value in</em> <em><img src="http://tex.s2cms.ru/svg/a_i" alt="a_i"></em>  <em>fit in</em> <em><img src="http://tex.s2cms.ru/svg/O(%5Clog%20n)" alt="O (\ log n)"></em>  <em>bit.</em> <br><br><h3>  1-sparse vector </h3><br>  To begin, we will solve a simpler problem.  Suppose we have a guarantee that the final vector contains exactly one nonzero position.  We say that such a vector is 1-sparse.  We will support two variables <img src="http://tex.s2cms.ru/svg/S_0%20%3D%20%5Csum_i%20a_i" alt="S_0 = \ sum_i a_i">  and <img src="http://tex.s2cms.ru/svg/S_1%20%3D%20%5Csum_i%20i%20%5Ccdot%20a_i" alt="S_1 = \ sum_i i \ cdot a_i">  .  Maintaining them is simple: on each update we add to the first <img src="http://tex.s2cms.ru/svg/%5CDelta" alt="\ Delta">  to second <img src="http://tex.s2cms.ru/svg/i%20%5Ccdot%20%5CDelta" alt="i \ cdot \ Delta">  . <br><br>  Denote the desired position by <img src="http://tex.s2cms.ru/svg/i'" alt="i '">  .  If it is only one, then <img src="http://tex.s2cms.ru/svg/S_0%20%3D%20a_%7Bi'%7D" alt="S_0 = a_ {i '}">  and <img src="http://tex.s2cms.ru/svg/S_1%20%3D%20i'%20%5Ccdot%20a_%7Bi'%7D" alt="S_1 = i '\ cdot a_ {i'}">  .  To find a position, we consider <img src="http://tex.s2cms.ru/svg/i'%20%3D%20S_1%20%2F%20S_0" alt="i '= S_1 / S_0">  . <br><br>  You can probabilistically check whether the vector is 1-sparse.  For this we take a prime number <img src="http://tex.s2cms.ru/svg/p%20%3E%204%20%5Ccdot%20n" alt="p &amp; gt; 4 \ cdot n">  random integer <img src="http://tex.s2cms.ru/svg/z%20%5Cin%20%5B0%2C%20p)" alt="z \ in [0, p)">  and calculate the variable <img src="http://tex.s2cms.ru/svg/T%20%3D%20%5Csum_i%20a_i%20%5Ccdot%20z%5Ei%20%25%20p" alt="T = \ sum_i a_i \ cdot z ^ i% p">  .  The vector passes the 1-sparsity test if <img src="http://tex.s2cms.ru/svg/S_0%20%5Cneq%200" alt="S_0 \ neq 0">  and <img src="http://tex.s2cms.ru/svg/T%20%3D%20S_0%20%5Ccdot%20z%5E%7BS_1%20%2F%20S_0%7D" alt="T = S_0 \ cdot z ^ {S_1 / S_0}">  . <br><br>  Obviously, if the vector is really 1-sparse, then <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/T%20%3D%20%5Csum_i%20a_i%20%5Ccdot%20z%5Ei%20%3D%20a_%7Bi'%7D%20%5Ccdot%20z%5E%7Bi'%7D%20%3D%20S_0%20%5Ccdot%20z%5E%7BS_1%20%2F%20S_0%7D" alt="T = \ sum_i a_i \ cdot z ^ i = a_ {i '} \ cdot z ^ {i'} = S_0 \ cdot z ^ {S_1 / S_0}"></div><br>  and he will pass the test.  Otherwise, the probability of passing the test is not more than <img src="http://tex.s2cms.ru/svg/0.25" alt="0.25">  (actually, maximum <img src="http://tex.s2cms.ru/svg/n%20%2F%20p" alt="n / p">  ). <br><br><div class="spoiler">  <b class="spoiler_title">Why?</b> <div class="spoiler_text">  In terms of a polynomial, a vector passes the test if the values ‚Äã‚Äãof a polynomial <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/p(z)%20%3D%20%5Csum_i%20a_i%20%5Ccdot%20z%5Ei%20-%20S_0%20%5Ccdot%20z%5E%7BS_1%20%2F%20S_0%7D" alt="p (z) = \ sum_i a_i \ cdot z ^ i - S_0 \ cdot z ^ {S_1 / S_0}"></div><br>  randomly selected point <img src="http://tex.s2cms.ru/svg/z" alt="z">  equals zero.  If the vector is not 1-sparse, then <img src="http://tex.s2cms.ru/svg/p(z)" alt="p (z)">  is not identically zero.  If we passed the test, we guessed the root.  The maximum degree of a polynomial is <img src="http://tex.s2cms.ru/svg/n" alt="n">  means no more roots <img src="http://tex.s2cms.ru/svg/n" alt="n">  so the probability of guessing them is no more <img src="http://tex.s2cms.ru/svg/n%20%2F%20p" alt="n / p">  . </div></div><br>  If we want to increase the accuracy of verification to an arbitrary probability <img src="http://tex.s2cms.ru/svg/1%20-%20%5Cdelta" alt="1 - \ delta">  , then you need to calculate the value <img src="http://tex.s2cms.ru/svg/T" alt="T">  on <img src="http://tex.s2cms.ru/svg/O(%5Clog%20%5Cdelta%5E%7B-1%7D)" alt="O (\ log \ delta ^ {- 1})">  random <img src="http://tex.s2cms.ru/svg/z" alt="z">  . <br><br><h3><img src="http://tex.s2cms.ru/svg/s" alt="s">  -frame vector </h3><br>  Now we will try to solve the problem for <img src="http://tex.s2cms.ru/svg/s" alt="s">  - sparse vector, i.e.  containing no more <img src="http://tex.s2cms.ru/svg/s" alt="s">  nonzero positions.  We will need hashing and the previous method.  The general idea is to restore the entire vector, and then select some element randomly. <br><br>  Take a random 2-independent hash function <img src="http://tex.s2cms.ru/svg/h%20%3A%20%5Bn%5D%20%5Crightarrow%20%5B2s%5D" alt="h: [n] \ rightarrow [2s]">  .  This is such a function, which distributes two arbitrary different keys equally independently. <br><br><div class="spoiler">  <b class="spoiler_title">More about hash functions</b> <div class="spoiler_text">  The algorithms have two fundamentally different approaches to hash functions.  The first is based on the fact that the data is less random, and our favorite hash function will mix them correctly.  The second is that an evil adversary can pick up data, and the only chance to save the algorithm from unnecessary computation and other problems is to choose a hash function randomly.  Yes, sometimes it can work poorly, but we can measure how bad it is.  Here we are talking about the second approach. <br><br>  The hash function is selected from the family of functions.  For example, if we want to stir all the numbers from <img src="http://tex.s2cms.ru/svg/0">  before <img src="http://tex.s2cms.ru/svg/p%20-%201" alt="p - 1">  you can take random <img src="http://tex.s2cms.ru/svg/a" alt="a">  and <img src="http://tex.s2cms.ru/svg/b" alt="b">  and determine the hash function <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/h_%7Ba%2C%20b%7D(x)%20%3D%20a%20%5Ccdot%20x%20%2B%20b%20%5Ctext%7B%20mod%20%7D%20p." alt="h_ {a, b} (x) = a \ cdot x + b \ text {mod} p."></div><br>  Functions for all possible <img src="http://tex.s2cms.ru/svg/a%2C%20b%20%5Cin%20%5Bp%5D" alt="a, b \ in [p]">  set the family of hash functions.  Randomly select the hash function - it is essentially random to select those <img src="http://tex.s2cms.ru/svg/a" alt="a">  and <img src="http://tex.s2cms.ru/svg/b" alt="b">  .  They are usually chosen equiprobably from the set <img src="http://tex.s2cms.ru/svg/%5Bp%5D" alt="[p]">  . <br><br>  The remarkable property of the example above is that any two different keys are randomly distributed independently.  Formally, for any different <img src="http://tex.s2cms.ru/svg/x_1%2C%20x_2%20%5Cin%20%5Bp%5D" alt="x_1, x_2 \ in [p]">  and any, possibly the same, <img src="http://tex.s2cms.ru/svg/y_1%2C%20y_2%20%5Cin%20%5Bp%5D" alt="y_1, y_2 \ in [p]">  probability <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%5Ctextbf%7BPr%7D%5Cleft%5B%20h(x_1)%20%3D%20y_1%20%5Ctext%7B%20and%20%7D%20h(x_2)%20%3D%20y_2%20%5Cright%5D%20%3D%20p%5E%7B-2%7D." alt="\ textbf {Pr} \ left [h (x_1) = y_1 \ text {and} h (x_2) = y_2 \ right] = p ^ {- 2}."></div><br>  This property is called 2-independence.  Sometimes, the probability may not be <img src="http://tex.s2cms.ru/svg/p%5E%7B-2%7D" alt="p ^ {- 2}">  , but <img src="http://tex.s2cms.ru/svg/p%5E%7B-2%7D%20%5Cpm%20%5Cvarepsilon" alt="p ^ {- 2} \ pm \ varepsilon">  where <img src="http://tex.s2cms.ru/svg/varepsilon" alt="varepsilon">  some kind of reasonably small value. <br><br>  There is a 2-independence generalization - <img src="http://tex.s2cms.ru/svg/k" alt="k">  -independence.  This is when the function distributes not 2, <img src="http://tex.s2cms.ru/svg/k" alt="k">  arbitrary keys regardless.  Polynomial hash functions with <img src="http://tex.s2cms.ru/svg/k" alt="k">  random coefficients have this property. <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/p(x)%20%3D%20%5Csum_%7Bi%20%3D%200%7D%5E%7Bk%20-%201%7D%20a_i%20%5Ccdot%20x%5Ei%20%5Ctext%7B%20mod%20%7D%20p" alt="p (x) = \ sum_ {i = 0} ^ {k - 1} a_i \ cdot x ^ i \ text {mod} p"></div><br>  Have <img src="http://tex.s2cms.ru/svg/k" alt="k">  Independence is one unpleasant property.  With growth <img src="http://tex.s2cms.ru/svg/k" alt="k">  function takes up more memory.  This property does not depend on any particular implementation, but simply a general information property.  Therefore, the less independence we can do, the easier it is to live. <br></div></div><br>  Take a hash table size <img src="http://tex.s2cms.ru/svg/2s" alt="2s">  .  In each cell of the table, there will be an algorithm for a 1-sparse vector.  When we receive an update <img src="http://tex.s2cms.ru/svg/(i%2C%20%5CDelta)" alt="(i, \ Delta)">  , we send this update to the algorithm in the cell <img src="http://tex.s2cms.ru/svg/h(i)" alt="h (i)">  . <br>  It can be calculated that for a single cell, the probability that there will be a collision at least along two non-zero coordinates will be no more than <img src="http://tex.s2cms.ru/svg/0.4" alt="0.4">  . <br><br><div class="spoiler">  <b class="spoiler_title">Why?</b> <div class="spoiler_text">  The probability that another element does not fall into the cell to us <img src="http://tex.s2cms.ru/svg/(1%20-%201%20%2F%202s)" alt="(1 - 1 / 2s)">  .  The probability that everyone will not get to us: <img src="http://tex.s2cms.ru/svg/(1%20-%201%20%2F%202s)%5E%7Bs-%201%7D" alt="(1 - 1 / 2s) ^ {s- 1}">  .  The probability that at least someone will fall <img src="http://tex.s2cms.ru/svg/1%20-%20(1%20-%201%20%2F2s)%5E%7Bs%20-%201%7D" alt="1 - (1 - 1 / 2s) ^ {s - 1}">  .  You may notice that this function is monotonically increasing.  I'll just bring a picture here: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/0e5/e4c/23a/0e5e4c23a6bc4865b27cf2f3445e46bd.png"></div><br>  In the limit, the function gives the value <img src="http://tex.s2cms.ru/svg/1%20-%20e%5E%7B-0.5%7D%20%5Cleq%200.4" alt="1 - e ^ {- 0.5} \ leq 0.4">  . </div></div><br>  Suppose we want to restore all coordinates with probability of success. <img src="http://tex.s2cms.ru/svg/1%20-%20%5Cdelta" alt="1 - \ delta">  or with probability of failure <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  .  Take not one hash table, but immediately <img src="http://tex.s2cms.ru/svg/k%20%3D%20O(%5Clog%20(s%20%5Ccdot%20(%5Cdelta%20%2F%202)%5E%7B-1%7D))" alt="k = O (\ log (s \ cdot (\ delta / 2) ^ {- 1}))">  .  It is easy to understand that the probability of failure in decoding a particular coordinate will be <img src="http://tex.s2cms.ru/svg/(%5Cdelta%20%2F%202)%20%2F%20s" alt="(\ delta / 2) / s">  .  The probability of failure in decoding at least one of <img src="http://tex.s2cms.ru/svg/s" alt="s">  coordinates <img src="http://tex.s2cms.ru/svg/%5Cdelta%20%2F%202" alt="\ delta / 2">  .  If the total decoding for 1-sparse vectors works with the probability of failure <img src="http://tex.s2cms.ru/svg/%5Cdelta%20%2F%202" alt="\ delta / 2">  then we won. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9a0/78c/f27/9a078cf2703141b0be0b4d88e8af73c9.png"></div><br>  The final algorithm is as follows.  Take <img src="http://tex.s2cms.ru/svg/O(%5Clog(s%20%5Ccdot%20%5Cdelta%5E%7B-1%7D))" alt="O (\ log (s \ cdot \ delta ^ {- 1}))">  hash table size <img src="http://tex.s2cms.ru/svg/2s" alt="2s">  .  Each cell of the algorithm will have its own decoder for a 1-sparse vector with the probability of failure <img src="http://tex.s2cms.ru/svg/%5Cdelta%20%2F%202%20k%20s" alt="\ delta / 2 k s">  . <br><br>  Every update <img src="http://tex.s2cms.ru/svg/(i%2C%20%5CDelta)" alt="(i, \ Delta)">  processed in each hash table separately by the algorithm in the cell <img src="http://tex.s2cms.ru/svg/h_j(i)" alt="h_j (i)">  . <br><br>  Upon completion, we extract from all successfully completed 1-decoders by coordinate and merge them into one list. <br><br>  The maximum in the general table will be <img src="http://tex.s2cms.ru/svg/k%20%5Ccdot%20s" alt="k \ cdot s">  affected 1-decoders.  Therefore, the total probability that one of the 1-decoders will not work correctly will not exceed <img src="http://tex.s2cms.ru/svg/k%20s%20%5Ccdot%20%5Cdelta%20%2F%202%20ks%20%3D%20%5Cdelta%20%2F%202" alt="k s \ cdot \ delta / 2 ks = \ delta / 2">  .  Also, the probability that at least one coordinate will not be restored does not exceed <img src="http://tex.s2cms.ru/svg/%5Cdelta%20%2F%202" alt="\ delta / 2">  .  Overall, the probability of failure of the algorithm <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  . <br><br><h3>  Another hash for general case </h3><br>  Last step in <img src="http://tex.s2cms.ru/svg/L_0" alt="L_0">  -sampling, is to understand what to do with the general case.  We will use hashing again.  Take <img src="http://tex.s2cms.ru/svg/O(s)" alt="O (s)">  -independent hash function <img src="http://tex.s2cms.ru/svg/h%20%3A%20%5Bn%5D%20%5Crightarrow%20%5B2%5Ek%5D" alt="h: [n] \ rightarrow [2 ^ k]">  for some <img src="http://tex.s2cms.ru/svg/2%5Ek%20%5Cgeq%20n%5E3" alt="2 ^ k \ geq n ^ 3">  . <br><br>  Let's say that the update <img src="http://tex.s2cms.ru/svg/(i%2C%20%5CDelta)" alt="(i, \ Delta)">  is an <img src="http://tex.s2cms.ru/svg/j" alt="j">  interesting if <img src="http://tex.s2cms.ru/svg/h(i)%20%5Ctext%7B%20mod%20%7D%202%5Ej%20%3D%200" alt="h (i) \ text {mod} 2 ^ j = 0">  .  In other words, in binary record <img src="http://tex.s2cms.ru/svg/h(i)" alt="h (i)">  contains <img src="http://tex.s2cms.ru/svg/j" alt="j">  zeros at the end. <br><br>  Run the algorithm for <img src="http://tex.s2cms.ru/svg/s" alt="s">  -frame vector in parallel by <img src="http://tex.s2cms.ru/svg/%5Clog%20n" alt="\ log n">  levels.  At the level <img src="http://tex.s2cms.ru/svg/j" alt="j">  we will take into account only <img src="http://tex.s2cms.ru/svg/j" alt="j">  - interesting updates.  It is easy to understand that the more <img src="http://tex.s2cms.ru/svg/j" alt="j">  the less chance (and chances <img src="http://tex.s2cms.ru/svg/2%5E%7B-j%7D" alt="2 ^ {- j}">  ) have the update be taken into account. <br><br>  Find the first level with the highest <img src="http://tex.s2cms.ru/svg/j" alt="j">  where there came at least some updates, and try to restore it.  If the recovery is successful, we will return the randomly selected item. <br><br>  There are several points that I want to briefly pay attention to. <br><br>  First, how to choose <img src="http://tex.s2cms.ru/svg/s" alt="s">  .  In general, a vector may have more than <img src="http://tex.s2cms.ru/svg/s" alt="s">  non-zero positions, but with every increase <img src="http://tex.s2cms.ru/svg/j" alt="j">  per unit, mat.  the expectation of non-zero positions drops exactly 2 times.  You can choose a level at which the expectation will be between <img src="http://tex.s2cms.ru/svg/s%20%2F%204" alt="s / 4">  and <img src="http://tex.s2cms.ru/svg/s%20%2F%202" alt="s / 2">  .  Then from Chernov and <img src="http://tex.s2cms.ru/svg/O(s)" alt="O (s)">  independence of the hash function, the probability that the vector will be zero or have more than <img src="http://tex.s2cms.ru/svg/s" alt="s">  nonzero positions will turn out to be exponentially small. <br><br>  This determines the choice <img src="http://tex.s2cms.ru/svg/s%20%3D%20O(%5Clog%20%5Cdelta%5E%7B-1%7D)" alt="s = O (\ log \ delta ^ {- 1})">  where <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  - the permissible probability of failure. <br><br>  Secondly, from <img src="http://tex.s2cms.ru/svg/O(s)" alt="O (s)">  -independence of the hash function implies that for any position the probability to pass the filter will be equal.  Insofar as <img src="http://tex.s2cms.ru/svg/s" alt="s">  - sparse vectors, we can already recover, then getting a uniform distribution is already trivial. <br><br>  So we learned how to choose a random non-zero position according to a uniform distribution. <br><br><h2>  Mix, but do not shake </h2><br>  It remains to understand how to combine everything.  We know that in the graph <img src="http://tex.s2cms.ru/svg/n" alt="n">  vertices.  For each vertex, or rather, each row vector in the incidence matrix, we will <img src="http://tex.s2cms.ru/svg/%5Clog%20n" alt="\ log n">  sketches <img src="http://tex.s2cms.ru/svg/%5Csigma_1(A_v)%2C%20%5Csigma_2(A_v)%2C%20%5Cdots%2C%20%5Csigma_%7B%5Clog%20n%7D(A_v)" alt="\ sigma_1 (A_v), \ sigma_2 (A_v), \ dots, \ sigma _ {\ log n} (A_v)">  for <img src="http://tex.s2cms.ru/svg/L_0" alt="L_0">  -sampling.  On <img src="http://tex.s2cms.ru/svg/i" alt="i">  th iteration algorithm we will use for sampling <img src="http://tex.s2cms.ru/svg/i" alt="i">  sketches <br><br>  When adding an edge <img src="http://tex.s2cms.ru/svg/(u%2C%20v)" alt="(u, v)">  add vertices to all sketches <img src="http://tex.s2cms.ru/svg/u" alt="u">  and <img src="http://tex.s2cms.ru/svg/v" alt="v">  corresponding +1 and -1 respectively. <br><br>  When the ribs are over and we are asked about the components, we will run the tightening algorithm.  On <img src="http://tex.s2cms.ru/svg/i" alt="i">  iteration through <img src="http://tex.s2cms.ru/svg/L_0" alt="L_0">  -sampling from the sketch <img src="http://tex.s2cms.ru/svg/%5Csigma_i(v)" alt="\ sigma_i (v)">  find a neighbor to each vertex.  To pull the edge <img src="http://tex.s2cms.ru/svg/(u%2C%20v)" alt="(u, v)">  , we add all the sketches corresponding <img src="http://tex.s2cms.ru/svg/u" alt="u">  and <img src="http://tex.s2cms.ru/svg/v" alt="v">  .  At each new vertex we will save the list of vertices that were merged into it. <br><br>  Everything.  In the end, just go through the isolated peaks, the history of mergers restore the answer. <br><br><h2>  Who is to blame and what to do again </h2><br>  In fact, the topic of this post has arisen for a reason.  In January, Ilya Razenshtein (@ilyaraz), a graduate student at MIT, came to us at Peter's CS Club and talked about algorithms for big data.  There was a lot of interesting (see <a href="http://compsciclub.ru/courses/compactrepresenting/2016-spring/">course description</a> ).  In particular, Ilya managed to tell the first half of this algorithm.  I decided to finish the job and tell the whole result on Habr√©. <br><br>  In general, if you are interested in mathematics related to computational processes aka Theoretical Computer Science, come to our Academic University in the direction of <a href="http://mit.spbau.ru/csmaster">Computer Science</a> .  Inside they will teach complexity, algorithms and discrete mathematics.  The real science will start from the first semester.  You can get out and listen to courses in the <a href="http://compsciclub.ru/">CS Club</a> and <a href="http://compscicenter.ru/">CS Center</a> .  If you are not from St. Petersburg, there is a hostel.  A great chance to move to the Northern Capital. <br><br>  <a href="http://mit.spbau.ru/admission_form">Apply</a> , get ready and come to us. <br><br><h2>  Sources </h2><br><ul><li>  <a href="http://dimacs.rutgers.edu/~graham/pubs/papers/l0samp.pdf">"On Unifying the Space of L0-Sampling Algorithms", Graham Cormode, Donatella Firmani, 2013</a> </li><li>  <a href="https://people.cs.umass.edu/~mcgregor/papers/12-dynamic.pdf">Analyzing Graph Structure via Linear Measurements, Kook Jin Ahn, Sudipto Guha, Andrew McGregor, 2012</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/276563/">https://habr.com/ru/post/276563/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../276547/index.html">Install Azure Stack TP1</a></li>
<li><a href="../276549/index.html">Query Performance Insight: Who Eats Your Database Resources?</a></li>
<li><a href="../276551/index.html">Procedurally generated world maps on Unity C #, Part 4 (traffic)</a></li>
<li><a href="../276557/index.html">Methods of creating images on the example of Docker</a></li>
<li><a href="../276561/index.html">Automated access to SharePoint. How to facilitate the work of the administrator and to establish control over the distribution of rights</a></li>
<li><a href="../276565/index.html">You are not that paranoidÔºÅ (pre-friday post)</a></li>
<li><a href="../276567/index.html">Online audio advertising: everyone will be heard</a></li>
<li><a href="../276569/index.html">Acceleration of Python scripts without any mental effort</a></li>
<li><a href="../276575/index.html">Forwarding large files. Automatically receive download links to email</a></li>
<li><a href="../276579/index.html">Moscow Python Meetup ‚Ññ32</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>