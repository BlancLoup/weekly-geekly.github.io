<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Clearing web pages of information noise</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Greetings to all! 

 My previous articles were mainly about the theoretical part of Data Mining, today I want to talk about a practical example used i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Clearing web pages of information noise</h1><div class="post__text post__text-html js-mediator-article">  Greetings to all! <br><br>  My previous articles were mainly about the theoretical part of Data Mining, today I want to talk about a practical example used in a Ph.D. thesis (in this regard, this example cannot be considered a full-fledged working project at this stage of development, but it can be considered a prototype). <br><br>  We will clear the web page of the "information noise". 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><h4>  So what's the problem? </h4><br>  The problem is that a good half of websites contain a bunch of unnecessary information on the pages - the so-called ‚Äúinformation noise‚Äù.  This includes navigation, related links, design elements, and, of course, advertising. <br><br>  At the moment, all decisions related to content filtering are tied at the technological level - blocking pop-up windows, JavaScript, Flash, searching for forbidden words, or removing ad units from the database of registered hosts.  Of course, there are other ways, but now is not about that ... <br><br><h4>  The concept of information blocks </h4><br>  The meaning of this concept is the following - to consider a web page not as a whole, but as a set of information blocks, which we will consider as a unit of displayed information.  This approach allows you to select the necessary sections of content and analyze them in the context of the entire page.  Further on this in more detail. <br><br><h4>  Determining the importance of user information </h4><br>  It is clear that not all information is equally useful (important) for the user.  It is also clear that the assessment of importance is a subjective concept, but here I do not pretend to be absolute.  But, intuitively, the importance of information can be divided into three types: <br>  * important information (main content) <br>  * unimportant information (related links, most viewed, ‚Äúthey also buy with this product‚Äù, etc.) <br>  * information garbage (header, basement, advertising, etc.) <br><br>  You can, of course, break into more levels, but, I think, for the time being we will manage these three. <br><br><h4>  Problems and tasks </h4><br>  It was necessary to solve the following tasks to achieve the goal: <br>  * division of the web page into information blocks <br>  * creating a model to assess the importance of a particular unit <br>  * logic for deciding which unit to assign which type of importance <br><br><h4>  Splitting a web page into information blocks </h4><br>  Not quite a trivial task, as it may seem at first glance.  Early approaches were related to 1) analyzing the DOM model 2) analyzing a large number of pages within the site and defining the so-called.  "Template" site.  As a rule, these approaches did not give a good result. <br><br>  The solution is to use the <a href="http://research.microsoft.com/apps/pubs/default.aspx%3Fid%3D70027">VIPS (Vision-based Page Segmentation Algorithm) algorithm from Microsoft Research Asia</a> .  In short, they use a combined approach, namely, the analysis of the DOM model and its own segmentation rules, derived by experts or experimentally. <br><br>  Seen cons: <br>  * library on unmanaged C ++, so there is no tight integration with new controls (for example, with WebBrowser), so I had to play around with integration <br>  * the algorithm uses the property Granularity - i.e.  minimum distance between information blocks.  It is clear that these distances will be different for different sites.  Now you need to pick up hands.  Automatic selection of granularity - the subject of individual research. <br>  * the output of the algorithm produces something like XML, but much worse, for a very long time I had to write a parser, "understanding" this format <br><br>  Despite this, VIPS is quite convenient + for lack of alternatives they took it as a basis. <br><br><h4>  Creating a model to assess the importance of a particular unit </h4><br>  Everything is much more interesting here, as this part was done completely by myself. <br><br>  The main task was to determine the evaluation criteria and the rules by which different blocks differ.  Or more specifically: by what signs can you distinguish the set of links and the main content?  In this case, the percentage of words that are references is certainly higher than in ordinary text.  Further, the average length of the sentences of the main content is mostly larger than in the link unit.  So, the analysis of the main parameters (characteristics) of the blocks can tell what block we are in front of. <br><br>  The model is based on multivariate analysis and regression.  I selected about 20 parameters that could theoretically influence the definition of the type of content.  Next, it was necessary to determine the importance of each parameter in the regression model. <br><br>  Among the parameters were the following: <br>  * average sentence length <br>  * number of words <br>  * number of stop words <br>  * number of links, pictures, lists, etc. <br>  * relative parameters such as the number of link words / the number of all words, the percentage of occurrences of stop words <br>  * etc. <br><br><h4>  Regression model of the importance of information blocks </h4><br>  For this, a program was developed that: <br>  * Chose from Google 100-200 sites <br>  * divided each web page into information blocks <br>  * parsed (parsila) block content by 20 parameters <br>  * put it all in base <br><br>  Further, several experts for each block with their hands put the ‚Äúimportance‚Äù of each block at their discretion. <br><br>  The result was a database, on the basis of which a regression analysis was performed and each parameter was given its importance (degree of influence on the importance rating).  The regression was built in the SPSS math package. <br><br>  The result is a regression model of the type: <br><br>  y (param1, ..., param20) = coef1 * param1 + coef2 * param2 + coef3 * param3 + ... + coef20 * param20 <br><br>  I would say that the most "important" parameter was the percentage of stop words :) <br><br>  Having this model, we transfer the parameters of a specific block and get its quantitative (number) assessment.  It is clear that a block that receives a larger numerical value will be more ‚Äúimportant‚Äù for the user. <br><br>  The accuracy of this model can be improved by analyzing a large number of studied web pages.  After all, 200 pages for a very accurate model is not enough, but enough for our prototype. <br><br><h4>  The definition of "important" blocks </h4><br>  At the beginning, I used some ‚Äúboundaries‚Äù of importance assessment according to the type ‚Äúmore than 20 - main content, more than 10, but less than 20 ‚Äî not the main content‚Äù, etc.  But this approach did not produce results, since the ‚Äúpage to page is different‚Äù and coefficients could differ significantly within several web pages. <br><br>  A good solution was the use of the fuzzy clustering algorithm with-means, which for a particular page "decides" how to cluster our blocks by their numerical values, and "spreads" them into three clusters (three, because three types of importance). <br><br><h4>  What is the result? </h4><br>  As a result, we get ONLY the main content (well, of course, ideally, see the problems above). <br><br>  The implementation of the prototype is executed in the form of a browser codenamed ‚ÄúSmartBrowser‚Äù and can be quietly pulled from the site <a href="http://smartbrowser.codeplex.com/">http://smartbrowser.codeplex.com/</a> . <br><br>  Requirements: <br>  * Windows 32bit (VIPS dll needs to be registered in the system) <br>  * .NET Framework 3.5 <br><br><h4>  Examples </h4><br>  Examples can be found on <a href="http://msug.vn.ua/blogs/datamining/archive/2009/04/11/web-page-content-analysis-with-quot-smartbrowser-quot.aspx">this page</a> , where the news about the program was first published. <br><br>  This is what the program looks like: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5fb/958/a01/5fb958a01cdb8b21f816ba5c77147b44.png" alt="image"><br><br><h4>  Reviews </h4><br>  ‚ÄúSome‚Äù people from America wanted to be a sponsor of further development, but then the crisis ‚Äúburst out‚Äù and it was all over. <br><br>  The guys from Microsoft Research Asia (the authors of the VIPS algorithm) spoke positively about the idea and wished good luck in its development. <br><br>  If you have comments, want to develop this topic or just help with advice - always happy.  If someone has some groundwork in this area - let's cooperate :) </div><p>Source: <a href="https://habr.com/ru/post/66221/">https://habr.com/ru/post/66221/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../66210/index.html">And how did you choose your nickname,%% username?</a></li>
<li><a href="../66211/index.html">Ratings Service / Online service + REST API for searching movie ratings</a></li>
<li><a href="../66216/index.html">Nikon Coolpix S1000PJ: the first camera with a projector</a></li>
<li><a href="../66219/index.html">Braid will be released on the PlayStation 3</a></li>
<li><a href="../66220/index.html">KDE 4.3.0 released today!</a></li>
<li><a href="../66225/index.html">MOESK: Star Wars rest or Chubais is gone - the ice has moved !!!</a></li>
<li><a href="../66226/index.html">Website Security</a></li>
<li><a href="../66230/index.html">Firebug 1.4.2 - now in Russian!</a></li>
<li><a href="../66231/index.html">Donate or not donate local video content to Youtube?</a></li>
<li><a href="../66233/index.html">The program for determining the coordinates through the service Google Maps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>