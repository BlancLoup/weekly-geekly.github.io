<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Learn OpenGL. Lesson 4.11 - Smoothing</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Smoothing 
 In your research on three-dimensional rendering, you must have come across the appearance of pixelated chipping along the edges of the ren...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Learn OpenGL. Lesson 4.11 - Smoothing</h1><div class="post__text post__text-html js-mediator-article"><img align="left" src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="Ogl3" width="300"><h1>  Smoothing </h1><br>  In your research on three-dimensional rendering, you must have come across the appearance of pixelated chipping along the edges of the rendered models.  These marks inevitably appear due to the principle of converting vertex data into screen fragments with a rasterizer somewhere in the depth of the OpenGL pipeline.  For example, even on such a simple figure as a cube, these artifacts are already noticeable: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qi/-k/fn/qi-kfntvlxfnpas0s71youugf9s.png"></div><br>  A quick glance may not notice anything, but it is worth looking more closely and the marked notches appear on the faces of the cube.  Let's try to enlarge the image: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/og/qg/i3/ogqgi3u1i0rdxewxdfxzxfelqn0.png"></div><br>  No, this is no good.  Is this image quality you want to see in the release version of your application? <br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Content</b> <div class="spoiler_text">  Part 1. Start 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  <a href="https://habrahabr.ru/post/310790/">Opengl</a> </li><li>  <a href="https://habrahabr.ru/post/311198/">Creating a window</a> </li><li>  <a href="https://habrahabr.ru/post/311234/">Hello window</a> </li><li>  <a href="https://habrahabr.ru/post/311808/">Hello triangle</a> </li><li>  <a href="https://habrahabr.ru/post/313380/">Shaders</a> </li><li>  <a href="https://habrahabr.ru/post/315294/">Textures</a> </li><li>  <a href="https://habrahabr.ru/post/319144/">Transformations</a> </li><li>  <a href="https://habrahabr.ru/post/324968/">Coordinate systems</a> </li><li>  <a href="https://habrahabr.ru/post/327604/">Camera</a> </li></ol><br>  Part 2. Basic lighting <br><br><ol><li>  <a href="https://habrahabr.ru/post/329592/">Colors</a> </li><li>  <a href="https://habrahabr.ru/post/333932/">Lighting Basics</a> </li><li>  <a href="https://habrahabr.ru/post/336166/">Materials</a> </li><li>  <a href="https://habrahabr.ru/post/337550/">Texture Cards</a> </li><li>  <a href="https://habrahabr.ru/post/337642/">Sources of light</a> </li><li>  <a href="https://habrahabr.ru/post/338254/">Multiple light sources</a> </li></ol><br>  Part 3. Loading 3D Models <br><br><ol><li>  <a href="https://habrahabr.ru/post/338436/">Assimp library</a> </li><li>  <a href="https://habrahabr.ru/post/338436/">Mesh mesh class</a> </li><li>  <a href="https://habrahabr.ru/post/338998/">Model class</a> </li></ol><br>  Part 4. OpenGL advanced features <br><br><ol><li>  <a href="https://habrahabr.ru/post/342610/">Depth test</a> </li><li>  <a href="https://habrahabr.ru/post/344238/">Stencil test</a> </li><li>  <a href="https://habrahabr.ru/post/343096/">Mixing colors</a> </li><li>  <a href="https://habrahabr.ru/post/346964/">Face clipping</a> </li><li>  <a href="https://habrahabr.ru/post/347354/">Frame buffer</a> </li><li>  <a href="https://habrahabr.ru/post/347750/">Cubic cards</a> </li><li>  <a href="https://habrahabr.ru/post/350008/">Advanced data handling</a> </li><li>  <a href="https://habrahabr.ru/post/350156/">Advanced GLSL</a> </li><li>  <a href="https://habrahabr.ru/post/350782/">Geometric Shader</a> </li><li>  <a href="https://habrahabr.ru/post/352962/">Instancing</a> </li><li>  <b>Smoothing</b> </li></ol><br></div></div><br>  The effect of the apparent visibility of the pixel structure of an image along the edges of objects is called aliasing.  In the computer graphics industry, quite a few techniques have been accumulated, called anti-aliasing or anti-aliasing techniques, which are struggling with this effect, allowing for smooth transitions at the boundaries of objects. <br><br>  So, for example, one of the first was the <i>super sampling anti-aliasing</i> ( <i>SSAA</i> ) technique.  The implementation is done in two passes: first, the render goes to an off-screen frame buffer with a resolution that is noticeably larger than the screen;  then the image was transferred to the screen frame buffer with a decrease.  This data redundancy due to resolution differences was used to reduce the aliasing effect and the method worked fine, but there was one ‚ÄúBut‚Äù: performance.  The conclusion of the scene in a huge resolution took away a lot of power from the GPU and the age of fame of this technology was short-lived. <br><br>  But from the ashes of the old technology, a new, more advanced one was born: <i>multi sampling anti-aliasing</i> ( <i>MSAA</i> ).  It is based on the ideas of SSAA, but implements them by a much more efficient method.  In this tutorial, we will look at the MSAA approach, which is natively available in OpenGL. <br><br><h3>  Multisampling </h3><br>  To understand the essence of multisampling and how it works, we first have to go deeper into the guts of OpenGL and look at the work of its rasterizer. <br><br>  A rasterizer is a set of algorithms and procedures that stand between the finally processed vertex data and the fragment shader.  The rasterizer receives all vertices belonging to the primitive as input and converts this data into a set of fragments.  Vertex coordinates, theoretically, can be absolutely any, but not the coordinates of the fragments - they are strictly limited by the resolution of your output device and the size of the window.  And almost never the coordinates of the vertex of the primitive will not be superimposed on the fragments one-on-one: one way or another, the rasterizer will have to decide in some way in which fragment and by what screen coordinate each of the vertices will appear. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yw/rs/qf/ywrsqffdookjzfskr4pk9epax2g.png"></div><br>  The image shows a grid representing screen pixels.  In the center of each of them is <i>the sampling / sampling point</i> , which is used to determine whether the triangle covers a given pixel.  Red marked sampling points covered with a triangle - for them the rasterizer will generate the corresponding fragment.  Despite the fact that the edges of the triangle in some places overlap some pixels, they do not overlap the sampling point - here the fragment will not be created and the fragment shader for this pixel will not be executed. <br><br>  I think you already guessed the reasons for aliasing.  The render of this triangle on the screen will look like this: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/g_/zk/ou/g_zkouwtpzpp0irhhjlzuytikas.png"></div><br>  Because of the finiteness of the number of pixels on the screen, some located along the edges of the triangle will be painted over, and some will not.  As a result, it turns out that primitives are not rendered with smooth edges, which is manifested in the form of those notches. <br><br>  When using multisampling, not one point is used to determine the overlap of a pixel by a triangle, but several (hence the name).  Instead of a single sampling point in the center of the pixel, 4 subsample points will be used to determine the overlap, arranged according to a certain pattern.  The consequence is that the color buffer size should also increase fourfold (in terms of the number of subsample points used). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/r_/6x/tc/r_6xtc3jk43ys5r64spydjxcigg.png"></div><br>  The standard overlap definition is shown on the left.  For the selected pixel, the fragment shader will not be executed, and it will remain unpainted because no overlap has been registered.  The case on the right shows a multisampling case, where each pixel contains 4 subsample points.  Here you can see that the triangle covers only 2 subsample points. <br><blockquote>  The number of subsample points can be changed within certain limits.  A greater number of points - better quality smoothing. </blockquote>  From this point on, everything that happens becomes more interesting.  Having determined that the two points of the subsample pixel were covered with a triangle, it is necessary to derive the resulting color for this pixel.  The first guess would be to execute a fragment shader for each subsample point covered by a triangle and then average the colors of the whole subsample points in a pixel.  In this case, we would have to run the fragment shader several times with the vertex data interpolated to the coordinates of each of the overlapped subsampling points (twice in this example) and save the resulting colors at these points.  Fortunately, in fact, the multisampling process does not work that way - otherwise we would have to perform a considerable number of additional calls to the fragment shader, which would hit the performance a lot. <br><br>  In fact, when using MSAA, the fragment shader is executed exactly once, regardless of the number of subsample points closed by the primitive.  The fragment shader is executed with the vertex data interpolated to the <b>center of the</b> pixel, and the color obtained when it is executed is stored in each of the primitive subsample sampling points.  When all the subsampling points of the frame buffer are filled with the colors of the primitives drawn by us, then a pixel-by-pixel averaging of colors to one value per pixel occurs.  In this example, only two subsample points were overlapped and, accordingly, filled with the color of the triangle.  The remaining two were filled with a transparent background color.  When mixing the colors of these subsamples turned out to be a light blue color. <br><br>  The frame buffer as a result contains the image of primitives with much more smoothed edges.  See how the definition of subsample coverage on an already familiar triangle looks like: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lu/nb/86/lunb86hlebe8qynu8qwelu3stom.png"></div><br>  It can be seen that each pixel contains four subsample points (the pixels that are not important for example are left blank), while the subsample points covered with a triangle are marked with blue, and the uncovered ones are marked with gray.  A fragmentary shader will be called once inside the perimeter of a triangle, all of which will be saved in all four subsamples.  On the edges, not all subsamples will be covered, so the result of the fragment shader will be saved only in a part of them.  Depending on the number of triangle-covered subsample points, the resulting pixel color is determined based on the color of the triangle itself and other colors stored at the subsample points. <br><br>  Simply put, the more subsamples covered by a triangle, the more the color of the pixel will correspond to the color of the triangle.  If you now fill the colors of the pixels as in the example with a triangle without using multisampling, the following picture will be released: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ib/p9/nf/ibp9nfgobeph_jwoi1wp-nzxhum.png"></div><br>  As you can see, the fewer subsamples of a pixel belong to a triangle, the less its color corresponds to the color of a triangle.  The clear borders of the triangle are now surrounded by pixels of a slightly lighter shade, which creates a smoothing effect when viewed from a distance. <br>  But not only the color values ‚Äã‚Äãare subject to the operation of the multisampling algorithm: the depth buffer and the stencil also begin to use multiple subsamples for the pixel.  The vertex depth value is interpolated for each of the subsample points before performing the depth test.  Stencil values ‚Äã‚Äãare not stored for the entire pixel, but for each of the subsample points.  For us, this also means an increase in the amount of memory occupied by these buffers, in accordance with the number of subsamples used. <br><br>  Here we looked at the very basics of how multisampling works.  The true internal logic of the rasterizer will be more complicated than the review given here.  However, for the purposes of a general understanding of the principle and progress of multisampling, this is quite enough. <br><br><h3>  OpenGL multisampling </h3><br>  To use multisampling in OpenGL, you must use a color buffer that can store more than one color value per pixel (because MSAA means storing the color value at the subsampling points).  Thus, we need some special type of buffer that can store a given number of subsamples - a multisample buffer. <br><br>  Most window systems can provide us with a multisample buffer instead of a standard color buffer.  GLFW also has this functionality; all that is required is to set a special flag that signals our desire to use a buffer with N subsample points, instead of the standard one: <br><br><pre><code class="cpp hljs">glfwWindowHint(GLFW_SAMPLES, <span class="hljs-number"><span class="hljs-number">4</span></span>);</code> </pre> <br>  Now, calling <i>glfwCreateWindow</i> will create an output window with a color buffer storing four subsamples for each screen coordinate.  GLFW will also automatically create depth and stencil buffers using the same four subsample points per pixel.  And the size of each of these buffers will grow four times. <br><br>  After creating multisample buffers by GLWL, it remains to enable multisampling mode already in OpenGL: <br><br><pre> <code class="hljs lisp">glEnable(<span class="hljs-name"><span class="hljs-name">GL_MULTISAMPLE</span></span>)<span class="hljs-comment"><span class="hljs-comment">;</span></span></code> </pre> <br>  In most OpenGL drivers, multisampling is active by default, so this call will be redundant, but explicitly including the functions you need is a good tone, and it also allows you to activate the mode regardless of the defaults of the specific implementation. <br><br>  Actually, after ordering the multisample buffer and enabling the mode, all our work is finished, since everything else falls on the OpenGL rasterizer mechanisms and happens without our participation.  If we now try to bring out the green cube, familiar from the very beginning of the lesson, then we will see that its faces are now much smoother: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ym/np/os/ymnposeacpwq0xkqon6jdztx00y.png"></div><br>  Indeed, the edges of this cube look much more attractive.  And the same effect will affect any object in your scene. <br><br>  The source code of the example is <a href="https://learnopengl.com/code_viewer.php%3Fcode%3Dadvanced/anti_aliasing_multisampling">here</a> . <br><br><h1>  Off-screen multisampling </h1><br>  Creating a basic frame buffer with MSAA enabled is a simple task, thanks to GLFW.  If we want to create our own buffer, for example, for an off-screen render, then we will have to take this process into our own hands. <br><br>  There are two main methods of creating buffers with multisampling for further attachment to the frame buffer, similar to the examples already sorted out from the corresponding <a href="https://habrahabr.ru/post/347354/">lesson</a> : texture attachments and attachments of the render buffer type. <br><br><h4>  Multisampling Texture Attachment </h4><br>  To create a texture that supports multiple subsamples, use the texture target type <i>GL_TEXTURE_2D_MULTISAPLE</i> and the function <i>glTexImage2DMultisample</i> instead of the usual <i>glTexImage2D</i> : <br><br><pre> <code class="hljs lisp">glBindTexture(<span class="hljs-name"><span class="hljs-name">GL_TEXTURE_2D_MULTISAMPLE</span></span>, tex)<span class="hljs-comment"><span class="hljs-comment">; glTexImage2DMultisample(GL_TEXTURE_2D_MULTISAMPLE, samples, GL_RGB, width, height, GL_TRUE); glBindTexture(GL_TEXTURE_2D_MULTISAMPLE, 0);</span></span></code> </pre> <br>  The second argument specifies the number of subsamples in the created texture.  If the last argument is set to <i>GL_TRUE</i> , then the texture will use the same number and position of subsample points for each texel. <br><br>  To attach such a texture to the framebuffer object, use the same <i>glFramebufferTexture2D</i> call, but this time with the specified texture type GL_TEXTURE_2D_MULTISAMPLE: <br><br><pre> <code class="hljs lisp">glFramebufferTexture2D(<span class="hljs-name"><span class="hljs-name">GL_FRAMEBUFFER</span></span>, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D_MULTISAMPLE, tex, <span class="hljs-number"><span class="hljs-number">0</span></span>)<span class="hljs-comment"><span class="hljs-comment">;</span></span></code> </pre> <br>  As a result, the current frame buffer will be provided with a color-based texture buffer with multisampling support. <br><br><h4>  Renderbuffer with multisampling </h4><br>  Creating a render buffer with multiple subsample points is as easy as creating such a texture.  Moreover, it is even simpler: all you need to do is change the call to <i>glRenderbufferStorage</i> to <i>glRenderbufferStorageMultisample</i> when preparing memory for the currently rendered buffer manager: <br><br><pre> <code class="hljs lisp">glRenderbufferStorageMultisample(<span class="hljs-name"><span class="hljs-name">GL_RENDERBUFFER</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, GL_DEPTH24_STENCIL8, width, height)<span class="hljs-comment"><span class="hljs-comment">;</span></span></code> </pre> <br>  There is only one additional parameter from the new one, going after the target type of the render buffer, which indicates the number of subsample points.  Here we have four such points. <br><br><h4>  Render frame buffer with multisampling </h4><br>  The render buffer in the multisample frame buffer goes automatically, without the required actions on our part.  Every time we render into an attached frame buffer, the rasterizer itself performs the necessary operations.  And we get a color (depth, stencil) buffer with multiple subsample points at the output.  Since the frame buffer with multiple subsample points is still somewhat different from the usual one, it will not be possible to directly use its separate buffers for various operations, such as texture sampling in the shader. <br><br>  An image with multisampling support contains more information than a regular one, therefore it is necessary <i>to resolve</i> ( <i>resolve</i> ) this image, or, in other words, convert its resolution to a smaller one.  This operation is usually performed by calling <i>glBlitFramebuffer</i> , which allows you to copy the area of ‚Äã‚Äãone frame buffer to another with the associated resolution of the present buffers with multiple subsampling points. <br>  This function transfers the source area specified by the four coordinates in the screen space to the destination area also defined by the four screen coordinates.  I recall the lesson on <a href="https://habrahabr.ru/post/347354/">frame buffers</a> : if we bind a frame buffer object to the target <i>GL_FRAMEBUFFER</i> , then the binding is implicitly carried out both to the target read from the frame buffer and to the write target to the frame buffer.  To bind to these goals separately, special target identifiers are used: <i>GL_READ_FRAMEBUFFER</i> and <i>GL_DRAW_FRAMEBUFFER,</i> respectively. <br><br>  During its operation, the <i>glBlitFramebuffer</i> function uses these anchor points to determine which of the frame buffers is the source of the image and which is the receiver.  As a result, we could simply transfer the image from the multisample frame buffer to the standard using blitting: <br><br><pre> <code class="hljs lisp">glBindFramebuffer(<span class="hljs-name"><span class="hljs-name">GL_READ_FRAMEBUFFER</span></span>, multisampledFBO)<span class="hljs-comment"><span class="hljs-comment">; glBindFramebuffer(GL_DRAW_FRAMEBUFFER, 0); glBlitFramebuffer(0, 0, width, height, 0, 0, width, height, GL_COLOR_BUFFER_BIT, GL_NEAREST);</span></span></code> </pre> <br>  By assembling and running the application, we would get an image identical to the previous example that did not use the frame buffer: an acid-green cube drawn using MSAA, as can be seen by examining its faces ‚Äî they are still smooth: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ym/np/os/ymnposeacpwq0xkqon6jdztx00y.png"></div><br>  Sample sources are <a href="https://learnopengl.com/code_viewer_gh.php%3Fcode%3Dsrc/4.advanced_opengl/11.anti_aliasing_offscreen/anti_aliasing_offscreen.cpp">here</a> . <br><br>  But what if the image from the frame buffer with multiple subsample points we would like to use as a data source for post-processing?  We cannot directly use multisample textures in the shader.  But you can try to transfer the image from the multisample frame buffer using blit to another, with the usual, not multisample, buffers.  And then you can use a regular image as a resource for post-processing, in essence getting all the benefits of MSAA and adding post-processing on top of it.  Yes, for this whole process you will have to create a separate frame buffer, which is purely an auxiliary object for enabling MSAA textures into regular ones, which can be used in the shader.  In the form of pseudocode, the process looks like this: <br><br><pre> <code class="hljs ruby">unsigned int msFBO = CreateFBOWithMultiSampledAttachments(); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>     FBO        ... glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT<span class="hljs-number"><span class="hljs-number">0</span></span>, GL_TEXTURE_2D, screenTexture, <span class="hljs-number"><span class="hljs-number">0</span></span>); ... <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(!glfwWindowShouldClose(window)) { ... glBindFramebuffer(msFBO); ClearFrameBuffer(); DrawScene(); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>       glBindFramebuffer(GL_READ_FRAMEBUFFER, msFBO); glBindFramebuffer(GL_DRAW_FRAMEBUFFER, intermediateFBO); glBlitFramebuffer(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, width, height, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, width, height, GL_COLOR_BUFFER_BIT, GL_NEAREST); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>       ,     glBindFramebuffer(GL_FRAMEBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>); ClearFramebuffer(); glBindTexture(GL_TEXTURE_2D, screenTexture); DrawPostProcessingQuad(); ... }</code> </pre> <br>  If we add this code to post processing examples from the lesson on the <a href="https://habrahabr.ru/post/347354/">frame buffer</a> , we can apply all those effects to the image of the scene without jagged edges.  For example, with the blur effect you get something like this: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tt/cg/ll/ttcgll2qb5whbrs8xatxfibvkm4.png"></div><br><blockquote>  Since a standard texture with a single subsample point is used for postprocessing, some processing methods (searching for boundaries, for example) can add noticeable sharp edges and notches to the scene.  To bypass this artifact you will have to either blur the result or implement your own smoothing algorithm. </blockquote>  As you can see, for the combination of MSAA and off-screen rendering techniques, some details have to be taken into account.  But all the extra effort pays off with a much higher quality of the resulting image.  However, remember that the activation of multisampling can still significantly affect the final performance, especially when a large number of subsample points are set. <br><br><h1>  Own smoothing method </h1><br>  In fact, it is possible to transfer multisample textures directly into shaders, without blitting into auxiliary ordinary one.  In this case, the GLSL capabilities provide access to individual subsampling points in the texture, which can be used to create your own smoothing algorithms (which is often in large graphic applications). <br><br>  To begin, you will need to create a special sampler of the type <i>sampler2DMS</i> , instead of the usual <i>sampler2D</i> : <br><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">uniform</span></span> sampler2DMS screenTextureMS;</code> </pre> <br>  And to get the color value at the sampling point, use the following function: <br><br><pre> <code class="hljs lisp">vec4 colorSample = texelFetch(<span class="hljs-name"><span class="hljs-name">screenTextureMS</span></span>, TexCoords, <span class="hljs-number"><span class="hljs-number">3</span></span>)<span class="hljs-comment"><span class="hljs-comment">; //   4  </span></span></code> </pre> <br>  Here you can see an additional argument - the number of the subsample point (counting from zero), which is addressed. <br><br>  We will not consider the details of creating special smoothing algorithms here - this is nothing more than a starting point for your own research on this topic. <br><br>  <b>PS</b> : We have a <a href="https://t.me/joinchat/Cpb05A46UPpMWdNVVCb4Vg">telegram-konf</a> to coordinate transfers.  If there is a serious desire to help with the translation, then you are welcome! </div><p>Source: <a href="https://habr.com/ru/post/351706/">https://habr.com/ru/post/351706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../351694/index.html">Java 10 General Availability</a></li>
<li><a href="../351696/index.html">Why pay a reputation manager</a></li>
<li><a href="../351698/index.html">The most common questions on the interview programmer graphics</a></li>
<li><a href="../351700/index.html">Trends in outsourcing. Forecast for 2020</a></li>
<li><a href="../351704/index.html">History of ES6 Modules</a></li>
<li><a href="../351708/index.html">Preview RamblerFront & # 4</a></li>
<li><a href="../351710/index.html">Four levels of one-page apps that you need to know about</a></li>
<li><a href="../351712/index.html">Security Week 9: Miner eliminates competitors, snapshots for traffic lights and extremely intrusive cameras</a></li>
<li><a href="../351714/index.html">Evil by Design: interfaces from Mephistopheles (part two)</a></li>
<li><a href="../351716/index.html">The conference program of the Neurodata Lab and ITMO for Emotion AI, St. Petersburg, March 30</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>