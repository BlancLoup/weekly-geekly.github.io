<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Efficient multithreading in Python</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I want to share a simple recipe on how to efficiently perform a large number of http requests and other I / O tasks from regular Python. The most corr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Efficient multithreading in Python</h1><div class="post__text post__text-html js-mediator-article"> I want to share a simple recipe on how to efficiently perform a large number of http requests and other I / O tasks from regular Python.  The most correct thing to do would be to use asynchronous frameworks like Tornado or gevent.  But sometimes this option is not suitable, because it is problematic to build the event loop into an already existing project. <br><br>  In my case, a Django application already existed, from which some very small files had to be uploaded to AWS s3 about once a month.  As time went on, the number of files began to approach 50,000, and it was tiresome to unload them one by one.  As you know, s3 does not support multiple updates for one PUT request, and the experimentally set maximum speed of requests from the ec2 server in the same data center does not exceed 17 per second (which is not enough, by the way).  Thus, the update time for 50 thousand files began to approach one hour. <br><br>  Pythonists from childhood know that there is no point in using threads (threads of the operating system) because of the global interpreter loc.  But few realize that, like any lok, this is released from time to time.  In particular, this occurs during input-output operations, including network ones.  This means that streams can be used to parallelize http-requests ‚Äî while one thread is waiting for a response, another one calmly processes the result of the previous one or prepares the next one. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It turns out, all you need is a pool of threads that will execute queries.  Fortunately, such a pool has already been written.  Starting with version 3.2, for unifying all asynchronous work in Python, the library <code>concurrent.futures</code> appeared.  For the second version of Python, there is a backport under the name <a href="https://pypi.python.org/pypi/futures">futures</a> .  The code to the disgrace is simple: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> concurrent.futures <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ThreadPoolExecutor <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> ThreadPoolExecutor(concurrency) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> executor: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> executor.map(upload, queryset): <span class="hljs-keyword"><span class="hljs-keyword">pass</span></span></code> </pre><br>  Here <code>concurrency</code> is the number of workflows, <code>upload</code> is a function that performs the task itself, <code>queryset</code> is an iterator of objects that will be transferred one by one into the task.  Already this code with a concurrency of 150 could get through to the Amazon server ‚âà 450 requests per second. <a name="habracut"></a><br><br>  There is a need for a note regarding the tasks: they must be thread-safe.  Those.  several parallel tasks should not have shared resources, or should manage them correctly.  The global interpreter lock is a bad helper here - it does not guarantee that the execution of the thread will not be interrupted in the most inappropriate place.  If you use only urllib3, requests or boto, there is nothing to worry about, they are already thread-safe.  About other libraries you need to clarify.  Also, your own code can be thread safe. <br><br>  As time went on, the number of files began to approach 200 thousand.  What do you think, how much memory can occupy 200 thousand Django-models?  And 200 thousand futures?  And 200 thousand tasks?  All together about a gigabyte.  It became clear that sending everything to the executor at once was not an option.  But why not add new tasks at the end of the previous ones?  At the very beginning we add the number of tasks equal to the number of threads, we keep records of how many tasks are set, how many are completed.  We do not store futures ourselves, do not give them outside.  It turns out a very cool function that can be reused <font color="gray">(carefully, this is not the final version)</font> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> concurrent.futures <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ThreadPoolExecutor, Future <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">task_queue</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(task, iterator, concurrency=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">submit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: obj = next(iterator) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> StopIteration: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> stats[<span class="hljs-string"><span class="hljs-string">'delayed'</span></span>] += <span class="hljs-number"><span class="hljs-number">1</span></span> future = executor.submit(task, obj) future.add_done_callback(upload_done) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">upload_done</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(future)</span></span></span><span class="hljs-function">:</span></span> submit() stats[<span class="hljs-string"><span class="hljs-string">'delayed'</span></span>] -= <span class="hljs-number"><span class="hljs-number">1</span></span> stats[<span class="hljs-string"><span class="hljs-string">'done'</span></span>] += <span class="hljs-number"><span class="hljs-number">1</span></span> executor = ThreadPoolExecutor(concurrency) stats = {<span class="hljs-string"><span class="hljs-string">'done'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">'delayed'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>}  <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(concurrency): submit() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> stats</code> </pre><br>  It has only three actions: the <code>submit</code> function, which selects the next object from the iterator and creates a task for it, <code>upload_done</code> , which is called at the end of the task and sets the next one, and the cycle in which the first tasks are set.  We try to run: <br><br><pre> <code class="python hljs">stats = task_queue(upload, queryset.iterator(), concurrency=<span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\rdone {done}, in work: {delayed} '</span></span>.format(**stats), sys.stdout.flush() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> stats[<span class="hljs-string"><span class="hljs-string">'delayed'</span></span>] == <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> time.sleep(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)</code> </pre><br>  Great, it works!  It already uses the <code>iterator</code> querisset method.  It seems that it could be used in the first example with the <code>executor.map</code> function, but <code>executor.map</code> selects the entire iterator at once and makes it useless.  Immediately the objects are really selected, one for each running thread. <br><br>  However, there is a problem: it is worth increasing the number of streams, as exceptions of ‚ÄúValueError: generator already executing‚Äù begin to pour.  The code uses the same generator from all threads, so sooner or later two threads try to select values ‚Äã‚Äãat the same time (in fact, this can happen when there are only two threads, but with a lower probability).  The same applies to the counters, sooner or later, the two processes simultaneously consider one value, then both add one and both write down the ‚Äúinitial number + 1‚Äù rather than the ‚Äúinitial number + 2‚Äù.  Therefore, all work with shared objects must be wrapped in locks. <br><br>  There are other problems.  There is no handling of errors that may occur during the execution of a task.  If you interrupt the execution with ctrl + c, the main thread will throw an exception, and the rest will continue until the very end, so you need a mechanism for forcing the queue.  The executor just has a shutdown method for this purpose and one could give the executor out to stop him when the user presses ctrl + c.  But there is a better option: you can create futures that will be resolved upon completion of all the work and clean up the executor if someone cancels it from the outside.  Here is a version that takes into account all these errors: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">task_queue</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(task, iterator, concurrency=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">, on_fail=lambda _: None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">submit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: obj = next(iterator) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> StopIteration: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> result.cancelled(): <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> stats[<span class="hljs-string"><span class="hljs-string">'delayed'</span></span>] += <span class="hljs-number"><span class="hljs-number">1</span></span> future = executor.submit(task, obj) future.obj = obj future.add_done_callback(upload_done) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">upload_done</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(future)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io_lock: submit() stats[<span class="hljs-string"><span class="hljs-string">'delayed'</span></span>] -= <span class="hljs-number"><span class="hljs-number">1</span></span> stats[<span class="hljs-string"><span class="hljs-string">'done'</span></span>] += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> future.exception(): on_fail(future.exception(), future.obj) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> stats[<span class="hljs-string"><span class="hljs-string">'delayed'</span></span>] == <span class="hljs-number"><span class="hljs-number">0</span></span>: result.set_result(stats)  <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cleanup</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(_)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io_lock: executor.shutdown(wait=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)  io_lock = threading.RLock() executor = ThreadPoolExecutor(concurrency) result = Future() result.stats = stats = {<span class="hljs-string"><span class="hljs-string">'done'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">'delayed'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>} result.add_done_callback(cleanup) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io_lock: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(concurrency): submit()  <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result</code> </pre><br>  Here you need to use reentrant lok, because there is a certain probability that a very short task will be completed before the handler is <code>add_done_callback</code> to <code>add_done_callback</code> , and then the handler will be executed immediately in the same thread and will try to capture the lok again.  Dedlok will turn out.  Reentrant Lok will allow the same flow that captured it for the first time, calmly go in again, but will not allow itself to be captured from another flow until the first flow releases it as many times as it captured.  The code that uses this task queue changes a little: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> concurrent.futures <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ThreadPoolExecutor, Future, TimeoutError  result = task_queue(upload, queryset.iterator(), concurrency=<span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> result.done(): <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: result.result(<span class="hljs-number"><span class="hljs-number">.2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> TimeoutError: <span class="hljs-keyword"><span class="hljs-keyword">pass</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\rdone {done}, in work: {delayed} '</span></span>.format(**result.stats), sys.stdout.flush() <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> KeyboardInterrupt: result.cancel() <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span></code> </pre><br>  You no longer need to stupidly fall asleep every 200 milliseconds, you can fall asleep smartly, waiting for the queue to complete.  And in case of interruption stop the queue. <br><br>  <s>It was getting dark.</s>  As time went on, the number of files began to approach 1.5 million.  Despite the fact that everything looked as if everything was working with fixed memory consumption (the number of threads, futures and Django models should not change during the whole run), memory consumption still grew.  It turned out that <code>queryset.iterator()</code> does not work as expected.  Objects are actually created only when they are explicitly selected from the iterator, but the driver‚Äôs response to the raw database is still deleted immediately.  It turns out about 500 megabytes per million lines.  The solution to this problem is quite obvious: you need to make requests not for all objects at once, but to divide the portions.  In this case, it is necessary to avoid sampling with an offset, because a query of the type LIMIT 100 OFFSET 200000 actually means that the DBMS must be run through 200100 records.  Instead of offset, use a field selection with an index. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">real_queryset_iterator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(qs, pk=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'pk'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, chunk_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5000</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> qs = qs.order_by(pk)  chunk = list(qs[:chunk_size]) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> chunk: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> chunk: <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> item last_pk = getattr(chunk[<span class="hljs-number"><span class="hljs-number">-1</span></span>], pk) chunk = list(qs.filter(**{pk + <span class="hljs-string"><span class="hljs-string">'__gt'</span></span>: last_pk})[:chunk_size])</code> </pre><br>  Here pk is more like a pagination key than primary.  However, often the primary is well suited for this role.  Such an iterator actually consumes a fixed amount of memory and runs no slower than a sample at a time.  But if you increase the number of streams, another problem arises.  In Jang, database connections are local to threads, so when a new thread makes a request, a new connection is created.  Sooner or later, the number of connections reaches a critical number and an exception similar to this occurs: <br><br><pre> <code class="hljs pgsql">OperationalError: FATAL: remaining <span class="hljs-keyword"><span class="hljs-keyword">connection</span></span> slots are reserved <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> non-<span class="hljs-keyword"><span class="hljs-keyword">replication</span></span> <span class="hljs-keyword"><span class="hljs-keyword">superuser</span></span> connections</code> </pre><br>  The correct solution would be to use the same connection for all threads, since  we have already limited the ability to simultaneously make requests from different threads.  There are no standard tools for this in Djanga, but this can be done with the help of a hack, replacing the <code>threading.local</code> object with a regular object: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> django.db <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> connections, DEFAULT_DB_ALIAS connections._connections = type(<span class="hljs-string"><span class="hljs-string">'empty'</span></span>, (object,), {})() connections[DEFAULT_DB_ALIAS].allow_thread_sharing = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  But you have to understand that this will kill the database thread safety in the rest of the application, so this option is only suitable for commands launched from the console.  A more humane option is to close the connection after each request, or after each element, which gives a not very large overhead. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">close_connection_iterator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(iterator, db=DEFAULT_DB_ALIAS)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> iterator: connections[db].close() <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> item result = task_queue( upload, close_connection_iterator(real_queryset_iterator(queryset)), concurrency=<span class="hljs-number"><span class="hljs-number">150</span></span> )</code> </pre><br>  There is a third solution: use a separate stream that will communicate with the database, transferring objects to other threads.  This option does not break anything else in the rest of the application and does not introduce the overhead of permanently re-opening connections.  But its implementation is quite complex and draws no less than a separate article. <br><br>  Perhaps it will take time, the number of files will increase to 10 million and new problems will appear.  But while it seems that the main problem will be that such an update will take about eight hours and will cost $ 50 only for PUT requests at current Amazon prices. <br><br>  Some theses from the read: <br><ol><li>  I / O streams on Python work well, but care must be taken for isolation. </li><li>  You need to run tens and hundreds of thousands of tasks very carefully, monitoring memory consumption. </li><li>  <code>queryset.iterator()</code> in the Djang ORS does not work exactly as expected. </li></ol><br>  The <code>task_queue</code> and <code>real_queryset_iterator</code> on the githaba: <br>  <a href="https://gist.github.com/homm/b8caf60c11997da69b1e">https://gist.github.com/homm/b8caf60c11997da69b1e</a> </div><p>Source: <a href="https://habr.com/ru/post/229767/">https://habr.com/ru/post/229767/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../229755/index.html">Meet Avaya ERS 4000</a></li>
<li><a href="../229757/index.html">Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images</a></li>
<li><a href="../229761/index.html">Fail story of SaaS Helpdesk for small business</a></li>
<li><a href="../229763/index.html">YaLinqo (LINQ to Objects for PHP) - version 2.0</a></li>
<li><a href="../229765/index.html">Juniper SRX Series Basic Setup</a></li>
<li><a href="../229773/index.html">Android "Evolution": how it was</a></li>
<li><a href="../229777/index.html">How to communicate with the 36-year-old space probe using GNU Radio</a></li>
<li><a href="../229779/index.html">Weka project for the task of recognition of tonality (sentiment)</a></li>
<li><a href="../229781/index.html">To help the school sysadmin</a></li>
<li><a href="../229783/index.html">Android game development</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>