<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deconvolutional Neural Network</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The use of classical neural networks for image recognition is complicated, as a rule, by a large dimension of the vector of input values ‚Äã‚Äãof the neur...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deconvolutional Neural Network</h1><div class="post__text post__text-html js-mediator-article"> The use of classical neural networks for image recognition is complicated, as a rule, by a large dimension of the vector of input values ‚Äã‚Äãof the neural network, a large number of neurons in the intermediate layers and, as a result, large expenditures of computing resources for training and computing the network.  Convolutional neural networks are less likely to have the disadvantages described above. <br><br>  The convolutional neural network ( <a href="http://en.wikipedia.org/wiki/Convolutional_neural_network"><i>pers</i></a> . <a href="http://en.wikipedia.org/wiki/Convolutional_neural_network"><i>Convolutional neural network</i></a> , <i>CNN</i> ) is a special architecture of artificial neural networks proposed by Yan Lecun and aimed at effective image recognition, is part of the technology of deep learning (eng. <a href="http://en.wikipedia.org/wiki/Deep_learning"><i>Deep leaning</i></a> ).  This technology is built by analogy with the principles of the <a href="https://ru.wikipedia.org/wiki/%25D0%2597%25D1%2580%25D0%25B8%25D1%2582%25D0%25B5%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BA%25D0%25BE%25D1%2580%25D0%25B0">visual cortex</a> , in which so-called simple cells were discovered that respond to straight lines from different angles and complex cells, the reaction of which is associated with the activation of a specific set of simple cells.  Thus, the idea of ‚Äã‚Äãconvolutional neural networks is the alternation of convolutional layers ( <i>convolution layers</i> ) and subsampling layers ( <i>subsampling layers</i> , subsample layers). [6] <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb1/a60/215/fb1a6021586266ad899dbecfbe13b39e.png" alt="image"><br>  Figure 1. The architecture of the convolutional neural network 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The key point in understanding convolutional neural networks is the concept of so-called ‚Äúshared‚Äù weights, i.e.  a part of the neurons of some considered layer of the neural network may use the same weights.  Neurons using the same weights are combined into <i>feature maps</i> , and each neuron of the feature map is associated with a portion of the neurons of the previous layer.  When computing the network, it turns out that each neuron performs a convolution (the <a href="http://en.wikipedia.org/wiki/Convolution">operation of convolution</a> ) of a certain area of ‚Äã‚Äãthe previous layer (determined by the set of neurons associated with the neuron).  The layers of the neural network constructed in the manner described are called convolutional layers.  In addition, convolutional layers in a convolutional neural network can be subsampling layers (performing the functions of decreasing the dimension of the feature map space) and fully connected layers (the output layer, as a rule, is always fully connected).  All three types of layers can alternate in arbitrary order, which allows mapping of features from feature maps, which in practice means the ability to recognize complex feature hierarchies [3]. <br><br>  What exactly affects the quality of pattern recognition when training convolutional neural networks?  Puzzled by this question, we stumbled upon an article by <a href="http://www.matthewzeiler.com/"><i>Matthew Zeiler</i></a> . <a name="habracut"></a>  He developed the concept and technology of <i>Deconvolutional Neural Networks</i> ( <i>DNN</i> ) for understanding and analyzing the performance of calibration neural networks.  The article by Matthew Ziler offers <i>Deconvolutional Neural Network</i> s technology, which builds hierarchical representations of the image (Figure 2), taking into account filters and parameters obtained during <i>CNN</i> training (Figure 2).  These representations can be used to solve problems of primary signal processing, such as noise reduction, and they can also provide low-level functions for object recognition.  Each level of the hierarchy can form more complex functions based on the functions of the levels located in the hierarchy below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b1/0ca/d3c/5b10cad3c446f35219d5572c3d95d46d.jpg" alt="image"><br>  Figure 2. Image views <br><br>  The main difference between <i>CNN</i> and <i>DNN</i> is that in <i>CNN the</i> input signal is subject to several layers of convolution and subsampling.  <i>DNN, on the</i> contrary, seeks to generate an input signal in the form of a sum of convolutions of feature maps taking into account the applied filters (Figure 3).  To solve this problem, a wide range of tools of pattern recognition theory is used, for example, algorithms for eliminating blur ( <i>deblurring</i> ).  The work, written by Matthew Seiler, is an attempt to link the recognition of image objects with low-level tasks and data processing and filtering algorithms. <br><br>  Understanding the convolution operation requires an interpretation of the behavior of feature maps in intermediate layers.  To study a convolutional neural network, the <i>DNN is</i> attached to each of its layers, as shown in Figure 3, providing a continuous path from the network's outputs to the image's input pixels.  First, a convolution operation is performed on the input image and feature maps are calculated over all layers, after which, to study the behavior in <i>CNN</i> , weights of all neurons in the layer are set to zero and the resulting feature maps are used as input parameters for the attached deconvnet layer.  Then we successively perform the operations: (i) separation, (ii) rectification, and (iii) filtering.  The trait maps in the layer below are reconstructed in such a way as to obtain the necessary parameters, such as the neuron weights in the layer and the filters used.  This operation is repeated until the values ‚Äã‚Äãof the input pixels of the image are reached. <br><br><img src="https://hsto.org/files/909/7ee/cf7/9097eecf74a34d509270b5a5ef74c24f.jpg" alt="image"><br>  Figure 3. The process of researching convolutional neural networks using <i>DNN</i> <br><br>  The separation operation: in convolutional neural networks, this is a union operation, it is irreversible, however, an approximate inverse value can be obtained by recording the location of the maxima within each region.  The operation of unification is understood as the summation of all input values ‚Äã‚Äãof the neuron and the transfer of the obtained sum to the transfer function of the neuron.  In <i>DNN</i> , a disconnect operation uses changes in the set of variables placed in the layer above, at the appropriate places in the layer that is being processed at the moment (see Figure 2). <br><br>  The operation of rectification: the convolutional neural network uses a nonlinear function ( <i>relu (x) = max (x, 0)</i> , where the x-input image), thereby ensuring that the resulting feature maps will always be positive. <br><br>  Filtering operation: a convolutional neural network uses the filters obtained in the network training process to convolve the feature maps from the previous layer.  To understand which filters were applied to an image, deconvnet uses transposed versions of the same filters.  Designing a ‚Äúdescent down‚Äù from higher levels uses parameter changes derived from <i>CNN</i> training.  Since these changes are characteristic of this input image, the reconstruction obtained from one function thus resembles a small piece of the initial image with structures (Figure 4) weighted in accordance with their contribution to the feature map.  Since the model is trained in accordance with the identified features, they, the structures, implicitly show which parts of the input image (or parts of two different images) are different in the features obtained [4].  Also, the resulting structures allow conclusions to be drawn about which low-level features of the image are key to its classification. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/213/6d3/825/2136d3825dedc139311c7d7eb5971144.jpg" alt="image"><br>  Fig.  4. Image structures. <br><br>  Although in theory the global minimum can always be found, in practice it is difficult.  This is due to the fact that the elements in the feature maps are connected to each other through filters.  One element in the map can affect other elements located far from this element, which means that minimization can take a very long time. <br><br>  Benefits of using <i>DNN</i> : <br><br>  1) conceptually simple training schemes.  <i>DNN</i> training is carried out through the use of unpooling, rectification and image filtering, as well as feature maps obtained during <i>CNN</i> training; <br>  2) applying <i>DNN</i> to the source images, you can get a large set of filters that cover the entire image structure using primitive representations;  In this way, filters are obtained that apply to the entire image, and not to each small piece of the original image.  This is a great advantage, as a more complete understanding of the processes occurring during <i>CNN</i> training appears. <br>  3) views (Fig. 2) can be obtained without configuring special parameters or additional modules, such as separation, rectification and filtering.  They, representations, turn out in the course of training of <i>CNN</i> ; <br>  4) the <i>DNN</i> approach is based on the global minimum search method, as well as using the filters obtained from <i>CNN</i> training, and is designed to minimize ill-conditioned costs that arise in the convolutional approach. <br><br>  The review article also contains the results of experiments conducted by Matthew Zyler.  The network proposed by him at <i><a href="http://www.image-net.org/challenges/LSVRC/2012/results.php">ImageNet</a> 2013</i> competitions showed the best result in solving the problem of image classification, the error was only 14.8%.  Classification of objects in 1000 categories.  The training sample consisted of 1.2 million images, and the test sample of 150 thousand images.  For each test image, the recognition algorithm should issue 5 class marks in descending order of their reliability.  When calculating the error, it was taken into account whether the most reliable mark corresponds to the mark of the object class that is actually present in the image for each image.  The use of 5 labels is intended to exclude the ‚Äúpunishment‚Äù for the algorithm in the case when it recognizes objects of other classes in the image that can be implicitly represented [1].  More competitions for ImageNet 2013 are described <a href="http://habrahabr.ru/company/nordavind/blog/206342/">here</a> . <br><br>  The results of <i>Deconvolution Neural Networks</i> are shown in Figure 5. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/914/683/517/914683517a1648fdc75d4b218700b970.jpg" alt="image"><br>  Figure 5. <i>DNN</i> results <br><br>  Seiler plans to further develop the <i>DNN</i> technology in the following areas: <br><br>  1) Improving the classification of images in <i>DNN.</i>  <i>DNN</i> networks have been introduced in order to understand the features of the learning process for convolutional networks.  Using the parameters obtained during the training of the convolutional neural network, in addition to the high-level functions, a mechanism can be provided to increase the level of classification in <i>DNN</i> .  Further work is related to the classification of the original images, so you can say that the template method will be applied.  Images will be classified based on the class to which the object belongs. <br>  2) <i>DNN</i> scaling.  Inference methods used in <i>DNN</i> , by their nature, are slow, since many iterations are necessary.  Numerical approximation methods based on direct communication should also be investigated.  This will require only those functions and merge parameters for the current batch of snapshots that allow the <i>DNN to</i> scale to large data sets. <br>  3) improvement of convolutional models for the detection of several objects in the image.  Convolutional networks are known to be used for classification for many years and have recently been applied to very large data sets.  However, further development of algorithms used in the convolutional approach is necessary to detect several objects at once in the image.  To detect <i>CNN at</i> once several objects in an image, a large set of training data is required, and the number of parameters for training a neural network also increases significantly. [4] <br><br>  After studying his article, they decided to conduct a study on <i>DNN</i> .  Matthew Seiler developed the <a href=""><i>Deconvolutional Network Toolbox</i></a> for <i>Matlab</i> .  And immediately ran into a problem - the non-trivial task of installing this <i>Toolbox</i> .  After a successful installation, we decided to share these skills with habravchanami. <br><br>  So, let's proceed to the installation process.  <i>Deconvolutional Network Toolbox was</i> installed on a computer with the following technical characteristics: <br>  ‚Ä¢ <i>Windows 7 64x</i> <br>  ‚Ä¢ <i>Matlab b2014a</i> <br><br>  Let's start with preparing the software that needs to be installed: <br><br>  1) <a href="http://www.microsoft.com/en-us/download/details.aspx%3Fid%3D3138"><i>Windows SDK</i></a> , during installation, you must remove the checkmarks from the <i>Visual C ++ Compilers</i> items <i><br></i>  <i>Microsoft Visual C ++ 2010</i> <br>  If the computer already has <i>VS</i> 2010 <i>redistributable</i> x64 or <i>VS</i> 2010 <i>redistributable</i> x86, it will have to be removed. <br>  Finish the installation of the <i>Windows SDK</i> , and install the <a href="http://www.microsoft.com/en-us/download/details.aspx%3Fdisplaylang%3Den%26id%3D4422">patch</a> <br>  2) After that, download and install <i>VS</i> 2010 <br>  3) Also, to install this toolbox, you need to install the <i>icc</i> compiler, in our case it is the <i>Intel C ++ Composer XE Compiler 2011</i> . <br>  4) In <i>Matlab,</i> type the command <pre>  mbuild -setup </pre>  and automatically select <i>SDK 7.1</i> . <br>  Similarly happens with <pre>  mex ‚Äìsetup </pre><br>  If the compiler has been successfully installed, then you can now start building the toolbox. <br><br>  Software preparation is complete.  We start the compilation process. <br><br>  1) Download toolbox with <br>  <a href="">www.matthewzeiler.com/software/DeconvNetToolbox/DeconvNetToolbox.zip</a> and unpack <br>  2) In <i>Matlab,</i> go to the directory where the unpacked toolbox is located, and run the file <i>‚ÄúsetupDeconvNetToolbox.m‚Äù</i> <br>  3) Go to the <i>PoolingToolbox</i> folder.  Open the file compilemex.m <br>  This file needs a number of changes, as it is written for Linux. <br>  It is necessary to register the paths in <i>MEXOPTS_PATH</i> to <i>Matlab</i> , to the libraries located in the compiler folder for the 64-bit system, as well as to the compiler header files and <i>VisualStudio 2010</i> . <br>  4) Let's make some more changes, they look like this <br> <code>exec_string = strcat({'mex '},MEXOPTS_PATH,{' '},{'-liomp5mt max_pool.cpp'}); <br> eval(exec_string{1});</code> <br>  Similarly, you need to do for the rest of the compiled files. ( <a href="https://yadi.sk/i/TArJSX-3fUqmm">Example</a> ) <br>  5) We will also make changes to <i>mexopts.sh</i> <br>  It is also necessary to prescribe paths to the 64 and 32 bit compiler.  ( <a href="https://yadi.sk/d/y5exp4VHfUqvE">Example</a> ) <br>  6) Now go to the <i>IPP Convolution Toolbox</i> directory <br>  7) Go to the <i>MEX</i> folder and launch the <i>complimex.m</i> file, here you also need to register the same as in paragraph 4, and separately add the paths to <i>ipp_lib</i> and <i>ipp_include</i> .  (Example) <br>  <i>Matlab</i> will say that there are not enough <a href="https://yadi.sk/d/Vn9ceDIhfUpCJ">libraries</a> , they need to be put in <i>c: \ Program Files (x86) \ Intel \ ComposerXE-2011 \ ipp \ lib \ intel64 \</i> <br>  8) Similarly, p5 make changes <br><pre>  exec_string = strcat ({'mex'}, MEXOPTS_PATH, {''}, {IPP_INCLUDE_PATH}, {''}, {IPP_LIB64_PATH}, {''}, {IPP_LIB_PATH}, {''}, {'- liomp5mt -lippiemerged -lippimerged -lippcore -lippsemerged -lippsmerged -lippi ipp_conv2.cpp '});
 eval (exec_string {1}); </pre><br>  ( <a href="https://yadi.sk/d/cl6idDE-fUr7e">Example</a> ) <br>  Run the file, if everything worked correctly - we continue. <br>  9) Go to the <i>GUI</i> folder <br>  10) Open the file <i>gui.m</i> , here you need to register the path to the folder with the unpacked <i>Deconvolutional toolbox</i> , for me it looks like this <br> <code>START_DATASET_DIRECTORY = 'C:/My_projects/DeconvNetToolbox/DeconvNetToolbox'; <br> START_RESULTS_DIRECTORY = 'C:/My_projects/DeconvNetToolbox/DeconvNetToolbox';</code> <br>  ( <a href="https://yadi.sk/i/AkmXZlEafUrD4">Example</a> ) <br>  11) Run the file <i>gui.m.</i>  Earned?  Close and go on. <br>  12) Now in the folder where Tulbox was pumped out, we create the <i>Results</i> folder, and in it the <i>temp</i> folder.  Now we start from the <i>Results gui.m</i> folder <i>,</i> a graphical interface appears in which the parameters are set, in the lower right corner of the Save Results set to 1, and click on <i>Save</i> .  As a result of these actions, the <i>gui_has_set_the_params.mat</i> file is generated in the <i>GUI</i> directory with the parameters of the <i>DNN</i> network demonstration model proposed by Matthew Zyler. <br>  13) Now you can start learning the resulting model by calling the script <i>trainAll.m.</i> <br>  If all actions were performed correctly, then after completing the training in the <i>Results</i> folder you can see the result of the work. <br><br>  Now you can start doing research!  The results of the research will be devoted to a separate article. <br><br>  Bibliography: <br>  1) <a href="http://habrahabr.ru/company/nordavind/blog/206342/">habrahabr.ru/company/nordavind/blog/206342</a> <br>  2) <a href="http://habrahabr.ru/company/synesis/blog/238129/">habrahabr.ru/company/synesis/blog/238129</a> <br>  3) <a href="http://habrahabr.ru/post/229851/">habrahabr.ru/post/229851</a> <br>  4) <a href="http://www.matthewzeiler.com/pubs/">www.matthewzeiler.com/pubs</a> <br>  5) <a href="http://geektimes.ru/post/74326/">geektimes.ru/post/74326</a> <br>  6) <a href="http://nordavind.ru/node/550">nordavind.ru/node/550</a> </div><p>Source: <a href="https://habr.com/ru/post/253859/">https://habr.com/ru/post/253859/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../253847/index.html">Data center construction boom starts in Iceland</a></li>
<li><a href="../253849/index.html">Free webinar "Virtualization based on Hyper-V 3.0 and Windows Server 2012R2 Virtual Desktop Infrastructure"</a></li>
<li><a href="../253851/index.html">Another option for dynamic DNS on its site or how I gave up dyndns</a></li>
<li><a href="../253855/index.html">Farewell Note to the Programming Language</a></li>
<li><a href="../253857/index.html">Range functionality with ObservableCollection</a></li>
<li><a href="../253861/index.html">3CX updated software client for Mac</a></li>
<li><a href="../253863/index.html">Google Maps History</a></li>
<li><a href="../253865/index.html">The evolution of mobile applications</a></li>
<li><a href="../253867/index.html">How to become a test automation?</a></li>
<li><a href="../253869/index.html">"Perfect" cluster. Part 3.1 Implementing MySQL Multi-Master Cluster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>