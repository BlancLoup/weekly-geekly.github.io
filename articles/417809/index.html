<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI, practical course. Modern deep neural network architectures for image classification</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the previous article, Overview of Neural Networks for image classification , we familiarized ourselves with the basic basic concepts of convolution...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AI, practical course. Modern deep neural network architectures for image classification</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/sz/-n/ep/sz-neph-gqvvjim1l0dreihnxlu.png"><br><br>  In the previous article, <a href="https://habr.com/company/intel/blog/415811/">Overview of Neural Networks for image classification</a> , we familiarized ourselves with the basic basic concepts of convolutional neural networks, as well as the underlying ideas.  In this article, we will look at several architectures of deep neural networks with large computing power ‚Äî such as AlexNet, ZFNet, VGG, GoogLeNet, and ResNet ‚Äî and summarize the main advantages of each of these architectures.  The structure of the article is based on a blog entry. <a href="https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html">Basic concepts of convolutional neural networks, part 3</a> . <br><a name="habracut"></a><br>  Currently, the main incentive underlying the development of machine recognition and image classification systems is the <a href="http://image-net.org/">ImageNet</a> Challenge campaign.  The campaign is a data contest, in which participants are provided with a large data set (over a million images).  The task of the competition is to develop an algorithm that allows to classify the required images into objects in 1000 categories - such as dogs, cats, cars and others - with a minimum number of errors. <br><br>  According to the official rules of the competition, the algorithms must generate a list of no more than five categories of objects in descending order of trust for each category of images.  The quality of image marking is evaluated based on the label that best matches the ground truth property of the image.  The idea is to allow the algorithm to identify several objects in the image and not charge penalty points if any of the objects found are actually present in the image, but were not included in the ground truth property. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the first year of the competition, participants were provided with pre-selected signs of images for training the model.  These could be, for example, signs of the <a href="http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/">SIFT</a> algorithm, processed using vector quantization and suitable for use in the ‚Äúbag of words‚Äù method or for representation in the form of a spatial pyramid.  However, in 2012 there was a real breakthrough in this area: a group of scientists from the University of Toronto demonstrated that a deep neural network can achieve significantly better results compared to traditional models of machine learning, built on the basis of vectors from previously selected properties of images.  In the following sections, the first innovative architecture proposed in 2012, as well as the architecture being its followers up to 2015, will be considered. <br><br><img src="https://habrastorage.org/webt/b1/yc/0j/b1yc0jlxh6r5g9xmpvsfocbxmxo.png"><br>  <i>Chart of changing the number of errors (in percent) when classifying ImageNet * images for the five leading categories.</i>  <i>Image taken from Kaiming He, <a href="https://arxiv.org/pdf/1512.03385.pdf">Deep residual learning for image recognition.</a></i> <br><br><h3>  <font color="#0071c5">AlexNet</font> </h3><br>  <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet</a> architecture was proposed in 2012 by a group of scientists (A. Krizhevsky, I. Satskever and J. Hinton) from the University of Toronto.  It was an innovative work in which the authors first used (at that time) deep convolutional neural networks with a total depth of eight layers (five convolutional and three fully connected layers). <br><br><img src="https://habrastorage.org/webt/fm/wq/lm/fmwqlmznjszot3yzk1zfejfab6w.png"><br>  <i>AlexNet Architecture</i> <br><br>  The network architecture consists of the following layers: <br><br><ul><li>  [Convolutional layer + selection of maximum value + normalization] x 2 </li><li>  [Convolution layer] x 3 </li><li>  [Select the maximum value] </li><li>  [Full Linked] x 3 </li></ul><br>  Such a scheme may look slightly strange, because the learning process was divided between two graphics processors due to its high computational complexity.  This division of work between graphics processors requires manual separation of the model into vertical blocks that interact with each other. <br><br>  AlexNet architecture has reduced the number of errors for the five leading categories to 16.4 percent - almost doubled compared with previous advanced developments!  Also within the framework of this architecture, an activation function such as a linear rectification unit ( <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> ), which is currently the industry standard, was introduced.  The following is a brief summary of the other basic properties of the AlexNet architecture and its learning process: <br><br><ul><li>  Intensive data augmentation </li><li>  Exclusion method </li><li>  Optimization using SGD torque (see optimization guide ‚ÄúOverview of Gradient Descent Optimization Algorithms‚Äù) </li><li>  Manual setting of the learning speed (decrease of this coefficient by 10 with stabilization of accuracy) </li><li>  The resulting model is a collection of seven convolutional neural networks. </li><li>  The training was conducted on two NVIDIA * GeForce GTX * 580 GPUs with a total of 3 GB of video memory on each of them. </li></ul><br><h3>  <font color="#0071c5">ZFNet</font> </h3><br>  The <a href="https://arxiv.org/pdf/1311.2901v3.pdf">ZFNet</a> network architecture proposed by the researchers M. Zeiler and R. Fergus from New York University is almost identical to the architecture of AlexNet.  The only significant differences between them are as follows: <br><br><ul><li>  The filter size and pitch in the first convolutional layer (in AlexNet, the filter size is 11 √ó 11, and the pitch is 4; in ZFNet, it is 7 √ó 7 and 2, respectively) </li><li>  The number of filters in pure convolutional layers (3, 4, 5). </li></ul><br><img src="https://habrastorage.org/webt/gj/ji/wz/gjjiwzynwfzcnsrw3_vzgilojoo.png"><br>  <i>ZFNet architecture</i> <br><br>  Thanks to the ZFNet architecture, the number of errors for the five leading categories dropped to 11.4 percent.  Perhaps the main role in this is played by the fine tuning of the hyperparameters (size and number of filters, packet size, learning rate, etc.).  However, it is also likely that the ideas of ZFNet architecture have become a very significant contribution to the development of convolutional neural networks.  Zieler and Fergus proposed a system of visualization of nuclei, weights, and hidden presentation of images, called DeconvNet.  Thanks to it, a better understanding and further development of convolutional neural networks has become possible. <br><br><h3>  <font color="#0071c5">VGG Net</font> </h3><br>  In 2014, K. Simonyan and E. Zisserman (A. Zisserman) from Oxford University proposed an architecture called <a href="https://arxiv.org/pdf/1409.1556v6.pdf">VGG</a> .  The basic and distinctive idea of ‚Äã‚Äãthis structure is to <i>keep the filters as simple as possible</i> .  Therefore, all convolution operations are performed using a filter with a size of 3 and a step of 1, and all subsampling operations with a filter of 2 and a step of 2. However, this is not all.  At the same time with the simplicity of convolutional modules, the network has grown significantly in depth - now it has 19 layers!  The most important idea, first proposed in this paper, is to <i>overlay convolutional layers without sub-sampling layers</i> .  The underlying idea is that such an overlay still provides a fairly large receptive field (for example, three superimposed 3 √ó 3 convolutional layers with a step of 1 have a receptive field similar to one 7 √ó 7 convolutional layer) however, the number of parameters is significantly less than in networks with large filters (serves as a regularizer).  In addition, it becomes possible to introduce additional nonlinear transformations. <br><br>  Essentially, the authors have demonstrated that even with very simple standard blocks one can achieve excellent quality results in the ImageNet competition.  The number of errors for the top five categories dropped to 7.3 percent. <br><br><img src="https://habrastorage.org/webt/x7/rk/yj/x7rkyjkvxchmnso5gd56gf83eec.png"><br>  <i>VGG architecture.</i>  <i>Note that the number of filters is inversely proportional to the spatial size of the image.</i> <br><br><h3>  <font color="#0071c5">GoogLeNet</font> </h3><br>  Previously, the entire development of the architecture was to simplify the filters and increase the depth of the network.  In 2014, C. Segedi (C. Szegedy), together with other participants, proposed a completely different approach and created the most complex architecture at that time, called GoogLeNet. <br><br><img src="https://habrastorage.org/webt/dl/rg/c7/dlrgc7gmujh1atkvisnx5onluim.png"><br>  <i>Architecture GoogLeNet.</i>  <i>It uses the Inception module, highlighted in green in the figure;</i>  <i>network building is carried out on the basis of these modules</i> <br><br>  One of the main achievements of this work is the so-called Inception module, which is shown in the figure below.  Networks of other architectures process the input data sequentially, layer by layer, while using the Inception module, the <i>input data is processed in parallel</i> .  This allows you to speed up the output, as well as minimize the <i>total number of parameters</i> . <br><br><img src="https://habrastorage.org/webt/uo/ny/0t/uony0thmws6rtd5jyloaqxs5swe.png"><br>  <i>Inception module.</i>  <i>Note that the module uses several parallel branches that calculate different properties based on the same input data, and then combine the results</i> <br><br>  Another interesting technique used in the Inception module is the use of 1 √ó 1 convolutional layers. This may seem meaningless until we recall the fact that the filter covers the entire depth dimension.  Thus, a 1 √ó 1 convolution is a simple way to reduce the dimension of the property map.  This type of convolutional layers was first presented in the work of the <a href="https://arxiv.org/pdf/1312.4400v3.pdf">Network on the network of</a> M. Lin and co-authors, a comprehensive and understandable explanation can also be found in the blog post <a href="http://iamaaditya.github.io/2016/03/one-by-one-convolution/">Convolution [1 √ó 1] - usefulness contrary to the intuition</a> of A. Prakash. <br><br>  Ultimately, this architecture reduced the number of errors for the five leading categories by another half a percent - to a value of 6.7 percent. <br><br><h3>  <font color="#0071c5">ResNet</font> </h3><br>  In 2015, a group of researchers (Kaiming Hee and others) from Microsoft Research Asia came up with an idea that is currently considered by the majority of the community to be one of the most important stages in the development of in-depth training. <br><br>  One of the main problems of deep neural networks is the problem of a vanishing gradient.  In a nutshell, this is a technical problem that arises when using the method of back propagation of error for the gradient calculation algorithm.  When working with back propagation of errors, a chain rule is used.  Moreover, if the gradient has a small value at the end of the network, then it can take an infinitely small value by the time it reaches the beginning of the network.  This can lead to problems of completely different properties, including the impossibility of network training in principle (for more information, see R. Kapur's blog entry (R. Kapur) <a href="https://ayearofai.com/rohan-4-the-vanishing-gradient-problem-ec68f76ffb9b">The problem of a vanishing gradient</a> ). <br><br>  To solve this problem, Kaiming Hee and his group proposed the following idea - to allow the network to study the residual mapping (the element that should be added to the input data) instead of the mapping itself.  Technically, this is done using the bypass connection shown in the figure. <br><br><img src="https://habrastorage.org/webt/0r/tc/qs/0rtcqsfuosnmqzprsvgdiho2i_o.png"><br>  <i>The schematic diagram of the residual block: the input data is transmitted via a reduced connection bypassing the conversion layers and added to the result.</i>  <i>Please note that the ‚Äúidentical‚Äù connection does not add additional parameters to the network, so its structure is not complicated</i> <br><br>  This idea is extremely simple, but at the same time extremely effective.  It solves the problem of a vanishing gradient, allowing it to move without any changes from the upper to the lower layers by means of ‚Äúidentical‚Äù connections.  Thanks to this idea, it is possible to train very deep, extremely deep networks. <br><br>  The network that won the ImageNet Challenge competition in 2015 contained 152 layers (the authors were able to train the network that contained 1001 layers, but it produced approximately the same result, so they stopped working with it).  In addition, this idea has reduced the number of errors for the five leading categories literally twice - to a value of 3.6 percent.  According to the study <a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">What I learned by competing with a convolutional neural network in the ImageNet competition</a> held by A. Karpathy, the human performance for this task is approximately 5 percent.  This means that the ResNet architecture is capable of surpassing human results, at least in this task of image classification. </div><p>Source: <a href="https://habr.com/ru/post/417809/">https://habr.com/ru/post/417809/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../417793/index.html">Forget about alien mega-structures: new observations explain the behavior of the star Tabbi with dust alone</a></li>
<li><a href="../417795/index.html">My video game obsession in adolescence is not a ‚Äúplay disorder‚Äù</a></li>
<li><a href="../417797/index.html">4 reasons why NASA projects violate deadlines and inflate the budget</a></li>
<li><a href="../417801/index.html">How I moved to Israel after blocking Telegram</a></li>
<li><a href="../417803/index.html">Batch photo processing in Blender</a></li>
<li><a href="../417813/index.html">Zabbix - monitoring OSPF neighbors using SNMPv3 TRAPs, pain and despair</a></li>
<li><a href="../417815/index.html">As I UDP game server on Golang wrote</a></li>
<li><a href="../417817/index.html">Hyperloop TT will build a commercial highway in China</a></li>
<li><a href="../417821/index.html">Network Digest: 20 expert materials on protocols, standards and information security</a></li>
<li><a href="../417823/index.html">"New Generation": launched the world's first commercial network 5G</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>