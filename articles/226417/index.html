<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Logic of auto-robot: from engine vision to transmission control</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A.Zhukovsky, S. Usilin, V.Postnikov 
 Today we want to talk about the new project, which started a little more than a year ago at the department of "C...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Logic of auto-robot: from engine vision to transmission control</h1><div class="post__text post__text-html js-mediator-article"><h6>  A.Zhukovsky, S. Usilin, V.Postnikov </h6><br>  Today we want to talk about the new project, which started a little more than a year ago at the department of "Cognitive technologies" of MIPT. <br><br>  It consists in creating a machine vision system, a robot - car ( <a href="https://habr.com/ru/company/cognitive/blog/226417/">Fig. 1</a> ), which should process the video stream in real time, recognize the surrounding scene, detect objects and form a control action aimed at solving the set task. <br><a name="pic1"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/84e/fc7/d17/84efc7d1784a01f91b70b519416312c7.jpg"><br><h6>  Fig.  one </h6><br>  At the same time, we did not attempt to completely recreate the real conditions of the road scene, excluding all the charms of small-sized modeling. <br><a name="habracut"></a><br>  To begin with, on simple examples, we wanted to work out the main architectural components of the system (the base for receiving video stream and distributed processing on combinations of minicomputers and video cameras, as a prototype System ‚Äì on ‚Äì a ‚Äì Chip (SoC)), potentially suitable for solving more complex problems. <br><br>  We taught the robot to move along the corridor and detect simple objects, for example, an orange road cone.  The task was that he could drive up to the object and stop.  And then they decided to play with the ball.  In the current version, if the ball is in the field of view of the camera, the robot detects the ball, accelerates and pushes it with a bumper.  If the ball leaves the field of view of the camera, the robot starts searching for it. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/YIjRrALX2ig%3Ffeature%3Doembed&amp;xid=17259,15700002,15700021,15700186,15700190,15700253&amp;usg=ALkJrhhSLpNntF15zg_5d6LDfdYRGREBYw" frameborder="0" allowfullscreen=""></iframe><br><h6>  The video was shot during a report at the autumn conference of young scientists at MIPT, <br>  right in the hallway of the main building </h6><br>  Now we teach the robot to pass the "snake" for a while.  This exercise allows you to assess the quality of the control system and its progress from version to version.  And also to compare with the quality of manual control with human participation. <br><br>  Initially, our robot contained only a control computer, a camera and, in fact, a chassis.  This model is a sports SUV Traxxas Slash 2wd made in the ratio of 1:10.  ( <a href="https://habr.com/ru/company/cognitive/blog/226417/">Fig. 2</a> , <a href="https://habr.com/ru/company/cognitive/blog/226417/">Fig. 3</a> ) <br><a name="pic2"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/703/969/0d0/7039690d01b163e5b19e486a00ed0690.jpg"><br><h6>  Fig.  2 Traxxas Slash 2wd </h6><br>  The chassis controller is made on the basis of the Arduino nano, but in fact only the ATMega32 microcontroller is used from it. <br><br>  A little later, we added front sonar to the circuit to control the distance to the obstacles - in other words, so that the robot would not bumper into corners and walls. <br><br><a name="pic3"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/970/4cd/c44/9704cdc44ba0e31a0af4b9d1cb5b0b2b.jpg"><br><h6>  Fig.  3 Traxxas Slash 2wd </h6><br>  If in the first version, the robot broadcast video via HTTP back and control signals were generated on the desktop, in the current version 2.0 (shown in the video) the whole cycle is closed on board, with the main video processing burden placed on the Odroid U2 minicomputer.  ( <a href="https://habr.com/ru/company/cognitive/blog/226417/">Fig. 4 -1</a> ) <br><br>  In addition to the computer, the equipment version 2.0 includes: <br><br><ul><li>  robot control device (Fig. 4 -2); </li><li>  Logitech HD Pro C920 / Genius WideCam 1050 camcorder (almost arbitrary webcam can be used) (Figure 4-3); </li><li>  ASUS USB-N10 Wi-Fi adapter (Fig. 4-4); </li><li>  USB hub (Figure 4-5) </li><li>  sonar LV-MAXSONAR-EZ2 (Fig. 4-6) </li></ul><br><br><a name="pic4"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/5bd/0c9/aa2/5bd0c9aa28e8a0ed9f0b5f8cd893b57a.jpg"><br><h6>  Fig.  four </h6><br>  The functions of the robot control device include: <br><br><ol><li>  <b>implementation of commands of the controlling computer</b> : <br><ul><li>  generation of control PWM signals, </li><li>  external load control (7 channels); </li></ul><br></li><li>  <b>signal processing from sensors</b> : <br><ul><li>  Sonars (8 channels), </li><li>  Hall Sensor, </li><li>  battery voltage sensor (ADC); </li></ul><br></li><li>  <b>robot protection</b> : <br><ul><li>  emergency stop for frontal sonar, </li><li>  stop at loss of control signal. </li></ul><br></li></ol><br><a name="pic5"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/8dd/a74/f7b8dda74d239000cc09007b5b2b1935.jpg" width="560"><br><h6>  Fig.  5 Scheme of the equipment of the robot </h6><br>  Now we are collecting the 3rd version.  In it, the video capture system will already include two professional IDS video cameras, the video signal from which (including detection of objects) will be processed on separate minicomputers, in turn, connected to the central minicomputer, which produces the final scene recognition and control actions. <br><br>  It is also planned to put several sonars around the perimeter of the robot in order to more fully represent the environment for solving parking problems. <br><br>  Further, quite a few improvements are planned, for example, we want to hang on the robot light equipment, like real cars, for which some of the parts are printed on a 3D printer.  It is necessary to simulate the movement behind the car in front with a certain distance (a case of traffic in a dense stream or traffic jam). <br><br><h6>  <i>The first lyrical digression.</i> </h6>  By the way, if you do something like this, we immediately warn against using Chinese analogs - the first version of the motor controller was made on it, which resulted in a few weeks of searching for the cause of the strange motor behavior - it turned out that the microcontroller from the ‚Äúanalog‚Äù closed some inputs at the exits.  Perhaps, we were so lucky, but with the original Arduino there were no such problems. <br><br><h6>  <i>The second lyrical digression.</i> </h6>  Before creating the chassis controller, it turned out that it is not known how and what to control.  The lack of official documentation on the control signals of the chassis components made it possible to recall the labs on physics and dig deeper with the oscilloscope.  As a result, it turned out that pulse-width modulation is used there.  In general, nothing complicated. <br><br><h6>  <i>The third lyrical digression.</i> </h6>  Somewhere between the discovery of the problem and the gathering of a new controller, it was decided to abandon the circuit board on which the first controller was assembled, and therefore the ‚Äúiron-printer‚Äù method of PCB layout was taken from the naphthalene.  The result was very neat and cool. <br><br>  The robot behavior algorithm for chasing a ball is shown schematically in the figure below.  It seems that there is nothing incomprehensible in it.  Is that worth saying a few words about the reversal algorithm.  This is a test of the situation when the ball goes out of sight of the robot.  In fact, he has only 4 possibilities for a turn: forward right, forward left and back right and back left.  The robot remembers where it saw the ball for the last time and turns in this direction, by complete analogy with a football player, from whose sight the ball disappeared.  He seeks to turn in the direction where the ball flew. <br><br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/Nacd38fiVOo%3Ffeature%3Doembed&amp;xid=17259,15700002,15700021,15700186,15700190,15700253&amp;usg=ALkJrhhmkIfI2mjX-lGMvTQpnqhJimpmsg" frameborder="0" allowfullscreen=""></iframe><br><br>  For the reversal, we apply the "asterisk" algorithm: we are going, for example, first to the right and forward, then to the left and back, we get such arcs, convex toward the common center point.  This maneuver is reminiscent of a turn in a limited space, known to many by the traffic police exam ( <a href="https://habr.com/ru/company/cognitive/blog/226417/">Fig. 6</a> ). <br><br><a name="pic6"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f9c/c3d/b7b/f9cc3db7b8a8d64d8842d6209d678aba.jpg" width="280"><br><h6>  Fig.  6 </h6><br>  If there is a deadlock due to the fact that the robot gets stuck, for example, having caught on the leg of the chair, the control program identifies this situation due to the discrepancy between the engine speed and the angle of rotation of the wheels.  In this case, the robot is trying to pass back, make a maneuver on the "asterisk" and continue to move to the goal. <br><br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/mkwnUkuXKvQ%3Ffeature%3Doembed&amp;xid=17259,15700002,15700021,15700186,15700190,15700253&amp;usg=ALkJrhh2FlLlEs9RzSImCrDgs1fE7-_p-g" frameborder="0" allowfullscreen=""></iframe><br><br><h6>  <i>The fourth lyrical digression.</i> </h6>  When we were preparing for the conference of young scientists of the Moscow Institute of Physics and Technology, we increased the parameter of acceleration to increase the audience perception.  As a result, the robot began to run into obstacles more often, since the detection circuit of the ‚Äústuck‚Äù case stopped working adequately - the wheels began to slip.  In addition, at higher speeds, the robot began to miss the ball more often (this can be seen in the first video).  Therefore, we had to solve the problem of optimal balancing between the processing speeds of the video stream, the movement of the robot and decision making.  In terms of complexity, it resembled the problem of getting used to an old Soviet-made car with a manual gearbox, such as the Moskvich or Zhiguli, each of which had its own grip and ignition adjusted.  Whoever faced this, he understands that it takes some time to adjust to catch the balance between the clutch and the gas pedal, so that the car accelerates smoothly. <br><br><a name="pic7"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f02/ca1/0af/f02ca10af252e1d5aaa580f2fb76e119.jpg" width="560"><br><h6>  Fig.  7 Robot Behavior Behavior Algorithm </h6><br>  In the third version of the robot (it is almost complete), we switched to using a ‚Äúprofessional‚Äù video camera and lens. <br><br><a name="pic8"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f85/367/307/f8536730722b1f385719caa1cbf2d6db.jpg"><br><h6>  Fig.  eight </h6><br>  In parallel, we are conducting experiments on the installation of cameras on slats, which are mounted on the rails of a full-size vehicle ( <a href="https://habr.com/ru/company/cognitive/blog/226417/">Fig. 8</a> ).  This will allow to reproduce the real geometry and conditions of the road scene. <br><br>  We are going to tell about the new version of the robot in the next article. <br><br></div><p>Source: <a href="https://habr.com/ru/post/226417/">https://habr.com/ru/post/226417/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../226397/index.html">Five stories about Cabir, the first virus for smartphones</a></li>
<li><a href="../226401/index.html">PHDays IV hacked into "smart city"</a></li>
<li><a href="../226407/index.html">Mobile Application Design</a></li>
<li><a href="../226411/index.html">The biggest black hole in the known universe</a></li>
<li><a href="../226413/index.html">The sum of opinions: what users say in the test drive Nokia Lumia 1520</a></li>
<li><a href="../226419/index.html">Django on production. uWSGI + nginx. Detailed guide</a></li>
<li><a href="../226421/index.html">Shadow rendering using Parallel-Split Shadow Mapping</a></li>
<li><a href="../226423/index.html">Launch Internet Explorer Developer Channel</a></li>
<li><a href="../226425/index.html">About encryption of referrers in Yandex</a></li>
<li><a href="../226427/index.html">The evolution of Microsoft web frameworks. ASP.NET vNext</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>