<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep Learning: Comparing Framework for Character Deep Learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We present you a translation of a series of articles devoted to deep learning. The first part describes the choice of a framework with an open code fo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep Learning: Comparing Framework for Character Deep Learning</h1><div class="post__text post__text-html js-mediator-article">  We present you a translation of a series of articles devoted to deep learning.  The first part describes the choice of a framework with an open code for symbolic deep learning, between MXNET, TensorFlow, Theano.  The author compares in detail the advantages and disadvantages of each of them.  In the following sections, you will learn about fine tuning of deep convolutional networks, as well as the combination of a deep convolutional neural network with a recurrent neural network. <br><br><img src="https://habrastorage.org/files/122/03e/92f/12203e92fd124525bdad9acf0c8bfd5f.jpg"><br><a name="habracut"></a><br><h2>  The series of articles "Deep Learning" </h2><br>  1. <a href="https://habrahabr.ru/company/microsoft/blog/313318/">Comparison of frameworks for symbolic deep learning</a> . <br>  2. <a href="https://habrahabr.ru/company/microsoft/blog/314934/">Transfer learning and fine tuning of deep convolutional neural networks</a> . <br>  3. A <a href="https://habrahabr.ru/company/microsoft/blog/316456/">combination of a deep convolutional neural network with a recurrent neural network</a> . <br><br>  Note: further narration will be conducted on behalf of the author. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Character frameworks </h2><br>  Symbolic computing frameworks ( <a href="https://github.com/dmlc/mxnet">MXNET</a> , <a href="https://www.tensorflow.org/">TensorFlow</a> , <a href="https://github.com/Theano/Theano">Theano</a> ) are characterized by symbolic graphs of vector operations, such as matrix addition / multiplication or convolution.  A layer is simply a set of such operations.  Due to the division into small composite components (operations), users can create new complex types of layers without using low-level languages ‚Äã‚Äã(as in <a href="http://caffe.berkeleyvision.org/">Caffe</a> ). <br><br>  I have experience using different frameworks for symbolic computing.  As it turned out, they all have both advantages and disadvantages in the device and the current implementation, but none of them fully meets all the requirements.  However, I currently prefer Theano. <br><br>  Next, we compare the listed frameworks for symbolic computing. <br><table border="1"><tbody><tr><th><h5>  <b>Characteristic</b> </h5></th><th><h5>  <b>Theano</b> </h5></th><th><h5>  <b>Tensorflow</b> </h5></th><th><h5>  <b>MXNET</b> </h5></th></tr><tr><td>  <b>Software</b> </td><td>  Theano </td><td>  Tensorflow </td><td>  MXNET </td></tr><tr><td>  <b>Author</b> </td><td>  Montreal university </td><td>  Google Brain Team </td><td>  Distributed (Deep) Machine Learning Community </td></tr><tr><td>  <b>Software License</b> </td><td>  BSD license </td><td>  Apache 2.0 </td><td>  Apache 2.0 </td></tr><tr><td>  <b>Open source</b> </td><td>  Yes </td><td>  Yes </td><td>  Yes </td></tr><tr><td>  <b>Platform</b> </td><td>  Cross-platform solution </td><td>  Linux, Mac OS X, Windows support planned </td><td>  Ubuntu, OS X, Windows, AWS, Android, iOS, JavaScript </td></tr><tr><td>  <b>Programming language</b> </td><td>  Python </td><td>  C ++, Python </td><td>  C ++, Python, Julia, Matlab, R, Scala </td></tr><tr><td>  <b>Interface</b> </td><td>  Python </td><td>  C / C ++, Python </td><td>  C ++, Python, Julia, Matlab, JavaScript, R, Scala </td></tr><tr><td>  <b>CUDA support</b> </td><td>  Yes </td><td>  Yes </td><td>  Yes </td></tr><tr><td>  <b>Automatic differentiation</b> </td><td>  Yes </td><td>  Yes </td><td>  Yes </td></tr><tr><td>  <b>Availability of pre-trained models</b> </td><td>  Using model zoo in Lasagne </td><td>  Not </td><td>  Yes </td></tr><tr><td>  <b>Recurrent networks</b> </td><td>  Yes </td><td>  Yes </td><td>  Yes </td></tr><tr><td>  <b>Convolution networks</b> </td><td>  Yes </td><td>  Yes </td><td>  Yes </td></tr><tr><td>  <b>Limited Boltzmann machines / deep trust networks</b> </td><td>  Yes </td><td>  Yes </td><td>  Yes </td></tr></tbody></table><br><h2>  Comparison of character and non-character frameworks </h2><br><h4>  Non-character frameworks </h4><br>  <b>Benefits:</b> <br><br><ul><li>  Non-character (imperative) neural network frameworks such as <a href="https://github.com/torch/">torch</a> and <a href="https://github.com/BVLC/caffe/">caffe</a> , as a rule, have a very similar computational part. </li><li>  From the point of view of expressiveness, imperative frameworks are built quite well, they can have a graph-based interface (for example, <a href="https://github.com/torch/nngraph">torch / nngraph</a> ). </li></ul><br>  <b>Disadvantages:</b> <br><br><ul><li>  The main disadvantage of imperative frameworks is manual optimization.  For example, on-site operations need to be implemented manually. </li><li>  Most imperative frameworks are symbolic in expressiveness. </li></ul><br><h4>  Character frameworks </h4><br>  <b>Benefits:</b> <br><br><ul><li>  In symbolic frameworks, automatic optimization is possible based on dependency graphs. </li><li>  In symbolic frameworks, you can get much more reusable memory features.  For example, this is perfectly implemented in MXNET. </li><li>  Symbolic frameworks can automatically calculate the optimal schedule.  More details can be found <a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">here</a> . </li></ul><br>  <b>Disadvantages:</b> <br><br><ul><li>  Available open source symbolic frameworks are still underdeveloped and inferior to imperative in performance. </li></ul><br><h2>  Adding new operations </h2><br>  In all of these frameworks, adding operations while maintaining acceptable performance is not easy. <br><table border="1"><tbody><tr><th>  <b>Theano / MXNET</b> </th><th>  <b>Tensorflow</b> </th></tr><tr><td>  You can add Python operations with support for embedded C operators. </td><td>  Forward in C ++, symbolic gradient in Python. </td></tr></tbody></table><br><h2>  Code reuse </h2><br>  It takes a lot of time to train deep networks.  Therefore, Caffe released several pre-trained models (model zoo) that could be used as initial samples when transferring training or fine-tuning deep networks for specific areas of knowledge or custom images. <br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  Lasagne is a high-level platform based on Theano.  Lasagne makes it easy to use pre-trained Caffe models. </td><td>  No support for pre-trained models. </td><td>  MXNET provides the caffe_converter tool for converting pre-trained caffe models to MXNET format. </td></tr></tbody></table><br><h2>  Low Level Tensor Operators </h2><br>  Rather efficient implementation of low-level operators: they can be used as composite components when creating new models without spending effort on writing new operators. <br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  Many simple operations </td><td>  Quite good </td><td>  Very little </td></tr></tbody></table><br><h2>  Flow control operators </h2><br>  Flow control operators enhance the expressiveness and versatility of the character system. <br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  Supported </td><td>  In the format of the experiment </td><td>  Not supported </td></tr></tbody></table><br><h2>  High level support </h2><br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  A ‚Äúclean‚Äù character computing framework.  You can create high-level platforms as required.  Successful examples include <a href="http://keras.io/">Keras</a> , <a href="http://lasagne.readthedocs.org/en/latest/">Lasagne</a> , <a href="http://blocks.readthedocs.org/en/latest/">blocks.</a> </td><td>  A good device from the point of view of learning neural networks, but at the same time, this framework is not focused exclusively on neural networks, which is very good.  You can use <b>graph collections</b> , <b>queues,</b> and <b>image additions</b> as composite components for high-level shells. </td><td>  In addition to the symbolic part, MXNET also provides all the necessary <a href="https://github.com/dmlc/mxnet/tree/master/example/image-classification">components</a> for classifying images, from loading data to building models with methods to start learning. </td></tr></tbody></table><br><h2>  Performance </h2><br><h4>  Single-GPU Performance Measurement </h4><br>  In my tests, the performance of the LeNet model for the MNIST dataset is measured for a single-GPU configuration (NVIDIA Quadro K1200 GPU). <br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  Fine </td><td>  Average </td><td>  Excellent </td></tr></tbody></table><br><h4>  Memory </h4><br>  The amount of GPU memory is limited, so using for large models can be problematic. <br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  Fine </td><td>  Average </td><td>  Excellent </td></tr></tbody></table><br><h4>  Single-GPU speed </h4><br>  Theano compiles graphs for a very long time, especially in complex models.  TensorFlow is still a little slower. <br><table border="1"><tbody><tr><th>  <b>Theano / MXNET</b> </th><th>  <b>Tensorflow</b> </th></tr><tr><td>  Compare to CuDNNv4 </td><td>  Approximately twice as slow </td></tr></tbody></table><br><h4>  Support parallel and distributed computing </h4><br><table border="1"><tbody><tr><th>  <b>Theano</b> </th><th>  <b>Tensorflow</b> </th><th>  <b>MXNET</b> </th></tr><tr><td>  Experimental Multi-GPU Support </td><td>  Multi-GPU </td><td>  Distributed </td></tr></tbody></table><br><h2>  Conclusion </h2><br>  Theano (with high-level Lasagne and Keras solutions) is an excellent choice for deep learning models.  Using Lasagne / Keras is very easy to create new networks and modify existing ones.  I prefer Python, so I choose Lasagne / Keras because of the very advanced Python interface.  However, these solutions do not support R. The possibilities of transferring training and fine-tuning in Lasagne / Keras show that it is very easy to modify existing networks, as well as to customize for subject-oriented user data. <br><br>  After comparing the frameworks, we can conclude that the most optimal solution will be MXNET (better performance, efficient memory use).  In addition, it has excellent R support. Actually, this is the only platform that <a href="http://dmlc.ml/rstats/2015/11/03/training-deep-net-with-R.html">supports</a> all functions on R. In MXNET, transfer of training and fine-tuning of networks are possible, but they are quite difficult to perform (compared to Lasagne / Keras).  Because of this, it will be difficult not only to modify the existing training networks, but also to configure it for subject-oriented user data. <br><br>  <i>If you see an inaccuracy of the translation, please let us know in your private messages.</i> </div><p>Source: <a href="https://habr.com/ru/post/313318/">https://habr.com/ru/post/313318/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../313306/index.html">Donald Knut: how I started analyzing algorithms and went to the USSR for this (37.91.97 / 97)</a></li>
<li><a href="../313308/index.html">Clever floriculture, or Let Itshnik in the garden ... Part 2</a></li>
<li><a href="../313310/index.html">DevCon School: Future Technologies, November 1 (Moscow)</a></li>
<li><a href="../313312/index.html">Security Week 42: winter is coming, exploding pigs, half the Internet is encrypted</a></li>
<li><a href="../313316/index.html">How to deal with cybercrime, while extracting good profits</a></li>
<li><a href="../313320/index.html">SDN - 10 years from idea to implementation</a></li>
<li><a href="../313322/index.html">The realities of work as a game designer in a big studio on the example of BioWare</a></li>
<li><a href="../313326/index.html">Game industry: useful materials for game development from A to Z</a></li>
<li><a href="../313328/index.html">A massive DDoS on the infrastructure of the DNS provider Dyn.com led to the inaccessibility of Twitter, Github, Heroku and other sites.</a></li>
<li><a href="../313330/index.html">Binary (file) storage, a terrible tale with a gloomy end</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>