<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Random forest vs neural network: who will better cope with the task of recognizing gender in speech (part 2)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The first part of our guide was devoted to an interesting machine learning task - recognizing gender by voice. We described the general approach to mo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Random forest vs neural network: who will better cope with the task of recognizing gender in speech (part 2)</h1><div class="post__text post__text-html js-mediator-article">  <a href="https://habrahabr.ru/company/neurodatalab/blog/334136/">The first part of</a> our guide was devoted to an interesting machine learning task - recognizing gender by voice.  We described the general approach to most of the problems of speech processing and with the help of a random forest trained on the statistics of acoustic attributes, we solved the problem with a rather high accuracy - 98.4% of correctly classified audio fragments. <br><br>  In the second part of the guide, we will see if neural networks can cope with this task more effectively than a random forest, and also try to take into account the biggest drawback of classical methods - the inability to work with data sequences. <br><br>  In a sense, this stage is redundant: the sex of a person does not change during a conversation (at least at the current stage of development and under the specified standard conditions), therefore, it is not worth counting on an increase in accuracy.  But for academic purposes, we will try. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
     <a href="https://habrahabr.ru/company/neurodatalab/blog/335804/"><img src="https://habrastorage.org/web/ed4/a89/4d7/ed4a894d7c094bbf86e27c0425f1c779.jpg"></a> <a name="habracut"></a>  <i>/ Photograph by <a href="https://www.flickr.com/photos/9516941%40N08/34976664984/in/photolist-VhLxW1-jfLp9U-bBUZRk-UL84Zj-e3zyBL-7hSu7G-oTkoL6-dVN3cF-dAD6dB-evcscu-9bJLX8-fb3aPZ-V9YDyq-hK1mfQ-sE9WLd-hFv6Qm-kVXPJw-dDjZRb-i9XYo2-7Y2JQa-dMKrzL-9JvcnN-9d89tL-7iZXpE-dMKrAQ-i9Y3HV-bHN9ii-o6cuWr-rcp6MD-dixuFr-SodZ3m-i9Yno8-qhMJif-ogQTuZ-GCedF-i9Y1rb-4XSFPB-e1GoYU-bA2H1u-emUjxL-e4qHGD-8Ziuou-Soe1kb-gw1X4w-egwuN1-bPjU8D-ax8haC-hX3b1q-bxFkzf-dDeBBV">Tristan Bowersox</a> / <a href="https://creativecommons.org/licenses/by/2.0/">CC-SA</a></i> <br><br><h2>  Another chapter on how neural networks work </h2><br>  It is believed that the artificial neural network (neural network) is a mathematical model of the human brain.  Actually, <a href="https://habrahabr.ru/post/250625/">no</a> : 50-60 years ago, biologists at a certain level studied the electrical processes in the brain, and mathematicians created a simplified model and programmed it. <br><br>  It turned out that such structures are able to solve some simple problems, but a) worse than classical methods and b) much slower than them.  And the undisputed status quo persisted for half a century - scientists developed a theory (teaching methods, architectures, fundamental mathematical questions), and computer hardware and software developed so that it became possible to solve some problems on a home PC at the world level. <br><br>  But <a href="https://habrahabr.ru/post/259191/">not everything is</a> so smooth: a neuronet can learn to distinguish a cheetah from a leopard, and can consider one of these animals a spotted sofa.  In addition, the processes of teaching a person and a machine are different: a computer needs thousands of teaching examples, while a person needs several.  Obviously, the work of artificial neural networks is not very similar to human thinking, and they are not a computer model of the brain, but just another class of models in the list: Random Forest, SVM, XGBoost, etc., although with advantageous features. <br><br>  Historically, the first working neural network architecture is a multi-layer perceptron.  It consists of layers, and each layer consists of neurons.  The signal is transmitted in one direction - from the first layer to the last, and each neuron of the current layer is connected with all the neurons of the previous one, and with different weights.  The weight of the connection between two neurons has a physical meaning of its importance: the greater its value, the greater the contribution to the output value of the neuron.  To teach a neural network means to find such weights so that we can get what we need on the output layer. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/073/e72/6c7/073e726c7c1f43269f77ad02d73b0c72.jpg" width="300"></div><br><br>  The fully connected architectures do not qualitatively differ from the classical methods: they take a vector of numbers as input, somehow they are processed, and the output is a set of probabilities that the input vector belongs to one of the classes (this is the case for the classification task, but others can be considered).  In practice, other architectures (convolutional, recurrent) are used to process the input features, obtaining the so-called high-level features, and then process them using fully connected layers. <br><br>  Analysis of the work of convolutional networks can be found <a href="https://habrahabr.ru/post/309508/">here</a> and <a href="https://habrahabr.ru/company/wunderfund/blog/314872/">here</a> (there are thousands of them, so we leave the choice to the reader), and we will analyze the recurrent ones separately.  At the input, they take sequences of numbers, no matter whether they are signs, signal values, or word labels.  The role of neurons for them is usually performed by special cells, which, in addition to summing the input signal and receiving the output signal, have a set of additional parameters ‚Äî internal values ‚Äã‚Äãthat are remembered and affect the output value of the cell. <br><br>  Today the most widely used recurrent architecture is Long Short-Term Memory (LSTM).  In the simplest implementation, each cell contains three specific elements: input, output, and forgetting valve.  They determine the proportions in which the processed input data and stored values ‚Äã‚Äãneed to be ‚Äúmixed‚Äù in order to get the most useful signal at the output.  To teach an LSTM network is to find the parameters of the valves and the weight of connections between the LSTM cells on the first layers and the neurons of the last layers, for which the output layer for the input sequence would return the probabilities of belonging to each of the classes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/060/8c4/2e4/0608c42e414a465781c46cac1a4c7db6.png" width="600"></div><br><br><h2>  Initial settings </h2><br>  We hope that you have read the <a href="https://habrahabr.ru/company/neurodatalab/blog/334136/">first</a> part of this guide.  In it you can find a description of the speech base, the calculated signs, as well as the results of the work of the Random Forest classifier.  He studied at the statistics of signs counted on good (up to a certain limit) filtered sections of speech - frames.  For each characteristic, the mean, median, minimum and maximum values, as well as the standard deviation were considered. <br><br>  Neural networks are more demanding on the number of training examples.  In the last part, we studied 436 audio fragments from 109 speakers (four utterances for each) taken from the <a href="http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html">VCTK</a> base.  It turned out that none of the neural network architectures we tested could learn to reasonable accuracy values, and we took more fragments ‚Äî a total of 5000. However, the increased sample did not lead to a significant increase in accuracy ‚Äî 98.5% of correctly classified fragments.  The first experiment we want to perform is to train a fully connected neural network on the same set of features. <br><br>  We continue to write all the code in Python, we take the implementation of neural networks from Keras - the most convenient library, through which you can implement the necessary architectures in a couple of lines. <br><br>  We import everything that we need: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv, os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> RFC <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GroupKFold <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Dropout, LSTM, Activation, BatchNormalization <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.wrappers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Bidirectional <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> to_categorical</code> </pre> <br>  We take the implementation of the random forest from sklearn, and from there, cross-validation into groups.  From Keras, we take the base class for the models, the layers, the Bidirectional wrapper, which allows the use of bidirectional LSTM, as well as the to_categorical function encoding class labels in one-hot vector. <br><br>  We read all the data: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'data.csv'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>)<span class="hljs-keyword"><span class="hljs-keyword">as</span></span> c: r = csv.reader(c, delimiter=<span class="hljs-string"><span class="hljs-string">','</span></span>) header = next(r) data = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> row <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> r: data.append(row) data = np.array(data) genders = data[:, <span class="hljs-number"><span class="hljs-number">0</span></span>].astype(int) speakers = data[:, <span class="hljs-number"><span class="hljs-number">1</span></span>].astype(int) filenames = data[:, <span class="hljs-number"><span class="hljs-number">2</span></span>] times = data[:, <span class="hljs-number"><span class="hljs-number">3</span></span>].astype(float) pitch = data[:, <span class="hljs-number"><span class="hljs-number">4</span></span>:<span class="hljs-number"><span class="hljs-number">5</span></span>].astype(float) features = data[:, <span class="hljs-number"><span class="hljs-number">4</span></span>:].astype(float)</code> </pre> <br>  And get a sample: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, subj, names, statistics=[np.mean, np.std, np.median, np.min, np.max])</span></span></span><span class="hljs-function">:</span></span> avx = [] avy = [] avs = [] keys = np.unique(names) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ki, k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(keys): idx = names == k v = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> stat <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> statistics: v += stat(x[idx], axis=<span class="hljs-number"><span class="hljs-number">0</span></span>).tolist() avx.append(v) avy.append(y[idx][<span class="hljs-number"><span class="hljs-number">0</span></span>]) avs.append(subj[idx][<span class="hljs-number"><span class="hljs-number">0</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(avx), np.array(avy).astype(int), np.array(avs).astype(int) filter_idx = pitch[:, <span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">1</span></span> filtered_average_features, filtered_average_genders, filtered_average_speakers = make_sample(features[filter_idx], genders[filter_idx], speakers[filter_idx], filenames[filter_idx])</code> </pre><br>  Here we applied filtering by frequency ‚Äî we threw out from consideration those sections of speech where the pitch frequency was not determined.  This can happen in two cases: the frame does not correspond to speech in general, or corresponds to consonant sounds or whispers.  In our task, we can throw out absolutely all frames without a pitch, but in many others, filtering should be done less greedily. <br><br>  Next you need to implement a fully connected neural network: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_dnn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, tx, ty)</span></span></span><span class="hljs-function">:</span></span> yc = to_categorical(y) <span class="hljs-comment"><span class="hljs-comment"># one-hot encoding for y tyc = to_categorical(ty)# one-hot encoding for y_test inp = Input(shape=(x.shape[1],)) model = BatchNormalization()(inp) model = Dense(100, activation='tanh')(model) model = Dropout(0.5)(model) model = Dense(100, activation='tanh')(model) model = Dropout(0.5)(model) model = Dense(100, activation='sigmoid')(model) model = Dense(2, activation='softmax')(model) model = Model(inputs=[inp], outputs=[model]) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc']) modelcheckpoint = ModelCheckpoint('model.weights', monitor='val_loss', verbose=1, save_best_only=True, mode='min') model.fit(x, yc, validation_data=(tx, tyc), epochs=100, batch_size=100, callbacks=[modelcheckpoint], verbose=2) model.load_weights('model.weights') return model</span></span></code> </pre><br>  The first layer of the network is <a href="https://habrahabr.ru/post/309302/">Batch Normalization</a> .  It eliminates the need to normalize the data, and also speeds up the learning process and makes it possible to avoid retraining to some extent.  Initially, each batch (a portion of data at each iteration of training) is normalized to its own mean and standard deviations, and then scaled using a linear transformation, the parameters of which are to be optimized. <br><br>  Approximately for the same purpose, after each fully connected layer, there are <a href="https://habrahabr.ru/company/wunderfund/blog/330814/">Dropout</a> layers.  They randomly select some of the neurons (in our case, half) of the previous layer and reset their output values.  This makes the network more stable: even if we remove some of the links, it will still give the correct answer.  Exactly for this reason, in practice, layers with double the number of neurons and a 50% <i>dropout</i> are more effective than ordinary layers. <br><br>  Dense - directly full mesh layers.  Their outputs are a classical weighted sum of input signals with some weights, which is nonlinearly transformed using the activation function.  On the first layers, this is <i>tanh</i> , and on the last, <i>softmax</i> , so that the sum of the output signal equals one and corresponds to the probability of being in one of the classes.  Model checkpoint is rather a decorative thing, rewriting a model after each training epoch, only if the error measure on the test sample ‚Äî the <i>validation loss</i> ‚Äî is less than the previous saved model.  This ensures that the most efficient model is recorded in <i>model.weights</i> . <br><br>  It remains to describe the process of cross-validation of the speakers and compare the fully connected network and the random forest described above on the same data: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">subject_cross_validation</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf, x, y, subj, folds)</span></span></span><span class="hljs-function">:</span></span> gkf = GroupKFold(n_splits=folds) scores = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> train, test <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> gkf.split(x, y, groups=subj): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> clf == <span class="hljs-string"><span class="hljs-string">'dnn'</span></span>: model = train_dnn(x[train], y[train], x[test], y[test]) score = model.evaluate(x[test], to_categorical(y[test]))[<span class="hljs-number"><span class="hljs-number">1</span></span>] scores.append(score) <span class="hljs-keyword"><span class="hljs-keyword">elif</span></span> clf == <span class="hljs-string"><span class="hljs-string">'lstm'</span></span>: model = train_lstm(x[train], y[train], x[test], y[test]) score = model.evaluate(x[test], to_categorical(y[test]))[<span class="hljs-number"><span class="hljs-number">1</span></span>] scores.append(score) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: clf.fit(x[train], y[train]) scores.append(clf.score(x[test], y[test])) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.mean(scores) score_filtered = subject_cross_validation(RFC(n_estimators=<span class="hljs-number"><span class="hljs-number">1000</span></span>), filtered_average_features, filtered_average_genders, filtered_average_speakers, <span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> score_filtered score_filtered = subject_cross_validation(<span class="hljs-string"><span class="hljs-string">'dnn'</span></span>, filtered_average_features, filtered_average_genders, filtered_average_speakers, <span class="hljs-number"><span class="hljs-number">5</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Utterance classification an averaged features over filtered frames, accuracy:'</span></span>, score_filtered)</code> </pre> <br>  We obtained approximately the same accuracy values ‚Äã‚Äã- 98.6% for a random forest and 98.7% for a neural network.  Probably, you can optimize the parameters and get higher accuracy, but immediately proceed to what it was all about: recurrent networks. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_sequences</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, subj, names)</span></span></span><span class="hljs-function">:</span></span> sx = [] sy = [] ss = [] keys = np.unique(names) sequence_length = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ki, k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(keys): idx = names == k v = x[idx] w = np.zeros((sequence_length, v.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]), dtype=float) sh = v.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> sh &lt;= sequence_length: dh = sequence_length - sh <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> dh % <span class="hljs-number"><span class="hljs-number">2</span></span> == <span class="hljs-number"><span class="hljs-number">0</span></span>: w[dh//<span class="hljs-number"><span class="hljs-number">2</span></span>:sequence_length-dh//<span class="hljs-number"><span class="hljs-number">2</span></span>, :] = v <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: w[dh//<span class="hljs-number"><span class="hljs-number">2</span></span>:sequence_length<span class="hljs-number"><span class="hljs-number">-1</span></span>-dh//<span class="hljs-number"><span class="hljs-number">2</span></span>, :] = v <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: dh = sh - sequence_length w = v[sh//<span class="hljs-number"><span class="hljs-number">2</span></span>-sequence_length//<span class="hljs-number"><span class="hljs-number">2</span></span>:sh//<span class="hljs-number"><span class="hljs-number">2</span></span>+sequence_length//<span class="hljs-number"><span class="hljs-number">2</span></span>, :] sx.append(w) sy.append(y[idx][<span class="hljs-number"><span class="hljs-number">0</span></span>]) ss.append(subj[idx][<span class="hljs-number"><span class="hljs-number">0</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(sx), np.array(sy).astype(int), np.array(ss).astype(int)</code> </pre> <br>  First you need to make a sample of the sequences.  Keras, despite its simplicity, is sometimes fastidious, and here it is necessary that the input variables in the <i>.fit</i> or <i>.fit_on_batch methods</i> can be naturally transformed into tensors.  For example, sequences of different lengths (and we have this particular case) do not possess this property. <br><br>  This purely technical limitation of the library can be circumvented in several ways.  The first is training in batch size 1. The obvious disadvantages of this approach are the inapplicability of <i>batch normalization</i> and the catastrophic increase in training time. <br><br>  The second way is to add zeros to the sequence (padding) to get the desired dimension.  At first glance, this seems wrong, but the network learns not to respond to such values.  Also, these methods can be combined - to split the length of the sequence into several groups, inside each hold a padding and train. <br><br>  We consider sequences of length 100 ‚Äî this corresponds to one second of speech.  To do this, we cut the long sequences in such a way that exactly 100 points remain, moreover, symmetrical with respect to the middle, and short ones with zeroes at the beginning and end to the desired length. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_lstm</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, tx, ty)</span></span></span><span class="hljs-function">:</span></span> yc = to_categorical(y) tyc = to_categorical(ty) inp = Input(shape=(x.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], x.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>])) model = BatchNormalization()(inp) model = Bidirectional(LSTM(<span class="hljs-number"><span class="hljs-number">100</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, recurrent_dropout=<span class="hljs-number"><span class="hljs-number">0.1</span></span>), merge_mode=<span class="hljs-string"><span class="hljs-string">'concat'</span></span>)(model) model = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(model) model = Bidirectional(LSTM(<span class="hljs-number"><span class="hljs-number">100</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, recurrent_dropout=<span class="hljs-number"><span class="hljs-number">0.1</span></span>), merge_mode=<span class="hljs-string"><span class="hljs-string">'concat'</span></span>)(model) model = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(model) model = Bidirectional(LSTM(<span class="hljs-number"><span class="hljs-number">2</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, recurrent_dropout=<span class="hljs-number"><span class="hljs-number">0.1</span></span>), merge_mode=<span class="hljs-string"><span class="hljs-string">'ave'</span></span>)(model) model = Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(model) model = Model(inputs=[inp], outputs=[model]) model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'rmsprop'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) modelcheckpoint = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">'model.weights'</span></span>, monitor=<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_best_only=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'min'</span></span>) model.fit(x, yc, validation_data=(tx, tyc), epochs=<span class="hljs-number"><span class="hljs-number">100</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">50</span></span>, callbacks=[modelcheckpoint], verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) model.load_weights(<span class="hljs-string"><span class="hljs-string">'model.weights'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Bidirectional wrapper using <i>merge_mode</i> glues the outputs of the argument layer for the normal input sequence and in the reverse order.  In our case, this is an LSTM layer with 100 cells.  The <i>return_sequences</i> flag determines whether a sequence of internal cell states will be returned, or only the last one will return. <br><br>  Inside LSTM and after the recurrent layers, a <i>dropout</i> is applied, and after the last layer (with <i>return_sequences = False</i> ), there is a <i>softmax</i> activation function.  Also, the model is compiled with the <a href="https://habrahabr.ru/post/318970/">Rmsprop</a> optimizer - a modification of the stochastic gradient descent.  In practice, it often turns out that it works better for recurrent networks, although this is not strictly proven and can always be different. <br><br><pre> <code class="python hljs">filter_idx = pitch[:, <span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">1</span></span> filtered_sequences_features, filtered_sequences_genders, filtered_sequences_speakers = make_sequences(features[filter_idx], genders[filter_idx], speakers[filter_idx], filenames[filter_idx]) score_lstmfiltered = subject_cross_validation(<span class="hljs-string"><span class="hljs-string">'lstm'</span></span>, filtered_sequences_features, filtered_sequences_genders, filtered_sequences_speakers, <span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> score_lstm_filtered</code> </pre> <br>  Hooray!  99.1% of correctly classified points per 5-fold cross-validation by speakers.  This is the best result among all considered architectures. <br><br><h2>  Conclusion </h2><br>  The lion's share of machine learning guides, articles and popular science materials are devoted to image recognition.  Very rarely - training with reinforcements.  More rarely - audio processing.  Partly, probably, this is due to the fact that out-of-the-box methods for audio processing do not work, and one has to spend his time on understanding processes, data preprocessing and other inevitable iterations.  But it is precisely the complexity that makes the task interesting. <br><br>  Gender recognition seems to be a simple task, because a person copes with it almost unmistakably.  But its solution by the methods of machine learning "in the forehead" demonstrates an accuracy of about 70%, which is objectively not enough.  However, even simple algorithms can achieve an accuracy of about 97-98%, if you do everything right: for example, filter the source data.  Complex neural network approaches increase accuracy to more than 99%, which is hardly fundamentally different from human performance. <br><br>  In fact, the potential of recurrent neural networks in this article is not fully disclosed.  Even for the classification task (many to one) they can be used more efficiently.  But of course, we will not do this yet.  We offer readers to do without filtering frames, allowing the network to learn how to process only the necessary frames, and consider longer (either shorter or thinned) sequences. <br><br>  Worked on the material: <br><br><ul><li>  <b>Gregory Sterling</b> , mathematician, leading expert of the <a href="http://neurodatalab.com/">Neurodata Lab</a> on machine learning and data analysis </li><li>  <b>Eva Kazimirova</b> , biologist, physiologist, expert of the <a href="http://neurodatalab.com/">Neurodata Lab</a> in the field of acoustics, voice and speech analysis </li></ul><br>  Stay with us. </div><p>Source: <a href="https://habr.com/ru/post/335804/">https://habr.com/ru/post/335804/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../335792/index.html">Fighting hardcodes with static C # analyzers</a></li>
<li><a href="../335794/index.html">The return of Locky and Mamba: users are attacking new versions of encryption viruses</a></li>
<li><a href="../335796/index.html">Baruch Sadogursky, JFrog: Developer Advocate, Java 9 and Kotlin's world domination (but you better look at Groovy)</a></li>
<li><a href="../335798/index.html">What a job scheduler can do in Postgres Pro</a></li>
<li><a href="../335800/index.html">The Great Silk Road: from tablets from China to a nanny-robot from Moscow region</a></li>
<li><a href="../335806/index.html">Guide to localizing applications for the Chinese market. Part 1</a></li>
<li><a href="../335808/index.html">BIM: how we build builders in construction</a></li>
<li><a href="../335810/index.html">We break and restore the Chinese IP camera</a></li>
<li><a href="../335812/index.html">Simple Java code breaking the Scala type inference system</a></li>
<li><a href="../335814/index.html">Kubernetes success stories in production. Part 3: GitHub</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>