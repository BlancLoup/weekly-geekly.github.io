<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Big Data from A to Z. Part 5.2: Advanced hive features</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! In this article we will continue to look at the possibilities of the hive engine that translates SQL-like queries in the MapReduce task. 

 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Big Data from A to Z. Part 5.2: Advanced hive features</h1><div class="post__text post__text-html js-mediator-article">  <strong>Hi, Habr!</strong>  In this article we will continue to look at the possibilities of the hive engine that translates SQL-like queries in the MapReduce task. <br><br>  In the <a href="https://habrahabr.ru/company/dca/blog/283212/">previous</a> article, we looked at the basic features of hive, such as creating tables, loading data, and performing simple SELECT queries.  Now let's talk about advanced features that will allow you to squeeze the most out of Hive. <br><br> <a href="https://habrahabr.ru/company/dca/blog/305838/"><img src="https://habrastorage.org/getpro/habr/post_images/eeb/0ce/fcf/eeb0cefcff6cfe83badacfa667e1127d.png"></a> <br><a name="habracut"></a><br><h2>  User Defined Functions </h2><br>  One of the main obstacles to working with Hive is the stiffness of standard SQL.  This problem can be solved by using language extensions ‚Äî the so-called User Defined Functions.  Quite a lot of useful features are built right into the Hive language.  Here are some of the most interesting in my opinion (information taken from <a href="https://cwiki.apache.org/confluence/display/Hive/Home">official documentation</a> ): 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>Json</b> <br><br>  A fairly common task when dealing with large data is the processing of unstructured data stored in json format.  To work with json hive, support the special <b>get_json_object</b> method, which allows you to extract values ‚Äã‚Äãfrom json documents.  To retrieve values ‚Äã‚Äãfrom an object, a limited version of the JSONPath notation is used.  The following operations are supported: <br><br><ul><li>  $: Returns the root object </li><li>  .: Turns in a child object </li><li>  []: Address by index in array </li><li>  *: Wildcard for </li></ul><br>  <b>Examples of working with Json from official documentation:</b> <br><br>  Let there is a table: src_json, consisting of one column (json) and one row: <br><br><pre><code class="hljs json">{<span class="hljs-attr"><span class="hljs-attr">"store"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"fruit"</span></span>:\[{<span class="hljs-attr"><span class="hljs-attr">"weight"</span></span>:<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-attr"><span class="hljs-attr">"type"</span></span>:<span class="hljs-string"><span class="hljs-string">"apple"</span></span>},{<span class="hljs-attr"><span class="hljs-attr">"weight"</span></span>:<span class="hljs-number"><span class="hljs-number">9</span></span>,<span class="hljs-attr"><span class="hljs-attr">"type"</span></span>:<span class="hljs-string"><span class="hljs-string">"pear"</span></span>}], <span class="hljs-attr"><span class="hljs-attr">"bicycle"</span></span>:{<span class="hljs-attr"><span class="hljs-attr">"price"</span></span>:<span class="hljs-number"><span class="hljs-number">19.95</span></span>,<span class="hljs-attr"><span class="hljs-attr">"color"</span></span>:<span class="hljs-string"><span class="hljs-string">"red"</span></span>} }, <span class="hljs-attr"><span class="hljs-attr">"email"</span></span>:<span class="hljs-string"><span class="hljs-string">"amy@only_for_json_udf_test.net"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"owner"</span></span>:<span class="hljs-string"><span class="hljs-string">"amy"</span></span> }</code> </pre> <br>  Examples of queries to the table: <br><br><pre> <code class="hljs pgsql">hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> get_json_object(src_json.json, <span class="hljs-string"><span class="hljs-string">'$.owner'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> src_json; amy hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> get_json_object(src_json.json, <span class="hljs-string"><span class="hljs-string">'$.store.fruit\[0]'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> src_json; {"weight":<span class="hljs-number"><span class="hljs-number">8</span></span>,"type":"apple"} hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> get_json_object(src_json.json, <span class="hljs-string"><span class="hljs-string">'$.non_exist_key'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> src_json; <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span></code> </pre> <br>  <b>Xpath</b> <br><br>  Similarly, if the data that needs to be processed using hive is not stored in json, but in XML, it can be processed using the <b>xpath</b> function <b>, which</b> allows parsing XML using the <a href="https://www.w3.org/TR/xpath/">appropriate language</a> .  An example of parsing xml data with xpath: <br><br><pre> <code class="hljs pgsql">hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> xpath(<span class="hljs-string"><span class="hljs-string">'&lt;a&gt;&lt;b&gt;b1&lt;/b&gt;&lt;b&gt;b2&lt;/b&gt;&lt;/a&gt;'</span></span>,<span class="hljs-string"><span class="hljs-string">'a/*/text()'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sample_table <span class="hljs-keyword"><span class="hljs-keyword">limit</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> ; ["b1","b2"]</code> </pre> <br>  <b>Other useful built-in functions:</b> <br><br>  The built-in library contains a fairly rich set of built-in functions.  There are several groups: <br><br><ul><li>  Mathematical functions (sin, cos, log, ...) </li><li>  Functions for working with time (from_unix_timestamp, to_date, current date, hour (string date), timediff, ...) - a very rich choice of functions for converting dates and times </li><li>  Functions for working with strings.  It supports both generally applicable functions, such as lengh, reverse, regexp, and specific ones, such as parse_url or already considered get_json_object) </li><li>  Many different system functions are current_user, current_database, ... </li><li>  Cryptographic functions - sha, md5, aes_encrypt, aes_decrypt ... </li></ul><br>  A complete list of built-in hive functions can be found <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual%2BUDF">here</a> . <br><br><h2>  Writing your own UDF </h2><br>  It is not always enough built-in functions hive to solve the problem.  If there is no built-in function, you can write your own UDF.  This is done in java. <br><br>  Let us analyze the creation of a custom UDF using the example of a simple string conversion function in lowercase: <br><br>  <strong>1.</strong> Create the com / example / hive / udf package and create the Lower.java class in it: <br><br><pre> <code class="hljs axapta">mkdir -p com/example/hive/udf <span class="hljs-keyword"><span class="hljs-keyword">edit</span></span> com/example/hive/udf/Lower.java</code> </pre> <br>  <strong>2.</strong> Implement the Lower class itself: <br><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> com.example.hive.udf; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.hive.ql.exec.<span class="hljs-type"><span class="hljs-type">UDF</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.hadoop.io.<span class="hljs-type"><span class="hljs-type">Text</span></span>; public <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Lower</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">UDF</span></span></span><span class="hljs-class"> </span></span>{ public <span class="hljs-type"><span class="hljs-type">Text</span></span> evaluate(<span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-type"><span class="hljs-type">Text</span></span> s) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (s == <span class="hljs-literal"><span class="hljs-literal">null</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">null</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Text</span></span>(s.toString().toLowerCase()); } }</code> </pre> <br>  <strong>3.</strong> Add the necessary libraries to CLASSPATH (in your hadoop distribution, references to jar files may be slightly different): <br><br><pre> <code class="hljs javascript"><span class="hljs-keyword"><span class="hljs-keyword">export</span></span> CLASSPATH=<span class="hljs-regexp"><span class="hljs-regexp">/opt/</span></span>cloudera/parcels/CDH/lib/hive/lib/hive-exec.jar:<span class="hljs-regexp"><span class="hljs-regexp">/opt/</span></span>cloudera/parcels/CDH/lib/hadoop/hadoop-common.jar</code> </pre> <br>  <strong>4.</strong> Compile our UDF-ku and collect the jar-archive: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">javac</span></span> com/example/hive/udf/Lower.java jar cvf my_udf.jar *</code> </pre> <br>  <strong>5.</strong> In order to be able to use a function in hive, you need to explicitly declare it: <br><br><pre> <code class="hljs pgsql">hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">ADD</span></span> JAR my_udf.jar; hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">create</span></span> <span class="hljs-keyword"><span class="hljs-keyword">temporary</span></span> <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> my_lower <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-string"><span class="hljs-string">'com.example.hive.udf.Lower'</span></span>; hive&gt; <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> my_lower(<span class="hljs-string"><span class="hljs-string">'HELLO'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sample_table <span class="hljs-keyword"><span class="hljs-keyword">limit</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>; hello</code> </pre> <br><h2>  Transformation table using scripts </h2><br>  Another way to extend the standard HIVE functionality is to use the TRANSFORM method, which allows you to convert data using custom scripts in any programming language (this is especially suitable for those who do not like java and do not want to write udf on it). <br><br>  The syntax for using the command is as follows: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TRANSFORM</span></span>(&lt;<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>&gt;) <span class="hljs-keyword"><span class="hljs-keyword">USING</span></span> &lt;script&gt; <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> &lt;new_columns&gt;</code> </pre> <br>  &lt;script&gt; - in this case, it is a program that receives data on stdin, converts it, and outputs converted data to stdout.  In fact, this is very similar to the streaming interface for running map-reduce tasks, which we wrote about in the <a href="https://habrahabr.ru/company/dca/blog/268277/">Big Data</a> article <a href="https://habrahabr.ru/company/dca/blog/268277/">from A to Z. Part 2: Hadoop</a> <br><br>  <b>Example:</b> <br><br>  Suppose we have a table with the salaries of users who receive salaries in different currencies: <br><br><pre> <code class="hljs ruby">+-------------------+---------------------+-----------------------+ <span class="hljs-params"><span class="hljs-params">| user_salary.name  |</span></span> user_salary.salary  <span class="hljs-params"><span class="hljs-params">| user_salary.currency  |</span></span> +-------------------+---------------------+-----------------------+ <span class="hljs-params"><span class="hljs-params">| alexander         |</span></span> <span class="hljs-number"><span class="hljs-number">100000</span></span>              <span class="hljs-params"><span class="hljs-params">| RUB                   |</span></span> <span class="hljs-params"><span class="hljs-params">| evgeniy           |</span></span> <span class="hljs-number"><span class="hljs-number">4000</span></span>                <span class="hljs-params"><span class="hljs-params">| EUR                   |</span></span> <span class="hljs-params"><span class="hljs-params">| alla              |</span></span> <span class="hljs-number"><span class="hljs-number">50000</span></span>               <span class="hljs-params"><span class="hljs-params">| RUB                   |</span></span> <span class="hljs-params"><span class="hljs-params">| elena             |</span></span> <span class="hljs-number"><span class="hljs-number">1500</span></span>                <span class="hljs-params"><span class="hljs-params">| EUR                   |</span></span> +-------------------+---------------------+-----------------------+</code> </pre><br>  We want to get a sign in which there will be ruble salaries for all users.  To do this, we write a script in python that performs data conversion: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys EXCHANGE_RATE = <span class="hljs-number"><span class="hljs-number">75</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> <span class="hljs-type"><span class="hljs-type">line</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sys.stdin: <span class="hljs-type"><span class="hljs-type">name</span></span>, salary, currency = <span class="hljs-type"><span class="hljs-type">line</span></span>.rstrip("\n").split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> currency == <span class="hljs-string"><span class="hljs-string">'EUR'</span></span>: print <span class="hljs-type"><span class="hljs-type">name</span></span> + "\t" + str(<span class="hljs-type"><span class="hljs-type">int</span></span>(salary) * EXCHANGE_RATE) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: print <span class="hljs-type"><span class="hljs-type">name</span></span> + "\t" + salary</code> </pre> <br>  The script implies that the input data comes in a tsv format (columns are separated by a tab).  If the table contains the value NULL, the script will receive the value '\ N'. <br><br>  Then use this script to convert the table: <br><br><pre> <code class="hljs smalltalk"><span class="hljs-number"><span class="hljs-number">0</span></span>: jdbc:hive2://localhost:<span class="hljs-number"><span class="hljs-number">10000</span></span>/default&gt; select transform(name, salary, currency) using <span class="hljs-string"><span class="hljs-string">'python transform_to_rub.py'</span></span> as (name, rub_salary) from user_salary; +------------+-------------+ | name | rub_salary | +------------+-------------+ | alexander | <span class="hljs-number"><span class="hljs-number">100000</span></span> | | evgeniy | <span class="hljs-number"><span class="hljs-number">300000</span></span> | | alla | <span class="hljs-number"><span class="hljs-number">50000</span></span> | | elena | <span class="hljs-number"><span class="hljs-number">112500</span></span> | +------------+-------------+</code> </pre> <br>  In fact, using the TRANSFORM operation makes it possible to completely replace the classic MapReduce with hive. <br><br><h2>  Mapjoin </h2><br><br>  As we wrote in the article about the <a href="https://habrahabr.ru/company/dca/blog/270453/">techniques and strategies for working with MapReduce</a> - in order for JOIN to implement two tables, in general, several MapReduce tasks are needed.  Since hive works on MapReduce, JOIN is also an expensive operation for it. <br>  However, if one of the two tables that you need to fully join into the RAM memory of each node, you can do with MapReduce by loading the label into memory.  This pattern is called MapJoin.  In order for Hive to use MapJoin it is necessary to give him a hint (‚Äúhint‚Äù in Hive terminology). <br><br>  <b>Example:</b> <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-comment"><span class="hljs-comment">/*+ MAPJOIN(time_dim) */</span></span> COUNT(*) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> store_sales <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> time_dim <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> (ss_sold_time_sk = t_time_sk)</code> </pre> <br>  In this example, it is assumed that the table ‚Äústore_sales‚Äù is large, and the table ‚Äútime_dim‚Äù is small and is stored in memory.  / * + MAPJOIN (time_dim) * / - this is exactly the same hint for for HIVE about starting the MAPJOIN task <br><br><h2>  Transactional model </h2><br>  The transactional <a href="https://en.wikipedia.org/wiki/ACID">ACID</a> model implies support for 4 basic properties: <br><br><ul><li>  <b>Atomicity</b> - the operation is either entirely performed by completely changing the data, or it falls and leaves no traces behind it. <br><br></li><li>  <b>Consistency</b> - after the application performs an operation, its result becomes available for all subsequent operations. <br><br></li><li>  <b>Isolation</b> - the operations of some users do not have side effects on other users. <br><br></li><li>  <b>Durability</b> - changes made as a result of a successful operation preserve the result even in the event of a system failure. <br></li></ul><br>  Generally speaking, Hive is not well suited for dealing with changing data, but there are several cases where support for changing data is needed.  First of all it is: <br><br><ul><li>  Data added in streaming mode (from systems such as <a href="https://flume.apache.org/">flume</a> , <a href="http://kafka.apache.org/">kafka</a> ).  I want the data to be available for analysis in hive immediately as they arrived <br><br></li><li>  Updating the schema ‚Äî for example, adding a new column to the hive table.  I want the column to either be successfully added to each record, or to fall and not to be added to any <br><br></li><li>  Sometimes you still need to update individual records. <br></li></ul><br>  For these purposes, starting from version 0.14, hive has been implemented to support the transactional model, implemented by three operations - INSERT, UPDATE and DELETE. <br><br>  Support for these operations is very limited: <br><br><ul><li>  Currently only <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual%2BORC">ORC</a> format files are supported. <br><br></li><li>  By default, transaction support is disabled.  To enable it, you must make the <a href="https://cwiki.apache.org/confluence/display/Hive/Hive%2BTransactions">appropriate changes</a> to the hive configuration file. <br><br></li><li>  There is no support for BEGIN, COMMIT, ROLLBACK commands familiar with relational databases. </li></ul><br>  Transaction support is implemented using delta files.  That is, when performing the data update operation, the data in the source file is not updated, but a new file is created where it is noted which lines were changed.  Later, hive will combine them with the compaction operation (the same is used in hbase). <br><br>  In general, since transaction support is very limited, it is worth thinking very seriously before using this functionality in Hive.  It may be worth looking in the direction of HBase or traditional relational databases. <br><br><h2>  Conclusion </h2><br>  In this and <a href="https://habrahabr.ru/company/dca/blog/283212/">previous</a> article in the series, we looked at the main features of Hive, a powerful tool that facilitates working with MapReduce tasks.  Hive is perfect for analysts who are used to working with SQL, can be easily integrated into the existing infrastructure with the support of the JDBC driver, and taking into account support for User Defined Functions and custom transformations, it allows you to completely transfer data processing from the classic MapReduce to yourself.  However, hive is not a ‚Äúsilver pill‚Äù - for frequently updated data you can look towards tools such as Hbase and classic relational databases. <br><br>  In the next articles of the series, we will continue to look at tools for working with big data and methods for processing them.4 <br><br>  <a href="https://www.youtube.com/channel/UCOvuB83CWNZ0yz8qeNpWIIQ">Youtube Channel about data analysis</a> </div><p>Source: <a href="https://habr.com/ru/post/305838/">https://habr.com/ru/post/305838/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../305826/index.html">Transition from monolith to microservices</a></li>
<li><a href="../305828/index.html">Angular2-like registration of components and dependencies for knockoutjs</a></li>
<li><a href="../305832/index.html">After a year of using NodeJS to develop</a></li>
<li><a href="../305834/index.html">Reuse rows for high performance on React Native ListView</a></li>
<li><a href="../305836/index.html">Mobile programmatic "on the fingers": the revolution will be velvet</a></li>
<li><a href="../305840/index.html">Basics of game design: 20 board games. Part Four: Train Ticket, Carcassonne, Colonialists</a></li>
<li><a href="../305842/index.html">Improving colors on the web (for eplofilov)</a></li>
<li><a href="../305844/index.html">Lenovo will fix a 0day ThinkPwn vulnerability in the firmware of its computers</a></li>
<li><a href="../305846/index.html">API Yandex.Panoram: how to make your virtual walk or just bring a person from the subway</a></li>
<li><a href="../305848/index.html">A collection of songs with a guitar to the day of the system administrator (with chords!)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>