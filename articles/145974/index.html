<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Testing: Manual or Automated?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I want to share my experience in organizing the testing process, which covers 3 years of my work and the creation of several large systems. The descri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Testing: Manual or Automated?</h1><div class="post__text post__text-html js-mediator-article">  I want to share my experience in organizing the testing process, which covers <b>3 years of</b> my work and the creation of several large systems.  The description will only affect the automation of "manual" testing without interfering with other aspects of software development. <br><br>  I think it is worth mentioning at once that at all stages we used: <br><ul><li>  Unit tests with a coating of about 50% </li><li>  Continuous Integration with the launch of unit tests (later integration tests), automatic build and release release </li><li>  The intersection of flexible methodologies under the common name <a href="http://www.dotnetconf.ru/Materialy/Praktika_raboty_s_krupnimi_proektami_ot_scrum_xp_k_kanban">ScrumbanXP</a> </li></ul><br><br>  Everywhere, where I will talk about testing automation, we will talk about testing the interface with connection to external resources (database, file system, services, etc.). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br><br><h4>  Step 1. No testers </h4><br><br>  On the first major project in which I participated, there were no testers.  The developers, before uploading to the combat server, themselves checked the main parts of the system.  With this approach, bugs are often crawled out. <br><br>  It was obvious to everyone that programmers love their code and are not very enthusiastic about testing a newly written feature.  About testing previously written features, and even other developers, we can‚Äôt say anything at all.  The programmers themselves will not re-run all sorts of scenarios to work with the system and go into all the tabs of all pages. <br><br>  In fact, on this project we could afford a similar approach.  Our users sat within reach.  It was a project for the internal automation of the company.  Operators and managers who worked with the System could come to us and discuss the functionality, point out errors.  Accordingly, we could make a quick fix and upload the revised version. <br><br>  Error reports boiled down to screams behind the wall.  Losses at bugs were insignificant, the situation suited everyone. <br><br>  Judging by the survey that I conducted. <a href="http://habrahabr.ru/post/122252">How is the testing process arranged for you?</a>  most can afford just such an approach to testing. <br><br><h4>  Step 2. Start test automation </h4><br><br>  We started to make a new system, which should have been used not only by the people behind the wall, but also by outside users.  There is a need to hire a <b>tester</b> who would protect us from bad releases. <br><br>  I hired a tester and, to begin with, we decided that testing should be automated, like running unit tests.  Automation was supposed to save the tester from constantly repeating the same scenarios. <br><br>  <b>The idea was simple and seemed to everyone to solve problems.</b>  <b>We wanted CI to launch an integration test suite at night.</b>  <b>In the morning we come, if the tests are all green, it means you can make a release.</b>  <b>If there are red tests, then we fix, run the entire test suite again, etc.</b>  <b>until all the tests turn green.</b> <br><br>  For recording tests, we tried various options, settled on <a href="http://seleniumhq.org/">Selenium</a> .  At first, the tests were written on the Selenium API itself.  Over time, a wrapper above the low-level API began to be created, and this wrapper was turned into a DSL for testing. <br><br>  While the tester was dealing with the products for testing and was developing the test automation process, development did not stop.  We had to release new versions after every 1-2 iterations.  The tester was constantly in the stage of chasing programmers.  His goal was 100% coverage of scenarios so that we can safely release new versions without fear of bugs. <br><br><h4>  Step 3. Fight for green tests </h4><br><br>  Problems with test automation were unexpected for us.  In fact, we were not ready for them. <br><br><h5>  Long feedback </h5><br><br>  The larger the system, the more tests we wrote.  Tests began to work really slowly.  If they took place in 14 hours - it was incredible luck.  Over time, the tests no longer fit into the gap between 6:00 pm of the last day and 9:00 am of the current day.  We did not receive feedback from the tests, there were downtime at work.  It also happened that the lights would be turned off or the server would reboot, then the time losses were too great. <br><br><h5>  Green tests?  No, did not see </h5><br><br>  Green tests have never been.  True once were, on December 30 they started and gave the result as 100% green.  Perhaps it was their gift to us for the New Year.  More of this all time was not. <br><br>  Why they were not green?  There were several reasons for this: <br><br><ul><li>  <b>Fragile tests</b> - the interface is constantly changing and the tests did not keep pace with these changes. </li><li>  <b>Inflexible tests</b> - the system architecture is constantly being improved, there are generalizing solutions for code flexibility.  The test code (description) also needs to be refactored and generalized to make them easier to maintain.  For example, we should have many typical workflows with minor changes.  Developers <br>  coming up with an architecture that is flexible enough to allow <br>  quickly implement these workflows.  Accordingly, the test architecture should <br>  to improve in a similar way and ‚Äúkeep up‚Äù with the improvement of architecture <br>  code, which was not done due to insufficient qualifications of the tester.  Of- <br>  for the fact that the test architecture "does not have time" for the code architecture, programmers <br>  implement the features faster and faster and the backlog of the tester accumulates </li><li>  <b>Minor bugs</b> - tests did not always find critical bugs, sometimes they fell because of minor bugs that we knew about, but correcting them was not a priority.  For this, they even specially made a plugin for TeamCity and it was possible to watch whether the test should fall or not.  A set of falling tests with minor bugs did not allow the tests to be green. </li><li>  <b>Unreadable tests</b> - for example, we have a complicated script with a large <br>  number of actions, the result of which you want to test.  Respectively, <br>  The test can not be divided into several small ones (not an intermediate result is checked, <br>  and the final, which is achieved as a result of several actions).  The code for such a test <br>  need to be optimized so that it remains understandable and readable, which is also not <br>  managed to achieve. </li><li>  <b>Long scenarios</b> - to implement long scenarios we need to do, for example, 10-20 steps.  The intermediate result is not important, only the final one is important.  There are a number of problems with long scenarios: <br><ul><li>  If an error occurred at the 2nd step, then the entire script is considered to be in error.  In this case, the red test says not about the error in what it tested, but in the error of the step that was somewhere in the beginning (they could change the Login interface). </li><li>  In long scenarios, the steps are often repeated, duplication occurs. </li><li>  The long scenario cannot be started from the middle, because for this it is necessary to prepare a special state of the system, in which it must be to the N-th step.  This brings additional fragility to the test structure. </li></ul><br></li></ul><br><br>  Due to the <b>instability of the</b> tests and the fact that we did not have time to update them, we had to: <br><br><ul><li>  Switch the developer to help testers switch to <a href="http://www.specflow.org/">SpecFlow</a> , otherwise testers did not keep the amount of tests in C # code.  The head of the testing department at that time <a href="http://www.dotnetconf.ru/Materialy/Priemochnie_testi_na_ogurce">gave a</a> report on the subject of <a href="http://www.dotnetconf.ru/Materialy/Priemochnie_testi_na_ogurce">acceptance tests on a cucumber</a> </li><li>  70% of the time testers rewrote automatic tests to match the current set of system functions.  Those.  it was a job for the sake of the tests themselves. </li><li>  As a consequence of the above, we hired more testers. </li></ul><br><br><h5>  Is the goal achieved? </h5><br><br>  <b>We had a goal - to see green integration tests and, without fear of bugs, upload to the combat server.</b>  <b>In fact, we have not achieved this goal.</b> <br><br>  As a result, the very first launch of the system in real conditions showed that auto tests pass a lot of bugs.  We found these bugs when we manually poked the system.  In 10 minutes of manual testing, the most critical bugs were discovered. <br><br>  I decided to cancel the work on all integration tests and entered manual testing with writing test scripts in Google Docs.  After that, we finished the main bugs and testing was perfectly integrated into the Kanban stream. <br><br><h4>  Current state </h4><br><br>  At the moment, in my company, we with a team of testers follow the approach: manual testing + writing test scripts in Google Docs.  Testers manually pierce all the scripts before pouring. <br><br>  Test scripts are considered part of the project artifacts and are delivered to the customer along with the source code. <br><br>  In fact, it gives excellent results.  In releases we have only minor bugs, or bugs, which are in fact features. <br><br><h4>  Against test automation? </h4><br><br>  It is necessary to understand the limits of applicability of the approach to test automation.  For example, if you write a bug, which catches errors 404 and 500 on a live server, then the effort is justified. <br><br>  If you have a simple application that sometimes changes, it makes sense to make a set of integration tests for it, but combine it with manual testing. <br><br>  If you want to replace manual testing with 100% automatic, then consider how to avoid the problems described above.  Perhaps we <b>had to</b> first use manual testing, and then, automate those parts, the automation of which will give the maximum effect without the need to maintain these tests. <br><br>  I will be glad to hear how testing has evolved in your company. <br><br><hr><br><br>  <b><i>Links</i></b> <br><br>  <a href="http://www.joelonsoftware.com/articles/fog0000000067.html">Top Five (Wrong) Reasons You Don't Have Testers</a> , Joel Spolsky <br>  <a href="http://www.joelonsoftware.com/articles/fog0000000043.html">The Joel Test: 12 Steps to Better Code</a> , Joel Spolsky <br>  <a href="http://www.slideshare.net/Cartmendum/testlabs09-part-i%3Ffrom%3Dss_embed">Monkey against robots.</a>  <a href="http://www.slideshare.net/Cartmendum/testlabs09-part-i%3Ffrom%3Dss_embed">Part I (TestLabs09)</a> , Maxim Dorofeev <br>  <a href="http://www.slideshare.net/Cartmendum/testlabs-part-ii%3Ffrom%3Dss_embed">Monkey against robots.</a>  <a href="http://www.slideshare.net/Cartmendum/testlabs-part-ii%3Ffrom%3Dss_embed">Part II (TestLabs09)</a> , Maxim Dorofeev <br>  <a href="http://www.slideshare.net/Cartmendum/test-labs09-dorofeev-m-part-iii%3Ffrom%3Dss_embed">Monkey against robots.</a>  <a href="http://www.slideshare.net/Cartmendum/test-labs09-dorofeev-m-part-iii%3Ffrom%3Dss_embed">Part III (TestLabs09)</a> , Maxim Dorofeev <br>  <a href="http://www.dotnetconf.ru/Materialy/Organizacia_raboty_komandy_v_agile_razrabotka_testirovanie">Organizing team work in Agile: development + testing</a> </div><p>Source: <a href="https://habr.com/ru/post/145974/">https://habr.com/ru/post/145974/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../145968/index.html">Software development quotes</a></li>
<li><a href="../145970/index.html">A simple site with the possibility of authorization on node.js</a></li>
<li><a href="../145971/index.html">Circos Review: The Circle Is Good</a></li>
<li><a href="../145972/index.html">WikiWars: Wikipedia Search Fights</a></li>
<li><a href="../145973/index.html">Stream radio or police wave online</a></li>
<li><a href="../145977/index.html">Groovy and AST Transformations on Application Security Service</a></li>
<li><a href="../145980/index.html">Setting up a correct shutdown of guest Windows 2003 in qemu-kvm Linux</a></li>
<li><a href="../145981/index.html">Does your VDS / VPS / Dedicated hoster alert you about reboots and shutdowns?</a></li>
<li><a href="../145982/index.html">Trigger Timer for Nikon</a></li>
<li><a href="../145983/index.html">In Scotland, plan to create an underwater power plant</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>