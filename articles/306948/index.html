<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Sign Language Translator: Implementing Support Vector Machines on Intel Edison</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the world there are 30 million people who have problems with speech. In order to communicate with others, they use sign language. And what if the i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Sign Language Translator: Implementing Support Vector Machines on Intel Edison</h1><div class="post__text post__text-html js-mediator-article">  In the world there are 30 million people who have problems with speech.  In order to communicate with others, they use sign language.  And what if the interlocutor does not understand such a language?  How to overcome the language barrier?  Our story today is dedicated to the gesture recognition project.  The Intel Edison board accepts information from sensors attached to a special glove, processes it using the support vector machine, finds out which letter corresponds to the gesture, and sends what it has to Android to the dubbing application. <br><br> <a href="https://habrahabr.ru/company/intel/blog/306948/"><img src="https://habrastorage.org/getpro/habr/post_images/118/ccb/2b7/118ccb2b706d8ee6ab6b76fd60ad466b.jpg"></a> <br>  <i><font color="#999999">Intel Edison and Sensor Glove: The Basis of a Sign Language Recognition System</font></i> <br><a name="habracut"></a><br>  Intel Edison became the basis of our development is not accidental.  First, it has sufficient performance and RAM to implement the support vector method and process data in real time.  Secondly, Edison has a built-in Bluetooth module that is used to communicate with an Android device.  If you can not wait to get acquainted with the software part of the project, take a look <a href="">here</a> .  In the meantime, we will talk about how our system works. <br><br><h2>  <font color="#0071c5">Hardware</font> </h2><br>  On each of the five fingers of the glove, which supplies the initial data to the sign language recognition system, a flexible sensor is attached.  The electrical resistance of the sensors depends on their bending.  Thus, the more bent the finger to which the sensor corresponds, the higher the resistance. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/298/884/598/298884598cc0423661b294072ff336ca.png"></div><br>  <i><font color="#999999">Sensor whose electrical resistance depends on the bend</font></i> <br><br>  In particular, here we use Spectra Symbol‚Äôs 4.5 ‚Ä≥ unidirectional flexible sensors manufactured by Spectra Symbol. They are analog resistors that work as variable voltage dividers. <br><br>  This is what the circuit diagram for a glove board in KiCad looks like. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/061/bed/b50/061bedb5061f76f73314ebf5929cf454.png"></div><br>  <i><font color="#999999">PCB for gloves</font></i> <br><br>  Reading sensor readings in Intel XDK IoT Edition is performed using a library for working with flexible sensors. <br><br><pre><code class="hljs javascript"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> flexSensor_lib = <span class="hljs-built_in"><span class="hljs-built_in">require</span></span>(<span class="hljs-string"><span class="hljs-string">'jsupm_flex'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> Flex1 = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> flexSensor_lib.Flex(<span class="hljs-number"><span class="hljs-number">4</span></span>);</code> </pre> <br>  We need information from each of the sensors in a standardized format.  Since the spread of the values ‚Äã‚Äãof the source data is quite high, in this form they are difficult to interpret.  Preliminary data processing is that we first find out the values ‚Äã‚Äãcorresponding to the minimum and maximum bending, and then use this information in order to bring the indicators to a range of values ‚Äã‚Äãfrom 1.0 to 2.0.  Here is how this operation, for one of the sensors, looks like in the code. <br><br><pre> <code class="hljs actionscript"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> ScaleMin = <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> ScaleMax = <span class="hljs-number"><span class="hljs-number">2.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> flexOneMin = <span class="hljs-number"><span class="hljs-number">280</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> flexOneMax = <span class="hljs-number"><span class="hljs-number">400</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> flex1 = (scaleDown(Flex1.value(), flexOneMin, flexOneMax)).toFixed(<span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">scaleDown</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(flexval, flexMin, flexMax)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> new_val = (flexval - flexMin) / (flexMax - flexMin) * ((ScaleMax - ScaleMin) + ScaleMin); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> new_val; }</code> </pre> <br>  After preliminary data processing, we transfer them to the sign language recognition system.  This is a classifier based on the support vector method. <br><br><h2>  <font color="#0071c5">Implementation of the support vector method</font> </h2><br>  The support vector machine (SVM) is a learning algorithm with a teacher that analyzes the data used for classification and regression analysis.  At the initial stage of work, a set of training examples is submitted to the system input, each of which belongs to one of the n categories.  Based on these data, the learning algorithm builds a model that classifies new sets of indicators, relating them to one of the existing categories.  This is a deterministic binary linear classifier.  Based on the teaching examples, the algorithm finds the optimal hyperplane, which allows it to relate new examples to existing categories. <br><br>  In the project, we use the <a href="https://www.npmjs.com/package/node-svm">node-svm library</a> , a JavaScript implementation of one of the most popular SVM libraries, <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM</a> .  To install the library, use the following command: <br><br><pre> <code class="hljs sql">npm <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> node-svm</code> </pre> <br>  Then we copy the library folder to the project directory.  In addition, before using the node-svm library, you need to install some additional npm packages, on which this library depends: <br><br><ul><li>  Stringify object. </li><li>  Mout. </li><li>  Graceful-fs. </li><li>  Optimist. </li><li>  Osenv. </li><li>  Numeric. </li><li>  Q. </li><li>  underscore </li></ul><br>  To install packages, use the following command: <br><br><pre> <code class="hljs sql">npm <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> &lt;<span class="hljs-keyword"><span class="hljs-keyword">package</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>&gt;</code> </pre> <br>  After everything is installed, we can create a classifier and configure the kernel parameters: <br><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> clf = new svm.<span class="hljs-type"><span class="hljs-type">CSVC</span></span>({ gamma: <span class="hljs-number"><span class="hljs-number">0.25</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, normalize: <span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">reduce</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>, kFold: <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-comment"><span class="hljs-comment">//     k  });</span></span></code> </pre> <br>  Parameter C controls the relationship between SVM errors on training data and maximizing the width of the border between classes.  This parameter is used at the training stage of the model and indicates how much the outliers will be taken into account when calculating the reference vectors.  The best values ‚Äã‚Äãfor the parameters C and gamma are determined using a grid search.  Here we do not perform the reduction of the dimensionality of the data, since each of the values ‚Äã‚Äã(measurements) coming from the sensors is important in the classification of gestures. <br><br>  The next step of our work is to build a model: in training the classifier and creating a report.  The training takes a few seconds. <br><br><pre> <code class="hljs lua">svm.<span class="hljs-built_in"><span class="hljs-built_in">read</span></span>(fileName) .<span class="hljs-keyword"><span class="hljs-keyword">then</span></span>(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataset)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> clf.train(dataset) .progress(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(progress)</span></span></span></span> { console.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(<span class="hljs-string"><span class="hljs-string">'training progress: %d%'</span></span>, Math.round(progress*<span class="hljs-number"><span class="hljs-number">100</span></span>)); }); }) .spread(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, report)</span></span></span></span> { console.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(<span class="hljs-string"><span class="hljs-string">'SVM trained. \nReport:\n%s'</span></span>, so(report)); }).done(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { console.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(<span class="hljs-string"><span class="hljs-string">'Training Complete.'</span></span>); });</code> </pre> <br>  The classifier is then used to analyze real-time gestures.  A one-dimensional array is fed to the input of the system; at the output, we obtain the prediction that the gesture belongs to one or another group.  This code snippet shows how we pass sensor readings as parameters to the classifier: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">prediction</span></span> = clf.predictSync([flex1, flex2, flex3, flex4, flex5]);</code> </pre> <br>  In addition, based on the source data, you can get the probability for each class using the following command: <br><br><pre> <code class="hljs">probability= clf.predictProbabilitiesSync ([flex1, flex2, flex3, flex4, flex5]);</code> </pre> <br>  The character received during the classification is transmitted to the Android device each time a program running on Edison receives a request to read data. <br><br><h2>  <font color="#0071c5">Creating a file with training data</font> </h2><br>  The training.ds file contains 832 lines with training data.  Manually working with this amount of information is inconvenient, so we used the code below to distribute the examples into classes, that is, to assign letters of the alphabet to gestures. <br><br>  It is in the logtrainingdata.js file: <br><br><pre> <code class="hljs lua">var data = <span class="hljs-string"><span class="hljs-string">"X"</span></span> + <span class="hljs-string"><span class="hljs-string">" "</span></span> + <span class="hljs-string"><span class="hljs-string">"1:"</span></span> + f1ex1 + <span class="hljs-string"><span class="hljs-string">" "</span></span> + <span class="hljs-string"><span class="hljs-string">"2:"</span></span> + flex2 + <span class="hljs-string"><span class="hljs-string">" "</span></span> + <span class="hljs-string"><span class="hljs-string">"3:"</span></span> + flex3 + <span class="hljs-string"><span class="hljs-string">" "</span></span> + <span class="hljs-string"><span class="hljs-string">"4:"</span></span> + flex4 + <span class="hljs-string"><span class="hljs-string">" "</span></span> + <span class="hljs-string"><span class="hljs-string">"5:"</span></span> + flex5 + <span class="hljs-string"><span class="hljs-string">"\n"</span></span>; //X    ,     .     . : A=<span class="hljs-number"><span class="hljs-number">0</span></span>, B=<span class="hljs-number"><span class="hljs-number">1</span></span>,C=<span class="hljs-number"><span class="hljs-number">2</span></span>‚Ä¶ //       fs.appendFile(<span class="hljs-string"><span class="hljs-string">'training.ds'</span></span>, data, <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(err)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (err) { console.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(err) } });</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/75f/37c/0d4/75f37c0d48675b60d73141321e134d61.png"></div><br>  <i><font color="#999999">A fragment of the data file for the system learning</font></i> <br><br><h2>  <font color="#0071c5">Edison preparation and program launch</font> </h2><br>  Before an Android device can communicate with an application running on Edison, Bluetooth must be enabled on the board.  This is done like this: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">rfkill</span></span> unblock bluetooth killall bluetoothd hciconfig hci0 up</code> </pre> <br>  You can check if the Bluetooth module is working by typing: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">hcitool</span></span> dev</code> </pre> <br>  If everything goes as it should, the MAC address of the Edison Bluetooth adapter will be displayed in response. <br>  Run the main program: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">node</span></span> main.js</code> </pre> <br>  And now let's take a look at the part of the project that runs on Android. <br><br><h2>  <font color="#0071c5">Android application for dubbing recognized gestures</font> </h2><br>  The Android application used in our project uses the system's ability to convert text to speech, and thus voices the recognized gestures.  The application allows the user to customize the language, speed and tone of speech, as well as test the settings. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c9e/c3b/c48/c9ec3bc485c69460c097ea470d30a836.jpg"></div><br>  <i><font color="#999999">Application for dubbing recognized gestures</font></i> <br><br>  The main button on the application screen is Scan.  It serves to search for the Intel Edison board and to connect to it.  After connecting, the Android application accepts the data recognized by the reference vector algorithm, displays and pronounces the letter corresponding to the gesture.  This is how it all looks. <br><br><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://player.vimeo.com/video/172075355&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjzGGFlVMw1qsAsVhbDPv1GXmn6lQ" width="560" height="315" frameborder="0" title="Sign up for the Edison" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe><br><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  We talked about how, using Intel Edison, affordable software, flexible sensors and Android-smartphone, build a system that can help those who use sign language, to expand the boundaries of communication.  As you can see, on the basis of universal components, you can very quickly create a prototype of a completely new IoT device.  In perspective, this is one of those ‚Äúthings‚Äù that can make the world a better place. </div><p>Source: <a href="https://habr.com/ru/post/306948/">https://habr.com/ru/post/306948/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../306932/index.html">How we accelerated PHP projects 40 times with caching</a></li>
<li><a href="../306934/index.html">An example of the calculation of the robust controller (H-infinity control)</a></li>
<li><a href="../306940/index.html">Coroutines everywhere</a></li>
<li><a href="../306944/index.html">Machine learning for tennis prediction: part 1</a></li>
<li><a href="../306946/index.html">Lead from the fields: who and how applied qualitative methods in UX Research to develop IT products. Part 1 of 6</a></li>
<li><a href="../306950/index.html">Hackers got access to Telegram user accounts in Iran</a></li>
<li><a href="../306954/index.html">As we NoSQL in "Relation" replicated</a></li>
<li><a href="../306956/index.html">Will Twitter be the second ‚ÄúYahoo!‚Äù</a></li>
<li><a href="../306958/index.html">Another version of TFS settings for team work</a></li>
<li><a href="../306960/index.html">Throwing large volumes of documentation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>