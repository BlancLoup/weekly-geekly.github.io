<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>When the old MapReduce is better than the new Tez</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As everyone knows, the amount of data in the world is growing, it becomes more difficult to collect and process the flow of information. For this is t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>When the old MapReduce is better than the new Tez</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/9d1/42a/2da/9d142a2dac0b4d16b43f7808d23f80ec.png"><br><br>  As everyone knows, the amount of data in the world is growing, it becomes more difficult to collect and process the flow of information.  For this is the popular Hadoop solution with the idea of ‚Äã‚Äãsimplifying the development and debugging methods of multi-threaded applications using the MapReduce paradigm.  This paradigm does not always successfully cope with its tasks, and after a while there appears a ‚Äúsuperstructure‚Äù over Hadoop: <a href="https://tez.apache.org/">Apache Tez</a> with the <a href="https://ru.wikipedia.org/wiki/%25D0%259D%25D0%25B0%25D0%25BF%25D1%2580%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B0%25D1%2586%25D0%25B8%25D0%25BA%25D0%25BB%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584">DAG</a> paradigm.  The appearance of Tez adapts and HDFS-SQL-processor Hive.  But not always the new is better than the old.  In most cases, HiveOnTez is much faster than HiveOnMapReduce, but some pitfalls can greatly affect the performance of your solution.  Here I want to tell you what nuances I encountered.  Hope this helps you speed up ETL or another Hadoop UseCase. <br><a name="habracut"></a><br><h1>  MapReduce, Tez and Hive </h1><br>  As I said earlier, there is more and more data in the world.  And for their storage and processing, they come up with more and more tricky solutions, among them Hadoop.  To make the processing of data stored on HDFS easy for even an ordinary analyst, there are several SQL add-ins over Hadoop.  The oldest and ‚Äúsimplest‚Äù of them is Hive.  The essence of Hive is this: we have data in some distinct column-store format, we enter information about them in metadata, we write standard SQL with a number of restrictions, and it generates a chain of MapReduce-jobs that solve our problem.  Nice, comfortable, but slow.  For example, here‚Äôs a simple query: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> t1.column1, t2.column2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> table1 t1 <span class="hljs-keyword"><span class="hljs-keyword">inner</span></span> <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> table2 t2 <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> t1.column1 = t2.column1 <span class="hljs-keyword"><span class="hljs-keyword">union</span></span> <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> t3.column1, t4.column2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> table3 t3 <span class="hljs-keyword"><span class="hljs-keyword">inner</span></span> <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> table4 t4 <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> t3.column1 = t4.column1 <span class="hljs-keyword"><span class="hljs-keyword">order</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> column1;</code> </pre> <br>  This query spawns four jobs: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  table1 inner join table2; </li><li>  table3 inner join table4; </li><li>  union; </li><li>  sort. </li></ul><br><img src="https://habrastorage.org/files/1aa/41c/fd5/1aa41cfd5e1e4a33844aaeed7fcb7964.png"><br><br>  Steps are executed sequentially, and each of them ends with writing data to HDFS.  It looks quite suboptimal.  For example, steps 1 and 2 could be performed in parallel.  And there are also situations where it is reasonable to use the same Mapper for several steps, and then apply several Reducer types to the results of these Mappers.  But the concept of MapReduce within the framework of a single job does not allow to do so.  To solve this problem, Apache Tez appears fairly quickly with the concept of DAG.  The essence of the DAG is that instead of a pair of Mapper-Reducer (+ epsilon) we build a non-cyclic directed graph, each vertex of which is a Mapper.Class or Reduser.Class, and the edges mean data flows / execution order.  In addition to DAG, Tez provided several more bonuses: an accelerated start-up of jobs (you can send DAG-jobs via an already running Tez-Engine), the ability to keep resources in the memory of the node between steps, independently start parallelization, etc. Naturally, together with Tez came out and the corresponding add-on over Hive.  With this add-on, our request will turn into a DAG-job of approximately the following structure: <br><br><ol><li>  Mapper reads table1. </li><li>  Mapper reads table2 and joins it with the result of step 1. </li><li>  Mapper reads table3 and filters column1 IS NOT NULL. </li><li>  Mapper reads table4 and filters column1 IS NOT NULL. </li><li>  Reducer joins the results of steps 3 and 4. </li><li>  Reducer doing union. </li><li>  Reducer Group By and Sort. </li><li>  Collects the result. </li></ol><br><img src="https://habrastorage.org/files/282/2aa/81d/2822aa81d1b54a1f914e2bd24bc3e791.png"><br><br>  In fact, steps 1 and 2 are the first join, and 2, 3 and 4 are the second join (I specially selected tables of different sizes so that the joines were processed differently).  In this case, two blocks from each other are independent and can be executed in parallel.  This is very cool.  Tez really gives a significant increase in the speed of processing complex requests.  But sometimes Tez can be worse than MapReduce, and therefore, before being sent to production, it is worth trying a query with both <code>set hive.execution.engine=tez</code> , and <code>set hive.execution.engine=mr</code> . <br><br><h1>  So what is Tez? </h1><br>  All you need to know about Tez: it changes the MapReduce logic to DAG logic (directed by acyclic graph - directed acyclic graph), allowing you to perform several different processes in the same DataFlow, be it Mapper or Reducer.  The main thing is that its input data is ready.  You can store data locally on the nodes between steps, and sometimes just in the node's RAM, without resorting to disk operations.  You can optimize the number and location of Mappers and Reducers in order to minimize data transfer over the Network, even taking into account multi-step calculations, reuse containers that have already worked in neighboring processes within the same Tez-Job, and adjust parallel execution for statistics, collected in the previous step.  In addition, the engine allows the end user to create DAG tasks with the same simplicity as MapReduce, while he himself will be engaged in resources, restarts and DAG management on the cluster.  Tez is very mobile, adding support for Tez does not break processes already running, and testing the new version is possible locally "on the client side" when the old version of Tez will work in all cluster tasks.  Last but not least: note that Tez can run on a cluster as a service and work in the "background" mode, which allows it to send tasks for execution much faster than it happens when you start MapReduce.  If you have not tried Tez and you still have doubts, then look at the speed comparison published in <a href="http://www.slideshare.net/Hadoop_Summit/w-1205phall1saha">the</a> HortonWorks <a href="http://www.slideshare.net/Hadoop_Summit/w-1205phall1saha">presentation</a> : <br><br><img src="https://habrastorage.org/files/3d7/c8e/77b/3d7c8e77ba094947aafeae9b39e67e48.png"><br><br>  And paired with Hive: <br><br><img src="https://habrastorage.org/files/91a/1bc/129/91a1bc129a934a559274e907f3d944cb.png"><br><br>  But with all this beauty of graphics and descriptions in HiveOnTez there are problems. <br><br><h1>  Tez is less resistant to uneven data distribution than MapReduce </h1><br>  The first and biggest problem is the difference between creating a DAG-job and MapReduce-job.  They have one principle: the number of Mappers and Reducers is calculated at the moment of starting the job.  Only when a request is executed by a chain of MapReduce-jobs, does Hadoop calculate the required number of tasks based on the result of the previous steps and the collected analytics by source, and in the case of DAG-job this happens before all steps are calculated, only on the basis of analytics. <br><br>  Let me explain by example.  Somewhere in the middle of a query as we perform subqueries, we have two tables.  According to statistics estimates, each has n lines and k unique join-key values.  At the output we expect approximately n * k lines.  And let's say that this quantity fits well into one container, and Tez will select one Reducer for the next step (say, sorting).  And this number Reducer'ov already in the process of execution will not change regardless of anything.  Now suppose that in fact these tables have a very bad skew: for one value there is n - k + 1 row, and all the rest - for one row.  Thus, at the output we get n ^ 2 + k ^ 2 - 2kn - k + 2n rows.  That is, (n + 2 - 2k) / k + (k - 1) / n is more than n / k twice.  And already such amount one Reducer will carry out eternity.  And in the case of MapReduce, having received n ^ 2 + k ^ 2 - 2kn - k + 2n at the output of this step, Hadoop will objectively evaluate its strength and produce the necessary number of Mappers and Reduceres.  As a result, with MapReduce, everything will work much faster. <br><br>  Dry calculations may seem far-fetched, but in reality this situation is real.  And if it did not happen, then consider yourself lucky.  I came across a similar effect from Tez-DAG when using the lateral view in complex queries or custom Mappers. <br><br><h1>  Features tuning Tez </h1><br>  Ironically, the last important feature of Tez I know that can harm is related to its strength - DAG.  Most often, a cluster is not just a repository of information.  It is also the system in which the data is processed, and it is important that this part of the cluster is not affected by the rest of the activity.  Since nodes are a resource, usually the number of your containers is not unlimited.  So, when you run a job, it is better not to clog all containers, so as not to slow down the regular processes.  And then the DAG can give you a pig.  DAG is required (on average in the ward) fewer containers due to their reuse, smoother loading, etc. But when there are many fast steps, containers begin to multiply exponentially.  The first Mappers have not yet finalized, but the data is already being distributed by other Mappers, containers are allocated for all this, and - boom!  Your cluster is crammed into the ceiling, no one else can run a single job.  There are not enough resources, and you see how the numbers on the progress bar are slowly changing.  MapReduce is free of this effect because of its consistency, but you pay for it, as always, with speed. <br><br>  We have long known how to deal with the fact that the standard MapReduce takes too many containers.  Adjust the parameters: <br><br><ul><li>  <code>mapreduce.input.fileinputformat.split.maxsize</code> : decreasing - increasing the number of Mappers; </li><li>  <code>mapreduce.input.fileinputformat.split.minsize</code> : increasing - decreasing the number of Mappers; </li><li>  <code>mapreduce.input.fileinputformat.split.minsize.per.node</code> , <code>mapreduce.input.fileinputformat.split.minsize.per.rack</code> : more fine-tuning to control local (in the sense of a node or rack) partitions; </li><li>  <code>hive.exec.reducers.bytes.per.reducer</code> : increasing - reducing the number of Reducer'ov; </li><li>  <code>mapred.tasktracker.reduce.tasks.maximum</code> : set the maximum number of Reducer's; </li><li>  <code>mapred.reduce.tasks</code> : set a specific number of Reducer'ov. </li></ul><br>  Caution!  In a DAG, all reduce-steps will have as many processes as you specify here!  But the Tez parameters are more cunning, and the parameters that we set for MapReduce do not always affect it.  First, Tez is very sensitive to <code>hive.tez.container.size</code> , and the Internet advises taking values ‚Äã‚Äãbetween <code>yarn.scheduler.minimum-allocation-mb</code> and <code>yarn.scheduler.maximum-allocation-mb</code> .  Secondly, take a look at the hold options for an unused container: <br><br><ul><li>  <code>tez.am.container.ide.release-timeout-max.millis</code> ; </li><li>  <code>tez.am.container.ide.release-timeout-min.millis</code> . </li></ul><br>  The <code>tez.am.container.reuse.enabled</code> option activates or deactivates the reuse of containers.  If it is disabled, the previous two parameters do not work.  And third, look at the grouping options: <br><br><ul><li>  <code>tez.grouping.split-waves</code> ; </li><li>  <code>tez.grouping.max-size</code> ; </li><li>  <code>tez.grouping.min-size</code> . </li></ul><br>  The fact is that for the sake of parallelizing the reading of external data, Tez changed the process of forming tasks: first Tez estimates how many waves (w) can be run on the cluster, then this number is multiplied by the parameter <code>tez.grouping.split-waves</code> , and the product (N) is divided on the number of standard splits per task.  If the result of actions is between <code>tez.grouping.min-size</code> and <code>tez.grouping.max-size</code> , then everything is fine and the task starts in N tasks.  If not, the number adapts to the frame.  Documentation on Tez advises ‚Äúonly as an experiment‚Äù to set the parameter <code>tez.grouping.split-count</code> , which cancels all the above logic and groups splits into the number of groups specified in the parameter.  But I try not to use this feature, it does not give flexibility to Tez and Hadoop as a whole for optimization for specific input data. <br><br><h1>  Tez nuances </h1><br>  In addition to major problems, Tez is not free from small flaws.  For example, if you use http Hadoop ResourceManager, then you will not see in it how many Tez-job containers are occupied, and even more so in what state its Mappers and Reducer are.  To monitor the status of the cluster, I use this small python script: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading result = [] e = threading.Lock() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getContainers</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(appel)</span></span></span><span class="hljs-function">:</span></span> attemptfile = os.popen(<span class="hljs-string"><span class="hljs-string">"yarn applicationattempt -list "</span></span> + appel[<span class="hljs-number"><span class="hljs-number">0</span></span>]) attemptlines = attemptfile.readlines() attemptfile.close() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> attemptlines[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> attemptlines[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> attempt <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> attemptlines: splt = attempt.split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( splt[<span class="hljs-number"><span class="hljs-number">1</span></span>].strip() == <span class="hljs-string"><span class="hljs-string">"RUNNING"</span></span> ): containerfile = os.popen(<span class="hljs-string"><span class="hljs-string">"yarn container -list "</span></span> + splt[<span class="hljs-number"><span class="hljs-number">0</span></span>] ) containerlines = containerfile.readlines() containerfile.close() appel[<span class="hljs-number"><span class="hljs-number">2</span></span>] += int( containerlines[<span class="hljs-number"><span class="hljs-number">0</span></span>].split(<span class="hljs-string"><span class="hljs-string">"Total number of containers :"</span></span>)[<span class="hljs-number"><span class="hljs-number">1</span></span>].strip() ) e.acquire() result.append(appel) e.release() appfile = os.popen(<span class="hljs-string"><span class="hljs-string">"yarn application -list -appStates RUNNING"</span></span>) applines = appfile.read() appfile.close() apps = applines.split(<span class="hljs-string"><span class="hljs-string">'application_'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> apps[<span class="hljs-number"><span class="hljs-number">0</span></span>] appsparams = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> app <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> apps: splt = app.split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) appsparams.append([<span class="hljs-string"><span class="hljs-string">'application_'</span></span> + splt[<span class="hljs-number"><span class="hljs-number">0</span></span>],splt[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-number"><span class="hljs-number">0</span></span>]) cnt = <span class="hljs-number"><span class="hljs-number">0</span></span> threads = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> app <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> appsparams: threads.append(threading.Thread(target=getContainers, args=(app,))) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> thread <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads: thread.start() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> thread <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads: thread.join() result.sort( key=<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x:x[<span class="hljs-number"><span class="hljs-number">2</span></span>] ) total = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> app <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result: print(app[<span class="hljs-number"><span class="hljs-number">0</span></span>].strip() + <span class="hljs-string"><span class="hljs-string">'\t'</span></span> + app[<span class="hljs-number"><span class="hljs-number">1</span></span>].strip() + <span class="hljs-string"><span class="hljs-string">'\t'</span></span> + str(app[<span class="hljs-number"><span class="hljs-number">2</span></span>]) ) total += app[<span class="hljs-number"><span class="hljs-number">2</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Total:"</span></span>,total)</code> </pre><br>  Despite the assurances of HortonWorks, our practice shows that when in Hive you make a simple SELECT smth FROM table WHERE smth, then most often MapReduce will work faster, though not by much.  In addition, at the beginning of the article I deceived you a little: paralleling in HiveOnMapReduce is possible, but not so intellectual.  It is enough to make <code>set hive.exec.parallel=true</code> and configure <code>set hive.exec.parallel.thread.number=</code> ... - and independent steps (pairs Mapper + Reducer) will be executed in parallel.  Yes, it is not possible that at the output of one Mapper several Reducer or next Mappers will be launched.  Yes, parallelization is much more primitive, but also speeds up work. <br><br>  Another interesting feature of Tez is that it runs its engine on a cluster and keeps it turned on for a while.  On the one hand, it really speeds up the work, since the task runs on the nodes much faster.  But on the other hand, an unexpected minus: important processes in this mode cannot be started, because the TEZ-engine eventually generates too many classes and drops from GC-overflow.  And it happens like this: you launched <code>nohup hive -f ....hql &gt; hive.log &amp;</code> for the night <code>nohup hive -f ....hql &gt; hive.log &amp;</code> , came in the morning, but it fell somewhere in the middle, the hive was completed, the temporary tables went away, and everything must be considered anew.  Unpleasant <br><br>  Adds to the piggy bank of minor problems that the good old MapReduce has already entered a stable release, and TEZ, despite its popularity and progressiveness, is still in version 0.8.4, and bugs in it can occur at any step.  The most terrible bug for me is the deletion of information, but I have not seen anything like that.  But with the incorrect calculation on Tez we came across, and MapReduce considers it correct.  For example, my colleague used two tables ‚Äî table1 and table2, which have a unique EntityId field.  I made a request through Tez: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> table1.EntityId, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> table1 <span class="hljs-keyword"><span class="hljs-keyword">left</span></span> <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> table2 <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> table1.EntityId = table2.EntityId <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> EntityId <span class="hljs-keyword"><span class="hljs-keyword">having</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre><br>  And I got some lines on the output!  Although MapReduce expectedly returned an empty result.  There is a <a href="https://issues.apache.org/jira/browse/HIVE-9743">bugreport</a> about a similar problem. <br><br><h1>  Conclusion </h1><br>  Tez is an unconditional good, which in most cases makes life easier, allows you to write more complex queries to Hive and expect a quick response to them.  But, like any good, it requires a cautious approach, caution and knowledge of some nuances.  And as a result, sometimes using the old, proven, reliable MapReduce is better than using Tez.  I was very surprised that I could not find a single article (neither in RuNet, nor in English) about the minuses of HiveOnTez, and decided to fill this gap.  I hope that the information will be useful to someone.  Thank!  Good luck to everyone and bye! </div><p>Source: <a href="https://habr.com/ru/post/312194/">https://habr.com/ru/post/312194/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312182/index.html">Selection of podcasts and video sites for content marketing, interface design and usability</a></li>
<li><a href="../312184/index.html">Hide text from prying eyes (Scala example)</a></li>
<li><a href="../312186/index.html">Call center for a small company: Symbiosis amoCRM and Hive</a></li>
<li><a href="../312188/index.html">Usage Chart in Software Development</a></li>
<li><a href="../312190/index.html">Apply the Check Knowledge Module (CKM) in projects based on Oracle Data Integrator</a></li>
<li><a href="../312196/index.html">@ActivityScope with Dagger 2</a></li>
<li><a href="../312198/index.html">Visual Studio "15" Preview 5</a></li>
<li><a href="../312200/index.html">The problem of the Internet - in low bandwidth</a></li>
<li><a href="../312202/index.html">Multiple PHP versions under one Apache on Windows (v2)</a></li>
<li><a href="../312206/index.html">Preparing to migrate vCenter Server to vSphere 6.0 Update 2m. Part 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>