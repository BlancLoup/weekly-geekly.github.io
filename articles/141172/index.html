<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>OpenMP Optimization</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The gradual development of the project went on as usual. 

 For a part of the funds received under the grant, the personal computer equipment park was...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>OpenMP Optimization</h1><div class="post__text post__text-html js-mediator-article">  The gradual development of the project went on as usual. <br><br>  For a part of the funds received under the grant, the personal computer equipment park was updated.  As a result, the calculations are now carried out not on a long-suffering laptop, but on a perfectly acceptable machine with a pseudo-eight-core Intel Core i7-2600 and 8 Gb of RAM on board.  And the development is done under Visual Studio 2005 (obtained through the DreamSpark program) with the connected trial version of the Intel FORTRAN Compiler 12 / Intel Parallel Studio XE 2011 (it all runs under Win 7).  OpenMP is used as a parallel API. <br><br>  In view of the obviously noticeable growth of available capacities, new negative features of the algorithm written earlier were found.  First of all, since March, a deep optimization of the computational part of the code was carried out, which made it possible to gain about 70% in performance.  Such an increase was ensured primarily by the elimination of division operations, as well as an increase in the number of predictable variables. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>upd: The</b> post, in general, is about the gray working everyday life, and does not contain any discoveries in itself. <br><br><a name="habracut"></a><h4>  Minor mischief </h4><br>  The program was regularly used and produced good results, until one day it was decided to check how well the parallelization was performed.  And, rather, even expectedly, than surprisingly, execution in one thread turned out to be on average twice as fast as multi-threaded launches, regardless of the number of threads. <br><br>  The answer, in general, lies on the surface.  From the mathematical point of view, the algorithm was optimized to such an extent that its bottleneck was the exchange of data between individual streams, which was confirmed even by a brief analysis in the Intel Vtune Amplifier.  The greatest time required to initialize the threads and their local variables, as well as access to common variables and arrays.  A significant role in the visibility of the dirty trick was played by the fact that until now a rough computational grid was used, only 3x200 spatial nodes (a kind of imitation of a one-dimensional problem), and the computation time was relatively small. <br><br><h4>  Minor fixes </h4><br>  What was done for optimization? <br><br>  First of all, the directives and the separation of variables into classes are corrected.  In particular, the main working arrays in which the values ‚Äã‚Äãthat are the purpose of the calculation are stored from <code>SHARED</code> were turned into <code>THREADPRIVATE</code> by setting the <code>COMMON</code> attribute (which simultaneously optimized their placement in memory) and <code>COPYIN</code> directives.  The precomputed variables were left as <code>SHARED</code> , since  the application of <code>FIRSTPRIVATE</code> or <code>COPYIN</code> to them not only did not give a noticeable effect, but also worsened the results.  In total, the directive before the main work cycles took something like this: <br><pre> <code class="diff hljs"><span class="hljs-addition"><span class="hljs-addition">!$OMP PARALLEL DO NUM_THREADS(Threads_number) SCHEDULE(DYNAMIC) &amp; !$OMP PRIVATE(...) &amp; !$OMP COPYIN(...) &amp; !$OMP DEFAULT(SHARED)</span></span></code> </pre><br>  Here lists of variables are omitted, because  with them the code takes about a dozen lines. <br><br>  In total, there are nine such places in the code.  Nine bottlenecks through which the program, quoting M. Evdokimov, "Squeaks, but climbs." <br><br>  Throwing different variables back and forth lasted a couple of evenings, but the optimality of work could not be considered.  The launch on a full processor load showed that on average only 2.1 - 2.3 threads simultaneously exist.  Processor time was spent regularly in eight times.  For clarity, histograms from VTune Amplifier for 3x200 grid: <br><img src="https://habrastorage.org/storage2/6d4/28d/c40/6d428dc401c4d18c09894d7fd7c07251.jpg" alt="3x200: 2.237"><br>  For 100x100: <br><img src="https://habrastorage.org/storage2/fd8/048/2f2/fd80482f2c2578b43dd0d77ea5d5334c.jpg" alt="100x100: 4.717"><br>  For 200x200: <br><img src="https://habrastorage.org/storage2/134/eb0/cbd/134eb0cbd5c5d0443d0c54b286ea9fa1.jpg" alt="200x200: 5.938"><br><br>  Obviously, as the share of computations increases, the results improve, but there is no desire to call it such a high efficiency. <br><br>  Applying forced sleep deprivation to streams by increasing the KMP_BLOCKTIME value from 200 ms to 10 s just a little helped in the same way. <br><br><h4>  Nonsense is rarely small </h4><br>  Unexpectedly, a stern look was cast on the "space-time" structure formed by the flows in the algorithm.  And everything immediately fell into place.  The weak point was the directive <br><pre> <code class="diff hljs"><span class="hljs-addition"><span class="hljs-addition">!$OMP PARALLEL DO NUM_THREADS(Threads_number) SCHEDULE(DYNAMIC)</span></span></code> </pre><br>  The <code>PARALLEL</code> keyword is responsible, as is well known, beyond the boundaries of the parallel and sequential code area.  Upon its achievement, the creation of new threads, the redistribution of local variables in their memory and other procedures that require a considerable amount of time occur.  There were nine such places, as already mentioned.  Accordingly, nine times the streams were created and destroyed, and at the same time between them in some places there were not even consecutive sections.  Schematically, it can be represented on this picture: <br><img src="https://habrastorage.org/storage2/6ff/d79/3ef/6ffd793eff77d6c8742a975356f44a85.jpg" alt="no optimization"><br><br>  A complete reorganization of the structure of the parallel part of the program was carried out.  Now the flow diagram looks like this: <br><img src="https://habrastorage.org/storage2/c02/5fb/74a/c025fb74a96aabb20d7a28e687185e19.jpg" alt="optimized"><br>  Vertical dashed lines conventionally show the boundaries of parallel loops, and towards the end, the <code>SINGLE</code> directive is used ‚Äî it writes the calculation results to a disk, for which the work of all streams, except for one, is suspended.  It is at least difficult to parallelize it, although there is an idea to record in one stream and perform a further loop in the others, since  He does not depend on writing to disk, or rearrange them in places.  But these are details that have nothing to do with the case. <br><br>  And in the source text the directive structure looks like this: <br><pre> <code class="diff hljs">Time_cycle: do n = 0, Nt, 1 !$OMP PARALLEL NUM_THREADS(Threads_number) &amp; !$OMP PRIVATE(...) &amp; !$OMP COPYIN(...) &amp; !$OMP DEFAULT(SHARED) !$OMP DO SCHEDULE(DYNAMIC) ... !$OMP END DO ...  7    !$OMP SINGLE ...    !$OMP END SINGLE !$OMP DO SCHEDULE(DYNAMIC) ... !$OMP END DO !$OMP END PARALLEL enddo Tyme_Cycle</code> </pre><br>  That is, the whole cycle body in time (the program makes a direct numerical simulation of the evolution of the hydrodynamic system) is now in a parallel area, the threads are created at the beginning of the iteration and are destroyed only when it is completed, and not resurrected repeatedly.  It is no longer possible to wrap in a parallel area and a time cycle, since each iteration of it, of course, is completely dependent on the previous one ( <i>please correct it, if not so - my logic here gives a certain failure</i> ). <br><br>  The final improvement aimed at speeding up work was disabling the barrier synchronization between the flows in some cycles where it would not affect subsequent calculations. <br><br>  As a result, the time of really parallel code execution seems to be increasing.  On the 3x200 grid, the VTune node represents this result: <br><img src="https://habrastorage.org/storage2/c1b/0b7/6f0/c1b0b76f0382780860225a4133ae155d.jpg" alt="3x200: 3.041"><br><br>  On the grid 100x100 - this: <br><img src="https://habrastorage.org/storage2/0c9/801/a64/0c9801a64fc6d58eb242944262c90bdb.jpg" alt="100x100: 4.722"><br><br>  Finally, at 200x200 - this: <br><img src="https://habrastorage.org/storage2/2a1/cff/4bf/2a1cff4bf21b6d0a3c963b8a1e18fbc6.jpg" alt="200x200: 5.962"><br><br>  Thus, we confirm the long-standing truth that on large grids, when there are really many calculations, they take up most of the time and parallelism is effective.  On small grids, it is required to optimize the exchange between processes, otherwise the results are not joyful.  And despite this, the successive stages occupy a predominant part of the working time. <br><br>  The question arises, is it worth the work done to optimize the spent time and effort?  Check the actual speed of the program.  The launch was carried out on the same three different grids with eight streams, and the time to a certain reference point was measured.  The control points are different in all cases, therefore, it will be incorrect to compare the absolute values ‚Äã‚Äãbetween different grids - 1 million iterations for 3 x 200, 500 thousand for 100 x 100 and 200 thousand for 200 x 200 nodes.  The second line in parentheses shows the relative difference in the execution time of the two program options. <br><table><tbody><tr><th>  Mesh size </th><th>  Lead time with </th></tr><tr><td>  3 x 200, before optimization </td><td>  94.4 </td></tr><tr><td>  3 x 200 optimized </td><td>  70.0 (-26%) </td></tr><tr><td>  100 x 100, before optimization </td><td>  352 </td></tr><tr><td>  100 x 100, optimized </td><td>  285 (-19%) </td></tr><tr><td>  200 x 200, before optimization </td><td>  543 </td></tr><tr><td>  200 x 200 optimized </td><td>  436 (-19%) </td></tr></tbody></table><br>  It is obvious that the optimization carried out provided a good performance boost. <br><br>  At the same time, we compare the quality of parallelization, determining in the same way the performance gain with increasing number of threads.  Immediately it should be noted that on one stream the calculations may turn out to be faster than on two or three, due to, firstly, the lack of the need to exchange data with neighbors, and secondly, the work of TurboBoost, raising the clock frequency by 400 MHz.  Also recall that the physical cores of the processor mentioned at the beginning are only 4, and the acceleration on 8 threads is the result of Hyper-Threading. <br><br>  Grid 3x200, 1 million iterations: <br><table><tbody><tr><th>  The number of threads before optimization </th><th>  Lead time with </th></tr><tr><td>  one </td><td>  80.9 </td></tr><tr><td>  2 </td><td>  88.7 </td></tr><tr><td>  3 </td><td>  84.4 </td></tr><tr><td>  four </td><td>  83.7 </td></tr><tr><td>  eight </td><td>  94.4 </td></tr><tr><th>  The number of threads after optimization </th><th>  Lead time with </th></tr><tr><td>  one </td><td>  87.9 </td></tr><tr><td>  2 </td><td>  145 </td></tr><tr><td>  3 </td><td>  113 </td></tr><tr><td>  four </td><td>  97.8 </td></tr><tr><td>  eight </td><td>  70.0 </td></tr></tbody></table><br>  Grid 100x100, 500 thousand iterations: <br><table><tbody><tr><th>  The number of threads before optimization </th><th>  Lead time with </th></tr><tr><td>  one </td><td>  918 </td></tr><tr><td>  2 </td><td>  736 </td></tr><tr><td>  3 </td><td>  536 </td></tr><tr><td>  four </td><td>  431 </td></tr><tr><td>  eight </td><td>  352 </td></tr><tr><th>  The number of threads after optimization </th><th>  Lead time with </th></tr><tr><td>  one </td><td>  845 </td></tr><tr><td>  2 </td><td>  528 </td></tr><tr><td>  3 </td><td>  434 </td></tr><tr><td>  four </td><td>  381 </td></tr><tr><td>  eight </td><td>  285 </td></tr></tbody></table><br>  If on a small number of nodes the results are ambiguous, to put it mildly, although evidencing in favor of multithreading and optimization success, then on a large number of them - everything is again evident. <br><br>  Findings?  The main conclusion is the same - watch how the flows in the program are born and die.  Extending their life may be helpful. <br><br>  The implemented rearranging of the space-time structure of the streams is described, in particular, here: <br>  <a href="http://software.intel.com/ru-ru/articles/more-work-sharing-with-openmp/">Efficient load balancing between threads using OpenMP *</a> .  That's just it was read after coming up with a solution.  <i>Would save a couple of days, eh.</i> </div><p>Source: <a href="https://habr.com/ru/post/141172/">https://habr.com/ru/post/141172/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../141162/index.html">Sovereign: algorithm</a></li>
<li><a href="../141164/index.html">Lightcube (photobox, lightbox) do-it-yourself for 300r</a></li>
<li><a href="../141165/index.html">Testing ExtJS / Sencha components and applications using the PhantomJS engine</a></li>
<li><a href="../141166/index.html">Google Chrome: AdBlock now shows you cats instead of ads!</a></li>
<li><a href="../141171/index.html">Since the first of April!</a></li>
<li><a href="../141173/index.html">Childish poems demand justice</a></li>
<li><a href="../141174/index.html">The world's slowest Linux computer</a></li>
<li><a href="../141175/index.html">Digium purchased by Microsoft, Asterisk will not be free and will work under Windows</a></li>
<li><a href="../141176/index.html">New Google Chrome feature for parallel multi-task solving.</a></li>
<li><a href="../141178/index.html">Youtube Collections - all Youtube videos on disks!</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>