<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Refinement ffmpeg video player</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the previous article, we reviewed the main components of ffmpeg and built on their basis the simplest player to play video at decoding speed, witho...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Refinement ffmpeg video player</h1><div class="post__text post__text-html js-mediator-article">  In the <a href="http://habrahabr.ru/blogs/video/137793/">previous</a> article, we reviewed the main components of ffmpeg and built on their basis the simplest player to play video at decoding speed, without synchronization. <br>  In this article we will look at how to add sound reproduction and deal with synchronization. <br><a name="habracut"></a><br><h4>  Introduction </h4><br>  The basis of most applications and frameworks for working with multimedia is the graph.  The nodes of the graph are objects that perform a specific task.  For example, consider this graph video player. <br><div style="text-align:center;"><img src="https://habrastorage.org/storage2/c91/75d/876/c9175d876e109a9133bd34a25c780749.png"></div><br>  The work begins with the <b>Read data</b> block, in which in our case the file is read.  In the more general case, this is the receipt of data via a network, or from a hardware source. <br>  <b>Demultiplexing splits</b> the incoming stream into several outgoing streams (for example, audio and video).  Demultiplexing works at the data container level, that is, at this stage it does not matter what codec a particular stream is encoded.  Examples of containers: AVI, MPEG-TS, MP4, FLV. <br>  After demultiplexing, the received streams are <b>decoded in video</b> <b>decoding</b> and <b>audio decoding</b> blocks.  At the output of the decoder will be data in standard formats - YUV or RGB frames for video and PCM data for audio.  Decoding is usually done in separate streams.  <b>Displaying video</b> displays the video on the screen, and <b>Playing Audio</b> plays the resulting audio stream. <br><br><h4>  Implementation </h4><br>  For our player, we will use a similar implementation.  In a separate stream, we will read the file and demultiplex it into streams, in the other two streams we will decode video and audio.  Then, using SDL, display a picture on the screen and play audio.  In the main application thread, we will process the SDL events. <br><br>  The code for this example was quite large, I decided not to give it here in its entirety.  I will show only the fundamental points.  All code can be viewed at the link at the end of the article. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      First of all, we merge all the main variables into one common context: <br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MainContext</span></span></span><span class="hljs-class"> {</span></span> AVFormatContext *format_context; <span class="hljs-comment"><span class="hljs-comment">// Streams Stream video_stream; Stream audio_stream; // Queues PacketQueue videoq; PacketQueue audioq; /* ... */ } MainContext;</span></span></code> </pre> <br>  This context will be passed to all streams.  <i>video_stream</i> and <i>audio_stream</i> contain information and video and audio streams, respectively.  <i>videoq</i> and <i>audioq</i> are the queues in which the demultiplexing thread will add read packets.  Given these changes, the <i>demuxing</i> code ( <i>demux_thread</i> ) will be quite simple and will take the following form: <br><pre> <code class="cpp hljs">AVPacket packet; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (av_read_frame(main_context-&gt;format_context, &amp;packet) &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (packet.stream_index == video_stream_index) { <span class="hljs-comment"><span class="hljs-comment">// Video packet packet_queue_put(&amp;main_context-&gt;videoq, &amp;packet); } else if (packet.stream_index == audio_stream_index) { // Audio packet packet_queue_put(&amp;main_context-&gt;audioq, &amp;packet); } else { av_free_packet(&amp;packet); } }</span></span></code> </pre><br>  Here we read the next packet from the file, and, depending on the type of stream, we put it in the appropriate queue for decoding.  This is the main function of the de-multiplexing flow, no more actions are performed in it. <br>  Now consider the more complex video and audio decoding streams. <br><br><h4>  Video playback </h4><br>  The process of decoding and displaying video was discussed in a previous article.  The main code remained unchanged, but was divided into two parts - video decoding performed in a separate stream ( <i>video_decode_thread</i> ) and display in a window ( <i>video_refresh_timer</i> ), performed in the main stream by timer.  This separation must be done to facilitate the implementation of synchronization, which we will consider in the second part of the article. <br><br>  Image update is done on a timer, rather than in a separate stream, since SDL <a href="http://www.libsdl.org/docs/html/thread.html">requires</a> that video operations be performed on the main application stream.  Similarly, you cannot create overlay from an arbitrary stream.  This limitation can be circumvented, for example, using SDL events and a condition variable.  But we will not do it.  We confine ourselves to one overlay, which we will create before the start of decoding. <br><br><h4>  Audio playback </h4><br>  Computer sound is a continuous stream of <i>samples</i> .  Each sample is the value of the waveform.  Sounds are recorded at a specific <i>sampling rate</i> , and must be played at the same frequency.  <i>The sampling rate</i> is the number of samples per second.  For example, 44100 samples per second - the audio CD sampling rate.  In addition, audio can contain multiple channels.  For example, for stereo samples will come two at a time.  When retrieving data from a file, it is not known how many samples will be received, but FFmpeg will not give incomplete samples.  This also means that FFmpeg will not share stereo samples. <br><br>  The first step is to configure the SDL to output audio.  In the initialization function, you must add the flag <i>SDL_INIT_AUDIO</i> .  Then fill the <i>SDL_AudioSpec</i> structure and pass it to the <i>SDL_OpenAudio</i> function: <br><pre> <code class="cpp hljs">SDL_AudioSpec wanted_spec, spec; <span class="hljs-comment"><span class="hljs-comment">// Set audio settings from codec info wanted_spec.freq = codec_context-&gt;sample_rate; wanted_spec.format = AUDIO_S16SYS; wanted_spec.channels = codec_context-&gt;channels; wanted_spec.silence = 0; wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE; wanted_spec.callback = audio_callback; wanted_spec.userdata = main_context; if (SDL_OpenAudio(&amp;wanted_spec, &amp;spec) &lt; 0) { fprintf(stderr, "SDL: %s\n", SDL_GetError()); return -1; } SDL_PauseAudio(0);</span></span></code> </pre><br>  The SDL uses the callback function to output audio. <br>  The structure has the following parameters: <br><ul><li>  <i>freq</i> : sample rate. </li><li>  <i>format</i> : The format of the transmitted data.  The symbol ‚ÄúS‚Äù in ‚ÄúAUDIO_S16SYS‚Äù means that the data will be signed, 16 - the size of the sample is 16 bits, ‚ÄúSYS‚Äù - the system byte order is used.  It is in this format that FFmpeg returns the decoded data. </li><li>  <i>Channels</i> : The number of audio channels. </li><li>  <i>silence</i> : Meaning "silence."  For character data, 0 is usually used. </li><li>  <i>samples</i> : The size of the SDL audio buffer.  Normal values ‚Äã‚Äãare values ‚Äã‚Äãfrom 512 to 8192 bytes.  We will use 1024. </li><li>  <i>callback</i> : callback function to fill the buffer with data. </li><li>  <i>userdata</i> : User data passed to the callback function.  We use our main context here. </li></ul><br>  Calling <i>SDL_PauseAudio (0)</i> starts the audio playback.  If there is no data in the buffer, ‚Äúsilence‚Äù will be played. <br><br><h5>  Audio decoding </h5><br>  As you probably remember, during demultiplexing, we folded the read packets into a separate <i>audioq queue</i> .  The main purpose of the <i>audio_decode_thread</i> decoding <i>function</i> is to receive a packet from a queue, decode it and put it into another buffer, which will then be read in the function we specified in <i>SDL_OpenAudio</i> . <br><br>  We will use a <a href="http://en.wikipedia.org/wiki/Circular_buffer">ring buffer</a> as such a <a href="http://en.wikipedia.org/wiki/Circular_buffer">buffer</a> .  Prototypes of the main functions: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ring_buffer_write</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(RingBuffer* rb, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">* buffer, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> len, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> block)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ring_buffer_read</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(RingBuffer* rb, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">* buffer, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> len, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> block)</span></span></span></span>;</code> </pre><br>  The purpose of the arguments must be clear from the title.  The <i>block</i> argument indicates whether the function should block if there is not enough space in the buffer or no data to read. <br><br>  So, the entire decoding function is as follows: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">audio_decode_thread</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *arg)</span></span></span><span class="hljs-function"> </span></span>{ assert(arg != <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); MainContext* main_context = (MainContext*)arg; Stream* audio_stream = &amp;main_context-&gt;audio_stream; AVFrame frame; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>) { avcodec_get_frame_defaults(&amp;frame); <span class="hljs-comment"><span class="hljs-comment">// Get packet from queue AVPacket pkt; packet_queue_get(&amp;main_context-&gt;audioq, &amp;pkt, 1); // The audio packet can contain several frames int got_frame; int len = avcodec_decode_audio4(audio_stream-&gt;codec_context, &amp;frame, &amp;got_frame, &amp;pkt); if (len &lt; 0) { av_free_packet(&amp;pkt); fprintf(stderr, "Failed to decode audio frame\n"); break; } if (got_frame) { // Store frame // Get decoded buffer size int data_size = av_samples_get_buffer_size(NULL, audio_stream-&gt;codec_context-&gt;channels, frame.nb_samples, audio_stream-&gt;codec_context-&gt;sample_fmt, 1); ring_buffer_write(&amp;main_context-&gt;audio_buf, frame.data[0], data_size, 1); } av_free_packet(&amp;pkt); } return 0; }</span></span></code> </pre><br>  The decoding of an audio packet is performed by the <i>avcodec_decode_audio4</i> function. In case the whole frame is decoded (the <i>got_frame</i> flag), we determine the size of the buffer in bytes using the <i>av_samples_get_buffer_size</i> function and write it to our ring buffer. <br><br><h5>  Audio playback </h5><br>  It remains quite a bit, namely to reproduce the decoded samples.  This is done in the <i>audio_callback</i> callback function: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">audio_callback</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">* userdata, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">uint8_t</span></span></span></span><span class="hljs-function"><span class="hljs-params">* stream, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> len)</span></span></span><span class="hljs-function"> </span></span>{ assert(userdata != <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); MainContext* main_context = (MainContext*)userdata; ring_buffer_read(&amp;main_context-&gt;audio_buf, stream, len, <span class="hljs-number"><span class="hljs-number">1</span></span>); }</code> </pre><br>  Everything is elementary here.  We take out <i>len</i> bytes from the buffer and store them in the provided SDL buffer. <br><br>  Unlike video, audio immediately plays at the correct speed.  This happens because the sampling rate was explicitly specified when configuring the audio output, and the call to the SDL callback function will be executed with this frequency. <br><br><h4>  Synchronization </h4><br>  The video and audio streams in the file have information about at what time and at what speed they should be played.  For audio streams, this is the sampling rate that we met in the previous section, and for video streams this is the number of frames per second ( <a href="http://en.wikipedia.org/wiki/Frame_rate">FPS</a> ).  However, it is impossible to perform synchronization only on the basis of these values, since the computer is not an ideal device, and most video files have inaccurate values ‚Äã‚Äãof these parameters.  Instead, each packet in the stream contains two values ‚Äã‚Äã‚Äî a <b>decoding label</b> (decoding timestamp, DTS) and a <b>display label</b> (presentation timestamp, <a href="http://en.wikipedia.org/wiki/Presentation_time_stamp">PTS</a> ).  The existence of two different values ‚Äã‚Äãis due to the fact that the frames in the file may not go in order.  This is possible if there are <b>B-frames</b> in the video ( <a href="http://en.wikipedia.org/wiki/Video_compression_picture_types">Bi-predictive picture</a> , a frame that depends on both the previous and the next frames).  Also on the video may be repeating frames. <br><br>  There are three synchronization options: <br><ul><li>  sync video to audio; </li><li>  synchronization of audio to video; </li><li>  synchronization of video and audio with an external generator; </li></ul><br><br>  Consider the simplest of these options, namely the <b>synchronization of video to audio</b> .  After displaying the current frame, we will calculate the next display time based on the PTS.  To update the image we will use SDL timers. <br><br>  In our main context, add the following fields: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MainContext</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-comment"><span class="hljs-comment">/* ... */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> video_clock; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> audio_clock; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> frame_timer; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> frame_last_pts; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> frame_last_delay; <span class="hljs-comment"><span class="hljs-comment">/* ... */</span></span> } MainContext;</code> </pre><br><ul><li>  <i>video_clock</i> : video display frequency; </li><li>  <i>audio_clock</i> : audio playback frequency; </li><li>  <i>frame_timer</i> : current display time; </li><li>  <i>frame_last_pts</i> : PTS value of the last frame shown; </li><li>  <i>frame_last_delay</i> : delay value of the last frame displayed; </li></ul><br>  During initialization, let's assign an initial value for <i>frame_timer</i> : <br><pre> <code class="cpp hljs">main_context-&gt;frame_timer = (<span class="hljs-keyword"><span class="hljs-keyword">double</span></span>)av_gettime() / <span class="hljs-number"><span class="hljs-number">1000000.0</span></span>;</code> </pre><br><br>  In the video decoding stream, we will calculate the display time of the next frame: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> pts = frame.pkt_dts; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (pts == AV_NOPTS_VALUE) { pts = frame.pkt_pts; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (pts == AV_NOPTS_VALUE) { pts = <span class="hljs-number"><span class="hljs-number">0</span></span>; } pts *= av_q2d(main_context-&gt;video_stream-&gt;time_base); pts = synchronize_video(main_context, &amp;frame, pts);</code> </pre><br>  You may notice that the <i>pts</i> value can take one of three values: <br><ul><li>  <i>frame.pkt_dts</i> : FFmpeg reorders frames during decoding so that the DTS value matches the PTS value of the frame being decoded.  In this case, we use DTS. </li><li>  <i>frame.pkt_pts</i> : If there is no DTS value, try using PTS. </li><li>  <i>0</i> : If both values ‚Äã‚Äãare missing, we will use the last saved video frequency value. </li></ul><br>  Function code <i>synchronize_video</i> : <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">double</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">synchronize_video</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(MainContext* main_context, AVFrame *src_frame, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params"> pts)</span></span></span><span class="hljs-function"> </span></span>{ assert(main_context != <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); assert(src_frame != <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); AVCodecContext* video_codec_context = main_context-&gt;video_stream-&gt;codec; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(pts != <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">/* if we have pts, set video clock to it */</span></span> main_context-&gt;video_clock = pts; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-comment"><span class="hljs-comment">/* if we aren't given a pts, set it to the clock */</span></span> pts = main_context-&gt;video_clock; } <span class="hljs-comment"><span class="hljs-comment">/* update the video clock */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> frame_delay = av_q2d(video_codec_context-&gt;time_base); <span class="hljs-comment"><span class="hljs-comment">/* if we are repeating a frame, adjust clock accordingly */</span></span> frame_delay += src_frame-&gt;repeat_pict * (frame_delay * <span class="hljs-number"><span class="hljs-number">0.5</span></span>); main_context-&gt;video_clock += frame_delay; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pts; }</code> </pre><br>  In it, we update the frequency of the video, and also take into account possible repeated frames. <br><br>  In the audio decoding stream, we will save the audio frequency in order to synchronize with it later: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (pkt.pts != AV_NOPTS_VALUE) { main_context-&gt;audio_clock = av_q2d(main_context-&gt;audio_stream-&gt;time_base) * pkt.pts; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-comment"><span class="hljs-comment">/* if no pts, then compute it */</span></span> main_context-&gt;audio_clock += (<span class="hljs-keyword"><span class="hljs-keyword">double</span></span>)data_size / (audio_codec_context-&gt;channels * audio_codec_context-&gt;sample_rate * av_get_bytes_per_sample(audio_codec_context-&gt;sample_fmt)); }</code> </pre><br><br>  In the video display function, we will calculate the delay before the next frame is displayed: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">double</span></span> delay = compute_delay(main_context); schedule_refresh(main_context, (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)(delay * <span class="hljs-number"><span class="hljs-number">1000</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span>));</code> </pre><br><br>  And the ‚Äúheart‚Äù of our sync is the <i>compute_delay</i> function: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">double</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compute_delay</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(MainContext* main_context)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> delay = main_context-&gt;pict.pts - main_context-&gt;frame_last_pts; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (delay &lt;= <span class="hljs-number"><span class="hljs-number">0.0</span></span> || delay &gt;= <span class="hljs-number"><span class="hljs-number">1.0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Delay incorrect - use previous one delay = main_context-&gt;frame_last_delay; } // Save for next time main_context-&gt;frame_last_pts = main_context-&gt;pict.pts; main_context-&gt;frame_last_delay = delay; // Update delay to sync to audio double ref_clock = get_audio_clock(main_context); double diff = main_context-&gt;pict.pts - ref_clock; double sync_threshold = FFMAX(AV_SYNC_THRESHOLD, delay); if (fabs(diff) &lt; AV_NOSYNC_THRESHOLD) { if (diff &lt;= -sync_threshold) { delay = 0; } else if (diff &gt;= sync_threshold) { delay = 2 * delay; } } main_context-&gt;frame_timer += delay; double actual_delay = main_context-&gt;frame_timer - (av_gettime() / 1000000.0); if(actual_delay &lt; 0.010) { /* Really it should skip the picture instead */ actual_delay = 0.010; } return actual_delay; }</span></span></code> </pre><br>  First, we calculate the delay between the previous and current frame and save the current values.  After that, we take into account the possible desynchronization with audio and calculate the duration of the required delay until the next frame. <br><br>  That's all!  Launch the player and enjoy watching! <br><br><h4>  Conclusion </h4><br>  In this part we have completed the development of the simplest player, improved the structure of the program, added audio playback and synchronization. <br>  Of the topics not covered are: rewind, fast / slow playback, other synchronization options. <br>  There is also a completely separate topic of coding and multiplexing.  Perhaps I will try to consider it in the next article. <br><br>  <a href="http://pastebin.com/GtvTv9ps">Source code player</a> . <br><br>  <b>Thank you all for your attention!</b> </div><p>Source: <a href="https://habr.com/ru/post/138426/">https://habr.com/ru/post/138426/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../138411/index.html">First look at the tablet Samsung Galaxy Tab 2</a></li>
<li><a href="../138412/index.html">POLL: The best Samsung device</a></li>
<li><a href="../138418/index.html">When do you use the letter "e" when writing?</a></li>
<li><a href="../138421/index.html">Humble Bundle Mojam: creating a game in live broadcast</a></li>
<li><a href="../138423/index.html">As we consider users Cut the Rope. Part 1</a></li>
<li><a href="../138428/index.html">Mozilla revealed the mobile operating system Boot2Gecko</a></li>
<li><a href="../138430/index.html">JoDo.im - symbiosis of jabber-server and freelance management system</a></li>
<li><a href="../138432/index.html">Simulation of the perfect book repository</a></li>
<li><a href="../138434/index.html">Screenshots of the new Google Drive service have appeared on the Internet.</a></li>
<li><a href="../138435/index.html">Refusing to use CMS when designing web applications</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>