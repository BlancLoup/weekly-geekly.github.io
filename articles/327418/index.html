<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>From Oracle to PostgreSQL - a 4-year path, a report by Andrei Rynkevich</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="2017 was a significant event for PG Day - we transformed our event into the largest database conference. 

 We do not change our traditions and are pr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>From Oracle to PostgreSQL - a 4-year path, a report by Andrei Rynkevich</h1><div class="post__text post__text-html js-mediator-article"> <i>2017 was a significant event for <a href="http://pgday.ru/ru/2017%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><b>PG Day</b></a> - we transformed our event into the largest database conference.</i> <i><br><br></i>  <i>We do not change our traditions and are preparing a rich and interesting program dedicated to the World.</i>  <i>Nevertheless, communication with colleagues and feedback from the participants make it clear that a huge number of specialists are engaged in the operation of several data storage systems, either by force or by their own decision.</i>  <i>We do not want to deprive colleagues of the opportunity to communicate with each other, share experiences and find ways to solve their problems.</i>  <i>That is why, in 2017, <b><a href="http://pgday.ru/ru/2017%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich">PG Day</a></b> is divided into <b>5</b> parallel threads in various areas: <b>PostgreSQL</b> , <b>MySQL</b> , <b>Oracle</b> , <b>MS SQL Server</b> , <b>NoSQL</b> solutions and other free and commercial DBMS.</i> <i><br><br></i>  <i>Despite the fact that radical changes in the structure of the GHG of the Day began only this year, interest in our event from the workshops in the workshop began to appear much earlier.</i>  <i>At one of the past PG Day, <b>Andrei Rynkevich</b> presented an interesting report <b>from Oracle to PostgreSQL - a 4-year-long path</b> based on the experience of migration at <b>Phorm</b> , the decoding of which we are pleased to present to Habr readers.</i> <br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The report ‚ÄúFrom Oracle to PostgreSQL - a path that is 4 years long‚Äù about the biggest challenge in our project, which should be completed in the next month with the installation of products fully working on PostgreSQL on ‚Äúproduction‚Äù. <br><br><img src="https://habrastorage.org/files/924/fd0/be5/924fd0be543d4c919da8370d6bbc16d7.png"><br><br>  At the very beginning we had Oracle and practically no user activity.  In such conditions, it doesn‚Äôt matter what technology you use.  No matter how well you write requests, everything works perfectly.  But analysts come to your aid. <br><br>  So a special kind of statistics appeared, the keys in which, even with our weak loads, completely hammered the disc to the eye: it was <b>about 5 TB</b> .  Of course, we turned off the statistics, but for the first time we began to think about an additional database for expansion.  The load grew, but our optimization capabilities were limited to the Oracle license.  The current license allows you to use only 4 cores, with such a restriction we cannot even use standby for requests, we do not have partitioning - you cannot go far on such a train.  Therefore, we began to look for options for expansion. <br><br><img src="https://habrastorage.org/files/d18/54f/8c7/d1854f8c779848059cc07f64529ace2e.png"><br><br>  At the beginning we looked at the possibilities of Oracle.  The current license <b>cost us ¬£ 15,000 per year</b> (support plus upgrade for new versions).  The removal of licensing restrictions on processors and documents for partitioning added quite a significant contribution to this amount, so we did not go this route, since there was not much money. <br><br>  The first solution we looked at was MySQL.  At that time, MySQL was already used in our projects, but after talking with people, we realized that it showed itself to be quite problematic and with limited functionality.  Therefore, quite a bit of a look at the NoSQL solution.  We did not have developers for NoSQL at that time, and this seemed to us a very radical change, so we also set it aside. <br><br>  The most suitable solution for us was <b>Greenplum</b> - this is an MPP database built on the basis of PostgreSQL.  Of course, the only negative is that it was also paid, but the amounts are no longer the same as those of Oracle, so we decided to stop at PostgreSQL with the goal of further migrating to Greenplum.  According to the plan, such a migration should not be too difficult. <br><br><img src="https://habrastorage.org/files/156/d01/7eb/156d017ebe4344d1a77ab3850bb27047.png"><br><br>  To begin with, we bought two hosts: master + standby (24 cores, 128 GB RAM), built a three-byte (3 TB) RAID10 - these are not SSD drives, because SSDs were very expensive at that time.  And they thought about what to do next. <br><br><img src="https://habrastorage.org/files/57c/e46/be2/57ce46be27a74c7caa73107aad15ef65.png"><br><br>  I confess that at the very beginning we did not have a clear, detailed understanding of all the steps of the migration.  At some point, we still <b>had to draw a road map of</b> how we move.  On the screen, you see a very curtailed version of this roadmap.  From the stages we can distinguish the following: <br><ul><li>  replication of data from the Oracle database to the PostgreSQL database; </li><li>  Merger - as a way to fill "raw" blocks in the database itself; </li><li>  transfer statistics from Oracle to Postgres; </li><li>  transfer of functionality; </li><li>  transfer tables and related projects. </li></ul><br>  Further - consistently about each stage. <br><br><img src="https://habrastorage.org/files/fa5/a88/a08/fa5a88a08fb84be7a5c740e5faafa396.png"><br><br>  At the very beginning, we already understood that we would not have the opportunity to migrate in one sitting, so we decided to start with statistics.  And there was such a moment that some statistics are partially located on PostgreSQL, and the rest is on Oracle (mostly entities).  The problem is that reports require both.  Question: how are we going to build reports? <br><br>  We dismissed the option on Oracle right away, because we still have limited opportunities there.  It is possible to set up an application service, extort entities from Oracle, and statistics from PostgreSQL, somehow connecting and filtering.  Such an application does the work for the database.  This approach seemed to us very difficult, so we further implemented three approaches, which we use in different degrees. <br><br>  <b>The first option</b> is to extort necessary entities from Oracle using a DBI link when requesting a report in PostgreSQL, this approach is working and is well applicable for small samples, because when you need to pump large data with a large number of entities, everything slows down dramatically, plus requests is very complicated.  This approach is relevant when the relevance of entities is needed: you go to the ‚Äúedit‚Äù page, add a new element and, when saved, you should immediately display it with new statistics. <br><br>  <b>The next option</b> is to completely transfer all entities from Oracle to PostgreSQL, periodically transfer all entities.  We also use this approach, but the fact is that the number of entities occupies about 100 GB in us, therefore the actuality of the entity in the postgrese is lagging behind.  But this option works well when you need to handle large reports that do not require data relevance.  But, knowing our operators, who come to us in half an hour, as soon as some kind of statistics begins to fall behind, we decided to implement <b>streaming replication</b> : when updating to Oracle, the entity almost immediately falls into Postgres. <br><br><img src="https://habrastorage.org/files/680/8de/96d/6808de96d1784848a0e8005e5e6eca77.png"><br><br>  To address this issue, the following options were considered: <br><br>  <b>WisdomForce Database Sync</b> is a commercial product that existed at the time.  He was quite happy with us and the speed was about 5,000 updates per second, but at that moment when we decided to use it, another company bought it, and the project disappeared from the market, so we had to figure it out and build solutions ourselves. <br><br>  The first option that was considered is <b>Oracle DataChange Capture</b> .  These are Java processes that run in an Oracle database.  They know how to catch changes to the plates and stuff them in the queue.  Unfortunately, the speed of this decision was lost in history, but it was not very high. <br><br>  The first replication option was built on the <b>Materialized View Logs</b> - these are special Oracle tablets that store all changes to the master tablets and are used for quick recalculation to the Materialized View. <br><br>  This solution turned out to be quite simple to implement and gave a speed of about 500 updates per second, but the product grew and this was not enough.  Then we switched to a special Oracle technology <b>Stream</b> , which is used to replicate data from Oracle to other sources.  The current speed also allows you to pump and update entities at a speed of 5000 updates per second (up to 50,000 could be reached), while the average delay takes up to 30 seconds.  And what is interesting is that even if you updated one record in Oracle, it gets into the Stream not immediately, but with some delay, because there is some latency in all these processes. <br><br>  Oracle also has a continuation of stream technology - XStreams, which allows you to get better results, but this solution is paid for them, so we tested it, but did not use it. <br><br><img src="https://habrastorage.org/files/7ec/23c/0ef/7ec23c0ef0e1440abe670d46ff5a1fcd.png"><br><br>  <b>The replication scheme is quite simple</b> .  Now, Oracle has processes that read redo logs - this is an analogue of WAL files in PostgreSQL.  All labels that need to be replicated are recorded in a separate ‚ÄúReplication data‚Äù label.  With the help of intermediate software, redo-logs are hung on each table.  As a result, at the output, we get data that also forms our ‚ÄúReplication Data‚Äù label. <br><br><img src="https://habrastorage.org/files/c49/593/25d/c4959325dfeb4665a8ddc173fa683c14.png"><br><br>  On the PostgreSQL side, we have built <b>a replication application / utility in Java</b> - it reads this data from Replication Data and writes it to PostgreSQL.  The advantage is that, if it is possible to read and write data transactionally, there is no violation of integrity. <br><br>  As for the speed of 5000 per second - basically, the narrow link in this place is the replication utility.  Stream-processes, as I said, allow you to keep up to 50,000 sorts / updates.  To speed up the utility, we split it into <b>3 threads</b> : <br><ol><li>  The first stream read data from replication data and transformed it into queries that could be applied already on PostgreSQL. </li><li>  The second applied these changes. </li><li>  The third one cleared the processed data from the replication data table. </li></ol><br><img src="https://habrastorage.org/files/2f1/cb0/33d/2f1cb033dbf845f9a1ddf84c7838099b.png"><br><br>  Stream processes allow not only replicating data, but also DDL.  We first rushed to solve this problem.  Fortunately, the system is complex, and I wanted to minimize all manual twitching, but this was not easy, because the DDL language itself is diverse.  Plus, there is a moment of ambiguity in translating DDL from Oracle to PostgreSQL.  It happened so that often in our production we got out unregistered versions of this DDL.  As a result, we decided that it would be easier for us to recreate them in the postgres and reload the data.  As a result, we left one instruction that we support - this is TRUNCATE. <br><br><img src="https://habrastorage.org/files/ddd/a1a/976/ddda1a9763ef4fadb3baa0fbb09307cc.png"><br><br>  The speed of 5000 updates per second, in most cases, is acceptable, but there is one moment when it was not enough.  This is exactly patching a large amount of data in Oracle.  So, there were cases when the update affected tens of gigabytes.  Stream processes are quite heavy, because to drive all these volumes through them is quite expensive for the server.  Therefore, we came up with such a scheme. <br><br>  If a database developer understands that his patch will affect a large number of changes, he sets a certain flag in the patch system that he needs to stop replication.  By applying this patch, the patch system stopped streaming processes, did its own business with tablets, and at the very end wrote a marker on our replication table indicating that the patch was over and the flag that the tablets needed to be initialized.  Further the system of a patch started postgres.  She waited for this last marker, written in Oracle, already at Postgres, which passed through replication.  He always came last.  The system looked at the flag and, if it was necessary to recreate the labels, it recreated them and extorted all the entities from Oracle using a DBI link.  And then she did the patching of the system itself.  On it with replication everything. <br><br><img src="https://habrastorage.org/files/422/177/0a6/4221770a600043d58c6d4369dc57b393.png"><br><br>  <b>The next step</b> is to load data into the database itself.  In fact, our project is divided into several: in fact, the database itself;  UI, which fills in the base of the entity and issues reports;  server logs, which daily pumps through the base 150 GB, using stored procedures. <br><br>  Since database developers do not really control the log-server-database link, there are many problems.  For example, statistics come from different countries, at different times and in different volumes, which periodically gives rise to load jumps.  It is clear that this affects all users.  The next problem, sometimes unexpected: the log server gives out too large data packets.  Again, the processing of such packs takes up a lot of resources from the server and affects all other processes.  In addition, there is still a difficulty in handling failed patches for statistics. <br><br>  If something ‚Äúzafeilosya‚Äù, these statistics remain on the log server.  The database developer needs to somehow get there (and this is not always possible), convert the stored procedure (in plan, call, fix, re-fill).  This is quite a difficult decision.  Therefore, on the postgres side, we went a little differently, namely, we upload files, i.e.  the log server no longer calls the stored procedure, but issues csv files. <br><br><img src="https://habrastorage.org/files/1d7/7b9/837/1d77b9837fa04435ade2d0cfed81c150.png"><br><br>  There is a <b>Merger</b> program, which, according to certain rules, each type of statistics is uploaded to the database.  All the files were located on the same host, it solved all previous problems, i.e.  load jumps affected only the number of unprocessed files on the disk.  The filed files could always be found, fixed right there with their hands, put back and loaded.  Also, Merger broke large bundles apart, so there were no very long transactions. <br><br><img src="https://habrastorage.org/files/9d9/9a3/bb6/9d99a3bb603f4bf5abb72d73737bc85f.png"><br><br>  Merger also went a long way. <br><br>  The first version was made on the knee and looks like this green line.  This is his decision.  That is, for each type of statistics, the ‚Äústaging‚Äù label and the procedure that placed these labels in the database were created.  But this option is not suitable for all solutions, so we wanted to come to something simpler, more universal.  So we have the second option. <br><br>  On the screen you see the very first and simplest rule for processing statistics.  The program by the name of the file understood which rule to take, the same rule corresponded to a label in the database.  Primary keys were selected from this label, and already for these primary keys for each row it was already possible to understand whether INSERT or UPDATE should be done. <br><br>  Such rules describe most types of statistics, but there are still many options.  Therefore, the Merger syntax is growing and growing.  So, there are rules for INSERT, UPDATE, setting conditions, when you need to do this or another partitioning, flooding with any other perverted ways.  But it‚Äôs possible to single out the following.  It so happens that statistics comes earlier than entities in PostgreSQL.  This happens, for example, when the replication itself ‚Äúfell‚Äù or did not work for some time. <br><br><img src="https://habrastorage.org/files/a78/39b/ccf/a7839bccf9774a65aff4392a86e7901f.png"><br><br>  To solve this problem, we also created a cunning scheme.  In Oracle, there is a <b>label</b> , <b>HEART_BEAT</b> is called, and the job, which inserts a timestamp into it every 30 seconds.  This label is replicated to the PostgreSQL database, and Merger can already understand what is required.  He watches the last heartbeat arriving and processes only those files that are younger than this heartbeat, otherwise we may lose some data.  It is clear that if there is no entity, but it is already in the statistics, then it will disappear when merj. <br><br><img src="https://habrastorage.org/files/31a/cd7/26e/31acd726e61e464f864b32f039d11044.png"><br><br>  Having replication and Merger, we could go on to transfer statistics.  On the slide you can see a slightly modified and truncated version of this process.  From the stages we can distinguish the following: <br><ul><li>  creating labels and rules for Merger; </li><li>  transfer server logs to logging in both Oracle and PostgreSQL via csv files. </li></ul><br>  For some reason, we had a fear to move everything else at once.  Therefore, at each stage we tried to somehow keep with the possibility of going back if something goes wrong.  If double logging remained on the production for some time, then we started translating both the UI and the reports. <br><br>  Here we also realized our fear of transition, and therefore there could be <b>two identical reports</b> in the system at once, one of which worked on Oracle and the other on PostgreSQL.  This turned out to be quite convenient for both developers and testers: you could always run the same queries, see the results and visually compare them, solve the problems found. <br><br><img src="https://habrastorage.org/files/fe2/a0f/05e/fe2a0f05e3084534b63e4f56e02c4292.png"><br><br>  The more statistics appeared in PostgreSQL, the more often new cases appeared.  So, for example, according to statistics in PostgreSQL, at some point we needed to update the entities already in Oracle.  For example, when passing certain threshold values, it was necessary to change the status.  In this case, on the postgres side, we got some job that maximally aggregated the necessary statistics and stuffed it into Oracle via dbi link.  There - already through a stored procedure or in a separate table, which was processed by the corresponding job in Oracle.  Then the data, statuses and entities changed in Oracle and through replication came to PostgreSQL. <br><br><img src="https://habrastorage.org/files/441/5f3/c5c/4415f3c5ca7d4afb9bb919fc05ae68b5.png"><br><br>  Guess what it is?  This is a <b>collection of entities</b> .  I drove all entities into Modeler, and he built all the connections between them.  As you can see, the grid is quite dense, not everything even got into the screen.  Therefore, the same trick with the statistics: we didn‚Äôt manage to transfer everything in parts, because the connections are rather dense.  In addition, in the UI, the ORM system works with us, and it is quite difficult to break the links there.  In fact, you have to implement two-phase commit to different databases.  Running two variants into the same ORM was also problematic for the model.  Therefore, we decided to postpone the entire migration of the entities to the last spurt, while at the same time preparing all the necessary moments. <br><br>  For one of the plates, we still had to implement the transfer, break the connection, it took quite a long time.  The reason is that this tablet is very large and it has changed intensively.  It was expensive for initialization in the postgrese (the need to pump all the entities) and for the replication process. <br><br><img src="https://habrastorage.org/files/872/54b/575/87254b57502944a4ae22902c78eb5ff4.png"><br><br>  With the transfer of functionality was a little easier.  On the screen, you can see some interrelation of the stages of transition of some part of the system from Oracle to PostgreSQL.  There are, of course, fewer connections, but each square consists of small squares, which has its own connections.  Therefore, in order to facilitate the last spurt, we have maximally simplified everything we can.  You can select <b>three options</b> . <br><br>  <b>Full transfer of functionality</b> when we completely removed it from Oracle and started on postgrese.  In some cases this was possible. <br><br>  In most cases, we <b>transferred the functionality and ran it idle</b> .  For example, billing has worked in this mode for about a year, allowing us to find many performance problems and a number of critical bugs.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But the results of such a billing, of course, were thrown into the trash. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dead transfer</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is a transfer of the stored procedures, rewriting them from Oracle to postgres. These procedures might not even work. And, often, they did not work, they were not called. But this allowed us to create a set of "blanks" to the next step.</font></font><br><br><img src="https://habrastorage.org/files/a5b/2c8/4a7/a5b2c84a7690425aa2c35de1458a8fdc.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Actually, having prepared everything to go to the last spurt, we overcame it with this last spurt. In fact, we moved all the statistics, included the functionality that was idling and which was lying dead weight. The release itself took place with a rather large ‚Äúdowntime‚Äù, since you need to transfer a fairly large amount of relevant data and perform some migrations point by point. It is interesting that, despite the fact that we did a lot of things, we found that we forgot to transfer certain modules, so we had to postpone the release for about a week. And even after that, somewhere in a week or two, we found another module that had not been migrated, and we already had to finish it live. </font></font><br><br><img src="https://habrastorage.org/files/0e3/f3e/c2c/0e3f3ec2c4b14c0592bff3b9465c46cc.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 years</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- this is quite a long time. To understand whether this value is justified or not, we wrote out a number of metrics, some of which you see on the slide. Probably, each of you was mistaken in the initial assessment of the volume of this or that work. This mistake was made by us. Initially, our assessment was a year and a half. And even now, when everything is completed, few people call the number for more than two years, because it all merged into a continuous stream. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As you can see, the base is not very big, but not very small either. If you take the code, to write a number with 0, you need to write about </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">80 lines per day</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . It‚Äôs not so much even for a small team.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The greatest time was taken to study and compare different solutions. Of the other points that are not technical, there are several. As you can see, the transfer involved about 30 people who worked in different teams, in different places. And the coordination of such a national team has required quite a long time. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One of the moments was the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">loss of focus.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. I thought for a long time what it was until I encountered this with my own eyes. The fact is that we acted proactively and we didn‚Äôt have such big problems on Oracle in most cases, so all the migration tasks went a bit in the background. And, since there were quite a lot of short-term tasks, this strategic direction was slightly moved to the background. There were cases when we forgot about migration for a week or two. </font></font><br><br><img src="https://habrastorage.org/files/8aa/6bd/0a6/8aa6bd0a66f44a3f98d5a77eb1fd98cb.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Despite the fact that PostgreSQL is a pretty cool database and with each release we like it more and more, we still lacked some moments during the migration. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Joba</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , in Oracle, they exist in the database itself and it was unusual to go beyond the framework, run some crontab. In addition, you need to monitor all this, that it all starts and runs well.</font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resource management</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : sometimes it is good to divide resources between processes, for example, between user requests and statistics. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The coolest thing</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in Oracle, in my opinion, because it saved me several times, is flashback. This is an opportunity to restore some version in a short period of time. We are thinking of something like this, we are thinking of realizing it as a postgres, since there were moments when we had to restore large chunks of entities due to incidents. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Also </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OEM (Oracle Enterprise Management)</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- this is a web application. When we have these or other problems, DBA climbs into this OEM, sees all the activities there are. You can go through the stories, see what happened, compare the interaction of various aspects and do all your admins. In PostgreSQL, of course, DBA has skill at the tips of the fingers, so it can issue all requests with the same speed as through this application, but the convenience suffers for people who are not DBA. Therefore, we still wrote our own version of the OEM, it was important to preserve the entire history of requests for tables and queries. In the end, we could go in and see what was slowing down there, see all the interrelations and make changes in our code. </font></font><br><br><img src="https://habrastorage.org/files/5bc/847/6af/5bc8476afa8f44e2b6a753c5849923ac.png"><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Greenplum</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">we still did not buy, the crisis, but the volumes are growing, so we are faced with the same problems that we already had Oracle, on PostgreSQL, but on a larger scale. So, the first of the problems we have encountered is </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">disk restriction</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . At some point, we even had to do an un-raid operation on several sections. Having thus turned RAID-10 into RAID-5, it seems.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The main problem of this operation is that the data stored on these sections are lost, so we had to play the tags on the disk to fit everything. Upon request, we also have problems, we stick to some of the limitations in processing, to the extent that we even have to disable some of the functionality. And some volumetric statistics that require a lot of space and processing, we even </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">carried out the</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> postgres </font><b><font style="vertical-align: inherit;">to a separate place</font></b><font style="vertical-align: inherit;"> and develop all this direction in a special way, because the further, the worse. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">New version watched? We watched and watched, but we transferred the main statistics to Hadoop, for short. On hadupe we are faced </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Impala</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, such a column, in fact, a database that is responsible for our data. And we even have a strategic task to bring all the volume statistics that are not needed for billing, or for the work of momentary jobs, in the Hadoop cluster and, if we need something, then return it once. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So, our operators love to watch hourly statistics. The volume of keys in the main event table is very large and it is expensive for the server, so we have already taken out the hourly statistics to </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hadoop</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/files/a61/060/56f/a6106056fcce49a29cd997efd8bc97b9.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The thematic expansion of </font></font><a href="http://pgday.ru/ru/2017%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PG Day'17</font></font></b></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> increased the interest of our listeners and speakers in the subject of </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">migrations</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from one data warehouse to another. Migration issues will be considered in almost </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">every section.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">so no questions will be left! Especially for you we are preparing to present some interesting reports. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vasily Sozykin</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex.Money</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tells you about the </font></font><b><a href="http://pgday.ru/ru/2017/papers/154%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">migration of a loaded service from Oracle to PotgreSQL</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , a fascinating story about how Yandex specialists migrated a truly huge base without downtime. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alexander Korotkov</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Postgres Professional</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in his report ‚Äú </font></font><b><a href="http://pgday.ru/ru/2017/papers/151%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Our Response to Uber</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äù will analyze the sensational story about the relocation of the popular Taxi service from PostgreSQL back to MySQL. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kristina Kucherova</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Distillery</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> will tell you how she and her colleagues came to a decision about</font></font><b><a href="http://pgday.ru/ru/2017/papers/114%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OLTP migration of a part of their system from MS SQL to PostgreSQL</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and how it turned out for them.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Well, the fourth, no less intriguing, report on</font></font><b><a href="http://pgday.ru/ru/2017/papers/143%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> online data replication in Greenplum of 25 DBMSs running Oracle</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is prepared for you by</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dmitry Pavlov</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , the head of the Date Warehouse administration team at</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tinkoff</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Bank</font><font style="vertical-align: inherit;">. Dmitry is not the first time speaking at PG Day. His previous reports were a resounding success and were packed to capacity.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">At the very last moment, when we were preparing this issue for publication and were already ready to press the ‚Äú</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Publish</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äù</font><font style="vertical-align: inherit;">button</font><font style="vertical-align: inherit;">, colleagues from the</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> research institute ‚ÄúVoskhod‚Äù</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> applied for a report.</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dmitry Pogibenko</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> will tell about</font></font><b><a href="http://pgday.ru/ru/2017/papers/196%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">successful migration of the state system Mir database (more than 10 TB of data!) from DB2 to PostgreSQL</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> with minimal downtime. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparing for your own migration? </font><font style="vertical-align: inherit;">Have you had a successful transition from one repository to another and are you eager to share your experience? </font><font style="vertical-align: inherit;">Be sure to</font></font><a href="http://pgday.ru/ru/2017/request/registration%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Drynkevich"><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> come</font></font></b></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to us at PG Day, buy tickets at spring prices, apply for reports, deadline soon! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">See you in summer in St. Petersburg!</font></font></div><p>Source: <a href="https://habr.com/ru/post/327418/">https://habr.com/ru/post/327418/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327408/index.html">Why I don't want to program in Perl anymore</a></li>
<li><a href="../327410/index.html">TLS SNI standard distribution</a></li>
<li><a href="../327412/index.html">DentalTap Service Overview - Business and Communication sections</a></li>
<li><a href="../327414/index.html">Restore 1C Enterprise (DBF) after formatting</a></li>
<li><a href="../327416/index.html">A systematic approach to testing Android applications, or what the developers were silent</a></li>
<li><a href="../327420/index.html">Already this year: Google plans to create a quantum computer</a></li>
<li><a href="../327422/index.html">Data loading from REST API</a></li>
<li><a href="../327424/index.html">Moving from Disqus to Github comments</a></li>
<li><a href="../327426/index.html">Trying to manage freeing memory in javascript</a></li>
<li><a href="../327428/index.html">Experiment: passersby draw famous logos from memory</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>