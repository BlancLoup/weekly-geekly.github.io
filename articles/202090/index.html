<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Basics of analyzing data in python using pandas + sklearn</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, dear readers. In today's post, I will continue my series of articles on analyzing data in python using the Pandas module and tell you ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Basics of analyzing data in python using pandas + sklearn</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, dear readers.  In today's post, I will continue my series of articles on analyzing data in python using the <a href="http://pandas.pydata.org/">Pandas</a> module and tell you one of the options for using this module in conjunction with the module for machine learning <a href="http://scikit-learn.org/stable/">scikit-learn</a> .  The work of this bundle will be shown on the example of the <a href="https://www.kaggle.com/c/titanic-gettingStarted/data">task</a> about the rescued from the "Titanic".  This task is very popular among people just starting to do data analysis and <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B0%25D1%2588%25D0%25B8%25D0%25BD%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BE%25D0%25B1%25D1%2583%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">machine learning</a> . <br><a name="habracut"></a><br><br><h4>  Formulation of the problem </h4><br>  So, the essence of the task is to build a model using machine learning methods that predicts whether a person will be saved or not.  2 files are attached to the task: <br><ul><li>  <i>train.csv</i> - the data set on the basis of which the model will be built ( <i>training sample</i> ) <br></li><li>  <i>test.csv</i> - data set for model checking <br></li></ul><br>  As it was written above, for the analysis modules Pandas and scikit-learn will be needed.  With <b>Pandas,</b> we will conduct an initial analysis of the data, and <b>sklearn</b> will help in calculating the predictive model.  So, first, load the required modules: <br>  In addition, explanations are given for some fields: <br><ul><li>  <b>PassengerId</b> - passenger ID <br></li><li>  <b>Survival</b> - a field in which it is indicated that a person was saved (1) or not (0) <br></li><li>  <b>Pclass</b> - contains socio-economic status: <br><ol><li>  tall </li><li>  average </li><li>  low </li></ol></li><li>  <b>Name</b> - passenger's name <br></li><li>  <b>Sex</b> - passenger floor <br></li><li>  <b>Age</b> - age <br></li><li>  <b>SibSp</b> - contains information about the number of second-order relatives (husband, wife, brothers, sets) <br></li><li>  <b>Parch</b> - contains information on the number of relatives on the board of the 1st order (mother, father, children) <br></li><li>  <b>Ticket</b> - ticket number <br></li><li>  <b>Fare</b> - ticket price <br></li><li>  <b>Cabin</b> - Cabin <br></li><li>  <b>Embarked</b> - landing port <br><ul><li>  C - Cherbourg </li><li>  Q - Queenstown </li><li>  S - Southampton <br></li></ul></li></ul><br><br><h4>  Input analysis </h4><br>  &gt; So, the task is formed and you can begin to solve it. <br>  First, let's load a test sample and see how it looks like: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_csv, DataFrame, Series data = read_csv(<span class="hljs-string"><span class="hljs-string">'Kaggle_Titanic/Data/train.csv'</span></span>)</code> </pre> <br><table border="1"><tbody><tr><th>  PassengerId </th><th>  Survived </th><th>  Pclass </th><th>  Name </th><th>  Sex </th><th>  Age </th><th>  Sibsp </th><th>  Parch </th><th>  Ticket </th><th>  Fare </th><th>  Cabin </th><th>  Embarked </th></tr><tr><td>  one </td><td>  0 </td><td>  3 </td><td>  Braund, Mr.  Owen harris </td><td>  male </td><td>  22 </td><td>  one </td><td>  0 </td><td>  A / 5 21171 </td><td>  7.2500 </td><td>  NaN </td><td>  S </td></tr><tr><td>  2 </td><td>  one </td><td>  one </td><td>  Cumings, Mrs.  John Bradley (Florence Briggs Th ... </td><td>  female </td><td>  38 </td><td>  one </td><td>  0 </td><td>  PC 17599 </td><td>  71.2833 </td><td>  C85 </td><td>  C </td></tr><tr><td>  3 </td><td>  one </td><td>  3 </td><td>  Heikkinen, Miss.  Laina </td><td>  female </td><td>  26 </td><td>  0 </td><td>  0 </td><td>  STON / O2.  3101282 </td><td>  7.9250 </td><td>  NaN </td><td>  S </td></tr><tr><td>  four </td><td>  one </td><td>  one </td><td>  Futrelle, Mrs.  Jacques Heath (Lily May Peel) </td><td>  female </td><td>  35 </td><td>  one </td><td>  0 </td><td>  113803 </td><td>  53.1000 </td><td>  C123 </td><td>  S </td></tr><tr><td>  five </td><td>  0 </td><td>  3 </td><td>  Allen, Mr.  William Henry </td><td>  male </td><td>  35 </td><td>  0 </td><td>  0 </td><td>  373450 </td><td>  8.0500 </td><td>  NaN </td><td>  S </td></tr></tbody></table><br>  It can be assumed that the higher the social status, the greater the likelihood of salvation.  Let's check it out by looking at the number of survivors and drowning depending on the grade.  For this you need to build the following summary: <br><br><pre> <code class="python hljs">data.pivot_table(<span class="hljs-string"><span class="hljs-string">'PassengerId'</span></span>, <span class="hljs-string"><span class="hljs-string">'Pclass'</span></span>, <span class="hljs-string"><span class="hljs-string">'Survived'</span></span>, <span class="hljs-string"><span class="hljs-string">'count'</span></span>).plot(kind=<span class="hljs-string"><span class="hljs-string">'bar'</span></span>, stacked=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/c64/b62/cbc/c64b62cbc06141e072d550b6b2f3ca7c.png" alt="image"><br>  Our above assumption is that the higher their social status among passengers is, the higher is their likelihood of salvation.  Now let's take a look at how the number of relatives affects the fact of salvation: <br><br><pre> <code class="python hljs">fig, axes = plt.subplots(ncols=<span class="hljs-number"><span class="hljs-number">2</span></span>) data.pivot_table(<span class="hljs-string"><span class="hljs-string">'PassengerId'</span></span>, [<span class="hljs-string"><span class="hljs-string">'SibSp'</span></span>], <span class="hljs-string"><span class="hljs-string">'Survived'</span></span>, <span class="hljs-string"><span class="hljs-string">'count'</span></span>).plot(ax=axes[<span class="hljs-number"><span class="hljs-number">0</span></span>], title=<span class="hljs-string"><span class="hljs-string">'SibSp'</span></span>) data.pivot_table(<span class="hljs-string"><span class="hljs-string">'PassengerId'</span></span>, [<span class="hljs-string"><span class="hljs-string">'Parch'</span></span>], <span class="hljs-string"><span class="hljs-string">'Survived'</span></span>, <span class="hljs-string"><span class="hljs-string">'count'</span></span>).plot(ax=axes[<span class="hljs-number"><span class="hljs-number">1</span></span>], title=<span class="hljs-string"><span class="hljs-string">'Parch'</span></span>)</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/b86/14a/1c7/b8614a1c73db29d7173856f3e05f3c4c.png" alt="image"><br>  As can be seen from the graphs, our assumption was again confirmed, and not many of the people with more than 1 relatives were saved. <br>  Now we speculate about the data that are cabin numbers.  Theoretically, there may not be any data about user cabins, so let's look at this field as much as this one is filled in: <br><br><pre> <code class="python hljs">data.PassengerId[data.Cabin.notnull()].count()</code> </pre> <br><br>  As a result, only 204 records and 890 are filled in, on the basis of this it can be concluded that this field can be omitted during analysis. <br>  The next field that we will analyze will be a field with age ( <i>Age</i> ).  Look at how full it is: <br><br><pre> <code class="python hljs">data.PassengerId[data.Age.notnull()].count()</code> </pre> <br><br>  This field is almost all filled (714 non-empty records), but there are empty values ‚Äã‚Äãthat are not defined.  Let's give it a value equal to the median by age of the entire sample.  This step is needed for more accurate model building: <br><br><pre> <code class="python hljs">data.Age = data.Age.median()</code> </pre> <br>  We have left to deal with the fields <i>Ticket</i> , <i>Embarked</i> , <i>Fare</i> , <i>Name</i> .  Let's look at the Embarked field, in which the landing port is located, and check if there are any passengers whose port is not listed: <br><br><pre> <code class="python hljs">data[data.Embarked.isnull()]</code> </pre> <br><table border="1"><tbody><tr><th>  PassengerId </th><th>  Survived </th><th>  Pclass </th><th>  Name </th><th>  Sex </th><th>  Age </th><th>  Sibsp </th><th>  Parch </th><th>  Ticket </th><th>  Fare </th><th>  Cabin </th><th>  Embarked </th></tr><tr><td>  62 </td><td>  one </td><td>  one </td><td>  Icard, Miss.  Amelie </td><td>  female </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  113572 </td><td>  80 </td><td>  B28 </td><td>  NaN </td></tr><tr><td>  830 </td><td>  one </td><td>  one </td><td>  Stone, Mrs.  George Nelson (Martha Evelyn) </td><td>  female </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  113572 </td><td>  80 </td><td>  B28 </td><td>  NaN </td></tr></tbody></table><br><br>  So we found 2 such passengers.  Let's assign these passengers the port in which the village has the most people: <br><br><pre> <code class="python hljs">MaxPassEmbarked = data.groupby(<span class="hljs-string"><span class="hljs-string">'Embarked'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'PassengerId'</span></span>] data.Embarked[data.Embarked.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><br>  Well, we have dealt with one more field and now we have fields with the passenger's name, ticket number and ticket price. <br>  In fact, we need only the price ( <i>Fare</i> ) of these three fields, since  it determines to some extent the ranking within the classes of the <i>Pclass</i> field.  That is, for example, people inside the middle class can be divided into those who are closer to the first (upper) class, and who are closer to the third (lower) class.  Let's check this field for empty values ‚Äã‚Äãand if any, we will replace the price with the median at the price of all the samples: <br><br><pre> <code class="python hljs">data.PassengerId[data.Fare.isnull()]</code> </pre> <br>  In our case there are no empty entries. <br>  In turn, the ticket number and the passenger's name will not help us in any way, since this is just reference information.  The only thing for which they can be useful is the definition of which of the passengers are potentially relatives, but since people who have relatives almost did not escape (this was shown above), we can ignore this data. <br>  Now, after removing all unnecessary fields, our set looks like this: <br><br><pre> <code class="python hljs">data = data.drop([<span class="hljs-string"><span class="hljs-string">'PassengerId'</span></span>,<span class="hljs-string"><span class="hljs-string">'Name'</span></span>,<span class="hljs-string"><span class="hljs-string">'Ticket'</span></span>,<span class="hljs-string"><span class="hljs-string">'Cabin'</span></span>],axis=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><table border="1"><tbody><tr><th>  Survived </th><th>  Pclass </th><th>  Sex </th><th>  Age </th><th>  Sibsp </th><th>  Parch </th><th>  Fare </th><th>  Embarked </th></tr><tr><td>  0 </td><td>  3 </td><td>  male </td><td>  28 </td><td>  one </td><td>  0 </td><td>  7.2500 </td><td>  S </td></tr><tr><td>  one </td><td>  one </td><td>  female </td><td>  28 </td><td>  one </td><td>  0 </td><td>  71.2833 </td><td>  C </td></tr><tr><td>  one </td><td>  3 </td><td>  female </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  7.9250 </td><td>  S </td></tr><tr><td>  one </td><td>  one </td><td>  female </td><td>  28 </td><td>  one </td><td>  0 </td><td>  53.1000 </td><td>  S </td></tr><tr><td>  0 </td><td>  3 </td><td>  male </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  8.0500 </td><td>  S </td></tr></tbody></table><br><br><h4>  Input Preprocessing </h4><br>  The preliminary analysis of the data is completed, and according to its results, we have obtained a kind of sample, which contains several fields and it would seem possible to break the construction of the model, if not for one ‚Äúbut‚Äù: our data contain not only numerical, but also text data. <br>  Therefore, before building a model, you need to encode all our text values. <br>  You can do it manually, or by using the <a href="http://scikit-learn.org/stable/modules/preprocessing.html">sklearn.preprocessing</a> module.  Let's use the second option. <br>  You can encode a list with fixed values ‚Äã‚Äãusing the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">LabelEncoder ()</a> object.  The essence of this function is that the input to it is a list of values, which must be encoded, the output is a list of classes whose indices are the codes of the elements of the input list. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LabelEncoder label = LabelEncoder() dicts = {} label.fit(data.Sex.drop_duplicates()) <span class="hljs-comment"><span class="hljs-comment">#     dicts['Sex'] = list(label.classes_) data.Sex = label.transform(data.Sex) #       label.fit(data.Embarked.drop_duplicates()) dicts['Embarked'] = list(label.classes_) data.Embarked = label.transform(data.Embarked)</span></span></code> </pre> <br>  As a result, our initial data will look like this: <br><table border="1"><tbody><tr><th>  Survived </th><th>  Pclass </th><th>  Sex </th><th>  Age </th><th>  Sibsp </th><th>  Parch </th><th>  Fare </th><th>  Embarked </th></tr><tr><td>  0 </td><td>  3 </td><td>  one </td><td>  28 </td><td>  one </td><td>  0 </td><td>  7.2500 </td><td>  2 </td></tr><tr><td>  one </td><td>  one </td><td>  0 </td><td>  28 </td><td>  one </td><td>  0 </td><td>  71.2833 </td><td>  0 </td></tr><tr><td>  one </td><td>  3 </td><td>  0 </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  7.9250 </td><td>  2 </td></tr><tr><td>  one </td><td>  one </td><td>  0 </td><td>  28 </td><td>  one </td><td>  0 </td><td>  53.1000 </td><td>  2 </td></tr><tr><td>  0 </td><td>  3 </td><td>  one </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  8.0500 </td><td>  2 </td></tr></tbody></table><br><br>  Now we need to write the code to bring the verification file in the desired form.  To do this, you can simply copy the pieces of code that were above (or just write a function to process the input file): <br><br><pre> <code class="python hljs">test = read_csv(<span class="hljs-string"><span class="hljs-string">'Kaggle_Titanic/Data/test.csv'</span></span>) test.Age[test.Age.isnull()] = test.Age.mean() test.Fare[test.Fare.isnull()] = test.Fare.median() <span class="hljs-comment"><span class="hljs-comment">#      MaxPassEmbarked = test.groupby('Embarked').count()['PassengerId'] test.Embarked[test.Embarked.isnull()] = MaxPassEmbarked[MaxPassEmbarked == MaxPassEmbarked.max()].index[0] result = DataFrame(test.PassengerId) test = test.drop(['Name','Ticket','Cabin','PassengerId'],axis=1) label.fit(dicts['Sex']) test.Sex = label.transform(test.Sex) label.fit(dicts['Embarked']) test.Embarked = label.transform(test.Embarked)</span></span></code> </pre><br><br>  The code described above performs almost the same operations as we did with the training sample.  The difference is that a line was added to process the <i>Fare</i> field, if it is not filled out. <br><table border="1"><tbody><tr><th>  Pclass </th><th>  Sex </th><th>  Age </th><th>  Sibsp </th><th>  Parch </th><th>  Fare </th><th>  Embarked </th></tr><tr><td>  3 </td><td>  one </td><td>  34.5 </td><td>  0 </td><td>  0 </td><td>  7.8292 </td><td>  one </td></tr><tr><td>  3 </td><td>  0 </td><td>  47.0 </td><td>  one </td><td>  0 </td><td>  7.0000 </td><td>  2 </td></tr><tr><td>  2 </td><td>  one </td><td>  62.0 </td><td>  0 </td><td>  0 </td><td>  9.6875 </td><td>  one </td></tr><tr><td>  3 </td><td>  one </td><td>  27.0 </td><td>  0 </td><td>  0 </td><td>  8.6625 </td><td>  2 </td></tr><tr><td>  3 </td><td>  0 </td><td>  22.0 </td><td>  one </td><td>  one </td><td>  12.2875 </td><td>  2 </td></tr></tbody></table><br><br><h4>  Construction of classification models and their analysis </h4><br>  Well, the data is processed and you can start building a model, but first you need to decide how we will check the accuracy of the model obtained.  For this test, we will use <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%25A1%25D0%25BA%25D0%25BE%25D0%25BB%25D1%258C%25D0%25B7%25D1%258F%25D1%2589%25D0%25B8%25D0%25B9_%25D0%25BA%25D0%25BE%25D0%25BD%25D1%2582%25D1%2580%25D0%25BE%25D0%25BB%25D1%258C">sliding controls</a> and <a href="http://ru.wikipedia.org/wiki/ROC-%25D0%25BA%25D1%2580%25D0%25B8%25D0%25B2%25D0%25B0%25D1%258F">ROC curves</a> .  We will perform the test on the training sample, after which we apply it to the test sample. <br>  So consider a few machine learning algorithms: <br><ul><li>  <a href="http://ru.wikipedia.org/wiki/%25CC%25E5%25F2%25EE%25E4_%25EE%25EF%25EE%25F0%25ED%25FB%25F5_%25E2%25E5%25EA%25F2%25EE%25F0%25EE%25E2">Support Vector Machine</a> <br></li><li>  <a href="http://ru.wikipedia.org/wiki/%25CC%25E5%25F2%25EE%25E4_k_%25E1%25EB%25E8%25E6%25E0%25E9%25F8%25E8%25F5_%25F1%25EE%25F1%25E5%25E4%25E5%25E9">Nearest Neighbor Method</a> <br></li><li>  <a href="http://ru.wikipedia.org/wiki/Random_forest">Random forest</a> <br></li><li>  <a href="http://ru.wikipedia.org/wiki/%25D0%259B%25D0%25BE%25D0%25B3%25D0%25B8%25D1%2581%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">Logistic regression</a> <br></li></ul><br>  Let's load the libraries we need: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cross_validation, svm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KNeighborsClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> roc_curve, auc <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pylab <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pl</code> </pre><br>  To begin with, it is necessary to divide our training sample into an indicator that we study, and its defining characteristics: <br><br><pre> <code class="python hljs">target = data.Survived train = data.drop([<span class="hljs-string"><span class="hljs-string">'Survived'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment">#    Id        kfold = 5 #    itog_val = {} #       </span></span></code> </pre><br>  Now our learning sample looks like this: <br><table border="1"><tbody><tr><th>  Pclass </th><th>  Sex </th><th>  Age </th><th>  Sibsp </th><th>  Parch </th><th>  Fare </th><th>  Embarked </th></tr><tr><td>  3 </td><td>  one </td><td>  28 </td><td>  one </td><td>  0 </td><td>  7.2500 </td><td>  2 </td></tr><tr><td>  one </td><td>  0 </td><td>  28 </td><td>  one </td><td>  0 </td><td>  71.2833 </td><td>  0 </td></tr><tr><td>  3 </td><td>  0 </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  7.9250 </td><td>  2 </td></tr><tr><td>  one </td><td>  0 </td><td>  28 </td><td>  one </td><td>  0 </td><td>  53.1000 </td><td>  2 </td></tr><tr><td>  3 </td><td>  one </td><td>  28 </td><td>  0 </td><td>  0 </td><td>  8.0500 </td><td>  2 </td></tr></tbody></table><br>  Now we divide the indicators obtained earlier into 2 subsamples (training and test) for calculating ROC curves (for sliding control, this is not necessary, since the verification function does it itself. The <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html">cross_validation</a> module‚Äôs <a href="http://scikit-learn.org/stable/modules/cross_validation.html">train_test_split</a> function will help us with this: <br><br><pre> <code class="python hljs">ROCtrainTRN, ROCtestTRN, ROCtrainTRG, ROCtestTRG = cross_validation.train_test_split(train, target, test_size=<span class="hljs-number"><span class="hljs-number">0.25</span></span>)</code> </pre><br>  As parameters, it is passed to: <br><ul><li>  Parameter Array <br></li><li>  Array of indicators <br></li><li>  The ratio in which the training set will be split (in our case, 1/4 of the data from the original training set will be allocated to the test set) <br></li></ul><br>  At the output, the function returns 4 arrays: <br><ol><li>  New learning array of parameters <br></li><li>  test array of parameters <br></li><li>  New array of indicators <br></li><li>  test array of indicators <br></li></ol><br><br>  Below are the listed methods with the best parameters selected by experience: <br><pre> <code class="python hljs">model_rfc = RandomForestClassifier(n_estimators = <span class="hljs-number"><span class="hljs-number">70</span></span>) <span class="hljs-comment"><span class="hljs-comment">#   -  model_knc = KNeighborsClassifier(n_neighbors = 18) #   -  model_lr = LogisticRegression(penalty='l1', tol=0.01) model_svc = svm.SVC() #  kernek='rbf'</span></span></code> </pre><br>  Now check the resulting models using the sliding control.  To do this, we need to use the cross_val_score function <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html">.</a> <br><pre> <code class="python hljs">scores = cross_validation.cross_val_score(model_rfc, train, target, cv = kfold) itog_val[<span class="hljs-string"><span class="hljs-string">'RandomForestClassifier'</span></span>] = scores.mean() scores = cross_validation.cross_val_score(model_knc, train, target, cv = kfold) itog_val[<span class="hljs-string"><span class="hljs-string">'KNeighborsClassifier'</span></span>] = scores.mean() scores = cross_validation.cross_val_score(model_lr, train, target, cv = kfold) itog_val[<span class="hljs-string"><span class="hljs-string">'LogisticRegression'</span></span>] = scores.mean() scores = cross_validation.cross_val_score(model_svc, train, target, cv = kfold) itog_val[<span class="hljs-string"><span class="hljs-string">'SVC'</span></span>] = scores.mean()</code> </pre><br>  Let's look at the graph of the average cross-test tests for each model: <br><br><pre> <code class="python hljs">DataFrame.from_dict(data = itog_val, orient=<span class="hljs-string"><span class="hljs-string">'index'</span></span>).plot(kind=<span class="hljs-string"><span class="hljs-string">'bar'</span></span>, legend=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/0c4/800/17d/0c480017dfbcc82215a8e568d3db0ecb.png" alt="image"><br><br>  As you can see from the graph, the RandomForest algorithm showed itself best of all.  Now let's take a look at the graphs of ROC-curves, to assess the accuracy of the classifier.  We will draw graphs using the <a href="http://matplotlib.org/">matplotlib</a> library: <br><br><pre> <code class="python hljs">pl.clf() plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) <span class="hljs-comment"><span class="hljs-comment">#SVC model_svc.probability = True probas = model_svc.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN) fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1]) roc_auc = auc(fpr, tpr) pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('SVC', roc_auc)) #RandomForestClassifier probas = model_rfc.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN) fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1]) roc_auc = auc(fpr, tpr) pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('RandonForest',roc_auc)) #KNeighborsClassifier probas = model_knc.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN) fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1]) roc_auc = auc(fpr, tpr) pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('KNeighborsClassifier',roc_auc)) #LogisticRegression probas = model_lr.fit(ROCtrainTRN, ROCtrainTRG).predict_proba(ROCtestTRN) fpr, tpr, thresholds = roc_curve(ROCtestTRG, probas[:, 1]) roc_auc = auc(fpr, tpr) pl.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % ('LogisticRegression',roc_auc)) pl.plot([0, 1], [0, 1], 'k--') pl.xlim([0.0, 1.0]) pl.ylim([0.0, 1.0]) pl.xlabel('False Positive Rate') pl.ylabel('True Positive Rate') pl.legend(loc=0, fontsize='small') pl.show()</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/2c5/ef2/a8c/2c5ef2a8ce2d782b09a08a5036cdfa68.png" alt="image"><br>  As can be seen from the results of ROC analysis, the best result again showed RandomForest.  Now it remains to apply our model to the test sample: <br><br><pre> <code class="python hljs">model_rfc.fit(train, target) result.insert(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-string"><span class="hljs-string">'Survived'</span></span>, model_rfc.predict(test)) result.to_csv(<span class="hljs-string"><span class="hljs-string">'Kaggle_Titanic/Result/test.csv'</span></span>, index=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre><br><br><h4>  Conclusion </h4><br>  In this article I tried to show how you can use the <b>pandas</b> package in conjunction with the <b>sklearn</b> machine learning <b>package</b> .  The resulting model with Kaggle submission showed an accuracy of 0.77033.  In the article, I wanted to show more precisely how to work with the tools and the progress of the research, rather than building a detailed algorithm, such as in <a href="http://habrahabr.ru/post/165001/">this</a> series of articles. </div><p>Source: <a href="https://habr.com/ru/post/202090/">https://habr.com/ru/post/202090/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../202072/index.html">KnpMenuBundle + Sonata. Making a menu from the base</a></li>
<li><a href="../202074/index.html">A 3D printer that prints metal products is available for pre-order for $ 750.</a></li>
<li><a href="../202078/index.html">MIT developed a physically changing screen</a></li>
<li><a href="../202080/index.html">We distribute servers for interesting projects.</a></li>
<li><a href="../202088/index.html">Optimization of applications for Android x86: proven methods</a></li>
<li><a href="../202092/index.html">Windows Virtual Servers: New Features</a></li>
<li><a href="../202096/index.html">Amazon offers AppStream developers to stream applications from the cloud</a></li>
<li><a href="../202098/index.html">Crutches notes</a></li>
<li><a href="../202100/index.html">Stasis - an isometric, sci-fi point-and-click adventure (Kickstarter Campaign)</a></li>
<li><a href="../202102/index.html">Minification of CSS and Javascript in the ASP.NET Website Project</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>