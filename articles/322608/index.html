<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Parsim weblancer using PROXY</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Objective 


1. Parsim website using proxy server. 
2. Save data in CSV format. 
3. We write a search engine based on the data found. 
4. We build the...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Parsim weblancer using PROXY</h1><div class="post__text post__text-html js-mediator-article"><h2>  Objective </h2><br><h4><ol><li>  Parsim website using proxy server. </li><li>  Save data in CSV format. </li><li>  We write a search engine based on the data found. </li><li>  We build the interface. </li></ol></h4><br><img src="https://habrastorage.org/files/2ee/bc8/fe8/2eebc8fe855d47e5a45df619b4c6c5b8.JPG"><br><br>  We will use the programming language Python.  The site from which we will download data is <a href="http://www.weblancer.net/">www.weblancer.net</a> (parsing the old version of this site was posted <a href="https://www.youtube.com/watch%3Fv%3DKPXPr-KS-qk%26t%3D301s">here</a> ), it has job offers at <a href="http://www.weblancer.net/jobs/">www.weblancer.net/jobs</a> .  From it we will receive data - this is the name, price, number of applications, category, a brief description of the proposed work. <br><br>  Logging in using a proxy means entering the site under a false address.  It is useful for parsing a site with a ban protection by IP address (that is, if you too often, within a short period of time, enter the site). <a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Import modules </h2><br><br>  Modules for directly parsing: requests and BeautifulSoup, they will be enough for us.  Save the data in csv format will help us a module with the same name - csv.  The tkinter module will help us with the interface, which is extremely painful (if you want a better interface, I advise you to use the <a href="https://pythonworld.ru/gui/pyqt5-firstprograms.html">pyQt5</a> module).  The work of searching and replacing data will be performed by the re module. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-comment"><span class="hljs-comment">#   HTTP- import urllib.request # HTTP from lxml import html #    xml  html,      html import re #     from bs4 import BeautifulSoup #    HTML import csv #     CSV import tkinter #  from tkinter.filedialog import * # </span></span></code> </pre> <br><h2>  Variables </h2><br><br>  We create an array, where we will store the previously used proxies, and two text variables, we equate the site‚Äôs address to the first one, and declare the second to be global (there are options when using global variables may adversely affect the program‚Äôs performance, learn more about its use <a href="https://pythonprogramming.net/global-local-variables/">here</a> ) get its data in functions. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">global</span></span> proxy1 <span class="hljs-comment"><span class="hljs-comment">#          proxy1 = '' #     BASE_URL = 'https://www.weblancer.net/jobs/' #    massiv = [] #   </span></span></code> </pre><br><br>  Variables for tkinter: <br><br><pre> <code class="python hljs">root = Tk() <span class="hljs-comment"><span class="hljs-comment">#  root.geometry('850x500') #       txt1 = Text(root, width = 18, heigh = 2) #      txt2 = Text(root, width = 60, heigh = 22) #     lbl4 = Label(root, text = '') #    btn1 = Button(root, text = ' ') #   btn2 = Button(root, text = '  ') #   btn3 = Button(root, text = ' ') #    lbl1 = Label(root, text = '    ') #   lbl2 = Label(root, text = '') #     lbl3 = Label(root, text = '') #    </span></span></code> </pre><br><br>  Variable.grid (row, column) - we define the location of the element in the display window.  Bind - keystroke.  The following code is placed at the very end of the program: <br><br><pre> <code class="python hljs">btn1.bind(<span class="hljs-string"><span class="hljs-string">'&lt;Button-1&gt;'</span></span>, main) <span class="hljs-comment"><span class="hljs-comment">#      btn2.bind('&lt;Button-1&gt;', poisk) #     btn3.bind('&lt;Button-1&gt;', delete) #    lbl2.grid(row = 4, column = 1) lbl4.grid(row = 5, column = 1) lbl3.grid(row = 3, column = 1) btn1.grid(row = 1, column = 1) btn3.grid(row = 2, column = 1) btn2.grid(row = 1, column = 2) lbl1.grid(row = 2, column = 2) txt1.grid(row = 3, column = 2) txt2.grid(row = 6, column = 3) root.mainloop() # </span></span></code> </pre><br><br><h2>  Main function </h2><br><br>  First of all, let's write the main function (why the function, not the procedure? In the future, we will need to start it with bind (keystroke), this is easier to do with the function), and later we will add other functions.  Procedures that will be useful to us: <br><br><ul><li>  config - makes changes to widget elements.  For example, we will replace the text in the Label widgets. </li><li>  update - used to update the widget.  Face the problem - the widget will be changed only after the completion of the cycle, update allows you to update the contents of the widget every pass of the cycle. </li><li>  re.sub (pattern, changeable string, string) - finds the pattern in the string and replaces it with the specified substring.  If the pattern is not found, the string remains unchanged. </li><li>  get - makes an http request, if it is equal to "200" - the entrance to the site was successful. </li><li>  content - allows you to get html-code. </li><li>  L.extend (K) - expands the list L, adding to the end all the elements of the list K </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(event)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     event (  ) page_count = get_page_count(get_html(BASE_URL)) #    ,     ,  http-   BASE_URL lbl3.config(text='  : '+str(page_count)) #    lbl3     page = 1 #   projects = [] #      while page_count != page: # ,   page      proxy = Proxy() # ,     proxy = proxy.get_proxy() # proxy- lbl4.update() #  lbl4.config(text=': '+proxy) #     global proxy1 #  proxy1 = proxy #       try: #   for i in range(1,10): #         (range - ,         ).       ,        page += 1 #      lbl2.update() #  lbl2.config(text=' %d%%'%(page / page_count * 100)) #     100% r = requests.get(BASE_URL + '?page=%d' % page, proxies={'https': proxy}) #     parsing = BeautifulSoup(r.content, "lxml") # html-   BeautifulSoup (      )       projects.extend(parse(BASE_URL + '?page=%d' % page, parsing)) #    parse (    html-)      save(projects, 'proj.csv') #     csv,    projects except requests.exceptions.ProxyError: #     continue #  while except requests.exceptions.ConnectionError: #    continue #  while except requests.exceptions.ChunkedEncodingError: #     ,    continue #  while</span></span></code> </pre><br><br><h2>  Counting pages </h2><br><br>  We write the function to get the url: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_html</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       url,   page_count[count] response = urllib.request.urlopen(url) #   ¬´¬ª  httplib,  ,          return response.read() #      read   </span></span></code> </pre><br><br>  Now with the url we are looking for all the pages: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_page_count</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(html)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    html soup = BeautifulSoup(html, 'html.parser') # html-  url ,   paggination = soup('ul')[3:4] #  ,     lis = [li for ul in paggination for li in ul.findAll('li')][-1] #       lis,         for link in lis.find_all('a'): #         var1 = (link.get('href')) #   var2 = var1[-3:] # ,     return int(var2) #     </span></span></code> </pre><br><br><h2>  Getting proxy </h2><br><br>  The code was partially taken from <a href="https://www.youtube.com/channel/UCSgiQqbW5j9xOZqSJafi_VQ/featured">Igor Danilov</a> .  We will use <a href="http//younglinux.info/oopython/init.php">__init __ (self)</a> - the class constructor, where self is the element in whose place the object is substituted at the time of its creation.  Important!  __init__ with two underscores on each side. <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Proxy</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  proxy_url = 'http://www.ip-adress.com/proxy_list/' #   ,  - proxy_list = [] #    def __init__(self): #      self r = requests.get(self.proxy_url) #http-  get,       url str = html.fromstring(r.content) #    lxml.html.HtmlElement result = str.xpath("//tr[@class='odd']/td[1]/text()") #           for i in result: #    if i in massiv: #       yy = result.index(i) #       result del result[yy] #  result   self.list = result #    def get_proxy(self): #    self for proxy in self.list: #      if 'https://'+proxy == proxy1: #,        ,  : global massiv #massiv   massiv = massiv + [proxy] #    url = 'https://'+proxy #    return url # </span></span></code> </pre><br><br><h2>  Page parsing </h2><br><br>  Now we find on each page of the site we need the data.  New procedures: <br><br><ul><li>  find_all - in the html-code of the page searches for blocks and elements that are in it. </li><li>  text - retrieving from the html-code only the text displayed on the site. </li><li>  L.append (K) - adds the element K to the end of the list L. </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(html,parsing)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     html  parsing projects = [] #  ,       table = parsing.find('div' , {'class' : 'container-fluid cols_table show_visited'}) #  html-,  , , ,  ,   for row in table.find_all('div' , {'class' : 'row'}): #   cols = row.find_all('div') #   price = row.find_all('div' , {'class' : 'col-sm-1 amount title'}) #   cols1 = row.find_all('div' , {'class' : 'col-xs-12' , 'style' : 'margin-top: -10px; margin-bottom: -10px'}) #    if cols1==[]: #   , application_text = '' #    else: #   application_text = cols1[0].text #    html- cols2 = [category.text for category in row.find_all('a' , {'class' : 'text-muted'})] #        projects.append({'title': cols[0].a.text, 'category' : cols2[0], 'applications' : cols[2].text.strip(), 'price' : price[0].text.strip() , 'description' : application_text}) #  projects      return projects #   </span></span></code> </pre><br><br><h2>  Cleaning function </h2><br><br>  The only procedure necessary for us to delete is to delete an object by the specified identifier or tag. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(event)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  txt1.delete(1.0, END) #     txt2.delete(1.0, END) #    </span></span></code> </pre><br><br><h2>  Search data </h2><br><br>  The function will search for sentences in the description of which the words we need are mentioned.  Writing in the field will have to be carried out taking into account the knowledge of regular expressions (for example, python | Python, C \ + \ +). <br><br><ul><li>  csv.DictReader - the constructor returns iterator objects to read <br>  data from file. </li><li>  split - splits a line into parts using a separator, and returns these parts as a list. </li><li>  join - converts a list into a string, treating each element as a string. </li><li>  insert - add items to the list by index. </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">poisk</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(event)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     event    file = open("proj.csv", "r") # ,      rdr = csv.DictReader(file, fieldnames = ['name', 'categori', 'zajavki', 'case', 'opisanie']) #      poisk = txt1.get(1.0, END) #       poisk = poisk[0:len(r)-1] #     ,     ('\n') for rec in rdr: # ,     csv- data = rec['opisanie'].split(';') #       data1 = rec['case'].split(';') #       data = ('').join(data) #   data1 = ('').join(data1) #   w = re.findall(poisk, data) #       if w != []: #,   w    ,   if data1 == '': # ,     ,   data1 = '' #     txt2.insert(END, data+'--'+data1+'\n'+'---------------'+'\n') #   ,  ,    , ,        </span></span></code> </pre><br><br><h2>  Saving data </h2><br><br>  As already said: the data will be saved in csv format.  If you wish, you can rewrite the function for any other format. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">save</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(projects, path)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#         path with open(path, 'w') as csvfile: #   path  w (    .     .     _,    ) writer = csv.writer(csvfile) #writer -   , csv -    writer.writerow(('', '', '' , '' , '')) #writerow -      for project in projects: #    try: #   writer.writerow((project['title'], project['category'], project['applications'], project['price'], project['description'])) #    except UnicodeEncodeError: # description       ,      writer.writerow((project['title'], project['category'], project['applications'], project['price'], '')) #   </span></span></code> </pre><br><br>  I hope this information will be useful in your work.  Good luck. <br><br></div><p>Source: <a href="https://habr.com/ru/post/322608/">https://habr.com/ru/post/322608/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../322598/index.html">Doom engine source code analysis: rendering</a></li>
<li><a href="../322600/index.html">IoT Security: Securing Azure IoT Deployment</a></li>
<li><a href="../322602/index.html">Why i ignore google recruiters</a></li>
<li><a href="../322604/index.html">Query translation to SQL using LinqToSql in tests</a></li>
<li><a href="../322606/index.html">Experience preparing and passing the Oracle Certified Professional Java SE 8 Programmer 1Z0-810 exam</a></li>
<li><a href="../322610/index.html">The digest of interesting materials for the mobile # 192 developer (February 20-26)</a></li>
<li><a href="../322612/index.html">Perspective API is available for developers.</a></li>
<li><a href="../322614/index.html">Overview of automated paid parking systems</a></li>
<li><a href="../322616/index.html">Setting up DKIM / SPF / DMARC records or defending against spoofing</a></li>
<li><a href="../322618/index.html">Visualization of JavaScript exchange sorting algorithms</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>