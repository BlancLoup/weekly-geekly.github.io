<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Whiskers, paws and tail: how does a neural network recognize cats and other objects?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Image recognition is a classic example of the use of neural networks. Recall how the network learning process takes place, what difficulties arise and...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Whiskers, paws and tail: how does a neural network recognize cats and other objects?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/f98/0bb/ba2/f980bbba20ad95e4e6b400351f436658.jpg" alt="image"><br><br>  Image recognition is a classic example of the use of neural networks.  Recall how the network learning process takes place, what difficulties arise and why use biology in development.  Details under the cut. <br><a name="habracut"></a><br>  <i>Dmitry Soshnikov, a technical evangelist of Microsoft, a member of the Russian Association of Artificial Intelligence, a teacher of functional and logical programming of AI in MAI, MIPT and HSE, as well as our <a href="https://binarydistrict.com/ru/%3Futm_sourse%3Dhabr">courses</a> will help us in the story.</i> <br><br>  Imagine that we have a lot of pictures that need to be sorted in two piles using a neural network.  How can this be done?  Of course, everything depends on the objects themselves, but we can always identify some features. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We need to know as much information as possible about the input data and take it into account when entering manually, even before learning the network.  For example, if we have a task to detect multi-colored cats in a picture, it is not the color that is important, but the shape of the object.  When we get rid of color by going to a black and white image, the network will learn much faster and more successfully: it will have to recognize several times less information. <br><br>  For recognizing arbitrary objects, for example, cats and frogs, the color is obviously important: the frog is green, and cats are not.  If we leave color channels, for each palette, the network learns to re-recognize image objects, because this color channel is fed to other neurons. <br><br>  And if we want to destroy the famous meme about cats and bread, having taught the neural network to detect an animal in any picture?  It would seem that the colors and shape are approximately the same.  What to do then? <br><br><h3>  Filter banks and biological vision </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0p/pb/az/0ppbaztk2umnpdurzir6qbcvrsm.png" alt="image"></div><br><br>  Using different filters, you can select different image fragments, which are then detected and explored as separate properties.  For example, to submit to the input of traditional machine learning or neural networks.  If the neural network has additional information about the structure of objects with which it works, the quality of work increases. <br><br>  In the field of machine vision, filter banks have been accumulated - filter sets to highlight the main features of objects. <br><br>  Similar "architecture" is used in biology.  Scientists believe that human vision does not determine the entire image as a whole, but highlights the characteristic features and unique features by which the brain identifies an object.  Accordingly, for quick and correct recognition of the object, you can define the most unique features.  For example, cats can have whiskers - fan horizontal dashes on the image. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/baa/b9e/4b9/baab9e4b97aceb77ec70abeda6be022d.png" alt="image"></div><br><br><h4>  Weight Sharing </h4><br>  So that the network does not have to learn separately to recognize cats in different parts of the picture, we ‚Äúshare‚Äù the weights responsible for recognition between different fragments of input signals. <br><br>  This requires a specialized network architecture: <br><br><ul><li>  image convolutional networks </li><li>  text / string recurrent networks </li></ul><br>  Neural networks that are effectively used in image recognition, which use special convolutional layers (Convolution Layers). <br><br>  The basic idea is this: <br><br><ul><li>  Use weight sharing to create a ‚Äúfilter window‚Äù running through the image. </li><li>  The filter applied to the image helps to identify fragments that are important for recognition. </li><li>  While in traditional machine vision, filters are designed by hand, neural networks allow us to construct optimal filters through training. </li><li>  Image filtering can be naturally combined with neural network calculation. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/397/495/585/397495585e3328991240440dad9d42fa.gif" alt="image"></div><br>  For image processing, convolution is used, as in signal processing. <br><br>  We describe the convolution function with the following parameters: <br><br><ul><li>  kernel - the core of the bundle, the weights matrix </li><li>  pad - how many pixels should be added to the image along the edges </li><li>  stride - the frequency of the filter.  For example, for stride = 2, we will take every second pixel of the image vertically and horizontally, reducing the resolution by half </li></ul><br><pre><code class="markdown hljs">In [1]: def convolve(image, kernel, pad = 0, stride = 1): rows, columns = image.shape output<span class="hljs-emphasis"><span class="hljs-emphasis">_rows = rows // stride output_</span></span>columns = columns // stride result = np.zeros((output<span class="hljs-emphasis"><span class="hljs-emphasis">_rows, output_</span></span>columns)) if pad &gt; 0: image = np.pad(image, pad, 'constant') kernel<span class="hljs-emphasis"><span class="hljs-emphasis">_size = kernel.size kernel_</span></span>length = kernel.shape[0] half<span class="hljs-emphasis"><span class="hljs-emphasis">_kernel = kernel_</span></span>length // 2 kernel<span class="hljs-emphasis"><span class="hljs-emphasis">_flat = kernel.reshape(kernel_</span></span>size, 1) offset = builtins.abs(half<span class="hljs-emphasis"><span class="hljs-emphasis">_kernel-pad) for r in range(offset, rows - offset, stride): for c in range(offset, columns - offset, stride): rr = r - half_</span></span>kernel + pad cc = c - half<span class="hljs-emphasis"><span class="hljs-emphasis">_kernel + pad patch = image[rr:rr + kernel_</span></span>length, cc:cc + kernel<span class="hljs-emphasis"><span class="hljs-emphasis">_length] result[r//stride,c//stride] = np.dot(patch.reshape(1, kernel_</span></span>size), kernel_flat) return result</code> </pre> <br><pre> <code class="markdown hljs">In [2]: def show<span class="hljs-emphasis"><span class="hljs-emphasis">_convolution(kernel, stride = 1): """Displays the effect of convolving with the given kernel.""" fig = pylab.figure(figsize = (9,9)) gs = gridspec.GridSpec(3, 3, height_</span></span>ratios=[3,1,3]) start=1 for i in range(3): image = images<span class="hljs-emphasis"><span class="hljs-emphasis">_train[start+i,0] conv = convolve(image, kernel, kernel.shape[0]//2, stride) ax = fig.add_</span></span>subplot(gs[i]) pylab.imshow(image, interpolation='nearest') ax.set<span class="hljs-emphasis"><span class="hljs-emphasis">_xticks([]) ax.set_</span></span>yticks([]) ax = fig.add<span class="hljs-emphasis"><span class="hljs-emphasis">_subplot(gs[i + 3]) pylab.imshow(kernel, cmap='gray', interpolation='nearest') ax.set_</span></span>xticks([]) ax.set<span class="hljs-emphasis"><span class="hljs-emphasis">_yticks([]) ax = fig.add_</span></span>subplot(gs[i + 6]) pylab.imshow(conv, interpolation='nearest') ax.set<span class="hljs-emphasis"><span class="hljs-emphasis">_xticks([]) ax.set_</span></span>yticks([]) pylab.show()</code> </pre><br><pre> <code class="markdown hljs">In [3]: blur<span class="hljs-emphasis"><span class="hljs-emphasis">_kernel = np.array([[1, 4, 7, 4, 1], [4, 16, 26, 16, 4], [7, 26, 41, 26, 7], [4, 16, 26, 16, 4], [1, 4, 7, 4, 1]], dtype='float32') blur_</span></span>kernel /= 273</code> </pre><br><h3>  Filters </h3><br><h4>  Blur </h4><br>  The blur filter smooths out bumps and emphasizes the overall shape of objects. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t-/ho/vk/t-hovkjzscxtnmp2lp3qkcitp5g.png" alt="image"></div><br><pre> <code class="markdown hljs">In [4]: show<span class="hljs-emphasis"><span class="hljs-emphasis">_convolution(blur_</span></span>kernel)</code> </pre><br><h4>  Vertical edges </h4><br>  You can come up with a filter that highlights the vertical brightness transitions in the image.  Here, blue indicates the transition from black to white, yellow - vice versa. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xh/wk/bu/xhwkbu2o-aiah05inmkk5787unu.png" alt="image"></div><br><pre> <code class="markdown hljs">In [5]: vertical<span class="hljs-emphasis"><span class="hljs-emphasis">_edge_</span></span>kernel = np.array([[1, 4, 0, -4, 1], [4, 16, 0, -16, -4], [7, 26, 0, -26, -7], [4, 16, 0, -16, -4], [1, 4, 0, -4, -1]], dtype='float32') vertical<span class="hljs-emphasis"><span class="hljs-emphasis">_edge_</span></span>kernel /= 166</code> </pre><br><pre> <code class="markdown hljs">In [6]: show<span class="hljs-emphasis"><span class="hljs-emphasis">_convolution(vertical_</span></span>edge_kernel)</code> </pre><br><h4>  Horizontal edges </h4><br>  A similar filter can be constructed to highlight horizontal strokes in the image. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2i/ag/te/2iagteuxowjga-n39ppn1reg8na.png"></div><br><pre> <code class="markdown hljs">In [7]: horizontal<span class="hljs-emphasis"><span class="hljs-emphasis">_bar_</span></span>kernel = np.array([[0, 0, 0, 0, 0], [-2, -8, -13, -8, -2], [4, 16, 26, 16, 4], [-2, -8, -13, -8, -2], [0, 0, 0, 0, 0]], dtype='float32') horizontal<span class="hljs-emphasis"><span class="hljs-emphasis">_bar_</span></span>kernel /= 132</code> </pre><br><pre> <code class="markdown hljs">In [8]: show<span class="hljs-emphasis"><span class="hljs-emphasis">_convolution(horizontal_</span></span>bar_kernel)</code> </pre><br><h4>  Contour filter </h4><br>  You can also build a 9x9 filter that will highlight the edges of the image. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ts/1a/qw/ts1aqwsom1zbwqfvqh4lciubbv4.png"></div><br><pre> <code class="markdown hljs">In [9]: blob<span class="hljs-emphasis"><span class="hljs-emphasis">_kernel = np.array([[0, 1, 1, 2, 2, 2, 1, 1, 0], [1, 2, 4, 5, 5, 5, 4, 2, 1], [1, 4, 5, 3, 0, 3, 5, 4, 1], [2, 5, 3, -12, -24, -12, 3, 5, 2], [2, 5, 0, -24, -40, -24, 0, 5, 2], [2, 5, 3, -12, -24, -12, 3, 5, 2], [1, 4, 5, 3, 0, 3, 5, 4, 1], [1, 2, 4, 5, 5, 5, 4, 2, 1], [0, 1, 1, 2, 2, 2, 1, 1, 0]], dtype='float32') blob_</span></span>kernel /= np.sum(np.abs(blob_kernel))</code> </pre><br><pre> <code class="markdown hljs">In [10]: show<span class="hljs-emphasis"><span class="hljs-emphasis">_convolution(blob_</span></span>kernel)</code> </pre><br>  Thus, the classic example of digit recognition works: each digit has its own characteristic geometric features (two circles - eight, slash for half of the image - unit, etc.), according to which the neural network can determine what kind of object it is.  We create filters that characterize each digit, we run each of the filters through the image and minimize the error. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ig/ao/jm/igaojmwnq19n-ptfls8idazsme0.png" alt="image"></div><br>  If you apply a similar approach to the search for cats in the picture, it quickly turns out that there are many signs of a quadruped for learning neural network, and they are all different: tails, ears, whiskers, noses, wool and color.  And each cat can have nothing to do with the other.  A neural network with a small amount of data on the structure of the object will not be able to understand that one cat lies, and the second is on its hind legs. <br><br><h3>  The basic idea of ‚Äã‚Äãthe convolution network </h3><br><ul><li>  Create a convolutional layer in the neural network, which ensures the application of the filter to the image. </li><li>  We teach filter weights using the back distribution algorithm. </li></ul><br>  For example, we have an image <i>i</i> , 2 convolution filters <i>w</i> with outputs <i>o</i> .  Elements of the output image will be calculated as follows: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0d/zv/c1/0dzvc1tzmrh9aliul6rtvjysxxq.png"></div><br><h3>  Weight training </h3><br>  The algorithm is as follows: <br><br><ul><li>  A filter with the same weights is applied to all pixels of the image. </li><li>  At the same time, the filter ‚Äúruns through‚Äù the entire image. </li><li>  We want to train these weights (common to all pixels) using the backpropagation algorithm. </li><li>  For this it is necessary to reduce the application of the filter to a single multiplication of matrices. </li><li>  In contrast to the full layer layer, there will be fewer training scales, and more examples. </li><li>  Trick - im2col </li></ul><br><h4>  im2col </h4><br>  Let's start with the image x, where each pixel corresponds to a letter: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ce/mr/ih/cemrihdsv3ieli38vm1iyhehgza.png"></div><br>  Then we extract all 3x3 image fragments and place them in the columns of the large matrix X: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/er/rs/it/errsits8bxfqew7x9-raodafjge.png"></div><br>  Now we can save the filter weights in the usual matrix, where each row corresponds to one convolution filter: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qx/od/tm/qxodtmopxeyug1z6c0wkmcha8pi.png"></div><br>  Then the convolution over the entire image turns into a regular matrix multiplication: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_3/_n/wr/_3_nwrc6_rnkqwg6545e2x8jloq.png"></div><br><h3>  Image analysis problems </h3><br>  In the process of learning, many pitfalls can arise: incorrect sampling already on the second layer will ruin the whole learning process, it may not be large enough, because of which the network will not learn to detect all possible positions of the object features. <br><br>  There is a reverse situation: with an increase in the number of layers, the gradient damping occurs, too many parameters appear, and the function can get stuck in a local minimum. <br><br>  In the end, the curve code, too, has not been canceled. <br><br>  To teach how to work with neural networks, to cope with its training and to determine where it is possible to use machine learning in practice, Dmitry Soshnikov and I developed a special Neuro Workshop course.  Of course, it also describes how to solve the problems listed above. <br><br>  Neuro Workshop will be held 2 times: <br><br><ul><li>  <a href="https://binarydistrict.com/ru/courses/neuro-workshop/%3Futm_sourse%3Dhabr">12 May</a> </li><li>  <a href="https://binarydistrict.com/ru/courses/neuro-workshop-26-05-2018/%3Futm_sourse%3Dhabr">26 of May</a> </li></ul><br>  Choose a convenient day, come and ask Dmitry your questions. </div><p>Source: <a href="https://habr.com/ru/post/354524/">https://habr.com/ru/post/354524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../354512/index.html">How to use trams to make it easier for a taxi driver to find you</a></li>
<li><a href="../354516/index.html">There is work in RnD, or how to get away from monotonous and minor tasks</a></li>
<li><a href="../354518/index.html">And if we do not design a system for managing the production of IT products. Part 3. Infrastructure support</a></li>
<li><a href="../354520/index.html">How I wanted to teach others, and as a result I learned myself</a></li>
<li><a href="../354522/index.html">How is the recruitment at the department ABBYY in MIPT</a></li>
<li><a href="../354526/index.html">New "work" for GPUs: GPU will protect against virus attacks</a></li>
<li><a href="../354530/index.html">Art for IT</a></li>
<li><a href="../354532/index.html">Java 9 modules and dependency injection: using Guice</a></li>
<li><a href="../354536/index.html">The experience of the transition to the Atlassian Stride (from the word Suffer)</a></li>
<li><a href="../354538/index.html">How I found a bug in the Avios Travel system and got thousands of valid points for aviation miles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>