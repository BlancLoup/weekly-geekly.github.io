<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Setting up a small Hadoop 2.2.0 cluster from scratch</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article, the process of creating a small Hadoop cluster for experiments will be taken apart in steps. 

 Despite the fact that there are a lot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Setting up a small Hadoop 2.2.0 cluster from scratch</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/b1b/ba9/391/b1bba93918fcd31dcd41dd83b9860542.png"><br><br>  In this article, the process of creating a small Hadoop cluster for experiments will be taken apart in steps. <br><br>  Despite the fact that there are a lot of material on configuring / deploying Hadoop on the Internet on foreign resources, most of them either describe configuration of earlier versions (0.XX and 1.XX), or describe only configuration in single mode / pseudo distributed mode and only partially fully distributed mode.  There is practically no material in Russian at all. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      When I needed Hadoop myself, I was far from the first time able to set everything up.  The material was irrelevant, there were often configs that use deprecated parameters, so it is undesirable to use them.  And even when everything was set up, I asked many questions to which I was looking for answers.  There were also similar <a href="http://toster.ru/q/57046">questions</a> from other people. <br><br>  Anyone interested, please come on cat. <br><a name="habracut"></a><br><h4>  Presets </h4><br>  As an operating system for our cluster, I suggest using <a href="http://www.ubuntu.com/download/server">Ubuntu Server 12.04.3 LTS</a> , but with minimal changes it will be possible to do all the steps on a different OS. <br><br>  All nodes will work on VirtualBox.  System settings for the virtual machine, I exhibited small.  Only 8 GB of space for the hard disk, one core and 512 MB of memory.  The virtual machine is also equipped with two network adapters: one is NAT and the other is for the internal network. <br><br>  After the operating system has been downloaded and installed, you need to upgrade and install ssh and rsync: <br><pre><code class="bash hljs">sudo apt-get update &amp;&amp; sudo apt-get upgrade sudo apt-get install ssh sudo apt-get install rsync</code> </pre> <br><br><h4>  Java </h4><br>  For Hadoop, you can use either version 6 or version 7. <br>  In this article we will work with OpenJDK version 7: <br><br><pre> <code class="bash hljs">$ sudo apt-get install openjdk-7-jdk</code> </pre><br><br>  Although you can use a version from Oracle. <br><br><div class="spoiler">  <b class="spoiler_title">And How?</b> <div class="spoiler_text">  Clean up the OS from all dependencies OpenJDK sudo apt-get purge openjdk * <br>  Install python-software-properties which allows you to add new PPA: <br><pre> <code class="bash hljs">sudo apt-get install python-software-properties</code> </pre><br>  Add PPA from <a href="https://launchpad.net/~webupd8team/%2Barchive/java">launchpad.net/~webupd8team/+archive/java</a> <br><pre> <code class="bash hljs">sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java7-installer</code> </pre><br>  Read more: <a href="http://www.webupd8.org/2012/01/install-oracle-java-jdk-7-in-ubuntu-via.html">INSTALL ORACLE JAVA 7 IN UBUNTU VIA PPA REPOSITORY</a> <br></div></div><br><br><h4>  Create a separate account to run Hadoop </h4><br>  We will use the dedicated account to run Hadoop.  This is not required, but recommended.  We will also give the new user sudo rights to make their lives easier in the future. <br><br><pre> <code class="bash hljs">sudo addgroup hadoop sudo adduser --ingroup hadoop hduser sudo usermod -aG sudo hduser</code> </pre><br><br>  When creating a new user, you will need to enter a password. <br><br><h4>  / etc / hosts </h4><br>  We need all nodes to easily communicate with each other.  In a large cluster, it is advisable to use the dns server, but the hosts file will be suitable for our small configuration.  In it, we will describe the correspondence of the node ip-address to its name on the network.  For a single node, your file should look something like this: <br><br><pre> <code class="bash hljs">127.0.0.1 localhost <span class="hljs-comment"><span class="hljs-comment"># The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 192.168.0.1 master</span></span></code> </pre><br><br><h4>  Ssh </h4><br>  To manage the cluster nodes hadoop, you need ssh access.  For the created user hduser, grant access to master. <br>  First you need to generate a new ssh key: <br><br><pre> <code class="bash hljs">ssh-keygen -t rsa -P <span class="hljs-string"><span class="hljs-string">""</span></span></code> </pre><br><br>  During key creation a password will be requested.  Now you can not enter it. <br><br>  The next step is to add the generated key to the list of authorized: <br><br><pre> <code class="bash hljs">cat <span class="hljs-variable"><span class="hljs-variable">$HOME</span></span>/.ssh/id_rsa.pub &gt;&gt; <span class="hljs-variable"><span class="hljs-variable">$HOME</span></span>/.ssh/authorized_keys</code> </pre><br><br>  We check the performance by connecting to yourself: <br><br><pre> <code class="bash hljs">ssh master</code> </pre><br><br><h4>  Disable IPv6 </h4><br>  If you do not disable IPv6, then later you can get a lot of problems. <br>  To disable IPv6 in Ubuntu 12.04 / 12.10 / 13.04, you need to edit the sysctl.conf file: <br><br><pre> <code class="bash hljs">sudo vim /etc/sysctl.conf</code> </pre><br><br>  Add the following parameters: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># IPv6 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1</span></span></code> </pre><br><br>  Save and reboot the operating system. <br><br><div class="spoiler">  <b class="spoiler_title">But I need IPv6!</b> <div class="spoiler_text">  To disable ipv6 only in hadoop, you can add it to the file etc / hadoop / hadoop-env.sh: <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> HADOOP_OPTS=-Djava.net.preferIPv4Stack=<span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre><br></div></div><br><br><h4>  Install Apache Hadoop </h4><br>  Download the necessary files. <br>  Current versions of the framework are located at: <a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/">www.apache.org/dyn/closer.cgi/hadoop/common</a> <br><br>  As of December 2013, the stable version is 2.2.0. <br><br>  Create a downloads folder in the root directory and download the latest version: <br><br><pre> <code class="bash hljs">sudo mkdir /downloads <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> downloads/ sudo wget http://apache-mirror.rbc.ru/pub/apache/hadoop/common/stable/hadoop-2.2.0.tar.gz</code> </pre><br><br>  Unpack the contents of the package in / usr / local /, rename the folder and give the user hduser creator rights: <br><br><pre> <code class="bash hljs">sudo mv /downloads/hadoop-2.2.0.tar.gz /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/ sudo tar xzf hadoop-2.2.0.tar.gz sudo mv hadoop-2.2.0 hadoop chown -R hduser:hadoop hadoop</code> </pre><br><br><h4>  $ HOME / .bashrc Update </h4><br>  For convenience, let's add a list of variables to .bashrc: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#Hadoop variables export JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-i386 export HADOOP_INSTALL=/usr/local/hadoop export PATH=$PATH:$HADOOP_INSTALL/bin export PATH=$PATH:$HADOOP_INSTALL/sbin export HADOOP_MAPRED_HOME=$HADOOP_INSTALL export HADOOP_COMMON_HOME=$HADOOP_INSTALL export HADOOP_HDFS_HOME=$HADOOP_INSTALL export YARN_HOME=$HADOOP_INSTALL</span></span></code> </pre><br><br>  At this step, the preliminary preparations are completed. <br><h4>  Apache Hadoop setup </h4><br><br>  All subsequent work will be carried out from the / usr / local / hadoop folder. <br>  Open etc / hadoop / hadoop-env.sh and set JAVA_HOME. <br><br><pre> <code class="bash hljs">vim /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/hadoop/etc/hadoop/hadoop-env.sh</code> </pre><br><br>  We describe what nodes we will have in the cluster in the file etc / hadoop / slaves <br><br><pre> <code class="bash hljs">master</code> </pre><br><br>  This file can be located only on the main node.  All new nodes need to be described here. <br><br>  The main system settings are located in etc / hadoop / core-site.xml: <br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>fs.defaultFS<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>hdfs://master:9000<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br>  HDFS settings are in etc / hadoop / hdfs-site.xml: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>dfs.replication<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>1<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>dfs.namenode.name.dir<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>file:/usr/local/hadoop/tmp/hdfs/namenode<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>dfs.datanode.data.dir<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>file:/usr/local/hadoop/tmp/hdfs/datanode<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br>  Here, the dfs.replication parameter sets the number of replicas that will be stored on the file system.  By default, its value is <br><br>  3. It can not be more than the number of nodes in the cluster. <br>  The dfs.namenode.name.dir and dfs.datanode.data.dir parameters specify the paths where the HDFS data and information will be physically located.  You must create a tmp folder in advance. <br><br>  Let our cluster know that we want to use YARN.  To do this, change the etc / hadoop / mapred-site.xml: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>mapreduce.framework.name<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>yarn<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br>  All settings for YARN work are described in the file etc / hadoop / yarn-site.xml: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.nodemanager.aux-services<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>mapreduce_shuffle<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.resourcemanager.scheduler.address<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>master:8030<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.resourcemanager.address<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>master:8032<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.resourcemanager.webapp.address<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>master:8088<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>master:8031<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>yarn.resourcemanager.admin.address<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>master:8033<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br>  The resourcemanager settings are needed so that all nodes in the cluster can be seen in the control panel. <br><br>  Format HDFS: <br><pre> <code class="bash hljs">bin/hdfs namenode ‚Äìformat</code> </pre><br><br>  Run the hadoop service: <br><br><pre> <code class="bash hljs">sbin/start-dfs.sh sbin/start-yarn.sh</code> </pre><br><br>  * In the previous version of Hadoop, the sbin / start-all.sh script was used, but since version 2. *. * It has been declared obsolete. <br><br>  You need to make sure that the following java-processes are running: <br><pre> <code class="bash hljs">hduser@master:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/hadoop$ jps 4868 SecondaryNameNode 5243 NodeManager 5035 ResourceManager 4409 NameNode 4622 DataNode 5517 Jps</code> </pre><br><br>  You can test the cluster using standard examples: <br><br><pre> <code class="bash hljs">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar</code> </pre><br><br>  Now we have a ready-made image, which will serve as the basis for creating a cluster. <br><br>  Then you can create the required number of copies of our image. <br><br>  On the copies you need to configure the network.  It is necessary to generate new MAC addresses for network interfaces and issue the necessary ip-addresses to them.  In my example, I work with addresses like 192.168.0.X. <br><br>  Correct the / etc / hosts file on all nodes of the cluster so that it contains all matches. <br><br><div class="spoiler">  <b class="spoiler_title">Example</b> <div class="spoiler_text"><pre> <code class="bash hljs">127.0.0.1 localhost <span class="hljs-comment"><span class="hljs-comment"># The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 192.168.0.1 master 192.168.0.2 slave1 192.168.0.3 slave2</span></span></code> </pre><br></div></div><br><br>  For convenience, change the names of the new nodes on slave1 and slave2. <br><br><div class="spoiler">  <b class="spoiler_title">How?</b> <div class="spoiler_text">  Two files need to be changed: / etc / hostname and / etc / hosts. <br></div></div><br><br>  Generate new SSH keys on the nodes and add them all to the list of authorized ones on the master node. <br><br>  On each node in the cluster, we will change the dfs.replication parameter values ‚Äã‚Äãin etc / hadoop / hdfs-site.xml.  For example, set the value to 3 everywhere. <br><div class="spoiler">  <b class="spoiler_title">etc / hadoop / hdfs-site.xml</b> <div class="spoiler_text"><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>dfs.replication<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span>3<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">value</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">property</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">configuration</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br></div></div><br><br>  Add new nodes on the master node to the etc / hadoop / slaves file: <br><br><pre> <code class="bash hljs">master slave1 slave2</code> </pre><br><br>  When all settings are registered, then we can start our cluster on the main node. <br><br><pre> <code class="bash hljs">bin/hdfs namenode ‚Äìformat sbin/start-dfs.sh sbin/start-yarn.sh</code> </pre><br><br>  The following processes should start on the slaves: <br><br><pre> <code class="bash hljs">hduser@slave1:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/hadoop$ jps 1748 Jps 1664 NodeManager 1448 DataNode</code> </pre><br><br>  Now we have our own mini cluster. <br><br>  Let's run the Word Count task. <br>  To do this, we need to load several text files into HDFS. <br>  For example, I took books in txt format from the <a href="http://www.gutenberg.org/">Free ebooks</a> site <a href="http://www.gutenberg.org/">- Project Gutenberg</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Test files</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/hduser mkdir books <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> books wget http://www.gutenberg.org/cache/epub/20417/pg20417.txt wget http://www.gutenberg.org/cache/epub/5000/pg5000.txt wget http://www.gutenberg.org/cache/epub/4300/pg4300.txt wget http://www.gutenberg.org/cache/epub/972/pg972.txt wget http://www.gutenberg.org/cache/epub/132/pg132.txt wget http://www.gutenberg.org/cache/epub/1661/pg1661.txt wget http://www.gutenberg.org/cache/epub/19699/pg19699.txt</code> </pre><br></div></div><br>  Transfer our files to HDFS: <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/hadoop bin/hdfs dfs -mkdir /<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> bin/hdfs dfs -copyFromLocal /home/hduser/books/* /<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> bin/hdfs dfs -ls /<span class="hljs-keyword"><span class="hljs-keyword">in</span></span></code> </pre><br><br>  Run Word Count: <br><br><pre> <code class="bash hljs">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /out</code> </pre><br><br>  You can track the work through the console, or through the ResourceManager‚Äôs web interface at <a href="http://master/">master</a> : 8088 / cluster / apps / <br><br>  Upon completion, the result will be located in the / out folder in HDFS. <br>  In order to download it to the local file system let's execute: <br><pre> <code class="bash hljs">bin/hdfs dfs -copyToLocal /out /home/hduser/</code> </pre><br><br>  If you have any questions, ask them in the comments. </div><p>Source: <a href="https://habr.com/ru/post/206196/">https://habr.com/ru/post/206196/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../206182/index.html">Transformation of threats in the information space: from technological to social. Part II</a></li>
<li><a href="../206186/index.html">Open Terminal Client - First Step</a></li>
<li><a href="../206188/index.html">Taskurotta or process management in a distributed system</a></li>
<li><a href="../20619/index.html">Update Google Gears 0.2 - all focus on WorkerPoll</a></li>
<li><a href="../206192/index.html">DIY mini-desktop</a></li>
<li><a href="../206198/index.html">A passion for programming. Chapter 10. Fall in Love or Throw It</a></li>
<li><a href="../2062/index.html">The web has overstepped the mark of 100 million websites.</a></li>
<li><a href="../20620/index.html">FeedJournal: Kill a tree - make a newspaper of your favorite RSS.</a></li>
<li><a href="../206200/index.html">Video calls through the browser - how to make technology work for your company</a></li>
<li><a href="../206202/index.html">Skeptics list</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>