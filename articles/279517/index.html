<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We write VoIP iOS chat on CORE AUDIO for VK Mobile Challenge contest</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, the VC team announced a competition to develop a mobile application that would expand the capabilities of the social network " VKontakte ", ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We write VoIP iOS chat on CORE AUDIO for VK Mobile Challenge contest</h1><div class="post__text post__text-html js-mediator-article">  Recently, the VC team announced a competition to develop a mobile application that would expand the capabilities of the social network " <b>VKontakte</b> ", and I decided to take part, since under the terms of the competition you can come up with your own idea of ‚Äã‚Äãthe application.  I had three ideas, and I had to choose which one to take. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d03/660/f81/d03660f81eaa4c02f18fb7c9af06c63a.png" alt="image"><br><br><a name="habracut"></a><br>  <i>Dear readers of "Habrahabr", please send all errors and edits to this article to your private messages.</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <b>Idea 1</b> </h4><br>  I really like group chats in VC, it‚Äôs a pity that you can‚Äôt talk in voice in these chats.  Such group public audio chats can help gamers find friends for online iOS games.  For example, I create an audio chat called ‚ÄúAsphalt 8‚Äù - and everyone who wants to play with me - join my audio scene in the app, and we play together, talking in voice.  There are similar ‚Äúaudio shows‚Äù on the PlayStation 4 console - and I even know people who do not include PS4 for games, but only for chatting with friends who sit in these audio shows.  Why make a separate application if you can call Viber or Whatsapp and play games, talking in these applications?  But you can‚Äôt try calling on Viber and launching, for example, the game Deepworld - the call to Viber will immediately fly off, as the stream from Viber is interrupted by an audio stream from the game.  In Skype, the situation for gamers is better, the Skype audio session will remain active, even if you turn on the music, the music will only be muffled a little.  But nowadays it is considered bad form to call someone without warning, and suddenly I call a friend, but he doesn‚Äôt want to play the game now, which I will offer?  The solution is to create an audio track, and all friends will receive a notification: ‚ÄúYour friend Ivan Ivanov has created a Hearthstone party.‚Äù  Those of friends who want to join - they press on the notification and go to voice communication!  One click on the notification - and you are in a get-together, you no longer need to ring up friends. <br><br><h4>  <b>Idea 2</b> </h4><br>  VKontakte has a documents section, so why not make an analog Dropbox for VK?  Yes, it will be necessary to make a Windows / Mac client, in addition to a mobile, a folder will be created on the user's PC, all files from which will be synchronized with VKontakte documents and a folder on the mobile device.  It turns out some analog Dropbox with backend VKontakte. <br><br><h4>  <b>Idea 3</b> </h4><br>  There is the ‚ÄúTheory of Six Handshakes‚Äù - the theory that any two people on Earth are separated by no more than five levels of mutual friends (and, accordingly, six levels of connections).  So why not make an application in which you can find out how many people share me in VK, for example, with Pavel Durov?  That is, we enter two users into the mobile application window - and get a chain of friends through which we can make contact with the person we need.  To implement the idea, you will have to download all the profiles of VKontakte users, sorting them by ID. <br><br><h4>  <b>Core audio</b> </h4><br><blockquote>  <i>Attention!</i>  <i>Core Audio is famous for its complexity!</i>  <i>Attempts to google problems on stackoverflow.com often lead to questions that no one answered on this portal!</i>  <i>Paid support for Apple, too, throws up his hands!</i>  <i>Reefs emerge at every step of development!</i> </blockquote><br><br>  The choice fell on the first idea, since it seemed to me more difficult to implement, and in order to complicate the process, I decided to do the implementation on Core Audio, for which there is practically no documentation, so I will have to experiment.  Vkontakte would already have time to add audio calls, because even Facebook in a mobile client has the opportunity to call by voice!  Why is VC worse?  VK team already tried to start video calls in the web client, did alfa version, but that was it.  I consider that it is necessary to add the ability to call the VK mobile client without fail!  And within the framework of this article I will try to tell you how to do it. <br><br>  What do I even know about sound?  How is sound transmitted over the network?  With video, everything is simpler, each pixel can be encoded in RGB and transmit changes to the matrix of pixels in the array.  But what is the "cast of sound" for a unit of time?  And he is such an array of Float numbers: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/665/3b3/356/6653b335607dd7cfaa288654feaec395.png" alt="image"><br><br>  Moreover, if we add <b>(Float 1) + (Float 2) + (Float 3) + ... + (Float (n))</b> and divide the sum by the number of elements <b>(n)</b> , then we will get the volume of this impression! <br><br>  To double the sound level, we just need to multiply all the elements of this array by 2: <br><br>  <b>(Float 1) * 2 + (Float 2) * 2 + (Float 3) * 2 + ... + (Float (n)) * 2</b> <br><br>  But what if, in our case, the sound comes from several users, how do we ‚Äúglue‚Äù two audio streams?  The answer is simple - you just need to put the elements of these two arrays in pairs. <br><br><blockquote>  On Mac OS X, in both kAudioFormatFlagsCanonical and kAudioFormatFlagsAudioUnitCanonical, one array element is Float with a floating point, but floating point calculations were too expensive for crystals with ARM processors, therefore in iOS, kAudioFormatFlagsCanonical format is represented by full-set programs. kAudioFormatFlagsAudioUnitCanonical - fixed-point integers.  "8.24".  This means that 8 bits (the integer part) are to the left of the decimal point, and 24 bits (the fractional part) to the right. </blockquote><br><br><h4>  <b>Select the application name and icon</b> : </h4><br>  I had two names in my head, the first one was ‚ÄúTusa‚Äù, the second one was ‚ÄúWassap‚Äù.  The application is a group audio chat, so it would be great if the participants greeted the entry with the phrase ‚ÄúWassaaaap!‚Äù, But because of the similarity of the name with ‚ÄúWhatsApp‚Äù I chose the name ‚ÄúTusa‚Äù.  I chose a microphone as an icon first, but then replaced it with pebbles: <br><img src="https://habrastorage.org/getpro/habr/post_images/a60/aab/0f7/a60aab0f794149a8f7010e5c5b274724.png" alt="image"><br><br><h4>  <b>How does the application "Tusa"</b> </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/54e/8c0/945/54e8c0945f1cea3ee7e49284fdeedf2e.png" alt="image"><br><br><ul><li>  First, the user enters the start screen, where he is asked to log in using the VK button.  At this stage, the application receives user information and a list of friends (public information only). </li><li>  The application then sends the user information and the friends list to the PHP server, the PHP server in turn returns the audio chat list of the user's friends, and each ‚Äúget-together‚Äù is assigned an IP and a Python server port on which the sound is exchanged. </li><li>  The user selects the ‚Äúaudio party‚Äù, and the application connects to the desired Python server, or the user chooses to ‚Äúcreate a new party‚Äù, and already other users log on to this chat. </li></ul><br><br>  Why bother to use a PHP server?  Why not get a list of chats on the same Python server?  I made a PHP server so that I could parallelize the ‚Äúaudio parties‚Äù to different Python servers, and if the Internet channel on one Python server is full, then the PHP server will create audio rooms on another Python server with a separate IP address.  Also, the PHP part will be responsible for sending IN-APP notifications. <br><br><h4>  <b>A little experiment - the background</b> </h4><br>  Before getting acquainted with Core Audio, I decided to conduct a small experiment with my capabilities.  I imagined such a situation - my plane crashed a plane crash, and I found myself on an uninhabited island with other passengers with a Macbook, a router, XCODE out of the box, and a dozen iOS devices charged by solar panels.  I would not have any documentation on Core Audio, and since at that time I didn‚Äôt know how the sound was digitized, could I write an audio chat under these conditions?  All I knew at that time was how to write .wav (.caf) files and play them.  Recently, I developed an iOS realtime multiplayer game <a href="https://itunes.apple.com/ru/app/tanks-online-battle-arena/id1059798956%3Fl%3Den%26mt%3D8">‚ÄúTanchiki with Dandy‚Äù</a> , where up to 100 tanchiki are played on the same map.  I decided to turn the game into audio chatting in a few lines of code, recording the sound in a loop into a file, then sending this file to other users, and creating playlists from these files in users!  This is a complete idiocy - to send files with sound, and I conducted this experiment only because of my existing network engine, I wanted to know the delay indicators in this case and check the operation of my network code in the conditions of sending large amounts of data, but as a result, in addition to the detected network bugs code, I got interesting details of the performance of the audio player in iOS, which may be useful to readers. <br><br><h5>  <b>How to play sound in iOS?</b>  <b>Using AVAudioPlayer</b> </h5><br><pre><code class="objectivec hljs"><span class="hljs-built_in"><span class="hljs-built_in">AVAudioPlayer</span></span> *avPlayer = [[<span class="hljs-built_in"><span class="hljs-built_in">AVAudioPlayer</span></span> alloc] initWithContentsOfURL: [<span class="hljs-built_in"><span class="hljs-built_in">NSURL</span></span> fileURLWithPath:<span class="hljs-string"><span class="hljs-string">@"_.caf"</span></span>] error:<span class="hljs-literal"><span class="hljs-literal">nil</span></span>]; [avPlayer play];</code> </pre> <br><br>  The sound from other users comes in NSData format and is added to the playlist array, so using <b>AVAudioPlayer</b> you can play not the file from the folder, but the sound from <b>NSData</b> directly: <br><br><pre> <code class="objectivec hljs"><span class="hljs-built_in"><span class="hljs-built_in">AVAudioPlayer</span></span> *avPlayer = [[<span class="hljs-built_in"><span class="hljs-built_in">AVAudioPlayer</span></span> alloc] initWithData: data fileTypeHint:<span class="hljs-built_in"><span class="hljs-built_in">AVFileTypeCoreAudioFormat</span></span> error:<span class="hljs-literal"><span class="hljs-literal">nil</span></span>]; [avPlayer play];</code> </pre><br><br><h5>  How to know that AVAudioPlayer finished playback?  Via callback audioPlayerDidFinishPlaying: </h5><br><pre> <code class="objectivec hljs">- (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)audioPlayerDidFinishPlaying:(<span class="hljs-built_in"><span class="hljs-built_in">AVAudioPlayer</span></span> *)player successfully:(<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span>)flag { <span class="hljs-comment"><span class="hljs-comment">// AVAudioPlayer  , //      }</span></span></code> </pre><br><br>  I launched this option on the iPhone and iPad - but now disappointment, the sound was played with interruptions.  The fact is that the initialization of <b>AVAudioPlayer</b> takes up to 100 milliseconds, hence the lags with sound. <br><br>  The solution was <b>AVQueuePlayer</b> , which was specifically made to play playlists without delay between tracks, initialize <b>AVQueuePlayer</b> : <br><br><pre> <code class="objectivec hljs"><span class="hljs-built_in"><span class="hljs-built_in">AVQueuePlayer</span></span> avPlayer = [[<span class="hljs-built_in"><span class="hljs-built_in">AVQueuePlayer</span></span> alloc] initWithItems: playerItems]; avPlayer.volume = <span class="hljs-number"><span class="hljs-number">1</span></span>; [avPlayer play];</code> </pre><br><br>  To add a file to the playlist, use the <b>AVPlayerItem</b> : <br><br><pre> <code class="objectivec hljs"><span class="hljs-built_in"><span class="hljs-built_in">NSURL</span></span> *url = [<span class="hljs-built_in"><span class="hljs-built_in">NSURL</span></span> fileURLWithPath:pathForResource]; <span class="hljs-built_in"><span class="hljs-built_in">AVPlayerItem</span></span> *item = [<span class="hljs-built_in"><span class="hljs-built_in">AVPlayerItem</span></span> playerItemWithURL:url]; <span class="hljs-built_in"><span class="hljs-built_in">NSArray</span></span> *playerItems = [<span class="hljs-built_in"><span class="hljs-built_in">NSArray</span></span> arrayWithObjects:item, <span class="hljs-literal"><span class="hljs-literal">nil</span></span>]; [avPlayer insertItem:item afterItem:<span class="hljs-literal"><span class="hljs-literal">nil</span></span>];</code> </pre><br><br>  By launching this option, I heard a clear sound between my devices, the delay was about 250 milliseconds, since files of a shorter size could not be recorded, an error crashed.  And of course, this option was gluttonous to traffic, because besides the necessary sounds, a .wav (.caf) file that contained a header was transmitted over the network several times per second.  Also, this method does not work in the background, so in the background of iOS you cannot start playing new sounds.  On it we will finish experiment and we will begin to program the application. <br><br><h4>  <b>What do we know about Core Audio?</b> </h4><br>  The Apple website has an example of recording audio into an audio file using Core Audio, you can download it on the page: <br><br>  <a href="https://developer.apple.com/library/ios/samplecode/AVCaptureToAudioUnit/Introduction/Intro.html">https://developer.apple.com/library/ios/samplecode/AVCaptureToAudioUnit/Introduction/Intro.html</a> <br><br>  After studying this source code, it became clear to me that when recording sound many times per second, Callback is called <br><br><pre> <code class="objectivec hljs"><span class="hljs-meta"><span class="hljs-meta">#pragma mark ======== AudioUnit recording callback ========= static OSStatus PushCurrentInputBufferIntoAudioUnit(void * inRefCon, AudioUnitRenderActionFlags * ioActionFlags, const AudioTimeStamp * inTimeStamp, UInt32 inBusNumber, UInt32 inNumberFrames, AudioBufferList * ioData) { // AudioBufferList *ioData -      //    //    NSData      NSMutableData * soundData = [NSMutableData dataWithCapacity:0]; for( int y=0; y</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;ioData-&gt;</span></span></span><span class="hljs-meta">mNumberBuffers; y++ ) { AudioBuffer audioBuff = ioData-&gt;mBuffers[y]; //   ,     Float Float32 *frame = (Float32*)audioBuff.mData; //        [soundData appendBytes:&amp;frame length:sizeof(float)]; } return noErr; }</span></span></code> </pre><br><br>  Having <b>analyzed the AudioBufferList</b> format, which contained a sound in the form of a list of numbers, I <b>converted AudioBufferList</b> to <b>NSData</b> , building all the digits in a chain of 4 bytes - and through the python server in the loop passed this buffer to the remote device.  But how to play <b>AudioBufferList</b> on a remote device?  In the official source on the Apple site, I did not find the answer; the answer from Apple support did not give me the necessary information either.  But having spent enough time on the principle of ‚Äúscientific spear‚Äù, I realized that for this purpose there is a similar callback into which <b>AudioBufferList</b> should be substituted and it will be played on the fly: <br><br><pre> <code class="objectivec hljs"><span class="hljs-meta"><span class="hljs-meta">#pragma mark ======== AudioUnit playback callback ========= static OSStatus playbackCallback(void *inRefCon, AudioUnitRenderActionFlags *ioActionFlags, const AudioTimeStamp *inTimeStamp, UInt32 inBusNumber, UInt32 inNumberFrames, AudioBufferList *ioData) { //  *ioData    Floats, //       return noErr; }</span></span></code> </pre><br><br>  How to activate callbacks data?  First, rename your .m project file to .mm and import all the necessary C ++ libraries from the <b>AVCaptureToAudioUnit</b> project.  After that we create, configure and run our audio stream using this code: <br><br><pre> <code class="objectivec hljs"> <span class="hljs-comment"><span class="hljs-comment">//   OSStatus status; AudioComponentInstance audioUnit; //    AudioComponentDescription desc; desc.componentType = kAudioUnitType_Output; desc.componentSubType = kAudioUnitSubType_RemoteIO; desc.componentFlags = 0; desc.componentFlagsMask = 0; desc.componentManufacturer = kAudioUnitManufacturer_Apple; AudioComponent inputComponent = AudioComponentFindNext(NULL, &amp;desc); status = AudioComponentInstanceNew(inputComponent, &amp;audioUnit); //  IO    UInt32 flag = 1; status = AudioUnitSetProperty(audioUnit, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Input, 1, // Input &amp;flag, sizeof(flag)); //  IO    status = AudioUnitSetProperty(audioUnit, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Output, 0, // Output &amp;flag, sizeof(flag)); AudioStreamBasicDescription audioFormat; //    audioFormat.mSampleRate = 8000.00; audioFormat.mFormatID = kAudioFormatLinearPCM; audioFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked; audioFormat.mFramesPerPacket = 1; audioFormat.mChannelsPerFrame = 1; audioFormat.mBitsPerChannel = 16; audioFormat.mBytesPerPacket = 2; audioFormat.mBytesPerFrame = 2; // Apply format status = AudioUnitSetProperty(audioUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, // Input &amp;audioFormat, sizeof(audioFormat)); status = AudioUnitSetProperty(audioUnit, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Input, 0, // Output &amp;audioFormat, sizeof(audioFormat)); //  Callback    AURenderCallbackStruct callbackStruct; callbackStruct.inputProc = recordingCallback; callbackStruct.inputProcRefCon = (__bridge void * _Nullable)(self); status = AudioUnitSetProperty(audioUnit, kAudioOutputUnitProperty_SetInputCallback, kAudioUnitScope_Global, 1, // Input &amp;callbackStruct, sizeof(callbackStruct)); //  Callback    callbackStruct.inputProc = playbackCallback; callbackStruct.inputProcRefCon = (__bridge void * _Nullable)(self); status = AudioUnitSetProperty(audioUnit, kAudioUnitProperty_SetRenderCallback, kAudioUnitScope_Global, 0, // Output &amp;callbackStruct, sizeof(callbackStruct)); //      flag = 0; status = AudioUnitSetProperty(audioUnit, kAudioUnitProperty_ShouldAllocateBuffer, kAudioUnitScope_Output, 1, // Input &amp;flag, sizeof(flag)); //  status = AudioUnitInitialize(audioUnit); //  status = AudioOutputUnitStart(audioUnit);</span></span></code> </pre><br><br>  By the way, as an experiment, I studied the format of the caf file, after spending a lot of time with the HEX editor and tried to take an <b>AudioBufferList</b> on a remote device, add a byte header (header) to the .caf file, then save this <b>AudioBufferList</b> to a .caf file, and play back with using <b>AVQueuePlayer</b> .  And the strangest thing is that I did it! <br><br><h4>  <b>Novocaine</b> </h4><br>  So, we have already dealt with Core Audio, but how to make the process even easier and clearer?  And the answer is, you need to use <b>Novocaine</b> ! <br><br>  <a href="https://github.com/alexbw/novocaine">https://github.com/alexbw/novocaine</a> <br><br>  What is <b>Novocaine</b> ?  Three years, three coders designed Core Audio into a separate class, and it turned out great!  <b>Novocaine is</b> implemented in C ++, so in order to connect a C ++ class with our Objective C file, you need to rename it from .m to .mm - and import everything at the beginning of the .mm file. <br><br><h5>  <b>How to count audio to buffer?</b> </h5><br><pre> <code class="objectivec hljs">Novocaine *audioManager = [Novocaine audioManager]; [audioManager setInputBlock:^(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> *newAudio, <span class="hljs-built_in"><span class="hljs-built_in">UInt32</span></span> numSamples, <span class="hljs-built_in"><span class="hljs-built_in">UInt32</span></span> numChannels) { <span class="hljs-comment"><span class="hljs-comment">//         20  //  numChannels = 2,  newAudio[0]   1, // newAudio[1] -  2, newAudio[2] -  1  .. }]; [audioManager play];</span></span></code> </pre><br><br><h5>  <b>How to play the buffer?</b> </h5><br><pre> <code class="objectivec hljs">Novocaine *audioManager = [Novocaine audioManager]; [audioManager setOutputBlock:^(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> *audioToPlay, <span class="hljs-built_in"><span class="hljs-built_in">UInt32</span></span> numSamples, <span class="hljs-built_in"><span class="hljs-built_in">UInt32</span></span> numChannels) { <span class="hljs-comment"><span class="hljs-comment">// ,   -    //   float   audioToPlay }]; [audioManager play];</span></span></code> </pre><br><br>  Just like that! <br><br>  We try to collect all this on the iPhone and iPad, launch an audio call - and ... Echo!  Squeak!  The killing echo passes many times through the communication channel and crashes into the brain!  I expected that users would communicate, even without a headset, on the speakerphone, but the sound came from me to the remote device, from the speaker of the remote device I got into the microphone and came back to me.  Unpleasant  How to implement echo cancellation in iOS using Core Audio? <br><br>  You must use the <b>kAudioUnitSubType_VoiceProcessingIO</b> parameter for the audio stream, instead of the standard <b>kAudioUnitSubType_RemoteIO</b> .  Open the file <b>Novocaine.m</b> , find the line: <br><br><pre> <code class="objectivec hljs">inputDescription.componentSubType = kAudioUnitSubType_RemoteIO;</code> </pre><br>  replace with: <br><br><pre> <code class="objectivec hljs">inputDescription.componentSubType = kAudioUnitSubType_VoiceProcessingIO;</code> </pre><br><br>  We try to collect and see the error.  The fact is that by default our audio stream operated at a frequency of <b>44100.0 hz</b> , and I need a lower frequency for <b>kAudioUnitSubType_VoiceProcessingIO</b> to work. <br><br>  I changed the value of <b>44100.0</b> to <b>8000.0</b> - in all files, but the audio stream continued to be generated at a frequency of <b>44100.0</b> .  After parsing information on the Internet, I discovered that the Novocaine project on github has three "Pull requests" from third-party users, and one of them had a description: <br><br><blockquote>  Fixed Crash when launching from background while audio playing;  Ability to manage Sample Rate </blockquote><br><br>  Having copied all the modified lines from this request, I managed to start the audio stream at a frequency of <b>8000.0</b> and the echo cancellation worked!  The delay sound was 15-25 ms!  The application worked in a minimized form, even with the screen off on a locked iPhone! <br><br>  The fact is that iOS does not allow launching new sounds when the application is minimized, to check, you can launch the song in Safari from VK and minimize the browser.  As soon as the track ends, the new track from the playlist will not turn on until you make the browser active!  If you use audio streams in iOS, then the application will perfectly cope with the task of playing new sounds from the background! <br><br><h4>  <b>How sound is transmitted from device to device in the ‚ÄúTusa‚Äù application</b> </h4><br>  On the remote server, I open TCP port 7878 using the python script and create a TCP connection with this server from an iOS application: <br><br>  Then, collecting the sound into an array of float - I convert it to <b>NSMutableData</b> , building a <b>float</b> into <br>  chain of 4 bytes: <br><br><pre> <code class="objectivec hljs"><span class="hljs-built_in"><span class="hljs-built_in">NSMutableData</span></span> * soundData = [<span class="hljs-built_in"><span class="hljs-built_in">NSMutableData</span></span> dataWithCapacity:<span class="hljs-number"><span class="hljs-number">0</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numFrames; ++i) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> iChannel = <span class="hljs-number"><span class="hljs-number">0</span></span>; iChannel &lt; numChannels; ++iChannel) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> theta = data[i*numChannels + iChannel]; [soundData appendBytes:&amp;theta length:<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)]; } }</code> </pre><br><br>  Now the sound is in <b>soundData</b> , we transmit it to the server in the format: <br><br>  <b>LENGTH (soundData) + A + soundData</b> <br><br>  where <b>A</b> is the byte indicating that the sound came to the server, <b>LENGTH (soundData)</b> is the packet length (4 bytes), <b>soundData</b> is the data itself in the <b>NSData</b> format. <br><br>  I also tried to encrypt the entire audio stream by the secret key, the traffic volume increased by 50-100% - but in terms of iOS performance, the devices handle it with a bang.  Although for those who use <b>3G</b> in conditions of poor reception, such an increase in the Internet channel may turn out to be very heavy. <br><br>  The most annoying thing is that I initially implemented the whole project on the <b>Cocos2D</b> library intended for games, and it turned out that the <b>VK SDK</b> does not work with <b>Cocos2D</b> projects, but only supports <b>ARC</b> mode ( <b>Automatic Reference Counting</b> ), in which automatic work with memory release takes place.  In one of the past games, I also tried to embed the VK button, but due to errors I had to replace it with a Facebook button.  I hope that the next versions of the <b>VK SDK</b> will work with <b>Cocos2D</b> , but in the meantime I had to rewrite all the code on the standard Storyboard interfaces, removing all the " <b>release</b> " memory releases from the code.  And if a few days ago I was looking for where to insert ‚Äúrelease‚Äù in order to avoid memory leaks, then in ARC mode there is no such problem at all.  The application began to occupy only 10mb of RAM, instead of 30mb on <b>Cocos2D</b> . <br><br><blockquote>  <i>Note: I still managed to ‚Äúmake friends‚Äù of the Storyboard interfaces with Cocos2D, and run the Cocos2D game directly in the UIViewController, and Cocos2D runs in ARC mode, but this is a topic for a separate article</i> </blockquote><br><br><h4>  <b>Doubtful Innovation or UDP vs TCP</b> </h4><br>  Instead of the usual UDP protocol for VoIP, I used the TCP data transfer protocol as an experiment.  When transmitting audio over TCP, a small delay is created with each packet loss (due to the re-transmission of data).  As a result, because of the unstable Internet, the client in the incoming playlist of audio messages sometimes has too much data, the length of the incoming playlist begins to exceed several seconds, and something needs to be done about it.  I decided to try to correct the situation in the following way: <br><ul><li>  If the length of the incoming playlist exceeds 2 seconds - then I just skip the ‚Äúsilent‚Äù audio impressions, cutting out the silence between the phrases </li><li>  If the length of the incoming playlist exceeds the critical figure, then I simply increase the speed of the audio stream by 2 times until the playlist is of a satisfactory length.  As a result, the incoming voice in this situation sounds "accelerated." </li></ul><br><br>  Advantages of using TCP - all packets and phrases will be guaranteed to be delivered, and if you encrypt audio packets, there will be no problems with their decryption.  There is also no need for additional STUN and TURN servers through which all UDP traffic is ‚Äúproxied‚Äù for NAT traversal (you should not forget that almost all iOS users do not have an external IP), in the case of TCP, the exchange takes place directly between the server and the client. <br><br>  The advantages of using UDP are the absence of delays in packet loss, if packets are lost, the application will ignore this. <br><br>  Bottom line: In case of packet loss with a poor Internet connection, in any case we will have to abandon part of the audio data, in the case of the traditional VoIP UDP connection, these will be arbitrary audio data, including the audio date with voice, and in the case of TCP connections - we can choose which audio data to discard, and we choose to cut off ‚Äúquiet‚Äù audio data - this is how we compensate for the delay. <br><br>  Well, that's all, if you are interested in following the development of the project within the framework of the competition, provide a link to the VK project page: <a href="http://vk.com/id232953074">http://vk.com/id232953074</a> <br><br><blockquote>  At the moment, one of my games (Tanchiki Online) <b>went to the App Store main page</b> (Hurray!), All my servers were filled with thousands of players, so the launch of Tusa had to be postponed for several days.  All information about the launch, I'll post <b>VKontakte</b> . </blockquote><br><br>  The source code of the Tusa application, I will also try to post VKontakte, as soon as I give it a more optimized look. <br><br>  In the comments to the article, I would like to hear alternative <b>free (!)</b> Options for transferring an audio stream to iOS <b>through my own servers (!)</b> , Which could be used to transmit sound on VKontakte. <br><br>  Also in the comments, write whether there are analogues of the Tusa application in the App Store (In addition to the paid "Timspeak"). <br><br>  Since the VK contest was started to expand the VC client's capabilities, and my application demonstrates how to add calls to VC, I ask you to take part in the voting, do you think audio / video calls are needed in the VC mobile client?  Voting will not play a key role in the decision, but the VC developers will definitely notice it, because there are already calls on Facebook :) </div><p>Source: <a href="https://habr.com/ru/post/279517/">https://habr.com/ru/post/279517/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../279507/index.html">Entertaining analysis of one expression with square brackets</a></li>
<li><a href="../279509/index.html">Programmatic process lookup by name in QNX 6.5.0</a></li>
<li><a href="../279511/index.html">How to write an email to IT professionals: 5 tips</a></li>
<li><a href="../279513/index.html">Quick start a new application on React using nwb</a></li>
<li><a href="../279515/index.html">Use highcharts.js to create server side charts</a></li>
<li><a href="../279519/index.html">We make beautifully "broken" pictures</a></li>
<li><a href="../279521/index.html">"IoT" or "not IoT" - that is the question! (Windows 10 IoT FAQ), updated</a></li>
<li><a href="../279525/index.html">Yota Air: what does outside work teach?</a></li>
<li><a href="../279527/index.html">uDev tech events: Kharkov, March 30</a></li>
<li><a href="../279529/index.html">The company Crytek announced a new engine CryEngine V</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>