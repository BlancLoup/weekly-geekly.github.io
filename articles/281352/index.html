<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Superscalar Stacking Processor: Optimization</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continuation of a series of articles that analyze the idea of ‚Äã‚Äãa superscalar processor 
 OoO and stack machine frontend . The topic of this article i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Superscalar Stacking Processor: Optimization</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/9de/533/daf/9de533daf6d544f7b7c978eee6b74a2c.png"><br>  Continuation of a series of articles that analyze the idea of ‚Äã‚Äãa <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">superscalar</a> processor <br>  <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">OoO</a> and stack machine <a href="http://www.ixbt.com/cpu/cpu-pedia.shtml">frontend</a> .  The topic of this article is the optimization of memory accesses. <br><br>  Previous articles: <br>  <a href="https://habrahabr.ru/post/278575/">1</a> - description of work on a linear piece <br>  <a href="https://habrahabr.ru/post/279123/">2</a> - function call, save registers <br>  <a href="https://habrahabr.ru/post/280087/">3</a> - function call, inside view <br><a name="habracut"></a><br><br>  Until now, we have not paid attention to the weak point of all stack machines ‚Äî redundant memory accesses. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In fact, when the naive Kodo generator of a stack machine wants to get the value of the variable 'a', it writes the instruction 'push a'.  There is no possibility to refer to an already computed expression or its piece by the stack processor. <br><br>  For register processors, the compiler solves this problem by introducing temporary variables with possible placement in registers.  It is worth inventing a similar mechanism for our seemingly non-register architecture. <br><br>  However, there is almost no need to invent something, ‚Äúeverything is already stolen before us‚Äù (C). <br><ul><li>  we will enter the device of bookmarks (bookmarks) </li><li>  bookmark - the register to which the compiler can refer to the number, register and bookmark numbers are not required to match, although it would simplify life </li><li>  the compiler for each function determines the number of bookmarks that it is going to have </li><li>  at the start of the function, the required number of registers is allocated under the bookmarks; </li><li>  bookmarks get inside the register window and are acted upon by the FILL / SPILL mechanism </li><li>  if the compiler considers the calculated value to be valuable, then it sets the bookmark, for example, with the instruction 'bmk 1', which means: the value at the top of the stack is now considered bookmark number 1. Does the value copy to the bookmark register N1 or is the register responsible for this bookmark, no matter implementation details </li><li>  when in the future the compiler needs the value from this tab, it can use it, for example, like this: 'add_bmk 1', i.e.  the value from the top of the stack will be summed with the value of tab 1 and replaced with this value </li><li>  from the point of view of the processor backend, the good old mop summation of the two registers into the third one will be generated </li><li>  there is a need for a second line of arithmetic and logical instructions (add-&gt; add_bmk, mul-&gt; mull_bmk, cmp-&gt; cmp_bmk), but it's worth it </li><li>  or a more general variant - any of the arguments or the result of the three (two) -address instructions can be bookmarked </li><li>  You can imagine the dynamic allocation of bookmarks, without allocating the maximum number of bookmarks in order to optimize the number of registers used, but this (at first glance) looks too cruel in relation to the gland </li></ul><br>  As a result, the compiler has two conditionally new resources for optimization. <br><br>  The first is the identification and placement of bookmarks, the number of which can be quite large, it is not limited to the number of available registers for the lack thereof.  By and large, this is the equivalent of local variables located in the ‚Äúfast‚Äù stack. <br><br>  The second is an equivalent transformation of expressions to a form in which internal parallelism is maximally manifested.  The compiler tries to reduce the height of expression trees by growing in breadth. <br><br>  Well, let's not forget about the traditional optimization techniques that are not focused on registers and their distribution. <br><br>  In order to figure out how this can be implemented, take a look at those <br>  the possibilities that the <a href="http://llvm.org/docs/CommandGuide/llvm-as.html">LLVM assembler</a> provides us.  We are not going to really ignore the entire ‚Äúcultural layer‚Äù accumulated in this area. <br><br><h3>  Llvm </h3><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">a</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> m, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> n)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (m == <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> n + <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n == <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a(m - <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a(m - <span class="hljs-number"><span class="hljs-number">1</span></span>, a(m, n - <span class="hljs-number"><span class="hljs-number">1</span></span>)); }</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">received LLVM asm</b> <div class="spoiler_text"><pre> ;  Function Attrs: nounwind readnone
 define i32 @a (i32% m, i32% n) # 0 {
   % 1 = icmp eq i32% m, 0
   br i1% 1, label% tailrecurse._crit_edge, label% .lr.ph

 tailrecurse._crit_edge:;  preds =% tailrecurse.backedge,% 0
   % n.tr.lcssa = phi i32 [% n,% 0], [% n.tr.be,% tailrecurse.backedge]
   % 2 = add nsw i32% n.tr.lcssa, 1
   ret i32% 2

 .lr.ph:;  preds =% 0,% tailrecurse.backedge
   % n.tr2 = phi i32 [% n.tr.be,% tailrecurse.backedge], [% n,% 0]
   % m.tr1 = phi i32 [% 4,% tailrecurse.backedge], [% m,% 0]
   % 3 = icmp eq i32% n.tr2, 0
   % 4 = add nsw i32% m.tr1, -1
   br i1% 3, label% tailrecurse.backedge, label% 5

 ;  &lt;label&gt;: 5;  preds =% .lr.ph
   % 6 = add nsw i32% n.tr2, -1
   % 7 = tail call i32 @a (i32% m.tr1, i32% 6)
   br label% tailrecurse.backedge

 tailrecurse.backedge:;  preds =% 5,% .lr.ph
   % n.tr.be = phi i32 [% 7,% 5], [1,% .lr.ph]
   % 8 = icmp eq i32% 4, 0
   br i1% 8, label% tailrecurse._crit_edge, label% .lr.ph
 } </pre></div></div><br>  Here we see only the instructions of the control flow; there are no places where the specificity of the stack machine could manifest itself (except for such a calculation + -1). <br><br>  What about the <a href="https://ru.wikipedia.org/wiki/%25D0%2591%25D0%25B0%25D0%25B1%25D0%25BE%25D1%2587%25D0%25BA%25D0%25B0_(%25D0%2591%25D0%259F%25D0%25A4)">FFT ‚Äúbutterfly‚Äù</a> (this is rather from the data flow area)? <br><div class="spoiler">  <b class="spoiler_title">FFT fragment</b> <div class="spoiler_text">  ... <br>  for (n = 1; n &lt;= LogN; n ++) <br>  { <br>  rw = Rcoef [LogN - n]; <br>  iw = Icoef [LogN - n]; <br>  if (Ft_Flag == FT_INVERSE) iw = -iw; <br>  in = ie &gt;&gt; 1; <br>  ru = 1.0; <br>  iu = 0.0; <br>  for (j = 0; j &lt;in; j ++) <br>  { <br>  for (i = j; i &lt;N; i + = ie) <br>  { <br>  io = i + in; <br>  rtp = Rdat [i] + Rdat [io]; <br>  itp = Idat [i] + Idat [io]; <br>  rtq = Rdat [i] - Rdat [io]; <br>  itq = Idat [i] - Idat [io]; <br>  Rdat [io] = rtq * ru - itq * iu; <br>  Idat [io] = itq * ru + rtq * iu; <br>  Rdat [i] = rtp; <br>  Idat [i] = itp; <br>  } <br>  sr = ru; <br>  ru = ru * rw - iu * iw; <br>  iu = iu * rw + sr * iw; <br>  } <br>  ie &gt;&gt; = 1; <br>  } <br>  ... <br></div></div><br>  Body of the most nested loops assembler LLVM <br>  (clang -c bc -O3 --target = xcore -emit-llvm -S -o b_o3.ll) looks like this: <br><div class="spoiler">  <b class="spoiler_title">obtained LLVM assembler</b> <div class="spoiler_text">  .lr.ph21 :;  preds =% .preheader19,% .lr.ph21 <br>  % i.020 = phi i32 [% 76,% .lr.ph21], [% j.025,% .preheader19] <br>  % 57 = add nsw i32% i.020,% 54 <br>  % 58 = getelementptr inbounds double *% Rdat, i32% i.020 <br>  % 59 = load double *% 58, align 4,! Tbaa! 1 <br>  % 60 = getelementptr inbounds double *% Rdat, i32% 57 <br>  % 61 = load double *% 60, align 4,! Tbaa! 1 <br>  % 62 = fadd double% 59,% 61 <br>  % 63 = getelementptr inbounds double *% Idat, i32% i.020 <br>  % 64 = load double *% 63, align 4,! Tbaa! 1 <br>  % 65 = getelementptr inbounds double *% Idat, i32% 57 <br>  % 66 = load double *% 65, align 4,! Tbaa! 1 <br>  % 67 = fadd double% 64,% 66 <br>  % 68 = fsub double% 59,% 61 <br>  % 69 = fsub double% 64,% 66 <br>  % 70 = fmul double% ru.023,% 68 <br>  % 71 = fmul double% iu.024,% 69 <br>  % 72 = fsub double% 70,% 71 <br>  store double% 72, double *% 60, align 4,! tbaa! 1 <br>  % 73 = fmul double% ru.023,% 69 <br>  % 74 = fmul double% iu.024,% 68 <br>  % 75 = fadd double% 74,% 73 <br>  store double% 75, double *% 65, align 4,! tbaa! 1 <br>  store double% 62, double *% 58, align 4,! tbaa! 1 <br>  store double% 67, double *% 63, align 4,! tbaa! 1 <br>  % 76 = add nsw i32% i.020,% ie.028 <br>  % 77 = icmp slt i32% 76,% N <br>  br i1% 77, label% .lr.ph21, label% ._ crit_edge22 <br>  ... <br></div></div><br>  In the form of a dependency graph between instructions, it looks like this: <br><img src="https://habrastorage.org/files/bb8/faf/0b8/bb8faf0b838249038f8839f05d3e3647.png"><br>  Offhand, each vertex of the tree from which more than one edge extends is a candidate for the title of a bookmark.  At least in terms of floating point calculations. <br><br>  In any case, the implementation of the described architecture in LLVM does not look like a hopeless event. <br><br>  Dot file, suddenly come in handy: <br><div class="spoiler">  <b class="spoiler_title">fft.dot</b> <div class="spoiler_text">  digraph graphname { <br>  L000 [label = "% 54"]; <br>  L001 [label = "% Rdat"]; <br>  L002 [label = "% Idat"]; <br>  L003 [label = "% ru.023"]; <br>  L004 [label = "% iu.024"]; <br>  L005 [label = "% i.020"]; <br><br>  L02 [label = "% 57 = add nsw i32% i.020,% 54"]; <br>  L03 [label = "% 58 = getelementptr double *% Rdat, i32% i.020"]; <br>  L04 [label = "% 59 = load double *% 58"]; <br>  L05 [label = "% 60 = getelementptr double *% Rdat, i32% 57"]; <br>  L06 [label = "% 61 = load double *% 60"]; <br>  L07 [label = "% 62 = fadd double% 59,% 61"]; <br>  L08 [label = "% 63 = getelementptr double *% Idat, i32% i.020"]; <br>  L09 [label = "% 64 = load double *% 63"]; <br>  L10 [label = "% 65 = getelementptr double *% Idat, i32% 57"]; <br>  L11 [label = "% 66 = load double *% 65"]; <br>  L12 [label = "% 67 = fadd double% 64,% 66"]; <br>  L13 [label = "% 68 = fsub double% 59,% 61"]; <br>  L14 [label = "% 69 = fsub double% 64,% 66"]; <br>  L15 [label = "% 70 = fmul double% ru.023,% 68"]; <br>  L16 [label = "% 71 = fmul double% iu.024,% 69"]; <br>  L17 [label = "% 72 = fsub double% 70,% 71"]; <br>  L18 [label = "store double% 72, double *% 60"]; <br>  L19 [label = "% 73 = fmul double% ru.023,% 69"]; <br>  L20 [label = "% 74 = fmul double% iu.024,% 68"]; <br>  L21 [label = "% 75 = fadd double% 74,% 73"]; <br>  L22 [label = "store double% 75, double *% 65"]; <br>  L23 [label = "store double% 62, double *% 58"]; <br>  L24 [label = "store double% 67, double *% 63"]; <br><br>  L005-&gt; L02;  L000-&gt; L02;  L005-&gt; L03;  L001-&gt; L03; <br>  L03-&gt; L04;  L001-&gt; L05;  L02-&gt; L05;  L05-&gt; L06;  L04-&gt; L07; <br>  L06-&gt; L07;  L002-&gt; L08;  L005-&gt; L08;  L08-&gt; L09;  L002-&gt; L10; <br>  L02-&gt; L10;  L10-&gt; L11;  L09-&gt; L12;  L11-&gt; L12;  L04-&gt; L13; <br>  L06-&gt; L13;  L09-&gt; L14;  L11-&gt; L14;  L003-&gt; L15;  L13-&gt; L15; <br>  L004-&gt; L16;  L14-&gt; L16;  L15-&gt; L17;  L16-&gt; L17;  L17-&gt; L18; <br>  L003-&gt; L19;  L14-&gt; L19;  L004-&gt; L20;  L13-&gt; L20;  L19-&gt; L21; <br>  L20-&gt; L21;  L10-&gt; L22;  L21-&gt; L22;  L07-&gt; L23;  L03-&gt; L23; <br>  L08-&gt; L24;  L12-&gt; L24;  L05-&gt; L18; <br>  } <br></div></div><br><br><h3>  Epilogue </h3><br>  Here we come to the preliminary finish. <br>  Understood why you need a new architecture, offered a solution. <br>  Initially, the question was whether this architecture meets the requirements. <br>  And now we can answer, yes, at least in that small part of C, which we managed to verify, we received <br><ul><li>  expected hardware simplification </li><li>  outwardly imperceptible scalability by the number of registers </li><li>  as well as the number of functional devices </li><li>  potential compiler simplification </li></ul><br>  At the first (amateurish) view, the principal problems that impede the implementation of such an architecture in hardware are not visible. <br><br>  We intentionally did not consider such things as: <br><ul><li>  floating point calculations, do they need a separate stack, ... </li><li>  cpu state saving when switching context </li><li>  interrupts </li><li>  ... </li></ul><br>  All these questions are important, but less important. <br>  And at the moment the author considers his task accomplished. </div><p>Source: <a href="https://habr.com/ru/post/281352/">https://habr.com/ru/post/281352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../281340/index.html">6 reasons for the failure of the mobile game in the international market</a></li>
<li><a href="../281342/index.html">JavaScript goes beyond the Web in 2015</a></li>
<li><a href="../281344/index.html">What criteria are important for a large client when choosing an agency for web development?</a></li>
<li><a href="../281346/index.html">Dilute asynchronous programming functionality on Scala</a></li>
<li><a href="../281350/index.html">Haordic Organization Visa (Part 1)</a></li>
<li><a href="../281354/index.html">Implementation of monitoring and integration testing information system using Scalatest. Part 2</a></li>
<li><a href="../281356/index.html">Simple automation of the management of acts of marriage on SharePoint with examples and pictures</a></li>
<li><a href="../281358/index.html">JetBrains is looking for a technical evangelist with Java experience</a></li>
<li><a href="../281360/index.html">.Net Client for mail.ru cloud</a></li>
<li><a href="../281362/index.html">New Cisco Aironet IEEE 802.11ac Wave 2 Access Points</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>