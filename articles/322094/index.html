<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Introduction to lock-free programming</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this post, we would like to once again raise the topic of programming without blocking, first defining it, and then select a few key points from th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Introduction to lock-free programming</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/fdc/f57/43a/fdcf5743a889950c49194daf804cd394.jpg" alt="image"><br><br>  In this post, we would like to once again raise the topic of programming without blocking, first defining it, and then select a few key points from the variety of information.  We will show how these provisions relate to each other, using block diagrams, and then we touch on the details a little.  The minimum requirement for a developer who comprehends lock-free is the ability to write the correct multi-threaded code using mutexes or other high-level synchronization objects, for example, semaphores or events. <br><a name="habracut"></a><br>  Lock-free programming is a kind of test, and not so much because of the complexity of the task itself, but because of the difficulty of comprehending the essence of the subject. <br><br>  I was lucky to get the first insight into the lock-free of Bruce Dawson's excellent detailed article ‚Äú <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ee418650(v%3Dvs.85).aspx">Lockless Programming Considerations</a> ‚Äù.  And like so many others, I happened to apply Bruce's advice in practice, developing and debugging an unblocking code on platforms such as the Xbox 360. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Since then, many good works have been published, starting with abstract theory and proof of correctness and ending with practical examples and details of the hardware level.  I will give a list of links in the notes.  Sometimes the information in one source contradicts another, for example, some works assume <a href="http://en.wikipedia.org/wiki/Sequential_consistency">sequential consistency</a> (sequential consistency), which avoids the problems of memory ordering (memory ordering) - a real disaster for C / C ++ code.  At the same time, the new <a href="http://en.cppreference.com/w/cpp/atomic">library of atomic operations of the C ++ 11 standard</a> makes you look at the problem in a new light and abandon the usual way of presenting lock-free algorithms. <br><br><h2>  <font color="#c75733">What is it?</font> </h2><br>  Non-blocking programming is usually described as programming without mutexes, also called <a href="http://preshing.com/20111118/locks-arent-slow-lock-contention-is">locks</a> .  This is true, but it is only part of the picture.  The generally accepted definition based on academic literature is slightly broader.  ‚ÄúWithout locks‚Äù is essentially a certain property that allows you to describe the code, without going into details about how it is written. <br><br>  As a rule, if a part of your program satisfies the conditions listed below, then this part can be considered lock-free.  And vice versa, if this part does not satisfy these conditions, it will not be lock-free. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/dbd/745/b32/dbd745b32f6e437bba67878f149bae07.png"></div><br>  Translation: Do you work with multiple threads (interrupts, signal handlers, etc.)?  - Yes.  - Do threads have access to shared memory?  - Yes.  - Can threads block each other (in other words, can you schedule flows so that they are blocked indefinitely)?  - Not.  - This is non-blocking programming. <br><br>  In this sense, the term <i>lock</i> in a lock-free does not refer directly to mutexes, but rather to the possibility that the application itself will somehow be blocked, be it a deadlock, a dynamic deadlock, or hypothetical planning. streams performed by your worst enemy.  The last point may seem funny, but it is the key.  Shared mutexes can easily be disabled: as soon as a single thread receives a mutex, your adversary may simply never again plan this stream.  Of course, real operating systems do not work this way until we simply define the terms. <br><br>  Here is a simple example of an operation that does not contain mutexes, but still is not lock-free.  Initially, X = 0. As an exercise, think about how to plan the two threads so that none of them can get out of the loop. <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (X == <span class="hljs-number"><span class="hljs-number">0</span></span>) { X = <span class="hljs-number"><span class="hljs-number">1</span></span> - X; }</code> </pre> <br>  No one expects a large application to be completely lock-free.  Usually, we select a subset of lock-free operations from all of the code.  For example, in a nonblocking queue there may be a number of nonblocking operations: <code>push</code> , <code>pop</code> , perhaps <code>isEmpty</code> , etc. <br><br> <a href="http://www.amazon.com/gp/product/0123973376/ref%3Das_li_ss_tl%3Fie%3DUTF8%26tag%3Dpreshonprogr-20%26linkCode%3Das2%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0123973376"><img src="https://habrastorage.org/files/401/93d/e30/40193de302514cfcbbe0bb2fe057b38c.png" align="right"></a>  Hirliha and Shavit, the authors of <a href="http://www.amazon.com/gp/product/0123973376/ref%3Das_li_ss_tl%3Fie%3DUTF8%26tag%3Dpreshonprogr-20%26linkCode%3Das2%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0123973376">The Art of Multiprocessor Programming</a> , tend to represent such operations as class methods and propose the following brief definition of lock-free: "With infinite execution, infinitely often, the called method always ends."  In other words, as long as the program can <i>call</i> such lock-free operations, the number of <i>completed</i> calls will increase.  During such operations, locking the system is algorithmically impossible. <br><br>  One of the important consequences of non-blocking programming: even if one thread is in a state of waiting, it will not interfere with the progress of the other threads in their own lock-free operations.  This determines the value of non-blocking programming when writing interrupt handlers and real-time systems, when a specific task must be completed within a limited time, regardless of the state of the rest of the program. <br><br>  Last clarification: operations specifically <i>designed</i> for blocking do not deprive the algorithm of lock-free status.  For example, a pop operation of a queue may be intentionally blocked if the queue is empty.  The remaining paths will still be considered non-blocking. <br><br><h2>  <font color="#c75733">Non-locking programming mechanisms</font> </h2><br>  It turns out that in order to satisfy the non-blocking condition, there is a whole family of mechanisms: atomic operations, memory barriers, and the avoidance of ABA problems are just some of them.  And at this moment everything becomes hellishly difficult. <br><br>  How do all these mechanisms relate?  For illustration, I have drawn the following flowchart.  Decipher every block below. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/606/2c0/3a1/6062c03a162b4689b6fb91216a151e79.png"></div><br><h2>  <font color="#c75733">Atomic change operations (RMW, read-modify-write)</font> </h2><br>  Atomic operations are operations that perform indivisible memory manipulations: no thread can observe such an operation at an intermediate stage of execution.  In modern processors, many operations are already atomic.  For example, usually are atomic aligned read / write operations of simple types. <br><br><img src="https://habrastorage.org/files/e3c/752/822/e3c75282254545699dd01f1881a7c874.png" align="right">  <a href="http://en.wikipedia.org/wiki/Read-modify-write">RMW operations</a> go even further, allowing atomically to perform more complex transactions.  They are especially useful when the non-blocking algorithm has to support several streams for writing, because if you try several streams to execute RMW at one address, they will promptly line up and perform these operations one by one.  I already touched on RMW in this blog when I talked about the implementation of a <a href="http://preshing.com/20120226/roll-your-own-lightweight-mutex">lightweight mutex</a> , a <a href="http://preshing.com/20120305/implementing-a-recursive-mutex">recursive mutex,</a> and a <a href="http://preshing.com/20120522/lightweight-in-memory-logging">lightweight logging system</a> . <br><br>  Examples of RMW operations: <a href="http://msdn.microsoft.com/en-us/library/2ddez55b(v%3Dvs.90).aspx"><code>_InterlockedIncrement</code></a> in Win32, <a href="http://developer.apple.com/library/ios/"><code>OSAtomicAdd32</code></a> in iOS and <a href="http://www.stdthread.co.uk/doc/headers/atomic/atomic/specializations/integral/fetch_add.html"><code>std::atomic&lt;int&gt;::fetch_add</code></a> in C ++ 11.  Please note that the standard of atomic operations C ++ 11 does not guarantee that the implementation will be lock-free on any platform, so it is best to explore the capabilities of your platform and toolkit.  For confidence, you can call <a href="http://www.stdthread.co.uk/doc/headers/atomic/atomic/specializations/integral/is_lock_free.html"><code>std::atomic&lt;&gt;::is_lock_free</code></a> . <br><br>  Different processor families <a href="http://jfdube.wordpress.com/2011/11/30/understanding-atomic-operations/">support RMW differently</a> .  Processors such as PowerPC and ARM provide <a href="http://en.wikipedia.org/wiki/Load-link/store-conditional">LL / SC</a> instructions (load-link / store-conditional, load with mark / write attempt), which allows you to implement your own RMW transaction at a low level, although this is not often done.  Ordinary RMW is usually sufficient. <br><br>  As shown in the block diagram, atomic RMW is a necessary part of non-blocking programming, even on single-processor systems.  Without atomicity, a thread can be interrupted in the middle of a transaction, which can lead to an inconsistent state. <br><br><h2>  <font color="#c75733">Compare-And-Swap Cycles</font> </h2><br>  Perhaps the most talked about RMW operation is <a href="http://en.wikipedia.org/wiki/Compare-and-swap">compare-and-swap</a> (CAS).  In Win32, CAS is available using a family of built-in functions, such as <a href="http://msdn.microsoft.com/en-us/library/ttk2z1ws.aspx"><code>_InterlockedCompareExchange</code></a> .  Developers often run compare-and-swap in a loop to retry attempts to execute a stantation.  This scenario usually involves copying a shared variable to a local one, doing some work on it and trying to publish the changes using CAS. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> LockFreeQueue::push(Node* newHead) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (;;) { <span class="hljs-comment"><span class="hljs-comment">// Copy a shared variable (m_Head) to a local. Node* oldHead = m_Head; // Do some speculative work, not yet visible to other threads. newHead-&gt;next = oldHead; // Next, attempt to publish our changes to the shared variable. // If the shared variable hasn't changed, the CAS succeeds and we return. // Otherwise, repeat. if (_InterlockedCompareExchange(&amp;m_Head, newHead, oldHead) == oldHead) return; } }</span></span></code> </pre> <br>  Such cycles are also considered lock-free, since if the test did not pass in one thread, it means that it should have passed in another, although some architectures offer <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2748.html">a weaker version of CAS</a> , where this is not always the case.  During the implementation of the CAS cycle, you should try to avoid <a href="http://en.wikipedia.org/wiki/ABA_problem">ABA problems</a> . <br><br><h2>  <font color="#c75733">Sequential consistency</font> </h2><br>  Sequential consistency means that all threads agree with the order in which memory operations were performed, and that this order corresponds to the order of operations in the source code of the program.  With consistent consistency, we will not suffer from memory reordering tricks like the one I described <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act">in the previous post</a> . <br><br>  A simple (but obviously impractical) way to achieve consistent consistency is to turn off compiler optimizations and run all threads on a single processor.  The memory of one processor will never be in disarray, even if the threads are scheduled for a random time. <br><br>  Some programming languages ‚Äã‚Äãprovide consistent consistency even for optimized code executed on multiple processors.  In C ++ 11, you can declare shared variables as C ++ 11 atomic (atomic) types that provide ordering.  In Java, you can mark all shared variables as <code>volatile</code> .  Here is an example from my <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act">previous post</a> , rewritten in the style of C ++ 11: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::atomic&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt; X(<span class="hljs-number"><span class="hljs-number">0</span></span>), Y(<span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> r1, r2; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">thread1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ X.store(<span class="hljs-number"><span class="hljs-number">1</span></span>); r1 = Y.load(); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">thread2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Y.store(<span class="hljs-number"><span class="hljs-number">1</span></span>); r2 = X.load(); }</code> </pre> <br>  Since the atomic types of C ++ 11 ensure consistent consistency, it is impossible to get r1 = r2 = 0 at the output.  To get the desired result, the compiler adds additional instructions ‚Äî usually these are memory barriers or RMW operations.  Because of these additional instructions, the implementation may be less efficient than the one where the developer works with memory sequencing directly. <br><br><h2>  <font color="#c75733">Memory ordering (memory reordering)</font> </h2><br>  As suggested in the flowchart, each time a lock-free development for a multi-core (or any other <a href="http://en.wikipedia.org/wiki/Symmetric_multiprocessing">SMP</a> -) system, when your environment does not guarantee consistent consistency, you need to think about how to deal with the problem of <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act">memory reordering</a> . <br><br>  In modern architectures, there are three groups of tools that ensure correct memory ordering at both the <a href="http://preshing.com/20120625/memory-ordering-at-compile-time">compiler</a> level and the <a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations">processor</a> level: <br><br><ul><li>  Lightweight instructions for synchronization and memory barriers, which I will discuss in <a href="http://preshing.com/20120913/acquire-and-release-semantics">future posts</a> ; </li><li>  The complete instructions of the memory barriers that I have <a href="http://preshing.com/20120522/lightweight-in-memory-logging">demonstrated before</a> ; </li><li>  Memory operations based on acquire / release semantics (semantics of resource capture / release). </li></ul><br>  Acquire semantics provides memory ordering for subsequent operations, release semantics for previous ones.  These semantics are partially suitable for the case of producer / consumer relations, when one thread publishes information and another reads it.  We will discuss this in more detail <a href="http://preshing.com/20120913/acquire-and-release-semantics">in a future post</a> . <br><br><h2>  <font color="#c75733">Different processors have different memory models.</font> </h2><br>  When it comes to memory reordering, <a href="http://www.linuxjournal.com/node/8212/print">all CPU families have their own habits</a> .  The rules are fixed in the documentation of each manufacturer and are strictly followed in the manufacture of iron.  For example, PowerPC or ARM processors can change the order of instructions themselves, while the x86 / 64 family from Intel and AMD usually do not.  It is said that the former have a <a href="http://preshing.com/20120930/weak-vs-strong-memory-models">weaker memory model</a> . <br><br>  There is a great temptation to abstract from these low-level details, especially when C ++ 11 provides us with a standard way to write portable code without blocking.  But I think that at present most lock-free developers have at least some idea of ‚Äã‚Äãthe difference in hardware platforms.  The key difference that is definitely worth remembering is that, at the instruction level in x86 / 64, each load from memory occurs with acquire-semantics, and each entry in memory - with release-semantics - at least for non-SSE instructions and not for write-combining memory.  As a result, earlier quite often they wrote lock-free code that worked on x86 / 64, but <a href="http://www.drdobbs.com/parallel/208801974">fell on other processors</a> . <br><br>  If you are interested in technical details of how and why processors reorder the memory, I recommend reading Appendix C in <a href="http://kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.2011.01.02a.pdf">Is Parallel Programming Hard</a> .  In any case, do not forget that the reordering of memory may also occur due to the fact that the compiler reordered the instructions. <br><br>  In this post, I almost did not touch the practical side of programming without locks, for example, when should they be engaged?  How much do we need it?  I also did not mention the importance of testing your lock-free algorithms.  Nevertheless, I hope that this introduction has allowed some readers to become familiar with the basic principles of lock-free, so that they can go deeper into the subject without feeling completely at a loss. <br><br><h2>  <font color="#c75733">Additional links</font> </h2><br> <a href="http://www.amazon.com/gp/product/1933988770/ref%3Das_li_ss_tl%3Fie%3DUTF8%26tag%3Dpreshonprogr-20%26linkCode%3Das2%26camp%3D1789%26creative%3D390957%26creativeASIN%3D1933988770"><img src="https://habrastorage.org/files/3ea/897/414/3ea897414ffa4da0a9da1ffddc3563db.png" align="right"></a> <ul><li>  <a href="http://www.justsoftwaresolutions.co.uk/blog/">Anthony Williams blog</a> and his book <a href="http://www.amazon.com/gp/product/1933988770/ref%3Das_li_ss_tl%3Fie%3DUTF8%26tag%3Dpreshonprogr-20%26linkCode%3Das2%26camp%3D1789%26creative%3D390957%26creativeASIN%3D1933988770">C ++ Concurrency in Action</a> </li><li>  <a href="http://www.1024cores.net/">The site of Dmitriy V'jukov</a> and various <a href="https://groups.google.com/forum/%3Ffromgroups">forum discussions</a> </li><li>  <a href="http://bartoszmilewski.com/">Bartosz Milewski Blog</a> </li><li>  <a href="http://cbloomrants.blogspot.ca/2012/06/06-12-12-another-threading-post-index.html">Low-Level Threading series</a> in the Charles Bloom blog </li><li>  Doug Lea, <a href="http://g.oswego.edu/dl/jmm/cookbook.html">JSR-133 Cookbook</a> </li><li>  Howells and McKenney, <a href="http://www.kernel.org/doc/Documentation/memory-barriers.txt">memory-barriers.txt</a> document </li><li>  Hans Boehm, a <a href="http://www.hpl.hp.com/personal/Hans_Boehm/c%2B%2Bmm/">collection of references</a> on the C ++ 11 memory model </li><li>  Herb Sutter, <a href="http://www.gotw.ca/publications/">Effective Concurrency</a> series </li></ul></div><p>Source: <a href="https://habr.com/ru/post/322094/">https://habr.com/ru/post/322094/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../322080/index.html">Indoor Air Quality Monitor</a></li>
<li><a href="../322082/index.html">Transition from Google Analytics to Firebase</a></li>
<li><a href="../322084/index.html">How slyamzit Habr in a quick way</a></li>
<li><a href="../322088/index.html">Benefits of Enterprise Mobility Management with Citrix XenMobile</a></li>
<li><a href="../322092/index.html">‚ÄúProgramming as a way of creative implementation‚Äù or Corona SDK for those who want</a></li>
<li><a href="../322096/index.html">Tale of a small internship in a small company [Part II]</a></li>
<li><a href="../322098/index.html">Again, February seventeenth, we are preparing a revolutionary revolver for satellite navigation.</a></li>
<li><a href="../322100/index.html">Open Data Day in Moscow</a></li>
<li><a href="../322102/index.html">Reuse of code in microservice architecture - on the example of SPRING BOOT</a></li>
<li><a href="../322104/index.html">How to reduce the number of unsubscribe from the newsletter</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>