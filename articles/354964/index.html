<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Richard Hamming: Chapter 16. Digital Filters - 3</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="â€œThe goal of this course is to prepare you for your technical future.â€ 
 Hi, Habr. Remember the awesome article "You and your work" (+219, 2394 bookma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">ğŸ”</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">ğŸ“œ</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">â¬†ï¸</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">â¬‡ï¸</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Richard Hamming: Chapter 16. Digital Filters - 3</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  â€œThe goal of this course is to prepare you for your technical future.â€ </blockquote><br><img src="https://habrastorage.org/getpro/habr/post_images/d10/8d7/f7a/d108d7f7adc1fb48d3b61a1753ac4238.jpg" alt="image" align="right">  Hi, Habr.  Remember the awesome article <a href="https://habrahabr.ru/post/209100/">"You and your work"</a> (+219, 2394 bookmarks, 377k readings)? <br><br>  So Hamming (yes, yes, self-checking and self-correcting <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25B4_%25D0%25A5%25D1%258D%25D0%25BC%25D0%25BC%25D0%25B8%25D0%25BD%25D0%25B3%25D0%25B0">Hamming codes</a> ) has a whole <a href="http://worrydream.com/refs/Hamming-TheArtOfDoingScienceAndEngineering.pdf">book</a> based on his lectures.  We translate it, because the man is talking. <br><br>  This book is not just about IT, it is a book about the thinking style of incredibly cool people.  <i>â€œThis is not just a charge of positive thinking;</i>  <i>it describes the conditions that increase the chances of doing a great job. â€</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We have already translated 18 (out of 30) chapters.  And <a href="http://hamming.ru/">we are working</a> on the publication "in paper." <br><br><h3>  Chapter 16. Digital Filters - 3 </h3><br>  <i>(For the translation, thanks to Andrey Pakhomov, who responded to my call in the â€œprevious chapter.â€) Who wants to help with the translation, layout and publishing of the book - write in a personal or mail magisterludi2016@yandex.ru</i> <br><br>  And now we are ready to consider the systematic synthesis of non-recursive filters.  The method of synthesis of such filters is shown in Figure 16.1 and consists of 6 parts.  On the left above the sketch of the filter that you would like to get in the ideal case.  It can be a low pass filter, a high pass filter, a bandpass barrier, a band pass filter, a stopper filter, or even a differentiator.  For all types of filters, except for the differentiator, they usually strive to obtain a transfer characteristic equal to 0 or 1 at different frequency intervals, while for the differentiator they tend to get <i>iÏ‰</i> as a transfer characteristic, because the derivative of the eigenfunction of the filter is equal to <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f10/9e0/7d8/f109e07d8765b0a75c451ad9fc83d249.png"><br><br>  <i>therefore, the desired coefficients are iÏ‰.</i> <a name="habracut"></a><br><br>  For the differentiator, a cutoff frequency will most likely be set, because, as you may have noticed, the differentiation increases the amplitude of the signal by multiplying it by <i>Ï‰</i> .  In the high-frequency region, where noise is usually located, the transfer function has the highest values â€‹â€‹(Figure 16.II).  Also note in Figure 15.II. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e2/369/ff8/3e2369ff8074364d56f9174d6d9e6f37.png"><br><br>  Figure 16.I <br><br>  The coefficients of the corresponding members of the Fourier series expansion are easily calculated, since the integrands in the expression for their calculation are simple (when there is a derivative, it is possible to use integration in parts).  Suppose we presented a series expansion in the form of complex exponentials.  Then the filter coefficients are the coefficients of the corresponding members of the series, presented in an exponential form.  In the top right corner of Figure 16.I, a symbolic graph of coefficients is presented (of course, coefficients are complex numbers). <br><br>  At the next stage (presented below in Figure 16.I) we must limit the decomposition in a row to 2N + 1 members (this is similar to using a rectangular window).  This limiting the number of members (the right side of the illustration) leads to the Gibbs effect (the left side of the illustration).  The coefficients with the window functions imposed on them are presented in the lower right part of the illustration, and the final filter in the lower left part. <br><br>  The method presented above requires choosing the number of members of the Fourier series (N) and the shape of the window function.  If the initial selection of these parameters is not suitable for your task, you select other parameters and try again.  This is a trial and error method. <br><br>  James Frederick Kaiser proposed a method of synthesis, which allows you to simultaneously calculate the number of coefficients of a series, and get a specific window function from a certain family of window functions.  In this case, two parameters must be specified: deviation from the ideal filter along the vertical axis (Î´) and the width of the transition region between the passband and the suppression bandwidth (Î”F), an example is shown in Figure 16.III. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4a/7e1/b18/c4a7e1b187c71710ef01623cff5408d6.png"><img src="https://habrastorage.org/getpro/habr/post_images/99b/522/030/99b52203009e887b53fa1d43069880af.png"><br>  Figure 16.III <br><br>  For a band-pass filter, with a given bandwidth <i>f <sub>p</sub></i> and a suppression band <i>f</i> <sub>p</sub> , the following sequence of calculations applies: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b5b/bfa/864/b5bbfa8647a0f63e0d85ef03ceb80e00.png"><br><br>  If the obtained value of N is too large, then you need to stop and revise the design of the filter, otherwise you go to the next step: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/80c/a93/5e6/80ca935e6b2e73ca4d9f78fe2d3899dc.png">  The dependence Î± (A) is presented in graph 16.IV.  The initial Fourier series expansion coefficients are given as <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b9/8ce/688/4b98ce6887152964963df7f19ebb758e.png"><br><br>  These coefficients should be multiplied by the corresponding weighting factors <i>w <sub>k of the</sub></i> window function <br><br><img src="https://habrastorage.org/getpro/habr/post_images/85d/5c9/78e/85d5c978eca0d31979c706ea3889a4b7.png"><br><br>  Where <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3b4/cd3/37e/3b4cd337edc8634b54473764d6b892c2.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6a8/674/ed8/6a8674ed866cc1667e0000724bdc0a36.png"><br><br>  Chart 16.IV <br><br>  I <sub>0</sub> ( <i>x</i> ) is the Bessel function of the imaginary argument of zero order.  To calculate its value, you need a comparatively few terms, because the series converges quickly due to the square <i>n</i> !  in the denominator. <br><br>  It is best to calculate the value of I <sub>0</sub> ( <i>x</i> ) recursively;  for a given <i>x, the</i> next member of the series is expressed through the previous as <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4d0/7e6/29a/4d07e629a58230fccb9036a28bf8ca41.png"><br><br>  <i>For a low pass or high pass filter, one of the values â€‹â€‹of f <sub>p</sub></i> or <i>f <sub>s</sub></i> has limnit possibel for it.  For a frequency-rejection filter, the formulas for calculating the coefficients <i>c <sub>k</sub></i> vary slightly. <br><br>  Let's examine the coefficients of the Kaiser window function, <i>w <sub>k</sub> :</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0eb/41b/6c1/0eb41b6c1baa426cfc470c14fe227be6.png"><br><br>  If we examine these numbers, we see that for Î±&gt; 0 they resemble a raised cosine <br><br><img src="https://habrastorage.org/getpro/habr/post_images/827/49d/728/82749d728b53a543fe515400dee483ee.png"><br><br>  and the corresponding window function is similar to the windows of Hann and Hamming.  For A&gt; 21 there is a â€œplatformâ€.  For A &lt;21, when Î± = 0, all weighting factors <i>w</i> <sub>k</sub> are equal to one and we get a window similar to the Lanczos window.  With increasing A, a platform gradually emerges.  Thus, the Kaiser window has the same properties as many popular windows, but the specific window that you use is built on the basis of the specified parameters, and not on the basis of prejudice or conjecture. <br><br>  How did the Kaiser derive these formulas?  To some extent by trial and error.  Initially, he assumed that he had one gap and he modeled many options on the computer to see the duration of the front Î”F ( <i>the signal front is a signal transition from state 0 (lower level) to 1 (upper level). In this case, there is ie, the width of the transition band between the passband and the attenuation band.</i> ) and the pitch Î´.  After a fair amount of reflection, the touch of the muse and not having anything defined as a function of A, we note that with increasing A we arrive from the Lanczos window (A &lt;21) to the platform of increasing height, 1 / I <sub>0</sub> (Î±).  In the ideal case, he wanted to get an elongated spheroidal function, but he noticed that the values â€‹â€‹obtained by him were precisely approximated by I <sub>0</sub> ( <i>x</i> ).  He built graphs and approximated functions.  I asked him how he got 0.4 for the exponent degree.  He said that he tried 0.5 at the beginning, but that turned out to be too much, then a value of 0.4, which also perfectly suited, was the next logical choice.  This is a good example of the fact that the use of already known knowledge in combination with a computer, as a tool for experiments, leads to very useful results, even in theoretical studies. <br>  Sometimes the Kaiser method fails when there is more than one slice (in fact, the slice is displayed symmetrically and at a negative frequency range) and then the ringing due to different sections will overlap each other and the predicted ringing value will be exceeded.  In such a situation, which sometimes does happen, you should simply repeat the synthesis with less stringent restrictions.  The entire program can be executed on a small, programmable calculator placed in the hand, for example, TI-59, not to mention a modern PC. <br><br>  And now let's go back to the final Fourier series.  The Fourier functions are remarkable in that they are orthogonal, not only on a continuous interval, but also on a set of individual points equidistant from each other.  Therefore, the whole theory remains the same, except that the expansion in a series can have as many members as there are points in the original array.  For 2N points, in the general case, only one term for the highest frequency, cosine, is present in the series expansion (since the sine value will be zero at the sampling points).  The coefficients are defined as the sum of the data values â€‹â€‹multiplied by the corresponding Fourier functions.  The resulting representation, taking into account the rounding, will reproduce the original data. <br><br>  The calculation of the decomposition will look like 2N operations of addition and multiplication for each of the 2N values â€‹â€‹of the original data, that is, something about (2N) <sup>2</sup> operations of addition and multiplication.  The use of two optimizations: (1) adding and subtracting terms with the same multiplier before performing the multiplication operation and (2) calculating higher frequencies by multiplying lower frequencies resulted in a fast Fourier transform (FFT), which requires N logN operations.  Such a reduction in the required computational power has greatly changed the entire field of science and technology - what was previously impossible due to high costs and a long computation time, has become ubiquitous. <br><br>  And now is the time for another life story.  You all have heard about the FFT and the publication of Kuli-Tukey.  An FFT is sometimes called a Kuli-Tukey transform or algorithm.  Tukey prompted me, in part, the basic ideas of the FFT.  At that time, I had an IBM-programmed external punch card calculator (IBM Card Programmed Calculator), and the butterfly operation he had in mind was absolutely not practical on the equipment I had.  A few years later, I had a programmable IBM-650 inside, and he reminded me of these optimizations again.  All I remembered then was that it was one of Tukey's few bad ideas;  I absolutely forgot why she was bad - only because of the limitations of the equipment that I had then.  Thus, I did not implement FFT, although the book, which I had already published by that time, shows that I already knew everything that was necessary for that, and could realize FFT very simply! <br><br>  Moral: if you remember that something cannot be done, then also remember the main reasons why this cannot be done, so that later, when circumstances change, you will not say: â€œThis cannot be done.â€  Think of my mistake!  Could something be more stupid?  Fortunately for my ego, this is a common mistake (and I made it more than once), but due to the fact that I got into a mess with CFT, I am now very sensitive to it.  I also noticed that others too often make mistakes in the same way â€” too often!  Please remember the story of how foolish I was and what opportunity I missed because of this, and do not make such mistakes yourself.  When you decide that something is impossible, do not say again in the future that it is impossible before you do not study in detail why you were right when you said that it was impossible. <br><br>  Now I have to return to the delicate topic of the power spectrum, which is equal to the sum of the squares of the two coefficients of a given frequency in the real numbers region or the square of the module in the complex domain.  An examination of this question will convince you that this value depends only on the signal itself and does not depend on the location of the origin point in time, in contrast to the values â€‹â€‹of the coefficients, which depend on the location of the origin point.  Spectrum plays a very important role in science and technology.  It was the spectral lines that opened up the black box of the atomic structure and allowed Bor to look inside.  The newer quantum mechanics, which appeared in 1925, changed everything to be a little confident in something, but the spectrum was still the key.  We also regularly examine black boxes by examining the dependencies between the spectra of the input and output signals, in order to gain an understanding of their internal structure - note that it is always unique, but in general we get enough information to form new theories. <br><br>  Let me carefully analyze what we are doing and what we mean by that, because it largely determines what we see in the end.  Usually, at least in our imagination, we are dealing with an analog signal.  It is usually infinite and we take readings on a time interval of length 2L.  This is the same as multiplying a signal by a Lanczos window, or a rectangular window, if you prefer.  This means that a convolution of the original signal occurs with the corresponding function of the form (sin x) / x, Figure 16.V - the longer the signal, the narrower the (sinx) / x loops.  Each pure spectral line spreads along the corresponding (sinx) / x curve. <br>  Figure 16.V <img src="https://habrastorage.org/getpro/habr/post_images/b7e/2d2/e11/b7e2d2e114e096179a464a4eec43d04a.png"><br>  We then sample at equal time intervals and high frequencies are superimposed on lower frequencies.  Obviously, regardless of the order of these two operations â€” discretization and signal limiting by time â€” we will get the same result.  As I have already mentioned, once, I have carefully worked through the corresponding algebraic transformations to make sure that what should be true from the point of view of the theory is in fact also true in practice. <br><br>  Then we use PBF, which is just an ingenious and accurate method of obtaining the coefficients of a finite Fourier series.  The fact is that when we allow the representation of a signal in the form of a finite Fourier series, we assume that the original function is periodic with a period length equal to exactly the sampling period multiplied by the number of samples taken.  We forcibly take all non-harmonic frequencies for harmonics - we forcibly convert a continuous spectrum into a line spectrum.  Such mapping is not a local effect, and as you can easily calculate that non-harmonic frequencies are superimposed on all harmonic frequencies, of course, the most on adjacent frequencies, but they also influence on more distant frequencies. <br><br>  I avoided subtracting the average value â€” the standard technique from the statistics domain, which is used for convenience or calibration.  This technique reduces the amplitude of the zero frequency in the spectrum to zero and introduces a serious discontinuity in the spectrum.  If a window function is subsequently used, it will simply spread this gap across adjacent frequencies.  During data processing for Tukey, I often used the subtraction of a linear or even quadratic trend, from the flight data of an airplane or a rocket.  But the spectrum of the sum of two signals is by no means the sum of the spectra!  With the addition of two functions, the individual frequencies are added algebraically, and they can both reinforce each other and completely extinguish, and this will lead to an absolutely false result.  A trend line has a big gap at the end (remember that we assume that the functions are periodic), because its coefficients decrease as 1 / k, which is not at all fast.  We still partially use them, because we donâ€™t know what to replace them with - and none of those I know has any reasonable arguments against my comments. <br><br>  But back to the theory.  Each spectrum of real noise decreases rather quickly as we strive for an infinite frequency, otherwise it would have infinite energy.  But the sampling process itself imposes higher frequencies to lower ones, and such a reduction in bandwidth, as shown in graph 16.VI, tends to lead to a flat spectrum - remember that frequencies add up algebraically.  Thus, there is a tendency to observe a flat spectrum for noise, and if the spectrum is flat, then we call this noise white noise.  The signal is mainly located in the low frequency region.  This statement is valid for several reasons, including the use of oversampling (sampling more often than required by the Nyquist theorem), which allows us to use averaging to reduce the measurement error.  Thus, a typical spectrum will look like the one shown in graph 16.VI.  Therefore, a low-pass filter is so common for removing noise.  No single linear method can separate a signal from noise at the same frequency, but noise outside the signal frequency can be removed by a low-pass filter.  Thus, when we use oversampling, we have a chance to remove most of the noise with a low-pass filter. <br><br>  Remember that we have an implicit limitation that we are dealing with a linear system.  Analysis of the stock market using Fourier transforms revealed the presence of extremely white noise in the data, and this was interpreted as the impossibility of forecasting prices on the stock exchange - this is only true if you use simple linear predictors.  However, it says nothing about the practical application of nonlinear predictors.  Here again we can observe a wide distribution of incorrect interpretation of the results due to the use of a mathematical tool, without an understanding of the fundamentals that underlie it.  Little knowledge is a dangerous thing, especially if you have gaps in fundamental knowledge. <br><br>  I neatly mentioned in the preface to the topic of digital filters that at the time, I thought I did not know anything about them.  What I didnâ€™t know then - just because I didnâ€™t know anything about designing recursive digital filters â€” so much so that I had already created them by that time when I studied the theory of predictor-correctors in relation to the numerical solution of ordinary differential equations.  Proof is almost a recursive digital filter! <br><br>  When I studied how to integrate the system of ordinary differential equations numerically, I was free from stereotypes from the field of digital filters, and I soon realized that a limited input signal, as digital filter experts say, if you integrate it, can cause an unlimited output signal - what they called unstable, but it is absolutely obvious that you should get if you integrate - even a constant value at the input will lead to a linear increase at the output.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In fact, when I later encountered the task of landing the trajectory on the moon, where there is no air, and therefore there is no resistance, therefore there is no explicit first derivative in the equation, and I wanted to use such solutions using a suitable formula for numerical integration, I found that I had a quadratic error growth; a small rounding error in the calculation of the acceleration will not be corrected and will lead to a quadratic error in determining the location; error in acceleration leads to a quadratic increase in error in the calculation of the location. This is the root of the problem, in contrast to the Earth, where air resistance plays the role of feedback and corrects the wrong acceleration, and as a result, corrects the error in the location.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thus, to this day, I have to do with the issue of the stability of digital filters, which means not the exponential growth of the output signal with a limited input signal. At the same time, polynomial growth is allowed, and this is no longer the standard stability criterion inherited from classic analog filters, where if it is not limited, everything will melt in you - in any case, they were never seriously considered as an integration tool. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We will look at this in more detail in the next chapter, which is devoted to recursive filters, which play an important role in integration.</font></font><br><br>  <i>To be continued...</i> <br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Who wants to help with the translation, layout and publication of the book - write in a personal or mail magisterludi2016@yandex.ru</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> By the way, we also started the translation of another cool book - </font></font><a href="https://habrahabr.ru/post/349916/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">â€œThe Dream Machine: The History of Computer Revolutionâ€</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Book content and translated chapters</font></font></b> <div class="spoiler_text">  <a href="https://habr.com/post/345752/">Foreword</a> <br><ol><li> Intro to The Art of Doing Science and Engineering: Learning to Learn (March 28, 1995) <a href="https://habrahabr.ru/post/348770/">:  1</a> </li><li> Â«Foundations of the Digital (Discrete) RevolutionÂ» (March 30, 1995) <a href="https://habrahabr.ru/post/345836/"> 2.   () </a> </li><li> Â«History of Computers â€” HardwareÂ» (March 31, 1995) <a href="https://habr.com/post/349936/"> 3.   â€” </a> </li><li> Â«History of Computers â€” SoftwareÂ» (April 4, 1995) <a href="https://habrahabr.ru/post/346566/"> 4.   â€” </a> </li><li> Â«History of Computers â€” ApplicationsÂ» (April 6, 1995) <a href="https://habr.com/post/351148/"> 5.   â€”  </a> </li><li> Â«Artificial Intelligence â€” Part IÂ» (April 7, 1995) <i>( )</i> </li><li> Â«Artificial Intelligence â€” Part IIÂ» (April 11, 1995) <i>( )</i> </li><li> Â«Artificial Intelligence IIIÂ» (April 13, 1995) <a href="https://habrahabr.ru/post/349934/"> 8.  -III</a> </li><li> Â«n-Dimensional SpaceÂ» (April 14, 1995) <a href="https://habrahabr.ru/post/348264/"> 9. N- </a> </li><li> Â«Coding Theory â€” The Representation of Information, Part IÂ» (April 18, 1995) <i>( )</i> </li><li> Â«Coding Theory â€” The Representation of Information, Part IIÂ» (April 20, 1995) </li><li> Â«Error-Correcting CodesÂ» (April 21, 1995) <i>( )</i> </li><li> Â«Information TheoryÂ» (April 25, 1995) <i>( ,  )</i> </li><li> Â«Digital Filters, Part IÂ» (April 27, 1995) <a href="https://habr.com/post/348276/"> 14.   â€” 1</a> </li><li> Â«Digital Filters, Part IIÂ» (April 28, 1995) <a href="https://habr.com/post/354878/"> 15.   â€” 2</a> </li><li> Â«Digital Filters, Part IIIÂ» (May 2, 1995) <a href="https://habr.com/post/354964/"> 16.   â€” 3</a> </li><li> Â«Digital Filters, Part IVÂ» (May 4, 1995) </li><li> Â«Simulation, Part IÂ» (May 5, 1995) <i>( )</i> </li><li> Â«Simulation, Part IIÂ» (May 9, 1995) <i></i> </li><li> Â«Simulation, Part IIIÂ» (May 11, 1995) </li><li> Â«Fiber OpticsÂ» (May 12, 1995) <i> </i> </li><li> Â«Computer Aided InstructionÂ» (May 16, 1995) <i>( )</i> </li><li> Â«MathematicsÂ» (May 18, 1995) <a href="https://habrahabr.ru/post/346562/"> 23. </a> </li><li> Â«Quantum MechanicsÂ» (May 19, 1995) <a href="https://habrahabr.ru/post/345366/"> 24.  </a> </li><li> Â«CreativityÂ» (May 23, 1995). : <a href="https://habrahabr.ru/post/336846/"> 25. </a> </li><li> Â«ExpertsÂ» (May 25, 1995) <a href="https://habrahabr.ru/post/346560/"> 26. </a> </li><li> Â«Unreliable DataÂ» (May 26, 1995) <i>( )</i> </li><li> Â«Systems EngineeringÂ» (May 30, 1995) <a href="https://habrahabr.ru/post/346556/"> 28.  </a> </li><li> Â«You Get What You MeasureÂ» (June 1, 1995) <a href="https://habrahabr.ru/post/350144/"> 29.   ,   </a> </li><li> Â«How Do We Know What We KnowÂ» (June 2, 1995) <i> </i> </li><li> Hamming, Â«You and Your ResearchÂ» (June 6, 1995). <a href="https://habrahabr.ru/post/209100/">:    </a> </li></ol><br>     ,     â€”       magisterludi2016@yandex.ru <br></div></div></div><p>Source: <a href="https://habr.com/ru/post/354964/">https://habr.com/ru/post/354964/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../354954/index.html">JavaFx, a simple COM port terminal</a></li>
<li><a href="../354956/index.html">VPN for a beer?</a></li>
<li><a href="../354958/index.html">One year in Figme. On the pros and cons of the design tool is subjective</a></li>
<li><a href="../354960/index.html">Extensions for VS Code and JavaScript programming</a></li>
<li><a href="../354962/index.html">Logging as a way to debug code</a></li>
<li><a href="../354966/index.html">Effective online quality assessment in the development of web services. Yandex lecture</a></li>
<li><a href="../354968/index.html">We are looking for cycles on the Lorenz attractor in the Maxima package.</a></li>
<li><a href="../354970/index.html">Splunk Distributed Search. Or how to build an indexer cluster on Splunk?</a></li>
<li><a href="../354972/index.html">Qt News, June 2017 - May 2018</a></li>
<li><a href="../354974/index.html">"Fant" and Okmeter: a symbiosis for the benefit of monitoring</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>