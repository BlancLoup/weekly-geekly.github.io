<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>First steps in machine learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, dear friend, have you always wanted to try machine learning, but the area looked mysterious and difficult? I would like to share with you my st...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>First steps in machine learning</h1><div class="post__text post__text-html js-mediator-article">  Hello, dear friend, have you always wanted to try machine learning, but the area looked mysterious and difficult?  I would like to share with you my story as I took the first steps in machine learning, with zero knowledge of Python and higher mathematics with a small example. <br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Preamble</b> <div class="spoiler_text">  I work as a web developer in a consulting company, and sometimes there comes a time when one project is already over, and the next one has not yet been appointed.  Everyone who is on the bench, in order not just to sit down, must contribute to the company's intellectual property.  As a rule, this is either the creation of training materials on a topic that the author owns, or the study of a new technology and the subsequent demonstration or presentation at the end of the week. <br><br>  I decided, since there is such an opportunity, then try to touch the topic of Machine Learning, since it is stylish, fashionable and youthful.  From previous knowledge in this topic, I had only a couple of presentations from the lead developer, which were more popularizing than informational. <br><br>  I identified a specific problem to solve it using machine learning and started digging.  I want to note that having the ultimate goal was easier to navigate the flow of information. <br></div></div><br><h3>  Stick a shovel </h3><br>  First of all, I went to the official website of TensorFlow and read <a href="https://www.tensorflow.org/get_started/get_started_for_beginners">ML for Beginners</a> and <a href="https://www.tensorflow.org/get_started/premade_estimators">TensorFlow for beginners</a> .  Materials in English. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      TensorFlow is a Google team handicraft and the most popular machine learning library that supports Python, Java, C ++, Go, as well as the ability to use the computing power of a graphics card for computing complex neural networks. <br><br>  In my search, I found another library for machine learning, <a href="http://scikit-learn.org/stable/">Scikit-learn</a> oriented to Python.  Plus of this library, in a large number of algorithms for machine learning right out of the box, which was a definite plus in my case, since the presentation was on Friday, and I really wanted to demonstrate a working model. <br><br>  In search of ready-made examples, I came across a <a href="https://bugra.github.io/work/notes/2014-12-26/language-detector-via-scikit-learn/">tutorial</a> on the definition of the language in which the text was written using Scikit-learn. <br><br>  So, my task was to train the model to determine the presence of SQL injections in the text string.  (Of course, you can solve this problem with regular expressions, but for educational purposes, you can <s>shoot a cannon on sparrows</s> ) <br><br><h3>  First of all, first thing dataset ... </h3><br>  The type of task that I am trying to solve is a classification, that is, the algorithm should, in response to fed data, give me which category this data belongs to. <br><br>  The data in which the algorithm will look for patterns are called <b>features</b> . <br>  The category to which a particular feature belongs is called a <b>label</b> .  It is important to note that the input data may have several features, but only one label. <br><br>  In the classic example of machine learning, identifying varieties of iris flowers along the length of pistils and stamens, each individual column with information about the size of this <b>feature</b> , and the last column, which means to which of the subspecies of iris the flower with such values ‚Äã‚Äãis <b>label</b> <br><br><img src="https://habrastorage.org/webt/y0/uh/ya/y0uhyaecndyzfatuzpo-jjodhro.png"><br><br>  The way I will solve the classification problem is called supervised learning, or supervised learning.  This means that in the process of learning, the algorithm will receive both features and labels. <br><br>  Step number one in solving any problem using machine learning is the collection of data on which this machine will learn.  In an ideal world, this should be real data, but, unfortunately, I could not find anything on the Internet that would satisfy me.  It was decided to generate the data independently. <br><br>  I wrote a script that generated random email addresses and SQL injections.  As a result, in my csv file there were three types of data: random emails (20 thousand), random emails with SQL injection (20 thousand) and clean SQL injections (10 thousand).  It looked like this: <br><br><img src="https://habrastorage.org/webt/pq/om/iv/pqomivxywui7urtgouvg1wvd1yw.png"><br><br>  Now the source data must be considered.  The function returns sheet X, which contains features, sheet Y, which contains labels for each feature and sheet label_names, which simply contains textual definitions for labels, is needed for convenience when displaying the results. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_dataset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> X = [] y = [] label_names = [<span class="hljs-string"><span class="hljs-string">"safe data"</span></span>,<span class="hljs-string"><span class="hljs-string">"Injected email"</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'trainingSet.csv'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> csvfile: readCSV = csv.reader(csvfile, delimiter=<span class="hljs-string"><span class="hljs-string">'\n'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> row <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> readCSV: splitted = row[<span class="hljs-number"><span class="hljs-number">0</span></span>].split(<span class="hljs-string"><span class="hljs-string">','</span></span>) X.append(splitted[<span class="hljs-number"><span class="hljs-number">0</span></span>]) y.append(splitted[<span class="hljs-number"><span class="hljs-number">1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"\n\nData set features {0}"</span></span>. format(len(X))) print(<span class="hljs-string"><span class="hljs-string">"Data set labels {0}\n"</span></span>. format(len(y))) print(X) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> X, y, label_names</code> </pre> <br>  Further, these data need to be broken into a training set and a test one.  The cross_validation.train_test_split () function carefully written for us will help us with this. It will shuffle the records and return us four sets of data - two training and two test for features and labels. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Split the dataset on training and testing sets X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2,random_state=0)</span></span></code> </pre> <br>  Then we initialize the vectorizer object, which will read the data transferred to it by one character, combine them into <a href="https://ru.wikipedia.org/wiki/N-%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B0">N-grams</a> and translate into numerical vectors, which is capable of perceiving the machine learning algorithm. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#Setting up vectorizer that will convert dataset into vectors using n-gram vectorizer = feature_extraction.text.TfidfVectorizer(ngram_range=(1, 4), analyzer='char')</span></span></code> </pre><br><h3>  We feed the data </h3><br>  The next step is to initialize the pipeline and transfer to it the previously created vectorizer and the algorithm with which we want to analyze our data set.  In this we will use the <a href="https://ru.wikipedia.org/wiki/%25D0%259B%25D0%25BE%25D0%25B3%25D0%25B8%25D1%2581%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D1%258F">logistic regression</a> algorithm. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#Setting up pipeline to flow data though vectorizer to the liner model implementation pipe = pipeline.Pipeline([('vectorizer', vectorizer), ('clf', linear_model.LogisticRegression())])</span></span></code> </pre><br>  The model is ready for data digestion.  Now we simply transfer training sets of features and labels to our pipeline and the model starts learning.  In the next line we skip the test set features through the pipeline, but now we use the predict to get the number of correctly guessed data. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#Pass training set of features and labels though pipe. pipe.fit(X_train, y_train) #Test model accuracy by running feature test set y_predicted = pipe.predict(X_test)</span></span></code> </pre><br>  If you want to know how accurate the model is in predictions, you can compare the correct data and the test labels. <br><br><pre> <code class="python hljs">print(metrics.classification_report(y_test, y_predicted,target_names=label_names))</code> </pre> <br>  The accuracy of the model is determined by the value from 0 to 1, and can be converted to percentages.  This model gives the correct answer in 100% of cases.  Of course, using real data, this result is not so easy to achieve, and the task is quite simple. <br><br><img src="https://habrastorage.org/webt/ol/20/xp/ol20xpd9chilxry1vp-4axwoilw.png"><br><br>  The final final touch is to keep the model in a trained form so that it can be used without any re-training in any other python program.  We serialize the model into a pickle file using the built-in Scikit-learn functions: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#Save model into pickle. Built in serializing tool joblib.dump(pipe, 'injection_model.pkl')</span></span></code> </pre><br>  A small demonstration of how to use the serialized model in another program. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.externals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> joblib <span class="hljs-comment"><span class="hljs-comment">#Load classifier from the pickle file clf = joblib.load('injection_model.pkl') #Set of test data input_data = ["aselectndwdpyrey@gmail.com", "andrew@microsoft.com'", "a.johns@deloite.com", "'", "select@mail.jp", "update11@nebuzar.com", "' OR 1=1", "asdasd@sick.com'", "andrew@mail' OR 1=1", "an'drew@bark.1ov111.com", "andrew@gmail.com'"] predicted_attacks = clf.predict(input_data).astype(np.int) label_names = ["Safe Data", "SQL Injection"] for email, item in zip(input_data, predicted_attacks): print(u'\n{} ----&gt; {}'.format(label_names[item], email))</span></span></code> </pre><br>  At the output we get the following result: <br><br><img src="https://habrastorage.org/webt/fg/oc/wa/fgocwavzgzb1fcgetbkegume3zm.png"><br><br>  As you can see, the model confidently determines SQL injections. <br><br><h3>  Conclusion </h3><br>  As a result, we have a trained model for determining SQL injections, in theory, we can plug it into the server part, and in the case of injection detection, redirect all requests for a fake database to keep us from looking at other possible vulnerabilities.  To demonstrate at the end of the week, I wrote a small REST API on Flask. <br><br>  These were my first steps in machine learning.  I hope that I can inspire those who, like me for a long time, looked at machine learning with interest, but were afraid to touch it. <br><br><div class="spoiler">  <b class="spoiler_title">Full code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ensemble <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> feature_extraction <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> linear_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pipeline <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cross_validation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> metrics <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.externals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> joblib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_data <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-comment"><span class="hljs-comment"># Load the dataset from the csv file. Handled by load_data.py. Each email is split in characters and each one has label assigned X, y, label_names = load_data.get_dataset() # Split the dataset on training and testing sets X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2,random_state=0) #Setting up vectorizer that will convert dataset into vectors using n-gram vectorizer = feature_extraction.text.TfidfVectorizer(ngram_range=(1, 4), analyzer='char') #Setting up pipeline to flow data though vectorizer to the liner model implementation pipe = pipeline.Pipeline([('vectorizer', vectorizer), ('clf', linear_model.LogisticRegression())]) #Pass training set of features and labels though pipe. pipe.fit(X_train, y_train) #Test model accuracy by running feature test set y_predicted = pipe.predict(X_test) print(metrics.classification_report(y_test, y_predicted,target_names=label_names)) #Save model into pickle. Built in serializing tool joblib.dump(pipe, 'injection_model.pkl')</span></span></code> </pre><br></div></div><br><h3>  Reference materials </h3><br>  I leave a list of useful resources that helped me with this project (almost all of them are in English) <br><br>  <a href="https://www.tensorflow.org/get_started/get_started_for_beginners">Tensorflow for begginers</a> <br>  <a href="http://scikit-learn.org/stable/tutorial/index.html">Scikit-Learn Tutorials</a> <br>  <a href="https://bugra.github.io/work/notes/2014-12-26/language-detector-via-scikit-learn/">Building Language Detector via Scikit-Learn</a> <br><br>  I found several excellent <a href="https://medium.com/%40ageitgey/machine-learning-is-fun-80ea3ec3c471">articles on Medium</a> including a series of eight articles that give a good idea of ‚Äã‚Äãmachine learning with simple examples.  ( <a href="https://algotravelling.com/ru/%25D0%25BC%25D0%25B0%25D1%2588%25D0%25B8%25D0%25BD%25D0%25BD%25D0%25BE%25D0%25B5-%25D0%25BE%25D0%25B1%25D1%2583%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5-%25D1%258D%25D1%2582%25D0%25BE-%25D0%25B2%25D0%25B5%25D1%2581%25D0%25B5%25D0%25BB%25D0%25BE-1/">UPD: Russian translation of the same articles</a> ) </div><p>Source: <a href="https://habr.com/ru/post/350984/">https://habr.com/ru/post/350984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../350972/index.html">Organization of information systems production processes. Part 1. Starting point</a></li>
<li><a href="../350974/index.html">Slingshot APT: Advanced virus found - it went unnoticed for 6 years</a></li>
<li><a href="../350976/index.html">Guide to SEO javascript sites. Part 1. The Internet through the eyes of Google</a></li>
<li><a href="../350978/index.html">Drupal 8 + Varnish: Cache HTML correctly</a></li>
<li><a href="../350982/index.html">6 myths about Service Fabric</a></li>
<li><a href="../350986/index.html">Centralized continuous deployment for the year vol 2</a></li>
<li><a href="../350988/index.html">Recruitment: play, hitting the target</a></li>
<li><a href="../350990/index.html">‚ÄúWe'll have to write by ourselves. They sat down and wrote ": the life of the developers of the laboratory cluster of super-arrays in Sbertech</a></li>
<li><a href="../350992/index.html">Organization of information systems production processes. Part 2. Formation of the design solution</a></li>
<li><a href="../350994/index.html">31 business cybersecurity tips</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>