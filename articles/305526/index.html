<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>City AD: schoolchildren and students</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr. This year, we have quite successfully passed experiments to involve young programmers in AD: 


- started a hackathon where schoolchildren a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>City AD: schoolchildren and students</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/961/5c2/119/9615c21190444158b121a489601135e4.png"></p><br><p>  Hi, Habr.  This year, we have quite successfully passed experiments to involve young programmers in AD: </p><br><ul><li><p>  started a <a href="https://habrahabr.ru/post/276079/">hackathon</a> where schoolchildren and students competed on an equal footing (schoolchildren won), helped organize <a href="https://habrahabr.ru/post/283430/">the NTI Olympiad</a> based on big data. </p><br></li><li><p>  opened the <a href="https://habrahabr.ru/company/goto/blog/302334/">direction of</a> hellish miracles <a href="https://habrahabr.ru/post/261041/">in summer schools</a> .  They learned how parametric modeling was mastered, how the schoolchildren wrote the recommendation system of the Rain news, mastered the basics of Mitnick's social engineering, we will tell in the next article. </p><br></li><li>  organized meetings for the "bitten" in Yandex with the Hedgehog.  The Hedgehog (Alexander Panin) did not resist the charm of the young "dataseintists" on the hackathon, since every Saturday one of the talks turns into a Small AD to the sounds of the harp, on which the Hedgehog plays during the breaks. </li></ul><br><h4>  School </h4><br><p>  Inspired by the persistence of the guys, we decided to start involving older students.  Conceived <a href="http://goto.msk.ru/school">school</a> right in Moscow, it will take place from August 1 to August 8 at the Faculty of Computer Science of the Higher School of Economics; everyone who is under the age of 22 is invited to participate. </p><br><p>  The school program consists of two blocks: an intensive with case analysis from leading industry experts and team work on a project with an experienced curator. </p><br><h4>  Selection </h4><br><p>  To participate, it is necessary to pass the selection - to solve the real problem faced by our partner E-Contenta when developing the recommendation engine for Tviz.tv.  Until July 25, we make decisions in any way - it is interesting to look at non-standard ideas, perhaps, who will surpass the partner‚Äôs decision.  Experienced participants have the opportunity to declare themselves and win a grant for free education. </p><br><p>  Our goal is to give young people the opportunity to immerse themselves in Data Science not for 180 thousand in "adult" courses.  Selection is aimed primarily at testing motivation. </p><a name="habracut"></a><br><h4>  Qualifying task </h4><br><p> The main task is to analyze the interests of users based on the available data and build an algorithm for recommending new films. <br>  In the beginning, it is proposed to solve several simple analytical problems (tasks 1 and 2) using the proposed data, and then try to get a solution to the creative problem. <br>  The ideal solution to the task should contain: an answer, a code that reproduces this answer, and a description of what you have done.  The solution is recommended to be sent in the Python language (2.7 or 3.4 / 3.5).  You can use any library if you are ready to explain in a conversation how they work.  If you ‚Äúwrite off‚Äù (borrow materials from the Internet) - please refer to the source.  Borrowing at the specified source is not punished, if you are able to explain what exactly is happening in the code and why it solves the problem for which you use it.  Cheating without specifying the source is always punishable. <br>  The code that works not only for you is welcome (especially for the advanced direction) (for example, it is useful to pin the dependencies in <code>requirements.txt</code> ).  It is also desirable to have an obvious / documented entry point.  Git-repositories with signed commits, laid out in IPFS, will be considered separately :) </p><br><h4>  Data </h4><br><p>  Archive data can be downloaded <a href="https://yadi.sk/d/SqsWFcpds9rTL">here</a> .  Part of the data was anonymized, part is missing - in the real world the server is broken, the data disappears.  <a href="https://github.com/goto-ru/2016.09-school-baseline/blob/master/data_manipulation.ipynb">An example of reading data</a> . </p><br><p>  In it you will find: </p><br><p>  A sample of which viewers liked which movies. </p><br><div class="spoiler">  <b class="spoiler_title">train_likes.csv</b> <div class="spoiler_text"><p>  A table with lines like user_id, item_id, channel, time. </p><br><ul><li>  user_id - viewer id </li><li>  item_id - movie id </li><li>  channel - channel identifier </li><li>  time - time (timestamp) </li></ul><br><p>  Each such four means that at the moment of <code>time</code> user <code>user_id</code> liked the movie <code>item_id</code> , <br>  which went on <code>channel</code> . </p></div></div><br><p>  Movie descriptions </p><br><div class="spoiler">  <b class="spoiler_title">items.json</b> <div class="spoiler_text"><p>  Metadata about movies in json format (opens with any standard json module).  Each line must contain: </p><br><ul><li>  id - movie id </li><li>  duration - the duration of the movie </li><li>  year - production year ratio </li><li>  genre - genre number (categorical variable, 10 genres in total) </li><li>  f_ {number} - additional features (see below). </li></ul><br><p>  The coefficients of the <code>duration</code> and <code>year</code> - the arithmetic transformation of the duration of the film and the year of release, made in order to save personal data. </p><br><p>  Signs of <code>f_*</code> are various anonymized signs of the film.  Examples of such signs are ‚ÄúProduction Country ‚Äî USA‚Äù or ‚ÄúBudget is greater than $ 100k‚Äù (yes ‚Äî 1, no ‚Äî 0 or not present). </p><br><p>  Important.  Not all films have a description line: about 2/3 of the films that were stuck are described. </p></div></div><br><p>  Movie schedule </p><br><div class="spoiler">  <b class="spoiler_title">schedule.csv</b> <div class="spoiler_text"><p>  A table with lines of the form <code>time_end, time_start, item_id, channel</code> . </p><br><ul><li>  time_end - transfer end time </li><li>  time_start - the start time of the transfer </li><li>  item_id - movie id </li><li>  channel - channel id </li></ul></div></div><br><p>  <strong>Task 1</strong> <strong><br></strong> <br>  Not all channels and not all movies are equally popular.  First, calculate how many average user likes ( <code>train_likes</code> ) are in one channel.  Also count the number of movies that have at least 5 likes.  The recommended output format is one real number (average number of likes per channel) and one integer (number of movies with 5+ likes). </p><br><p>  <strong>Task 2</strong> <strong><br></strong> <br>  Viewers usually have their own genre preferences, and these preferences may vary from channel to channel.  Note that not all films are known for their genres - such films will have to be counted separately.  First, calculate the amount of likes for each genre and separately for movies where the genre is unknown.  Next, calculate the same amount of likes by genre for each of the top 10 most favorite channels. <br>  The recommended output format is a line of numbers: the number of likes of each genre ascending the number of the genre, at the end the number of likes for films with an unknown genre.  Next, 10 of the same lines for each of the top 10 channels in popularity.  It is necessary to clarify which channel is shown on each line. </p><br><p>  <strong>Task 3</strong> <strong><br></strong> <br>  Your main goal is to learn how to recommend movies to users so that they like them.  There are many ways to do this using fairly simple assumptions.  For example: </p><br><ul><li>  You like movies like those that you already had.  If there is a movie in the sample that is featured by ( <code>items.json</code> ) is similar to other movies you like, then you will probably like this movie too. </li><li>  Similar users like similar movies.  If users who like the same movies as you usually like 1 more movie that you don‚Äôt know about, you will most likely like this movie. </li><li>  Channels form their programs in such a way that at one time there are programs designed for approximately the same audience. </li><li>  And so on </li></ul><br><h4>  Parting words and help </h4><br><p>  Your first task is to create a minimum workable solution.  If you have not previously used machine learning, you can try using the intuitive considerations above and a hard-coded predictive algorithm. </p><br><p>  Not all such ideas will work, so you will need to check whether this or that hypothesis works.  For example, to check how the idea of ‚Äã‚Äã‚Äúlooking at similar users‚Äù works, you can use the metric <a href="https://stackedit.io/viewer">mAP @ k</a> or <a href="https://stackedit.io/viewer">NDCG</a> . </p><br><p>  You can also offer your quality assessment methodology and tell us why you chose it.  Be sure to describe all your attempts, good luck and failures in the report: we will know what to teach you.  Those who cannot attend school or are over 22 years old, but would like to exercise, can also send us solutions, send feedback and invite you to visit. </p><br><p>  <strong>A lot of good about collaborative filtering under the spoiler ‚Üì</strong> </p><br><div class="spoiler">  <b class="spoiler_title">Baseline to help</b> <div class="spoiler_text"><p>  tl; dr: <a href="https://github.com/goto-ru/2016.09-school-baseline">https://github.com/goto-ru/2016.09-school-baseline</a> . </p><br><p>  The baseline we have prepared is based on the second idea - collaborative filtering. <br>  In our algorithm, we use only data about likes, forgetting about the signs of the film.  This is a very rough assumption, for sure, entering information about the content of the film will significantly improve the result, try it. </p><br><p>  The idea behind the root of our method is as follows: </p><br><ul><li>  user likes the same movies as similar users </li><li>  the movie is watched by the same users that watch movies similar to it </li></ul><br><p>  In other words, each user has some unknown set of interests that determines which films he likes.  The film, in turn, also has a profile that is responsible for how much the audience likes it.  We do not know the psychological profile of each user and the audience of each film, but we can restore it using the above ideas. </p><br><p>  <b>Cosine measure</b> <b><br></b> </p><br><p>  First, we will consider an intuitive way of solving the problem, based on how the user is suitable for the movie audience. <br>  We present the data in the format of the <code> -&gt;  </code> .  The recommendation of the item movie to the user user is calculated as follows: </p><br><ul><li>  For each movie polynkannogo user, we find other people who liked the movie. </li><li>  Let's put all such ‚Äúfriends on likes‚Äù together and call them the neighbors (neighborhood) of the user. </li><li>  For an item movie, find out its audience - many users who liked it </li><li>  The suitability of a movie to a user is how much the user's ‚Äúlike friends‚Äù like this movie. </li></ul><br><p>  <a href="https://nbviewer.jupyter.org/github/goto-ru/2016.09-school-baseline/blob/master/baseline-simple.ipynb">Detailed description of the algorithm</a> . </p><br><p>  This method is probably better than random fortune telling, however, it treats all the "neighbors" of the user in the same way, guided only by the number of times they have watched the same films. <br>  Since users usually watch quite a few films, it will often turn out that two users with almost perfectly coinciding interests do not have ‚Äúcommon‚Äù films, although the films of one user would have liked the other if he knew about them. </p><br><p>  <strong>Svd</strong> </p><br><p>  In order to correct this shortcoming, we will try to move from "users who have watched movies watched by another user" to explicitly obtain "user interests" and "movie audience".  This move will greatly improve the quality of the result. </p><br><p>  <a href="https://nbviewer.jupyter.org/github/goto-ru/2016.09-school-baseline/blob/master/baseline-intermediate.ipynb">So, math</a> . </p><br><img src="https://habrastorage.org/files/eaf/7a3/2f9/eaf7a32f931f4eb085d4d1196471afab.jpg"><br><p>  The rich inner world of the user and the artistic depth of the film must somehow be encoded, and even so that it is easy to understand how close two users are, two films or how much the film fits the user. </p><br><p>  We probably don‚Äôt want to do this with our hands, so like all normal mathematics we say that the user's soul is limited to a vector of several numbers.  Knowing the complexity and versatility of human nature, we will allocate as much as 100 numbers (of any real numbers).  What exactly are the numbers - do not yet know. </p><br><p>  For fidelity, we will also match 100 numbers.  In the language of mathematicians, we have just introduced 2 vectors - the vector of "user interests" and the vector of "film audience".  In the language of programmers, we declared 2 arrays, did not specify them at all, and we show off without any reason. </p><br><p>  Now let's understand what we want from these vectors. <br>  Let's say that vectors are "similar" if their scalar product is large.  How big is this scalar product, too, do not say - we are mathematicians!  We can only say that similar users have more than dissimilar ones.  The same with movies - let similar films have a scalar product larger, and unlike films smaller. </p><br><p>  Finally, the most important thing is that we have a user vector, we have a movie vector.  Let's want the scalar product of the vector of the user to the vector of the film to be as close as possible to 1 if the user likes this movie, and to 0 if they do not like it or not. <br>  Why so - yes, that's what they wanted.  It might have been desirable that if the film was not to be liked, it was -1, and if they didn‚Äôt watch it, it was 0, but unfortunately, we only have ‚Äúlikes‚Äù of users - there are no dictionaries in the sample. </p><br><p>  And now let's move to a larger scale.  We have several tens of thousands of users and even more - movies. <br>  We also know that such users like this movie. </p><br><p>  We will be generous, give 100 numbers to each user, and even to each film.  We can do it this way - the number in float32 weighs 4 bytes, and we need these numbers according to rough estimates (number of users + number of films) ~ 10 ^ 5. <br>  We need the main condition to be fulfilled: the scalar product of the user's soul to the movie audience should be closer to 1 if the user likes the movie, and 0 if not like. </p><br><p>  Let's call a vector <img src="https://tex.s2cms.ru/svg/i" alt="i">  of that user <img src="https://tex.s2cms.ru/svg/U_%7Bi%7D" alt="U_ {i}">  vector <img src="https://tex.s2cms.ru/svg/j" alt="j">  of that film <img src="https://tex.s2cms.ru/svg/V_%7Bi%7D" alt="V_ {j}">  .  For simplicity of notation, <img src="https://tex.s2cms.ru/svg/U" alt="U">  - All users, <img src="https://tex.s2cms.ru/svg/V" alt="V">  - all movies. </p><br><p>  Achieving perfect equality is most likely not possible, and the fewer numbers we give per soul / film, the worse the approximation will be, but we will be satisfied if the scalar product is just close enough to the correct value. <br>  In the language of mathematicians, such a task is called an optimization problem: we want to select such vectors of users and films so that the error is minimal: </p><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Csum_%7Bi%2Cj%7D((U_%7Bi%7D%20%2CV_%7Bj%7D)-like_%7Bi%2Cj%7D)%5Cto%20min%2C" alt="\ sum_ {i, j} ((U_ {i}, V_ {j}) - like_ {i, j}) \ to min,"></div><br><p>  Where <img src="https://tex.s2cms.ru/svg/like_%7Bi%2Cj%7D%3D1" alt="like_ {i, j} = 1">  if user <img src="https://tex.s2cms.ru/svg/U_%7Bi%7D" alt="U_ {i}">  liked <img src="https://tex.s2cms.ru/svg/V_%7Bi%7D" alt="V_ {i}">  otherwise 0. </p><br><p>  Finally, to fit the methods of well-known mathematicians, we introduce for each of the 100 components of the "importance" vectors - the same for all users / films.  Formally, this is the S vector, in which again there are 100 numbers. </p><br><div style="text-align:center;"><img src="https://tex.s2cms.ru/svg/%5Csum_%7Bi%2Cj%7D((U_%7Bi%7D%20%2CS%2CV_%7Bj%7D)-like_%7Bi%2Cj%7D)%5Cto%20min%2C" alt="\ sum_ {i, j} ((U_ {i}, S, V_ {j} - like_ {i, j}) \ to min."></div><br><div class="spoiler">  <b class="spoiler_title">Gradient descent</b> <div class="spoiler_text"><p>  One way to solve the problem can be described like this: <br>  First we write in <img src="https://tex.s2cms.ru/svg/U_%7Bi%7D" alt="U">  and <img src="https://tex.s2cms.ru/svg/V_%7Bi%7D" alt="V">  all users and movies are random numbers. <br>  Next in the loop: </p><br><ul><li>  We select the user <img src="https://tex.s2cms.ru/svg/U_%7Bi%7D" alt="U_ {i}">  and film <img src="https://tex.s2cms.ru/svg/V_%7Bi%7D" alt="V_ {i}">  . </li><li>  We consider the scalar product of vectors <img src="https://tex.s2cms.ru/svg/U_%7Bi%7D" alt="U">  , <img src="https://tex.s2cms.ru/svg/S_%7Bi%7D" alt="S">  , <img src="https://tex.s2cms.ru/svg/V_%7Bi%7D" alt="V">  . </li><li>  We consider an "error" if we have not gotten (negative error) - we move the numbers to <img src="https://tex.s2cms.ru/svg/U_%7Bi%7D" alt="U_ {i}">  , <img src="https://tex.s2cms.ru/svg/S_%7Bi%7D" alt="S">  and <img src="https://tex.s2cms.ru/svg/V_%7Bi%7D" alt="V_ {i}">  so that the dot product is slightly increased.  If we overdo it (the error is positive), we move the same numbers in the opposite direction. </li><li><p>  Finally, if the error is zero, change nothing. </p><br><p>  Now select the next user and repeat the process until U, S and V are set to approximately the same values.  Due to the fact that every time we choose a new user and a movie, such reductions-increases on average over many iterations will reduce our ‚Äúmistake‚Äù, and to the best degree, fulfill our ‚ÄúWishlist‚Äù.  Thus, after many iterations, we get the vectors suitable for our problem. </p><br></li></ul></div></div><br><p>  From deliberately limiting the number of numbers in the vectors to 100, not allowing us to perfectly fit all likes and non-likes, we are only better off: </p><br><ul><li>  We train our model on those likes that are in the sample.  If we give ideal units on polikan films and ideal zeros on non-polished ones, we cannot recommend the user any films other than those that he has already watched. </li><li>  If our algorithm is specifically co-ordinated, then on some films from among the non-tiled ones, the algorithm will produce a large scalar product - by mistake.  In other words, it seems that the interests of the user fall under the typical audience of the film, but the trouble is that in fact the user did not like this film. </li><li>  In fact, this is no mistake - if the movie is so suitable for the user, but he hasn‚Äôt liked it yet, then it's time to recommend the movie to the user, and the user is likely to like it. </li></ul><br><p>  Moving from idea to implementation and from concept to specific methods and data structures: in a simple form, it suffices to take only <code>user_id &lt;-&gt; film_id</code> from <code>train_likes.csv</code> ;  each such pair means that the user <code>user_id</code> watched the <code>film_id</code> (and there is also time and channel in the same file, which we now ignore).  We build from these relationships a sparse adjacency matrix, to which we apply Truncated Singular Value Decomposition.  This method compresses the original matrix, trying to find such a hidden feature space where the feature vectors of users and films they like are close;  we get the kth order approximation.  After this compression, we reconstruct the original matrix - with some error.  It is thanks to this error that everything works: well, films that the user has not watched, but who like users like him, will now have a value not of <code>0</code> , but <code>0.4</code> , because  we could not save all the data under compression, and the user "mixed" with those similar to himself. </p><br><p>  The code is based on the above: <a href="https://github.com/goto-ru/2016.09-school-baseline">matrix decomposition and reproducible notebooks to watch for free without SMS</a> . </p><br><p>  Once again we emphasize that the above uses only the minimum possible data: whether the user watched a movie or not.  Considering additional metadata (for example, genre or time of display), one can significantly improve the quality of prediction;  a combination of collaborative and content filtering methods (through initialization, for example, a matrix of feature films derived from metadata) is the next logical step <del>  on a slippery data analysis track </del>  in solving this problem. </p></div></div><br><div class="spoiler">  <b class="spoiler_title">Solution interface</b> <div class="spoiler_text"><p>  Recommended interface: it is desirable that your program has a function ( <a href="https://nbviewer.jupyter.org/github/goto-ru/2016.09-school-baseline/blob/master/baseline-intermediate.ipynb">example</a> ) that takes parameters (user_id, film_id, additional information) and returns the predicted confidence of the model in like.  To calculate the ranking metrics you also need a <a href="https://nbviewer.jupyter.org/github/goto-ru/2016.09-school-baseline/blob/master/baseline-intermediate.ipynb">ranking interface</a> : <code>(user_id, k) -&gt; Sequence[confidence]</code> . <br>  The main thing that will affect the assessment is the performance of the solution (significantly better than at random), the validity of the assessment of the quality of the decision, and only then the final quality.  A simple working solution that is honestly analyzed is always better than an insane mixture of everything that you found on the Internet, about which it is not clear how it works and an overestimation of quality.  Machine learning is desirable but not necessary. <br>  In addition to such a system, I would like to receive a report from you in an arbitrary format, from which you can understand exactly what you did and why, as well as how you evaluated the quality of your recommendation system.  The recommended maximum report size is 3000 characters, including spaces: <code>(assert len(u""" """) &lt;=3000)</code> . </p></div></div><br><p>  We are waiting for all possible solutions, and even with great impatience - solutions without ML.  The main thing is motivation, and ignorance of ML is a sure sign that the school will be useful. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/305526/">https://habr.com/ru/post/305526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../305512/index.html">Pass a technical interview (level 3)</a></li>
<li><a href="../305514/index.html">Rclone: ‚Äã‚Äãrsync for clouds</a></li>
<li><a href="../305516/index.html">The thorny path of ITSM in Russia</a></li>
<li><a href="../305520/index.html">How artificial restrictions help in work</a></li>
<li><a href="../305524/index.html">Organization of an international gambling company in Curacao</a></li>
<li><a href="../305528/index.html">Android development using qt and android studio part two</a></li>
<li><a href="../305530/index.html">Linux kernel module on Swift</a></li>
<li><a href="../305532/index.html">Sort warnings of static analyzers by priority when searching for and fixing program errors</a></li>
<li><a href="../305534/index.html">Clojure course materials</a></li>
<li><a href="../305536/index.html">Rust code is included in Firefox 48</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>