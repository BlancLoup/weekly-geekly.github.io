<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Experiments with Neural Interfaces in JavaScript</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The author of the material, the translation of which we are publishing today, says that for the last couple of years he has noticed a steady interest ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Experiments with Neural Interfaces in JavaScript</h1><div class="post__text post__text-html js-mediator-article">  The author of the material, the translation of which we are publishing today, says that for the last couple of years he has noticed a steady interest in neurotechnology.  In this article, she wants to talk about her experiments with various hardware and software systems that allow you to establish a connection between the brain and the computer. <br><br> <a href="https://habr.com/company/ruvds/blog/433874/"><img src="https://habrastorage.org/webt/gw/xa/hl/gwxahlizikvt65xbfo0wr-3vrts.jpeg"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Prehistory</font> </h2><br>  I do not have basic computer education (I studied advertising and marketing).  I mastered programming on courses in General Assembly. <br><br>  When I was looking for the first job, I started experimenting with JavaScript and with different devices.  In particular, my first project was the management organization of the <a href="https://www.sphero.com/de_de/%3F___store%3Dde_de">Sphero</a> robotic ball through arm movement using <a href="https://www.leapmotion.com/">Leap Motion</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/032/a1b/9e4/032a1b9e490fa0c6a9c1875450e03f4e.gif"></div><br>  <i><font color="#999999">Sphero ball, hand operated with Leap Motion technology</font></i> <br><br>  This was my first experience using JavaScript to manage something outside of the browser.  I was immediately, as they say, "hooked." <br><br>  Since then, I have spent a lot of time working on interactive projects.  Every time, taking on a new project, I tried to find for myself more and more complex tasks.  So I constantly developed and learned something new. <br><br>  After experimenting with various devices, in search of another interesting task, I came across sensors of brain activity from the <a href="http://neurosky.com/">NeuroSky</a> company. <br><br><h2>  <font color="#3AC1EF">The first experiments with the neuro headset</font> </h2><br>  When I was interested in experiments with sensors of brain activity, I decided to purchase a NeuroSky neuro headset.  She was much cheaper than other similar offers. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4bf/3a6/f45/4bf3a6f459737bb3ef29bc51ee256f71.png"></div><br>  <i><font color="#999999">NeuroSky Neuro Headset</font></i> <br><br>  I didn‚Äôt know if my qualification was enough to write at least something for such a device (I just finished programming courses at that moment), so I decided to choose something cheaper so that if the task turns out to be for me prohibitively difficult, do not waste too much money.  Fortunately, a JavaScript framework has already been created to work with the headset, so it was quite easy to start the experiments.  In particular, I used the assessment of the level of my attention to control the Sphero ball and the Parrot AR.Drone quadrocopter. <br><br>  During the experiments, I quickly realized that this neuro headset is not particularly accurate.  She has only three sensors, so she allows to obtain rather approximate data on brain activity.  The device gives access to the raw data from each sensor, which allows, for example, to visualize this data.  But the fact that the headset has only three electrodes does not allow us to draw any serious conclusions about what is happening in the human brain based on the data obtained from it. <br><br>  When I decided to look for other devices for reading indicators of brain activity, I found a nemo headset <a href="https://www.emotiv.com/epoc/">Emotiv Epoc</a> .  I got the feeling that this thing has more serious features in comparison with the NeuroSky headset, so I decided to buy it to continue my experiments. <br><br>  Before I talk about how Emotiv Epoc works, I suggest to briefly talk about how the human brain works. <br><br><h2>  <font color="#3AC1EF">How the brain works</font> </h2><br>  I can't call myself a great neuroscience expert, so my story about the brain will be rather superficial.  Namely, I want to talk about a few basic things that need to be known to those who want to better understand how the neurohearnes work. <br>  The brain consists of many billions of neurons - specialized cells that are engaged in the processing, storage and transmission of information.  Different parts of the brain, consisting of neurons, are responsible for different physiological functions. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ddb/e6d/880/ddbe6d8800bda77bd95562ab92692f32.jpg"></div><br>  <i><font color="#999999">Different parts of the brain (source - macmillan.org.uk)</font></i> <br><br>  For example, let's talk about how the brain controls the movements.  Parts of the brain, such as the primary motor cortex and the cerebellum, are responsible for movement and coordination.  The signals of the corresponding neurons act on the muscles, which leads to movements. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/604/43a/ef2/60443aef22e4bb9cd5bc50e3dc694677.jpg"></div><br>  <i><font color="#999999">Neuron Anatomy</font></i> <br><br>  As I said, an extremely simple description of the brain is presented here, but for us the most important thing is that the activity of neurons can be tracked by electroencephalography (EEG) methods, by reading indicators of brain electrical activity from the surface of the scalp. <br><br>  Other technologies can also be used to monitor brain activity, but their use implies surgery.  In particular, we are talking about electrocorticography - with this approach, the electrodes are superimposed directly on the cerebral cortex. <br><br>  Now that we‚Äôve figured out that the brain generates electrical signals that can be read as we work, let's talk about the Emotiv Epoc headset. <br><br><h2>  <font color="#3AC1EF">How the neuro headset works</font> </h2><br>  The Emotiv company produces several types of neurogarnitures: <br><br><ul><li>  Emotiv Insight </li><li>  Emotiv Epoc Flex Kit </li><li>  Emotiv Epoc </li></ul><br>  The Epoc headset has 14 sensors (also called ‚Äúchannels‚Äù) located in different places of the head. <br><br>  The following figure, on the left, shows the layout of electrodes 10-20 recommended by the International Federation of Electroencephalography and Clinical Neurophysiology.  Each electrode corresponds to a specific area of ‚Äã‚Äãthe brain.  The use of the 10-20 system allows you to follow a certain standard when creating various devices and performing scientific research of the brain. <br>  The figure on the right shows the layout of the electrodes of the Emotiv Epoc headset.  To compare it with the 10-20 system, the selection is green and orange. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8c5/fd0/907/8c5fd0907892ad6a6b829b2ed646312f.png"></div><br>  <i><font color="#999999">Comparison of the international electrode placement system 10-20 and the Emotiv Epoc headset</font></i> <br><br>  The 14 Epoc channels are not so much, but the electrodes are placed evenly across the scalp.  This gives hope that with Epoc it is possible to obtain fairly accurate information about brain activity. <br><br>  The headset captures sensors at a frequency of 2048 samples per second (SPS).  At the same time, the user has access to the signal sampling rate of 128 or 256 SPS.  The device is capable of capturing brain waves with a frequency of 0.16 to 43 Hz.  There are various rhythms of the brain, their brief characteristics are shown in the following figure. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/9f0/8d5/fb59f08d59ec0df374852e294c593499.jpg"></div><br>  <i><font color="#999999">Brain Wave Types</font></i> <br><br>  Why is it important?  The fact is that depending on the application that needs to be built on the basis of an electroencephalograph, we may need to pay special attention to brain waves of a certain frequency.  For example, if we need to create a program to help meditators, then we will probably be interested only in theta waves, whose frequency is 4-8 Hz. <br><br>  Having dealt with the principles underlying electroencephalography, let's talk about the capabilities of Emotiv Epoc and related software. <br><br><h2>  <font color="#3AC1EF">Emotiv Epoc features</font> </h2><br>  Emotiv software is not open source, a special license is required to access the raw sensor signal.  Under normal conditions, the following features are available when working with Emotiv Epoc: <br><br><ul><li>  Measurement of indicators characterizing the position of the user's head in space using an accelerometer and gyroscope. </li><li>  Measurement of the level of arousal, involvement, relaxation, interest, stress, concentration. </li><li>  Recognition of facial muscle movements, giving an idea of ‚Äã‚Äãthe user's facial expression.  For example, we are talking about blinking and a smile. </li><li>  Recognition of mental commands (movement and turns). </li></ul><br>  In order to use the recognition of mental commands, first the user needs to train the <a href="https://www.emotiv.com/developer/">system</a> .  Learning data is saved as a file. <br><br>  If you want to develop your own programs for Emotiv Epoc, you can use the API Cortex and the corresponding SDK (its support is discontinued after the release of version 3.5).  If you want to use JavaScript, you can take a look at my development, the <a href="">Epoc.js</a> library. <br><br><h2>  <font color="#3AC1EF">Epoc.js library</font> </h2><br>  Epoc.js is a framework designed to interact with Emotiv Epoc and Insight devices using JavaScript.  This framework gives the developer access to the above features of the systems from Emotiv and allows you to interact with the <a href="https://github.com/Emotiv/community-sdk/tree/master/tools/XavierComposer/Mac">emulator</a> . <br>  Here is the simplest project based on Epoc.js: <br><br><pre><code class="plaintext hljs">const epoc = require('epocjs')(); epoc.connectToLiveData('path/to/profile/file', function(event){  var action = event.blink === 1 ? 'blinking' : 'not blinking';  console.log(action); });</code> </pre> <br>  In this sample code, we include the Node.js <code>epocjs</code> module and create an instance of the corresponding object.  Then we call the <code>connectToLiveData</code> method of this object, passing it the path to the file with user data obtained after training the system, and the callback function.  This function is passed an event object that contains various properties available for tracking.  For example, if we want the program to respond to blinking, the <code>event.blink</code> property is <code>event.blink</code> . <br><br>  Each such property can be set to either 0 or 1. A unit in the property value means that the system has recorded a corresponding event.  A full list of these properties can be found <a href="">here</a> . <br><br>  The described library was created using the Emotiv C ++ SDK, Node.js and three modules for Node.js: Node-gyp, Bindings and Nan.  When developing it, an approach was used that can now be considered obsolete.  Now the use of <a href="https://nodejs.org/api/n-api.html">N-API</a> is relevant. <br><br>  Having discussed the various possibilities of neuroheternologies and the ways of program work with them, I will tell you about several prototypes created by me that involve the neurointerface. <br><br><h2>  <font color="#3AC1EF">Prototypes</font> </h2><br><h3>  <font color="#3AC1EF">‚ñç1.</font>  <font color="#3AC1EF">Keyboard</font> </h3><br>  This is how the keyboard is controlled by eye movements. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/64a/d35/786/64ad35786e964b66cddcdd62b7a38fc3.png"></div><br>  <i><font color="#999999">Eye Movement Prototype Keyboard</font></i> <br><br>  This was my first project created using Emotiv Epoc.  I wondered if it was possible to create a simple interface using a neuro headset that allows a person to interact with a computer using eye movements.  For example, when you translate the view to the right or left on the keyboard, the corresponding keys are highlighted.  In order to "press" the highlighted key, you need to blink.  The corresponding letter appears in the box above the keyboard. <br><br>  This project looks very simple, but the most important thing is that it works. <br><br><h3>  <font color="#3AC1EF">‚ñç2.</font>  <font color="#3AC1EF">WebVR</font> </h3><br>  In my second project I used mental commands.  Creating it, I wanted to understand whether it is possible to control an object that is in three-dimensional space, just thinking about something. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a3c/45d/6b2/a3c45d6b2d4be7a9b49a07aafa732bd2.gif"></div><br>  <i><font color="#999999">Thought-driven web interface</font></i> <br><br>  Here, to create a simple three-dimensional environment, I used the Three.js library, the Epoc.js library was used to recognize mental commands, and web sockets were used to send data from the server to the client. <br><br><h3>  <font color="#3AC1EF">‚ñç3.</font>  <font color="#3AC1EF">Iot</font> </h3><br>  Starting the third project, I wanted to explore the possibilities of controlling real devices with the help of mental commands.  I have been interested in IoT development using JavaScript for quite some time, so it was interesting for me to know what happens if I combine the Parrot quadrocopter and the neuro headset. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a68/38d/791/a6838d7917c54de10ed3366274e33801.jpg"></div><br>  <i><font color="#999999">Quadcopter</font></i> <br><br>  All the projects described above, all the prototypes created, are pretty simple designs that I created in order to test some ideas in practice and evaluate the possibilities and limitations of neural interfaces. <br><br><h2>  <font color="#3AC1EF">Neural Interface Restrictions</font> </h2><br>  The word ‚Äúneural interface‚Äù sounds amazing, and when it turns out that a computer can be controlled by the power of thought, it may seem that here it is - the future, but in fact, neurocomputer technologies still have quite a few limitations. <br><br><h3>  <font color="#3AC1EF">‚ñçNeediness in learning</font> </h3><br>  It‚Äôs quite normal that users have to train the system, during which they record brain waves and compare them with certain commands, but for many, such a step is an obstacle to adopting a new technology.  It's hard for me to imagine that someone will spend time learning neurocomputer systems, except that such a system will be really needed by someone, and the accuracy with which she recognizes mental commands will be at a very high level. <br><br><h3>  <font color="#3AC1EF">‚ñç Delays</font> </h3><br>  When I developed my prototype, based on computer perception of mental commands, I found out that there was some delay between the moment when I started thinking and the program when I reacted to this thought. <br><br>  I think the point here is that the machine learning algorithm used in the prototype receives data from the device in real time.  In order to recognize the thought, which he had previously learned, he needs indicators collected over a certain period of time. <br><br>  This has an impact on which programs can be built on the basis of a neural interface.  For example, a program that helps to meditate looks quite realistic, since the delays between a change in brain state and the program‚Äôs response do not particularly affect the results of such a program.  However, if you aim to create something like a wheelchair controlled by thoughts, the problem of delays becomes much more acute, calling into question a similar development. <br><br><h3>  <font color="#3AC1EF">‚ñçNon-invasive technology and accuracy of indicators</font> </h3><br>  Electroencephalogram removal devices are great for everyday use in ordinary life situations.  It is enough to put on a headset, putting a special gel on the sensors, and everything is ready.  However, the fact that signals generated by the brain are read from the scalp, and not, say, from the surface of the brain itself, impairs the accuracy of such signals. <br><br>  If we talk about the frequency of removal indicators, it is very good in existing devices.  The same cannot be said about the spatial characteristics of the data obtained.  EEG devices can only read signals originating in those parts of the brain that are close to the surface of the head.  About what happens in the deeper structures of the brain, using a similar approach can not be known. <br><br><h3>  <font color="#3AC1EF">‚ñç Community acceptance</font> </h3><br>  Neuro headset - this is not the cutest and most familiar device.  I think that as long as these headsets look like they are now, they are unlikely to be worn in public places.  As technology advances, it may be that devices are created that may be hidden in accessories like hats, but even here you may encounter a problem related to the fact that such devices will be inconvenient when worn for a long time. <br><br>  EEG sensors should fit quite tightly to the scalp to remove the quality indicators of brain activity.  And if their pressure immediately after putting on the headset can almost not be felt, over time it begins to cause discomfort.  Moreover, if the sensors also need to be applied gel, it turns into an additional barrier to the wide distribution of neurohears. <br><br>  As you can see, the current state of affairs in the field of neural interfaces suggests that they are unlikely to be widespread.  However, if we talk about the future, then we can say that such devices have interesting perspectives. <br><br><h2>  <font color="#3AC1EF">Neural Interface Features</font> </h2><br>  If you take into account the current state of technology and think about what they may become in the future, you can find several options for their application. <br><br><h3>  <font color="#3AC1EF">‚ñçHelp people with disabilities</font> </h3><br>  I would like the neuro headsets to help people with disabilities live a fuller life and be more independent. <br><br>  This is what I thought about when I created my first prototype - a keyboard, controlled by eye movements.  This development of mine is far from the level when it could be used in practice, but working on this project, it was interesting for me to understand whether a quite affordable consumer device can really help someone.  Not everyone has access to complex medical systems, and I was just amazed that the not very expensive thing, which can be freely purchased from the online store, is able to solve important and necessary tasks. <br><br><h3>  <font color="#3AC1EF">‚ñçMental practices</font> </h3><br>  Mental practices, in particular - meditation - this is the scope of neurohears, which already today attracts a certain attention (for example, the <a href="https://choosemuse.com/">Muse</a> headset helps to meditate).  It is about helping someone who wants to meditate, to do everything right. <br><br><h3>  <font color="#3AC1EF">‚ñçHelp in solving health problems</font> </h3><br>  If the neuro headsets would penetrate into our lives as much as mobile phones, we could probably create applications that can respond to health problems.  For example, it would be great if there were applications that, based on an analysis of brain activity, would help fight strokes, panic attacks, epileptic seizures. <br><br><h3>  <font color="#3AC1EF">‚ñç Improving labor productivity</font> </h3><br>  The neuroheckair can help meditate, which means that with its help you can really figure out what time of day a person concentrates.  This information, obtained by regularly wearing a headset, can help to understand when it is best to engage in some kind of activity.  You can even imagine that the work schedule will be organized in accordance with the individual characteristics of a person, which will increase the productivity of his work. <br><br><h3>  <font color="#3AC1EF"> Art</font> </h3><br>  I like, on my own initiative, during off-hours, to explore phenomena at the intersection of art and technology.  I believe that one should not underestimate the work in this direction related to neural interfaces, since, although they may seem ‚Äúfrivolous,‚Äù they help to better understand technologies that will prove useful in more ‚Äúserious‚Äù cases of their use. <br><br><h2>  <font color="#3AC1EF">Combination of electrical brain activity sensors with other sensors</font> </h2><br>  Recently, I had the idea that EEG sensors should not be considered as something completely independent.  Our brain perceives the world through the senses.  He is not able to see without eyes and to hear without ears.  Therefore, if we want to extract the maximum benefit from the data on the electrical activity of the brain, we may need to monitor other vital signs. <br><br>  The main problem here is that all this can lead to the fact that people will be literally hung with various sensors. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d2e/28b/039/d2e28b039767959114ec7f1381849e03.png"></div><br>  <i><font color="#999999">Are there too many sensors?</font></i>  <i><font color="#999999">(source of illustration - cognionics.net)</font></i> <br><br>  Perhaps no one will constantly wear the sensors shown in the previous figure. <br><br><h2>  <font color="#3AC1EF">Openbci</font> </h2><br>  A few weeks ago, I acquired something new ‚Äî the <a href="https://openbci.com/">OpenBCI</a> complex.  My next step is to study the raw data obtained from EEG sensors and apply machine learning methods to this data.  OpenBCI is an open source project, so their development seems to me perfectly suitable for this purpose.  I still didn‚Äôt work much with their headset, so far I only had enough time to connect it to a computer and set it up.  Here is how it all looks. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/112/860/ae0/112860ae0cdb6470d77d657664024e5a.gif"></div><br>  <i><font color="#999999">Openbci</font></i> <br><br><h2>  <font color="#3AC1EF">Results</font> </h2><br>  The author of this material says that he continues to study neural interfaces.  Hopefully, her story will help those who are interested in this topic, but do not dare to begin practical actions, to take the first steps in the field of the use of neurohears.  If all of this is interesting to you - <a href="https://habr.com/company/ruvds/blog/341426/">here is</a> another one of our publications about neuroheaders and JavaScript about Muse. <br><br>  <b>Dear readers!</b>  Do you plan to do experiments with neurohearnes? <br><br><div style="text-align:center;"> <a href="https://ruvds.com/ru-rub/news/read/95"><img src="https://habrastorage.org/webt/n0/ry/op/n0ryop7wfykgkeicz3mtuwghrcu.jpeg"></a> </div></div><p>Source: <a href="https://habr.com/ru/post/433874/">https://habr.com/ru/post/433874/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../433864/index.html">Improving Development Productivity with Vue - Part 1</a></li>
<li><a href="../433866/index.html">‚ÄúHomemade lokalki‚Äù revived in the form of mesh networks. LibreRouter and other free routers</a></li>
<li><a href="../433868/index.html">Why the Alphabet glucose meter didn't take off</a></li>
<li><a href="../433870/index.html">Why is it so difficult to continuously measure glucose levels?</a></li>
<li><a href="../433872/index.html">Mobile access - using a smartphone in access control systems</a></li>
<li><a href="../433876/index.html">Three-dimensional presentation of products on Three.js for the smallest</a></li>
<li><a href="../433878/index.html">KVM, PCI passthrough, Looking Glass and all-all</a></li>
<li><a href="../433880/index.html">Life hacks for developers: efficient use of SQ (Source Qualifier) ‚Äã‚Äãin the Informatica Power Center</a></li>
<li><a href="../433884/index.html">Legal aspects of video surveillance: how to avoid problems with the law</a></li>
<li><a href="../433886/index.html">Python machine learning with interactive Jupyter demos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>