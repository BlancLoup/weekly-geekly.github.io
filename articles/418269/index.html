<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How the CPU Manager in Kubernetes works</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Note trans. : This article was published on the official Kubernetes blog and was written by two Intel employees who are directly involved in the devel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How the CPU Manager in Kubernetes works</h1><div class="post__text post__text-html js-mediator-article">  <i><b>Note</b></i>  <i><b>trans.</b></i>  <i>: This article was published on the official Kubernetes blog and was written by two Intel employees who are directly involved in the development of the CPU Manager ‚Äî a new feature in Kubernetes, which we wrote about in the <a href="https://habr.com/company/flant/blog/338230/">release 1.8</a> review.</i>  <i>At the moment (ie, for K8s 1.11), this feature has the status of a beta version, and read more about its purpose later in the article.</i> <br><br>  The publication is about the <a href="https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/">CPU Manager</a> - a beta feature in Kubernetes.  CPU Manager allows you to better distribute workloads in Kubelet, i.e.  on the Kubernetes node agent, by assigning the allocated CPUs to the specific hearth containers. <br><br><img src="https://habrastorage.org/webt/h-/5g/yo/h-5gyocq5lrz2vsvso7ioblnb3q.png"><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Sounds great!  But will the CPU Manager help me? </h2><br>  Depends on workload.  A single compute node in a Kubernetes cluster can run multiple hearths, and some of them can run loads that are active in CPU consumption.  In this scenario, hearths can compete for the process resources available on this node.  When this competition escalates, the workload may move to other CPUs depending on whether it was <i>throttled</i> under and what CPUs are available at the time of planning.  In addition, there may be cases where the workload is sensitive to context switches.  In all of these scenarios, workload performance may suffer. <br><br>  If your workload is sensitive to such scenarios, you can enable CPU Manager to provide better performance isolation by allocating specific CPUs to the load. <br><br>  CPU Manager can help loads with the following characteristics: <br><br><ul><li>  CPU-sensitive throttling; </li><li>  context sensitive; </li><li>  CPU-sensitive cache miss; </li><li>  benefit from the sharing of processor resources (for example, data and instruction caches); </li><li>  memory sensitive traffic between processor sockets <i>(a detailed explanation of what the authors mean is given on the <a href="https://unix.stackexchange.com/questions/458812/what-does-cross-socket-traffic-mean">Unix Stack Exchange</a> - <b>approx. transl.</b> )</i> ; </li><li>  hyperthreads sensitive to or requiring the same physical core of the CPU. </li></ul><br><h2>  OK!  How to use it? </h2><br>  Using CPU Manager is easy.  First, <a href="https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/">turn it on using the</a> Kubelet <a href="https://kubernetes.io/docs/tasks/administer-cluster/cpu-management-policies/">Static Policy</a> running on the cluster's compute nodes.  Then set the guaranteed <a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/"><i>Guaranteed</i> Quality of Service (QoS)</a> class for the hearth.  Request an integer number of CPU cores (for example, <code>1000m</code> or <code>4000m</code> ) for containers that need dedicated cores.  Create under the previous method (for example, <code>kubectl create -f pod.yaml</code> ) ... and voila - the CPU Manager will assign the dedicated processor cores to each sub-container in accordance with their needs for the CPU. <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Pod metadata: name: exclusive-2 spec: containers: - image: quay.io/connordoyle/cpuset-visualizer name: exclusive-2 resources: # Pod is in the Guaranteed QoS class because requests == limits requests: # CPU request is an integer cpu: 2 memory: "256M" limits: cpu: 2 memory: "256M"</code> </pre> <br>  <i>BOM specification requesting 2 dedicated CPUs.</i> <br><br><h2>  How does the CPU Manager work? </h2><br>  We consider three types of control of CPU resources available in most Linux distributions, which will be relevant in relation to Kubernetes and the actual purposes of this publication.  The first two are CFS shares (what is my weighted "fair" share of CPU time in the system) and CFS quota (what is the maximum CPU time allocated to me for the period).  CPU Manager also uses the third one, which is called CPU affinity (on which logical CPUs I am allowed to perform calculations). <br><br>  By default, all runs and containers running on the Kubernetes cluster node can run on any available system kernels.  The total number of shares to be assigned and quota are limited by the CPU resources reserved for <a href="https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/">Kubernetes and system daemons</a> .  However, the limits on the CPU time used can be determined using the <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/">limits on the CPU in the heart rate specification</a> .  Kubernetes uses the <a href="https://www.kernel.org/doc/Documentation/scheduler/sched-bwc.txt">CFS quota</a> to enforce CPU limits on the pod containers. <br><br>  When you turn on the CPU Manager with the <i>Static</i> policy, it manages the allocated CPU pool.  Initially this pool contains all the CPUs of the compute node.  When Kubelet creates a container in the hearth with a guaranteed number of dedicated processor cores, the CPUs assigned to this container are allocated to it for the duration of its life and removed from the shared pool.  The loads from the remaining containers are transferred from these dedicated cores to others. <br><br>  All containers without dedicated CPUs ( <i>Burstable</i> , <i>BestEffort,</i> and <i>Guaranteed with non-integer CPUs</i> ) run on the cores remaining in the shared pool.  When a container with a dedicated CPU stops working, its cores are returned to the shared pool. <br><br><h2>  More detail, please ... </h2><br><img src="https://habrastorage.org/webt/cr/w-/-8/crw--8xnqnkcu8fl18xxbbeyfzk.png"><br><br>  The above diagram demonstrates the anatomy of the CPU Manager.  It uses the <code>UpdateContainerResources</code> method from the Container Runtime Interface (CRI) interface to change the CPUs on which the containers run.  <i>The manager</i> periodically <code>cgroupfs</code> to <code>cgroupfs</code> current state ( <i>State</i> ) of the CPU resources for each running container. <br><br>  The CPU Manager uses <a href=""><i>Policies</i></a> to decide whether to assign CPU cores.  Implemented two policies: <i>None</i> and <i>Static</i> .  By default, starting with Kubernetes 1.10, it is included with the <i>None</i> policy. <br><br>  The <i>Static</i> policy assigns dedicated pods to pod containers with a guaranteed QoS class that requests an integer number of cores.  The <i>Static</i> policy attempts to assign the CPU in the best topological manner and in the following sequence: <br><br><ul><li>  Assign all CPUs of a single processor socket, if available, and the container requires a CPU of at least the entire CPU socket. </li><li>  Assign all logical CPUs (hyperthreads) of a single physical CPU core, if they are available and the container requires a CPU of at least the entire core. </li><li>  Assign any available logical CPUs with a preference for CPUs from a single socket. </li></ul><br><h2>  How does the CPU Manager improve the isolation of computing? </h2><br>  With <i>Static</i> policy enabled in CPU Manager, workloads may show better performance for one of the following reasons: <br><br><ul><li>  Dedicated CPUs can be assigned to a container with a workload, but not other containers.  These (other) containers do not use the same CPU resources.  As a result, we expect better performance due to isolation in cases of an ‚Äúaggressor‚Äù <i>(demanding of CPU resources - <b>approx. Transl.</b> )</i> Or an adjacent workload. </li><li>  The competition for the resources used by the workload is reduced, since we can divide the CPU by the load itself.  These resources can include not only the CPU, but also cache hierarchies, and memory bandwidth.  This improves the overall performance of the workloads. </li><li>  CPU Manager assigns CPUs in topological order based on the best available options.  If the whole socket is free, it will assign all of its CPUs to the workload.  This improves the performance of the workload due to the absence of traffic between the sockets. </li><li>  Containers in sills with <i>guaranteed</i> QoS are subject to CFS quota restrictions.  Workloads that are prone to sudden surges can be planned and exceed their quota before the end of their allotted period, as a result of which they are repaid <i>(throttled)</i> .  The CPUs involved at this time can have both significant and not very useful work.  However, such containers will not be subject to CFS throttling, when the CPU quota is supplemented by the allocation policy of the allocated CPUs. </li></ul><br><h2>  OK!  Do you have any results? </h2><br>  In order to see the performance improvements and isolation provided by the inclusion of the CPU Manager in Kubelet, we conducted experiments on a compute node with two sockets (Intel Xeon CPU E5-2680 v3) and hyperthreading turned on.  A node consists of 48 logical CPUs (24 physical cores, each with hyperthreading).  The following shows the benefits of CPU Manager in performance and isolation, fixed by benchmarks and real-world workloads in three different scenarios. <br><br><h3>  How to interpret graphics? </h3><br>  For each scenario, graphs ( <a href="https://ru.wikipedia.org/wiki/%25D0%25AF%25D1%2589%25D0%25B8%25D0%25BA_%25D1%2581_%25D1%2583%25D1%2581%25D0%25B0%25D0%25BC%25D0%25B8">span diagrams</a> , box plots) are shown illustrating the normalized execution time and its variability when starting the benchmark or the real load with the CPU Manager turned on and off.  Executable time is normalized to best performance starts (1.00 on the Y axis represents the best start time: the smaller the graph value, the better).  The height of the plot on the graph shows the variation in performance.  For example, if a segment is a line, then there is no performance variation for these launches.  At these sites themselves, the median line is the median, the upper one is the 75th percentile, and the lower one is the 25th percentile.  The height of the segment (i.e., the difference between the 75th and 25th percentiles) is defined as the interquartile interval (IQR).  "Whiskers" show data outside this interval, and the points show the outliers.  Emissions are defined as any data that is 1.5 times different from IQR - less or more than the corresponding quartile.  Each experiment was conducted 10 times. <br><br><h3>  Protection against load aggressors </h3><br>  We launched six benchmarks from <a href="http://parsec.cs.princeton.edu/">the PARSEC suite</a> (workloads ‚Äúvictims‚Äù) <i>[for more details about victim workloads, you can read, for example, <a href="https://library.netapp.com/ecmdocs/ECMP1364220/html/GUID-71BD6939-9E02-451E-A222-9086B68B52A2.html">here</a> - <b>approx.</b></i>  <i><b>trans.</b></i>  <i>]</i> adjacent to the CPU-loading container (‚Äúaggressor‚Äù workload) with the CPU Manager on and off. <br><br>  The aggressor container was launched <a href="https://gist.github.com/balajismaniam/7c2d57b2f526a56bb79cf870c122a34c">as a</a> <i>Burstable</i> QoS class, requesting 23 CPUs with the <code>--cpus 48</code> flag.  Benchmarks are run <a href="https://gist.github.com/balajismaniam/fac7923f6ee44f1f36969c29354e3902">as pods</a> with the QoS class <i>Guaranteed</i> , requiring a set of CPUs from a full socket (that is, 24 CPUs on this system).  The graphs below show the normalized launch time for the poda with the benchmark next to the aggressor hearth, with and without the <i>Static</i> policy of the CPU Manager.  In all test cases, you can see improved performance and reduced variability in performance when policies are enabled. <br><br><img src="https://habrastorage.org/webt/tb/aj/gu/tbajgurqlbubtzm3il4d9vzoh8i.png"><br><br><h3>  Isolation for adjacent loads </h3><br>  This demonstrates how CPU Manager can be useful in the case of many co-located workloads.  The span diagrams below show the performance of two benchmarks from the PARSEC suite ( <i>Blackscholes</i> and <i>Canneal</i> ) running for the QoS classes <i>Guaranteed</i> (Gu) and <i>Burstable</i> (Bu), adjacent to each other, with <i>Static</i> turned on and off. <br><br>  Following clockwise from the top left chart, we see <i>Blackscholes</i> performance for Bu QoS (top left), <i>Canneal</i> for Bu QoS (top right), <i>Canneal</i> for Gu QoS (bottom right), and <i>Blackscholes</i> for Gu QoS (bottom left).  On each of the graphs, they are located (again we go clockwise) together with <i>Canneal</i> for Gu QoS (upper left), <i>Blackscholes</i> for Gu QoS (upper right), <i>Blackscholes</i> for Bu QoS (lower right) and <i>Canneal</i> for Bu QoS (lower left) respectively.  For example, a <i>Bu-blackscholes-Gu-canneal</i> (top left) <i>chart</i> shows performance for <i>Blackscholes</i> running from Bu QoS and located next to <i>Canneal</i> with a Gu QoS class.  In each case, the Gu QoS class requires a full socket core (that is, 24 CPUs), while the Bu QoS class requires 23 CPUs. <br><br>  There is better performance and less variation in performance for both adjacent workloads in all tests.  For example, look at the <i>Bu-blackscholes-Gu-canneal</i> (top left) and <i>Gu-canneal-Bu-blackscholes</i> (bottom right).  They show the performance of simultaneously running <i>Blackscholes</i> and <i>Canneal</i> with the CPU Manager turned on and off.  In this case, <i>Canneal</i> receives more dedicated cores from the CPU Manager, since it belongs to the Gu QoS class and requests an integer number of CPU cores.  However, <i>Blackscholes also</i> gets a dedicated set of CPUs, since this is the only workload in the shared pool.  As a result, both <i>Blackscholes</i> and <i>Canneal</i> take advantage of the isolation of loads in the case of CPU Manager. <br><br><img src="https://habrastorage.org/webt/et/wj/93/etwj93f4gv4pbjyoq8-6_nfmtmm.png"><br><br><h3>  Insulation for separately standing loads </h3><br>  This demonstrates how CPU Manager can be useful for freestanding real-life workloads.  We took two loads from the <a href="https://github.com/tensorflow/models/tree/master/official">official TensorFlow models</a> : <a href="https://github.com/tensorflow/models/tree/master/official/wide_deep">wide and deep</a> and <a href="https://github.com/tensorflow/models/tree/master/official/resnet">ResNet</a> .  For them, typical data sets are used (census and CIFAR10, respectively).  In both cases, <a href="https://gist.github.com/balajismaniam/941db0d0ec14e2bc93b7dfe04d1f6c58">pods</a> ( <a href="https://gist.github.com/balajismaniam/9953b54dd240ecf085b35ab1bc283f3c">wide and deep</a> , <a href="https://gist.github.com/balajismaniam/a1919010fe9081ca37a6e1e7b01f02e3">ResNet</a> ) require 24 CPUs, which corresponds to a full socket.  As shown in the graphs, in both cases, the CPU Manager provides better isolation. <br><br><img src="https://habrastorage.org/webt/ln/hv/a6/lnhva6g-1coouyustgjq-ziwybk.png"><br><br><h2>  Restrictions </h2><br>  Users may want to get CPUs allocated on a socket close to the bus connecting to an external device such as an accelerator or high-performance network card in order to avoid traffic between the sockets.  This type of configuration is not yet supported in the CPU Manager.  Since the CPU Manager provides the best possible distribution of CPUs belonging to a socket or physical core, it is sensitive to extreme cases and can lead to fragmentation.  The CPU Manager does not take into account the <code>isolcpus</code> Linux kernel <code>isolcpus</code> , although it is used as a popular practice for some cases <i>(for more information about this parameter, see, for example, <a href="https://www.linuxtopia.org/online_books/linux_kernel/kernel_configuration/re46.html">here</a> - <b>note transl.</b> )</i> . <br><br><h2>  PS from translator </h2><br>  Read also in our blog: <br><br><ul><li>  ‚ÄúWhat happens in Kubernetes when starting the kubectl run?‚Äù: <a href="https://habr.com/company/flant/blog/342658/">Part 1</a> and <a href="https://habr.com/company/flant/blog/342822/">part 2</a> ; </li><li>  ‚Äú <a href="https://habr.com/company/flant/blog/335552/">How does the Kubernetes scheduler actually work?</a>  "; </li><li>  " <a href="https://habr.com/company/flant/blog/415393/">Kubernetes: the life of the hearth</a> "; </li><li>  " <a href="https://habr.com/company/flant/blog/340010/">CRI-O - Docker alternative to launch containers in Kubernetes</a> "; </li><li>  " <a href="https://habr.com/company/flant/blog/331188/">Our experience with Kubernetes in small projects</a> " <i>(video of the report, which includes an introduction to the technical device Kubernetes);</i> </li><li>  " <a href="https://habr.com/company/flant/blog/341760/">Infrastructure with Kubernetes as an affordable service</a> ." </li></ul></div><p>Source: <a href="https://habr.com/ru/post/418269/">https://habr.com/ru/post/418269/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../418257/index.html">Github.com refuses to use jQuery and switches to pure JavaScript</a></li>
<li><a href="../418261/index.html">The self-made glove stun gun is a weapon for the boom</a></li>
<li><a href="../418263/index.html">Russian scientists are developing a compact and cheap MEG system</a></li>
<li><a href="../418265/index.html">The organization of network interaction of physical and virtual machines</a></li>
<li><a href="../418267/index.html">IT digest of August events</a></li>
<li><a href="../418271/index.html">Splitting a line by separator. A little about CONNECT BY</a></li>
<li><a href="../418273/index.html">Development tools for the ‚ÄúBaikal-T1‚Äù platform were transferred to the Russian ALT distribution kit</a></li>
<li><a href="../418275/index.html">3D Printing Lessons. Printing thin-walled models from 3Dtool</a></li>
<li><a href="../418277/index.html">Box-shadows Device</a></li>
<li><a href="../418279/index.html">Password reset on Cisco ASA without idle for active / standby failover scheme</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>