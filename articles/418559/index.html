<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>NL2API: Creating Natural Language Interfaces for the Web API</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! Most recently, we briefly talked about the Natural Language Interfaces (Natural Language Interfaces). Well, today we have not briefly. Under...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>NL2API: Creating Natural Language Interfaces for the Web API</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  Most recently, we <a href="https://habr.com/company/microsoft/blog/416723/">briefly talked</a> about the Natural Language Interfaces (Natural Language Interfaces).  Well, today we have not briefly.  Under the cat you will find a full story about creating NL2API for the Web-API.  Our colleagues from Research have tested a unique approach to collecting training data for the framework.  Join now! <br><br><img src="https://habrastorage.org/webt/ry/bd/kj/rybdkjnazdjarwxlrggugof4pja.jpeg"><a name="habracut"></a><br><br><h2>  annotation </h2><br>  As the Internet evolves towards a service-oriented architecture, software interfaces (APIs) are becoming increasingly important as a way to provide access to data, services, and devices.  We are working on the problem of creating a natural language API for the API (NL2API), focusing on web services.  NL2API solutions have many potential benefits, for example, helping to simplify the integration of web services into virtual assistants. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We offer the first integrated platform (framework), which allows you to create NL2API for a specific web API.  The key task is to collect data for training, that is, the pairs ‚ÄúNL command - API call‚Äù, which allow NL2API to study the semantics of both NL commands that do not have a strictly defined format, and formal API calls.  We offer our own unique approach to the collection of training data for NL2API using crowdsourcing - attracting numerous remote workers to the generation of various NL teams.  We optimize the crowdsourcing process itself to reduce costs. <br><br>  In particular, we offer a fundamentally new hierarchical probabilistic model that will help us distribute the budget for crowdsourcing, mainly between those API calls that have a high value for learning NL2API.  We apply our framework to the real API and show that it allows you to collect high-quality training data with minimal costs, as well as create high-performance NL2API from scratch.  We also demonstrate that our crowdsourcing model improves the efficiency of this process, that is, the training data collected within its framework provides higher NL2API performance, far exceeding the baseline. <br><br><h2>  Introduction </h2><br>  Application programming interfaces (APIs) are playing an increasingly important role in the virtual and physical world due to the development of technologies such as service-oriented architecture (SOA), cloud computing and the Internet of things (IoT).  For example, web services hosted in the cloud (weather, sports, finance, etc.) provide data and services to end users via a web API, and IoT devices allow other network devices to use their functionality. <br><br><img src="https://habrastorage.org/webt/tc/kd/fb/tckdfbxc1i4zg4km413wnducl_4.png"><br>  <i>Figure 1. The ‚ÄúNL-command (left) and API call (right)‚Äù pairs, collected</i> <i><br></i>  <i>our framework, and comparison with IFTTT.</i>  <i>GET-Messages and GET-Events are two web APIs for searching emails and calendar events, respectively.</i>  <i>The API can be called with various parameters.</i>  <i>We concentrate on fully parameterized API calls, while IFTTT is limited to APIs with simple parameters.</i> <br><br>  APIs are commonly used in various software applications: desktop applications, websites, and mobile applications.  They also serve users through a graphical user interface (GUI).  The GUI made a great contribution to the popularization of computers, but, as computer technology developed, its numerous limitations increasingly manifest themselves.  On the one hand, since devices are becoming smaller, more mobile and smarter, the requirements for a graphic image on the screen are constantly increasing, for example, with respect to portable devices or devices connected to IoT. <br><br>  On the other hand, users have to adapt to various specialized GUIs for various services and devices.  As the number of available services and devices increases, the cost of training and adapting users also grows.  Natural language interfaces (NLI), such as Apple Siri and Microsoft Cortana virtual assistants, also known as conversational or conversational interfaces (CUI), demonstrate significant potential as a single intelligent tool for a wide range of server services and devices. <br><br>  This paper deals with the problem of creating a natural language interface for an API (NL2API).  But, unlike virtual assistants, this is not a general-purpose NLI, <br>  we are developing approaches to creating NLIs for specific web APIs, that is, APIs for web services like the multisport service ESPN1.  Such NL2APIs can solve the problem of scalability of general-purpose NLI, providing the possibility of distributed development.  The usefulness of a virtual assistant largely depends on the breadth of its capabilities, that is, on the number of services it supports. <br><br>  However, integrating web services into a virtual assistant one by one is incredibly hard work.  If individual web services providers had an inexpensive way to create NLI for their APIs, the integration costs would be significantly reduced.  A virtual assistant would not have to handle different interfaces for different web services.  It would be enough for him to simply integrate the individual NL2API, which achieve uniformity due to natural language.  On the other hand, NL2API can also simplify the discovery of web services and the programming of API recommendation and assistance systems, eliminating the need to memorize the large number of available web APIs and their syntax. <br><br>  <b>Example 1.</b> Two examples are shown in Figure 1. The API can be called with different parameters.  In the case of the email search API, users can filter email by specific properties or search for emails by keywords.  The main task of NL2API is to match NL commands with corresponding API calls. <br><br>  <b>Task.</b>  The collection of training data is one of the most important tasks related to research in the development of NLI interfaces and their practical application.  NLI interfaces use supervised training data, which in the case of NL2API consists of NL command ‚Äì API call pairs, to learn semantics and uniquely match NL commands with corresponding formalized representations.  Natural language is very flexible, so users can describe an API call in syntactically different ways, that is, paraphrasing takes place. <br><br>  Consider the second example in Figure 1. Users can rephrase this question as follows: ‚ÄúWhere will the next meeting take place‚Äù or ‚ÄúFind a venue for the next meeting‚Äù.  Therefore, it is extremely important to collect sufficient training data for the system to recognize such variants in the future.  Existing NLIs generally adhere to the ‚Äúbest of principle‚Äù principle in the data collection process.  For example, the closest analogue of our methodology for comparing NL commands with API calls is using the IF-This-Then-That (IFTTT) concept - ‚Äúif it is, then‚Äù (Figure 1).  The training data comes directly from the IFTTT website. <br><br>  However, if the API is not supported or not fully supported, there is no way to remedy the situation.  In addition, the training data collected in this way is of little use for supporting extended commands with several parameters.  For example, we analyzed the anonymized Microsoft API call logs to search emails for a month and found that about 90% of them use two or three parameters (approximately in equal amounts), and these parameters are quite diverse.  Therefore, we strive to provide full support for API parameterization and to implement extended NL commands.  The problem of deploying an active and customizable process of collecting training data for a specific API currently remains unresolved. <br><br>  The use of NLI in combination with other formalized views, such as relational databases, knowledge bases and web tables, has been worked out fairly well, while the development of the NLI for the web API has received almost no attention.  We offer the first comprehensive platform (framework), which allows you to create NL2API for a specific web API from scratch.  In the implementation for the web API, our framework includes three steps: (1) Representation.  The original HTTP Web API format contains many redundant and, therefore, distracting details from the point of view of the NLI interface. <br><br>  We suggest using an intermediate semantic representation for the web API in order not to overload NLI with unnecessary information.  (2) A set of training data.  We propose a new approach to obtaining controlled training data based on crowdsourcing.  (3) NL2API.  We also offer two NL2API models: a language-based extraction model and a recurrent neural network model (Seq2Seq). <br><br>  One of the key technical results of this work is a fundamentally new approach to the active collection of training data for NL2API based on crowdsourcing - we use remote performers to annotate API calls when they are compared with NL teams.  This allows you to achieve three design goals by ensuring: (1) Customizability.  It must be possible to specify which parameters for which API to use and how much training data to collect.  (2) Low cost.  The services of crowdsourcing workers are much cheaper than the services of specialized specialists, therefore, they need to be hired.  (3) High quality.  The quality of the training data should not be reduced. <br><br>  When designing this approach, there are two main problems.  First, API calls with extended parameterization, as in Figure 1, are incomprehensible to the average user, so you need to decide how to formulate the annotation problem so that crowdsourced workers can easily cope with it.  We begin by developing an intermediate semantic representation for the web API (see Section 2.2), which allows us to seamlessly generate API calls with the required parameters. <br><br>  Then we think up a grammar to automatically convert each API call to a canonical NL command, which can be quite cumbersome, but it will be understood by the average crowdsourced worker (see section 3.1).  The performers will only have to rephrase the canonical team to make it sound more natural.  This approach helps to prevent many errors in the collection of training data, since the task of rephrasing is much simpler and clearer for the average crowdsourcing worker. <br><br>  Secondly, it is necessary to understand how to define and annotate only those API calls that are of real value for NL2API learning.  The ‚Äúcombinatorial explosion‚Äù that arises during parameterization leads to the fact that the number of calls even for one API can be quite large.  Annotate all calls does not make sense.  We offer a fundamentally new hierarchical probabilistic model for the implementation of the crowdsourcing process (see Section 3.2).  By analogy with language modeling in order to obtain information, we assume that NL commands are generated based on the corresponding API calls, so a language model should be used for each API call in order to register this ‚Äúspawning‚Äù process. <br><br>  Our model is based on the compositional nature of API calls or formalized representations of the semantic structure as a whole.  At the intuitive level, if an API call consists of simpler calls (for example, ‚Äúunread emails about the application for a candidate of science degree‚Äù = ‚Äúunread emails‚Äù + ‚Äúemails for an application for the degree of candidate of science‚Äù, we can build it a language model from simple API calls even without annotation, so by annotating a small number of API calls, we can calculate the language model for everyone else. <br><br>  Of course, the calculated language models are far from ideal, otherwise we would have already solved the problem of creating an NL2API.  Nevertheless, such an extrapolation of the language model to non-annotated API calls gives us a holistic view of the entire space of API calls, as well as the interaction of natural language and API calls, which allows us to optimize the crowdsourcing process.  In Section 3.3, we describe an algorithm for selective annotation of API calls that helps to make API calls more distinct, that is, to ensure the maximum divergence of their language models. <br><br>  We apply our framework to two deployed APIs from the Microsoft Graph API2 package.  We demonstrate that high-quality training data can be collected at minimal cost, provided that the proposed approach is used3.  We also show that our approach improves crowdsourcing efficiency.  At similar costs, we collect higher-quality training data, significantly exceeding the basic indicators.  As a result, our NL2API solutions provide higher accuracy. <br><br>  In general, our main contribution includes three aspects: <br><br><ul><li>  We were one of the first to start exploring the NL2API problematics and suggested a comprehensive framework for creating NL2API from scratch. </li><li>  We proposed a unique approach to the collection of training data using crowdsourcing and a fundamentally new hierarchical probabilistic model for optimizing this process. </li><li>  We applied our framework to real web APIs and demonstrated that a sufficiently effective NL2API solution can be created from scratch. </li></ul><br><img src="https://habrastorage.org/webt/t4/fs/vl/t4fsvlxndjmziwbvzjh2rwqut2c.png"><br>  <i>Table 1. OData request parameters.</i> <br><br><h2>  Preamble </h2><br><h4>  RESTful API </h4><br>  Recently, web APIs that meet the architectural style of REST, that is, the RESTful API, have become increasingly popular due to their simplicity.  RESTful APIs are also used in smartphones and IoT devices.  Restful APIs work with resources that are addressed via a URI and provide access to these resources for a wide range of clients using simple HTTP commands: GET, PUT, POST, etc. We will mainly work with the RESTful API, but the basic methods can be used and other APIs. <br><br>  For example, let's take the popular open data protocol (OData) for the RESTful API and two web APIs from the Microsoft Graph API (Figure 1), which, respectively, are used to search for emails and calendar events of the user.  Resources in OData are entities, each of which is associated with a list of properties.  For example, the Message entity ‚Äî an email ‚Äî has properties such as subject (subject), from (from), isRead (read), receivedDateTime (received date and time), and so on. <br><br>  In addition, OData defines a set of query parameters, allowing you to perform advanced resource manipulations.  For example, the FILTER parameter allows you to search for emails from a specific sender or emails received on a specific date.  The request parameters that we will use are presented in Table 1. We call each combination of the HTTP command and an entity (or set of entities) as an API, for example, GET-Messages ‚Äî to search for emails.  Any parameterized request, for example, FILTER (isRead = False), is called a parameter, and an API call is an API with a list of parameters. <br><br><h4>  NL2API </h4><br>  The main task of NLI is to compare statements (natural language commands) with a certain formalized representation of, for example, logical forms or SPARQL queries for knowledge bases or web API in our case.  When it is necessary to focus on the semantic mapping, without being distracted by irrelevant details, an intermediate semantic representation is usually used in order not to work directly with the target one.  For example, combinatorial categorical grammar is widely used to create NLI interfaces for databases and knowledge bases.  A similar approach to abstraction is also very important for NL2API.  Many details, including URL conventions, HTTP headers and response codes, can ‚Äúdistract‚Äù NL2API from solving the main task - the semantic mapping. <br><br>  Therefore, we create an intermediate representation for the RESTful APIs (Figure 2) called the API frame, this representation reflects the semantics of the frame.  Frame API consists of five parts.  HTTP Verb (HTTP Command) and Resource (Resource) are basic elements for the RESTful API.  Return Type allows you to create composite APIs, that is, combine several API calls to perform a more complex operation.  Required Parameters are most often used in PUT or POST calls to the API, for example, for sending e-mail, the required parameters are the addressee, the header and the message body.  Optional Parameters are often present in GET calls in the API, they help narrow down the information request. <br><br>  If the required parameters are missing, we serialize the API frame, for example: GET-messages {FILTER (isRead = False), SEARCH (‚ÄúPhD application‚Äù), COUNT ()}.  An API frame can be deterministic and converted to a real API call.  During the conversion process, the necessary contextual data will be added, including the user ID, location, date and time.  In the second example (Figure 1), the now value in the FILTER parameter will be replaced with the date and time of the execution of the corresponding command during the conversion of an API frame to an actual API call.  Further we will use the concepts of an API frame and an API call interchangeably. <br><br><img src="https://habrastorage.org/webt/zq/ya/1s/zqya1s2fappwxv0soevosjshp6o.png"><br>  <i>Figure 2. Frame API.</i>  <i>Above: team in natural language.</i>  <i>Middle: Frame API.</i>  <i>Below: API call.</i> <br><br><img src="https://habrastorage.org/webt/d1/4j/br/d14jbrsdzhethdl8tpvjlf0v7bq.png"><br>  <i>Figure 3. Crowdsourcing conveyor.</i> <br><br><h2>  Collection of training data </h2><br>  This section describes our proposed fundamentally new approach to collecting training data for NL2API solutions using crowdsourcing.  First, we generate API calls and convert each of them into a canonical command, based on a simple grammar (section 3.1), and then use crowdsourcing workers to paraphrase canonical commands (Figure 3).  Given the compositional nature of API calls, we proposed a hierarchical probabilistic model of crowdsourcing (section 3.2), as well as an algorithm for optimizing crowdsourcing (section 3.3). <br><br><img src="https://habrastorage.org/webt/-m/hx/zh/-mhxzhnfom3w3n8cck-nkazfwiu.png"><br>  <i>Figure 4. Generation of canonical command.</i>  <i>Left: lexicon and grammar.</i>  <i>Right: example of derivation.</i> <br><br><h4>  API call and canonical command </h4><br>  We generate API calls based solely on the API specification.  In addition to schema elements such as request parameters and entity properties, we need property values ‚Äã‚Äãto generate API calls that are not provided by the API specification.  For properties with enumerated values, such as Boolean, we list the possible values ‚Äã‚Äã(True / False). <br><br>  For properties with values ‚Äã‚Äãof an unlimited type, such as Datetime, we will synthesize several representative values, such as today or this_week for receivedDateTime.  It is necessary to understand that these are abstract values ‚Äã‚Äãat the API frame level and they will be converted to real according to the context (for example, the actual date and time) when the API frame is converted to a real API call. <br><br>  It‚Äôs easy to list all combinations of query parameters, properties, and property values ‚Äã‚Äãto create API calls.  Simple heuristics allow you to weed out not quite suitable combinations.  For example, TOP is applied to a sorted list, so this parameter must be used in conjunction with ORDERBY.  In addition, properties of type Boolean, for example isRead, cannot be used in ORDERBY.  Nevertheless, the ‚Äúcombinatorial explosion‚Äù in any case determines the presence of a large number of API calls for each API. <br><br>  The average user is hard to understand API calls.  Similarly, we convert an API call into a canonical command.  We form an API-specific lexicon and a common grammar for the API (Figure 4).  Lexicon allows you to get the lexical form and syntactic category for each element (HTTP commands, entities, properties and property values). ,   ‚ü®sender ‚Üí NP[from]‚ü© ,     from  ¬´sender¬ª,    ‚Äî   (NP),     . <br><br>       (V),   (VP),  (JJ), - (CP),   ,       (NP/NP),    (PP/NP),  (S)  . . <br><br>  ,       API     ,           RESTful API    OData ‚Äî ¬´ ¬ª    . 17     4     API,     ( 5). <br><br>   ,          API.     ‚ü®t1, t2, ..., tn ‚Üí c[z]‚ü©,  <img src="https://habrastorage.org/webt/h5/rj/n2/h5rjn28vmc1twejoa5459flx0gm.png">    , z    API,  cz ‚Äî   .     4.   API    ,     S,     G4,     API   . C    ,          ,               - ¬´that is not read¬ª. <br><br>  ,      . ,  VP[x = False]     B2,   B4,       x.  x     VP,   B2 (, x is hasAttachments ‚Üí ¬´do not have attachment¬ª);    JJ,    B4 (, x is isRead ‚Üí ¬´is not read¬ª).       (¬´do not read¬ª or ¬´is not have attachment¬ª)       . <br><br><h4>   </h4><br>       API,   ,            .         ,   ,   API  .   ,          NLI,                  .         API     . , z12 = GET-Messages {COUNT(),FILTER(isRead=False)}   z1 = GET- Messages{FILTER(isRead=False)}  z2 = GET-Messages{COUNT()} (     ). <br><br><img src="https://habrastorage.org/webt/fa/w0/eh/faw0ehohhnasifwgtragzrqwg3o.png"><br> <i> 5.  . i-     API  i .  ‚Äî  .        .</i> <br><br>         ,         . <br><br>           API. <br><br> <b> 3.1 ().</b>  API    API <br><img src="https://habrastorage.org/webt/jp/nd/rx/jpndrxembixwz20-sym5vtxyhaq.png"> ,    r (z)     z,  <img src="https://habrastorage.org/webt/zq/ih/u5/zqihu5tkga6iigokecjod-cg5um.png">   <img src="https://habrastorage.org/webt/_a/1x/jv/_a1xjvs9yduvatefhmfdk6xumq8.png">    ,  <img src="https://habrastorage.org/webt/0e/oy/hw/0eoyhwaahe8xlrbplt1nqajeego.png">   <img src="https://habrastorage.org/webt/np/q5/sy/npq5syhh47uv3yvyba_t1_4tqc0.png"><br><br>      API,     API    .  API         ,     <br>    .       ( SeMesh). <br><br>           ,  ,  ,    API z,     ,    <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  .        ,   <img src="https://habrastorage.org/webt/on/eh/p5/onehp5mxamc9ehgpsl1u4pbkfr4.png">  where <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  . <br><br>   ,     ,    -       (Bag of Bernoulli, BoB).       W, ,    w  ,    z,   BoB ‚Äî        <img src="https://habrastorage.org/webt/k0/gw/fj/k0gwfjeikxqircdxhndamv6xbba.png">  .    <img src="https://habrastorage.org/webt/j1/vn/qm/j1vnqmhyhigxbdpj7s5irirmxae.png">     <img src="https://habrastorage.org/webt/ub/xi/rx/ubxirxha2um6wer3obznfezis7w.png">  . <br><br> ,   ()  <img src="https://habrastorage.org/webt/m5/nb/sr/m5nbsrzyyxpfpzc6isj_qrjjxbs.png">  z, <br>    (MLE)   BoB   ,  w: <br><br><img src="https://habrastorage.org/webt/ix/gv/2q/ixgv2qua9ifqtxbp1mi3hf58izc.png"><br><br> <b> 2.</b>     API z1 ,      u1 = ¬´find unread emails¬ª  u2 =¬´emails that are not read¬ª,  u = {u1, u2 }. pb (¬´emails¬ª|z) = 1.0,  ¬´emails¬ª    .  , pb (¬´unread¬ª|z) = 0.5  pb (¬´meeting¬ª|z) = 0.0. <br><br>          : <br> ,   . <br><br> <b>ANNOTATE</b> ()    <img src="https://habrastorage.org/webt/m5/nb/sr/m5nbsrzyyxpfpzc6isj_qrjjxbs.png">      z        <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">   . <br><br> <b>COMPOSE</b> ()           <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  .    , <img src="https://habrastorage.org/webt/zq/ih/u5/zqihu5tkga6iigokecjod-cg5um.png"> ‚Äî    z.       ,        ,  <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">    <img src="https://habrastorage.org/webt/xe/zj/vd/xezjvdelmyapzpsz-c-ubbyrowq.png">  : <br><br><img src="https://habrastorage.org/webt/1j/kw/gy/1jkwgy2cjdyy2tkd9fd94_vdtf0.png"><br><br>  f   .   BoB      : <br><br><img src="https://habrastorage.org/webt/-j/yo/yc/-jyoycveazjjahzb2va3w26sfv0.png"><br><br>  ,  ui   zi, u ‚Äî  <img src="https://habrastorage.org/webt/lr/ls/g_/lrlsg_9r0ga50mjkj47anmczlga.png">   u,   w   u.    ,     - ui.   z  , Œ∏e x  ,   .   -      .        , ,   ,    API,     (2).      BoB. <br><br> <b> 3.</b> ,        API z1  z2,      : <img src="https://habrastorage.org/webt/zy/pr/yx/zypryx-8unafep9q1_lu2bnwewi.png"> = {¬´find unread emails¬ª, ¬´emails that are not read¬ª}  <img src="https://habrastorage.org/webt/7n/4a/74/7n4a746gi-pf2_nf0ocy0dohdqm.png"> = {¬´how many emails do I have¬ª, ¬´find the number of emails¬ª}.     <img src="https://habrastorage.org/webt/7a/uj/od/7aujod7s9qek21mw3zemkcgaake.png">  and <img src="https://habrastorage.org/webt/vp/so/fn/vpsofnkfxhjn38dfcjpm6bqzzio.png">  .     <img src="https://habrastorage.org/webt/qt/tm/ud/qttmudo6ekcwmdeptxfjigmmcck.png"> ,   <img src="https://habrastorage.org/webt/hx/6c/sn/hx6csng8_0l_yqxgvteefbapkm0.png">  . ,   ¬´emails¬ª, pb (¬´emails¬ª|z1) = 1.0  pb (¬´emails¬ª|z2) = 1.0,  ,   (3) ,  pb (¬´emails¬ª|z12) = 1.0,    ,         z12. , pb (¬´find¬ª|z1) = 0.5  pb (¬´find¬ª|z2) = 0.5,  , pb (¬´find¬ª|z12) = 0.75.         z1  z2,     z12   . <br><br> ,     . ,                 ,      .       3,    ‚Äî TOP(1), FILTER(start&gt;now)  ORDERBY(start,asc) ‚Äî    ¬´next¬ª.           API,        .          ,       ,    API. <br><br>  ‚Äî  .  ,             .           . -       ,      . <br><br> <b>INTERPOLATE</b> ()      z,     z  ,   ,      <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">   <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  and <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  . <br><br><img src="https://habrastorage.org/webt/s4/qk/00/s4qk00v3xupp-nglc-ge-mmgwxa.png"><br><br>   Œ±      <br>  ,  ,  ,  ,   ,     ,     ,      .   , <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">    ,      ,         ().   <img src="https://habrastorage.org/webt/xt/ml/w5/xtmlw5p16zioqn1amioucvjhe5o.png"> ,     <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  .   ,   , <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  = <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  .    <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  = <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  . <br><br>       ,    <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">   z ( 1),        .  ,   <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">      .     ,    <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  and <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">    z.     ,         .     ,    <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">   . <br><br> <i> 1. Update Node Distributions of Semantic Mesh</i> <br><br><img src="https://habrastorage.org/webt/wd/ja/xx/wdjaxx4oqk_1rqniul9rnbc-fno.png"><br><br><h4> 3.3   </h4><br>          API,       .            API,   .             . <br><br>       Z.   ‚Äî        <img src="https://habrastorage.org/webt/ti/9x/ac/ti9xacqha0b1hbtkyeejh30f3sk.png"> ,     .       state, <br>      policy <img src="https://habrastorage.org/webt/9i/oc/9m/9ioc9mao9yuvhq7uhkiemeqet4g.png">         . <br><br>          , ,      ,        ( 2),    .   ,      ,        Z ( 3).        ( 5),  <br>        ( 6),       ( 7),         ( 8).   ,       ,   . <br><br><img src="https://habrastorage.org/webt/va/tz/hs/vatzhsjcogvaktg8wh4h0a8al70.png"><br> <i> 6.  . z12  z23     . w ‚Äî ,    d(z12, z23),     ,    .          z12  z23 ( ). z2   0,       z12  z23;             z12  z23.</i> <br><br>            ,          ,    ,     .            ,   ¬´ ¬ª.      ,        NLI,    f: X ‚Üí Y,  X ‚Äî   ,          ,  Y      . <br><br>         ,     Y   .          -.      Y,    API,      ,    X,  .  ,      .  ,       .          . <br><br>    ,       . ,  ,    API   .     ,   <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">     .       <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  n-  <img src="https://habrastorage.org/webt/nv/ky/pn/nvkypndwq-7j6xnikrteas3oiq4.png"> ,  n = | <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  | ‚Äî  .      d (        L1)   <img src="https://habrastorage.org/webt/jc/z9/de/jcz9demx4drw0fsgz1niisgavd0.png"> ,           . <br><br>     ,        .           ,      .        ,       .        ,    ,      . <br><br><img src="https://habrastorage.org/webt/of/tp/sl/oftpslo2cmmijyxtccepbyqsmsc.png"><br><br>  Where <img src="https://habrastorage.org/webt/1g/-h/nh/1g-hnhpklydkghmo4z7pq7ujouu.png">    K  ,           . <br><br> <i> 2. Iteratively Annotate a Semantic Mesh with a Policy</i> <br><br><img src="https://habrastorage.org/webt/5p/j2/2r/5pj22rp_c5npknusixp4k4ulfli.png"><br><br> <i> 3. Compute Policy based on Diferential Propagation</i> <br><br><img src="https://habrastorage.org/webt/s5/ee/zb/s5eezb7ls03ly9nfndyotsqhlva.png"><br><br> <i> 4. Recursively Propagate a Score from a Source Node to All Its Parent Nodes</i> <br><br><img src="https://habrastorage.org/webt/m9/ge/vt/m9gevt8-vlgwxxulaxyfxkovdmk.png"><br><br>           Œò.            .      ,      :       ,     ,         . <br><br>        ,     ,     . ,     ¬´unread emails about PhD application¬ª  ¬´how many emails are about PhD application¬ª ,      ¬´emails about PhD application¬ª           .    ,      : ¬´unread emails¬ª  ¬´how many emails¬ª. <br><br>       6,    ‚Äî   3.         ,   ( 6),        .    ,           ( 9, 10   4).    ‚Äî              ( 12). <br><br><h2> -  </h2><br>    ,    NL2API    .      NL2API ,       NLI         API. <br><br><h4>       </h4><br>       NLI   ,     NL2API     ,         (LM)   . <br><br>   u    API z        u.     BoB <img src="https://habrastorage.org/webt/rq/qs/9-/rqqs9-qn12-qsdd7mahxx5tg-si.png">   API z   -: <br><br><img src="https://habrastorage.org/webt/lr/4f/pt/lr4fptel7voyxz2pelzjinbyu14.png"><br><br>     ,  0 ‚â§ Œ≤ ‚â§ 1 ‚Äî   .    <img src="https://habrastorage.org/webt/rh/1e/wc/rh1ewczas_fvleaxd5za0qvury0.png"> ,    ,     .  API      : <br><br><img src="https://habrastorage.org/webt/3c/sf/fu/3csffus3jr7h6kpxq6czdyvhdtm.png"><br><br> (     ) <br><br><img src="https://habrastorage.org/webt/0s/xu/y-/0sxuy-xon3k12zlsbn2f41wzyco.png"><br><br>  API        . <br><br><h4>   Seq2Seq </h4><br>  Neural networks are becoming more common as models for NLI, while the Seq2Seq model is better suited for this purpose because it allows you to naturally process input and output sequences of variable length.  We are adapting this model for NL2API. <br><br>  For input sequence e <img src="https://habrastorage.org/webt/sl/zv/2w/slzv2wvhssrsrt-2cehxkcosmr0.png">  , the model estimates the conditional probability distribution p (y | x) for all possible output sequences <img src="https://habrastorage.org/webt/zz/ar/74/zzar74ttz1utynmp2qpkuprrhwc.png">  .  The lengths T and T ‚Ä≤ can vary and take any values.  In NL2API, x is an output statement.  y can be a serialized API call or its canonical command.  We will use canonical commands as target output sequences, which actually turns our problem into a rephrasing problem. <br><br>  An encoder implemented as a recurrent neural network (RNN) with controlled recurrent blocks (GRU) first represents x as a fixed-size vector, <br><br><img src="https://habrastorage.org/webt/_l/vv/ht/_lvvhtq3g73uajiwibi7r5xzspc.png"><br><br>  where RN N is a brief representation for applying the GRU to the entire input sequence, marker by marker, followed by the output of the last hidden state. <br><br>  The decoder, which is also the RNN with the GRU, takes h0 as the initial state and processes the output sequence y, marker by marker, to generate a sequence of states, <br><br><img src="https://habrastorage.org/webt/eo/lg/9l/eolg9ljwlyskjfurunypvlmswaa.png"><br><br>  The output layer takes each decoder state as an input value and generates a dictionary distribution. <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  as output value.  We simply use affine transformation followed by the soft variable logistic function: <br><br><img src="https://habrastorage.org/webt/qr/ty/c9/qrtyc9lsayvqiczswbr-837_pba.png"><br><br>  The final conditional probability, which allows you to evaluate how well the canonical command y rephrases the input statement x, - <img src="https://habrastorage.org/webt/l5/yt/wn/l5ytwnga_iegxtspqogvabwe5g0.png"><img src="https://habrastorage.org/webt/ul/7k/ny/ul7knyk1imjwc0p_hrjisfmy8-e.png">  .  API calls are then ranked by the conditional probability of their canonical command.  We recommend to get acquainted with the source, where the process of learning the model is described in more detail. <br><br><h2>  Experiments </h2><br>  Experimentally, we study the following research subjects: [PI1]: Can we, using the proposed framework, collect high-quality training data at a reasonable price?  [PI2]: Does the semantic network provide a more accurate assessment of language models than a maximum likelihood estimate?  [PI3]: Does a differential distribution strategy allow for more efficient crowdsourcing? <br><br><h4>  Crowdsourcing </h4><br>  We apply the proposed framework to the two Microsoft web APIs - GET-Events and GET-Messages - which provide access to advanced search services for user emails and calendar events, respectively.  We create a semantic network for each API, listing all API calls (section 3.1) and up to four parameters in each.  The distribution of API calls is shown in Table 2. We use an internal crowdsourcing platform, similar to Amazon Mechanical Turk.  To ensure the flexibility of the experiment, we annotated all API calls with a maximum of three parameters. <br><br>  However, in each particular experiment, we will use only a specific subset for learning.  Each API call is annotated with 10 statements, and we pay 10 cents for each statement.  201 participants are involved in annotation, all of them have been selected using the qualification test.  On average, the performer took 44 seconds to rephrase the canonical team, so we can get 82 teaching examples from each artist per hour, and the cost will be $ 8.2, which, in our opinion, is quite a bit.  Regarding the quality of annotations, we manually checked 400 collected statements and found that the proportion of errors is 17.4%. <br><br>  The main causes of errors are related to the absence of certain parameters (for example, the performer did not specify the ORDERBY parameter or a COUNT parameter) or incorrect interpretation of the parameters (for example, ascending ranking is indicated when ranking is in descending order).  These examples account for about half of the errors.  The proportion of errors is comparable to that of other crowdsourcing projects in the field of NLI.  Thus, we consider the answer to [PI1] to be positive.  Data quality can be improved by engaging independent crowdsourced workers for post-testing. <br><br>  In addition, we received an annotated independent test set formed randomly from the entire semantic network and including, among other things, API calls with four parameters (Table 3).  Each API call in the test set initially had three statements.  We conducted a test and weed out statements with errors in order to improve the quality of testing.  The final test set included 61 API calls and 157 statements for GET-Messages, as well as 77 API calls and 190 statements for GET-Events.  Not all test statements were included in the training data, besides many test API calls (for example, calls with four parameters) were not involved in training, therefore, the test set was very complex. <br><br><img src="https://habrastorage.org/webt/dc/yk/nv/dcyknvmod2su0cutkru02tpklti.png"><br>  <i>Table 2. Distribution of API calls.</i> <br><br><img src="https://habrastorage.org/webt/x9/dm/_b/x9dm_bbbgyua7xe0cl1fzjloc5o.png"><br>  <i>Table 3. The distribution of the test set: statements (calls).</i> <br><br><h4>  Staging experiment </h4><br>  As an estimate, we use accuracy, that is, the proportion of test statements for which the maximum prediction was correct.  Unless otherwise specified, the balance parameter is Œ± = 0.3, and the smoothing parameter is LM Œ≤ = 0.001.  The number of pairs of vertices K used for differential propagation is 100,000. The set value for the state, size, encoder, and decoder in the Seq2Seq model is 500. Parameters are selected based on the results of a preliminary study on a separate test set (regardless of testing). <br><br>  The semantic network is not only useful for optimizing crowdsourcing as the first of its kind model of the crowdsourcing process for NLI, it also has technical advantages.  Therefore, we will evaluate the semantic network and the optimization algorithm separately. <br><br><h4>  Evaluation of the semantic network </h4><br>  Overall effectiveness.  In this experiment, we evaluate the model of the semantic network and, in particular, the effectiveness of the operations of composition and interpolation from the point of view of optimizing the assessment of language models.  The quality of language models can be judged by the effectiveness of the LM model: the more accurate the assessment, the higher the efficiency.  We use several training sets corresponding to different sets of annotated vertices.  ROOT is the root vertices.  TOP2 = ROOT + all nodes of layer 2;  and TOP3 = TOP2 + all nodes of layer 3. This allows the semantic network to be evaluated using different amounts of training data. <br><br>  The results are shown in table 4. When working with the base model LM, we use the maximum likelihood estimate (MLE) to analyze the language model, that is, we use <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  for all non-annotated vertices, and uniform distribution for non-annotated vertices.  It is not surprising that the efficiency is rather low, especially if the number of annotated vertices is small, since the MLE cannot provide information about non-annotated vertices. <br><br>  By adding the composition to the MLE, we can estimate the expected distribution <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  for non-annotated vertices but <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  still used for annotated vertices, i.e. no interpolation.  This allows you to significantly optimize the API and a variety of training data.  With just 16 annotated API calls (ROOT), a simple LM model with SeMesh can outperform a more sophisticated Seq2Seq model with more than a hundred annotated API calls (TOP2) and approach a model containing about 500 annotated API calls (TOP3). <br><br>  These results clearly show that the language models evaluated using the composition operation are sufficiently accurate, the validity of the assumption that the expressiveness of the statements (Section 3.2) is proved empirically.  It can be noted that working with GET-Events is generally more difficult than with GET-Messages.  This is because GET-Events uses <br>  more teams that are tied to time, and events may relate to the future or the past, whereas e-mails always refer only to the past. <br><br><img src="https://habrastorage.org/webt/pb/ym/e4/pbyme4xdpxcqabwlawu_bmkefkg.png"><br>  <i>Table 4. Overall Accuracy Percentage.</i>  <i>The operations of the semantic network greatly optimize the simple LM model, making it better for the more complex Seq2Seq model, when the amount of training data is rather small.</i>  <i>The results prove that the semantic network provides an accurate assessment of language models.</i> <br><br>  The effectiveness of the LM + composition decreases when we use more training data, which indicates that it is inexpedient to use only <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  and the need to combine with Œ∏em with <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  .  When we interpolate <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  and <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  then we achieve improvements everywhere except at the ROOT level, where none of the peaks can be simultaneously <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  and <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  .  Unlike composition, the more training data we use for interpolation, the better the result of the operation.  In general, the semantic network provides significant optimization compared to the basic MLE indicators.  Thus, we consider the answer to [PI2] to be positive. <br><br>  The best indicators of accuracy are in the range from 0.45 to 0.6: they are not very high, but they are on the same level as indicators of modern methods of applying NLI to knowledge bases.  This reflects the complexity of the problem, as the model must exactly find the best among thousands of related API calls.  By collecting additional statements for each API call (see also Figure 7) and using more advanced models, such as bidirectional RNNs with an attention mechanism, you can further improve efficiency.  We will leave these questions for future work. <br><br>  The impact of hyperparameters.  Now consider the influence of two hyperparameters on the semantic network: the number of statements | u |  and the balance parameter Œ±.  Here, we still rely on the effectiveness of the LM model (Figure 7).  Sayings are randomly selected when | u |  &lt;10, and the model output is given average marks for 10 repeated runs.  We show the results for GET-Events, for GET-Messages they are similar. <br><br>  It is not surprising that the more statements we annotate for each vertex, the higher the efficiency, although the increment gradually decreases.  Therefore, in the presence of such a possibility, it is recommended to collect additional statements.  On the other hand, the model efficiency is practically independent of Œ±, since this parameter lies in the allowable range ([0.1, 0.7]).  The influence of the parameter Œ± increases with the number of annotated vertices, which is quite expected, since interpolation affects only annotated vertices. <br><br><h4>  Crowdsourcing optimization </h4><br>  In this experiment, we evaluate the effectiveness of applying the proposed differential propagation strategy (DP) to optimize crowdsourcing.  Various crowdsourcing strategies iteratively select API annotation calls.  At each iteration, each strategy selects 50 API calls, and then they are annotated, and the two NL2API models use the accumulated annotated data for training. <br><br>  Finally, models are evaluated on a test set.  We use the basic LM model, which does not depend on the semantic network.  The best crowdsourcing strategy should provide the best model performance for the same number of annotations.  Instead of annotating vertices on the fly using crowdsourcing, we use annotations collected earlier as a pool of candidates (section 5.1), so all strategies will be selected only from existing API calls with three parameters. <br><br><img src="https://habrastorage.org/webt/lg/xz/z9/lgxzz9zznpwnk0c4vdqfnfaurrg.png"><br>  Figure 7. Effects of hyperparameters. <br><br><img src="https://habrastorage.org/webt/ak/5p/da/ak5pda8vlogeadhfjphy-t33dcg.png"><br>  Figure 8. Crowdsourcing optimization experiment.  Left: GET-Events.  Right: GET-Messages <br><br>  We take the breadth first strategy (BF) as a basic strategy, which in the downstream direction gradually annotates each layer of the semantic network.  It resembles a strategy out.  So we get the basic indicators.  Calling top-level APIs is usually more important because they are compositions of low-level API calls. <br><br>  The results of the experiment are shown in Figure 8. For both NL2API models and both APIs, the DP strategy generally improves efficiency.  When we annotate only 300 calls for each API, as applied to the Seq2Seq model, DP provides an absolute increase in accuracy of more than 7% for both APIs.  When the pool of candidates is exhausted, the two algorithms converge, which is expected.  The results show that DP allows you to define API calls that are highly valuable for learning NL2API.  Thus, we consider the answer to [PI3] to be positive. <br><br><h2>  Related research areas </h2><br>  Natural language interface.  Over the creation of natural language interfaces (NLI) experts have been working for several decades.  The first NLI mainly used the rules.  Learning-based methods have firmly taken the lead in recent years.  The most popular learning algorithms are based on log-line models and relatively recently developed deep neural networks. <br><br>  The application of NLI to relational databases, knowledge bases and web tables has been studied fairly well, but there is almost no research on the API.  NL2API developers face two major problems: the lack of a single semantic representation for the API and, in part because of this, the lack of training data.  We are working on solving both problems.  We offer a unified semantic representation of the API based on the REST standard and a fundamentally new approach to the collection of training data in this representation. <br><br>  <b>Collection of training data for NLI.</b>  Existing training data collection solutions for NLI generally adhere to the principle of "the best of the possible".  For example, questions in natural language are collected using the Google Suggest API, and the authors receive commands and corresponding API calls from the IFTTT website.  Researchers have relatively recently begun to explore approaches to creating NLI, involving the collection of training data using crowdsourcing.  Crowdsourcing has become a familiar practice in various language related studies. <br><br>  However, there is little study of its application to create NLI interfaces, which allow solving the unique and intriguing task of modeling the interaction between natural language representations and formalized representations of the semantic structure.  Most of these studies involve the application of NLI to knowledge bases, where a formalized presentation is expressed by logical forms in a certain logical formalism.  The authors propose to transform logical forms into canonical commands with the help of grammar, and in described methods for refining generated logical forms and screening out those that do not correspond to a significant question in natural language. <br><br>  A semi-automatic framework is proposed for interacting with users on the fly and comparing commands in natural language with API calls on smartphones.  The authors propose a similar solution based on a crowdsourcing framework, where performers interactively perform annotation tasks for the web API.  But no researcher has so far dealt with the use of the compositionality of formal representations to optimize the crowdsourcing process. <br><br>  <b>Semantic methods for web API.</b>  There are a number of other semantic methods developed for the web API.  For example, the semantic descriptions of the web API are retrieved in order to simplify the composition of the API, while the proposed search mechanism for the web API to compose the compositions.  The NL2API technology will potentially allow to solve such problems, for example, when used as a single search engine to find an API. <br><br><h2>  Conclusions and directions for further research </h2><br>  We formulated the problem of creating a natural language interface for web APIs (NL2API) and proposed a comprehensive framework for developing NL2API from scratch.  One of the key technical results of the work is a fundamentally new approach to the collection of training data for NL2API based on crowdsourcing.  The work opens up several areas for further research: (1) The language model.  How, by way of generalization, to move from individual words to more complex language units, for example, phrases?  (2) Crowdsourcing optimization. <br><br>  How to use the semantic network as efficiently as possible?  (3) Model NL2API.  For example, the framework for filling slots in voice dialogue systems is optimally suited for our presentation of API frames.  (4) Composition API.  How to collect training data while using multiple APIs?  (5) Optimization during the interaction: how to continue to improve the NL2API in the process of user interaction after the initial training? </div><p>Source: <a href="https://habr.com/ru/post/418559/">https://habr.com/ru/post/418559/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../418547/index.html">Asynchronous example programming: reconstructing java.util.concurrent.CompletableFuture methods</a></li>
<li><a href="../418549/index.html">Creating a bot for participation in the AI ‚Äã‚Äãmini cup 2018 based on a recurrent neural network (part 3)</a></li>
<li><a href="../418551/index.html">How much should a programmer know math?</a></li>
<li><a href="../418553/index.html">Kotlin + React vs Javasript + React</a></li>
<li><a href="../418557/index.html">Calculation of wave processes in the hydraulic line by the method of characteristics</a></li>
<li><a href="../418561/index.html">State machines in the service of MVP. Yandex lecture</a></li>
<li><a href="../418563/index.html">The digest of interesting materials for the mobile developer # 263 (July 23 - July 29)</a></li>
<li><a href="../418565/index.html">On the way to 100% of code coverage by tests in Go using the example of sql-dumper</a></li>
<li><a href="../418567/index.html">Dell will cease to be a private company and for the first time in 5 years will place shares on the exchange.</a></li>
<li><a href="../418569/index.html">New satellites - new bugs: The GOES-17 satellite's infrared sensor does not cool well</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>