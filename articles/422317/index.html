<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why are TPUs so well suited for depth learning?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Third Generation Tensor Processor 

 Google Tensor Processor is a special-purpose integrated circuit ( ASIC ) developed from scratch by Google to perf...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why are TPUs so well suited for depth learning?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/hc/p7/cd/hcp7cda1npc6ylbq16nwwcsyxd4.jpeg"><br>  <i>Third Generation Tensor Processor</i> <br><br>  <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D0%25BD%25D0%25B7%25D0%25BE%25D1%2580%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25BF%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581%25D0%25BE%25D1%2580_Google">Google Tensor Processor</a> is a special-purpose integrated circuit ( <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D0%25BD%25D1%2582%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D1%2585%25D0%25B5%25D0%25BC%25D0%25B0_%25D1%2581%25D0%25BF%25D0%25B5%25D1%2586%25D0%25B8%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D0%25BD%25D0%25B0%25D0%25B7%25D0%25BD%25D0%25B0%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F">ASIC</a> ) developed from scratch by Google to perform machine learning tasks.  It works in several major Google products, including Translate, Photos, Search Assistant and Gmail.  Cloud TPU provides the benefits of scalability and ease of use for all developers and data scientists to launch advanced Google cloud machine learning models.  At the Google Next '18 conference, we announced that Cloud TPU v2 is now available to all users, including <a href="https://console.cloud.google.com/freetrial">free trial accounts</a> , and Cloud TPU v3 is available for alpha testing. <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f34/b73/cee/f34b73ceecf379f47dd446f0cc8b1a7c.jpg"><br><br>  But many people ask - what is the difference between CPU, GPU and TPU?  We made a <a href="https://tpudemo.com/">demo site</a> , where the presentation and animation, which answers this question.  In this post I would like to dwell in more detail on certain features of the content of this site. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  How neural networks work </h2><br>  Before we start comparing CPU, GPU and TPU, let's see what kind of computation is required for machine learning ‚Äî specifically, for neural networks. <br><br>  Imagine, for example, that we use a single-layer neural network to recognize handwritten numbers, as shown in the following diagram: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d6/bf4/585/2d6bf4585be28678f66652fd77ecb2f8.png"><br><br>  If the picture is a grid of 28x28 pixels in the gray scale, it can be converted into a vector of 784 values ‚Äã‚Äã(dimensions).  The neuron recognizing the digit 8 takes these values ‚Äã‚Äãand multiplies them with the parameter values ‚Äã‚Äã(red lines in the diagram). <br><br>  The parameter works as a filter, extracting the features of the data, talking about the similarity of the image and form 8: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/020/141/559/0201415596ab1132ba07a3b430a2fa34.gif"><br><br>  This is the simplest explanation for data classification by neural networks.  Multiplication of data with the corresponding parameters (coloring of points) and their addition (sum of points on the right).  The highest result indicates the best match between the entered data and the corresponding parameter, which is likely to be the correct answer. <br><br>  Simply put, neural networks are required to make a huge number of multiplications and additions of data and parameters.  Often we organize them in the form of <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BC%25D0%25BD%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25BC%25D0%25B0%25D1%2582%25D1%2580%25D0%25B8%25D1%2586">matrix multiplication</a> , which you might encounter at school on algebra.  Therefore, the problem is to perform a large number of matrix multiplications as quickly as possible, spending as little energy as possible. <br><br><h2>  How does the CPU work </h2><br>  How does the CPU approach this task?  CPU is a general-purpose processor based on <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D1%2580%25D1%2585%25D0%25B8%25D1%2582%25D0%25B5%25D0%25BA%25D1%2582%25D1%2583%25D1%2580%25D0%25B0_%25D1%2584%25D0%25BE%25D0%25BD_%25D0%259D%25D0%25B5%25D0%25B9%25D0%25BC%25D0%25B0%25D0%25BD%25D0%25B0">von Neumann architecture</a> .  This means that the CPU works with software and memory in some way: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/963/029/620/96302962031a0a23ecf34b868d194161.gif"><br><br>  The main advantage of the CPU is flexibility.  Thanks to the von Neumann architecture, you can download completely different software for millions of different purposes.  The CPU can be used for word processing, rocket engine management, banking transactions, image classification using a neural network. <br><br>  But since the CPU is so flexible, the hardware does not always know in advance what the next operation will be until it reads the next instruction from the software.  The CPU needs to store the results of each calculation in a memory located inside the CPU (the so-called registers, or <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D1%258D%25D1%2588_%25D0%25BF%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581%25D0%25BE%25D1%2580%25D0%25B0">L1 cache</a> ).  Access to this memory becomes a minus of the CPU architecture, known as the bottleneck of the von Neumann architecture.  Although a huge amount of computation for neural networks makes predictable future steps, each CPU <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D1%2580%25D0%25B8%25D1%2584%25D0%25BC%25D0%25B5%25D1%2582%25D0%25B8%25D0%25BA%25D0%25BE-%25D0%25BB%25D0%25BE%25D0%25B3%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B5_%25D1%2583%25D1%2581%25D1%2582%25D1%2580%25D0%25BE%25D0%25B9%25D1%2581%25D1%2582%25D0%25B2%25D0%25BE">arithmetic logic unit</a> (ALU, a component that stores and manages multipliers and adders) performs operations sequentially, each time accessing memory, which limits the overall throughput and consumes a significant amount of energy. . <br><br><h2>  How does the GPU </h2><br>  To increase throughput compared to the CPU, the GPU uses a simple strategy: why not embed thousands of ALUs in the processor?  A modern GPU contains about 2500-5000 ALUs on a processor, which makes it possible to perform thousands of multiplications and additions simultaneously. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbb/bcb/17b/fbbbcb17b7732e20d2658d5e76023beb.gif"><br><br>  This architecture works well with applications requiring massive parallelization, such as, for example, multiplication of matrices in a neural network.  With a typical deep-field training (GO) training load, the throughput in this case is increased by an order of magnitude compared to the CPU.  Therefore, today the GPU is the most popular processor architecture for GO. <br><br>  But the GPU still remains a general-purpose processor that must support a million different applications and software.  And this brings us back to the fundamental problem of the bottleneck of von Neumann architecture.  For each calculation in thousands of ALUs, GPUs, you need to refer to registers or shared memory to read and store intermediate results of calculations.  Since the GPU performs more parallel computing on thousands of its ALUs, it also spends proportionately more energy on memory access and occupies a larger area. <br><br><h2>  How does TPU work </h2><br>  When we developed TPU at Google, we built an architecture designed for a specific task.  Instead of developing a general-purpose processor, we developed a matrix processor specialized for working with neural networks.  TPU will not be able to work with a word processor, control rocket engines or perform banking transactions, but it can process a huge number of multiplications and additions for neural networks at an incredible speed, while consuming much less energy and accommodating in a smaller physical volume. <br><br>  The main thing that allows him to do this is a radical elimination of the bottleneck of von Neumann architecture.  Since the main task of TPU is the processing of matrices, the developers of the scheme were familiar with all the necessary computation steps.  Therefore, they were able to place thousands of multipliers and adders, and physically combine them, forming a large physical matrix.  This is called a <a href="https://en.wikipedia.org/wiki/Systolic_array">pipeline array architecture</a> .  In the case of Cloud TPU v2, two pipeline arrays of 128 x 128 are used, which in total gives 32,768 ALU for 16-bit floating point values ‚Äã‚Äãon a single processor. <br><br>  Let's see how a pipeline array performs calculations for a neural network.  First, the TPU loads the parameters from the memory into the matrix of multipliers and adders. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ec/de3/fc6/9ecde3fc6d69116db89aacd83bdf15e5.gif"><br><br>  The TPU then loads the data from the memory.  By performing each multiplication, the result is transmitted to the following multipliers, while simultaneously performing additions.  Therefore, the output will be the sum of all multiplications of data and parameters.  During the entire process of volume calculations and data transfer, memory access is completely unnecessary. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/04a/ef8/b31/04aef8b31b8eb550ba093df4eb811d58.gif"><br><br>  Therefore, TPU shows a large bandwidth when calculating for neural networks, consuming much less energy and taking up less space. <br><br><h2>  Advantage: 5 times reduced cost </h2><br>  What are the benefits of TPU architecture?  Cost  Here is the cost of Cloud TPU v2 work for August 2018, at the time of this writing: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e2f/340/d86/e2f340d861ef00ac9ceac0e7d6dc5f24.png"><br>  Regular and TPU cost of work for different regions of Google Cloud <br><br>  Stanford University is distributing a set of tests <a href="https://dawn.cs.stanford.edu/benchmark/">DAWNBench</a> , measuring the speed of systems with deep learning.  There you can look at various combinations of tasks, models and computing platforms, as well as the corresponding test results. <br><br>  At the time of the end of the competition in April 2018, the minimum cost of training on processors with non-TPU architecture was $ 72.40 (for ResNet-50 training with 93% accuracy on ImageNet on <a href="https://aws.amazon.com/ru/ec2/spot/">spot instances</a> ).  With the help of Cloud TPU v2, such training can be held for $ 12.87.  This is less than 1/5 of the cost.  Such is the power of architecture designed specifically for neural networks. </div><p>Source: <a href="https://habr.com/ru/post/422317/">https://habr.com/ru/post/422317/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422303/index.html">Best SQL Builder - use jOOQ on Android</a></li>
<li><a href="../422305/index.html">Distribution of the number of Russian employees by salaries based on a large online survey on a non-specialized platform</a></li>
<li><a href="../422309/index.html">How to protect data in cloud neural networks - a new encryption method is proposed</a></li>
<li><a href="../422311/index.html">Python interesting and useful. Part 2</a></li>
<li><a href="../422315/index.html">How to survive the hunter bugs: the daily struggle for income</a></li>
<li><a href="../422319/index.html">For the first time the Russian team got into the largest scientific accelerator IndieBio</a></li>
<li><a href="../422321/index.html">Optimization of work with prototypes in JavaScript engines</a></li>
<li><a href="../422323/index.html">Hackers: Russia and China</a></li>
<li><a href="../422325/index.html">DevDay about testing: Relax. Test it easy</a></li>
<li><a href="../422327/index.html">Project schedule vs Backlog: a battle without chances</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>