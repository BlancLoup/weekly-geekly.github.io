<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Saga about the cluster. Everything you wanted to know about Postgres horizontal scaling</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Oleg Bartunov (@zen), Alexander Korotkov (@smagen), Fedor Sigaev 
 Ilya Kosmodemyansky: Now there will be the most burning topic on PostgreSQL. All th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Saga about the cluster. Everything you wanted to know about Postgres horizontal scaling</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/1a7/443/d60/1a7443d608be3231161976b5b7702737.jpg"><br><br><h3>  Oleg Bartunov (@zen), Alexander Korotkov (@smagen), Fedor Sigaev </h3><br>  <b><i>Ilya Kosmodemyansky:</i></b> Now there will be the most burning topic on PostgreSQL.  All the years that we have been engaged in consulting, the first thing people ask is: ‚ÄúHow to make multimaster replication, how to achieve magic?‚Äù.  Many professional wizards will talk about how this is now well and great implemented in PostgreSQL - the guys from Postgres Professional will tell everything about the cluster in this report.  The name is appropriate - ‚ÄúSaga‚Äù - something epic and monumental.  Now the guys from Postgres Professional will start their saga, and it will be interesting and good. <br><br>  So, Oleg Bartunov, Alexander Korotkov and Fedor Sigaev. <br><a name="habracut"></a><br>  <b><i>Oleg Bartunov:</i></b> Ilya said that we will talk about how Postgres has everything well with the cluster, but in fact we will tell you about what is happening in the Postgres community with this topic.  In fact, the topic is ambiguous, and we will try to show it, why all this is not so difficult, and what prospects await us. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      First I want to introduce myself - the three of us are the leading developers from Russia in the Postgres community. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e82/190/3d1/e821903d16b60a5d82745df2c244b2d4.png"><br><br>  Everything that we did in Postgres, we tried to list in this small table (on the slide), you probably know our work. <br><br>  We decided to first make some play and show how difficult and painful it is to work with distributed things.  The first slide we have is called "Distributed misfortunes." <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ba2/be5/39c/ba2be539c1b5c71100f015fe6cc1be11.png"><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://player.vimeo.com/video/150116341" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <b><i>Fedor Sigaev:</i></b> I will continue. <br><br>  When they talk about a cluster, as a rule, they are either people who understand what it is about, and then we immediately delve into the details: "how you have done this and how it is implemented as a single commit, and how you interact with the nodes, and as a recovery? ‚Äù, or these are people who come and say that a cluster is‚Äú we will put several wheelbarrows one under the other, they will all work and we will be happy ‚Äù. <br><br>  I wanted to show in the sketch that it is not so simple, and any cluster requires some solutions.  First, I will ask Ivan Panchenko and Kolya Shaplov to leave - we will appoint them as servers.  Server A and Server B. We will act in the hope that they are honest servers, i.e.  honest databases.  Sasha, I will ask to be a client.  The client is not in the sense of who came to the bank and broke up with the money, but in the sense that this is some kind of application that serves external clients of our bank.  We will not keep in mind those customers directly.  Actually, the client is our application. <br><br>  Here our application begins a transaction and distributes on the begin command.  After that, the client comrade departs from the databases, shakes hands with them and says that they need to be done in some abstract manner: ‚Äúchange something here, insert it, delete here, it‚Äôs absolutely not a matter of principle‚Äù. <br><br>  Now, as everyone likes to say, a two-phase commit solves our problems.  The client distributes them to the prepare command.  What does the database actually do?  It performs all the triggers, it checks constraint, etc.  After that, if these commands have passed, the database promises that the commit will always take place, i.e.  whatever happens even when power is lost. <br><br>  Here, our client issues one commit, goes to one database.  Vanya we have commited.  But during the second Sasha goes, goes, and then the light turns off - all three of them fall.  Fell.  Light turned on.  They rise, but the commit did not come.  The client is not a dream at all, because everything is gone.  The database named after Vanya Panchenko read her WAL logs, read that she was in a happy state ‚Äî I did everything.  The database provided by Kolya, server B, reads its WAL-log, finds what is written ‚Äúprepared to commit‚Äù, and then hangs up with a question - there was no commit.  What should she do?  And she has absolutely nowhere to go.  The client does not know anything about this, Vanya, too - he has his commit.  Question: what to do, how to get out of this situation? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/439/da5/fcb/439da5fcbd185ecdfa5a9410777c4ed1.png"><br><br>  One database all successfully zakommitila, the second hangs in the question.  There are not many outputs.  Call the DBA or someone else, for example, a system administrator.  He tries to understand from the logs what has happened, that in one database it is committed, and in the other - not.  At this time, if you are not afraid of losing money, then your cluster works with inconsistent data, or you completely stop the service, say that we are doing technical work, we find out who owes how much to whom. <br><br>  Or you enter into the work of the arbitrator.  The client will go to the arbitrator, not to our databases, it is the arbitrator who will distribute the tasks, write himself in the log that we are ‚Äúprepared to commit‚Äù, or ‚Äúwe have done this‚Äù.  After that, it distributes commits and logs itself to the log that the first base is recorded by the commit, and the second is not.  Next, we wake up, read the logs and the unfortunate Kolya, we say: ‚Äúcommute what you have found.‚Äù <br><br>  The trouble here is such that writing this arbiter from scratch is also a very, very difficult task.  And still, you have a moment when you told the commit to the base, but you didn‚Äôt have time to write yourself to the log.  So, this is one of the problems.  One of the many problems faced by any cluster solution that wants to be / seem reliable. <br><br>  For the next scene, let's imagine a bank that has 2 accounts, we have 1000 credit cards in each account.  We have one account with Vanya, one - with Kolya.  Client 1 (Sasha) polls the amount of bills.  What does he see?  He sees 1000 credit cards, 1000 credit cards, in the amount of 2000 credit cards.  Then Sasha starts a transaction - he gives ‚Äú-500 credit cards‚Äù to one base, the second ‚Äú+500 credit cards‚Äù.  And after that he asks: ‚Äúwhat do you have in total?‚Äù.  In total, he has: Vanya, he sees the result of 1500, and Kolya has 500 credit cards taken away - he has 500. Everything is good.  Client 1 sees 2000 again. <br><br>  Then Sasha starts this commit.  He starts kommitit with Kolya.  At this moment, client number 2 wakes up (a girl from the audience) and comes up with the question: ‚Äúshow how much money you have‚Äù.  Vanya's transaction is not yet committed, and what does the first client see?  He sees 1000. And Kolya‚Äôs commit has already come - he already has 500. What does the unhappy second client see as a result?  That money has gone somewhere.  He sees a total of 1500! <br><br>  These are the problems of inconsistency - you cannot commit to two different databases at the same time.  Those.  you always need to deal with it somehow.  Loki expose, and outside the database, or to prohibit access to databases.  Here is a staged misfortune right in the faces, what problems can be encountered. <br><br>  <b><i>Oleg Bartunov:</i></b> The conclusion from this view is that you cannot have a complete read with a two-phase commit, i.e.  even reading cannot be complete. <br><br>  <b><i>Fedor Sigaev:</i></b> Here we were not even very attracted to the two-phase commit, i.e.  a two-phase commit complicates the situation with running around, but in fact you still leave a ‚Äúhole‚Äù, during which you have already made one commit and the second does not.  Therefore, you will always have that moment when your state of the two bases is inconsistent. <br><br>  <b><i>Oleg Bartunov:</i></b> After we have shown you that everything is not so simple, we will move on to some political games. <br><br>  Why political games?  This is a conditional name.  Postgres is developed by the community, and in the community we have a kind of democracy, and in order to achieve any one decision, you have to use a lot of any gestures, conversations, etc.  I call all this political games. <br><br>  Until recently, we never thought about it at all.  And literally 2-3 years ago, this situation arose in open source, since  open source is becoming the dominant software development model.  On this graph you can see the global trends: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ebd/e41/be0/ebde41be046be8653ccc568c32c20828.png"><br><br>  We see that open source databases are growing, and proprietary databases are falling. <br><br>  Just a solution model.  Here, the Gartner's Magic Quadrant shows: on the left - for the last year, and on the right - this year. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8ef/f31/ef9/8eff31ef9b4553c7c08ee7e34f3432f6.png"><br><br>  We see that Postgres in the face of EnterpriseDB and Fujitsu has already become a leader in databases.  This is a rather remarkable event that, for the first time in 2014, the open source database entered the list of database leaders.  Those.  the market is heating up. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7f5/fe4/2be/7f5fe42be848101c69ab54703aee1ac9.png"><br><br>  It can be seen that 70% of databases will already be open source in 2018.  This is a prediction, you can believe in it and not believe it, but the tendency is that now people are more and more eager to start using databases.  And the open source database leader is Postgres.  There is also MySQL - this is also a very good database, but Postgres is a serious database, which is now at a very good take-off.  And this is felt in our community, because all the clients we come to start asking questions, start to demand some features from Postgres. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9fa/c26/a73/9fac26a736d32deb9cc57f70cd1ddf47.png"><br><br>  I‚Äôve stolen this slide from the EnterpriseDB presentation, it shows Postgres development stages.  They have designated: now there is an Enterprise stage.  Pay attention to the features that are written there, what they call Enterprise.  Everything is good, but we do not see the word "cluster" there.  Those.  it really is, really.  We still have no opinion in the community that we need a cluster solution. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/383/8e8/e46/3838e8e46fc80d2ded7a314b18177802.png"><br><br>  If you look at our Todo (I specifically made a screenshot) - we have a cluster there, but this is not the cluster.  This is the cluster command.  Those.  even in our Todo there is not a word about what a horizontal cluster should do, etc. <br><br>  It was all not done by chance.  On the one hand, the community is conservative, on the other hand, the market has not yet supported us. <br><br>  Now, especially in Russia, Postgres is considered as a candidate for very large projects, and the concept of a cluster has become a must have. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0a6/489/bd4/0a6489bd4789bf7d3f59813e0219ca1b.png"><br><br>  Look at the Postgres forks page.  See how many forks.  And that's not it. <br><br>  With red circles I marked those forks in which the cluster is a feature.  We see that practically all the forks that appeared from Postgres appeared only because they lacked a cluster.  And, in the end, the community began to think about what the cluster really should be in our Todo, what we have to do. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f1d/308/e51/f1d308e517fd51baf2177f9c8b38b3df.png"><br><br>  This is not the first time this happens.  Old-timers Postgres, old users, remember the talk of replication.  Once Postgres did not have replication, and it was said that replication is not needed in the kernel, replication must be a third-party product.  And so it was, until, again, users, the community suddenly realized that it should be at the core.  And it appeared with us and now replication is a good, normal tool that everyone uses.  There was also a story about the port on windows - how much we wanted, how much power we had, we otbrykalis from the port on windows, but in the end it was done. <br><br>  <b><i>Fedor Sigaev:</i></b> But we otbrykalis, we did not. <br><br>  <b><i>Oleg Bartunov:</i></b> As a result, the very revolutionary situation has now come, when the lower classes want, the leaders did not dare.  Moreover, an interesting situation - we organized a company, we talk with our customers, and we say: ‚Äúwe make a cluster‚Äù.  The 2ndQuadrant says the same thing: ‚Äúwe make a cluster‚Äù.  EnterpriseDB says: ‚Äúwe also make a cluster‚Äù.  However, all customers, as one, say: ‚Äúwe are not interested in your roadmap, we are interested in the roadmap community‚Äù, i.e.  you need the community to have this cluster and the community to work. <br><br>  On the slide, I briefly brought the decision, Sasha will tell. <br><br>  <b><i>Alexander Korotkov:</i></b> <br><br><ul><li>  Probably many have heard there Postgres XC XL.  XL was a fork from Postgres XC.  XC has now moved to X2, this is a separate fork, which implements sharding and replicable tables, it reaches global consistency through a separate service called GTM - Global Transaction Manager.  It is being developed by the 2ndQuadrant, MTT and Huawei.  Huawei, in addition, has its own proprietary fork MPPDB, this is fork from XC. </li></ul><br>  <b><i>Oleg Bartunov:</i></b> I want to say that these are databases that already have live users, i.e.  many banks in China use these XC. <br><br>  <b><i>Alexander Korotkov:</i></b> Despite the fact that there were bugs with consistency, China is so brave that it is ready to run the banks. <br><br><ul><li>  There is pg_shard - this is an open source extension to Postgres, which provides basic sharding functionality.  Again, there is no transaction manager, there is no distributed consistency, but you can use it for some web tasks. </li><li>  There is a Citus DB - this is still a proprietary base, which Citus Data promises to open.  There are richer functions, i.e.  more complex queries.  There you can organize some kind of lab, but again for OLTP no distributed consistency is guaranteed. </li><li>  FDW is for now the approach that EnterpriseDB is trying to do for Postgres, i.e.  add it to the main master branch.  The idea is to use the already existing Foreign Data wrappers mechanism, i.e.  appeal to some external data source in order to make a sharding.  In 9.6.  have already committed a patch that allows partitioning through the inheritance existing in Postgres.  In the same way, if you do the inheritance of foreign tables, external tables, then you can make some fairly simple sharding.  But, again, there are a lot of questions about how much the optimizer can optimize such distributed queries. </li></ul><br>  EnterpriseDB is currently working on patches so that Aggregate Pushdown can be done, i.e.  in order not to draw everything from shards, and then count the aggregates, and so that the aggregates can be counted on the shards themselves.  Similarly, Join pushdown ... And such a long enough roadmap, which may not be completely complete, is not clear when we get a full-fledged distributed optimizer.  However, the advantage of this approach is that we are improving FDW, and that in itself is good. <br><br><ul><li>  Greenplum is a commercial fork from Pivotal, which was recently released in open source 3 days ago. </li></ul><br>  <b><i>Oleg Bartunov:</i></b> You can download Greenplum on GitHub, compile, install, and you will already have the same massive parallel database that eBay has been working on for a long time, which now works at Tinkoff Bank, etc.  Those.  The open source development model here is open and shows its advantages. <br><br>  <b><i>Fedor Sigaev:</i></b> Just keep in mind - these are OLAP databases, not OLTP, i.e.  if you analyze something in Postgres en masse, then you can touch Greenplum or pg_shard, but it‚Äôs better not to get money there in the hope that they will be transferred reliably. <br><br>  <b><i>Alexander Korotkov:</i></b> And our project that we started is the Distributed Transaction Manager for the Postgres wizard.  About him, we will tell a little more separately. <br><br>  <b><i>Oleg Bartunov:</i></b> These are such lively active projects that exist, that have their own customers, they are developing.  And we see that there are resources, and there is no community decision. <br><br>  In the past PGCon, we raised this question and agreed that after all we will arrange a big meeting, the so-called cluster summit, where we will solve this problem, what will we do with it, how to live? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2e8/c5c/27f/2e8c5c27f545917b1e6f96367f090548.png"><br><br>  2 days ago we flew in from this meeting.  We met in Vienna and discussed the burning problems of the cluster, i.e.  raised the question of whether the community will have a cluster solution in Todo or not. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/85a/07c/7f6/85a07c7f63e5295abdd40e5f03a47ab1.png"><br><br>  We decided that the situation has matured so much that it should be designated in our Todo.  At the same time, we must continue to develop cluster solutions, because, as we have already shown, cluster solutions are very complex things, and we cannot say in advance that tomorrow or in 2 years this solution will win, therefore solutions must be developed.  At the same time, they should evolve in such a way that, say, our company‚Äôs commit does not block the road to other solutions - this is very important.  Decided - peace and love. <br><br>  The idea was to make Postgres infrastructure so that cluster solutions could be developed as extensions, which would greatly facilitate development.  We told about our distributed transaction manager, this idea seemed interesting to people, and we will push through this business in 9.6, i.e.  in 9.6 we will try to have distributed transactions already in Postgres, and anyone could already do a cluster, at least?  at the application level. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/887/b70/873/887b708731eda8da9282dde73e40a120.png"><br><br>  I added to the slide that I took from EnterpriseDB, October 31st, 2015.  I called this period as horizontal scaling (sharding), and we wrote a list of tasks that we will need to solve.  Those.  this is what we are promoting in the community now, so that the community is concerned about this. <br><br>  <b><i>Alexander Korotkov:</i></b> The goals are clear, and we want scalability for both reading and writing, except for this, in order to have high valability.  This can be achieved, for example, by using redundancy, i.e.  the same shard is kept not in one copy, but in two copies. <br><br>  And the tasks here are broken, here are the largest.  It is clear that they are actually even more.  The task we are busy with is managing distributed transactions.  The place where many different interests now intersect is the scheduler and executor of distributed queries, i.e.  FDW is one approach to distributed queries, pg_shard is another approach, Postgres XC XL is the third approach.  And maybe another 4th, 5th, etc.  But we hope, sooner or later in this direction, we, too, will come to some common denominator. <br><br>  <b><i>Oleg Bartunov:</i></b> Bruce Momzhan is here at the conference, he is a responsible person who should write a paragraph on clustering on Todo, and then everything will work out for us, because we must somehow combine our efforts. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b20/9d2/c54/b209d2c549e267212bff285486d13b9c.png"><br><br>  This picture means that there are a lot of ingredients, you can make a lot of things from them, but not the fact that it will work out. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c5/8e2/b63/8c58e2b63316598a954e5a3f1ee5dc68.png"><br><br>  <b><i>Alexander Korotkov:</i></b> We tried to make such a matrix in the table, we entered cluster solutions here, and both those that now exist and are developing, and those that once were in history and are no longer supported. <br><br>  <b><i>Fedor Sigaev:</i></b> We took the most popular.  Oleg initially showed that this matrix is ‚Äã‚Äãeven bigger, we could make pixel-by-pixel graphics, but nothing will be clear from it. <br><br>  <b><i>Oleg Bartunov:</i></b> One can consider this table for a long time, one can argue on it, it shows that there is no perfect solution.  For example, XC / XL / X2 looks the most attractive, it has the most plus signs.  FDW and pg_shard also have a lot of pluses, but something is missing, in particular, they lack data integrity. <br><br>  When the whole fight began, each company declared that ‚Äúwe make decisions, our decisions are good,‚Äù etc.  After all, we also took XL and started playing with it, we decided to make our cluster, but then we realized that XL was not very ready to use it in production, and we decided not to get involved in a common fight, but to concentrate on that common technological an element that everyone needs.  Those.  all cluster solutions need a distributed transaction manager. <br><br>  Therefore, we chose this direction and implemented it.  Now, we will tell what it is and why it is important, and what it gives to cluster solutions. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/265/364/e84/265364e84dd2e5a09c3f8ebb4ee76282.png"><br><br>  <b><i>Alexander Korotkov:</i></b> What do we, in general, want from a distributed transaction manager?  It is clear that we want the commit on our distributed system to be atomic.  Atomic means that, firstly, it is either atomically everywhere, or else it has rolled away.  Secondly, we want its atomic appearance, i.e.  This means that if you make a request to read to several databases (what we showed in the 2nd sketch), then we must either see everywhere every single commit or not see it everywhere.  There should not be such that we saw on one server that the money had already been transferred, and on another server we saw that they had not transferred, and as a result, the amount did not converge. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are different solutions for this problem, none of them are ideal in their properties. I‚Äôll talk about this in more detail in the next slides, but I‚Äôve got the idea that we want some pluggable API for the transaction manager.</font></font> Those.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">we have a manager in Postgres that allows you to perform local transactions - this is one implementation, then add to it several implementations of distributed transaction managers. So far, we can highlight three things, perhaps, then, we will have some more ideas, maybe even better than the ones we see now. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d43/c46/906/d43c469067433206887200fce25fc43c.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We took and allocated API which is necessary to implement such manager of distributed transactions. This is just a set of functions that Postgres has previously been protected with, and we select them into a separate so's, into a separate library, which can be changed. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oleg Bartunov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In general, we are just following the pluggable path. We have a glider pluggable, executer pluggable, we can do data types, indexes, and now we have Transaction Manager also be pluggable. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fedor Sigaev:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> For those who don't know, the Postgres executer is completely pluggable, i.e. you can use absolutely your executer, just like a glider. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/00e/b7f/cb8/00eb7fcb8b8f8a4f24e758868ae004d6.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We are asked: why these seven functions, and not the other seven functions on the previous slide? The answer is this: because we tried three different managers by nature and found out that these seven functions are enough to bring the Transaction Manager from Postgres into a separate process. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alexander Korotkov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Seven because we would like six, but six did not work, but eight are not needed.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/782/38e/481/78238e481a6a744d3d0fad59c3cc5341.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is how it was before the patch, i.e. </font><font style="vertical-align: inherit;">if all these calls went directly, they were wired into Postgres itself. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/76d/550/6ac/76d5506ac92e10f80c3bf7b03debd26a.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And then we selected it in a separate component called Transaction Manager.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d86/f45/21f/d86f4521f1c428857c29dd76c00b5a83.png"><br><br>  Further. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f78/ca0/77b/f78ca077b0d2db104b20def1bb024963.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> This is about how we have varieties of methods for managing distributed transactions, what advantages and disadvantages they have. </font></font><br><br><ul><li>   ‚Äî Snapshot sharing ‚Äî  ,     Postgres XC, XL.   ,       ,     ,      .    ,        ,  ,  -     ,       .     ? ,            .    ,         , ,      ‚Äî   ,    ,        .. </li><li>      Timestamp.    ,   ,   ,  Timestamp.       Timestamp,      ,     ,  , , ,  ,      .   MTP   ,    . ,  ,   , ,   ,   .         .       ,       ,     ,   ,   - ,     ,    ,      .   ,      two-phase commit,    ,    ,           . </li><li>     ‚Äî   .   ,          .         ,      . ,  ,  ,           '  ,     ,          , ..      ,        .      ,     ,        . </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/aa8/a2a/920/aa8a2a9203e3162cac653066c02b3698.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This architecture is the first approach we call DTM. We have several Postgres instances where data is directly stored, a coordinator who performs transactions and an arbitrator who stores transaction statuses gives snapshots. Moreover, in order for this arbitrator not to be a single point of failure, we also duplicate it, make slaves, and in the event of a failure, we switch the arbitrator to the slave. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ce/623/902/9ce62390205e8cdbf19cec6f64af86e1.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here's how it can work: our coordinator keeps two connections to two servers. From one of them, he starts a distributed transaction, and the other says to join this distributed transaction. Then it performs some actions, and then performs commit on both nodes.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4a/e75/2bf/c4ae752bf70c08ae4c086c7e1c061fd0.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">At the same time, these two nodes work with dtmd - with a daemon to support distributed transactions. The node from which the distributed transaction started begins, in response, it is assigned the id'shnik of this transaction, snapshot. Then the next node joins this transaction, gives the join command, also receives a snapshot. Global xmin must be maintained so that the vacuum can be distributed only the necessary things to clean. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/326/812/a6f/326812a6fd024938affe3e6c6f9bc4c9.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the end, both of these nodes send a command, the client says a commit, they in turn send a commit to dtmd too. If dtmd sees that a commit has come from each of the nodes that participated in this transaction, then it returns OK to both of them. If at least one of them told him a roadback, then he returns an error to all of them. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a6d/deb/217/a6ddeb217f65077b17e37944cd69504e.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">flow - this is what I explained, only in the form of a diagram.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/850/806/943/8508069432d6777966fbac5c081e5ed8.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another option is when there is no timestamp on the Timestamp, everything is up to the Postgres instances and the coordinator. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a49/007/a81/a49007a81b5a5ee4e8db49f56852d426.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/29e/792/178/29e7921786d039426e5ba94956cd5259.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here, about the same, but the feature is that you actually have to do a two-phase commit. We hope that we can make it easier later. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/dde/2d3/c0a/dde2d3c0af0453f2a916d38b32beb12f.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is about communication with the arbitrator. If for everybody, i.e. for each receipt of a snapshot, we are sent a separate TCP packet to the arbitrator - this happens for a very long time, so there is a special demon, do sockhub, which accordingly groups calls to the arbitrator and sends them in batches and receives responses. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/954/86f/2ef/95486f2ef035f25a1914e33f0ca45ae4.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c81/ff1/192/c81ff1192c2840664d2d112202831f96.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/aca/87a/455/aca87a45555b026d8d493db26d2cdb66.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here are some examples that we used for benchmarks.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/12a/736/36f/12a73636fe19a14374b76bf29b21e0d1.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The classic banking example, when we remove one account, transfer it to another - our second scene. </font><font style="vertical-align: inherit;">Similarly, we had a second stream, which in our scene was performed by a girl, from whom we considered the sum and checked whether it converges or not. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oleg Bartunov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Here in the example we used pg_shard. </font><font style="vertical-align: inherit;">pg_shard you can download, download even a patch, and you will have transactional status. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2b/8c7/64f/a2b8c764f6dcb26788f2377966acae37.png"><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alexander Korotkov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We have taken and applied our approach to distributed transactions to existing solutions that do not have support for distributed transactions - this is pg_shard and FDW. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/de0/2ec/26e/de02ec26ea50ff5a778f1fb96f6f7c7a.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here are the results.</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Blue is how we did without a distributed transaction manager. </font></font> Those.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> speed here due to the lack of consistency between nodes. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Red is when the client application does everything. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Green is pg_shard. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yellow - FDW. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Accordingly, we found that we rest against the speed of interaction with the arbitrator. </font><font style="vertical-align: inherit;">A certain optimization has already been done, then we continue to do further. </font><font style="vertical-align: inherit;">To all this, we have an approach with a timestamp, which is very promising in terms of scalability, because there is no single point in it where everyone goes for snapshots. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oleg Bartunov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> You are not upset here, which is lower than the blue one - you can never be faster than the blue one, you have to pay. </font><font style="vertical-align: inherit;">Here it is important that it is scaled, that three nodes are faster than one, and at the same time both consistency and high valability are respected. </font><font style="vertical-align: inherit;">I myself first upset. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/f94/4a6/78b/f944a678bd5358a65dfb0d1440acbe98.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We did a multimaster. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alexander Korotkov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We have some limited number of writing streams that replicate their write operations between all servers, and there are reading streams. You can see that the reading is scaled linearly, as expected. In the case when we have a multimaster, we can read from any server. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/497/8d4/466/4978d4466df0156ef70565d4499f0183.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We have the following roadmap - make a patch called XTM - an expandable transaction manager for 9.6., Then experiment with different different approaches to implementing a distributed transaction manager, including bringing the Timestamp approach to mind, continuing our work on integrating with different solutions. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We have shown who can now benefit from our work on the distributed transaction manager:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/b41/69c/9ee/b4169c9eeeff540b2f72f95425d2d35d.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">First, these are pg_shard and FDW - they can actually get their ACID properties thanks to our distributed transaction manager. </font><font style="vertical-align: inherit;">And forks XC / XL / X2, they can simply get less labor for synchronization with the master, because the distributed transaction manager will already be in the master branch and, accordingly, they can apply less labor, not synchronize their GTM. </font></font><br><br> <b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oleg Bartunov:</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Finishing, we thank you for your attention and say that we are waiting for the future. </font><font style="vertical-align: inherit;">We hope that the community will insert it all into Todo ... Experience shows that Postgres, of course, is swinging, but then it does everything very well.</font></font><br><br><h3>  Contacts </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬ª </font></font><a href="https://habrahabr.ru/users/zen/" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zen</font></font></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬ª </font></font><a href="https://habrahabr.ru/users/smagen/" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">smagen</font></font></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬ª </font></font><a href="https://habrahabr.ru/company/postgrespro/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Blog of Postgres Professional</font></font></a> <br><br><blockquote> <font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This report is a transcript of one of the best speeches at the conference of developers of high-loaded systems </font></font><a href="http://highload.ru/%3Futm_source%3Dhabr%26utm_medium%3Dmedia%26utm_campaign%3Dpast.articles%26utm_content%3Dcommon"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HighLoad ++</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Now we are actively preparing for the conference in 2016 - this year HighLoad ++ will be held in Skolkovo on November 7 and 8. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The most active and biggest track HighLoad ++? </font><font style="vertical-align: inherit;">This is PostgreSQL! </font><font style="vertical-align: inherit;">This year we were spun on a separate track, they bring their Western speakers, in general, they </font></font><a href="http://www.highload.ru/2016/abstracts"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">are coming off in full</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br></font>  <font color="gray">Also, some of these materials are used by us in an online training course on the development of high-load systems <a href="http://highload.guide/%3Futm_source%3Dhabr%26utm_medium%3Dmedia%26utm_campaign%3Dpast.articles%26utm_content%3Dcommon">HighLoad.Guide</a> is a chain of specially selected letters, articles, materials, videos.</font>  <font color="gray">Already, in our textbook more than 30 unique materials.</font>  <font color="gray">Get connected!</font> <br></blockquote></div><p>Source: <a href="https://habr.com/ru/post/312494/">https://habr.com/ru/post/312494/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../312476/index.html">How Asana makes it easier to work with the team, documents and brings more profit</a></li>
<li><a href="../312482/index.html">Hackathon according to criminal statistics</a></li>
<li><a href="../312484/index.html">How to love mbed, and then screw it up twice</a></li>
<li><a href="../312490/index.html">How to assemble bigrams for a body of any size on a home computer</a></li>
<li><a href="../312492/index.html">OpenShift v3. Part II. Continue dating. ROR4</a></li>
<li><a href="../312496/index.html">How we built our mini data center. Part 2 - Hermoson</a></li>
<li><a href="../312498/index.html">A few words about moving to Cyprus</a></li>
<li><a href="../312500/index.html">Do not step on our rake with TK: an epic contest experience and a couple of tales</a></li>
<li><a href="../312504/index.html">Web Alerts in Loaded Projects</a></li>
<li><a href="../312506/index.html">.NET Portability Analyzer</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>