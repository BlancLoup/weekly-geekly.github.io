<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÄúActive Search‚Äù: how we chose the search engine for the DLP system</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="During the course of work, the DLP system intercepts huge amounts of information every day - these are letters from employees, information about users...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>‚ÄúActive Search‚Äù: how we chose the search engine for the DLP system</h1><div class="post__text post__text-html js-mediator-article">  During the course of work, the DLP system intercepts huge amounts of information every day - these are letters from employees, information about users' actions on workstations, information about file resources stored in an organization's network, and alerts about unauthorized data output outside the organization.  But this information will be useful only if a high-quality search engine is implemented in the DLP across the entire array of intercepted communications.  Since the first version of our DLP solution was released in 2000, we have changed the search mechanism in the archive several times.  Today we want to talk about what technologies we used, what advantages and disadvantages we saw in them, and why we ultimately refused them.  Perhaps someone our experience will be useful. <br><img src="https://habrastorage.org/webt/59/ef/5d/59ef5d020da94739058054.jpeg"><br><a name="habracut"></a><br>  In the most general terms, our requirements for the search engine are as follows: it should be convenient and allow the user to quickly navigate through the entire array of information collected, namely: <br><br><ul><li>  To conduct investigations without losing even the smallest details. </li><li>  Quickly search for information of interest on a variety of parameters. </li><li>  Have the ability to account for the morphology of the Russian language. </li></ul><br><h3>  Beginning of the path and basic needs: Oracle ConText, Tsearch2 and Russian context optimizer <br></h3><br>  In the first steps of the development of the product, when we controlled only corporate mail, the Oracle DBMS was used to store the intercepted data.  The search was quite simple, and it was implemented on a standard Oracle ConText (later - Oracle Text), which was supplied as part of the Oracle Database.  We have used this solution for many years, because  at that time, it fully met our needs. <br><br>  The user could set a search query for a set of attributes of the intercepted data (letter and part sizes, file names, data types, values ‚Äã‚Äãof arbitrary mail and mime headers and their parameters, number of attachments) and search the text of letters even despite the lack of Oracle ConText in Russian morphology.  The issue of such requests was quite qualitative, but this mechanism had critical shortcomings for us - the low speed of the search queries and the absence of Russian morphology. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Later, with the strengthening of PostgreSQL‚Äôs market position, we began using it as an alternative to Oracle.  Together with PostgreSQL, we obtained the Tsearch2 full-text search module, which already supported Russian morphology and finally allowed us to implement full-text search through captured letters using word forms.  This significantly reduced the time that the security officer had to spend on working with the system.  It was no longer necessary to perform many queries, independently sorting out possible word forms.  In addition, Tsearch worked faster on small data volumes than Oracle ConText, and for some customers it was a more convenient option. <br><br>  But there were serious drawbacks: <br><br><ul><li>  No search for phrases. </li><li>  The speed of execution of search queries, although it was higher than that of Oracle ConText, still left much to be desired. </li></ul><br>  In anticipation of new solutions, we did our own research and constantly analyzed the search mechanisms appearing on the market.  At some point, we found an alternative to Oracle Text - the product of the Russian context optimizer, which allowed us to build a context index based on Russian morphology.  It was a bit slower, but now we could implement a search using various word forms, including the data base managed by Oracle. <br><br><h3>  Work speed is critical: Sphinx <br></h3><br>  As time went on, we mastered the interception of new communication channels, began to monitor the actions of users at workstations and monitor the rules for storing documents in the local network.  A large number of different types of data appeared, storage volumes increased, due to which the old search mechanisms began to work slowly and inefficiently. <br><br>  Standard means of DBMS could no longer increase the speed, and the question arose of creating an external index.  After a series of studies, the Sphinx search engine (the SQL Phrase Index) was chosen for this purpose.  It could be used for databases running both Oracle and PostgreSQL. <br><br>  With Sphinx, we performed a full-text search.  To optimize the search and the ability to create complex queries, we first searched using an external index ‚Äî we performed a full-text search by word forms, and then we found a search by the attributes of the letters in the database.  Thanks to Sphinx, the speed of execution of a number of queries was significantly increased - from tens of minutes (up to hours) to several minutes.  But it required major improvements from our side. <br><br>  In addition, we have seen a number of drawbacks with Sphinx: <br><br><ul><li>  One index could only be updated in one thread.  Accordingly, it was impossible to build an index in parallel from several processes, and the index simply did not have time for new data.  To solve this problem, we had to add functionality that allows us to scale the search, taking into account the parallel construction of the index on several machines. </li><li>  Support only Russian and most popular European languages.  For us, this drawback was not a problem, but if you have plans to work in the international market, keep in mind that the languages ‚Äã‚Äãsupported by the built-in and provided plug-ins will not be enough for you. </li><li>  Lack of opportunities for analytics - building aggregates, statistics, tops, graphs.  We had to create all these analytical functions independently using a DBMS, and not an external index. </li><li>  The focus of Sphinx on the indexation of web-resources, and not the archives of messages.  ‚ÄúThis is not a bug, this is a feature,‚Äù but it was extremely difficult for us to accept this feature, since for a DLP system this is a completely alien functionality. </li></ul><br>  We continued to monitor the market for interesting search mechanisms and, among other things, we tested the SOLR search engine on the DLP file storage.  In short, compared with Sphinx, SOLR did not demonstrate any advantages, and we stayed on Sphinx. <br><br><h3>  Not only fast, but also smart: Elastic Search <br></h3><br>  At some point, Elastic Search drew our attention.  He initially possessed many features that we had to implement in Sphinx independently.  In particular, Elastic Search supported distributed architecture.  He allowed us to perform a really fast search - not in minutes, but in seconds - by creating an index of the most frequently used data.  The load tests we conducted showed that the search speed using Elastic Search for 17 million messages is less than a second.  At the same time, the user could still make requests for headers and structural information, and this is also implemented by means of the database. <br><br>  In general, the transition to Elastic Search allowed not only to ‚Äúoverclock‚Äù the search, but also to unload the development, which no longer had to refine it, in order to provide users with the necessary tools.  At the same time, Elastic Search is not only a search mechanism and storage, but also various analytical tools, such as visualization, log collector, etc. <br><br>  We believe that a very important direction of DLP development over which we must actively work is the automation of user activity, i.e.  security person.  And one of the necessary conditions for automation is the availability of ready-to-use data slices for decision-making, which allow you not to manually make standard queries each time, but to immediately receive information from a pre-configured dashboard. <br><br>  Only by means of Elastic Search, we created a desktop for the manager and administrator with a variety of dashboards, which present the most interesting data from the point of view of information security.  This is a decrease <a href="https://habrahabr.ru/company/solarsecurity/blog/316980/">in the</a> person‚Äôs ‚Äú <a href="https://habrahabr.ru/company/solarsecurity/blog/316980/">trust level</a> ‚Äù, statistics on the most frequently sent files, and uncharacteristic employee contacts regarding his environment.  The entire event and incident zone is also implemented on the Elastic Search tools.  Here's what it looks like: <br><br><img src="https://habrastorage.org/webt/59/ef/6c/59ef6c9d625f7645415390.jpeg"><br>  <i>Executive desk</i> <br><br><img src="https://habrastorage.org/webt/59/ef/6c/59ef6c9e83d0c240742368.png"><br>  <i>Analyst Desktop</i> <br><br><img src="https://habrastorage.org/webt/59/ef/6c/59ef6c9de3459921269482.jpeg"><br>  <i>Heat map communications</i> <br><br><img src="https://habrastorage.org/webt/59/ef/6c/59ef6c9eb76a6191988876.png"><br>  <i>Changing the level of trust in the employee's "file"</i> <br><br>  In general, as our experience has shown, for solving DLP Elastic Search tasks next to its predecessor Sphinx is a concept car next to the Lada Kalina.  But, of course, with the proviso that the search is applied to the huge DLP archives for such a specific and complex task as the investigation of information security incidents.  If you, as a developer, do not have such tasks, then Sphinx may be a perfectly acceptable option. <br><br><h3>  Future plans <br></h3><br>  But, no matter how good Elastic Search is, we continue to conduct various studies to improve its search engines.  Now we are engaged in the optimization of existing tools Elastic Search and conduct research on the use of neural networks as a search tool.  So who knows - maybe someday we will continue this article with a chapter on artificial intelligence ... </div><p>Source: <a href="https://habr.com/ru/post/340874/">https://habr.com/ru/post/340874/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../340862/index.html">Linux Piter # 3: what about this time?</a></li>
<li><a href="../340866/index.html">Google Forms: we fix event of sending the form in Google Analytics</a></li>
<li><a href="../340868/index.html">Design for iPhone X. Guidelines for iOS 11</a></li>
<li><a href="../340870/index.html">Tale of sysctl (penguin folk story)</a></li>
<li><a href="../340872/index.html">Cloud Digest: about technologies, SSL certificates and IaaS provider operation</a></li>
<li><a href="../340876/index.html">Check whether the service pack is present on the system before installation</a></li>
<li><a href="../340878/index.html">Exantech Code Jam: Hacktoberfest 2017</a></li>
<li><a href="../340880/index.html">Bad Rabbit: a new wave of attacks using a ciphering virus</a></li>
<li><a href="../340882/index.html">Telemetry and software</a></li>
<li><a href="../340884/index.html">There is no time to explain! or how to make friends terraform with minikube and kubernetes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>