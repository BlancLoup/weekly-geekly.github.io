<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A simple speech recognition algorithm based on a short dictionary based on the MFCC</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Greetings to all readers of habrahabr! 

 Recently there has been a significant increase in interest in speech recognition technology. There are sever...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A simple speech recognition algorithm based on a short dictionary based on the MFCC</h1><div class="post__text post__text-html js-mediator-article">  Greetings to all readers of habrahabr! <br><br>  Recently there has been a significant increase in interest in speech recognition technology.  There are several reasons for this growth, in particular, a significant increase in computational capabilities and training material.  On Habrahar user <a href="http://habrahabr.ru/users/domage/" class="user_link">domage</a> was published a whole series of articles on the basics of speech recognition technology.  Also worth noting is the article <a href="">Mel-cepstral coefficients (MFCC) and speech recognition</a> and the work done on its basis for identifying a person by voice: <a href="http://habrahabr.ru/post/144491/">Who is it?</a>  <a href="http://habrahabr.ru/post/144491/">- Identification of a person by voice</a> . <br>  This paper proposes a simple algorithm (and its implementation in C ++) of a speech recognition system using a short vocabulary based on an analysis of the statistical distribution of chalk-cepstral coefficients ( <a href="http://en.wikipedia.org/wiki/Mel-frequency_cepstrum">Mel-frequency cepstrum coefficients</a> , MFCC). <br><a name="habracut"></a><br><br><h4>  Formulation of the problem </h4><br>  There are many methods of speech recognition, in most cases they are based on the methods of statistical analysis and probability theory (Hidden Markov Model, Gaussian Mixture Model, etc.).  As you know, google provides a free service for recognizing short voice messages.  On the basis of this service, speech recognition using a microcontroller was even suggested: <a href="">Speech recognition on STM32F4-Discovery</a> .  However, the question arises: is there an opportunity to make your speech recognition system, even if it is in a rather limited dictionary, without using ‚Äúexternal‚Äù services, while at the same time working quickly and with acceptable quality? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  main idea </h4><br>  So, for speech recognition we will use MFCC.  In order not to go into details, I‚Äôll say that it is worth treating them only as some kind of filter whose input is a phonogram, and the output is a set of vectors (coefficients), which we will recognize as some word or set of words.  In fairness, it is worth noting that there are many other acoustic features used for speech recognition: Perceptual linear predictive (PLP), Linear prediction cepstral coefficient (LPCC), Linear frequency cepstral coefficients (LFCC). <br>  The basic idea is to use <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis">linear discriminant analysis</a> to identify a word.  However, it is applicable only for vectors of the same dimension.  Because  words can be of different lengths, the question arises: how to transform a sequence of an arbitrary number of MFCC vectors into a vector of fixed dimension? <br>  One can proceed as follows: find the places of "thickening" of the distribution of these vectors and take the concatenation of vectors, which are the centers of "thickening", as the resulting vector.  Such a concatenated vector will be called the super vector of averages, and the centers themselves will be called averages.  At the same time, we will use the super vector of averages obtained on all MFCC vectors of the entire training base as a ‚Äústarting point‚Äù.  Thus transforming the sequence of MFCC vectors into one super vector of mediums of a fixed dimension, we can apply various classification methods. <br>  The principal disadvantage of this approach is obvious: the dynamics of the distribution of MFCC signs over time is not taken into account, therefore, the system is not a priori capable of distinguishing, for example, the words ‚Äúhead fish‚Äù and ‚Äúabyrwalg‚Äù, because  the overall distribution of the MFCC vectors of such words will be approximately the same (respectively, the centers of "condensations" will coincide). <br><br><h4>  Algorithm Description </h4><br>  As a learning base, we will use a multitude of files, each of which is a set of MFCC vectors obtained from a phonogram with a recording of one or another word.  In this case, files with the record of the same word should be combined into one group. <br>  Here is the distribution of the first two components of the MFCC vectors of the entire training base: <br><img src="https://habrastorage.org/storage2/334/aa2/6c9/334aa26c9d22564d45996252407d4f05.jpg"><br><br>  The algorithm consists of the following steps: <br><ol><li>  We find the super vector of averages for the entire training base using the <a href="http://ru.wikipedia.org/wiki/K-means">K-</a> means algorithm. <br>  An example of the operation of the K-means algorithm for K = 10 is shown in the figure: <br><img src="https://habrastorage.org/storage2/001/49d/797/00149d797fee849a33ebe236a0a834ed.jpg"><br>  where the big red squares are the desired mean values. <br><br></li><li>  For each base file, we find our own average values ‚Äã‚Äãusing the formula: <br>  Mk = a * Mk0 + (1 - a) * Mk ', k = 1: K <br>  where Mk0 is the average value found in claim 1, <br>  Mk 'is the average value obtained as a result of applying one iteration of the K-means algorithm for the MFCC vectors of a file using Mk0 as the initial value, <br>  a = R / (R + Nk), where R is the ‚Äúsensitivity‚Äù coefficient, Nk is the number of MFCC vectors corresponding to the mean value Mk '. <br>  The average values ‚Äã‚Äãfound in this way will be called the accepted average values. <br>  An example of adapted mean values ‚Äã‚Äãfor a file is shown in the figure: <br><img src="https://habrastorage.org/storage2/7d0/1e7/e5d/7d01e7e5dae467b8c5c4c8aac4dc008e.jpg"><br><br></li><li>  Having now, instead of the original phonograms, the adapted super vector of the averages, we <abbr title="Linear Discriminant Analysis">carry</abbr> out <abbr title="Linear Discriminant Analysis">LDA</abbr> for N classes (each class corresponds to one word). <br>  As a result, we must obtain a matrix consisting of vectors of a new basis, when projected onto which the initial adapted super vector of averages should be divided sufficiently well.  Example for N = 4: <br><img src="https://habrastorage.org/storage2/624/fb1/ed6/624fb1ed6b3c7101b92f9ea5da24a970.jpg"><br><br></li><li>  We project all the adapted super vector of averages onto a new basis and find the mean values ‚Äã‚Äãand the standard deviation (standard deviation) of the projections for each class. <br></li><li>  To determine whether a test track belongs to a particular class (i.e., recognition), we perform paragraphs for it.  2 and 4, then we find the distances of the obtained projection to the average values ‚Äã‚Äãof all classes (we can additionally normalize them to the corresponding standard deviation).  The minimum distance and will correspond to the class to which the test phonogram belongs. <br></li></ol><br><br><h4>  Implementation </h4><br>  A complete implementation of the described algorithm, along with the source codes and the base for testing, can be found <a href="https://www.dropbox.com/sh/gi0wimk8hs6mc13/F-90y7AYLn">here</a> . <br>  Creating your own word recognition system consists of the following steps: <br><ol><li>  Recording of phonograms for training and testing <br>  For recording, you can use any program that can record sound and save it in WAVE format.  I recommend using the free <a href="http://audacity.sourceforge.net/%3Flang%3Dru">Audacity</a> program. <br>  The developed system is not able to allocate speech segments, so when recording you need to try, so that only the speech is present in the phonogram.  The better the microphone is used, the better the system is obtained.  It is necessary to record in mono mode with a sampling frequency of 16000. <br></li><li>  Construction of MFCC vectors <br>  To build MFCC vectors, you can use the free library <a href="https://gforge.inria.fr/projects/spro/">SPro 5.0</a> .  I took responsibility, went through this library a bit, corrected a couple of errors, and built the sfbcep.exe program under windows (see the ../spro-5.0 folder).  The 32-bit version of this program is in the ../tools folder.  To build MFCC vectors, I used the following parameters: <br><pre><code class="bash hljs">sfbcep.exe --format=wave --sample-rate=16000 --mel --freq-min=0 --freq-max=8000 --fft-length=256 --length=16.0 --<span class="hljs-built_in"><span class="hljs-built_in">shift</span></span>=10.0 --num-ceps=13 [ WAVE-] [   MFCC-]</code> </pre> <br></li><li>  Training and testing system <br>  For learning and testing the system, I wrote the wrsystem program in C ++.  The full source code is in the ../wrsystem folder.  The 32-bit version of this program can be found in the ../tools folder. <br>  The implementation of the <abbr title="Linear Discriminant Analysis">LDA</abbr> algorithm was borrowed from the <a href="http://www.alglib.net/">ALGLIB</a> library. <br>  The wrsystem program has two modes of operation: training (in the case of the presence of the --learn parameter) and testing.  This program takes three basic parameters as input: <br>  - Path to the file with the description of the base of learning (testing) (parameter --base).  An example of a file with a description of the database is in the ../base folder, and a description of the format can be viewed by running the program with the parameter --help. <br>  - Path to the binary file that stores the result of the system learning (parameter --system).  In training mode, this file is created; in test mode, it is read. <br>  - Path to the file to which the system test results are recorded on the specified base: entanglement matrix and Word Error Rate value (parameter - test_results). <br></li></ol><br><br><h4>  Experimental results </h4><br>  As an experiment, I created a system that can recognize the 14 words recorded in my voice.  For learning the system, I recorded each word 4-5 times, and for testing - 7 times.  The total training base contains 63 files, and the testing base contains 98. The following parameters were used when training: <br><ul><li>  Number of average values: 10 <br></li><li>  The coefficient of "sensitivity" in the adaptation: 20 <br></li><li>  Projection dimension: 20 <br></li><li>  Use of normalization on standard deviation: none <br></li></ul><br>  The test result on the basis of training showed the level of word recognition error (WER) 1.6%, and on the basis of testing 5.1%. <br><br><h4>  What you should pay attention to </h4><br>  I would like to make a few comments.  First, in order for any system (including the one described here) to qualitatively recognize the speech of any person, it is necessary to have a huge training base with recording all the words spoken by different people in different emotional states using different recording devices (telephone, microphone, eavesdropping). device, etc.).  Those.  the system that you teach, using only your voice and only your home headset, probably will not work for your friends and even for you if you use any other microphone.  Secondly, the described system has a very limited potential due to its triviality.  Despite the fact that it works, this approach was proposed only as an experiment and is not suitable for industrial use without any modifications. <br><br>  That's all, thank you for your attention! </div><p>Source: <a href="https://habr.com/ru/post/150251/">https://habr.com/ru/post/150251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../150245/index.html">Fall Angry Birds</a></li>
<li><a href="../150247/index.html">In-location Alliance</a></li>
<li><a href="../150248/index.html">Dirtiest job at google</a></li>
<li><a href="../150249/index.html">Installing a screw 3.5 "inside the body of a chipboxed Xbox 360</a></li>
<li><a href="../150250/index.html">Why Apple is going to court</a></li>
<li><a href="../150252/index.html">Who we are and what we do here</a></li>
<li><a href="../150255/index.html">Operating system Tizen - Bada repeating path</a></li>
<li><a href="../150256/index.html">Standalone IP Camera</a></li>
<li><a href="../150257/index.html">Breadboard - electronic designer for all</a></li>
<li><a href="../150259/index.html">Good job, Apple, you fooled the whole world</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>