<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We track Millenium Falcon with TensorFlow</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At the time of this writing, most major technology companies (such as IBM, Google, Microsoft, and Amazon) offer easy-to-use visual recognition APIs. S...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We track Millenium Falcon with TensorFlow</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/l1/2c/7b/l12c7bo_adfwi1v0tpyu9dqwxto.png"><br><br>  At the time of this writing, most major technology companies (such as IBM, Google, Microsoft, and Amazon) offer easy-to-use visual recognition APIs.  Similar tools are offered by smaller companies, for example, Clarifai.  But none of them offers a means to detect objects (object detection). <a name="habracut"></a><br><br><img src="https://habrastorage.org/getpro/habr/post_images/016/14e/6ba/01614e6ba1d596f97abeee5c1573f0e8.gif" alt="image">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Both pictures show examples of tagging using the standard <a href="https://www.ibm.com/watson/services/visual-recognition/">Watson Visual Recognition</a> classifier.  Only the first picture was first passed through the object detection model. <br><br><img src="https://habrastorage.org/webt/nt/cp/b_/ntcpb_w846yrouedr6ti6kbet5o.png"><br><br>  Object detection can greatly outperform ‚Äúsimple‚Äù visual recognition.  But if you want to implement object detection, you have to work hard. <br><br>  Depending on the situation, you may not need a custom object detection model.  The corresponding <a href="https://www.tensorflow.org/">TensorFlow</a> API provides several models with different performance and accuracy based on <a href="http://cocodataset.org/">COCO</a> dataset. <br><br>  For your convenience, I have compiled a complete list of objects that COCO models can detect: <br><br><img src="https://habrastorage.org/webt/wa/n0/yy/wan0yyttj6hkws0a8ikmyw20due.png"><br><br>  If you want to detect logos or something else that is not included in the list, you will have to write your own custom detector.  I wanted the machine to detect the Han Solo ship Millennium Falcon and the imperial fighter Tie Fighter.  Obviously, this is a very important task, because you never know when it will be useful in life ... <br><br><h3>  <font color="#cc0000">Image annotation</font> </h3><br>  Model training is a time consuming task.  Probably, you just thought: ‚ÄúHey, I don‚Äôt want to lay down my bones here!‚Äù.  If so, you can read <a href="https://medium.com/unsupervised-coding/dont-miss-your-target-object-detection-with-tensorflow-and-watson-488e24226ef3">my article</a> on the use of the finished model.  This way is much easier. <br><br>  You will need to collect a lot of images and provide them with annotations.  They include the definition of the coordinates of the object and the corresponding designation.  For a picture with two Tie Fighter annotations might look like this: <br><br><pre><code class="hljs xml"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">annotation</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">folder</span></span></span><span class="hljs-tag">&gt;</span></span>images<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">folder</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">filename</span></span></span><span class="hljs-tag">&gt;</span></span>image1.jpg<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">filename</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">size</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">width</span></span></span><span class="hljs-tag">&gt;</span></span>1000<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">width</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">height</span></span></span><span class="hljs-tag">&gt;</span></span>563<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">height</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">size</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">segmented</span></span></span><span class="hljs-tag">&gt;</span></span>0<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">segmented</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">object</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>Tie Fighter<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">bndbox</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmin</span></span></span><span class="hljs-tag">&gt;</span></span>112<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmin</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymin</span></span></span><span class="hljs-tag">&gt;</span></span>281<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymin</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmax</span></span></span><span class="hljs-tag">&gt;</span></span>122<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmax</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymax</span></span></span><span class="hljs-tag">&gt;</span></span>291<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymax</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">bndbox</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">object</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">object</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span>Tie Fighter<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">name</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">bndbox</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmin</span></span></span><span class="hljs-tag">&gt;</span></span>87<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmin</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymin</span></span></span><span class="hljs-tag">&gt;</span></span>260<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymin</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmax</span></span></span><span class="hljs-tag">&gt;</span></span>95<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">xmax</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymax</span></span></span><span class="hljs-tag">&gt;</span></span>268<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">ymax</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">bndbox</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">object</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">annotation</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br>  For my model, which will work with Star Wars, I collected 308 images, each with 2-3 objects.  I recommend collecting at least 200-300 examples of each object. <br><br>  ‚ÄúWow,‚Äù you thought, ‚Äúhave to shovel hundreds of images and write a bunch of XML for everyone?‚Äù <br><br>  Of course not!  There are quite a few annotation tools, such as <a href="https://github.com/tzutalin/labelImg">labelImg</a> or <a href="https://rectlabel.com/">RectLabel</a> .  I used <a href="https://medium.com/%40rectlabel">RectLabel</a> , but it is only for macOS.  Although the tool will have to sweat, believe me.  It took me 3-4 hours of continuous work to annotate my entire dataset. <br><br>  If you have money, you can hire someone to do it.  Or use something like <a href="https://www.mturk.com/">Mechanical Turk</a> .  If you are a poor student, like me, and / or you like many hours of monotonous work, you can make annotations yourself. <br><br>  If you do not want to write a conversion script, then when writing annotations, make sure that they are exported in the PASCAL VOC format.  It is used by many, including me, so you can borrow the above script (I myself borrowed it from someone). <br><br>  Before running the script, you need to prepare the data for processing TensorFlow. <br><br><h3>  <font color="#cc0000">Repository cloning</font> </h3><br>  Clone <a href="https://github.com/bourdakos1/Custom-Object-Detection">my repository first</a> .  The directory structure should look like this: <br><br><pre> <code class="hljs ruby">models <span class="hljs-params"><span class="hljs-params">|-- annotations |</span></span> <span class="hljs-params"><span class="hljs-params">|-- label_map.pbtxt |</span></span> <span class="hljs-params"><span class="hljs-params">|-- trainval.txt |</span></span> <span class="hljs-string"><span class="hljs-string">`-- xmls | |-- 1.xml | |-- 2.xml | |-- 3.xml | `</span></span>-- ... <span class="hljs-params"><span class="hljs-params">|-- images |</span></span> <span class="hljs-params"><span class="hljs-params">|-- 1.jpg |</span></span> <span class="hljs-params"><span class="hljs-params">|-- 2.jpg |</span></span> <span class="hljs-params"><span class="hljs-params">|-- 3.jpg |</span></span> <span class="hljs-string"><span class="hljs-string">`-- ... |-- object_detection | `</span></span>-- ... <span class="hljs-string"><span class="hljs-string">`-- ...</span></span></code> </pre><br>  I included my training data there, so you can run everything out of the box.  But if you want to create a model with your data, you will have to add training images to images, XML annotations in annotations / xmls, and also have to update the trainval.txt and label_map.pbtxt. <br><br>  trainval.txt is a list of files that allows you to find and correlate JPG and XML files.  The following is the contents of the trainval.txt list, allowing you to find abc.jpg, abc.xml, 123.jpg, 123.xml, xyz.jpg and xyz.xml: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">abc</span></span> <span class="hljs-number"><span class="hljs-number">123</span></span> xyz</code> </pre><br>  Note: make sure that except for the extensions, the names of the JPG and XML files are the same. <br><br>  label_map.pbtxt - the list of objects that we want to detect.  It should look something like this: <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">item</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">id</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span> name: <span class="hljs-string"><span class="hljs-string">'Millennium Falcon'</span></span> } <span class="hljs-selector-tag"><span class="hljs-selector-tag">item</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">id</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span> name: <span class="hljs-string"><span class="hljs-string">'Tie Fighter'</span></span> }</code> </pre><br>  <b>Running script</b> <br><br>  Install Python and pip, and then install the script requirements: <br><br><pre> <code class="hljs sql">pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> -r requirements.txt</code> </pre> <br>  Add <code>models</code> and <code>models/slim</code> to <code>PYTHONPATH</code> : <br><br><pre> <code class="hljs ruby">export PYTHONPATH=$PYTHONPATH<span class="hljs-symbol"><span class="hljs-symbol">:</span><span class="hljs-string"><span class="hljs-symbol"><span class="hljs-string">`pwd`</span></span></span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span><span class="hljs-string"><span class="hljs-symbol"><span class="hljs-string">`pwd`</span></span></span><span class="hljs-symbol">/slim</span></span></code> </pre> <br>  <b>Important</b> : this command must be executed every time the terminal is started.  Or add it to the <code>~/.bashrc</code> . <br><br>  Run the script: <br><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">python</span></span> object_detection/create_tf_record.py</code> </pre> <br>  When he is done, you will have the files train.record and val.record.  We will use them to train the model. <br><br><h3>  <font color="#cc0000">Download the base model</font> </h3><br>  Learning from scratch of an object detector can take days, even when using <a href="http://www.nvidia.com/object/what-is-gpu-computing.html">multiple video cards</a> .  To speed up the process, we will take a detector already trained in another dataset and use some of its parameters to initialize our new model. <br><br>  You can download the model <a href="">from here</a> .  Here, all models differ in accuracy and speed of work.  I used <code>faster_rcnn_resnet101_coco</code> . <br><br>  Extract and transfer all model.ckpt files to the root directory of your repository. <br><br>  You must have a file faster_rcnn_resnet101.config.  These are the settings for working with the <code>faster_rcnn_resnet101_coco</code> model.  If you have taken another model, you can find the corresponding configuration file <a href="https://github.com/bourdakos1/Custom-Object-Detection/tree/master/object_detection/samples/configs">here</a> . <br><br><h3>  <font color="#cc0000">Can be trained</font> </h3><br>  Run the script, after which the training should begin! <br><br><pre> <code class="hljs tex">python object_detection/train.py <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--logtostderr <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--train_dir=train <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--pipeline_config_path=faster_rcnn_resnet101.config</code> </pre> <br>  <b>Note:</b> replace the <code>pipeline_config_path</code> with the path to your configuration file. <br><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">4</span></span>: ...</code> </pre><br>  Hooray!  Works! <br><br>  10 minutes later. <br><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">41</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">42</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">43</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">44</span></span>: ...</code> </pre><br>  The computer starts to smoke. <br><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">71</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">72</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">73</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> step <span class="hljs-number"><span class="hljs-number">74</span></span>: ...</code> </pre><br>  How long will this go on? <br><br>  The model that I used in the head gif passed through approximately 22,000 cycles. <br><br>  What? <br><br>  I used MacBook Pro.  If you run this model on a similar machine, I assume that each cycle takes about 15 seconds.  At this rate, getting a decent model will take 3-4 days of continuous work. <br><br>  This is stupid, I do not have so much time <br><br>  <a href="https://developer.ibm.com/linuxonpower/deep-learning-powerai/">PowerAI</a> to the rescue! <br><br><h3>  <font color="#cc0000">PowerAI</font> </h3><br>  PowerAI allows you to train our model on IBM Power Systems with P100 graphics processors! <br><br>  It took me only an hour for 10,000 cycles.  And it was just one graphics processor.  The real power of PowerAI lies in its ability to perform distributed learning with hundreds of GPUs with 95 percent efficiency. <br><br>  Thanks to PowerAI, IBM recently set a new record for learning image recognition with an accuracy of 33.8% in 7 hours.  The previous record belonged to Microsoft - accuracy of 29.9% in 10 days. <br><br>  Sooo quick! <br><br>  Since I‚Äôm teaching not millions of images, I don‚Äôt really need such resources.  One processor is enough. <br><br><h3>  <font color="#cc0000">Nimbix Account Creation</font> </h3><br>  Nimbix provides developers with trial accounts with 10 hours of free work on the PowerAI platform.  You can register <a href="https://www.nimbix.net/cognitive-journey/">here</a> . <br><br>  Note: Registration is not automatic, so approval may take up to 24 hours. <br><br>  After the registration is approved, you will receive an email with instructions on how to confirm and create an account.  You will be asked for a promotional code, leave the field blank. <br><br>  Now you can login <a href="https://mc.jarvice.com/">here</a> . <br><br><h3>  <font color="#cc0000">Deploy PowerAI Notebooks Application</font> </h3><br>  Search for PowerAI Notebooks. <br><br><img src="https://habrastorage.org/webt/yo/y6/ax/yoy6axo9uas1ovyaaxychpd4zb8.png"><br><br>  Click on the result and select TensorFlow. <br><br><img src="https://habrastorage.org/webt/le/zx/tu/lezxtuszwxwhres9unqxwbjjzxa.png"><br><br>  Select the type of machine 32 thread POWER8, 128GB RAM, 1x P100 GPU w / NVLink (np8g1). <br><br><img src="https://habrastorage.org/webt/5v/hb/kk/5vhbkkrzxcwf4nfgbdkuibva3ca.png"><br><br>  A panel appears, as in the image below.  When the status of the server becomes Processing, you can access it. <br><br>  Get the password by clicking on (click to show). <br><br>  Then to start Notebooks, click Click here to connect. <br><br><img src="https://habrastorage.org/webt/xm/1d/uf/xm1duf0uxgm5oxvfnsc0coen_lg.png"><br><br>  Login with the nimbix name and the password you received. <br><br><img src="https://habrastorage.org/webt/co/8n/9e/co8n9eoccp68jsgyqul6lmbwntg.png"><br><br><h3>  <font color="#cc0000">Getting started</font> </h3><br>  Click on the New drop down menu and select Terminal to open a new terminal window. <br><br><img src="https://habrastorage.org/webt/cb/fl/0a/cbfl0a7j1acvy_bdqijurydn6ic.png"><br><br>  You will be greeted by a familiar interface: <br><br><img src="https://habrastorage.org/webt/iu/s4/0r/ius40ravmkcq4qwpufhowftlv30.png"><br><br>  <b>Note: the</b> terminal may not work in Safari. <br><br>  The learning process runs the same way as on the local computer.  If you are using my training data, then just clone my repository using the command: <br><br>  git clone <a href="">github.com/bourdakos1/Custom-Object-Detection.git</a> <br><br>  Or clone your repository.  Then inside the root directory, run cd: <br><br><pre> <code class="hljs pgsql">cd Custom-<span class="hljs-keyword"><span class="hljs-keyword">Object</span></span>-Detection</code> </pre> <br>  Execute the code below, downloading the previously trained model faster_rcnn_resnet101_coco, which we have already downloaded earlier. <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">wget</span></span> http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz tar -xvf faster_rcnn_resnet101_coco_11_06_2017.tar.gz mv faster_rcnn_resnet101_coco_11_06_2017/<span class="hljs-regexp"><span class="hljs-regexp">model.ckpt.*</span></span></code> </pre> <br>  Then update PYTHONPATH again, since you have a new terminal: <br><br><pre> <code class="hljs ruby">export PYTHONPATH=$PYTHONPATH<span class="hljs-symbol"><span class="hljs-symbol">:</span><span class="hljs-string"><span class="hljs-symbol"><span class="hljs-string">`pwd`</span></span></span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span><span class="hljs-string"><span class="hljs-symbol"><span class="hljs-string">`pwd`</span></span></span><span class="hljs-symbol">/slim</span></span></code> </pre> <br>  Now you can run the command to start learning: <br><br><pre> <code class="hljs tex">python object_detection/train.py <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--logtostderr <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--train_dir=train <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--pipeline_config_path=faster_rcnn_resnet101.config</code> </pre><br><h3>  <font color="#cc0000">Downloading your model</font> </h3><br>  When will the model be ready?  Depends on your training data.  The more of them, the more cycles you need to drive.  I got a pretty smart model after about 4500 cycles.  And it reached its peak in about 20,000 cycles.  In general, I drove 200,000 cycles, but the model did not become better. <br><br>  I recommend downloading your model every 5000 cycles or so, and evaluating its work in order to understand whether you are moving in the right direction.  Click on the Jupyter logo in the upper left corner, then go through the file tree to Custom-Object-Detection / train. <br><br>  Download all model.ckpt files with the largest number in the title. <br><br>  ‚Ä¢ model.ckpt-STEP_NUMBER.data-00000-of-00001 <br>  ‚Ä¢ model.ckpt-STEP_NUMBER.index <br>  ‚Ä¢ model.ckpt-STEP_NUMBER.meta <br><br>  <b>Note:</b> you can download only one file at a time. <br><br><img src="https://habrastorage.org/webt/pq/at/5l/pqat5lyrb1ip1l1cozb8_cn_fuc.png"><br><br>  <b>Note:</b> after completing the training, click on the red button, otherwise the clock will go on indefinitely. <br><br><h3>  <font color="#cc0000">Export the resulting graph</font> </h3><br>  To use your model in code, you need to convert checkpoint files (model.ckpt-STEP_NUMBER. *) Into a fixed <a href="http://deepdive.stanford.edu/inference">inference graph</a> . <br><br>  Transfer the downloaded checkpoint files to the root folder of your repository. <br><br>  Then run this command: <br><br><pre> <code class="hljs tex">python object_detection/export_inference_graph.py <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--input_type image_tensor <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--pipeline_config_path faster_rcnn_resnet101.config <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--trained_checkpoint_prefix model.ckpt-STEP_NUMBER <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>--output_directory output_inference_graph</code> </pre><br>  Do not forget export <code>PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim</code> . <br><br>  A new <code>output_inference_graph</code> directory should appear with the file <code>frozen_inference_graph.pb</code> .  We need him. <br><br><h3>  <font color="#cc0000">Model testing</font> </h3><br>  Now run the command: <br><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">python</span></span> object_detection/object_detection_runner.py</code> </pre> <br>  It will apply your object detection model, located in output_inference_graph / frozen_inference_graph.pb, to all the images in the test_images directory and write the results to the output / test_images directory. <br><br><h3>  <font color="#cc0000">results</font> </h3><br>  This is what we get when we run through the model for all frames of the excerpt from "Star Wars: The Awakening of Power." <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/xW2hpkoaIiM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p>Source: <a href="https://habr.com/ru/post/345250/">https://habr.com/ru/post/345250/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../345238/index.html">10 of the most important English words of 2017 according to Merriam-Webster</a></li>
<li><a href="../345240/index.html">Servlet 4.0: We do more faster. Server push</a></li>
<li><a href="../345242/index.html">How a non-refundable cost error can ruin a game developer</a></li>
<li><a href="../345244/index.html">The backend of the World in Conflict game server is publicly available.</a></li>
<li><a href="../345246/index.html">Finding the 3rd item from the end of a linked list in Java</a></li>
<li><a href="../345252/index.html">Lectures Tehnotreka. Android Development (Fall 2017)</a></li>
<li><a href="../345254/index.html">What salaries for IT specialists are offered by My Circle employers, data for May-October 2017</a></li>
<li><a href="../345256/index.html">‚ÄúVirtual University‚Äù: What VR-projects are being developed at ITMO University</a></li>
<li><a href="../345258/index.html">Telecommunications operators of the Russian Federation. 2017. Some Analytics</a></li>
<li><a href="../345260/index.html">Year of the bear. How Fancy Bear Spent 2017 Year</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>