<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Structure from motion</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="If you look at the sequence of frames in which the camera moves, then the brain easily perceives the geometric structure of the content. However, in c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Structure from motion</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/5c1/8ce/2c1/5c18ce2c110e45d69715197ac0ccce03.png"><br>  If you look at the sequence of frames in which the camera moves, then the brain easily perceives the geometric structure of the content.  However, in computer vision this is not a trivial problem.  In this article I will try to describe a possible solution to this problem. <br><a name="habracut"></a><br>  Before reading this article, it will not hurt to carefully read the article <a href="https://habrahabr.ru/post/130300/">"Fundamentals of stereo vision"</a> . <br><br>  So, we are faced with the task of turning a sequence of two-dimensional images into a three-dimensional structure.  The task is not simple, and you need to simplify it. <br>  First, suppose that we only have two frames.  Let's designate them as A and B. <br>  Secondly, we will work with a finite set of points corresponding to each other on frames A and B. Denote the points on the image as <img src="https://habrastorage.org/files/339/966/3b6/3399663b658044479efe99c956d38b05.png">  .  Then the points on frames A and B will be <img src="https://habrastorage.org/files/0d2/fb8/eee/0d2fb8eeeb7f43a98bff60032a1495e4.png">  and <img src="https://habrastorage.org/files/da4/dde/afc/da4ddeafcf7041f5b3dc25af437c88d1.png">  .  Each pair of points corresponds to a point in three-dimensional space. <img src="https://habrastorage.org/files/da0/98c/7cf/da098c7cf1a54a0abc1ce6ac5ec60ab3.png">  . <br><br>  Now you need to decide how to search. <img src="https://habrastorage.org/files/0d2/fb8/eee/0d2fb8eeeb7f43a98bff60032a1495e4.png">  and <img src="https://habrastorage.org/files/da4/dde/afc/da4ddeafcf7041f5b3dc25af437c88d1.png">  .  To do this, on the first frame we will select points, with the greatest contrast - ‚Äúspecial‚Äù points (features).  For this you can use surf, <a href="https://habrahabr.ru/post/244541/">fast or something else</a> .  These points will be <img src="https://habrastorage.org/files/0d2/fb8/eee/0d2fb8eeeb7f43a98bff60032a1495e4.png">  .  Then it is necessary to find correspondences to these points on the second frame using the same surf or <a href="https://habrahabr.ru/post/201406/">optical</a> <a href="https://habrahabr.ru/post/169055/">flow</a> algorithm.  And this is the point <img src="https://habrastorage.org/files/da4/dde/afc/da4ddeafcf7041f5b3dc25af437c88d1.png">  . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      And now we come to the central question of this article: how from the points <img src="https://habrastorage.org/files/0d2/fb8/eee/0d2fb8eeeb7f43a98bff60032a1495e4.png">  and <img src="https://habrastorage.org/files/da4/dde/afc/da4ddeafcf7041f5b3dc25af437c88d1.png">  (point-correspondences, point correspondences) get the coordinates of the points and the position of the camera in space?  First you need to figure out how the point it falls on the image.  Need to build a mathematical model of the camera. <br><br><h3>  Projective Camera Model </h3><br>  Since you have probably already read the article "Fundamentals of stereo vision", this formula should be familiar: <br><img src="https://habrastorage.org/files/1a1/6c2/bb4/1a16c2bb4da448dbbf3546bedca24617.png">  . <br>  Or if you describe more fully: <br><img src="https://habrastorage.org/files/8e4/02d/303/8e402d3031264874bb84077a9f5aac93.png">  . <br>  Here X is a three-dimensional point in space. <br>  x is the coordinate of the point in the image in <a href="https://ru.wikipedia.org/wiki/%25D0%259E%25D0%25B4%25D0%25BD%25D0%25BE%25D1%2580%25D0%25BE%25D0%25B4%25D0%25BD%25D1%258B%25D0%25B5_%25D0%25BA%25D0%25BE%25D0%25BE%25D1%2580%25D0%25B4%25D0%25B8%25D0%25BD%25D0%25B0%25D1%2582%25D1%258B">uniform coordinates</a> , and <img src="https://habrastorage.org/files/3ea/2c2/f60/3ea2c2f608084aa394acc5c29be01dbe.png">  i.e. the translation to the usual coordinates of the image will be as follows: <img src="https://habrastorage.org/files/20a/509/762/20a509762c8c4369a02c9f7df9db87d0.png">  . <br>  The process of converting a point in space to image coordinates can be divided into two stages, implemented by two matrices in the formula: <br><ol><li>  [R | t] - R and t represent the position of the camera in space.  At this stage, the coordinates of the points are transferred to the local coordinates of the camera.  R is a 3x3 rotation matrix, t is a three-dimensional displacement vector - together they make up the transition matrix [R | t] (3x4 size), it determines the position of the camera in the frame.  [R | t] is the same as the view matrix in three-dimensional graphics (if you do not take into account that it is not 4x4 in size). <br><img src="https://habrastorage.org/files/6cc/21d/bcc/6cc21dbcc1734df9b7eedb71504c2920.png">  - this is a matrix of camera rotation, <img src="https://habrastorage.org/files/6d1/096/430/6d10964303f64dccaf7801741a0afd0e.png">  - three-dimensional coordinates of the location of the camera in space.  R and t are called external camera parameters. </li><li>  K is the matrix of the camera.  The local coordinates of the points are converted to homogeneous coordinates of the image.  f <sub>x</sub> , f <sub>y</sub> - the focal distance in pixels, c <sub>x</sub> , c <sub>y</sub> - the optical center of the camera (usually the coordinates of the center of the image).  These parameters are called internal camera parameters. </li></ol><br>  An important property of this model is that the points lying on one straight line in space will also lie on one straight line on the image. <br>  In fact, the described model can be very inaccurate.  In real cameras, lens distortions come into play, due to which straight lines become curves.  This distortion is called <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D0%25B8%25D1%2581%25D1%2582%25D0%25BE%25D1%2580%25D1%2581%25D0%25B8%25D1%258F">distortion</a> .  There are different models that correct these distortions.  <a href="https://github.com/uzh-rpg/rpg_vikit/tree/master/vikit_common/src">Here</a> are some of their implementations.  The parameters of this model are also included in the concept of internal camera parameters. <br>  Given the distortion of our formula is complicated: <br><img src="https://habrastorage.org/files/a4d/d84/731/a4dd847311ea4fac8395de1b4c6d7569.png">  , where D (X) is a function that takes homogeneous coordinates of image points and returns normal coordinates on the image.  We also need the inverse function later, InvD (ix). <br>  Internal camera parameters must be known in advance.  Clarification of these parameters is a separate topic, we will assume that they already exist. <br><br>  Distortion distortion does not depend on the depth of visible points, but only the coordinates in the image.  It means that you can ‚Äúfix‚Äù the image (getting straight lines where they should be) without knowing the external parameters of the camera and the coordinates of points in space.  Then you can use the camera model without the function D. <br><img src="https://habrastorage.org/files/4e1/49b/411/4e149b4115aa4023b20633c12e30c774.jpg"><br>  The image with distortion on the left and on the right is the ‚Äúcorrected‚Äù image from lens distortions.  It is seen that the lines were straight. <br><br><h3>  Normalization of points </h3><br>  We agreed that the internal parameters are known to us, the coordinates of points on the image are known, and therefore it remains to find [R | t] and X <sub>i</sub> (camera positions and points in space). <br>  Our formula is already a little complicated, we need to simplify it.  To begin, do this: <br><img src="https://habrastorage.org/files/f92/a6e/d4e/f92a6ed4e2cb4446aa6fe7cd452873bc.png"><br>  The expression remains fair.  We continue: <br><img src="https://habrastorage.org/files/523/c97/666/523c976666a849708f53734318d32aca.png"><br>  Denote <img src="https://habrastorage.org/files/eca/c92/f5f/ecac92f5f5f846d1b97c5d895fb7f415.png">  (and if without distortion, then <img src="https://habrastorage.org/files/ba3/407/647/ba3407647102427db6b0b37ced951c81.png">  ).  Since all parameters are known, nx <sub>i</sub> can be calculated in advance.  Recalling how the matrix K looks like, it can be understood that nx <sub>z</sub> = 1. This will help with further calculations.  As a result, the formula becomes simpler: <br><img src="https://habrastorage.org/files/00f/f7b/825/00ff7b825e9346f0843d2d22d9134544.png"><br><br>  nx <sub>i</sub> are the normalized points of the image. <br><br><h3>  Fundamental and Essential Matrices </h3><br>  So, suppose we have two images taken from the same camera.  We do not know the position of the cameras and the coordinates of points in space.  We agree to enter calculations regarding the first frame.  So it turns out that RA = I (I is the identity matrix), t <sup>A</sup> = (0, 0, 0).  The camera position in frame B is simply denoted as R and t (i.e., R <sup>B</sup> = R, t <sup>B</sup> = t).  [R | t] is the matrix of the coordinates of the second frame, and it is also the matrix of the displacement of the camera position from frame A to frame B. As a result, we get such a system (disregarding distortion!): <br><img src="https://habrastorage.org/files/551/c82/84b/551c8284b2504978961a3cda8dc4235c.png"><br>  Using the fundamental matrix F (fubdamental matrix), we obtain the following equation: <br><img src="https://habrastorage.org/files/15b/bd2/895/15bbd28958fe476cb7afe0e144dc7e6a.png"><br>  Also note that F has a size of 3x3 and must have a rank equal to 2. <br>  From the fundamental matrix F it is already possible to obtain the necessary R and t.  However, distortion spoils everything, with its account the dependence of points between frames will be non-linear, and this will no longer work. <br>  But we proceed to the normalized points and use the essential matrix E (essential matrix).  Everything will be almost the same, but simpler: <br><img src="https://habrastorage.org/files/7e9/8cb/9e6/7e98cb9e670f41439aaf87526b485f9b.png">  - The system of equations for the essential matrix; <br><img src="https://habrastorage.org/files/55e/1d8/758/55e1d8758df84f8da2df82d16dbd7f9f.png">  - the equation for her. <br>  And here we can safely take into account distortion. <br>  The fundamental and essence matrices are connected in this way: <br><img src="https://habrastorage.org/files/9c7/8f4/25e/9c78f425e4a249cfbe037d7ac28e9361.png"><br>  Now we are faced with the task of finding either the fundamental matrix F, or the essence matrix E, from which we can later get on R and t. <br><br><h3>  Essence matrix calculation (8-point algorithm) </h3><br>  Let's return to the equation: <br><img src="https://habrastorage.org/files/55e/1d8/758/55e1d8758df84f8da2df82d16dbd7f9f.png"><br>  The same formula can be rewritten in this form (we recall that <img src="https://habrastorage.org/files/300/ef0/ad2/300ef0ad22904f35a398839059fe9685.png">  and <img src="https://habrastorage.org/files/5d1/c21/fb7/5d1c21fb7eec4524a1781a37d8e1a01b.png">  ): <br><img src="https://habrastorage.org/files/184/7f2/e57/1847f2e5728247f1a96dd00af6283cce.gif">  , the parameter i is omitted here for the sake of convenience, but we mean that this is true for each point. <br>  We introduce the vector e and the matrix M: <br><img src="https://habrastorage.org/files/cc0/30b/8a3/cc030b8a32d1457793b1c3abd75804e4.png"><br><img src="https://habrastorage.org/files/503/02c/f81/50302cf81280475a8ec60f650f457c26.png"><br>  Then the whole system of equations can be represented as: <br><img src="https://habrastorage.org/files/72e/91c/ebc/72e91cebc4574904934837c7c8ba666e.png"><br>  We obtain a homogeneous system of equations, having solved which, we obtain E from e. The zero vector is the obvious solution, but we are clearly not interested in it.  At least 8 points are required for solving. <br><br><h3>  Solving systems of homogeneous equations using singular expansion </h3><br>  <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%25A1%25D0%25B8%25D0%25BD%25D0%25B3%25D1%2583%25D0%25BB%25D1%258F%25D1%2580%25D0%25BD%25D0%25BE%25D0%25B5_%25D1%2580%25D0%25B0%25D0%25B7%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">The singular decomposition</a> is a decomposition of the matrix, leading it to this form: <br><img src="https://habrastorage.org/files/471/778/cae/471778cae5184089ba0c4cec732e450d.png">  where U, V are orthogonal matrices, W is a diagonal matrix.  In this case, the diagonal elements of the matrix W are usually arranged in descending order.  Also the rank of the matrix W is the rank of the matrix M. And since W is a diagonal matrix, its rank is the number of nonzero diagonal elements. <br><br>  So, the following equation was given: <br><img src="https://habrastorage.org/files/72e/91c/ebc/72e91cebc4574904934837c7c8ba666e.png">  , where M is the known matrix, e is the vector that is not necessary to find. <br><img src="https://habrastorage.org/files/471/778/cae/471778cae5184089ba0c4cec732e450d.png"><br>  The rows V <sup>T</sup> , to which the zero diagonal element W on the same line corresponds, are the null-spaces of the matrix M, that is, in this case, are linearly independent solutions of our system.  And since the elements of W are arranged in descending order, then you need to look at the last element of the matrix W. And the solution will be the last line <img src="https://habrastorage.org/files/450/d96/00e/450d9600e5f74ccf8f351749112e9b77.png">  . <br>  When calculating an entity matrix using 8 points, the last element of the matrix W should be zero - W <sub>99</sub> = 0, but in practice, due to errors, there will be some non-zero value, and the magnitude of this value can be used to estimate the magnitude of this error.  In this case, we get the best solution. <br>  Nevertheless, the solution we found is not the only one; moreover, there will be infinitely many solutions.  If you multiply the solution found by a factor, it will still remain a solution.  Thus, the coefficient hid in the equation (which can be any): <br><img src="https://habrastorage.org/files/1b0/49f/510/1b049f510d3944a7a5a4a1700ddb9319.png">  . <br>  True, all these decisions will be linearly dependent, and only one of them will be of interest to us. <br>  Hence the matrix E can also be scaled.  But the calculations are carried out in a homogeneous space and, as a result, they do not depend on the scaling (i.e., on the coefficient s). <br>  It is probably worth scaling the resulting matrix E so that E <sub>33</sub> = 1. <br><br><h3>  Calculation of an essence matrix (7-point algorithm) </h3><br>  You can do with 7 points. <br>  If we take only 7 points, then M will be a 7x9 matrix. <br>  Let's return to the expression: <br><img src="https://habrastorage.org/files/471/778/cae/471778cae5184089ba0c4cec732e450d.png"><br>  W - will also be a 9x9 matrix, as before, but now not only W <sub>99</sub> will be equal to zero (well, again without taking into account calculation errors), but also W <sub>88</sub> .  This means that we have two linearly independent solutions of the equation <img src="https://habrastorage.org/files/72e/91c/ebc/72e91cebc4574904934837c7c8ba666e.png">  .  From them we obtain two matrices E <sub>1</sub> and E <sub>2</sub> .  The solution will be the expression <img src="https://habrastorage.org/files/7d7/0eb/7b1/7d70eb7b17a44b61a67a2e4379c420f3.png">  . <br>  Essential matrix, as well as the fundamental, must have a rank equal to two, and since it has a size of 3x3, then the determinant of the matrix is ‚Äã‚Äã0 - <img src="https://habrastorage.org/files/787/703/51f/78770351fd2240bcacb040a5d3e0d0d3.png">  .  Consequently <img src="https://habrastorage.org/files/507/972/de9/507972de925145a6b855b1b2278a94af.png">  .  If we paint this equation, we get a cubic equation that has 1 or 3 solutions <img src="https://habrastorage.org/files/b16/f78/148/b16f78148b5c4e648c7060e4f9d27b6a.png">  .  So we get one or three matrix E. <br>  I will not paint the solution of this equation (it is voluminous, well, consider this as homework).  In a pinch, you can just watch the implementation in <a href="">opencv</a> right away. <br><br><h3>  Refinement of the essential (fundamental) matrix </h3><br>  Since everything in this world is imperfect, we will constantly receive mistakes that we need to fight.  So the essential matrix must have a rank equal to 2 and therefore <img src="https://habrastorage.org/files/787/703/51f/78770351fd2240bcacb040a5d3e0d0d3.png">  .  In practice, however, this will not be the case. <br>  To see what this is expressed in, let's take the fundamental matrix.  Essential matrix / fundamental matrix - the only difference is in what points we work with (normalized or points on the image). <br>  A ray emitted from point A of frame A will fall into frame B as a straight line (or not entirely due to distortion, but forget about it).  Suppose matrix F is the fundamental matrix of frames A and B ( <img src="https://habrastorage.org/files/15b/bd2/895/15bbd28958fe476cb7afe0e144dc7e6a.png">  ). <br>  Then if you release the beam from the point <img src="https://habrastorage.org/files/9cf/8a2/6ae/9cf8a26ae2274b3eb83884b0ce9ab685.png">  , then we get a straight line l on the frame B - <img src="https://habrastorage.org/files/c35/3e7/b29/c353e7b290d641378228ce1c549d5dd2.png">  .  This straight line is called the epipolar line, i.e. <img src="https://habrastorage.org/files/d83/832/54f/d8383254fa204aa181e00154f5b811ee.png">  where ix, iy are the coordinates of a point in the image.  And the same condition for a point on an image with homogeneous coordinates - <img src="https://habrastorage.org/files/404/51e/d6c/40451ed6c73147f48c24e998aef1e1f5.png">  .  Point <img src="https://habrastorage.org/files/536/ea8/b02/536ea8b023064804a7108d0127b0f323.png">  will lie on this line, therefore <img src="https://habrastorage.org/files/9ed/3fa/8ba/9ed3fa8ba5ef4e91bfa0ff1cf91b8015.png">  .  Hence comes the general formula - <img src="https://habrastorage.org/files/15b/bd2/895/15bbd28958fe476cb7afe0e144dc7e6a.png">  . <br><img src="https://habrastorage.org/files/dc1/2a4/54b/dc12a454b44544099b391f813bf4a520.jpg"><br>  The picture shows an example of the epipolar lines obtained from the correct fundamental matrix (the rank of which is 2, the picture on the right) and the wrong one (on the left). <br>  To get the correct fundamental matrix, we use the singularity decomposition property ‚Äî to bring the matrix closer to a given rank: <br><img src="https://habrastorage.org/files/e1c/bb3/680/e1cbb368005e40378d03fc76973b718b.png">  .  Ideally, W <sub>33</sub> (the last element of the diagonal) should be zero.  We introduce a new matrix W ', which is equal to W, only in which the element W' <sub>33</sub> = 0. <br>  Then the corrected version: <img src="https://habrastorage.org/files/db0/6ae/c20/db06aec201a547cf9bceed6ad41d5a67.png">  . <br>  Exactly the same principle works for the essential matrix. <br><br><h3>  Normalized version of the algorithm </h3><br>  To reduce the error obtained in the calculations, the points transform to a specific view.  Matrices T <sup>A</sup> and T <sup>B</sup> are selected, which (each independently and on its own frame) shift the average coordinate of the points to the point (0, 0) and scale so that the average distance to the center is equal to <img src="https://habrastorage.org/files/a10/80c/9c7/a1080c9c7560449a8fe36977db4b5d69.gif">  : <br><img src="https://habrastorage.org/files/1ad/c0f/f35/1adc0ff3561f478e99b011aeb3aef62f.png"><br>  A matrix T <sup>A, B</sup> have the form: <img src="https://habrastorage.org/files/165/1bd/0ff/1651bd0ff60944c78d4024276172941f.png">  , where c is the average coordinate of the frame points, s is the scale factor. <br>  After that, we calculate the entity matrix as usual.  After it is necessary to clarify it, as described above.  Denote the resulting matrix as E <sup>t</sup> . <br>  Summary Entity Matrix - <img src="https://habrastorage.org/files/90f/6fd/601/90f6fd6018244fdc832e69cd115be783.png">  . <br>  Eventually: <img src="https://habrastorage.org/files/48a/9e9/cbe/48a9e9cbe3f841c9ae9464205fc3058a.png"><br>  Again, if you need to find a fundamental matrix, all principles are preserved. <br><br><h3>  Getting the camera position from the entity matrix </h3><br>  We introduce the matrix H: <img src="https://habrastorage.org/files/50f/6ff/1ba/50f6ff1ba3b946b994295b5db4be97b2.png"><br>  We use singular decomposition on the essential matrix: <img src="https://habrastorage.org/files/108/53a/ab3/10853aab3ae84d9fb69ee2716539bfc0.png"><br>  Then we get the following solutions: <br><img src="https://habrastorage.org/files/76b/577/170/76b57717001e40a0bd99765189c13967.png"><br><img src="https://habrastorage.org/files/99b/f8e/08c/99bf8e08ca6a45ec948379198be62ef6.png"><br><img src="https://habrastorage.org/files/747/a8c/73b/747a8c73b7db4e648f6f11d64ab92e6e.png"><br><img src="https://habrastorage.org/files/b83/931/9eb/b839319eba544d1dac2542769205dc23.png">  where <img src="https://habrastorage.org/files/ca2/946/4eb/ca29464ebad44019a69cf193b94bd93f.png">  , <img src="https://habrastorage.org/files/99a/c67/425/99ac674259c94e38a47f64d770b3e4bd.png">  - coordinates of the camera position. <br>  We also need the position of the camera in the local coordinates of the camera itself: <img src="https://habrastorage.org/files/26a/2df/e22/26a2dfe22dd2467c9f26a40ec85dba64.png">  . <br>  There are four solutions: <img src="https://habrastorage.org/files/9e9/bbd/8b4/9e9bbd8b436b41ab8d14f83ce971bce5.png">  . <br>  In the case of an 8-point algorithm, choose from 4 solutions.  In the case of the 7-point algorithm, there will be three essence matrices, from which 12 solutions will be obtained.  You need to choose only one, the one that will give less errors. <br><br><h3>  Degenerate cases </h3><br>  Let us return to the calculation of the essence matrix.  We had the equation: <br><img src="https://habrastorage.org/files/72e/91c/ebc/72e91cebc4574904934837c7c8ba666e.png"><br>  Then we solved it with the help of singular decomposition: <br><img src="https://habrastorage.org/files/471/778/cae/471778cae5184089ba0c4cec732e450d.png"><br>  Solutions of this equation depend on the rank of the matrix W, well, or on the number of zeros in the diagonal of this matrix (we remember that this reflects the rank of the matrix).  That's just taking into account the error, we consider zero in this case a number that is close enough to zero. <br>  We have such options: <br><ul><li>  No zeros.  No solutions, probably the error came out too big. </li><li>  One zero.  One solution, the case in which the number of points is greater than or equal to eight. </li><li>  Two zeros.  One or three solutions.  Used seven or more points. </li><li>  Three zeros.  Then the condition should be true <img src="https://habrastorage.org/files/d6b/885/e3b/d6b885e3b67e409e956aaeafe94b53e8.png">  .  This is possible if the camera did not move from frame to frame, there was only a turn, that is, t = (0, 0, 0).  Or all points lie on the same plane.  In the second case, it is still possible to find the coordinates of these points and the position of the camera, but in other ways. </li></ul><br><br><h3>  Calculation of coordinates of points in space </h3><br>  Suppose now we have more than two frames - A, B, C, ... <br><img src="https://habrastorage.org/files/2c6/3c0/4ed/2c63c04ed5fb4cdeb2f9271515a0c7c3.png">  - the position of the camera frames A, B, C, ... <br><img src="https://habrastorage.org/files/f7f/757/479/f7f7574795b34d60b7b6f16aa76f55b6.png">  - normalized points <br>  Need to find the point <img src="https://habrastorage.org/files/81d/5c0/549/81d5c05490534e44a9908d69f4f04d7a.png"><br><img src="https://habrastorage.org/files/69f/c16/76e/69fc1676ec834224a87ef258fc4f4d38.png"><br>  Imagine this system as: <br><img src="https://habrastorage.org/files/b9f/e05/3e9/b9fe053e9ef84c0783e1861ee8c03364.png"><br><img src="https://habrastorage.org/files/d16/89d/4e7/d1689d4e7895473f9e12120c6419267c.png"><br>  In matrix form: <br><img src="https://habrastorage.org/files/abb/741/1ea/abb7411ea73544038571aba0956da887.png"><br><img src="https://habrastorage.org/files/e37/a0c/9a7/e37a0c9a7b4b475aadeb612278e0c86d.png"><br>  Using singular decomposition we find the vector <img src="https://habrastorage.org/files/afa/7dd/99c/afa7dd99cb944c1cb3e69afb84f20d8b.png">  , which the <img src="https://habrastorage.org/files/ac6/2b4/82f/ac62b482f95844f3bd896d0c8c7b2836.png">  (as described above).  Then <img src="https://habrastorage.org/files/4fe/dfc/652/4fedfc652e454c0c8564ed3ef8d955d3.png">  where s is some unknown coefficient.  Coming out <img src="https://habrastorage.org/files/0c1/d1b/088/0c1d1b088f75459e9807da4c09e57a0e.png">  . <br><br><h3>  Evaluation function </h3><br>  Cost functions are necessary in order to obtain some results, to assess how reliable they are, or to compare them with others. <br>  Take our model: <br><img src="https://habrastorage.org/files/ce6/d10/0b5/ce6d100b5e634d49a2d57ffa45566037.png">  - the intended result. <br><img src="https://habrastorage.org/files/9cf/8cb/ce2/9cf8cbce2b0d4c3a9e149f61b4323eb9.png">  - the real value of the point. <br>  Hence, the square of the error for the i-th point will be: <img src="https://habrastorage.org/files/fb6/c42/691/fb6c426919164e4fab9966a243351caa.png">  . <br>  In practice, some points will give more reliable results than others.  And some in general will obviously give the wrong ones.  As a result, it becomes necessary to select from the general array of points only those points that can be trusted, and the rest simply be discarded from the calculations. <br>  The easiest way to select ‚Äúreliable‚Äù points is to select a certain limit (say, 5 pixels), and take only those points that give an error less than this limit ( <img src="https://habrastorage.org/files/97a/b97/680/97ab97680c2d41418716e1f24a84bb85.png">  ).  It should also be noted that it is necessary to take into account that the point must lie in front of the camera in both frames, otherwise it must clearly be discarded. <br>  Thus, you can enter the evaluation function - the number of reliable points.  And when comparing, choose the result that gives a greater number of ‚Äúreliable‚Äù points. <br>  And you can use another, more ‚Äúthin‚Äù function: <br><img src="https://habrastorage.org/files/9a5/f7c/876/9a5f7c8764e641958b3d8bb2c6863180.png">  where limit is our chosen limit (5 pixels). <br>  The best option is the one that will give less value.  It is clear that here you should remove the ‚Äúunreliable‚Äù points for future calculations. <br><br><h3>  RANSAC method </h3><br><ol><li>  When calculating the essence matrix, it is necessary to discard ‚Äúunreliable‚Äù points, as they result in significant errors in the calculations.  You can determine the set of suitable points using the RANSAC algorithm. <br>  Repeat the cycle a specified number of times (for example, 100, 400): <br><ul><li>  We randomly select the minimum set of points for calculations (we have 7); </li><li>  We calculate the essence matrices from this set (I recall, it can turn out to be either one matrix or three) </li><li>  The evaluation function calculates the reliability of each matrix </li></ul></li><li>  From the previous cycle, we select the essence matrix, which gives the best result; </li><li>  We choose points for calculations that give an error when the error matrix obtained is an error less than the specified threshold; </li><li>  From the obtained set of points, we calculate the final essence matrix. </li></ol><br><br><h3>  General algorithm </h3><br><ol><li>  Find the ‚Äúspecial‚Äù points on the first frame. </li><li>  We define the point of correspondence between the two images. </li><li>  We find the essential (or, nevertheless, fundamental) matrix corresponding to these two images using RANSAC. </li><li>  We will have one or three solutions, from which we obtain 4 or 12 possible matrices [R | t].  Having the position of the cameras in both frames, we calculate the coordinates of points in space for each possible matrix.  From them we choose the best one using the evaluation function. </li></ol><br><br><h3>  What's next? </h3><br>  Initially, we proceeded from the assumption that we had only two frames. <br>  To work with a sequence of frames, you just need to split the sequence into successive pairs of frames.  By processing pairs of frames, we get the shift of the camera from one frame to another.  From this you can get the position coordinates of the camera in the remaining frames. <br><br>  Having received the main thing - the position of the cameras, you can act in different ways: <br><ul><li>  By the points-correspondences to get the three-dimensional coordinates of the points in space, a cloud of points will be released, which can be turned into a three-dimensional model. </li><li>  Use the fundamental matrix to calculate the depth map. </li><li>  Using two frames to initialize the map for <a href="https://ru.wikipedia.org/wiki/SLAM_(%25D0%25BC%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4)">SLAM</a> using the calculated coordinates of points in space, it is possible to quickly and easily obtain the position coordinates in the following frames. </li><li>  well and another </li></ul><br>  In general, you can act differently, using different methods, including those algorithms that have been described - are not the only ones. <br><br><h3>  Literature </h3><br>  <a href="https://en.wikipedia.org/wiki/Fundamental_matrix_(computer_vision)">Fundamental matrix</a> , <a href="https://en.wikipedia.org/wiki/Essential_matrix">Essential matrix</a> , <a href="https://en.wikipedia.org/wiki/Eight-point_algorithm">Eight-point algorithm</a> - more information on Wikipedia <br>  Hartley, Zisserman - Multiple View Geometry in Computer Vision - sponsored by this article </div><p>Source: <a href="https://habr.com/ru/post/301522/">https://habr.com/ru/post/301522/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../301512/index.html">ASP.NET Core Today: Pros and Cons</a></li>
<li><a href="../301514/index.html">Yandex employees will represent Russia in the C ++ Standardization Committee</a></li>
<li><a href="../301516/index.html">My URL is not your URL</a></li>
<li><a href="../301518/index.html">Russian IT companies view Agile as a means to implement an ‚Äúemergency strategy‚Äù of development in the market.</a></li>
<li><a href="../301520/index.html">ITMO University Digest: # 3 Neural networks: interesting articles from ITMO University journals</a></li>
<li><a href="../301524/index.html">What does Apple Watch: a year later</a></li>
<li><a href="../301528/index.html">80 for 20 - how not to optimize processes</a></li>
<li><a href="../301532/index.html">It's time to say goodbye to Rails.</a></li>
<li><a href="../301534/index.html">Manual installation of Windows 7/8 / 8.1 / 10 in a system with GRUB2 bootloader</a></li>
<li><a href="../301536/index.html">FizzBuzz on TensorFlow</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>