<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Automation in the development of the platform "1C: Enterprise"</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article will discuss how we automate the development and testing processes of the 1C: Enterprise 8 technology platform. The 1C: Enterprise 8 plat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Automation in the development of the platform "1C: Enterprise"</h1><div class="post__text post__text-html js-mediator-article">  This article will discuss how we automate the development and testing processes of the 1C: Enterprise 8 technology platform.  The 1C: Enterprise 8 platform is a set of tools for creating business applications and their execution environment.  This is a large (more than ten million lines of code) project in C ++, Java and JavaScript.  Dozens of programmers are working on it, simultaneously developing and supporting up to 10 different versions of the product. <br><br>  The platform works on various OS and DB versions: <br><br><ul><li>  OS: Windows, Linux, macOS </li><li>  DBMS: MS SQL, PostgreSQL, IBM DB2, Oracle, self-developed file DBMS </li><li>  Mobile OS: Android, iOS, Windows </li></ul><br>  Supports several types of clients: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  <a href="http://v8.1c.ru/overview/Term_000000124.htm">Thin client</a> </li><li>  <a href="http://v8.1c.ru/overview/Term_000000123.htm">Fat client</a> </li><li>  <a href="http://v8.1c.ru/overview/Term_000000125.htm">Web Client</a> (Internet Explorer, Microsoft Edge, Chrome, Firefox, Safari) </li><li>  <a href="https://wonderland.v8.1c.ru/blog/mobilnyy-klient/">Mobile client</a> </li></ul><br>  Considering that it is necessary to support a number of versions of the above operating systems, DBMS and browsers, platform testing becomes a non-trivial task. <br><br><img src="https://habrastorage.org/webt/uc/za/am/uczaammpyos-2v7duolxymw1eti.png" alt="image"><br><a name="habracut"></a><br><h3>  Common automation tasks </h3><br>  The goals that we set for ourselves: <br><br><ul><li>  Automate and speed up routine development and testing tasks to the maximum </li><li>  Continuous testing with minimal test effort </li><li>  Add only high quality code to the product version </li><li>  Do not break old functionality </li><li>  Increase the number of significant defects in the released platform to zero </li><li>  Detect problems early in order to minimize the cost of investigation and correction. </li></ul><br><img src="https://habrastorage.org/webt/hy/qm/tv/hyqmtvaolcdwvapkwlvjfevrilg.png" alt="image"><br>  <b>Simultaneous development of multiple platform versions</b> <br><br>  We use the practice of Continuous Integration (CI);  The merging of working copies of the code into the general main branch occurs several times a day; after the merge, the automatic assembly and autotesting of the modified project is performed.  If there are problems during assembly or testing, the modified code is returned for revision. <br><br><img src="https://habrastorage.org/webt/xi/zh/sj/xizhsjmkaogncitmktqgctbpqq8.png" alt="image"><br>  <b>Development processes of one version of the platform</b> <br><br>  Tasks for CI: <br><br><ul><li>  Assembly <br><ul><li>  A series of assemblies of various types and subsequent testing of changeable versions as part of a continuous loop.  To speed up the investigation of isolated changes in test results, we use incremental compilation ‚Äî only what has changed and direct dependencies is compiled.  For a full cycle of testing, assemblies are assembled completely.  The necessity and sequence of additional assemblies is determined by the results of testing, the preliminary analysis of which is automated. </li><li>  Check "aside" significant changes (integration assembly).  If the engineer considers the changes significant, he first merges them into a separate branch, collects it and runs all the tests.  If all tests pass successfully, changes are made to the main branch. </li><li>  The fastest error detection, if possible in automatic mode </li><li>  Automation of routine actions (analysis of dumps, migration of changes between branches, error logging) </li></ul></li><li>  Multi Level Testing <br><ul><li>  Regression </li><li>  Unit tests </li><li>  Integration testing </li><li>  Load tests </li><li>  Visual tests </li><li>  Backward compatibility tests </li><li>  Scenario testing </li></ul></li><li>  Progressive <br><ul><li>  Basically functional </li></ul></li><li>  Acceptance Testing </li><li>  Testing progress and change <br><ul><li>  here we also assign manual testing </li></ul></li></ul><br>  Automatic assembly with us are several times a day.  A full cycle of automatic testing takes about a day, which for some tasks, unfortunately, is unacceptably long (balancing testing resources speeds up the process if there are free resources - if there are any at the moment).  To neutralize this negative effect, we develop a ‚Äúlightweight‚Äù version of the tests, which should be run in an hour and affect about 80% of the functionality.  Thus, a general understanding of how efficient a build is is that we can get much faster.  There may be occasions when an hour is not needed. <br>  Now, when testing, the results of previous testing cycles are taken into account, and problem / new / corrected tests are launched with a higher priority, which allows you to see the progress of changes on the most modified functionality immediately at the beginning of testing. <br><br>  For some type of builds, the rule ‚Äú10 failures‚Äù is adopted, when a series of tests is automatically interrupted when 10 failures are reached within one series, in order to free up resources for testing other builds / other versions, etc. <br><br>  About 70 physical servers and about 1500 virtual servers participate in our build and testing. <br><br><h3>  Instruments </h3><br><h4>  Jenkins </h4><br>  We use <a href="https://ru.wikipedia.org/wiki/Jenkins_(%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BE%25D0%25B1%25D0%25B5%25D1%2581%25D0%25BF%25D0%25B5%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5)">Jenkins</a> as a continuous integration system.  During peak periods, it performs from 20 platform assemblies per day;  It takes about 1.5 hours for one complete assembly, and 1 hour for testing.  The build is carried out in parallel along architectures (Windows, Linux, macOS), each build is in hundreds of threads at the same time.  A few years ago, this approach allowed us to reduce the build time of one version of the platform with all architectures from 8 hours to 80 minutes, and we are not going to stop there. <br>  Through web services, Jenkins is integrated with our task tracker, Task Base (written on the 1C: Enterprise platform), and in case of problems, automatically initiates errors directly in the Task Base, putting links to test logs and artifacts.  Jenkins also prepares the platform for publication, if necessary, filters and parses dumps. <br><br>  Jenkins also manages testing, allowing you to implement arbitrarily complex scenarios on arbitrary hardware configurations, including a large number of virtual machines, and also does additional work, for example, delivering and installing a platform for 1,500 servers up to 70 times a day. <br><br><h4>  Apache jmeter </h4><br>  <a href="https://ru.wikipedia.org/wiki/JMeter">JMeter</a> has a very valuable quality - it has low hardware requirements for emulating a large number of users.  Also JMeter allows you to generate a mixed load in one test - HTTP, SOAP, JDBC, LDAP, SMTP, TCP. <br><br>  In particular, we use JMeter to test the performance of an application cluster and its individual components, as well as for load testing an application cluster with a large number (up to 10,000) of users.  For this test, one DB server, two 1C servers and one server load are sufficient. <br><br>  We have 4 test benches where a single cluster is tested, a cluster in fault tolerant and non-fault tolerant configurations;  to test these configurations, we need only two physical machines. <br><br><img src="https://habrastorage.org/webt/kk/0x/3i/kk0x3igx11364yazke1iu3eu3ak.png" alt="image"><br>  <b>JMeter Performance Charts</b> <br><br><h4>  Test center </h4><br>  For more complex testing, we use our product <a href="http://v8.1c.ru/expert/tc/tc_overview.htm">Test Center</a> (part of the <a href="http://v8.1c.ru/expert/etp.htm">Corporate Tool Package</a> ).  The Test Center is a configuration on the 1C: Enterprise 8 platform;  It allows you to describe multi-user test scripts, automatically run them and monitor the progress of their execution.  We run the Test Center on the so-called conveyors;  One pipeline consists of 2 powerful physical servers on which virtual machines are located: <br><br><ul><li>  1 application server 1C </li><li>  1 database server </li><li>  1 license server </li><li>  40 servers with client sessions </li></ul><br>  We put a lot of effort into improving the accuracy of the conveyor;  we now have, when running tests on the same platform versions and configurations, the scatter of results is less than 1.5%.  On one conveyor, there are either 100 very fast clients (performing operations without pauses), or 1000 clients that are close to real users (emulating the work of an ordinary person, with pauses between actions). <br>  Conveyors design stand types: <br><br><ul><li>  small </li><li>  medium </li><li>  big </li></ul><br>  Conveyors can assemble 15 different work site configurations.  Configurations vary in server composition, fault tolerance.  Servers can be on Linux and Windows.  The bases for testing (as well as test scenarios) are prepared in two versions: <br><br><ul><li>  cloudy, for <a href="http://v8.1c.ru/fresh/whatis.htm">1cfresh</a> technology (base with a large number of relatively small data areas) </li><li>  KORP, for large implementations (large base) </li></ul><br>  Separated information bases (for testing work in 1cfresh technology) with configurations: <br><br><ul><li>  1c accounting </li><li>  Management of our company </li><li>  Salary and personnel management </li></ul><br>  In CORP options, the configurations are tested: <br><br><ul><li>  Salary and Personnel Management </li><li>  1C: ERP Enterprise Management 2 </li></ul><br>  Load tests can involve: 1, 2, 4, 10 pipelines. <br>  Load tests are in options for 100, 200, 400, 3000 and 10,000 users. <br>  In different workplace configurations, the number of servers in a cluster varies from 1 to 6. <br><br>  To run tests for 10,000 users in one database, two working 1C application servers are used.  Each cluster configuration is configured automatically from hundreds of parameters at the beginning of each test.  In fact, we can assume that the stand is fully prepared for operation automatically, because: <br><br><ul><li>  platform is delivered </li><li>  scripts are delivered </li><li>  cluster is configured </li><li>  loading database </li><li>  configuration files are configured (by specified parameters) </li><li>  Information publications are being prepared. </li></ul><br>  Cluster configuration scripts, configuration files, OS, special processing are stored centrally in Git and delivered to the stands automatically when there are changes. <br>  We also have scenarios for testing restructuring (product version updates, during which the database structure is changed).  We are testing restructuring on the same stands.  After the test is completed, the final result is checked - the data in the database must be updated correctly, and the database structure must correspond to the new version.  Both the old and the <a href="https://wonderland.v8.1c.ru/blog/optimizatsiya-restrukturizatsii-bazy-dannykh/">new</a> restructuring mechanism are being tested. <br><br>  During the load tests, we automatically collect and analyze: <br><br><ul><li>  all errors according to the Test Center </li><li>  platform technology journal exceptions </li><li>  all requests from the technology magazine platform </li><li>  all errors from the log </li><li>  all measurements of performed operations with technological information on their performance </li><li>  all equipment load data </li></ul><br>  All data are automatically generated reports (different depending on the types of tests), which are sent to the responsible.  All data is stored and aggregated in a special database with statistics and test results. <br><br><img src="https://habrastorage.org/webt/6d/ai/r8/6dair8i4k2ywxkpnoshcfhm-mv4.png" alt="image"><br>  <b>Test Center Screen</b> <br><br>  We also perform load testing of 10,000 users in the ‚Äú1C: ERP Enterprise Management 2‚Äù configuration on a fault-tolerant cluster with simulation of equipment failures, network failures, insufficient memory, CPU resources, and disk space.  This is a large test scenario in which the hang of 1C server processes is modeled alternately throughout the test, some processes are ‚Äúkilled‚Äù by the taskkill utility, the network is shut down and restored, etc.  As part of testing, custom work scenarios are run in different subsystems ‚Äî warehouse, purchasing, sales, mutual settlements, etc.  In the ERP load test, about 400 key operations are performed, the test takes several hours. <br><br><div class="spoiler">  <b class="spoiler_title">One of the ERP test scenarios (running in parallel with other scenarios)</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/yg/-u/-l/yg-u-lm2ikmwyzddrn-f5uaiuus.png" alt="image"><br></div></div><br><h4>  Configuration Performance Comparison </h4><br>  On top of the described systems, our internal tool works - ‚ÄúConfiguration Performance Comparison‚Äù (SEC), which allows you to compare performance: <br><br><ul><li>  different versions of the same configuration on the same platform </li><li>  two platform versions with the same configuration </li><li>  different DB / OS versions with the same platform / configuration </li></ul><br>  In the "Configuration Performance Comparison" system, all the same parameters are collected that are collected during normal load tests.  The system allows you to automatically detect the appearance of an error, the change in the load on the servers, the change in the duration of requests (or the appearance of requests that were not there before). <br><br>  We analyze both the deterioration of performance and improvement, which can be a symptom of a problem. <br><br>  The system can be used for comparison. <br><br><ul><li>  configuration versions </li><li>  platform versions </li><li>  versions of the DBMS, </li><li>  any settings </li></ul><br>  As a result, we get reports on passed load tests, with detailed information and a comparison of performance, load on equipment;  the reports contain the time for the execution of queries to the DBMS, the facts of exceptions, etc. <br><br>  Performance benchmarking refers to measuring the overall performance of the configurations, average runtime and average <a href="https://its.1c.ru/db/metod8dev">APDEX</a> for each key operation. <br><br><h4>  Visual testing </h4><br>  All of the above tools emulate users, invoking the appropriate methods of embedded objects of the tested configurations, making calls to web and HTTP services, etc.  But it is also extremely important to test exactly what the user actually sees, especially the user working through the web client (where it can take quite a while for the browser to draw the interface).  We were faced with a situation where the performance in terms of automatic tests during the transition to the new version did not change, but when we put a person with a stopwatch, he got some numbers on the old version, and completely different ones on the new one.  This is due, in particular, with the time of drawing the graphical interface, which in the new version could for some reason change. <br>  We wrote our tool that allows you to do visual testing of almost any application.  The tool records the actions of the user running the application in a script file.  The tool also records the image of the working area of ‚Äã‚Äãthe screen.  When monitoring new client versions, scripts are played without user participation.  When playing a script, the tool, before simulating keystrokes or mouse buttons, expects the appearance of the same screen image (up to a pixel) as it was in the recorded script. <br><br>  The tool also measures the performance of applications with an accuracy of 25 milliseconds, the results are written to the log for further automatic comparison.  In some cases, we loop back parts of the script (for example, repeat order entry several times) to analyze the degradation of the runtime of the script.  This testing, in addition to measuring performance, also allows us to be confident that in the new version of the platform the user will see the same screens in the thin client and browser as on the previous version of the application. <br><br>  An example of launching a scenario for entering an order in the configuration ‚ÄúManagement of Our Firm‚Äù - an order is entered 5 times;  Here is the real speed of the 1C: Enterprise platform, if the user responds immediately to the availability of the interface: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/__15an8uXYE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h4>  Functional testing </h4><br>  We are also actively developing functional testing.  We test combinations of major OS versions and databases, for each such combination we have our own set of virtual machines, the whole set of combinations forms one pipeline;  Automated adding of new OS and DB combinations to this pipeline.  Each functional test turns into a set of tasks that are executed on all possible combinations;  tasks are performed by the first free stands.  The <a href="http://v8.1c.ru/overview/Term_000000008.htm">Configurator</a> (1C application development environment), the functions of the embedded language, the query language, etc. are tested. <br><br>  When testing the Configurator, we check most of the commands available on the Configurator command line.  In addition, we have a special library (we do not deliver it to the outside), which allows us to test the internal logic of the Configurator, which is available only through the user interface, without resorting to direct UI testing.  Thus, most of the functions for working with configuration extensions, the comparison / merge functional and other Configurator functionality are tested. <br><br>  For testing purposes, writing scripts in 1C is available in this mode.  Within the script, special objects are available for testing purposes.  The launch of the configurator in this mode can be combined in one test with the launch of the client application.  This allows using this mode not only as a tool for testing the configurator, but also as a way to set up a test environment. <br><br><h2>  <a href="https://en.wikipedia.org/wiki/Eating_your_own_dog_food">Eating your own dogfood</a> </h2><br>  There are a number of our internal tools written on the 1C: Enterprise platform that we use in our daily work.  They work on the latest build platform.  Below we will talk about two of them - the ‚ÄúTask Base‚Äù and ‚ÄúEmployee Reports‚Äù. <br><br><h4>  Task Database </h4><br>  Our internal task tracker, ‚ÄúTask database‚Äù is a configuration written on the 1C: Enterprise platform.  These are 21 independent bases (part of the bases are workers, part are test ones) on different versions of the platform, with different operating systems and DBMS, the bases are synchronized via the platform <a href="http://v8.1c.ru/overview/Term_000000269.htm">data exchange mechanism</a> ;  Platform versions are updated daily, on some servers experimental versions of the platform are installed with separate new features.  The newly built platform functionality can be tested on the ‚ÄúTask Base‚Äù the very next day.  Different database instances work with different server environments (OS, DBMS) and with different versions of the platform, and users also log in from different clients (thin client, <a href="https://wonderland.v8.1c.ru/blog/mobilnyy-klient/">mobile client</a> ) and through a web client from different browsers.  Thus, testing of different versions of the platform in different environments is carried out. <br><br><h4>  Employee reports </h4><br>  ‚ÄúEmployee reports‚Äù is a time tracker for time tracking, which is used by employees of the 1C: Enterprise platform development department.  It works on the latest build platform. <br><br><h4>  "1C: Document" </h4><br>  The standard solution <a href="http://v8.1c.ru/doc8/">"1C: Document Management"</a> , which is used by all employees of our company, we also use with new, not yet released versions of the platform. <br><br><h4>  Platform Tests in Application Solutions </h4><br>  Along with automatic visual tests of popular application solutions (Enterprise Accounting, Management of Our Firm, Salary and Personnel Management, etc.), we conduct manual tests: scenario, visual, manual testing of the test cases of the main cases.  After reaching a certain level of platform quality, we ask developers of application configurations to switch to development on a new version of the platform and test their products on the upcoming version. <br><br><h3>  Beta testing platform partners </h3><br>  Some of our partners are interested in using early, not yet released versions of the 1C: Enterprise platform.  Such partners sign with <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BE%25D0%25B3%25D0%25BB%25D0%25B0%25D1%2588%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25BE_%25D0%25BD%25D0%25B5%25D1%2580%25D0%25B0%25D0%25B7%25D0%25B3%25D0%25BB%25D0%25B0%25D1%2588%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B8">NDA</a> , 1C, get access to platform assemblies before the release of the test version and have the opportunity to use the latest version of the platform in real conditions.  This allows partners at an early stage to detect problems in the platform and to be sure that these problems will no longer exist in the release version of the platform.  We try to treat requests from such partners about the errors found with high priority.  By the way, if someone from the readers of this article wants to take part in the beta testing of the 1C: Enterprise platform, write to <b>CorpTechSupport@1c.ru</b> . <br><br><h3>  Plans </h3><br>  The plans include switching to Continuous Delivery, a practice that assumes that the main assembly is constantly ready for release in order to shorten the time from the end of development to release.  To achieve this, we want to expand our test coverage, develop functional and load testing. </div><p>Source: <a href="https://habr.com/ru/post/352210/">https://habr.com/ru/post/352210/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../352198/index.html">Classes and factory functions in javascript. What to choose?</a></li>
<li><a href="../352200/index.html">How to turn a website into a mobile application using 7 lines of JSON</a></li>
<li><a href="../352202/index.html">The book "Head First. Design patterns. Updated anniversary edition ¬ª</a></li>
<li><a href="../352206/index.html">Release of PVS-Studio for macOS: 64 weaknesses in Apple XNU Kernel</a></li>
<li><a href="../352208/index.html">How to perform many UI tests in parallel using Selenium Grid?</a></li>
<li><a href="../352212/index.html">Gaijin Engineer in Tokyo</a></li>
<li><a href="../352214/index.html">Unblock Hackathon Registration Open April 6-8</a></li>
<li><a href="../352218/index.html">US authorities will check the activities of the cryptocurrency fund founder techclog TechCrunch</a></li>
<li><a href="../352220/index.html">Softer Meetup. How to deal with User Story?</a></li>
<li><a href="../352222/index.html">Fernando Gaunt will talk about IPv6 security on PHDays 8</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>