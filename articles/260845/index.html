<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Stream data processing with Akka</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! Everyone is used to associating big data processing with Hadoop (or Spark ), which implement the MapReduce paradigm (or its extensions). In ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Stream data processing with Akka</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  Everyone is used to associating big data processing with <a href="https://ru.wikipedia.org/wiki/Hadoop">Hadoop</a> (or <a href="https://ru.wikipedia.org/wiki/Apache_Spark">Spark</a> ), which implement the MapReduce paradigm (or its extensions).  In this article, I will discuss the shortcomings of MapReduce, why we decided to abandon MapReduce, and how we adapted Akka + Akka Cluster to replace MapReduce. <br><br> <a href="http://habrahabr.ru/company/dca/blog/260845/"><img src="https://habrastorage.org/getpro/habr/post_images/b69/2a8/8b5/b692a88b5be7b7f242b430c7580bc5a2.jpg"></a> <br><a name="habracut"></a><br><h2>  Data Management Platform </h2><br>  The task for which we needed the tools to work with big data is user segmentation.  The class of systems that solve the problem of user segmentation throughout the world is called the Data Management Platform or DMP for short.  At the entrance of the DMP, data about user actions is received (first of all, these are facts of visits to various Internet pages), the output of the DMP is a ‚Äúuser profile‚Äù - its gender, age, interests, intentions, and so on.  This profile is further used for advertising targeting, personal recommendations and for personalizing content in general.  Read more about DMP here: <a href="http://digitalmarketing-glossary.com/What-is-DMP-definition">http://digitalmarketing-glossary.com/What-is-DMP-definition</a> . <br><br>  Since DMP works with data from a large number of users, the amount of data that needs to be processed can be very impressive.  For example, our DMP <a href="http://facetz.ru/">Facetz.DCA</a> processes data from 600 million browsers, processing almost half a petebyte of data daily. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  DMP Facetz.DCA Architecture </h2><br>  In order to process such data volumes, a good scalable architecture is required.  Initially, we built a system based on the hadoop stack.  A detailed description of the architecture deserves a separate article, in the same material I will limit myself to a brief description: <br><br><ol><li>  Logs of user actions are added to <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">HDFS</a> - a distributed file system, which is one of the basic components of the ecosystem hadoop <br><br></li><li>  From HDFS, data is added to the raw data storage, implemented on the basis of <a href="http://hbase.apache.org/">Apache HBase</a> ‚Äî a distributed, scalable database built on the basis of <a href="https://ru.wikipedia.org/wiki/BigTable">Big Table</a> ideas.  In fact, HBase is a very convenient database for key-value mass processing.  All user data is stored in one large facts table.  The data of one user corresponds to one line of HBase, which makes it very fast and convenient to get all the necessary information about it. <br><br></li><li>  Analytic Engine is launched once a day - a large MapReduce job, which, in fact, performs segmentation of users.  In essence, the Analytic Engine is a container for segmentation rules, which are separately prepared by analysts.  For example, one script may mark the gender of the user, another - his interests, and so on. <br><br></li><li>  Ready-made user segments are added to <a href="http://www.aerospike.com/"><u>Aerospike</u></a> ‚Äî a key-value database that is very well tuned for quick returns ‚Äî 99% of read requests work out in less than 1 ms, even with heavy loads of tens of thousands of requests per second. <br><br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/42c/5ec/213/42c5ec213164627507b5a5776ef91931.jpg"><br>  <i>Facetz.DCA Architecture</i> <br><br><h2>  MapReduce problems </h2><br>  The developed architecture proved to be good - it allowed to scale quickly up to the processing of user profiles of the entire Runet and mark them up with the help of hundreds of scripts (everyone can mark a user in several segments).  However, it was not without flaws.  The main problem is the lack of interactivity during processing.  MapReduce, by its nature, is a paradigm of offline ‚Äì data processing.  So, for example, if a user watched football tickets today, he can get into the ‚ÄúFootball Interests‚Äù segment only tomorrow.  In some cases, this delay is critical.  A typical example is retargeting - advertising a user of products that he has already looked at.  The graph shows the probability of making a purchase by the user after viewing the product over time: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a45/ee4/604/a45ee46043ccca6b36d283332f4768c2.jpg"><br>  <i>Graph of the probability of conversion after viewing the product.</i>  <i>When there is no real-time engine, only the green part is available to us, while the maximum probability falls on the first hours.</i> <br><br>  It can be seen that the highest probability of purchase is within the first few hours.  With this approach, the system would know that the user wants to buy goods only after a day ‚Äî when the probability of a purchase has practically reached the plateau. <br><br>  Obviously, a streaming real-time data processing mechanism is needed that minimizes latency.  At the same time, I want to preserve the versatility of processing - the ability to build arbitrarily complex segmentation rules for users. <br><br><h2>  Actor Model </h2><img src="https://habrastorage.org/getpro/habr/post_images/cbd/18a/56c/cbd18a56ccc71169ab3318694f3fc4c2.jpg"><br>  After some thought, we came to the conclusion that the reactive programming paradigm and the model of actors are best suited for solving the problem.  Actor is a parallel programming primitive that can: <br><br><ul><li>  Accept messages <br></li><li>  Send messages <br></li><li>  Create new actors <br></li><li>  Set reaction to messages <br></li></ul><br>  The model of actors originated in the erlang community, now implementations of this model exist for many programming languages. <br><br>  For scala, which our DMP is written in, akka is a very good <a href="http://akka.io/">toolkit</a> .  It is the basis of several popular frameworks, well documented.  In addition, on the Coursera there is an excellent course on the <a href="https://ru.coursera.org/course/reactive">principles of reactive programming</a> , in which these very principles are explained just by the example of akka.  Separately, it is worth mentioning the <a href="http://doc.akka.io/docs/akka/snapshot/java/cluster-usage.html">akka cluster</a> module, which allows you to scale solutions (based on actors) into several servers. <br><br><h2>  Real-Time DMP Architecture </h2><br>  The final architecture is as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8d2/53f/908/8d253f908261ff8f3b792e22fb7df8d7.jpg"><br><br>  The data provider adds information about user actions in RabbitMQ. <br><br><ol><li>  Dispatcher reads user action messages from RabbitMQ.  Dispatcher may be several, they work independently. <br><br></li><li>  For every online user, an actor is started in the system.  Dispatcher sends a message about a new event (read from RabbitMQ) to the corresponding actor (or gets a new actor if this is the first user action and there is no actor for it yet). <br><br></li><li>  The actor corresponding to the user adds information about the action to the list of user actions and runs segmentation scripts (the same ones that run the Analytic Engine during MapReduce processing). <br><br></li><li>  The data on the marked segments are added to Aerospike.  Also, data on segments and user actions are available via an API connected directly to the actors. <br><br></li><li>  If there is no data about the user within an hour, the session is considered complete and the actor is destroyed. </li></ol><br>  Sharding of actors across the cluster, their life and destruction is controlled by akka, which significantly simplifies development. <br><br><h2>  Current results: </h2><br><ul><li>  Akka-cluster of 6 nodes; <br></li><li>  Data flow 3000 events per second; <br></li><li>  4-6 million users online (depending on the day of the week); <br></li><li>  The average time to execute one user segmentation script is less than five milliseconds; <br></li><li>  The average time between an event and a segmentation based on this event is one second. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/281/7ad/875/2817ad875d4be31e67b560d2d12bed22.png"><br><br><h2>  Further development </h2><br>  Our Real-Time Engine has shown itself well and we plan to develop it further.  List of steps that we plan to take: <br><br><ul><li>  Persistence - now Real-Time Engine segments users only on the basis of the last session.  We plan to add pull-ups of older information from HBase when a new user appears. <br></li><li>  Currently, only a part of our data is transferred to realtime processing.  We plan to gradually transfer all our data sources to stream processing, after which the stream of processed data will increase to 30,000 events per second. <br></li><li>  After completing the transfer to Realtime, we will be able to abandon the daily calculation of MapReduce, which will save on servers due to the fact that only those users who are really active on the Internet today will be processed. <br></li></ul><br><h2>  Links to similar solutions </h2><br>  In the end, I would like to give a few links to some frameworks, on the basis of which you can also build stream processing of data: <br>  - <a href="https://storm.apache.org/">Apache Storm</a> <br>  - <a href="https://spark.apache.org/streaming/">Spark Streaming</a> <br>  - <a href="http://samza.apache.org/">Apache Samza</a> <br><br>  Thank you for your attention, we are ready to answer your questions. <br><br>  <a href="https://www.youtube.com/channel/UCOvuB83CWNZ0yz8qeNpWIIQ">Youtube Channel about data analysis</a> </div><p>Source: <a href="https://habr.com/ru/post/260845/">https://habr.com/ru/post/260845/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../260831/index.html">Network Interface for BMW</a></li>
<li><a href="../260833/index.html">How and where should SKZI be used - FSB point of view</a></li>
<li><a href="../260837/index.html">Making a home farm for video rendering.</a></li>
<li><a href="../260839/index.html">Metalworking - 2015, part two: welding, roboruki, manipulators, tumbling</a></li>
<li><a href="../260841/index.html">Google Cloud Messaging: ‚ÄúOwl, discover! Push has come! ‚Äù</a></li>
<li><a href="../260847/index.html">Hosting for business. The story of one move</a></li>
<li><a href="../260849/index.html">WorkFlowSoft - a tool for organizing the work of the company</a></li>
<li><a href="../260851/index.html">Quick helpers for your Asterisk</a></li>
<li><a href="../260855/index.html">How DIY robots will change education by 2035</a></li>
<li><a href="../260859/index.html">Hola prizes: consolatory and not only</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>