<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Recommender system on the knee as a means against existential crisis</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Maybe the reference to an existential crisis sounds too loud, but for me personally the problem of searching and choosing (or choosing and searching, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Recommender system on the knee as a means against existential crisis</h1><div class="post__text post__text-html js-mediator-article">  Maybe the reference to an <i><a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D0%25B7%25D0%25B8%25D1%2581%25D1%2582%25D0%25B5%25D0%25BD%25D1%2586%25D0%25B8%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25BA%25D1%2580%25D0%25B8%25D0%25B7%25D0%25B8%25D1%2581">existential crisis</a></i> sounds too loud, but for me personally the <b>problem of searching and choosing</b> (or choosing and searching, it matters) in the Internet world as well as in the world of simple things sometimes comes near torture.  The choice of the film for the evening, books by an unknown author, sausages in the store, a new iron - a wild number of options.  Especially when you don‚Äôt really know what you want.  And when you know, but you can‚Äôt try it - it‚Äôs not a holiday either - the world is diverse and you don‚Äôt try everything at once. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/59/e5/32/59e5329aa39d7837224854.png" alt="image" width="400"></div><br>  <b>Recommender systems</b> help a lot in choosing, but not everywhere and not always as we would like.  Often, the semantics of the content is not taken into account.  In addition, the full length of the problem is <i>" <a href="http://letopisi.org/index.php/%25D0%25A2%25D0%25B5%25D0%25BE%25D1%2580%25D0%25B8%25D1%258F_%25D0%25B4%25D0%25BB%25D0%25B8%25D0%25BD%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2585%25D0%25B2%25D0%25BE%25D1%2581%25D1%2582%25D0%25B0">long tail</a> "</i> , when the recommendations focus only on the most popular positions, and interesting, but not very popular in the mass of things they are not covered. <br><br>  I decided to <b>start</b> my experiment in this direction <b>by searching for interesting texts by</b> taking a rather small but writing community of authors who still remained on the <i><a href="http://www.livejournal.com/">LiveJournal</a></i> blogging platform.  About how <b>to make your own recommender system</b> and as a result get another helper in choosing wine for the evening - under the cut. <br><a name="habracut"></a><br><h4>  Why LiveJournal? </h4><br>  Well, first of all, this is a blog platform and often interesting things are written there.  Even despite the migration of users to Facebook in LJ, there are still, according to my estimates, about 35-40 thousand active blogs.  It is quite a reasonable volume for experiments without the use of big data tools.  Well, the cracking process itself is quite simple, unlike working with the same facebook. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the end, I wanted to get a tool to recommend interesting authors.  In the process of working on the project, the hotelies expanded and multiplied, and not everything turned out right away.  About what was possible and what are the future plans, and I will tell in this article. <br><br><h4>  Crawling </h4><br>  As already mentioned, crawling blogs on the LJ platform is quite simple - you can easily get the texts of posts, pictures (if they are needed) and even comments on posts with their structure.  I must say that it is the system of hierarchical commenting like on Habr√© that keeps some authors on this platform. <br><br>  So, a simple crawler on Perl, the code of which can be taken <a href="https://github.com/roman-lugovkin/lj-crawler">from me on github</a> 'for a couple of weeks of unhurried work, I downloaded texts and comments from about 40 thousand blogs for the period summer 2017 and summer 2016. These two periods were chosen for parallel comparison of activity in LiveJournal from year to year. <br><br><div class="spoiler">  <b class="spoiler_title">Why perl</b> <div class="spoiler_text">  Because I like this language, I work on it and I consider it very suitable for tasks with unpredictable flow and result - just what is needed in experimental information retrieval and data mining when maximum performance is not needed, but maximum flexibility is needed.  For data processing it is better, of course, to use python with a bunch of libraries under it. <br></div></div><br>  So, the initial data for the study turned out like this: <br><br>  - Analysis period: 6 months <br>  - Authors: approximately 45 thousand <br>  - Publications: approximately 2.5 million <br>  - Words: approximately 740 million <br><br><h4>  Analytical model and processing </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/59/e5/51/59e551d731aa0865037449.jpeg" alt="image" width="400"></div><br><br>  Since I am not a data scientist (although I watch contests on <a href="https://www.kaggle.com/romanl">kaggle</a> from time to time), the algorithms were chosen very simple - consider the proximity of the authors as the <i>cosine distance</i> between the vectors characterizing their texts. <br><br>  There were several approaches to the <b>construction of vectors with the characteristics of the authors' texts</b> : <br><br>  1. Obvious - we build vectors with the <i>TF-IDF</i> metric according to the assembled text corpus.  The disadvantage is that the vector space turns out to be very much multidimensional (~ 60 thousand) and very sparse. <br><br>  2. Dodgy - <i>clustering a text corpus</i> using <i>word2vec</i> and taking vectors as a projection of texts on the resulting clusters.  The advantage is relatively short vectors in the number of clusters (usually ~ 1000).  The disadvantage is that you need to train word2vec, select the number of clusters for clustering, think about how to project text on clusters, it is confused. <br><br>  3. And also not bad - to build vectors with gensim <i>doc2vec</i> .  Almost the same as the second option, but the side view and all the problems except training have already been solved.  But in python.  And I did not want this. <br><br>  As a result, the first model was chosen, supplemented by <i>LSA</i> methods <i>(Latent-semantic analysis)</i> in the form of <i>SVD decomposition of the</i> resulting matrix ‚Äúdocuments‚Äù - ‚Äúterms‚Äù.  The method has been described many times on Habr√©, I will not dwell. <br><br>  For the <b>lemmatization of terms</b> , or rather the reduction of Russian words to the basic form, the <i><a href="https://tech.yandex.ru/mystem/">mystem</a></i> utility from Yandex and a wrapper around it were used, which allows you to combine several documents into a single file to feed it to the utility input.  It was possible to call it on every document, which I did before, but this is not very effective.  Nouns, adjectives, verbs and adverbs with a length of more than 3 characters and with a frequency of use of more than 100 throughout the body <b>were selected</b> into the corpus. <br><br>  Here, for example, the top nouns, reduced to the basic form: <br><br>  1 person <br>  2. Time <br>  3. Russia <br>  4. Day <br>  5. Country <br><br>  <b>SVD decomposition</b> was done using the external utility <i><a href="https://github.com/lucasmaystre/svdlibc">SVDLIBC</a></i> , which had to be patched to use very large matrices, as it fell when trying to create a ‚Äúdense matrix‚Äù with the number of elements greater than the maximum value of the int type.  But the utility is good because it can work in sparse matrices and calculate only the required number of singular vectors, which significantly saves time.  By the way, for Perl there is a module <a href="">PDL :: SVDLIBC</a> based on the code of this utility. <br><br>  The choice of the length of the vector (the number of singular vectors in the decomposition) was made by ‚Äúexpert analysis‚Äù (read by eye) on the test set of journals.  As a result, I stopped at n = 500. <br><br>  The result of the analysis is a matrix of coefficients of similarity of the authors. <br><br><h4>  Result visualization </h4><br>  At the initial stage, I wanted to evaluate the structure of the thematic communities with my eyes in order to understand what to do with it further. <br><br>  I tried to use clustering and visualization in the form of <i>self-organizing maps (SOM)</i> from the analysis package <a href="https%253A%252F%252Fbasegroup.ru%252Fdeductor%252Fdescription%26usg%3DAOvVaw3fDSOH-Y1dLFxGRIIJdGoM">Deductor</a> by applying to the input a vector of 500 values ‚Äã‚Äãafter SVD.  The result made me wait (multithreading? No, did not hear) and did not please - three large clusters were traced and the authors were fairly densely located across the entire map field. <br><br>  It was obvious that <i>the distance matrix could be transformed into a graph by</i> keeping the edges with the value of the proximity factor greater than a certain threshold.  Having written the matrix converter to the GDF format graph (it seemed to me the most suitable for visualizing various parameters), after feeding this graph <i><a href="https://gephi.org/">to the Gephi graph visualization package</a></i> and experimenting with different layouts and display parameters I got this picture: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/59/e5/d1/59e5d101d781a194864120.png" alt="image"></div><br><br>  When you click on the picture and <a href="">here</a> you can meditate on it in a resolution of 3000x3000.  And if you sometimes go to LJ blogs, you may find familiar names there. <br><br>  This picture is fully consistent with my ideas about the thematic structure of the authors, although not perfect (too dense).  It remains a little - to give yourself and others the <b>opportunity to receive recommendations based on personal authoring preferences</b> : I asked the author‚Äôs name and received recommendations similar to him. <br><br>  For this purpose, a small visualization of the graph areas adjacent to the author of interest on <a href="https%253A%252F%252Fd3js.org%252F%26usg%3DAOvVaw3LPzG672wd3APWnSeZucyJ">d3js</a> was written using the <b>force layout</b> .  For each author (and there are a little more than 40 thousand of them, as I have already said) a json file was generated with a description of the nearby nodes of the graph, a <b>‚Äútag annotation‚Äù</b> based on a sorted list of popular words for this author and a similar annotation of his group that includes nearby knots.  Annotations should give some insight about what the author writes and what topics are relevant to similar bloggers. <br><br>  It turned out this mini-search engine <b><a href="http://similarity.me/">similarity.me</a></b> with recommendations and a graphics card: <br><br><div style="text-align:center;"> <a href="http://similarity.me/%3Fauthor%3Dmaxkatz" title="Opens in new window"><img src="https://habrastorage.org/webt/59/e5/d6/59e5d69e7f309214403027.png" alt="image" width="400"></a> </div><br><h4>  What can be improved? </h4><br><ul><li>  <b>Adequacy</b> - now the process of data collection is underway, so the coverage of posts will be greater and the semantic proximity of the authors on the map should become more adequate.  In addition, I plan to conduct an additional pre-selection of authors - to exclude "half-dead", fans of reposts, automatic publishers - this will allow a little to clear the graph from garbage. </li><li>  <b>Accuracy</b> - there is a thought to use neural networks to form vectors of documents and experiment with different distances except cosine. </li><li>  <b>Visualization</b> - try to impose a thematic structure on the structure of relations between the authors using hexagonal projections and all the same self-organizing maps.  Well, to achieve a clearer clustering of the overall map. </li><li>  <b>Annotation</b> - try annotation algorithms with the creation of phrases. </li></ul><br><h4>  What about vinishka? </h4><br>  The title picture is just a <b>wine list for taste characteristics</b> )) <br><br>  A side effect of the research was the thought ‚Äúrather than use this approach to recommend any products according to their descriptions.‚Äù  And for this purpose, the wine critic <a href="http://facebook.com/roudenko">Denis Rudenko‚Äôs</a> tasting notes in his blog at <a href="https://daily-winegraph.livejournal.com/">the Daily Wine Telegraph Daily</a> Journal were perfect.  Unfortunately, he abandoned their publication long ago, but more than 2000 descriptions of wines accumulated there are excellent material for such an experiment. <br><br>  Special preprocessing of texts was not done.  Having fed them to the system, I <a href="http://similarity.me/vine/">received a taste card of 700 best wines</a> with a recommendation of similar ones: <br><br><div style="text-align:center;"> <a href="http://similarity.me/vine/" title="In a new window"><img src="https://habrastorage.org/webt/59/e5/db/59e5db03e725b959748465.png" alt="image" width="400"></a> </div><br>  It can highlight the wines of the most popular grape varieties and their subjective (from the point of view of the taster) tastes. <br><br>  Plans to slightly optimize the recommendations by converting some adjectives into nouns, for example, ‚Äúblueberry‚Äù - ‚Äúblueberry‚Äù.  And place on the map all over 2000 tasted wines. <br><br>  This is how you can deal with the problem of choice (if all of a sudden it is relevant for you) by expanding these approaches to other areas. </div><p>Source: <a href="https://habr.com/ru/post/340262/">https://habr.com/ru/post/340262/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../340250/index.html">In simple words: smart contracts, Ethereum, ICO</a></li>
<li><a href="../340252/index.html">China is a digital power. Impressions of Huawei Connect 2017</a></li>
<li><a href="../340254/index.html">Jinja2 Extensions Guide</a></li>
<li><a href="../340256/index.html">BlackOasis APT: a new campaign with a new zerodem</a></li>
<li><a href="../340258/index.html">Hacking visual system: 11 optical illusions in graphic design</a></li>
<li><a href="../340264/index.html">8 key decisions in development on React</a></li>
<li><a href="../340266/index.html">What you need to know the head of the IT department?</a></li>
<li><a href="../340268/index.html">The philosophy of static code analysis: we have 100 programmers, the analyzer found few errors, is it useless?</a></li>
<li><a href="../340270/index.html">The New Stack statistics about the difficulties of implementing Kubernetes</a></li>
<li><a href="../340272/index.html">Bypass the limitations of WEB-browsers on the engine Chromium. From one iframe we change the contents of another iframe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>