<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Query Processing in Oracle and PostgreSQL: Implications of a Single Solution</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Processing SQL queries in both Orakle and Postgres has a lot in common. Anyway, you need to perform a syntactic analysis, check the semantics (which r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Query Processing in Oracle and PostgreSQL: Implications of a Single Solution</h1><div class="post__text post__text-html js-mediator-article">  Processing SQL queries in both Orakle and Postgres has a lot in common.  Anyway, you need to perform a syntactic analysis, check the semantics (which requires meta information, and it does not matter whether it is called a ‚Äúdata dictionary‚Äù or a ‚Äúsystem catalog‚Äù), perform any transformations, build an optimal execution plan (in both systems based on cost, and therefore requiring pre-collected statistics). <br><br>  But there is only one significant difference that radically changes the whole approach to processing.  Speech, of course, that Orakl uses a global cache of the disassembled requests, and Postgres saves requests locally. <br><br>  In the article we will try to trace how, due to the difference in one architectural solution, a completely different ideology of work in queries in two DBMS follows logically. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The examples given (which were run on versions of Oracle 11.2 XE and PostgreSQL 9.4) contain query execution times.  We are only interested in relative values: how many times the execution time has changed after making certain changes in the query.  In this case, the absolute figures may differ by orders of magnitude depending on the equipment, load and settings.  In order not to give rise to meaningless conclusions based on them, all absolute values ‚Äã‚Äãin the article are scaled so that one of the requests is 10 seconds in both systems. <br><a name="habracut"></a><br><h1>  Orakl </h1><br>  Orakl uses a cache of disassembled queries global for the entire instance (library cache, library cache).  The plan of any executed query is guaranteed to be in the cache: either the query is executed with the already prepared plan from the cache, or a new plan is built and stored in the cache - and this happens automatically. <br><br>  Simplifiedly, the general query execution scheme can be represented as follows: <br><br><ol><li>  Parsing a query (whether the SQL command was spelled correctly). </li><li>  Semantic analysis (whether the specified objects exist and whether there is access to them). </li><li>  If the finished plan is in the cache, then use it;  otherwise, further. </li><li>  Transformation (rewriting a query according to heuristic rules). </li><li>  Optimization (choice of execution plan with minimal cost). </li><li>  The location of the selected plan in the cache. </li></ol><br><br>  The same request, repeated two times in a row, will be processed differently.  The first time there will be a so-called full parse (hard parse) - from the first to the last item.  The second time, only partial parsing (soft parse) will be performed - syntactic and semantic analysis - after which a ready plan will be found and used in the cache, which is much more efficient. <br><br>  The presence of a global cache pushes to minimize the number of entries in it.  One reason is that a large stream of ‚Äúone-time‚Äù requests can force out useful plans from the cache, while these requests themselves will never be repeated.  But most importantly, parallel processes access the shared cache, therefore, it must be protected by locks and writing to it can become a bottleneck. <br><br>  Indeed, a process that performs many complete parses becomes a problem for the entire instance.  Consider this situation with the following example: <br><br> <strong><code>create table t(</code></strong> <br> <strong><code>id number primary key,</code></strong> <br> <strong><code>n number not null</code></strong> <br> <strong><code>);</code></strong> <br> <strong><code>insert into t(id, n)</code></strong> <br> <strong><code>select level, 1</code></strong> <br> <strong><code>from dual</code></strong> <br> <strong><code>connect by rownum &lt;= 100000;</code></strong> <br> <strong><code>exec dbms_stats.gather_table_stats(user,'T');</code></strong> <br> <strong><code>alter session set statistics_level=all;</code></strong> <br> <br>  Here we create a table, insert hundreds of thousands of rows into it (the ‚Äúdual connect by rowid &lt;= N‚Äù construction is an idiom to generate a sample of N rows) and collect statistics. <br><br>  Let us execute the PL / SQL code below, which updates the table line by line in a loop, using dynamically generated update queries (perhaps the example looks far-fetched, but in practice it is not like this): <br><br> <strong><code>begin</code></strong> <br> <strong><code>for i in (select id from t) loop</code></strong> <br> <strong><code>execute immediate 'update t set n = n + 1 where id = '||i.id;</code></strong> <br> <strong><code>end loop;</code></strong> <br> <strong><code>commit;</code></strong> <br> <strong><code>end;</code></strong> <br> <strong><code>/</code></strong> <br> <br>  If you run a trace, here's what you can find: <br><br> <code>OVERALL TOTALS FOR ALL RECURSIVE STATEMENTS</code> <br> <br> <code>call     count      cpu    elapsed       disk      query    current       rows</code> <br> <code>------- ------ -------- ---------- ---------- ---------- ---------- ----------</code> <br> <code>Parse   100003    92.63      95.40          0       2837          0          0</code> <br> <code>Execute 100003    13.57      14.29          0     200002     102225     100000</code> <br> <code>Fetch     1002     0.87       0.75          0      10173          0     100000</code> <br> <code>------- ------ -------- ---------- ---------- ---------- ---------- ----------</code> <br> <code>total   201008   107.08     110.46          0     213012     102225     200000</code> <br> <br> <code>Misses in library cache during parse: 100001</code> <br> <br>  Information on all SQL queries initiated from a code block is shown here.  The elapsed column shows the total elapsed time (which is made up of cpu and different expectations), and the lines parse, execute, fetch correspond to the stages of parsing, executing and receiving the results of the query.  As you can see, most of the time (95 seconds out of 110, column elapsed) went into the analysis of one hundred thousand (column count) of the same type of requests and placing their one-time plans in the cache.  If you run several similar processes at the same time, expectations such as ‚Äúlatch: shared pool‚Äù and ‚Äúlatch: row cache objects‚Äù will start to appear (the names change from version to version), indicating competition for access to the library cache. <br><br>  To avoid this, in Oracle it is common to use bind variables.  For example: <br><br> <strong><code>begin</code></strong> <br> <strong><code>for i in (select id from t) loop</code></strong> <br> <strong><code>execute immediate 'update t set n = n + 1 where id = :A' using i.id;</code></strong> <br> <strong><code>end loop;</code></strong> <br> <strong><code>commit;</code></strong> <br> <strong><code>end;</code></strong> <br> <strong><code>/</code></strong> <br> <br>  Or simply, without dynamic SQL, since PL / SQL automatically converts its variables to database bind variables: <br><br> <strong><code>begin</code></strong> <br> <strong><code>for i in (select id from t) loop</code></strong> <br> <strong><code>update t set n = n + 1 where id = i.id;</code></strong> <br> <strong><code>end loop;</code></strong> <br> <strong><code>commit;</code></strong> <br> <strong><code>end;</code></strong> <br> <strong><code>/</code></strong> <br> <br>  Here is what tracing will show in this case: <br><br> <code>OVERALL TOTALS FOR ALL RECURSIVE STATEMENTS</code> <br> <br> <code>call     count      cpu    elapsed       disk      query    current       rows</code> <br> <code>------- ------ -------- ---------- ---------- ---------- ---------- ----------</code> <br> <code>Parse        3     0.02       0.03          0        297          0          0</code> <br> <code>Execute 100002     9.08       9.28          0     201694     102315     100000</code> <br> <code>Fetch     1001     0.77       0.68          0      10173          0     100000</code> <br> <code>------- ------ -------- ---------- ---------- ---------- ---------- ----------</code> <br> <code>total   101006     9.87      10.00          0     212164     102315     200000</code> <br> <br>  The parsing time has been reduced to the minimum - all update requests now look the same for the DBMS.  "Same", that is, in fact, the key for the cache, is determined by two values: <br><br><ul><li>  sql_id - hash code of the query text (that is, queries that differ in any character are different queries), </li><li>  child_number is some additional number, the necessity of which is caused at least by the fact that syntactically identical queries (with the same sql_id) may be semantically different and must have different plans. </li></ul><br><br>  Thus, the update request is parsed only once (the number 3 in the count column corresponds to the PL / SQL block parses, the select query in the for clause, and the update query in the body of the loop).  His plan is placed in the cache and then everything works relatively quickly. <br><br>  (Why ‚Äúrelative‚Äù? Because the correct way is to perform the update with one command ‚Äúupdate t set n = n + 1‚Äù, which is performed an order of magnitude faster.) <br><br>  However, a ‚Äúgeneral‚Äù query plan, constructed without taking into account the values ‚Äã‚Äãof variables, will be adequate only for evenly distributed data. <br><br>  Let's change the table: add and index the flag field that is equal to ‚ÄúY‚Äù for 0.1% of the rows and ‚ÄúN‚Äù for the remaining 99.9%. <br><br> <strong><code>alter table t add (</code></strong> <br> <strong><code>flag char(1) check (flag in ('Y','N'))</code></strong> <br> <strong><code>);</code></strong> <br> <strong><code>update t</code></strong> <br> <strong><code>set flag = case when mod(id,1000)=0 then 'Y' else 'N' end;</code></strong> <br> <strong><code>create index t_flag on t(flag);</code></strong> <br> <br>  In order for the optimizer to take note of the irregularity of the data in the flag field, it is necessary to assemble a histogram on this field.  For example: <br><br> <strong><code>exec dbms_stats.gather_table_stats(user,'T',method_opt=&gt;'for columns flag size 2');</code></strong> <br> <br>  Interestingly, the explain plan command (the result of which is available using the dbms_xplan.display function) will still show a plan built on the assumption of uniformity, as if the optimizer is expecting to get half of the table: <br><br> <strong><code>explain plan for select * from t where flag = :f;</code></strong> <br> <strong><code>select * from table(dbms_xplan.display);</code></strong> <br> <br> <code>--------------------------------------------------------------------------</code> <br> <code>| Id  | Operation         | Name | Rows  | Bytes | Cost (%CPU)| Time     |</code> <br> <code>--------------------------------------------------------------------------</code> <br> <code>|   0 | SELECT STATEMENT  |      | 50000 |   488K|    76   (2)| 00:00:01 |</code> <br> <code>|*  1 |  TABLE ACCESS FULL| T    | 50000 |   488K|    76   (2)| 00:00:01 |</code> <br> <code>--------------------------------------------------------------------------</code> <br> <br> <code>Predicate Information (identified by operation id):</code> <br> <code>---------------------------------------------------</code> <br> <br> <code>1 - filter("FLAG"=:F)</code> <br> <br>  This means only that by and large the explain plan command in Orakle cannot be used.  It does not take into account either the values ‚Äã‚Äãof the variables or their types, and the plan generated by it does not fall into the cache and is not used in any way. <br><br>  In fact, when executing the query, Orakl ‚Äúspies‚Äù the values ‚Äã‚Äãof the binding variables (this is called ‚Äúbind peeking‚Äù) and builds a plan based on these values.  The real plan needs to be looked at directly in the cache when the request has already been sent for execution and parsed.  To do this, use the dbms_xplan.display_cursor function;  with the parameters specified in the example, it displays the plan of the last executed query and information about the bind variables: <br><br> <strong><code>var f char(1)</code></strong> <br> <strong><code>exec :f := 'Y'</code></strong> <br> <strong><code>select * from t where flag = :f;</code></strong> <br> <code>...</code> <br> <code>100 rows selected.</code> <br> <br> <strong><code>select * from table(dbms_xplan.display_cursor(format=&gt;'typical +peeked_binds'));</code></strong> <br> <br> <code>SQL_ID 6pncxxhknwgqc, child number 0</code> <br> <br> <code>--------------------------------------------------------------------------------------</code> <br> <code>| Id  | Operation                   | Name   | Rows  | Bytes | Cost (%CPU)| Time     |</code> <br> <code>--------------------------------------------------------------------------------------</code> <br> <code>|   0 | SELECT STATEMENT            |        |       |       |     2 (100)|          |</code> <br> <code>|   1 |  TABLE ACCESS BY INDEX ROWID| T      |   135 |  1350 |     2   (0)| 00:00:01 |</code> <br> <code>|*  2 |   INDEX RANGE SCAN          | T_FLAG |   135 |       |     1   (0)| 00:00:01 |</code> <br> <code>--------------------------------------------------------------------------------------</code> <br> <br> <code>Peeked Binds (identified by position):</code> <br> <code>--------------------------------------</code> <br> <br> <code>1 - :F (CHAR(30), CSID=873): 'Y'</code> <br> <br> <code>Predicate Information (identified by operation id):</code> <br> <code>---------------------------------------------------</code> <br> <br> <code>2 - filter("FLAG"=:F)</code> <br> <br>  Now it is clear that the optimizer took into account the value of the variable (section peeked binds), adequately estimated the number of lines (135; the error does not affect the result) and chose access by index. <br><br>  The problem is that the built ‚Äúprivate‚Äù plan gets into the cache and will be reused for the same requests - without taking into account the values ‚Äã‚Äãof variables.  This is not always good: in our example, access by index will be extremely inefficient for the value of 'N'.  Traditionally, the solution was to use dynamic SQL with literals pasted into the query text - but this solution is not a good one: in addition to the minuses discussed above, this approach is also dangerous with the possibility of SQL injections.  Therefore (starting with version 11g), Orakl is able to find and specially process requests that are sensitive to the values ‚Äã‚Äãof binding variables (this is called ‚Äúadaptive cursor sharing‚Äù).  When executing the query, the plan already in the cache is used, but the resources actually consumed are tracked and compared with the statistics of previous runs. <br><br>  Let's look at some of the information from the library cache on our request: <br><br> <strong><code>select child_number, is_bind_sensitive, is_bind_aware, executions, buffer_gets from v$sql where sql_id='6pncxxhknwgqc';</code></strong> <br> <br> <code>CHILD_NUMBER IS_BIND_SENSITIVE IS_BIND_AWARE EXECUTIONS BUFFER_GETS</code> <br> <code>------------ ----------------- ------------- ---------- -----------</code> <br> <code>0                 Y             N          1         128</code> <br> <br>  The request is marked as sensitive to variable values ‚Äã‚Äã(bind sensitive).  Buffer_gets - the number of read data blocks. <br><br>  If it is found that the request was executed worse with other values, then the next time it is executed it will be marked as bind aware. <br><br>  Perform the same query with a different flag field value: <br><br> <strong><code>exec :f := 'N'</code></strong> <br> <strong><code>select * from t where flag = :f;</code></strong> <br> <code>...</code> <br> <code>99900 rows selected.</code> <br> <br>  Let us make sure that the request was executed with a plan from the cache, and at the same time we will demonstrate the possibility of outputting in the plan not only expected, but also actual values ‚Äã‚Äã(for this purpose, the statistics_level parameter was first set): <br><br> <strong><code>select * from table(dbms_xplan.display_cursor(format=&gt;'allstats last'));</code></strong> <br> <br> <code>SQL_ID 6pncxxhknwgqc, child number 0</code> <br> <br> <code>-----------------------------------------------------------------------------------</code> <br> <code>| Id  | Operation                   | Name   | Starts | E-Rows | A-Rows | Buffers |</code> <br> <code>-----------------------------------------------------------------------------------</code> <br> <code>|   0 | SELECT STATEMENT            |        |      1 |        |  99900 |   41368 |</code> <br> <code>|   1 |  TABLE ACCESS BY INDEX ROWID| T      |      1 |    135 |  99900 |   41368 |</code> <br> <code>|*  2 |   INDEX RANGE SCAN          | T_FLAG |      1 |    135 |  99900 |    6842 |</code> <br> <code>-----------------------------------------------------------------------------------</code> <br> <br> <code>Predicate Information (identified by operation id):</code> <br> <code>---------------------------------------------------</code> <br> <br> <code>2 - access("FLAG"=:F)</code> <br> <br>  There is a discrepancy between the expected number of lines (135) and real (99900).  In addition, it is clear that for execution I had to read significantly more data than the first time (buffer_gets column): <br><br> <strong><code>select child_number, is_bind_sensitive, is_bind_aware, executions, buffer_gets from v$sql where sql_id='6pncxxhknwgqc';</code></strong> <br> <br> <code>CHILD_NUMBER IS_BIND_SENSITIVE IS_BIND_AWARE EXECUTIONS BUFFER_GETS</code> <br> <code>------------ ----------------- ------------- ---------- -----------</code> <br> <code>0                 Y             N          2       41496</code> <br> <br>  Run the query again: <br><br> <strong><code>select * from t where flag = :f;</code></strong> <br> <code>...</code> <br> <code>99900 rows selected.</code> <br> <br>  Now the new plan is already used, built for the new value of the binding variable (note the changed child number and the peeked binds section): <br><br> <strong><code>select * from table(dbms_xplan.display_cursor(format=&gt;'typical +peeked_binds'));</code></strong> <br> <br> <code>SQL_ID 6pncxxhknwgqc, child number 1</code> <br> <br> <code>--------------------------------------------------------------------------</code> <br> <code>| Id  | Operation         | Name | Rows  | Bytes | Cost (%CPU)| Time     |</code> <br> <code>--------------------------------------------------------------------------</code> <br> <code>|   0 | SELECT STATEMENT  |      |       |       |    77 (100)|          |</code> <br> <code>|*  1 |  TABLE ACCESS FULL| T    | 99856 |   975K|    77   (3)| 00:00:01 |</code> <br> <code>--------------------------------------------------------------------------</code> <br> <br> <code>Peeked Binds (identified by position):</code> <br> <code>--------------------------------------</code> <br> <br> <code>1 - :F (CHAR(30), CSID=873): 'N'</code> <br> <br> <code>Predicate Information (identified by operation id):</code> <br> <code>---------------------------------------------------</code> <br> <br> <code>1 - filter("FLAG"=:F)</code> <br> <br>  This time, the optimizer correctly estimated the number of rows (99856, with a small error) and chose a full table scan.  And the library cache now has two versions of the plan for the same query: <br><br> <strong><code>select child_number, is_bind_sensitive, is_bind_aware, executions, buffer_gets from v$sql where sql_id='6pncxxhknwgqc';</code></strong> <br> <br> <code>CHILD_NUMBER IS_BIND_SENSITIVE IS_BIND_AWARE EXECUTIONS BUFFER_GETS</code> <br> <code>------------ ----------------- ------------- ---------- -----------</code> <br> <code>0                 Y             N          2       41496</code> <br> <code>1                 Y             Y          1        6922</code> <br> <br>  Striving to minimize the number of plans in the cache forces the optimizer to "stumble" before deciding whether to have different plans for a single query.  Note that this can be avoided by manually giving a hint to the optimizer in advance. <br><br><h1>  Postgres </h1><br>  Postgres has no global cache of parsed queries.  Moreover, if you do not make special efforts, the request will not be stored locally in the memory of the process. <br><br>  In particular, if you repeat the same request, it will be fully understood every time.  Of course, a process written in this way will not work optimally, but at least it does not directly affect other processes. <br><br>  Consider an example: <br><br> <strong><code>create table t(</code></strong> <br> <strong><code>id serial primary key,</code></strong> <br> <strong><code>n numeric not null</code></strong> <br> <strong><code>);</code></strong> <br> <strong><code>insert into t(n)</code></strong> <br> <strong><code>select 1 from generate_series(1,100000);</code></strong> <br> <strong><code>analyze t;</code></strong> <br> <br>  Run the following PL / pgSQL code: <br><br> <strong><code>\timing on</code></strong> <br> <strong><code>do $$</code></strong> <br> <strong><code>declare</code></strong> <br> <strong><code>i record;</code></strong> <br> <strong><code>begin</code></strong> <br> <strong><code>for i in (select id from t) loop</code></strong> <br> <strong><code>execute 'update t set n = n + 1 where id = '||i.id;</code></strong> <br> <strong><code>end loop;</code></strong> <br> <strong><code>end;</code></strong> <br> <strong><code>$$ language plpgsql;</code></strong> <br> <code>DO</code> <br> <code>Time: 36164,377 ms</code> <br> <br>  In order to save the results of the analysis, the request must be prepared, and then the saved request can be reused: <br><br> <strong><code>prepare u(integer) as update t set n = n + 1 where id = $1;</code></strong> <br> <strong><code>execute u(1);</code></strong> <br> <strong><code>execute u(2);</code></strong> <br> <code>...</code> <br> <strong><code>execute u(100000);</code></strong> <br> <br>  This is exactly what happens if in a PL / pgSQL block you invoke a SQL command without using execute, as in the first example.  In our case, this gives a speed gain of 3.5 times: <br><br> <strong><code>do $$</code></strong> <br> <strong><code>declare</code></strong> <br> <strong><code>i record;</code></strong> <br> <strong><code>begin</code></strong> <br> <strong><code>for i in (select id from t) loop</code></strong> <br> <strong><code>update t set n = n + 1 where id = i.id;</code></strong> <br> <strong><code>end loop;</code></strong> <br> <strong><code>end;</code></strong> <br> <strong><code>$$ language plpgsql;</code></strong> <br> <code>DO</code> <br> <code>Time: 10000,000 ms</code> <br> <br>  (And the correct version ‚Äî one SQL command ‚Äî runs three more times faster.) <br><br>  The general scheme for parsing a request consists of the following steps: <br><br><ol><li>  Parsing; </li><li>  Semantic analysis; </li><li>  Rewriting the request (according to the rules, and both system and user); </li><li>  Optimization. </li></ol><br><br>  When preparing a request, it is analyzed and rewritten.  Optimization is performed again each time it is executed ‚Äî in this way, for each value of the binding variables, a ‚Äúprivate‚Äù plan is constructed. <br><br>  Consider an example of non-uniform data distribution (instead of a character variable, we can use the logical type): <br><br> <strong><code>alter table t add column</code></strong> <br> <strong><code>flag boolean;</code></strong> <br> <strong><code>update t</code></strong> <br> <strong><code>set flag = mod(id,1000)=0;</code></strong> <br> <strong><code>create index on t(flag);</code></strong> <br> <br>  The necessary histogram will be automatically constructed when analyzing the table: <br><br> <strong><code>analyze t;</code></strong> <br> <br>  Prepare the request: <br><br> <strong><code>prepare s1(boolean) as select * from t where flag = $1;</code></strong> <br> <br>  To find out which execution plan will be selected for the true value of the flag, you must use the explain command.  In Postgres, she is aware of the meaning and type of the binding variables and shows exactly the plan with which the command will be executed: <br><br> <strong><code>explain execute s1(true);</code></strong> <br> <code>QUERY PLAN</code> <br> <code>------------------------------------------------------------------------</code> <br> <code>Index Scan using t_flag_idx on t  (cost=0.29..14.31 rows=110 width=10)</code> <br> <code>Index Cond: (flag = true)</code> <br> <code>Filter: flag</code> <br> <br>  The optimizer intends to select 110 lines (also with a small error) and uses index access. <br><br>  The explain command is also convenient because it allows you not only to build a plan, but also to execute a command and immediately get both the expected and actual cardinality values.  Let's demonstrate this for another flag value: <br><br> <strong><code>explain analyze execute s1(false);</code></strong> <br> <code>QUERY PLAN</code> <br> <code>------------------------------------------------------------------------------------------------------</code> <br> <code>Seq Scan on t (cost=0.00..2958.00 rows=99890 width=10) (actual time=0.043..265.272 rows=99900 loops=1)</code> <br> <code>Filter: (NOT flag)</code> <br> <code>Rows Removed by Filter: 100</code> <br> <code>Execution time: 385.455 ms</code> <br> <br>  In this case, the optimizer expects to get 99890 rows (actually 99900) and adequately selects the full reading of the table. <br><br>  Here a problem arises that is the opposite of that which Oracle encounters: what if the plan does not depend on the values ‚Äã‚Äãof the binding variables?  In this case, it would be beneficial not to optimize the query every time. <br><br>  Indeed, Postgres can move from ‚Äúprivate‚Äù plans to a ‚Äúgeneric plan‚Äù, but does not do it right away.  The first five times the request is optimized in any case, and then preference is given to the general plan if its cost (as estimated by the optimizer) does not exceed the average cost of private plans.  The number five here is a certain compromise: a small value does not provide sufficient cost statistics for different values ‚Äã‚Äãof the binding variables, and a large value negates the optimization itself. <br><br>  Consider this mechanism for example with a uniform distribution of data: <br><br> <strong><code>prepare s2(integer) as select * from t where id = $1;</code></strong> <br> <strong><code>explain execute s2(1);</code></strong> <br> <code>QUERY PLAN</code> <br> <code>-----------------------------------------------------------------</code> <br> <code>Index Scan using t_pkey on t (cost=0.42..8.44 rows=1 width=10)</code> <br> <code>Index Cond: (id = 1)</code> <br> <br>  This is a private plan, as can be seen from the ‚ÄúIndex Cond: (id = 1)‚Äù condition ‚Äî a specific number is indicated here. <br><br>  However, if you call explain or simply execute the query four more times with any variable values, it will switch to the general plan: <br><br> <strong><code>execute s2(2);</code></strong> <br> <code>...</code> <br> <strong><code>execute s2(3);</code></strong> <br> <code>...</code> <br> <strong><code>execute s2(4);</code></strong> <br> <code>...</code> <br> <strong><code>execute s2(5);</code></strong> <br> <code>...</code> <br> <strong><code>explain execute s2(6);</code></strong> <br> <code>QUERY PLAN</code> <br> <code>-----------------------------------------------------------------</code> <br> <code>Index Scan using t_pkey on t (cost=0.42..8.44 rows=1 width=10)</code> <br> <code>Index Cond: (id = $1)</code> <br> <br>  Here in the condition ‚ÄúIndex Cond: (id = $ 1)‚Äù instead of a specific value, the number of the binding variable is indicated - this is a sign of a general plan.  Its cost in this case coincides with the cost of private plans. <br><br>  Now, a ready plan will be used for the request, which increases the efficiency of implementation (although it may lead to a problem in case of an error in calculating the cost or if the first five times turn out to be ‚Äúnot indicative‚Äù). <br><br><h1>  Conclusion </h1><br>  The decision to use the global cache of parsed queries in Orakle leads to the desire not to write to it more than is absolutely necessary - both because of the limited size and the danger of crowding out useful plans, and because of the competition of parallel processes for accessing the cache.  Therefore, Orakl starts with one general plan for the request and only if necessary passes to several private ones. <br><br>  On the contrary, the decision not to use the global cache in Postgrese makes it easier to treat unnecessary parsing.  Postgres, on the contrary, begins with private plans and then, if possible, moves on to the general. <br><br>  Orakl automatically caches query plans.  The developer in this regard is only required to remember to use bind variables, which is primarily dictated by the global cache constraints.  Because of the seriousness of the problem, Orakl even provides the parameter cursor_sharing, forcibly replacing all constants with variables. <br><br>  Postgres completely gives the decision about the need to save the parsed query in the hands of the developer - or a development tool.  The use of binding variables does not play such a dramatic role in productivity in Postgres (although the security issues from SQL injections are equally relevant for both systems). <br><br>  If several processes use the same request, in Orakle it will be parsed only one - the first - time.  The remaining processes will take advantage of a ready-made plan in the global cache. <br><br>  In Postgres, each process will have to parse the request itself.  But one-time requests are executed without the overhead of placing the plan in the cache. <br><br>  Each of the solutions has its advantages and disadvantages;  in any case, these features should be considered by developers and administrators who design, implement and maintain application systems. </div><p>Source: <a href="https://habr.com/ru/post/275755/">https://habr.com/ru/post/275755/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../275739/index.html">Cloud resizing of images</a></li>
<li><a href="../275745/index.html">Transponder DST40: principle of operation, the history of the appearance and hacking, as well as some practice on brute force</a></li>
<li><a href="../275747/index.html">How to transfer a site from Google Sites to your hosting</a></li>
<li><a href="../275749/index.html">Mission: Impossible: geolocation on Android without battery drain</a></li>
<li><a href="../275751/index.html">Centos 7.x USB Install Media (Add Centos to Multiboot)</a></li>
<li><a href="../275757/index.html">How to safely store and use secret data in R</a></li>
<li><a href="../275759/index.html">Highly accurate coordinates (+ -2cm) for virtual reality, kopter and robots</a></li>
<li><a href="../275761/index.html">Script automatic update DDNS for No-IP</a></li>
<li><a href="../275765/index.html">Considering difference schemes in Mathcad Express</a></li>
<li><a href="../275767/index.html">Own browser - the way the mouse: Theory</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>