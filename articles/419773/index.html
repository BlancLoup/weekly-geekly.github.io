<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>From zero to ‚ÄúActions on Google‚Äù hero: start</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hackathon Google, and all that is needed to start developing your applications for the assistant. 


 Google organized a hackathon dedicated to Action...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>From zero to ‚ÄúActions on Google‚Äù hero: start</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/ek/p5/kq/ekp5kqbvvl0p4mdidicbmgfw5b0.png" alt="image"><br><p>  Hackathon Google, and all that is needed to start developing your applications for the assistant. </p><br><p>  Google organized a hackathon dedicated to Actions On Google technology.  This is a good opportunity to gain experience and think about how to start making conversation user interface (CUI) for our applications.  Therefore, we assembled a team of two Android developers: <a href="https://habr.com/users/shipa_o/" class="user_link">shipa_o</a> , <a href="https://habr.com/users/raenardev/" class="user_link">raenardev</a> and designer <a href="https://habr.com/users/comradeguest/" class="user_link">comradeguest</a> and set off to participate. </p><a name="habracut"></a><br><h2>  What is Actions On Google? </h2><br><p>  Actions On Google (AoG) is a way to add your action to an assistant. <br>  This can be done using 4 tools: </p><br><ul><li>  <a href="https://developers.google.com/actions/content-actions/">Content Actions</a> ; </li><li>  <a href="https://developer.android.com/guide/slices/">Slices</a> ; </li><li>  <a href="https://developer.android.com/guide/actions/">App Actions</a> ; </li><li>  <a href="https://developers.google.com/actions/extending-the-assistant">Skill for google assistant</a> . </li></ul><br><p>  We made a skill on the hackathon - an application that expands the capabilities of the assistant, so we‚Äôll stop on it. </p><br><p> After the appeal ‚ÄúOkay, google.  I want to talk to <code>${_}</code> application_name <code>${_}</code> ‚Äù, the assistant opens the skill with which the user and the dialogue: </p><br><img src="https://habrastorage.org/webt/l2/vw/es/l2vwesoe1sywaswq0_8bmgjhhga.jpeg" alt="image" width="50%"><br><h3>  How to write a skill? <br></h3><br><p>  You will need two skills: <br>  - understanding of the work of the Conversational User Interface (CUI), the ability to design them; <br>  - ability to work with Natural Language Processing (NLP), for example, Dialogflow. </p><br><h4>  Stage 1: Design </h4><br><p>  To make your skill ever have a protein companion, it‚Äôs best to think about the future now.  Required will be those that take into account the context of use.  Interactive interfaces will be used when there is an opportunity to speak out loud, and it is more convenient and faster to interact with devices with voice than with hands, eyes and other parts of the body. </p><br><p>  Voice interface is consistent.  If you can show the entire order form on the graphic, and the person himself will choose what to look at first, and then what, then in the voice one can only ask questions one by one.  To come up with a compelling and convenient application, find the intersection between the user's needs and the possibility of using a voice interface (or the inability to use others). </p><br><p>  The first thing that comes to mind is a voice assistant for the blind, which helps to solve everyday tasks.  For example, place an order in a store, call a taxi, call relatives.  The second is a talking recipe book for housewives who have hands in flour.  The third is games in which you need to explain something. </p><br><p>  We decided to start with a simple and developed a robot that advises people to good movies.  We beat the imperfections of voice synthesizers: our assistant does not even pretend to be a man and in every possible way emphasizes his bright electronic individuality. </p><br><p>  Google wrote excellent <a href="https://developers.google.com/actions/extending-the-assistant">guidelines</a> on how to develop interactive interfaces.  And we will tell about how we designed our speaking firstborn. </p><br><p>  <b>1. Invocation</b> </p><br><p>  First you need to call an assistant.  The call can be explicit (Explicit Invocation) and indirect (Implicit Invocation).  Explicit treatment people will use when they already know the application.  An indirect need is for Google Assistant to recommend a suitable application in a specific situation.  Correctly chosen options for indirect treatment - as the right keywords in contextual advertising, only more "human". </p><br><table><tbody><tr><td>  Type of treatment </td><td><p>  Description </p><br></td><td>  Example </td></tr><tr><td>  Explicit Invocation </td><td>  With the mention of the name of the assistant </td><td><p><br>  Okay, Google, I want to talk to the Red passionate kinobot. <br>  Call me a movie boom. <br>  Where is there red and passionate? </p><br></td></tr><tr><td><br>  Indirect (Implicit Invocation) </td><td><br>  In context, when you need an assistant </td><td><br>  Okay, google, advise me some movie. <br>  I want to see a funny comedy. <br>  What movie to watch with a girl? </td></tr></tbody></table><br><p>  It is important that indirect calls are not too general.  As well as general keywords in contextual advertising, they only hinder the search for the necessary application and lower the application rating in the issue of the Assistant. </p><br><p>  Calls can contain a deep link to the individual functions of the voice assistant.  For example, usually our kinorobot begins communication with what offers a person to choose a genre.  But if they call him by indirect appeal ‚ÄúI want to see a funny comedy‚Äù, it is logical to start a dialogue with a proposal of a guaranteed good movie of the mentioned genre. </p><br><p>  <b>2. First greeting</b> </p><br><p>  The first greeting is what the application says to the person immediately after the call. <br>  First you need to let the user understand that the helper is already here: </p><br><blockquote>  Hi, protein life form.  I am a red passionate kinobot.  The purpose of my existence is to recommend good films to biological organisms. </blockquote><p>  And then - tell me what to do next.  Our robot is looking for films by genre, so we suggest, with which request a person can turn further: <br>  What do you want to see: maybe comedy, thriller or horror? </p><br><p>  New and experienced users can be welcomed in different ways.  If a person communicates with your assistant for the first time, you can tell a little about yourself.  If not at first, a long greeting will annoy him.  Therefore, you can go straight to the point: </p><br><table><tbody><tr><td>  First time </td><td><p>  Again </p><br></td></tr><tr><td>  Hi, protein life form.  I am a red passionate kinobot.  The purpose of my existence is to recommend good films to biological organisms.  What do you want to see: maybe comedy, thriller or horror? </td><td><br>  Greetings, man!  What genre are you interested in? </td></tr></tbody></table><br><p>  <b>3. Conversation in human terms.</b> </p><br><p>  Teach the helper to understand natural speech and keep up the conversation.  The easiest way to do this is to communicate with people from the target audience before developing.  Moreover, it is desirable verbally, and not in writing, because written speaking is more scarce than oral.  Play the role of a robot, and ask your interlocutor to imagine that he is using your future application.  Record all the dialogues on the recorder, and then decipher.  This will help design a pattern of a typical conversation and find where branches might appear. </p><br><h4>  Stage 2: Development </h4><br><p>  You can develop your own action for the assistant in several ways: </p><br><ul><li>  With Dialogflow. </li><li>  With Actions on Google SDK. </li><li>  You can process the text yourself - for example, if you have your own natural language processing solution (NLP). </li></ul><br><p>  The interaction of the assistant with your skill is drawn below. <br>  The dialogue looks like this: </p><br><ol><li><p>  The assistant translates the speech into text and sends it to your action. </p><br></li><li><p>  Text is processed by one of the above methods.  In this scheme - through Dialogflow. </p><br></li><li><p>  Dialogflow determines the intent (specific intent of the user) and receives <br>  from it entities (parameters). </p><br></li><li><p>  (Optional) Dialogflow can call the corresponding webhook, process the data on the backend and get a response. </p><br></li><li><p>  Dialogflow forms the answer. </p><br></li><li><p>  The assistant voices the answer, turns on the microphone and listens to what the user will say. </p><br></li></ol><br><img src="https://habrastorage.org/webt/ib/us/uf/ibusuffx_dlpg1eewj7ev4xcpzc.png" alt="image"><br><p>  <a href="https://www.youtube.com/watch%3Fv%3DHNfE0uaKcfY%26feature%3Dyoutu.be%26t%3D140">Assistant device action scheme</a> </p><br><h4>  Dialogflow </h4><br><p>  We will not describe in detail the basics of Dialogflow - Google released a good training video. </p><br><ol><li>  <a href="https://www.youtube.com/watch%3Fv%3D9aHusGxntPw">Intents</a> - about intent recognition, how exactly Dialogflow understands what the user is asking or what action he wants to perform. </li><li>  <a href="https://www.youtube.com/watch%3Fv%3DkzdL6GxJ_WY">Entities</a> - about the recognition of parameters within the phrase.  For example, in the case of recommending films, this is a specific genre. </li><li>  <a href="https://www.youtube.com/watch%3Fv%3D-tOamKtmxdY">Dialog Control</a> - about the mechanism of contexts (about it below) and fulfillment: how to handle the user's request itself by referring to your backend, and how to return something more interesting than a text response. </li></ol><br><p>  We will assume that you have already watched the video and sorted out the Dialogflow console.  Let's analyze the questions that arose in each of our parts in the process of implementation, and that something interesting can be noted. </p><br><p>  Remember also about the rules for building a good dialogue when you go to the implementation - it will affect a bunch of intents, a set of entities and their use in responses, the use of contexts and everything else. </p><br><h4>  Intents </h4><br><p>  There are <a href="https://designguidelines.withgoogle.com/conversation/conversational-components/errors.html">recommendations</a> to make a more detailed greeting for a new user, and for the rest to make it more concise.  How to implement it? </p><br><p>  In the Dialogflow console to determine this logic will not work.  This can be done inside the fulfillment for the welcome intent.  In other words, this will need to be done by hand. </p><br><p>  This also applies to error handling.  For example, the first time you can just ask again, and the second - tell you what kind of answer you expect from the user. </p><br><p>  Through responses, do not do this - a random response will be selected.  You can make it through fulfillment or a little tricky, tied to the context (see below). </p><br><h4>  Entities </h4><br><p>  <b>"Allow automated expansion" and sys.Any</b> </p><br><p>  If the phrase is similar in structure, then with the "Allow automated expansion" enabled, something can be recognized as a recognized entity that can still be handled with benefit. </p><br><p>  For example, your application recognizes the phrase "Advise me something from &lt;genre&gt;" for movie tips.  If you say "Advise me something from the food," then as a parameter "genre" you will not get what you would expect.  It makes sense if your set of genres is constantly dynamically updated on the backend, and the user‚Äôs response is processed there, but you don‚Äôt have time to update the entity. </p><br><p>  Another solution is to use sys.Any.  In this case, he will convey everything that was after the expected construction, which may be a whole sentence.  This gives more opportunities than automated expansion, but more disadvantages. </p><br><p>  <b>Singular and plural, cases, gender</b> </p><br><p>  Let's come up with a simple example.  We will talk about your favorite fruits, and the application will answer what they are cool.  In the examples below, P is the user, and A is our action. </p><br><blockquote>  P: Pineapples are the most delicious. <br>  A: Yes, pineapples are the coolest fruits! <br></blockquote><p>  In this example, we have an entity: Pineapples <br>  But what if the user says "Pineapple"?  We can add a synonym. </p><br><blockquote>  P: I liked the pineapple. <br>  A: Yes, pineapples are the coolest fruits! </blockquote><p>  By default, the reference form is used - i.e.  it is the original form, not its synonyms.  That is why the application does not say ‚ÄúYes, pineapple is the coolest fruit!‚Äù </p><br><p>  It is also worth considering when writing answers.  If we had the answer ‚ÄúYes, $ fruit is the coolest!‚Äú, We would get the following: </p><br><blockquote>  P: I liked the pineapple. <br>  A: Yes, pineapples are the coolest! </blockquote><p>  And do not forget about the cases: </p><br><blockquote>  P: I want drama. <br>  A: Here's a cool drama ... <br></blockquote><p>  Therefore, you should write both the initial values ‚Äã‚Äãof the entity and the answers in a consistent form.  For example, we can make all the original entity forms for fruits in the plural, and synonyms in any. </p><br><p>  We will do genres in Russian in the nominative case, but in any number (drama, horrors). </p><br><p>  When we get to the answers, we will not write at the same time ‚ÄúYes, $ fruit is the coolest fruit!‚Äù And ‚ÄúYes, $ fruit is the coolest!‚Äù - we always have fruits in the plural. </p><br><p>  In the case of the Russian language, it is worth going further and thinking how to write an agreed answer - we have not only cases (drama / drama), but also the gender (drama / western). </p><br><blockquote>  P: I want a western <br>  A: Here's a cool western ... <br></blockquote><br><blockquote>  P: I want a western <br>  A: Western?  Ok, here's a cool movie ... </blockquote><p>  But how to return exactly the entity form that the user said? </p><br><p>  In the case of genres, the synonym for "science fiction" might be "aliens."  Then, if the user said "aliens", "science fiction" would return as a parameter. <br>  If we want to get an entity in the form in which the user said, then it is worth choosing the value of $ entity.original </p><br><img src="https://habrastorage.org/webt/vf/eq/9f/vfeq9fm3m3dbgzmmyik5qxvvd0q.png" alt="image"><br><p>  But then there may be problems with inconsistency in the number and (especially) inconsistency of the cases.  Is it really necessary?  If so, create an entity for the singular, plural, and case.  Answers must also be consistent with the entity form that they use. </p><br><h4>  Contexts </h4><br><p>  Perhaps with this most problems. </p><br><p>  <b>Input context</b> </p><br><p>  This is the context to which a specific intent is attached.  Several intent can react to the same phrase, and most likely, the one that has the incoming context is active. <br>  Thus, it is possible, for example, to link the answer "yes / no" to a specific question, which is done when using follow-up intent in Dialogflow </p><br><p>  <b>Output context</b> </p><br><p>  This is the context that is activated when an intent is triggered.  This is how contexts are activated in the Dialogflow console (in a fulfillment, this can also be done).  We indicate the number of turns of the dialogue, during which it will be active, and after resetting the counter or after 20 minutes it is deactivated.  This means that the data inside this context will no longer be available and the intent for which it is the input will not work. </p><br><p>  Another trick is tied to this: you can activate the context with one intent, and manually deactivate it with another, simply by putting it as the output context for the second intent with the number of responses 0. </p><br><p>  If you don‚Äôt want to write code in a fulfillment, you can thus implement interesting logic, for example, using context as a counter, implement error handling when the assistant does not understand the user. </p><br><h4>  Dialogflow tips </h4><br><ul><li><p>  You do not need to restart the page with the assistant preview - when you made changes to the dialogflow agent, you can wait for the completion of its training and immediately repeat the unrecognized phrase in the simulator.  Dialogflow can be viewed as a backend to which the assistant refers. </p><br></li><li><p>  Use prebuilt agents - there you can see how to implement a typical scenario. </p><br></li><li><p>  Be careful with the Small talk section.  Using it does not turn off the microphone at the end of a conversation, and such answers usually do not contain call-to-action.  You do not direct the user to the next round of dialogue, and he does not quite understand what to say next.  Most likely because of this you can not pass a review.  It is better to make separate intents for this, if you can enter them into the dialogue. </p><br></li><li><p>  You should not edit the same intent together at the same time.  Now the simultaneous work of several people is not supported - it is not known whose changes will be overwritten. </p><br></li><li><p>  If you need to parallelize the work with the intent - it can be done in separate projects, and then just select the ones you need and transfer them.  Also import and export entities in json / xml and import / export for intent. </p><br></li><li><p>  Immediately it is worth considering that you write the action for a particular language.  Writing answers in Russian has additional nuances.  So localization of action looks more challenging than in the case of mobile apps GUI. </p><br></li><li><p>  Consider voice interface design rules - they affect not only the replica set, but also the structure as a whole.  You build a dialogue, so each answer must leave a call to action for the user to understand what to say. </p><br></li><li><p>  After everything is ready, and you start testing, do not be afraid to abandon individual branches of the dialogue or question forms.  Perhaps at the testing stage you will understand how to tie intents and what is missing for usability. </p><br></li></ul><br><h4>  Server connection </h4><br><p>  To connect the server you need to use fulfillment.  There are two options for this: </p><br><ul><li>  <strong>Webhook client</strong> .  <a href="https://dialogflow.com/docs/sdks">Multiple</a> languages ‚Äã‚Äãsupported. </li><li>  <strong>Inline Editor</strong> on Cloud Functions for Firebase (node.js). </li></ul><br><p>  Consider the simplest - Inline Editor. </p><br><p>  We do not pretend to be experts in node.js, correction of errors in comments is welcome. </p><br><p>  It is important to pay attention to the version of the API Dialogflow. <br>  Latest version v2.  All that is written for the v1 version does not work with it. <br>  You can read more about migration <a href="https://dialogflow.com/docs/reference/v1-v2-migration-guide">here</a> . </p><br><p>  Useful links: </p><br><ul><li>  <a href="https://github.com/dialogflow/dialogflow-fulfillment-nodejs">Documentation and library source code for working with dialogflow-fulfillment</a> </li><li>  <a href="https://dialogflow.com/docs/how-tos/getting-started-fulfillment">Getting started with Dialogflow fulfillment</a> </li><li>  <a href="https://dialogflow.com/docs/examples">Examples</a> </li><li>  Logs can be viewed here: <a href="">Go to the firebase console next to the Deploy button</a> </li></ul><br><h4>  Parse the standard template. </h4><br><div class="spoiler">  <b class="spoiler_title">When opening the Fulfillment section, the following code is displayed in the `index.js` file / tab:</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-string"><span class="hljs-string">'use strict'</span></span>; const <span class="hljs-keyword"><span class="hljs-keyword">functions</span></span> = require(<span class="hljs-string"><span class="hljs-string">'firebase-functions'</span></span>); const {WebhookClient} = require(<span class="hljs-string"><span class="hljs-string">'dialogflow-fulfillment'</span></span>); const {Card, Suggestion} = require(<span class="hljs-string"><span class="hljs-string">'dialogflow-fulfillment'</span></span>); process.env.<span class="hljs-keyword"><span class="hljs-keyword">DEBUG</span></span> = <span class="hljs-string"><span class="hljs-string">'dialogflow:debug'</span></span>; // enables lib debugging statements exports.dialogflowFirebaseFulfillment = <span class="hljs-keyword"><span class="hljs-keyword">functions</span></span>.https.onRequest((request, response) =&gt; { const agent = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> WebhookClient({ request, response }); console.log(<span class="hljs-string"><span class="hljs-string">'Dialogflow Request headers: '</span></span> + <span class="hljs-type"><span class="hljs-type">JSON</span></span>.stringify(request.headers)); console.log(<span class="hljs-string"><span class="hljs-string">'Dialogflow Request body: '</span></span> + <span class="hljs-type"><span class="hljs-type">JSON</span></span>.stringify(request.body)); <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> welcome(agent) { agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(`Welcome <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> my agent!`); } <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> fallback(agent) { agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(`I didn<span class="hljs-string"><span class="hljs-string">'t understand`); agent.add(`I'</span></span>m sorry, can you try again?`); } // // Uncomment <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> edit <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> make your own intent <span class="hljs-keyword"><span class="hljs-keyword">handler</span></span> // // uncomment `intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'your intent name here'</span></span>, yourFunctionHandler);` // // below <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">get</span></span> this <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> be run <span class="hljs-keyword"><span class="hljs-keyword">when</span></span> a Dialogflow intent <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> matched // <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> yourFunctionHandler(agent) { // agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(`This message <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> Dialogflow<span class="hljs-string"><span class="hljs-string">'s Cloud Functions for Firebase editor!`); // agent.add(new Card({ // title: `Title: this is a card title`, // imageUrl: '</span></span>https://developers.google.com/actions/images/badges/XPM_BADGING_GoogleAssistant_VER.png<span class="hljs-string"><span class="hljs-string">', // text: `This is the body text of a card. You can even use line\n breaks and emoji! `, // buttonText: '</span></span>This <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a button<span class="hljs-string"><span class="hljs-string">', // buttonUrl: '</span></span>https://assistant.google.com/<span class="hljs-string"><span class="hljs-string">' // }) // ); // agent.add(new Suggestion(`Quick Reply`)); // agent.add(new Suggestion(`Suggestion`)); // agent.setContext({ name: '</span></span>weather<span class="hljs-string"><span class="hljs-string">', lifespan: 2, parameters: { city: '</span></span>Rom<span class="hljs-string"><span class="hljs-string">e' }}); // } // // Uncomment and edit to make your own Google Assistant intent handler // // uncomment `intentMap.set('</span></span>your intent <span class="hljs-type"><span class="hljs-type">name</span></span> her<span class="hljs-string"><span class="hljs-string">e', googleAssistantHandler);` // // below to get this function to be run when a Dialogflow intent is matched // function googleAssistantHandler(agent) { // let conv = agent.conv(); // Get Actions on Google library conv instance // conv.ask('</span></span>Hello <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> the Actions <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> Google client library!<span class="hljs-string"><span class="hljs-string">') // Use Actions on Google library // agent.add(conv); // Add Actions on Google library responses to your agent'</span></span>s response // } // // See https://github.com/dialogflow/dialogflow-fulfillment-nodejs/tree/master/samples/actions-<span class="hljs-keyword"><span class="hljs-keyword">on</span></span>-google // // <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> a complete Dialogflow fulfillment library Actions <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> Google client library v2 integration sample // Run the proper <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-keyword"><span class="hljs-keyword">handler</span></span> based <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> the matched Dialogflow intent <span class="hljs-type"><span class="hljs-type">name</span></span> let intentMap = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Map(); intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'Default Welcome Intent'</span></span>, welcome); intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'Default Fallback Intent'</span></span>, fallback); // intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'your intent name here'</span></span>, yourFunctionHandler); // intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'your intent name here'</span></span>, googleAssistantHandler); agent.handleRequest(intentMap); });</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">And such dependencies in the file / tab `package.json`:</b> <div class="spoiler_text"><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"dialogflowFirebaseFulfillment"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"description"</span></span>: <span class="hljs-string"><span class="hljs-string">"This is the default fulfillment for a Dialogflow agents using Cloud Functions for Firebase"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"version"</span></span>: <span class="hljs-string"><span class="hljs-string">"0.0.1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"private"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"license"</span></span>: <span class="hljs-string"><span class="hljs-string">"Apache Version 2.0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"author"</span></span>: <span class="hljs-string"><span class="hljs-string">"Google Inc."</span></span>, <span class="hljs-attr"><span class="hljs-attr">"engines"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"node"</span></span>: <span class="hljs-string"><span class="hljs-string">"~6.0"</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"scripts"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"start"</span></span>: <span class="hljs-string"><span class="hljs-string">"firebase serve --only functions:dialogflowFirebaseFulfillment"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"deploy"</span></span>: <span class="hljs-string"><span class="hljs-string">"firebase deploy --only functions:dialogflowFirebaseFulfillment"</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"dependencies"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"actions-on-google"</span></span>: <span class="hljs-string"><span class="hljs-string">"2.0.0-alpha.4"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"firebase-admin"</span></span>: <span class="hljs-string"><span class="hljs-string">"^4.2.1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"firebase-functions"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.5.7"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"dialogflow"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.1.0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"dialogflow-fulfillment"</span></span>: <span class="hljs-string"><span class="hljs-string">"0.3.0-beta.3"</span></span> } }</code> </pre> </div></div><br><p>  First of all, update the dependencies of alpha and beta versions to the latest stable ones. </p><br><div class="spoiler">  <b class="spoiler_title">Here are the latest versions for now.</b> <div class="spoiler_text"><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"dependencies"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"actions-on-google"</span></span>: <span class="hljs-string"><span class="hljs-string">"^2.2.0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"firebase-admin"</span></span>: <span class="hljs-string"><span class="hljs-string">"^5.2.1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"firebase-functions"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.6.2"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"dialogflow"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.6.0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"dialogflow-fulfillment"</span></span>: <span class="hljs-string"><span class="hljs-string">"^0.5.0"</span></span> } }</code> </pre> </div></div><br><p>  And now let's look at the code in more detail. </p><br><div class="spoiler">  <b class="spoiler_title">Add import is done on top.</b> <div class="spoiler_text"><pre> <code class="hljs perl">// Cloud Functions  Firebase library const functions = <span class="hljs-keyword"><span class="hljs-keyword">require</span></span>(<span class="hljs-string"><span class="hljs-string">'firebase-functions'</span></span>); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>       const <span class="hljs-string"><span class="hljs-string">{WebhookClient}</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">require</span></span>(<span class="hljs-string"><span class="hljs-string">'dialogflow-fulfillment'</span></span>); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>       const {Card, Suggestion} = <span class="hljs-keyword"><span class="hljs-keyword">require</span></span>(<span class="hljs-string"><span class="hljs-string">'dialogflow-fulfillment'</span></span>);</code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">The whole point of fulfillment is to override the callback-a `dialogflowFirebaseFulfillment`</b> <div class="spoiler_text"><pre> <code class="hljs ruby">exports.dialogflowFirebaseFulfillment = functions.https.onRequest((request, response) =&gt; { console.log(<span class="hljs-string"><span class="hljs-string">'Dialogflow Request headers: '</span></span> + JSON.stringify(request.headers)); console.log(<span class="hljs-string"><span class="hljs-string">'Dialogflow Request body: '</span></span> + JSON.stringify(request.body)); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>   . const agent = new WebhookClient({ request, response }); <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>   let result = request.body.queryResult; <span class="hljs-regexp"><span class="hljs-regexp">//</span></span>  action  entities <span class="hljs-symbol"><span class="hljs-symbol">https:</span></span>/<span class="hljs-regexp"><span class="hljs-regexp">/dialogflow.com/docs</span></span><span class="hljs-regexp"><span class="hljs-regexp">/actions-and-parameters let action = result.action; let parameters = result.parameters; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/    https:/</span></span><span class="hljs-regexp"><span class="hljs-regexp">/dialogflow.com/docs</span></span><span class="hljs-regexp"><span class="hljs-regexp">/contexts let outputContexts = result.outputContexts; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/       let intentRequest = request.body.originalDetectIntentRequest; });</span></span></code> </pre> </div></div><br><p>  This callback will be called for those intent with which you activate fullfilment. </p><br><div class="spoiler">  <b class="spoiler_title">Now redefine the answer to intent.</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">exports.dialogflowFirebaseFulfillment = <span class="hljs-keyword"><span class="hljs-keyword">functions</span></span>.https.onRequest((request, response) =&gt; { const agent = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> WebhookClient({ request, response }); <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> welcome(agent) { //   agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(`Welcome <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> my agent!`); } <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> fallback(agent) { agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(`I didn<span class="hljs-string"><span class="hljs-string">'t understand`); agent.add(`I'</span></span>m sorry, can you try again?`); } //   ,  : // key -   intent-. // <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> -   ,   . let intentMap = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Map(); intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'Default Welcome Intent'</span></span>, welcome); intentMap.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'Default Fallback Intent'</span></span>, fallback); agent.handleRequest(intentMap); });</code> </pre> </div></div><br><p>  In this case, the code completely replaces the response of the intent from the Responses section. <br>  Responses will only be called if the callback fails, so error handling can be done there. </p><br><p>  We take out the functions of processing the intent from the callback. <br>  The welcome and fallback functions are in <a href="https://developer.mozilla.org/ru/docs/Web/JavaScript/Closures">closure</a> . </p><br><div class="spoiler">  <b class="spoiler_title">To get them out of the callback, you have to add the transfer of the function context and parameters via `bind`</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">exports.dialogflowFirebaseFulfillment = <span class="hljs-keyword"><span class="hljs-keyword">functions</span></span>.https.onRequest((request, response) =&gt; { const agent = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> WebhookClient({ request, response }); let intentMap = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Map(); //  <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>  Map.      intentMap .<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'Default Welcome Intent'</span></span>, welcome.bind(this, agent)) .<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(<span class="hljs-string"><span class="hljs-string">'Default Fallback Intent'</span></span>, fallback.bind(this, agent)); agent.handleRequest(intentMap); }); <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> welcome(agent) { agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>(`Welcome <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> my agent!`); } <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> fallback(agent) { //   <span class="hljs-number"><span class="hljs-number">2</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">add</span></span>    agent.<span class="hljs-keyword"><span class="hljs-keyword">add</span></span>([ `I didn<span class="hljs-string"><span class="hljs-string">'t understand`, `I'</span></span>m sorry, can you try again?` ]); }</code> </pre> </div></div><br><p> ,     ,       Google Assistant.  ,       . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/419773/">https://habr.com/ru/post/419773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../419763/index.html">Examples of calculating the "availability factor" for sets of network equipment</a></li>
<li><a href="../419765/index.html">The course "Web programming languages" (based on Ruby) from MSTU. N. E. Bauman on Tehnostrim channel</a></li>
<li><a href="../419767/index.html">The creator of Wikipedia answers the questions: programming, sleep, books, tips "for life"</a></li>
<li><a href="../419769/index.html">WireGuard will ‚Äúcome‚Äù to the Linux kernel - why?</a></li>
<li><a href="../419771/index.html">Fintech-digest: Central Bank speeds up the collection of biometrics of customers, cryptocurrency is falling, and the volume of the Internet of things market is growing</a></li>
<li><a href="../419775/index.html">My version of the "device for lucid dreaming" - a brief history and description of the first version</a></li>
<li><a href="../419777/index.html">How to sell NNN servers in the Netherlands and not stay with bare enthusiasm: the secrets of sales</a></li>
<li><a href="../419779/index.html">Grown lungs are successfully transplanted to a pig, in 5 years human tests are possible.</a></li>
<li><a href="../419781/index.html">SpaceX held the first Mars Workshop</a></li>
<li><a href="../419785/index.html">How MSTP works</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>