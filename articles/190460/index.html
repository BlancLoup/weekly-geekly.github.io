<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Google Research: Fast, accurate identification of 100,000 categories of objects on a single machine.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="People can distinguish between approximately 10,000 high-level visual categories, but we can distinguish between a much larger range of visual impulse...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Google Research: Fast, accurate identification of 100,000 categories of objects on a single machine.</h1><div class="post__text post__text-html js-mediator-article">  People can distinguish between approximately 10,000 high-level visual categories, but we can distinguish between a much larger range of visual impulses called <i>special signs</i> .  These signs may correspond to parts of the object, animal extremities, architectural details, objects on the ground and other visual images, the names of which we do not know, but it is this much larger set of signs that we use as the basis for the reconstruction and explanation of our daily visual experience. <a name="habracut"></a>  Such signs provide components for more complex visual impulses and create a context that is important for us to resolve ambiguous compositions. <br><br>  In contrast to the current practice of computer visual perception, the explanatory context necessary for solving visual details may not only be entirely local.  A flashing fast red bouncing signal along the ground can be a child's toy in the context of a playground or a rooster in the context of a barnyard.  It would be useful to have a large number of detectors of items capable of signaling the presence of such items, including detectors for sandboxes, swings, slides, cows, chickens, sheep, and agricultural machinery, necessary for context recognition in order to distinguish between these two options. <br><br>  The winners of the CVPR Best Paper Award (for the best report on computer vision and image recognition) this year, in collaboration with the Googlers team, which includes Tom Dean, Mark Ruzon, Mark Segal, Jonathan Shlens, Subhindra Vigyanarasimhan and Jay Yagnik, describe the technology that allow the computer vision system to extract the necessary type of semantically rich contextual information necessary for recognizing visual categories, even if careful viewing of the pixels covering the object in question may not be enough to identify them  pecifications the absence of such contextual clues.  In particular, we consider the main operation in machine vision, which includes determining the level of each specific location of objects in an image where a particular object may be present. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      This is the so-called <i>convolution</i> operator, which is one of the key elements used in machine vision and, more generally, in the processing of all signals.  Unfortunately, computationally, it is expensive and, therefore, researchers use it sparingly or use exotic SIMD hardware, such as graphics processors and FPGAs, to reduce computational overhead.  Let's turn everything upside down to show how quick tabular search can be used - a method called hashing - to exchange time for space, replacing the computationally expensive inner contour of the convolution operator - the sequence of multiplication and addition operations necessary to perform millions of convolutions. tabular search. <br><br>  We demonstrate the advantages of our approach by scaled object detection, bringing it from its current state with the involvement of several hundred or, at most, several thousand categories of objects to 100,000 categories, which would be the equivalent of over a million convolutions.  In addition, our demonstration was held on a single ordinary computer, which only needs a few seconds for each image.  The core technology is used in several parts of the Google infrastructure and can be applied to solving problems outside of computer vision, such as hearing signal processing. <br><br>  On Wednesday, June 26, Google‚Äôs engineers responsible for the research were awarded for the best talk at the IEEE Computer Vision and Pattern Recognition Conference held in Portland, Oregon. <br><br>  The full report can be found <a href="http://research.google.com/pubs/pub40814.html">here</a> . <br><br>  <b>The purpose of the publication on Habr√©:</b> to read comments about the prospects of technology based on this study and their application in the Internet. <br><br>  <b>PS</b> <br>  This is my first post on Habr√©.  I will be glad to your comments.  And do not judge strictly. <br>  Due to the lack of karma, there is no possibility to publish in the hubs "Artificial Intelligence" and "Google". <br>  I would be grateful if you tell me how to transfer to the specified hubs. </div><p>Source: <a href="https://habr.com/ru/post/190460/">https://habr.com/ru/post/190460/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../190444/index.html">10 myths about home 3D printing</a></li>
<li><a href="../190450/index.html">Google fell by two minutes - the volume of world traffic has decreased by 40%</a></li>
<li><a href="../190454/index.html">An overview of the open Adobe Brackets IDE</a></li>
<li><a href="../190456/index.html">Interstellar travel: from point A to point B</a></li>
<li><a href="../190458/index.html">I love graphics programming</a></li>
<li><a href="../190462/index.html">YouTube for the sake of experiment offers to disable advertising on the site</a></li>
<li><a href="../190464/index.html">The srcset WebKit attribute guide in img tag</a></li>
<li><a href="../190466/index.html">Florida, are going to use drones to fight mosquitoes</a></li>
<li><a href="../190468/index.html">Crossed the border - lost e-books</a></li>
<li><a href="../190472/index.html">The most popular article in a scientific journal</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>