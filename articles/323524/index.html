<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Learning to learn. Create self-improving AI</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Learning to learn 
 This time I conducted experiments on the topic of learning to learn, that is, algorithms that can learn how best to learn. 

 Obje...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Learning to learn. Create self-improving AI</h1><div class="post__text post__text-html js-mediator-article"><h2>  Learning to learn </h2><br>  This time I conducted experiments on the topic of learning to learn, that is, algorithms that can learn how best to learn. <br><img src="https://habrastorage.org/files/31c/8e8/6e4/31c8e86e4d024d9cbf9f09ba51ed7bab.jpg"><br>  Objectives of the experiment: <br><br>  1) Create an optimization algorithm that can be adapted in any standard way to any optimization problem or a set of problems.  By the word "adapt" I mean "to make the algorithm very well cope with this task." <br>  2) Adjust the algorithm for one task and see how its efficiency has changed in other tasks. <br><a name="habracut"></a><br><h2>  Why are optimization algorithms important at all? </h2><br>  Because so many tasks can be reduced to optimization problems.  For example, in this <a href="https://habrahabr.ru/post/323424/">article</a> you can see how to reduce the task of driving a vehicle to an optimization problem. <br>  In the example, we will test the algorithm on more traditional optimization problems, since this test will take less time than learning the neural network. <br><br><h2>  Task list </h2><br>  Our algorithm will have the following tasks: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      1) The problem of polynomial regression.  Given a certain function, it is necessary to construct a curve that will approximate the graph of this function by a graph of a 7th degree polynomial.  The optimizer selects regression coefficients.  The quality metric in this task is equal to the average deviation between the actual graph and the approximation.  The function has many local optima, but it is smooth. <br>  2) The problem on the quadratic function.  The quality metric q = (k1-10) ^ 2 + (k2 + 15) ^ 2 + (k3 + 10 * k4-0.06) ^ 2 + ..., that is, it is equal to the sum of squares of certain linear functions of the coefficients that the optimizer selects .  The function has many minima, but it is smooth. <br>  3) The problem on a discrete function.  The quality metric is calculated using the following algorithm: q = 1;  if (k1&gt; -2) {q + = 3};  if (k1 &lt;0.2) {q + = 15}; ..., then the graph of the function of any variable will look like a certain step line.  The function has few local optima, but it is not smooth. <br><br>  As a training task, I will apply task 2 (to a quadratic function), the other two as test ones. <br><br><h2>  Optimizer </h2><br>  As an optimizing algorithm, I will use my own hand-written ensemble of algorithms, which I called Abatur.  This ensemble includes several variants of coordinate descent, gradient descent, evolution, algorithm of a bee swarm.  And the control algorithm, which with different probability causes different modules. <br><br>  This is the main block of decision making in Abatura. <br><br><pre><code class="matlab hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> <span class="hljs-built_in"><span class="hljs-built_in">i</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span>:sz(<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-comment"><span class="hljs-comment">%optimizerData.optimizers -    reputation(i)=optimizerData.optimizers{i}.reputation; %optimizerData.optimizers{i}.reputation -    ,      reputationR(i)=reputation(i)*(1+0.5*randD()); end; [ampl,arg]=max(reputationR); [newK,dt]=feval(optimizerData.optimizers{arg}.name,optimizerData); optimizerData.dt=optimizerData.dt+dt; valNew=feval(optimizerData.func,newK); if(valNew&gt;=valOld) optimizerData.kArr=newK; valOld=valNew; end;</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">An example of an optimizer for Abatura.</b>  <b class="spoiler_title">Gradient descent</b> <div class="spoiler_text"><pre> <code class="matlab hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[kArrOld,dt]</span></span></span><span class="hljs-function"> = </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">constrainedGrad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kStep</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(16)</span></span></span><span class="hljs-function">;% </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-function"> -   .    .     . </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">stepGrad</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(19)</span></span></span><span class="hljs-function">;%    .  ,   </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sz</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">size</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData.kArr)</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArr</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">valOld</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">feval</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData.func,kArrOld)</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trg</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">randDS</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sz(2)</span></span></span><span class="hljs-function">)&lt;</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(17)</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">grad</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">zeros</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sz)</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dt</span></span></span><span class="hljs-function">=1+</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">floor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData.k(18)</span></span></span><span class="hljs-function">)*</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sum</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(trg)</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">for</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">j</span></span></span><span class="hljs-function">=1:</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(18)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">for</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">i</span></span></span><span class="hljs-function">=1:</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sz</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(2)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">if</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(trg(i)</span></span></span><span class="hljs-function">) </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">+</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">stepGrad</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">grad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">=</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feval(optimizerData.func,kArrOld)</span></span></span><span class="hljs-function">-</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">valOld</span></span></span><span class="hljs-function">)/</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">stepGrad</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">-</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">stepGrad</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">else</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">grad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">=0; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">end</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">end</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-function">+</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">grad</span></span></span><span class="hljs-function">*</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kStep</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">valNew</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">feval</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData.func,kArrOld)</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">if</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(valNew&gt;valOld)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">valOld</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">valNew</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">else</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-function">+</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">grad</span></span></span><span class="hljs-function">*</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kStep</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">end</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">end</span></span></span><span class="hljs-function">; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">end</span></span></span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Another optimizer for Abatura.</b>  <b class="spoiler_title">One of the evolutionary strategies</b> <div class="spoiler_text"><pre> <code class="matlab hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[kArrOld,dt]</span></span></span><span class="hljs-function"> = </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evolutionLight</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dt</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">abs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(round(optimizerData.k(32)</span></span></span><span class="hljs-function">)*</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">round</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData.k(37)</span></span></span><span class="hljs-function">)); </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kArrOld</span></span></span><span class="hljs-function">=</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evolutionRaw</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(optimizerData.func,optimizerData.kArr,optimizerData.k(32)</span></span></span><span class="hljs-function">,</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(33)</span></span></span><span class="hljs-function">,</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(34)</span></span></span><span class="hljs-function">,</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(35)</span></span></span><span class="hljs-function">,</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(36)</span></span></span><span class="hljs-function">,</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">optimizerData</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(37)</span></span></span><span class="hljs-function">); %   </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evolution</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">raw</span></span></span><span class="hljs-function">:  ,  ,  ,   </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(,  )</span></span></span><span class="hljs-function">,   ,  ,    ,   </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">end</span></span></span></span></code> </pre><br></div></div><br>  optimizerData.k is an array of Abatura parameters.  As can be seen in the code above, these parameters determine everything: the steps of the gradient descent, the size of the populations, the likelihood of an optimizer to work. <br><br>  Abatur himself cannot change these parameters, but some other algorithm that is engaged in Abatura optimization can change them.  Abatura training consists in selecting parameters k that maximize its metric. <br><br><h2>  Quality metric learning to learn </h2><br>  To optimize the ability to optimize it is necessary in some way to measure this very ability to optimize.  I applied the lrvt (logarithm-relative-value-time) metric. <br>  Lrvt = ((log (abs (valOld / valNew)) / log (10))) / log (dt + 10) <br>  ValOld - quality metric before optimization <br>  ValNew - quality metric after optimization <br>  Dt is the number of calculations of the function being optimized during optimization. <br><br>  I did not come up with this metric one time, it is the result of a long evolution of my quality metrics.  This metric correlates with valOld / valNew, that is, with the quantitative value of the upgrade and anti-correlates with dt, that is, the time spent on the upgrade. <br><br><h2>  Test 1. Gradient descent. </h2><br>  Let's run the gradient descent algorithm on all three of the listed tasks - just to have something to compare Abatur with.  The step number is plotted on the horizontal axis, and the quality metric on the vertical axis (the ideal solution is found if it is 0). <br><br>  1) Regression. <br><br><img src="https://habrastorage.org/files/91e/870/cef/91e870cef6bf4b39b13d64cb5e5b2fd4.png"><br><br>  Gradient descent lowered q from 1.002 to 0.988 per 100 cycles.  Weak, but stable. <br><br>  2) Quadratic function <br><br><img src="https://habrastorage.org/files/d3f/b45/994/d3fb459941f1483ebf86a258034fff55.png"><br><br>  Gradient descent lowered q from 140 to about 5 per 100 cycles.  Strong, but the algorithm has already reached saturation. <br><br>  3) Discrete function <br><br><img src="https://habrastorage.org/files/200/d9a/02c/200d9a02c47942118bb84049802a090e.png"><br><br>  Gradient descent lowered q from 3663.06 to 3662.98 per 100 cycles.  Very weak, very unstable. <br><br><h2>  Test 2. Abatur with default settings. </h2><br>  Now we will run Abatur with standard settings on the same tasks. <br><br>  1) Regression <br><br><img src="https://habrastorage.org/files/a2f/7f9/7ab/a2f7f97abe9b4b8c98254a79517e81b0.png"><br><br>  Reduced q from 1 to 0.91 in 20 cycles (in the remaining 80 cycles, he did nothing).  Weak, but much stronger than the gradient descent (which lowered from 1.002 to 0.988).  And extremely unstable. <br><br>  2) Quadratic function. <br><br><img src="https://habrastorage.org/files/645/6d5/703/6456d5703e2742c9ac4d6cd185131b85.png"><br><br>  Reduced q from 189 to 179 in 50 cycles (gradient descent lowered q from 140 to about 5).  In this situation, Abatur proved to be unstable and ineffective. <br><br>  3) Discrete function. <br><br><img src="https://habrastorage.org/files/448/876/0c9/4488760c9e2b4631a1bf423a26b3e4ab.png"><br><br>  Reduced q from 3663.27 to 3662.98.  Very weak, very unstable. <br><br>  <b>Test 3. Abathur trained.</b> <br><br>  We teach Abatur on a quadratic function.  As a learning algorithm we use Abatur with standard settings. <br><br>  1) Regression. <br><br>  The blue lines show the optimization process before learning.  Red - after. <br><br><img src="https://habrastorage.org/files/e9e/9d6/045/e9e9d604528c43a0abfbb532990d7453.png"><br><br>  Abathur trained improved the value from about 1 to about 0.17.  Much better and the old Abatura, and gradient descent. <br><br>  2) Quadratic function. <br><br><img src="https://habrastorage.org/files/0c0/7db/0c6/0c07db0c6b41416ea855a22a0556362c.png"><br><br>  Abathur trained improved the value from about 190 to a number less than 1. Much better than the old Abatura and gradient descent. <br><br>  3) Discrete function <br><br><img src="https://habrastorage.org/files/0c9/3e4/e99/0c93e4e9940d4f699e2873dbcadde30d.png"><br><br>  Abathur trained improved the value from about 3,600 to 0.01.  Much better and the old Abatura, and gradient descent (which did not cope at all). <br><br><h2>  Summary </h2><br>  1) Learning optimization algorithm created.  The shell for his training is created. <br>  2) I trained Abatur on one task.  He became better to solve all the above tasks.  Consequently, the algorithm selected heuristics, which in total are suitable for solving any problem from the list. <br><br><h2>  Sources of literature: </h2><br>  1) <a href="https://arxiv.org/pdf/1606.04474.pdf">‚ÄúLearning to learn by gradient descent‚Äù</a> <br>  2) <a href="https://en.wikipedia.org/wiki/Meta_learning_(computer_science)">‚ÄúMetalearning‚Äù</a> </div><p>Source: <a href="https://habr.com/ru/post/323524/">https://habr.com/ru/post/323524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../323514/index.html">CocoaHeads video footage March 1, 2017</a></li>
<li><a href="../323516/index.html">Complete latent semantic analysis with Python tools</a></li>
<li><a href="../323518/index.html">Development for Sailfish OS: Qt / C ++ Unit Testing under Sailfish OS</a></li>
<li><a href="../323520/index.html">Write me money: iMessage transfers</a></li>
<li><a href="../323522/index.html">Analyzing book recommendations for developers with Stack Overflow using Python tools</a></li>
<li><a href="../323526/index.html">Magic newtype in haskell</a></li>
<li><a href="../323528/index.html">Quality management system: how to understand the standards and start the process of their implementation in the company</a></li>
<li><a href="../323532/index.html">Turquoise Organizations: Examples and Common Answers</a></li>
<li><a href="../323534/index.html">Crowdinvesting in Russia: the StartTrack Experience</a></li>
<li><a href="../323536/index.html">An example of enterprise anti-virus integration with a SIEM platform. Part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>