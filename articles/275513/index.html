<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Docker: Environment for testing</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The last five years have brought a huge amount of technology into our lives, with the help of which you can quickly create isolated environments for d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Docker: Environment for testing</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/56d/453/ae2/56d453ae225c427ea1bd48e9a152d5fd.png"><br><br>  The last five years have brought a huge amount of technology into our lives, with the help of which you can quickly create isolated environments for development and testing.  But despite this, organizing a stable environment for testing is far from an easy task.  And if you need to test the network interaction of components and analyze the maximum level of load on them, then the task becomes even more difficult.  Adding the ability to quickly deploy the environment and the flexible configuration of individual components, we can get a small interesting project. <br>  In this article we will talk in detail about creating an environment based on Docker containers for testing our client-server application.  At the same time, if you look globally, this article will be a good illustration of the use of Docker and its nearest ecosystem. <br><a name="habracut"></a><br><h4>  Formulation of the problem </h4><br>  Our application collects, analyzes and stores all possible types of log files.  The main task of the environment is to conduct initial testing of the service under load. <br>  So, what we have: <br><ul><li>  Our service, written in Go and has a client-server architecture. </li><li>  The service is able to simultaneously write data to the storage of various types.  This point is very important when building the environment for testing. </li><li>  Developers need the ability to quickly and painlessly reproduce the faults found on the test environment. </li><li>  We need to test the networking of components in a distributed environment on multiple network nodes.  To do this, you need to analyze the traffic flow between clients and servers. </li><li>  We need to monitor resource consumption and ensure that the daemon is stable under high loads. </li><li>  And, of course, we want to look at all possible metrics in real time and on the results of testing. </li></ul><br>  As a result, we decided to build an environment for testing on the basis of Docker and related technologies.  This allowed us to realize all our requests and efficiently use the available hardware resources without having to buy a separate server for each individual component.  In this case, the hardware resources can be a separate server, a set of servers, or even a developer‚Äôs laptop. <br><br><h4>  Environment Architecture for Testing </h4><br>  First, consider the main components of the architecture: <br><ul><li>  An arbitrary number of server instances of our application. </li><li>  An arbitrary number of agents. </li><li>  Separate data storage environments such as ElasticSearch, MySQL or PostgreSQL. </li><li>  Load generator (we implemented a simple stress generator, but you can use any other, for example, Yandex.Tank or Apache Benchmark). </li></ul><br>  The environment for testing should be easy to lift and maintain. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We built a distributed network environment using Docker containers, isolating our and external services, and the docker-machine, which allows you to organize an isolated space for testing.  As a result, the architecture of the test environment looks like this: <br><br><img src="https://habrastorage.org/files/7b2/5bc/353/7b25bc35386d4bfeb866e67eaf1acf93.png"><br><br>  To visualize the environment, we use Weave Scope, as it is a very convenient and intuitive service for monitoring Docker containers. <br><br><img src="https://habrastorage.org/files/76c/afc/409/76cafc409504412b98a1036aaa936ac3.jpg"><br><br>  With this approach, it is convenient to test the interaction of SOA components, for example, small client-server applications like ours. <br><br><h4>  Implementing the base environment </h4><br>  Further, we will take a closer look at each step of creating a test environment based on Docker containers, using docker-compose and docker-machine. <br>  Let's start with the docker-machine, which allows us to painlessly isolate the test virtual environment.  In this case, it will be very convenient for us to work with this environment directly from the host system. <br>  So, create a test machine: <br><br><pre><code class="bash hljs">$ docker-machine create -d virtualbox testenv Creating VirtualBox VM... Creating SSH key... Starting VirtualBox VM... Starting VM... To see how to connect Docker to this machine, run: docker-machine env testenv</code> </pre> <br>  <i>This command creates a VirtualBox VM with CoreOS and Docker installed inside it (ready for work) (If you are using Windows or MacOS, it is recommended to install the Docker Toolbox, which already contains everything. And if you are using Linux, you need to install docker, docker-machine , docker-compose and VirtualBox independently).</i>  <i>We recommend that you familiarize yourself with all the features of the docker-machine, it is quite a powerful tool for managing environments.</i> <br><br>  As you can see from the output of this command, the docker-machine creates everything necessary for working with the virtual machine.  Once created, the virtual machine is up and running.  Let's check: <br><br><pre> <code class="bash hljs">$ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM testenv virtualbox Running tcp://192.168.99.101:2376</code> </pre><br>  Great, the virtual machine is running.  It is necessary to activate access to it in our current session.  Let's return to the previous step and carefully look at the last line: <br><br><pre> <code class="bash hljs">To see how to connect Docker to this machine, run: docker-machine env testenv</code> </pre><br>  This is an autosetup for our session.  Having executed this command we will see the following: <br><br><pre> <code class="bash hljs">$ docker-machine env testenv <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> DOCKER_TLS_VERIFY=<span class="hljs-string"><span class="hljs-string">"1"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> DOCKER_HOST=<span class="hljs-string"><span class="hljs-string">"tcp://192.168.99.101:2376"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> DOCKER_CERT_PATH=<span class="hljs-string"><span class="hljs-string">"/Users/logpacker/.docker/machine/machines/testenv"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> DOCKER_MACHINE_NAME=<span class="hljs-string"><span class="hljs-string">"testenv"</span></span> <span class="hljs-comment"><span class="hljs-comment"># Run this command to configure your shell: # eval "$(docker-machine env testenv)"</span></span></code> </pre><br>  This is just a set of environment variables that will tell your local docker client where to look for the server.  The last line is a hint.  Run this command and look at the output of the <code>ls</code> : <br><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(docker-machine env testenv)</span></span></span><span class="hljs-string">"</span></span> $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM testenv * virtualbox Running tcp://192.168.99.101:2376</code> </pre><br>  In the <code>ACTIVE</code> column, our active machine is marked with an asterisk.  Please note that the machine is active within the current session only.  We can open another terminal window and activate another machine there.  This can be useful for testing, for example, orchestration with Swarm.  But this is a topic for a separate article :). <br>  Next, check our docker server: <br><br><pre> <code class="bash hljs">$ docker info docker version Client: Version: 1.8.0 API version: 1.20 Go version: go1.4.2 Git commit: 0d03096 Built: Tue Aug 11 17:17:40 UTC 2015 OS/Arch: darwin/amd64 Server: Version: 1.9.1 API version: 1.21 Go version: go1.4.3 Git commit: a34a1d5 Built: Fri Nov 20 17:56:04 UTC 2015 OS/Arch: linux/amd64</code> </pre><br>  Focusing on OS / Arch, there will always be linux / amd64, since the docker server is running in a VM, you need to remember that.  Let's digress and look inside the VM: <br><br><pre> <code class="bash hljs">$ docker-machine ssh testenv <span class="hljs-comment"><span class="hljs-comment">## . ## ## ## == ## ## ## ## ## === /"""""""""""""""""\___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ / ===- ~~~ \______ o __/ \ \ __/ \____\_______/ _ _ ____ _ _ | |__ ___ ___ | |_|___ \ __| | ___ ___| | _____ _ __ | '_ \ / _ \ / _ \| __| __) / _` |/ _ \ / __| |/ / _ \ '__| | |_) | (_) | (_) | |_ / __/ (_| | (_) | (__| &lt; __/ | |_.__/ \___/ \___/ \__|_____\__,_|\___/ \___|_|\_\___|_| Boot2Docker version 1.9.1, build master : cef800b - Fri Nov 20 19:33:59 UTC 2015 Docker version 1.9.1, build a34a1d5 docker@testenv:~$</span></span></code> </pre><br>  Yes, this is boot2docker, but this is not interesting.  Let's look at the mounted sections: <br><br><pre> <code class="bash hljs">docker@testenv:~$ mount tmpfs on / <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> tmpfs (rw,relatime,size=918088k) proc on /proc <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> proc (rw,relatime) sysfs on /sys <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> sysfs (rw,relatime) devpts on /dev/pts <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> devpts (rw,relatime,mode=600,ptmxmode=000) tmpfs on /dev/shm <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> tmpfs (rw,relatime) fusectl on /sys/fs/fuse/connections <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> fusectl (rw,relatime) /dev/sda1 on /mnt/sda1 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> ext4 (rw,relatime,data=ordered) [... cgroup skipped ...] none on /Users <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> vboxsf (rw,nodev,relatime) /dev/sda1 on /mnt/sda1/var/lib/docker/aufs <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> ext4 (rw,relatime,data=ordered) docker@testenv:~$ ls /Users/ Shared/ logpacker/ docker@testenv:~$</code> </pre><br>  In this case, we use MacOS and, accordingly, the / Users directory (analogue of / home in linux) is mounted inside the machine.  This allows us to work transparently with files on the host system within the docker framework, that is, to quietly connect and disconnect volumes without worrying about the VM layer.  It is really very convenient.  In theory, we can forget about this VM, it is needed only for the docker to work in the ‚Äúnative‚Äù environment.  At the same time, the use of the docker client will be absolutely transparent. <br>  So, the base environment is built, then we will run Docker containers. <br><br><h4>  Configure and launch containers </h4><br>  Our application can work on a cluster basis, that is, it provides fault tolerance of the entire system in case of a change in the number of nodes.  Due to the internal interservice API, adding or deleting a new node to the cluster is painless and does not require overloading other nodes, and we also need to take this distinctive feature of our application into account when building the environment. <br>  In principle, everything fits well with the Docker ideology: ‚Äúone process - one container‚Äù.  Therefore, we will not depart from the canons and will do the same.  At the start, run the following configuration: <br><ul><li>  Three containers with the server side of the application. </li><li>  Three containers with the client part of the application. </li><li>  Generator load for each agent.  For example, Ngnix, which will generate logs, and we will stimulate it with Yandex.Tank or Apache Benchmark. </li><li>  And in another container, we move away from ideology.  Our service can work in the so-called ‚Äúdual mode‚Äù, i.e.  the client and server are on the same host; moreover, it is just one instance of the application, working immediately both as a client and as a server.  We will launch it in a container under the control of a supervisord, and our own small load generator will be launched in the same container as the main process. </li></ul><br>  So, we have a compiled binary of our application - this is one file, yes, thanks Golang :), with which we will assemble a universal container for launching the service, within the test environment.  The difference will be in the transferred keys (we start the server or the agent), we will manage them when the container is started.  Small nuances are in the last paragraph, when starting the service in ‚Äúdual mode‚Äù, but more on that later. <br>  So, prepare <code>docker-compose.yml</code> .  This is a file with directives for docker-compose, which will allow us to raise the test environment with one command: <br><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># external services elastic: image: elasticsearch ngx_1: image: nginx volumes: - /var/log/nginx ngx_2: image: nginx volumes: - /var/log/nginx ngx_3: image: nginx volumes: - /var/log/nginx # lp servers lp_server_1: image: logpacker_service command: bash -c "cd /opt/logpacker &amp;&amp; ./logpacker -s -v -devmode -p=0.0.0.0:9995" links: - elastic expose: - "9995" - "9998" - "9999" lp_server_2: image: logpacker_service command: bash -c "cd /opt/logpacker &amp;&amp; ./logpacker -s -v -devmode -p=0.0.0.0:9995" links: - elastic - lp_server_1 expose: - "9995" - "9998" - "9999" lp_server_3: image: logpacker_service command: bash -c "cd /opt/logpacker &amp;&amp; ./logpacker -s -v -devmode -p=0.0.0.0:9995" links: - elastic - lp_server_1 - lp_server_2 expose: - "9995" - "9998" - "9999" # lp agents lp_agent_1: image: logpacker_service command: bash -c "cd /opt/logpacker &amp;&amp; ./logpacker -a -v -devmode -p=0.0.0.0:9995" volumes_from: - ngx_1 links: - lp_server_1 lp_agent_2: image: logpacker_service command: bash -c "cd /opt/logpacker &amp;&amp; ./logpacker -a -v -devmode -p=0.0.0.0:9995" volumes_from: - ngx_2 links: - lp_server_1 lp_agent_3: image: logpacker_service command: bash -c "cd /opt/logpacker &amp;&amp; ./logpacker -a -v -devmode -p=0.0.0.0:9995" volumes_from: - ngx_3 links: - lp_server_1</span></span></code> </pre><br></div></div><br>  Everything is standard in this file.  We first run elasticsearch as the main storage, then three copies with nginx that will act as load providers.  Next, run our server applications.  Note that all subsequent containers are linked with previous ones.  As part of our docker network, this will allow us to access containers by name.  Below, when we analyze the launch of our service in ‚Äúdual mode‚Äù, we will come back to this point and consider it in a little more detail.  Also, with the first container in which the instance of the server application is located, agents are linked.  This means that all three agents will send logs to this particular server. <br><br>  Our application is designed in such a way that in order to add a new node to the cluster, it is enough for an agent or a server to inform about one existing cluster node and it will receive complete information about the entire system.  In the configuration files for each server instance, we specify our first node and the agents will automatically receive all the information about the current state of the system.  After some time after the launch of all system nodes, we simply turn off this instance.  In our case, the cluster transfers it painlessly, all information about the system is already distributed among all participants. <br><br>  And one more thing: pay attention to the logic of mount volumes.  On containers with nginx, we specify a named volume, which will be available in the docker network, and on containers with agents, we simply connect it by specifying the name of the service.  Thus, we will have a shared volume between consumers and suppliers of the load. <br><br>  So, we start our environment: <br><br><pre> <code class="bash hljs">$ docker-compose up -d</code> </pre><br>  We check that everything started up normally: <br><br><pre> <code class="bash hljs">$ docker-compose ps Name Command State Ports -------------------------------------------------------------------------------------------- assets_lp_agent_1_1 bash -c <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/logpacker ... Up assets_lp_agent_2_1 bash -c <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/logpacker ... Up assets_lp_agent_3_1 bash -c <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/logpacker ... Up assets_lp_server_1_1 bash -c <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/logpacker ... Up 9995/tcp, 9998/tcp, 9999/tcp assets_lp_server_2_1 bash -c <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/logpacker ... Up 9995/tcp, 9998/tcp, 9999/tcp assets_lp_server_3_1 bash -c <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt/logpacker ... Up 9995/tcp, 9998/tcp, 9999/tcp assets_ngx_1_1 nginx -g daemon off; Up 443/tcp, 80/tcp assets_ngx_2_1 nginx -g daemon off; Up 443/tcp, 80/tcp assets_ngx_3_1 nginx -g daemon off; Up 443/tcp, 80/tcp elastic /docker-entrypoint.sh elas ... Up 9200/tcp, 9300/tcp</code> </pre><br>  Ok, the environment has risen, it works and all ports are forwarded.  In theory, we can start testing, but we need to finish some points. <br><br><h4>  Container naming </h4><br>  Let's return to the container in which we wanted to launch our application in ‚Äúdual mode‚Äù.  The main process in this container will be the load generator (the simplest shell script).  It generates text strings and puts them into text ‚Äúlog‚Äù files, which, in turn, will be a load for our application.  First you need to collect the container with our application running under <code>supervisord</code> .  Take the latest version of <code>supervisord</code> , since we need the ability to transfer environment variables to the configuration file.  <code>supervisord</code> version 3.2.0 is suitable for us, but in Ubuntu 14.04 LTS, which we took as the base image, the <code>supervisord</code> version is quite old (3.0b2).  Install the latest version of <code>supervisord</code> via <code>pip</code> .  The final Dockerfile is: <br><br><div class="spoiler">  <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre> <code class="bash hljs">FROM ubuntu:14.04 <span class="hljs-comment"><span class="hljs-comment"># Setup locale environment variables RUN locale-gen en_US.UTF-8 ENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en ENV LC_ALL en_US.UTF-8 # Ignore interactive ENV DEBIAN_FRONTEND=noninteractive RUN apt-get update &amp;&amp; \ apt-get install -y wget unzip curl python-pip # Install supervisor via pip for latest version RUN pip install supervisor RUN mkdir -p /opt/logpacker ADD final/logpacker /opt/logpacker/logpacker ADD supervisord-logpacker-server.ini /etc/supervisor/conf.d/logpacker.conf ADD supervisor.conf /etc/supervisor/supervisor.conf # Load generator ADD random.sh /opt/random.sh # Start script ADD lp_service_start.sh /opt/lp_service_start.sh</span></span></code> </pre><br></div></div><br>  The load generator is extremely simple: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash # generate random lines OUTPUT_FILE="test.log" while true do _RND_LENGTH=`awk -v min=1 -v max=100 'BEGIN{srand(); print int(min+rand()*(max-min+1))}'` _RND=$(( ( RANDOM % 100 ) + 1 )) _A="[$RANDOM-$_RND] $(dd if=/dev/urandom bs=$_RND_LENGTH count=1 2&gt;/dev/null | base64 | tr = d)"; echo $_A; echo $_A &gt;&gt; /tmp/logpacker/lptest.$_RND.$OUTPUT_FILE; done</span></span></code> </pre><br>  The startup script is also not complicated: <br><br><pre> <code class="bash hljs"><span class="hljs-meta"><span class="hljs-meta">#!/bin/bash # run daemon supervisord -c /etc/supervisor/supervisor.conf # launch randomizer /opt/random.sh</span></span></code> </pre><br>  The whole trick will be in the <code>supervisord</code> configuration file and launching the Docker container. <br>  Consider the configuration file: <br><br><pre> <code class="bash hljs">[program:logpacker_daemon] <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=/opt/logpacker/logpacker %(ENV_LOGPACKER_OPTS)s directory=/opt/logpacker/ autostart=<span class="hljs-literal"><span class="hljs-literal">true</span></span> autorestart=<span class="hljs-literal"><span class="hljs-literal">true</span></span> startretries=10 stderr_logfile=/var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/logpacker.stderr.log stdout_logfile=/var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/logpacker.stdout.log</code> </pre><br>  Note the <code>%(ENV_LOGPACKER_OPTS)s</code> .  Supervisord can perform substitutions in the configuration file from environment variables.  The variable is written as <code>%(ENV_VAR_NAME)s</code> and its value is inserted into the configuration file when the daemon starts. <br>  We start the container by running the following command: <br><br><pre> <code class="bash hljs">$ docker run -it -d --name=dualmode --link=elastic -e <span class="hljs-string"><span class="hljs-string">'LOGPACKER_OPTS=-s -a -v -devmode'</span></span> logpacker_dualmode /opt/random.sh</code> </pre><br>  With the help of the <code>-e</code> switch, it is possible to set the necessary environment variable, while it will be set globally inside the container.  And that is what we substitute into the configuration file <code>supervisord</code> .  Thus, we can manage startup keys for our daemon and run it in the mode we need. <br>  We got a universal image, although a bit inconsistent with the ideology.  Let's look inside: <br><div class="spoiler">  <b class="spoiler_title">Environment</b> <div class="spoiler_text"><pre> <code class="bash hljs">$ docker <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it dualmode bash $ env HOSTNAME=6b2a2ae3ed83 ELASTIC_NAME=/suspicious_dubinsky/elastic TERM=xterm ELASTIC_ENV_CA_CERTIFICATES_JAVA_VERSION=20140324 LOGPACKER_OPTS=-s -a -v -devmode ELASTIC_ENV_JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/jre ELASTIC_ENV_JAVA_VERSION=8u66 ELASTIC_ENV_ELASTICSEARCH_REPO_BASE=http://packages.elasticsearch.org/elasticsearch/1.7/debian ELASTIC_PORT_9200_TCP=tcp://172.17.0.2:9200 ELASTIC_ENV_ELASTICSEARCH_VERSION=1.7.4 PATH=/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/sbin:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin:/usr/sbin:/usr/bin:/sbin:/bin ELASTIC_PORT_9300_TCP_ADDR=172.17.0.2 ELASTIC_ENV_ELASTICSEARCH_MAJOR=1.7 ELASTIC_PORT_9300_TCP=tcp://172.17.0.2:9300 PWD=/ ELASTIC_PORT_9200_TCP_ADDR=172.17.0.2 ELASTIC_PORT_9200_TCP_PROTO=tcp ELASTIC_PORT_9300_TCP_PORT=9300 SHLVL=1 HOME=/root ELASTIC_ENV_JAVA_DEBIAN_VERSION=8u66-b17-1~bpo8+1 ELASTIC_PORT_9300_TCP_PROTO=tcp ELASTIC_PORT=tcp://172.17.0.2:9200 LESSOPEN=| /usr/bin/lesspipe %s ELASTIC_ENV_LANG=C.UTF-8 LESSCLOSE=/usr/bin/lesspipe %s %s ELASTIC_PORT_9200_TCP_PORT=9200 _=/usr/bin/env</code> </pre><br></div></div><br>  In addition to our variable, which we explicitly specified when starting the container, we also see all the variables related to the linked container, namely: IP address, all open ports and all variables that were explicitly set when building the elasticsearch image using the ENV directive .  All variables have a prefix with the name of the export container and a name indicating their essence.  For example, <code>ELASTIC_PORT_9300_TCP_ADDR</code> indicates that a variable stores a value indicating the container named elastic and its ip address where port 9300 is open. If it‚Äôs not reasonable to raise a separate discovery service for the tasks assigned, then this is a great way to get an IP address and data from linked containers.  At the same time, it remains possible to use them in their applications that are running in Docker containers. <br><br><h4>  Container management and monitoring system </h4><br>  So, we have built an environment for testing that meets all of our initial requests.  Left a couple of nuances.  First, install the Weave Scope (screenshots of which were at the beginning of the article).  With Weave Scope, you can visualize the environment in which we operate.  In addition to displaying links and information about containers, we can <code>attach</code> to any container or run a full-fledged terminal with <code>sh</code> right in the browser.  These are irreplaceable functions when debugging and testing.  So, from the host machine, perform the following actions as part of our active session: <br><br><pre> <code class="bash hljs">$ wget -O scope https://github.com/weaveworks/scope/releases/download/latest_release/scope $ chmod +x scope $ scope launch</code> </pre><br>  After executing these commands, go to <a href="http://vm_ip/">VM_IP</a> : 4040, we get to the container management interface shown in the picture below: <br><br><img src="https://habrastorage.org/files/818/7c8/3e9/8187c83e90a84e1bbac6443aeb4cefc1.jpg"><br><br>  Great, almost everything is ready.  For complete happiness, we lack a monitoring system.  Let's use cAdvisor from Google: <br><br><pre> <code class="bash hljs">$ docker run --volume=/:/rootfs:ro --volume=/var/run:/var/run:rw --volume=/sys:/sys:ro --volume=/var/lib/docker/:/var/lib/docker:ro --publish=8080:8080 --detach=<span class="hljs-literal"><span class="hljs-literal">true</span></span> --name=cadvisor google/cadvisor:latest</code> </pre><br>  Now at <a href="http://vm_ip/">VM_IP</a> : 8080 we have a real-time resource monitoring system.  We can track and analyze the main metrics of our environment, such as: <br><br><ul><li>  use of system resources; </li><li>  network load; </li><li>  process list; </li><li>  other useful information. </li></ul><br>  The screenshot below shows the cAdvisor interface: <br><br><img src="https://habrastorage.org/files/988/e9a/6e9/988e9a6e9aa84e1cbd155c51762cffd7.jpg"><br><br><h4>  Conclusion </h4><br>  Using Docker containers, we built a complete test environment with the functions of automatic deployment and network interaction of all nodes, and most importantly, with flexible configuration of each component and the system as a whole.  Implemented all the basic requirements, namely: <br><ul><li>  Full network emulation for testing network interaction. </li><li>  Adding and deleting nodes with an application is done through changes to docker-compose.yml and is applied by one command. </li><li>  All nodes can fully receive information about the network environment. </li><li>  Adding and removing data stores is performed by one command. </li><li>  Management and monitoring of the system are available through the browser.  This is implemented with tools running separately in containers near our application, which allows them to be isolated from the host system. </li></ul><br><h4>  Links to all the tools mentioned in the article: </h4><br><ul><li>  <a href="https://docs.docker.com/">Docker</a> </li><li>  <a href="https://docs.docker.com/compose/">docker-compose</a> </li><li>  <a href="https://docs.docker.com/machine/">docker-machine</a> </li><li>  <a href="https://www.docker.com/docker-toolbox">Docker toolbox</a> </li><li>  <a href="http://www.weave.works/products/weave-scope/">Weave scope</a> </li><li>  <a href="https://github.com/google/cadvisor">cAdvisor</a> </li><li>  <a href="https://github.com/logpacker/docker-test-env">All configuration files and scripts used to build a test environment</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/275513/">https://habr.com/ru/post/275513/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../275503/index.html">Why is it difficult to program the UI and how does the perfect framework look like?</a></li>
<li><a href="../275505/index.html">Have you thought about the safety of ... a car?</a></li>
<li><a href="../275507/index.html">Search for a variety of regular expressions using the Hyperscan library</a></li>
<li><a href="../275509/index.html">Used servers as a reasonable alternative</a></li>
<li><a href="../275511/index.html">Using Kanban to Prepare Scrum Backlog</a></li>
<li><a href="../275515/index.html">Gradle: managing dependencies</a></li>
<li><a href="../275517/index.html">AnyConnect and Address Space Intersection</a></li>
<li><a href="../275519/index.html">Icons in the bookmarks bar and the weight of everything in the assembly Vivaldi 1.0.375.3</a></li>
<li><a href="../275521/index.html">Mocks, fakes and stubs in C ++</a></li>
<li><a href="../275525/index.html">Corporate Laboratories 2016 - practical training in the field of information security</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>