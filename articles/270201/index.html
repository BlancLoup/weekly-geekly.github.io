<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Solving the problem of credit scoring in the studio Microsoft Azure Machine Learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Summary 
 Predict whether a customer pays a loan or not. The challenge was proposed on an online tournament hosted by one bank. One example of its sol...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Solving the problem of credit scoring in the studio Microsoft Azure Machine Learning</h1><div class="post__text post__text-html js-mediator-article"><h4>  Summary </h4><br>  Predict whether a customer pays a loan or not.  The challenge was proposed on an online tournament hosted by one bank.  One example of its solution can be found <a href="http://habrahabr.ru/post/204500/">here</a> .  Our goal is to build a solution on the Microsoft Azure platform. <br><a name="habracut"></a><br><h4>  Formulation of the problem </h4><br>  The bank requests the applicant's credit history at the three largest Russian credit bureaus.  We are provided with a sample of Bank clients in the SAMPLE_CUSTOMERS (CSV) file.  The sample is divided into parts ‚Äútrain‚Äù and ‚Äútest‚Äù.  From the ‚Äútrain‚Äù sample, we know the value of the target variable bad - the presence of a ‚Äúdefault‚Äù (the client assumes a delay of 90 or more days during the first year of using the loan). <br><br>  The SAMPLE_ACCOUNTS (CSV) file contains data from the responses of credit bureaus to all inquiries on relevant clients.  The format of the data from the response of the bureau is information about the accounts of a person transmitted by other banks to the bureau.  The data format is described in detail in the ACCOUNT_DATA_FORMAT file. <br><br>  On the ‚Äútrain‚Äù sample, it is necessary to build a model that determines the probability of a ‚Äúdefault‚Äù, and put down the probabilities of ‚Äúdefault‚Äù for clients from the ‚Äútest‚Äù sample. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Import dataset into studio </h4><br>  The original data are in CSV format, but the studio correctly recognizes CSV with comma-delimited only.  Save the source files with customer information SAMPLE_ACCOUNTS.CSV and SAMPLE_CUSTOMERS.CSV with the required delimiters (for short, SAMPLE_ACCOUNTS.csv was saved as Sdvch.csv) and load them into azure. <br><br><img src="https://habrastorage.org/files/181/05b/9c5/18105b9c5b7e4b5d8d1b704270bfdcda.png"><br><br><h4>  Primary processing </h4><br>  SAMPLE_ACCOUNTS contains 280942 rows and 28 columns, each row contains information on one loan.  The column with customer IDs contains 50,000 unique values, which means there can be several lines for each customer.  Note that some loans are repeated, and the values ‚Äã‚Äãof some fields are missing.  The contents of the columns will be revealed further in the course of solving the problem. <br><br><img src="https://habrastorage.org/files/a1a/302/089/a1a30208949246fb8ecf3f0a8593cbb1.png"><br><br><img src="https://habrastorage.org/files/537/90e/b34/53790eb344514d5dafb295cbdee6bf39.png"><br><br>  In order to solve the problem, we will consolidate all the information for each client in one line.  To do this, run the scripts on Python above the database. <br><br><img src="https://habrastorage.org/files/476/d3e/a83/476d3ea83a294a3c9fbc070e922af016.png"><br><br>  The first script, in fact, consists of the ideas of the <a href="http://habrahabr.ru/post/204500/">solution</a> , which was discussed earlier.  Briefly tell them. <br>  Step 1. Drop the duplicate credits (lines) from the data set, leaving the line with the latest information.  To do this, we define a set of pillars that will act as a key, these are: tcs_customer_id, open_date, final_pmt_date, credit_limit, currency (id, credit opening date, estimated last payment date, credit limit, currency);  column inf_confirm_date (date of confirmation of information on the loan) will determine which of the duplicates remains. <br><br>  Step 2. Process the columns: pmt_string_84m (timeliness of payments), pmt_freq (payment frequency code), type (agreement type code), status (agreement status), relationship (type of relationship to the agreement), bureau_cd (code of the bureau from which the invoice was received) .  We calculate the number of each unique value for each customer and write these values ‚Äã‚Äãin new columns. <br><br>  Step 3. Convert the fact_close_date field, which contains the date of the last actual payment, so that it contains only 2 values: 0 - there was no last payment, 1 - the last payment was. <br><br>  Step 4. We will translate all credit limits to rubles.  For simplicity, the course is taken in 2013. <br><br>  Step 5. Fill in the gaps in the data 0 and perform the final grouping (with summation) by client, with the columns bki_request_date, inf_confirm_date, pmt_string_start, interest_rate, open_date, final_pmt_date, inf_confirm_date_max.  These are the dates and the interest paid on the loan. <br><br>  Below is the resulting dataset. <br><br><img src="https://habrastorage.org/files/ee4/628/ac3/ee4628ac392a47ddb93895fc2829e39d.png"><br><br><img src="https://habrastorage.org/files/34d/28b/58c/34d28b58cad94c50ba99c56bd28d4b75.png"><br><br><img src="https://habrastorage.org/files/d09/2c2/3d9/d092c23d9b1148bf8251a7bbe4c800b8.png"><br><br>  Let us dwell on the second script.  We propose not only to sum up all credit limits for each client, but to divide the entire amount into two parts: the active credit limit, with a status value of 00, and a closed one - with all other statuses.  We also introduce another column with the ratio of the total active limit to - closed, if the sum of the closed limit is zero, then the field will be filled with the letter A. The code of the second script is shown below. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">azureml_main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataframe1)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_csv, DataFrame,Series <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy SampleAccounts=dataframe1 SampleAccounts.final_pmt_date[SampleAccounts.final_pmt_date.isnull()] = SampleAccounts.fact_close_date[SampleAccounts.final_pmt_date.isnull()].astype(float) SampleAccounts.final_pmt_date.fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       sumtbl = SampleAccounts.pivot_table(['inf_confirm_date'], ['tcs_customer_id','open_date','final_pmt_date','credit_limit','currency'], aggfunc='max') #sumtbl -         SampleAccounts = SampleAccounts.merge(sumtbl, 'left', left_on=['tcs_customer_id','open_date','final_pmt_date','credit_limit','currency'], right_index=True, suffixes=('', '_max')) #      SampleAccounts=SampleAccounts.drop_duplicates(['tcs_customer_id','open_date','final_pmt_date','credit_limit','currency']).reset_index() df1=SampleAccounts.drop('index',axis=1) curs = DataFrame([33.13,44.99,36.49,1], index=['USD','EUR','GHF','RUB'], columns=['crs']) df2 = df1.merge(curs, 'left', left_on='currency', right_index=True) df2.credit_limit = df2.credit_limit * df2.crs #       df2=df2.drop(['crs'], axis=1) #  df3 = df2[['tcs_customer_id','credit_limit','status']] df3['act_lim']=df3.credit_limit[df3.status==0] df3.act_lim.fillna(0, inplace=True) df4=df3.copy() df4['credit_limit'] = numpy.where(df3['status']==0, 0, df3.credit_limit) df5=df4.groupby('tcs_customer_id').sum() df5.rename(columns={'credit_limit':'closed_limit'}, inplace=True) df6=df5.drop('status',axis=1) df6['otn_lim']=numpy.where(df6.closed_limit==0, 'A', df6.act_lim/df6.closed_limit) return df6</span></span></code> </pre> <br><img src="https://habrastorage.org/files/5be/134/c81/5be134c81c684fea9709a64e5cd5483d.png"><br><br><h4>  Azure processing </h4><br>  Using two ‚ÄúAdd Columns‚Äù blocks, we connect the bases of the resulting scripts processing with the SAMPLE_CUSTOMERS file. <br><br><img src="https://habrastorage.org/files/d11/369/9e2/d113699e2ab44b4994f50cb0fb3499ef.png"><br><br><img src="https://habrastorage.org/files/d95/1a8/3dd/d951a83dd9df438283e2325ed37a35ed.png"><br><br>  Next, divide the sample into two parts using the ‚ÄúSplit Data‚Äù block.  Choose a regular expression mode and set a condition on the column ‚Äúsample_type‚Äù, we need lines with the value ‚Äútrain‚Äù. <br><br>  Using the ‚ÄúProject Columns‚Äù block, we select the columns remaining for processing.  We will compare two data sets: on the left with all received columns (except sample_type, it is the same ‚Äútrain‚Äù everywhere), on the right without our modification, that is, with the exception of the active and closed limit columns and their relationship (and sample_type). <br><br><img src="https://habrastorage.org/files/01e/ab5/ea7/01eab5ea70e14437a6243251d77d2ce3.png"><br><br><img src="https://habrastorage.org/files/3b0/916/fbf/3b0916fbfb4e4583ac1d45dfae5d3481.png"><br><br>  Now add to the project another pair of modules "Split Data".  This time we use a pseudo-random row separation into two parts with a given ‚Äúrandom seed‚Äù field.  This is necessary so that the division of the sample into two parts takes place equally for the left and right bases.  The percentage for training and testing is 85% and 15%.  This is explained by the fact that in our case the base with 50,000 clients has already been divided into two train and test samples.  In theory, we would have to train 100% of the base train and put the result in test, but since we are learning and testing on the train, the ratio was chosen more favorable than the usual 75/25 or 80/20. <br><br><img src="https://habrastorage.org/files/d10/a9d/2b4/d10a9d2b4da74649b559381e2adfb246.png"><br><br>  To train the model, we will use a two-class elevated decision tree (two-class boosting) with standard values.  We also add the modules Train Model and Score Model.  In the ‚ÄúTrain Model‚Äù we indicate the required column for predicting bad. <br><br><img src="https://habrastorage.org/files/6b4/a8d/101/6b4a8d1015414b29b8a25fd714d80178.png"><br><br>  Visualization of the left block ‚ÄúScore Model‚Äù. <br><br><img src="https://habrastorage.org/files/4cb/ceb/443/4cbceb4439c74545b87e7e8298bc6e72.png"><br><br>  It remains to connect the outputs of the Score Model modules with the inputs of the Evaluate Model block, which allows you to compare the results of the two methods.  In our case - the results of the work of one classification method for two different data sets. <br><br><img src="https://habrastorage.org/files/396/8f4/f22/3968f4f225a84f64a5bdd010225045c0.png"><br><br>  The following screen shows the visualization of the Evaluate Model block, that is, the prediction results.  The blue line corresponds to the left database (with all received columns), the red line to the right one (with the exception of active, closed limit columns and their ratio). <br><br><img src="https://habrastorage.org/files/59b/80d/23e/59b80d23e1664e409154a503b255a58b.png"><br><br><img src="https://habrastorage.org/files/ba9/b0e/793/ba9b0e793f6149f5809cb77cc2bab8b3.png"><br><br><h4>  Conclusion </h4><br>  Given the distribution of seats held tournament <br><br><ol><li>  AUC 0.7057 </li><li>  AUC 0.7017 </li><li>  AUC 0.7012 </li><li>  AUC 0.6997 </li></ol>  we consider our AUC 0.706 result to be satisfactory (we should not forget that we did not test the program in the test sample, available only to the bank). <br><br><h5>  Thanks for attention! </h5><br><h5>  Resources used </h5><br><ul><li>  <a href="https://studio.azureml.net/">studio.azureml.net</a> </li><li>  <a href="http://pandas.pydata.org/">pandas.pydata.org</a> </li><li>  <a href="https://yandexdataschool.ru/edu-process/courses/machine-learning">yandexdataschool.ru/edu-process/courses/machine-learning</a> </li><li>  <a href="https://www.tinkoff.ru/tournament/">www.tinkoff.ru/tournament</a> </li><li>  <a href="http://habrahabr.ru/post/204500/">habrahabr.ru/post/204500</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/270201/">https://habr.com/ru/post/270201/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../270191/index.html">On the thirtieth anniversary of the first C ++ compiler: look for errors in Cfront</a></li>
<li><a href="../270193/index.html">Not a flux</a></li>
<li><a href="../270195/index.html">The book "The Perfect Programmer. How to become a software development professional?</a></li>
<li><a href="../270197/index.html">SAP - ABAP. Modifying a summary line in the ALV grid</a></li>
<li><a href="../270199/index.html">Translation agreement with Apple Developer Program License Agreement</a></li>
<li><a href="../270203/index.html">Snom C520 and C52 - space design and wide opportunities</a></li>
<li><a href="../270205/index.html">What is written with a pen, or how to check documents in MS Office formats</a></li>
<li><a href="../270207/index.html">Metronome IM and Jappix: a multi-functional Jabber, without difficulty in setting up</a></li>
<li><a href="../270209/index.html">Ansible 2.0 b2. Overview of innovations</a></li>
<li><a href="../270211/index.html">Monstrous frankenstek</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>