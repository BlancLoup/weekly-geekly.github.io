<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>iSCSI storage for the poor</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day, dear community! 

 In this article I would like to share the experience of creating disk storage, which resulted in many experiments, trial,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>iSCSI storage for the poor</h1><div class="post__text post__text-html js-mediator-article">  Good day, dear community! <br><br>  In this article I would like to share the experience of creating disk storage, which resulted in many experiments, trial, error, discoveries, seasoned with bitter disappointments.  And, finally, ended in some interesting, relatively budget and fast storage. <br><br>  If you have a similar task or if you are just interested in the title, then welcome to habrakat. <br><a name="habracut"></a><br><h4>  Prologue </h4><br>  So, recently, our department faced the task of providing a cluster of VMware ESXi 5.1 hypervisors with large storage.  On it, we planned to locate the encrypted maildir for dovecot and the ‚Äúcloud‚Äù file storage.  A prerequisite for allocating a budget was to provide storage space for company-critical information, and this section should be encrypted. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Iron </h4><br>  Unfortunately, and perhaps fortunately, we were not burdened with a large budget for such ambitious tasks.  Therefore, we, as true fans of maximalism, could not afford any kind of brand storage, and within the allocated material resources we chose the following hardware: <br><br><ul><li>  Server Chassis <b>Supermicro CSE-836BE16-R920B</b> <br>  There was a lot of reasoning, choosing the number of units, the size of hard drives, their speed, body, or immediately the platform, reviewed many options, smoked the Internet and eventually settled on this variant, as the optimal one for our tasks. </li><li>  Motherboard <b>Supermicro MBD-X9DRI-FO</b> <br>  The main condition was the presence of 4 ports PCI-E x8. </li><li>  <b>Intel Xeon E5-2603 processors</b> <br>  The choice was simple - with enough money.  In addition, we had to install 2 processors at once, and not one at first, then, if necessary, we would need to purchase, because only 3 PCI-E works with one occupied slot, and we had 4. </li><li>  <b>Seagate Constellation ES.3 ST3000NM0033 wheels</b> <br>  SATA because it is cheaper, and in the same money we received many times more free space than using SAS. </li><li>  <b>Adaptec ASR-7805Q</b> RAID Controller <br>  Since this is a storage system, they didn‚Äôt bother with the controller.  This series has SSD caching, which would be very useful for us, and there is a BBU immediately included, which is also a very useful option. </li><li>  <b>Intel</b> SSD <b>SSDSC2CW240A310</b> <br>  They were needed solely in order to work MaxCache (aka SSD cache). </li><li>  <b>Intel X520 DA2</b> Network Cards <br>  To avoid a bottleneck on network interfaces, it was necessary to provide a 10Gb link between the ESXi nodes and the storage system.  After studying the offers of the market, we may come to the not very elegant, but then to a suitable for the price and speed option using 10 gigabit network cards. </li></ul><br>  All this cost us about 200 thousand rubles. <br><br><h4>  Implementation </h4><br>  We decided to issue the target, that is, allocate storage resources to consumers, using iSCSI and NFS.  The most reasonable and quick solution, of course, would be to use FCoE, so as not to get into TCP with the corresponding overhead, which, in general, could be done with our network cards, but, unfortunately, we do not have an SFP switch with support FCoE, buy it was not possible, since it would cost us 500 TR  from above. <br>  Once again, having smoked the Internet, we found a way out of this in the vn2vn technology, but ESXi learns how to work with vn2vn only to the 6.x version, so, without thinking further, they started to think about what it is. <br><br>  Our corporate standard for Linux servers is CentOS, but in the current kernel (2.6.32-358) encryption is very slow, so I had to use Fedora as the OS.  Of course, this is a Red Hat test site, but in the latest Linux kernels, data is encrypted almost on the fly, and the rest is not what we need. <br>  In addition, the current 19 version will be used as the basis for RHEL 7, and therefore will allow us in the future to safely switch to CentOS 7. <br><br><h4>  Targets </h4><br>  In order not to inflate the article and do not move away from the topic, I omit all the uninteresting ones such as assembling iron, butting with the controller, installing the OS and others.  I will also try to describe as little as possible the target itself and limit myself only to its work with the ESXi initiator. <br><br>  From Target, we wanted to get the following: <br><ul><li>  correctly working caching - disks are rather slow, they can only be squeezed out of themselves 2000 iops; </li><li>  maximum speed of the disk subsystem as a whole, read (give as much as possible iops). </li></ul><br>  Meet, here they are. <br><br><h5>  LIO </h5>  <a href="http://linux-iscsi.org/">linux-iscsi.org</a> <br>  With the Linux kernel 3.10.10, it showed me 300 MB / s of writing and 600 MB / s of reading in blockio mode.  He showed the same numbers with a fileio and also with a RAM disk.  The graphs showed that the recording speed jumps very much, probably due to the fact that the ESXi initiator requires recording synchronization.  For the same reason, the number of IOPS per record was the same with fileio and blockio. <br>  In the meillists, it was recommended to disable emulate_fua_write, but this did not lead to any changes.  Moreover, with the 3.9.5 kernel, it shows the best results, which also makes us think about its future. <br>  LIO, judging by the description, can do a lot of things, but most features are available only in the commercial version.  The site, which, in my opinion, should be primarily a source of information, is full of advertisements, which causes a negative.  In the end, they decided to refuse. <br><br><h5>  istgt </h5>  <a href="http://www.peach.ne.jp/archives/istgt">www.peach.ne.jp/archives/istgt</a> <br>  Used in FreeBSD. <br>  Target works quite well, except for a few but. <br>  Firstly, it does not know how to blockio, secondly, it cannot use different MaxRec and MaxXtran, at least I did not succeed.  For small MaxRec values, the sequential write speed did not exceed 250 MB / s, and the read was at a quite high level - 700 MB / s.  Approximately 40K of iops, I received 4k randomly recorded with a queue depth of 32. With an increase in MaxRec, the write speed rises to 700 MB / s, the reading drops to 600 MB / s.  Iops fall to read 30K and 20K to write. <br>  That is, somehow it would be possible to find a middle ground, changing the settings, but somehow it seemed not to be difficult. <br><br><h5>  STGT </h5>  <a href="http://stgt.sourceforge.net/">stgt.sourceforge.net</a> <br>  With this target there were problems with setting up the interface with the hypervisor.  ESXi is constantly confused LUN - took one for the other, or stopped to see at all.  There was a suspicion of a problem in incorrect binding of serial numbers, but writing them in configs did not help. <br>  The speed is also not pleased.  Achieving more than 500 MB / sec from it, neither read nor write failed.  The amount of IOPS for reading is 20K, for writing it is approximately 15K. <br>  As a result, problems with the config and low rates in speed.  Refuse. <br><br><h5>  IET </h5>  <a href="http://iscsitarget.sourceforge.net/">iscsitarget.sourceforge.net</a> <br>  Worked almost flawlessly.  Read and write 700MB / sec.  IOPS on reading about 30K, on ‚Äã‚Äãrecord 2000. <br>  The ESXi initiator forced the target to write data to the disk immediately, without using the system cache.  Also, a few scared reviews about him in the maillists - many reported on unstable work under load. <br><br><h5>  SCST </h5>  <a href="http://scst.sourceforge.net/">scst.sourceforge.net</a> <br>  And finally got to the leader of our race. <br>  After rebuilding the kernel and the minimum configuration of the target itself, we received 750MB / s of reading and 950MB / s of writing.  IOPS in fileio mode - 44K for reading and 37K for writing.  Immediately, almost without a tambourine. <br>  This target seemed to me the perfect choice. <br><br><h4>  iSCSI for VMWare ESXi 5.1 on SCST and Fedora </h4><br>  And now, in fact, for the sake of which we all gathered here. <br>  A small instruction on how to set up an ESXi initiator.  I did not immediately decide to try to write an article on Habr, so the instruction will not be step by step - I restore it from memory, but it will contain the main points of the settings that allowed us to achieve the desired results. <br><br><h5>  ESXi 5.1 Preparation </h5><br>  The following settings have been made in the hypervisor: <br><ul><li>  In the iSCSI settings of the initiator, the delayed ACK is disabled for all targets.  Made in accordance with: <a href="http://kb.vmware.com/selfservice/microsites/search.do%3Flanguage%3Den_US%26cmd%3DdisplayKC%26externalId%3D1002598">kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=1002598</a> </li><li>  the initiator's parameters are changed in accordance with the parameters of the target: <blockquote>  InitialR2T = No <br>  ImmediateData = Yes <br>  MaxConnections = 1 <br>  MaxRecvDataSegmentLength = 1048576 <br>  MaxBurstLength = 1048576 <br>  FirstBurstLength = 65536 <br>  DefaultTime2Wait = 0 <br>  DefaultTime2Retain = 0 <br>  MaxOutstandingR2T = 32 <br>  DataPDUInOrder = No <br>  DataSequenceInOrder = No <br>  ErrorRecoveryLevel = 0 <br>  HeaderDigest = None <br>  DataDigest = None <br>  OFMarker = No <br>  IFMarker = No <br>  OFMarkInt = Reject <br>  IFMarkInt = Reject </blockquote></li></ul><br><br>  You will need to disable Interrupt Moderation and LRO for network adapters.  You can do this with the commands: <br><br><pre><code class="bash hljs">ethtool -C vmnicX rx-usecs 0 rx-frames 1 rx-usecs-irq 0 rx-framesirq 0 esxcfg-advcfg -s 0 /Net/TcpipDefLROEnabled esxcli system module parameters <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> -m ixgbe -p <span class="hljs-string"><span class="hljs-string">"InterruptThrottleRate=0"</span></span></code> </pre> <br><br>  The reasons why it is worth doing: <br>  <a href="http://www.odbms.org/download/vmw-vfabric-gemFire-best-practices-guide.pdf">www.odbms.org/download/vmw-vfabric-gemFire-best-practices-guide.pdf</a> <br>  <a href="http://www.vmware.com/files/pdf/techpaper/VMW-Tuning-Latency-Sensitive-Workloads.pdf">www.vmware.com/files/pdf/techpaper/VMW-Tuning-Latency-Sensitive-Workloads.pdf</a> <br><br>  In order not to set these values ‚Äã‚Äãagain, you can add them to this script: <br><blockquote>  /etc/rc.local.d/local.sh </blockquote><br><br><h5>  Fedora preparation </h5><br>  Download and install the latest version of Fedora at a minimum. <br><br>  Update the system and reboot: <br><br><pre> <code class="bash hljs">[root@nas ~]$ yum -y update &amp;&amp; reboot</code> </pre><br><br>  The system will work only on the local network, so I turned off the firewall and SELinux: <br><br><pre> <code class="bash hljs">[root@nas ~]$ systemctl stop firewalld.service [root@nas ~]$ systemctl <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span> firewalld.service [root@nas ~]$ cat /etc/sysconfig/selinux SELINUX=disabled SELINUXTYPE=targeted</code> </pre><br><br>  Configure network interfaces and disable the NetworkManager.service service.  It is not compatible with BRIDGE interfaces, and this was necessary for NFS. <br><br><pre> <code class="bash hljs">[root@nas ~]$ systemctl <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span> NetworkManager.service [root@nas ~]$ chkconfig network on</code> </pre><br><br>  LRO is disabled on network cards. <br><br><pre> <code class="bash hljs">[root@nas ~]$ cat /etc/rc.d/rc.local <span class="hljs-comment"><span class="hljs-comment">#!/bin/bash ethtool -K ethX lro off</span></span></code> </pre><br><br>  Following the recommendations from Intel, the following system parameters have been changed: <br><br><pre> <code class="bash hljs">[root@nas ~]$ cat /etc/sysctl.d/ixgbe.conf net.ipv4.tcp_sack = 0 net.ipv4.tcp_timestamps = 0 net.ipv4.tcp_rmem = 10000000 10000000 10000000 net.ipv4.tcp_wmem = 10000000 10000000 10000000 net.ipv4.tcp_mem = 10000000 10000000 10000000 net.core.rmem_max = 524287 net.core.wmem_max = 524287 net.core.rmem_default = 524287 net.core.wmem_default = 524287 net.core.optmem_max = 524287 net.core.netdev_max_backlog = 300000</code> </pre><br><br><h5>  Target preparation </h5><br>  To use SCST, it is recommended to add patches to the kernel.  This is optional, but with them the performance is higher. <br>  During the creation of the repository, the latest version of the kernel was - 3.10.10-200.  By the time you read the article, the kernel can already be updated, but I do not think that this will have a strong impact on the process. <br><br>  Creating an rpm package with a modified kernel is described in detail here: <br>  <a href="http://fedoraproject.org/wiki/Building_a_custom_kernel/ru">fedoraproject.org/wiki/Building_a_custom_kernel/en</a> <br><br>  But in order to avoid difficulties I will describe the preparation in detail. <br><br>  Create a user: <br><pre> <code class="bash hljs">[root@nas ~]$ useradd mockbuild</code> </pre><br><br>  Let's go to his environment: <br><pre> <code class="bash hljs">[root@nas ~]$ su mockbuild [mockbuild@nas root]$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span></code> </pre><br><br>  Install the build packages and prepare the kernel sources: <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ su -c <span class="hljs-string"><span class="hljs-string">'yum install yum-utils rpmdevtools'</span></span> [mockbuild@nas ~]$ rpmdev-setuptree [mockbuild@nas ~]$ yumdownloader --<span class="hljs-built_in"><span class="hljs-built_in">source</span></span> kernel [mockbuild@nas ~]$ su -c <span class="hljs-string"><span class="hljs-string">'yum-builddep kernel-3.10.10-200.fc19.src.rpm'</span></span> [mockbuild@nas ~]$ rpm -Uvh kernel-3.10.10-200.fc19.src.rpm [mockbuild@nas ~]$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rpmbuild/SPECS [mockbuild@nas ~]$ rpmbuild -bp --target=`uname -m` kernel.spec</code> </pre><br><br>  Now patches will be required.  Download SCST from svn repository: <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ svn co https://scst.svn.sourceforge.net/svnroot/scst/trunk scst-svn</code> </pre><br><br>  Copy the necessary parts in ~ / rpmbuild / SOURCES / <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ cp scst-svn/iscsi-scst/kernel/patches/put_page_callback-3.10.patch ~/rpmbuild/SOURCES/ [mockbuild@nas ~]$ cp scst-svn/scst/kernel/scst_exec_req_fifo-3.10.patch ~/rpmbuild/SOURCES/</code> </pre><br><br>  Add a line to the kernel config: <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ vim ~/rpmbuild/SOURCES/config-generic ... CONFIG_TCP_ZERO_COPY_TRANSFER_COMPLETION_NOTIFICATION=y ...</code> </pre><br><br>  Let's start editing kernel.spec. <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rpmbuild/SPECS [mockbuild@nas ~]$ vim kernel.spec</code> </pre><br><br>  We change: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#% define buildid .local</span></span></code> </pre><br>  On: <br><pre> <code class="bash hljs">%define buildid .scst</code> </pre><br><br>  We add our patches, preferably after all the others: <br><pre> <code class="bash hljs">Patch25091: put_page_callback-3.10.patch Patch25092: scst_exec_req_fifo-3.10.patch</code> </pre><br>  Add a command to apply the patch, it is recommended to add after the remaining entries: <br><pre> <code class="bash hljs">ApplyPatch put_page_callback-3.10.patch ApplyPatch scst_exec_req_fifo-3.10.patch</code> </pre><br><br>  After all the actions, run the build of rpm kernel packages with the included firmware files: <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ rpmbuild -bb --with baseonly --with firmware --without debuginfo --target=`uname -m` kernel.spec</code> </pre><br><br>  After the build is completed, install the firmware and kernel header files: <br><pre> <code class="bash hljs">[mockbuild@nas ~]$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rpmbuild/RPMS/x86_64/ [mockbuild@nas ~]$ su -c <span class="hljs-string"><span class="hljs-string">'rpm -ivh kernel-firmware-3.10.10-200.scst.fc19.x86_64.rpm kernel-3.10.10-200.scst.fc19.x86_64.rpm kernel-devel-3.10.10-200.scst.fc19.x86_64.rpm kernel-headers-3.10.10-200.scst.fc19.x86_64.rpm'</span></span></code> </pre><br><br>  Reboot. <br><br>  After a successful download, I hope, go to the directory with the SCST sources and by the root user build the target itself: <br><pre> <code class="bash hljs">[root@nas ~]$ make scst scst_install iscsi iscsi_install scstadm scstadm_install</code> </pre><br><br>  After the assembly, add the service to autorun: <br><pre> <code class="bash hljs">[root@nas ~]$ systemctl <span class="hljs-built_in"><span class="hljs-built_in">enable</span></span> <span class="hljs-string"><span class="hljs-string">"scst.service"</span></span></code> </pre><br><br>  And configure the config in /etc/scst.conf.  For example, my: <br><pre> <code class="bash hljs">[root@nas ~]$ cat /etc/scst.conf HANDLER vdisk_fileio { DEVICE mail { filename /dev/mapper/mail nv_cache 1 } DEVICE cloud { filename /dev/sdb3 nv_cache 1 } DEVICE vmstore { filename /dev/sdb4 nv_cache 1 } } TARGET_DRIVER iscsi { enabled 1 TARGET iqn.2013-09.local.nas:raid10-ssdcache { LUN 0 mail LUN 1 cloud LUN 2 vmstore enabled 1 } }</code> </pre><br><br>  Create files that allow or prohibit connections to the target from specific addresses, if you need it: <br><pre> <code class="bash hljs">[root@nas ~]$ cat /etc/initiators.allow ALL 10.0.0.0/24 [root@nas ~]$ cat /etc/initiators.deny ALL ALL</code> </pre><br><br>  After configuring the configuration files, run SCST: <br><pre> <code class="bash hljs">[root@nas ~]$ /etc/init.d/scst start</code> </pre><br><br>  If everything was done correctly, then the corresponding target will appear in ESXi. <br><br>  Thank you for reading to the end! </div><p>Source: <a href="https://habr.com/ru/post/200466/">https://habr.com/ru/post/200466/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../200456/index.html">DiemCms development team is recruited (OpenSource)</a></li>
<li><a href="../200458/index.html">Open data of Moscow and API Challenge competition based on them</a></li>
<li><a href="../200460/index.html">FOSS Sea technical conference: back-end based on free and open technologies</a></li>
<li><a href="../200462/index.html">5 reasons to teach children programming</a></li>
<li><a href="../200464/index.html">Comparison of SATA, SAS, SSD and RAID media with them</a></li>
<li><a href="../200468/index.html">A simple solution for administering phones and tablets + an invitation to tests</a></li>
<li><a href="../200472/index.html">We write instagram-robot, put likes by tags</a></li>
<li><a href="../200474/index.html">How to build Qt 5.1.1 using Visual Studio 2012 under XP</a></li>
<li><a href="../200476/index.html">Inventory servers without disgust</a></li>
<li><a href="../200478/index.html">Step-by-step guide to save related data Yii</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>