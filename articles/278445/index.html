<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Pomp - metaframe for parsing sites</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="With asyncio support and inspired by Scrapy . 

 Why another one? 
 First of all, as a data collection tool used in my hobby project, which would not ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Pomp - metaframe for parsing sites</h1><div class="post__text post__text-html js-mediator-article">  With asyncio support and inspired by <a href="http://scrapy.org/">Scrapy</a> . <br><br><h4>  Why another one? </h4><br>  First of all, as a data collection tool used in my hobby project, which would not crush with its power, complexity and heritage.  And yes, who will deliberately start something new on python2.x? <br><br>  As a result, the idea was to make a simple framework for the modern python3.x ecosystem, but as elegant as Scrapy. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Under the cat review article about <a href="https://bitbucket.org/estin/pomp">Pomp</a> in the style of FAQ. <br><a name="habracut"></a><br><h4>  Why do we need frameworks for parsing sites? </h4><br>  And indeed, after all, a <a href="http://lxml.de/">lot</a> can be done on a simple bundle of <a href="http://docs.python-requests.org/en/master/">requests</a> + <a href="http://lxml.de/">lxml</a> .  In reality, the frameworks set the rules and the necessary abstractions, and take a lot of the routine on themselves. <br><br><h4>  Why is pomp positioned as a "metaframe"? </h4><br>  Pomp out of the box does not provide something that can cover a wide range of requirements in solving the problems of parsing websites: parsing content, proxies, caching, processing redirects, cookies, authorization, form filling, etc. <br><br>  In this and weakness and at the same time the power of Pomp.  This framework is positioned as a "framework for frameworks", in other words, gives everything you need in order to make your framework and start productively "rivet" the web of spiders. <br><br>  Pomp gives the developer: <br><br><ul><li>  necessary abstractions (interfaces) and architecture similar to Scrapy; </li><li>  does not impose a choice of methods for working with the network and parsing the extracted content; </li><li>  can work both synchronously and asynchronously; </li><li>  competitive mining and parsing of content ( <a href="https://docs.python.org/3/library/concurrent.futures.html">concurrent.futures</a> ); </li><li>  does not require a "project", settings and other restrictions. </li></ul><br>  Winning: <br><br><ul><li>  run on python2.x, python3.x and pypy (you can even run on google app engine) </li><li>  You can use your favorite library to work with the network and to parse content; </li><li>  enter your turn tasks; </li><li>  develop your spider cluster; </li><li>  simpler transparent integration with headless browsers (see <a href="https://bitbucket.org/estin/pomp/src/82cbcabeb83a0b3041ee2ed76a6390eb91cd8a68/examples/e05_phantomjs.py%3Fat%3Ddefault%26amp%3Bfileviewer%3Dfile-view-default">phatnomjs integration</a> example). </li></ul><br>  In other words, from Pomp you can do Scrapy if you work with the network on <a href="https://twistedmatrix.com/trac/">Twisted</a> and parse the content using lxml, etc. <br><br><h4>  When should Pomp be used and when not? </h4><br>  In the case when you need to process N sources, with a common data model and with periodic data updates - this is the ideal case of using Pomp. <br><br>  If you need to process 1-2 sources and forget, then quickly and clearly do everything at requests + lxml, and do not use special frameworks at all. <br><br><h4>  Pomp vs Scrapy / Grab / etc? </h4><br>  You can try to compare only in the context of a specific task. <br><br>  And what is better to say is difficult, but for me it is a question that has been solved, since I can build a system of any complexity using Pomp.  Other frameworks often have to deal with their ‚Äúframeworks‚Äù and even hammer nails with a microscope, for example, using Scrapy to work with headless browsers, leaving all the power of Twisted to an end. <br><br><h1>  Architecture </h1><br> <a href=""><img src="https://habrastorage.org/files/f9e/d31/6cf/f9ed316cf6d1491284c558a99fcd38f4.png"></a> <br><br>  Main blocks: <br>  - queue of requests (tasks); <br>  - "transport" (on the diagram as BaseDownloader); <br>  - middlewares for pre- and post-processing requests; <br>  - pipelines for sequential processing / filtering / saving of extracted data; <br>  - crawler to parse content and generate the following requests; <br>  - the engine that links all the parts. <br><br><h1>  Simplest example </h1><br>  Search the page <a href="http://python.org/news">http://python.org/news for</a> suggestions with the word <code>python</code> simplest regexp. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pomp.core.base <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BaseCrawler <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pomp.contrib.item <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Item, Field <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pomp.contrib.urllibtools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> UrllibHttpRequest python_sentence_re = re.compile(<span class="hljs-string"><span class="hljs-string">'[\w\s]{0,}python[\s\w]{0,}'</span></span>, re.I | re.M) <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> MyItem(Item):  sentence = Field() <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> MyCrawler(BaseCrawler):  """Extract all sentences with `python` word"""  ENTRY_REQUESTS = UrllibHttpRequest(<span class="hljs-string"><span class="hljs-string">'http://python.org/news'</span></span>)  # entry <span class="hljs-type"><span class="hljs-type">point</span></span>  def extract_items(self, response):    <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> python_sentence_re.findall(response.body.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>)):      item = MyItem(sentence=i.strip())      print(item)      yield item <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>:  <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pomp.core.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Pomp  <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pomp.contrib.urllibtools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> UrllibDownloader  pomp = Pomp(    downloader=UrllibDownloader(),  )  pomp.pump(MyCrawler())</code> </pre> <br><h1>  An example of creating a "cluster" for <a href="http://www.craigslist.org/">craigslist.org</a> parsing </h1><br>  The example uses: <br>  - <a href="http://redis.io/">Redis</a> for organizing a centralized task queue; <br>  - Apache <a href="http://kafka.apache.org/">Kafka</a> for the aggregation of extracted data; <br>  - <a href="https://www.djangoproject.com/">Django</a> on postgres for storing and displaying data; <br>  - grafana with kamon dashboards to display the metrics for the operation of the <a href="https://github.com/kamon-io/docker-grafana-graphite">kamon-io / docker-grafana-graphite</a> cluster <br>  - <a href="https://docs.docker.com/compose/">docker-compose</a> to run this whole zoo on one machine. <br><br>  The source code and launch instructions are available here - <a href="https://github.com/estin/pomp-craigslist-example">estin / pomp-craigslist-example</a> . <br><br>  As well as <a href="https://drive.google.com/file/d/0BzRf6g_VWuIjZDUxMGc1Q1ZScFk/view">video without sound</a> , where most of the time was spent on the deployment environment.  On the video you can find some errors in collecting metrics about the size of the task queue. <br><br>  <strong>Note</strong> : in the example, errors in the analysis of some pages were intentionally not corrected, so that exceptions would be investigated during the work process. <br><br><h1>  Future plans </h1><br>  Pomp for the most part has already been formed and achieved its goals. <br>  Further development is likely to be tighter integration with asyncio. <br><br><h3>  Links </h3><br>  - project on bitbucket <a href="https://bitbucket.org/estin/pomp">https://bitbucket.org/estin/pomp</a> <br>  - a mirror of the project on github <a href="https://github.com/estin/pomp">https://github.com/estin/pomp</a> <br>  - documentation <a href="http://pomp.readthedocs.org/en/latest/">http://pomp.readthedocs.org/en/latest/</a> <br></div><p>Source: <a href="https://habr.com/ru/post/278445/">https://habr.com/ru/post/278445/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../278435/index.html">Image binarization: Bradley algorithm</a></li>
<li><a href="../278437/index.html">If programmers were making pancakes (according to kosher methodologies)</a></li>
<li><a href="../278439/index.html">We fix the error of installing updates Windows 7</a></li>
<li><a href="../278441/index.html">Track updates from MongoDB Replica Set Oplog using Scala and Akka Streams</a></li>
<li><a href="../278443/index.html">Physical web concept. Bluetooth beacons. Comparison of iBeacon, AltBeacon and Eddystone standards</a></li>
<li><a href="../278447/index.html">Ralph Baer: "Video Games, I'm your father!"</a></li>
<li><a href="../278449/index.html">Meet at CodeFest</a></li>
<li><a href="../278451/index.html">Dream job or a small history of mobile development</a></li>
<li><a href="../278453/index.html">Adding a proxy to any application on IIS</a></li>
<li><a href="../278459/index.html">Cool sharing pages on social networks using Open Graph</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>