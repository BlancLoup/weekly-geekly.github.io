<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Spatio-temporal image processing on GPU</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Not so long ago it became popular to use video cards for computing. One fine day, a few years ago, and I looked at a new, then, CUDA technology. There...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Spatio-temporal image processing on GPU</h1><div class="post__text post__text-html js-mediator-article">  Not so long ago it became popular to use video cards for computing.  One fine day, a few years ago, and I looked at a new, then, CUDA technology.  There was a good card in the hands of those times GTX8800, and there were also tasks for parallelization. <br>  Who worked with the GPU, knows about the integration of requests, the conflict of banks and how to deal with it, and if it did not work, then you can find several useful articles on the basics of programming on CUDA <a href="http://habrahabr.ru/post/56514/">[1]</a> .  The GTX8800 card, in a sense, was good because it was one of the first and supported only the first versions of CUDA, so it was clearly visible on it when there are bank conflicts or global memory requests are not merged, because time increased in this case times.  All this helped to better understand all the rules for working with the map and write normal code. <br>  In new models add more and more functionality, which facilitates and accelerates the development.  Atomic operations, cache, dynamic parallelism, etc. appeared. <br>  In the post, I will tell you about the space-time filtering of images and the implementation for compute capability = 1.0, and how you can accelerate the resulting result with new features. <br>  Temporal filtering can be useful when observing satellites or in other filtering situations when precise background suppression is required. <br><img src="https://habrastorage.org/getpro/habr/post_images/b0f/c4e/9bc/b0fc4e9bc6f2f4e8bd2388bd6c2363db.png"><br><a name="habracut"></a><br><br><h1>  Some theory </h1><br>  Cut as far as I could, but left the most important thing.  So, at the entrance comes a sequence of frames.  Each frame can be represented as the sum of the matrix noise, the background and the useful signal. <br><img src="https://habrastorage.org/getpro/habr/post_images/811/419/868/811419868bd01c48b8d7e7c9a0a62282.png"><br>  Using several previous frames, you can whitewash the newly arrived frame and highlight the signal, if present.  To do this, it is necessary to predict the background on this frame, to get its assessment, according to the implementation in the previous frames.  Let the number of frames in the history of N, then the background estimate can be represented as the sum of frames with some weights. <br><img src="https://habrastorage.org/getpro/habr/post_images/d30/10d/cd1/d3010dcd1c49dab890ffb7d8cf111978.png"><br>  The quality criterion will be the difference of the frame and the predicted background, which must be minimized. <br><img src="https://habrastorage.org/getpro/habr/post_images/215/691/a60/215691a60b3dfef6c7daa1c45c291269.png"><br>  The solution is: <br><img src="https://habrastorage.org/getpro/habr/post_images/2a0/560/3cf/2a05603cfd82f1126723cbb1a8856181.png"><br>  The sample correlation matrix is ‚Äã‚Äãcalculated as: <br><img src="https://habrastorage.org/getpro/habr/post_images/5c2/cfa/ccf/5c2cfaccfec357abb4c12b18bac6d993.png"><br>  and the vector of the right side has the form: <br><img src="https://habrastorage.org/getpro/habr/post_images/377/7cd/d41/3777cdd418f83fd224e7b403953ee123.png"><br>  where k, l - vary from 1 to N. <br>  However, this method does not take into account frame shift.  If we present the coefficients <img src="https://habrastorage.org/getpro/habr/post_images/21d/cb7/740/21dcb774022a65ca1671394c317bf02b.png">  as an explicit shift function <img src="https://habrastorage.org/getpro/habr/post_images/a30/219/d17/a30219d17919f9953107a49b7ae75079.png">  relative to some reference frame, it is possible to formulate a quality criterion and write a solution.  There should be a lot of formulas, but as a result <img src="https://habrastorage.org/getpro/habr/post_images/21d/cb7/740/21dcb774022a65ca1671394c317bf02b.png">  depends only on shifts. <br>  Shifts are calculated relative to some reference frame. <img src="https://habrastorage.org/getpro/habr/post_images/74e/b41/8fe/74eb418fe1da0dc5d3fe86d46e084d45.png">  according to the following formulas: <br><img src="https://habrastorage.org/getpro/habr/post_images/e23/b08/d4d/e23b08d4d237229626759d2e6ae6e6b3.png"><br>  Knowing the frame shifts relative to the reference frame, we calculate the vector of coefficients a (t) using the following formula: <br><img src="https://habrastorage.org/getpro/habr/post_images/9c5/220/d5d/9c5220d5d2461670f3589cad5313e7dd.png"><br>  Where Œ± is a vector of coefficients of a polynomial of degree n, Œ≥ is a sufficiently small quantity, E is the identity matrix. <br><img src="https://habrastorage.org/getpro/habr/post_images/84a/7a8/5e5/84a7a85e5dccd2d0bd98032582838850.png"><br><br><h1>  GPU implementation </h1><br>  Consider the implementation of the second filtering method.  On the GPU, it is beneficial to transfer the frame whitening function and the function of finding frame shifts.  The function of calculating the whitening coefficients by known shifts takes little time and is too small in size. <br>  Immediately, I‚Äôll make a reservation that this is one of the first projects I wrote, so the code does not pretend to perfection, however, I will try to point out the flaws and ways to correct them, some of them we will fix and look at the result. <br>  First, in the memory of the video card you need to throw a sequence of frames.  To do this, select an array with pointers to the GPU memory and then copy it into the GPU memory too. <br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> **h_array_list, **d_array_list; h_array_list = ( <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>** )<span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>( num_arrays * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* )); cudaMalloc((<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>**)&amp;d_array_list, num_arrays * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> * )); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; num_arrays; i++ ) cudaMalloc((<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>**)&amp;h_array_list[i], data_size); cudaMemcpy( d_array_list, h_array_list, num_arrays * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*), cudaMemcpyHostToDevice );</code> </pre> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      With such an organization there is a small flaw.  If you read from the frame as follows <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> bx = blockIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> by = blockIdx.y; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tx = threadIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ty = threadIdx.y; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> aBegin = nx * BLOCK_SIZE * by + BLOCK_SIZE * bx; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> a = inFrame[ j ][ aBegin + nx * ty + tx]</code> </pre><br>  then in earlier versions of the compute capability, with such a reading, requests were not merged into global memory. <br><br>  This is now a cache and pointers to frames are deposited in it and quickly read.  To satisfy the rules for merging requests, you must either preload these pointers into shared memory (which also takes time) or, for example, do this: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> **h_array_list, **d_array_list; h_array_list = ( <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>** )<span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>( <span class="hljs-number"><span class="hljs-number">16</span></span> * num_arrays * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* ) ); cudaMalloc((<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>**)&amp;d_array_list, <span class="hljs-number"><span class="hljs-number">16</span></span> * num_arrays * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span> *)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; num_arrays; i++ ) { cudaMalloc((<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>**)&amp;h_array_list[i*<span class="hljs-number"><span class="hljs-number">16</span></span>], data_size); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">1</span></span>; j &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; j++ ) h_array_list[ i*<span class="hljs-number"><span class="hljs-number">16</span></span> + j ] = h_array_list[ i*<span class="hljs-number"><span class="hljs-number">16</span></span> ]; } cudaMemcpy( d_array_list, h_array_list, <span class="hljs-number"><span class="hljs-number">16</span></span>*num_arrays * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*), cudaMemcpyHostToDevice );</code> </pre><br><br>  In this case, the read request will be merged and we will notice a noticeable speed increase. <br>  The frame whitening function for a GPU looks like this: <br><br><pre> <code class="cpp hljs">__<span class="hljs-function"><span class="hljs-function">global__ </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kernelWhite</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> * out, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> ** inFrame, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *at, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> nx, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> mem )</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> bx = blockIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> by = blockIdx.y; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tx = threadIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ty = threadIdx.y; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> aBegin = nx * BLOCK_SIZE * by + BLOCK_SIZE * bx; __shared__ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> frame1 [BLOCK_SIZE][BLOCK_SIZE]; __shared__ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> a [<span class="hljs-number"><span class="hljs-number">32</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = ty * BLOCK_SIZE + tx; <span class="hljs-comment"><span class="hljs-comment">//    if( i &lt; mem ) a[ i ] = at[ i ]; __syncthreads (); frame1 [ty][tx] = 0; //         for( int j = 0; j &lt; mem; j++ ) { frame1 [ty][tx] += a[ j ]*inFrame[ j*16 + tx ][ aBegin + nx * ty + tx]; } //   out [ aBegin + nx * ty + tx ] = inFrame[ mem*16 + tx ][ aBegin + nx * ty + tx] - frame1 [ty][tx]; }</span></span></code> </pre><br><br>  In general, everything is simple, we create shared memory for the result of the whitening of the frame, load our vector of coefficients, synchronize the threads, and further in the cycle we whitewash our frame with these coefficients.  Also here you can choose not a square block of flows, but a linear one, which in general will be even more correct, since it will reduce the number of calculations in the indexing. <br>  For the shift search function, a standard optimized algorithm was used to search for the sum of the array <a href="http://steps3d.narod.ru/tutorials/cuda-2-tutorial.html">[2]</a> .  In this function, you must first find the coefficients rij, gij, hij and then calculate it using the sum formulas given above. <br><br><div class="spoiler">  <b class="spoiler_title">__global__ void kernelShift (float * inFrameR, float * inFrame, float * outData, int nx)</b> <div class="spoiler_text"><pre> <code class="cpp hljs">__<span class="hljs-function"><span class="hljs-function">global__ </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kernelShift</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *inFrameR, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *inFrame, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *outData, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> nx )</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> bx = blockIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> by = blockIdx.y; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tx = threadIdx.x; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ty = threadIdx.y; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> aBegin = nx * BLOCK_SIZE * by + BLOCK_SIZE * bx; <span class="hljs-comment"><span class="hljs-comment">//        __shared__ float rij [BLOCK_SIZE*BLOCK_SIZE]; __shared__ float gij [BLOCK_SIZE*BLOCK_SIZE]; __shared__ float hij [BLOCK_SIZE*BLOCK_SIZE]; __shared__ float tmp [BLOCK_SIZE*BLOCK_SIZE]; __shared__ float p [BLOCK_SIZE*BLOCK_SIZE]; __shared__ float q [BLOCK_SIZE*BLOCK_SIZE]; __shared__ float frame1 [BLOCK_SIZE][BLOCK_SIZE]; //    shared memeory frame1 [ty][tx] = inFrameR [ aBegin + nx * ty + tx]; //  __syncthreads (); int i = ty * BLOCK_SIZE + tx; //   gij, hij, rij   1414. if( tx &gt; 0 &amp;&amp; &gt; 0 &amp;&amp; tx &lt; BLOCK_SIZEm1 &amp;&amp; ty &lt; BLOCK_SIZEm1 ) { gij[ i ] = ( frame1[ty + 1][tx] - frame1[ty - 1][tx] )/2.0; hij[ i ] = ( frame1[ty][tx + 1] - frame1[ty][tx - 1] )/2.0; rij[ i ] = ( frame1[ty][tx] + frame1[ty][tx + 1] + frame1[ty][tx - 1] + frame1[ty + 1][tx] + frame1[ty - 1][tx] )/5.0; } else { gij[ i ] = 0; hij[ i ] = 0; rij[ i ] = 0; } //  __syncthreads (); //    shared memeory frame1 [ty][tx] = inFrame [ aBegin + nx * ty + tx] - rij[i]; //  p, q p [i] = gij [i]*frame1 [ty][tx]; q [i] = hij [i]*frame1 [ty][tx]; //  u tmp [i] = hij [i]*hij [i]; //  v rij[i] = hij [i]*gij [i]; //  w hij [i] = gij [i]*gij [i]; __syncthreads (); for ( int s = BLOCK_SIZEhalfqrt; s &gt; 32; s &gt;&gt;= 1 ) { if ( i &lt; s ) { p [i] += p [i + s]; q [i] += q [i + s]; tmp [i] += tmp [i + s]; rij [i] += rij [i + s]; hij [i] += hij [i + s]; } __syncthreads (); } if ( i &lt; 32 ) { p [i] += p [i + 32]; p [i] += p [i + 16]; p [i] += p [i + 8]; p [i] += p [i + 4]; p [i] += p [i + 2]; p [i] += p [i + 1]; q [i] += q [i + 32]; q [i] += q [i + 16]; q [i] += q [i + 8]; q [i] += q [i + 4]; q [i] += q [i + 2]; q [i] += q [i + 1]; tmp [i] += tmp [i + 32]; tmp [i] += tmp [i + 16]; tmp [i] += tmp [i + 8]; tmp [i] += tmp [i + 4]; tmp [i] += tmp [i + 2]; tmp [i] += tmp [i + 1]; rij [i] += rij [i + 32]; rij [i] += rij [i + 16]; rij [i] += rij [i + 8]; rij [i] += rij [i + 4]; rij [i] += rij [i + 2]; rij [i] += rij [i + 1]; hij [i] += hij [i + 32]; hij [i] += hij [i + 16]; hij [i] += hij [i + 8]; hij [i] += hij [i + 4]; hij [i] += hij [i + 2]; hij [i] += hij [i + 1]; } if ( i == 0 ) { outData [ by*gridDim.x + bx ] = p[0]; outData [ by*gridDim.x + bx + gridDim.x*gridDim.y] = q[0]; outData [ by*gridDim.x + bx + 2*gridDim.x*gridDim.y] = tmp [0]; outData [ by*gridDim.x + bx + 3*gridDim.x*gridDim.y] = rij [0]; outData [ by*gridDim.x + bx + 4*gridDim.x*gridDim.y] = hij [0]; } };</span></span></code> </pre><br></div></div><br>  At the very end, it is still necessary to add the results for all the blocks.  Since the number of blocks is not very large, the result is more profitable to get on the processor.  Since for each frame the shift is calculated independently, we can come up with an implementation when one core counts the shift for all frames, adding another dimension to the flow table for indexing the filter memory frames.  However, it will be beneficial if the frames are small. <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    . int numbCoeff = regInfo-&gt;nx / threads.x*regInfo-&gt;nx / threads.y; cudaMemcpy( coeffhost, coeffdev, numbCoeff*5* sizeof ( float ), cudaMemcpyDeviceToHost ); float q = 0, p = 0; float u = 0, v = 0, w = 0; for( int i = 0; i &lt; numbCoeff; i++ ) { p += coeffhost[ i ]; q += coeffhost[ i + numbCoeff]; u += coeffhost[ i + 2*numbCoeff]; v += coeffhost[ i + 3*numbCoeff]; w += coeffhost[ i + 4*numbCoeff]; } dx = ( q * w - p * v )/( u * w - v * v ); dy = ( p * u - q * v )/( u * w - v * v );</span></span></code> </pre><br><br>  What are the main disadvantages here. <br>  1. The final result we get on the processor. <br>  2. The coefficients for the reference frame rij, gij, hij are repeatedly calculated for each frame. <br><br>  Let's look at the result in the profiler and evaluate whether this implementation works well.  The profiler tells us that the read requests are merged, and the instructions take up most of the time. <br>  Offset Search Core: <br><img src="http://habrastorage.org/storage3/85f/4b3/fa5/85f4b3fa5770dc11180e438248b31a14.png" alt="Core search offsets."><br>  Core to whitewash staff: <br><img src="http://habrastorage.org/storage3/26c/ee0/512/26cee0512b38940b67c568a73b4b48dc.png" alt="Core to whitewash staff."><br><br><h1>  <b>Work time and optimization</b> </h1><br>  Since the old GTX8800 was on a different computer and had already gone somewhere, I‚Äôm bringing results for the GTX Titan. <br>  For frames of size 512x512, the following work time results were obtained.  The core for calculating the shift coefficients takes 60 Œºs.  If we add to it the copying of the coefficients and the final summation, we get 130 Œºs.  With a memory of 20 frames, the running time is 2.6 ms, respectively.  The whitening function takes 156 ¬µs.  There is also a function for calculating the coefficients on the processor; this is another 50 ¬µs.  The total is 2.806 ms. <br><br>  Accordingly, on the CPU, the calculation of shifts takes 40 ms, the whitening of the frame is 30 ms and the calculation of the coefficients is another 50 Œºs.  In total, it turns out 70 ms, which is 25 times slower than on the GPU (in fact, it is not, but more on that later). <br><br>  The implementation is quite simple and is compatible with SS = 1.0.  Let's now see what can be fixed.  The last action in the search for shifts can be changed and implemented through atomic operations, which will work several times faster. <br><br>  The modified code now looks like this: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//       if ( i == 0 ) { atomicAdd( &amp;outData[0], p[0] ); atomicAdd( &amp;outData[1], q[0] ); atomicAdd( &amp;outData[2], tmp[0] ); atomicAdd( &amp;outData[3], rij[0] ); atomicAdd( &amp;outData[4], hij[0] ); } //  CPU   float p = coeffhost[ 0 ]; float q = coeffhost[ 1 ]; float u = coeffhost[ 2 ]; float v = coeffhost[ 3 ]; float w = coeffhost[ 4 ]; dx = ( q * w - p * v )/( u * w - v * v ); dy = ( p * u - q * v )/( u * w - v * v );</span></span></code> </pre><br>  In this case, the core takes about the same time, 66 ¬µs. <br><br>  You can get rid of multiple recounting rij, gij, hij by writing a separate kernel to calculate them, but then you have to load them every time, and this is three times more memory, since instead of loading one reference frame you will have to load three frames with coefficients.  The optimal solution would be to make one core to calculate all the shifts at once, making a frame-by-frame loop inside the core. <br>  Suppose that we have a more general task and could not have done so, and it would have been necessary to launch the kernel many times.  At this point, you might think that everything is fine, the cores are written as a whole optimally, and the acceleration turned out up to 25 times, but if you look at the profiler, we will see the following picture: <br><img src="http://habrastorage.org/storage3/38b/0fe/ead/38b0feead327502a1feb5a1c2455d07d.png"><br><br>  Our functions on the GPU work only a small amount of time, the rest is delays, copying memory and other intermediate operations.  In total, it raises 11.5 ms to calculate the offsets for all frames.  As a result, the acceleration turned out only 6 times relative to the CPU.  Remove all intermediate calculations and run the kernels one after the other in a loop: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; regressInfo-&gt;memory - <span class="hljs-number"><span class="hljs-number">1</span></span>; j++ ) kernelShift&lt;&lt;&lt; SKblocks, SKthreads &gt;&gt;&gt; ( ‚Ä¶ );</code> </pre><br><br>  After optimization, the profiler shows a completely different picture. <br><img src="http://habrastorage.org/storage3/725/a69/258/725a692580332ed1f7ec87c2231085ec.png"><br><br>  Much nicer turned out, really? .. Now the part with the calculation of shifts takes 1.40 ms instead of 11.5 ms.  There remained a small interval between the cores of 4 ¬µs, which is given by the profiler.  And now let's try to run the kernel in different threads. <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// stream for( int it = 0; it &lt; 4; it++ ) cudaStreamCreate( &amp;streamTX[it] ); ‚Ä¶‚Ä¶ for( int j = 0; j &lt; regressInfo-&gt;memory - 1; j++ ) kernelShift&lt;&lt;&lt; SKblocks, SKthreads, 0, streamTX[j%4] &gt;&gt;&gt; (‚Ä¶);</span></span></code> </pre><br><br>  Now the profiler shows this result and here the interval is 1.22 ms. <br><br><img src="http://habrastorage.org/storage3/d28/802/687/d28802687f2c19871c6af6776230cd70.png"><br><br>  And it is even less by 0.12 ms than 0.066 * 20 = 1.320. <br>  The processor load is 84%. <br><br><img src="http://habrastorage.org/storage3/5df/90c/cb6/5df90ccb62527f0655d4e9243e27272d.png"><br><br>  As a result, the total time is 1.22 ms + 50 Œºs + 156 Œºs = 1.426 ms, which is 50 times faster than on the CPU. <br>  Of course, it would be more correct to write one core for calculating shifts, but this is another way of optimization, and we considered a more general way, which cannot be underestimated.  You can write a good implementation on the GPU, but forget about optimizing interaction with the GPU.  The less time it takes for the kernel to work, the more the intervals between calls in which there are any actions on the CPU will be affected. <br><br><h1>  <b>Filtration results</b> </h1><br>  For example, images of the starry sky were taken, a moving dim object was added to them, small vibrations and self-noise. <br>  Before processing: <br><img src="http://habrastorage.org/storage3/e4f/0ea/945/e4f0ea94548f532677029d21654cf6b2.png"><br>  After treatment: <br><img src="http://habrastorage.org/storage3/f4e/aae/33e/f4eaae33ec10fdbcdbd39962deba06c8.png"><br>  Before processing: <br><img src="http://habrastorage.org/storage3/f44/4b5/aa9/f444b5aa9f7b384481ce4b30c6bf2b17.png"><br>  After treatment: <br><img src="http://habrastorage.org/storage3/d49/aaa/5a4/d49aaa5a4dfaa54184e04ebb4d041d28.png"><br><br>  In addition to the algorithm, it is possible and even necessary to add the function of deleting an object from previous frames, since it can badly spoil the result of filtering, leaving traces behind. <br>  Unfortunately, the real recording did not work out, but if it works out and it will be interesting for readers, I will write about the results. <br><br>  PS Found 4GB 10Mpix frames with a wide-angle camera.  I'll try to process. <br><br>  1. <a href="http://habrahabr.ru/post/56514/">Work with memory in CUDA.</a> <br>  2. <a href="http://steps3d.narod.ru/tutorials/cuda-2-tutorial.html">The algorithm for calculating the amount of CUDA.</a> </div><p>Source: <a href="https://habr.com/ru/post/210286/">https://habr.com/ru/post/210286/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../210276/index.html">Immersed boundary method for teapots</a></li>
<li><a href="../210278/index.html">$ 99,000 NES Cartridge on eBay</a></li>
<li><a href="../210280/index.html">Great Permutator - the experience of participating in bundles and not only</a></li>
<li><a href="../210282/index.html">Microsoft revenues hit record highs</a></li>
<li><a href="../210284/index.html">13 hacks for your Nokia Lumia</a></li>
<li><a href="../210288/index.html">Cheat Sheet by Design Patterns</a></li>
<li><a href="../210290/index.html">Bill Gates lost to Magnus Carlsen in chess in 9 moves</a></li>
<li><a href="../210294/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ93 (January 19 - 25, 2014)</a></li>
<li><a href="../210296/index.html">Splay trees</a></li>
<li><a href="../210298/index.html">Why do I bet on Julia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>