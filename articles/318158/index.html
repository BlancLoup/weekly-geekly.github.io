<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Slow Cooker: load testing network services</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Linkerd , our service mesh for cloud-based applications, has a duty to cope with large volumes of network traffic for a long time. Before the release ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Slow Cooker: load testing network services</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/4af/3b4/4b8/4af3b44b822c482083cdd2781bd0d3be.jpg" align="left" hspace="10" vspace="10"><br><p>  <em>Linkerd</em> , our <a href="https://blog.buoyant.io/2016/10/04/a-service-mesh-for-kubernetes-part-i-top-line-service-metrics/">service mesh</a> for cloud-based applications, has a duty to cope with large volumes of network traffic for a long time.  Before the release of the next release, compliance with this requirement must be carefully checked.  In this article, we describe the load testing strategies and the tools we use, and also consider a few of the problems found.  As a result, <strong>slow_cooker</strong> will be introduced - an open source load testing tool written on Go, which was created to perform long-term load tests and identify lifecycle issue identification. </p><a name="habracut"></a><br><p>  <a href="http://linkerd.io/">Linkerd</a> acts as a transparent proxy.  It adds connection pooling, failover, retry, load balancing with delays and much more to service-specific requests.  To be a viable and commercially viable system, <em>linkerd</em> must be able to cope with a very large number of requests over long periods of time in a changing environment.  Fortunately, <em>linkerd</em> is based on <a href="http://netty.io/">netty</a> and <a href="https://twitter.github.io/finagle/">Finagle</a> .  Among all network programs, their code is one of the most widely tested and tested in the course of industrial operation.  But code is one thing, but real performance is another. </p><br><p>  In order to evaluate the behavior of the system under industrial operation conditions, <em>linkerd</em> must be subjected to the most thorough and comprehensive load testing.  Moreover, since <em>linkerd</em> is part of the underlying infrastructure, its instances are rarely stopped or restarted, and each of them can pass through itself billions of requests in the face of the changing behavior of services and their clients.  This means that we also need to test lifecycle issues.  For network servers with high bandwidth, such as <em>linkerd</em> , life cycle problems include memory and socket leaks, bad GC pauses, as well as network and disk subsystem overload.  Such things happen infrequently, but if you do not learn to work them out properly, the consequences can be disastrous. </p><br><h4 id="kto-testiruet-programmy-dlya-testirovaniya">  Who tests software for testing? </h4><br><p>  At the initial stage of <em>linkerd</em> development <em>,</em> we used the popular load testing <a href="httpd.apache.org/docs/2.4/programs/ab.html">tools ApacheBench</a> and <a href="https://github.com/rakyll/hey">hey</a> .  (Of course, they only work with HTTP, and <em>linkerd proxies</em> various protocols, including Thrift, gRPC and Mux ‚Äî but. But we had to start somewhere.) </p><br><p>  Unfortunately, we quickly realized that, despite the undoubted usefulness of these tools for quickly obtaining performance data, they are not very good at identifying life-cycle problems that we wanted to learn to identify.  These tools provide a summary of the fact that the test was completed, and with this approach, problems can be overlooked.  Moreover, they rely on averages and standard deviations, which is not, in our opinion, the best way to assess system performance. </p><br><p>  To identify life cycle problems, we needed better metrics and the ability to see how <em>linkerd</em> behaves during long tests, running hours and days, not minutes. </p><br><h4 id="dlya-polucheniya-nezhnogo-koda-gotovim-ne-toropyas">  To get a gentle code we prepare slowly </h4><br><p>  Since we could not find a suitable tool, we had to make our own: <a href="https://github.com/buoyantio/slow_cooker">slow_cooker</a> .  <em>slow_cooker</em> is a load testing program designed specifically to perform long load tests and identify life cycle problems.  We use <em>slow_cooker extensively</em> to look for performance issues and test changes in our products.  In <em>slow_cooker</em> there are step-by-step reports (incremental reports) on the progress of the testing process, change detection (change detection) and all the necessary metrics. </p><br><p>  So that other people can use <em>slow_cooker</em> and participate in the development, today we open its source code.  See <a href="https://github.com/buoyantio/slow_cooker">slow_cooker source on GitHub</a> and the <a href="https://github.com/buoyantio/slow_cooker/releases">recently released release 1.0</a> . </p><br><p>  Let's talk about the features that <em>slow_cooker</em> provides. </p><br><p>  (For simplicity, we will test it directly on the web services themselves. In practice, of course, we use <em>slow_cooker</em> primarily to find problems with <em>linkerd</em> , and not with the services it serves.) </p><br><h4 id="poshagovyy-otchet-o-zaderzhkah-seti">  Step by Step Network Delay Report </h4><br><p>  Since <em>slow_cooker</em> is primarily aimed at identifying life cycle problems that occur over long time periods, it contains the idea of ‚Äã‚Äãstep-by-step reports.  Too much can be missed if we analyze the averaged values ‚Äã‚Äãof a very large amount of input data, especially when it comes to such temporary phenomena as the work of a garbage collector or the saturation of a network.  With step-by-step reports, we can see changes in throughput and delays directly on a running system. </p><br><p>  The example shows the output of <em>slow_cooker</em> obtained during <em>linkerd</em> load testing.  In our test scenario, <em>linkerd</em> balances the load between three <em>nginx</em> servers, each of which distributes static content.  Delays are given in milliseconds, and we derive <em>min</em> , <em>p50</em> , <em>p95</em> , <em>p99</em> , <em>p999,</em> and <em>max-</em> delays, fixed at ten-second intervals. </p><br><pre><code class="bash hljs">$ ./slow_cooker_linux_amd64 -url http://target:4140 -qps 50 -concurrency 10 http://perf-target-2:8080 <span class="hljs-comment"><span class="hljs-comment"># sending 500 req/s with concurrency=10 to http://perf-target-2:8080 ... # good/b/ft good% min [p50 p95 p99 p999] max change 2016-10-12T20:34:20Z 4990/0/0 5000 99% 10s 0 [ 1 3 4 9 ] 9 2016-10-12T20:34:30Z 5020/0/0 5000 100% 10s 0 [ 1 3 6 11 ] 11 2016-10-12T20:34:40Z 5020/0/0 5000 100% 10s 0 [ 1 3 7 10 ] 10 2016-10-12T20:34:50Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 8 ] 8 2016-10-12T20:35:00Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 9 ] 9 2016-10-12T20:35:11Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 11 ] 11 2016-10-12T20:35:21Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 9 ] 9 2016-10-12T20:36:11Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 9 ] 9 2016-10-12T20:36:21Z 5020/0/0 5000 100% 10s 0 [ 1 3 6 9 ] 9 2016-10-12T20:35:31Z 5019/0/0 5000 100% 10s 0 [ 1 3 5 9 ] 9 2016-10-12T20:35:41Z 5020/0/0 5000 100% 10s 0 [ 1 3 6 10 ] 10 2016-10-12T20:35:51Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 9 ] 9 2016-10-12T20:36:01Z 5020/0/0 5000 100% 10s 0 [ 1 3 5 10 ] 10</span></span></code> </pre> <br><p>  This report shows bandwidth in the <code>good%</code> column: how close we got to the required number of requests per second (RPS, requests per second). </p><br><p>  This report looks good: the system is fast and the response time is stable.  At the same time, we should be able to clearly see where and when the trouble started.  The <em>slow_cooker</em> output was configured to facilitate visual search for problems and outliers using vertical alignment, as well as an indicator of the change that occurred.  Let's look at an example where we got a very slow server: </p><br><pre> <code class="bash hljs">$ ./slow_cooker_linux_amd64 -totalRequests 100000 -qps 5 -concurrency 100 http://perf-target-1:8080 <span class="hljs-comment"><span class="hljs-comment"># sending 500 req/s with concurrency=10 to http://perf-target-2:8080 ... # good/b/ft good% min [p50 p95 p99 p999] max change 2016-11-14T20:58:13Z 4900/0/0 5000 98% 10s 0 [ 1 2 6 8 ] 8 + 2016-11-14T20:58:23Z 5026/0/0 5000 100% 10s 0 [ 1 2 3 4 ] 4 2016-11-14T20:58:33Z 5017/0/0 5000 100% 10s 0 [ 1 2 3 4 ] 4 2016-11-14T20:58:43Z 1709/0/0 5000 34% 10s 0 [ 1 6987 6987 6987 ] 6985 +++ 2016-11-14T20:58:53Z 5020/0/0 5000 100% 10s 0 [ 1 2 2 3 ] 3 -- 2016-11-14T20:59:03Z 5018/0/0 5000 100% 10s 0 [ 1 2 2 3 ] 3 -- 2016-11-14T20:59:13Z 5010/0/0 5000 100% 10s 0 [ 1 2 2 3 ] 3 -- 2016-11-14T20:59:23Z 4985/0/0 5000 99% 10s 0 [ 1 2 2 3 ] 3 -- 2016-11-14T20:59:33Z 5015/0/0 5000 100% 10s 0 [ 1 2 3 4 ] 4 -- 2016-11-14T20:59:43Z 5000/0/0 5000 100% 10s 0 [ 1 2 3 5 ] 5 2016-11-14T20:59:53Z 5000/0/0 5000 100% 10s 0 [ 1 2 2 3 ] 3 FROM TO #REQUESTS 0 2 49159 2 8 4433 8 32 8 32 64 0 64 128 0 128 256 0 256 512 0 512 1024 0 1024 4096 0 4096 16384 100</span></span></code> </pre> <br><p>  As you can see, the system works quickly and responsively, except for one hitch in 2016-11-14T20: 58: 43Z, during which the throughput fell to 34%, and then returned to normal.  As the owner of this service, you probably want to see the logs or performance indicators to find out the cause of the incident. </p><br><h4 id="primer-problemy-zhiznennogo-cikla-gc-pauza">  Example of a life cycle problem: GC-pause </h4><br><p>  In order to demonstrate the advantages of step-by-step reports in comparison with the usual reports that only show summary data, let's simulate a situation in which the garbage collector is running on the server.  In this example, we will directly test a single <em>nginx</em> process that distributes static content.  To simulate the delays caused by the garbage collector, we will pause and resume <em>nginx</em> in a cycle at five-second intervals (using <code>kill -STOP $PID</code> and <code>kill -CONT $pid</code> ). </p><br><p>  For comparison, let's start with a report from <a href="httpd.apache.org/docs/2.4/programs/ab.html">ApacheBench</a> : </p><br><pre> <code class="bash hljs">$ ab -n 100000 -c 10 http://perf-target-1:8080/ This is ApacheBench, Version 2.3 &lt;<span class="hljs-variable"><span class="hljs-variable">$Revision</span></span>: 1604373 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking perf-target-1 (be patient) Completed 10000 requests Completed 20000 requests Completed 30000 requests Completed 40000 requests Completed 50000 requests Completed 60000 requests Completed 70000 requests Completed 80000 requests Completed 90000 requests Completed 100000 requests Finished 100000 requests Server Software: nginx/1.9.12 Server Hostname: perf-target-1 Server Port: 8080 Document Path: / Document Length: 612 bytes Concurrency Level: 10 Time taken <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> tests: 15.776 seconds Complete requests: 100000 Failed requests: 0 Total transferred: 84500000 bytes HTML transferred: 61200000 bytes Requests per second: 6338.89 [<span class="hljs-comment"><span class="hljs-comment">#/sec] (mean) Time per request: 1.578 [ms] (mean) Time per request: 0.158 [ms] (mean, across all concurrent requests) Transfer rate: 5230.83 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.2 0 3 Processing: 0 1 64.3 0 5003 Waiting: 0 1 64.3 0 5003 Total: 0 2 64.3 1 5003 Percentage of the requests served within a certain time (ms) 50% 1 66% 1 75% 1 80% 1 90% 1 95% 1 98% 1 99% 2 100% 5003 (longest request)</span></span></code> </pre> <br><p>  Here we see a delay of 1.5 ms, with several emissions with more delays.  Such a report is easy enough to mistakenly consider normal, even though the service being tested did not respond to requests for exactly half the time spent on the test.  If the target SLA value is 1 second, then the service has exceeded it for more than half of the run, but from the report this may not be noticed! </p><br><p>  With <em>slow_cooker</em> step-by-step reports <em>,</em> we see that there is a constantly <em>emerging</em> problem with bandwidth.  It is also much more obvious that <em>P99.9</em> has consistently high values ‚Äã‚Äãthroughout the test: </p><br><pre> <code class="bash hljs">$ ./slow_cooker_linux_amd64 -totalRequests 20000 -qps 50 -concurrency 10 http://perf-target-2:8080 <span class="hljs-comment"><span class="hljs-comment"># sending 500 req/s with concurrency=10 to http://perf-target-2:8080 ... # good/b/ft good% min [p50 p95 p99 p999] max change 2016-12-07T19:05:37Z 2510/0/0 5000 50% 10s 0 [ 0 0 2 4995 ] 4994 + 2016-12-07T19:05:47Z 2520/0/0 5000 50% 10s 0 [ 0 0 1 4999 ] 4997 + 2016-12-07T19:05:57Z 2519/0/0 5000 50% 10s 0 [ 0 0 1 5003 ] 5000 + 2016-12-07T19:06:07Z 2521/0/0 5000 50% 10s 0 [ 0 0 1 4983 ] 4983 + 2016-12-07T19:06:17Z 2520/0/0 5000 50% 10s 0 [ 0 0 1 4987 ] 4986 2016-12-07T19:06:27Z 2520/0/0 5000 50% 10s 0 [ 0 0 1 4991 ] 4988 2016-12-07T19:06:37Z 2520/0/0 5000 50% 10s 0 [ 0 0 1 4995 ] 4992 2016-12-07T19:06:47Z 2520/0/0 5000 50% 10s 0 [ 0 0 2 4995 ] 4994 FROM TO #REQUESTS 0 2 19996 2 8 74 8 32 0 32 64 0 64 128 0 128 256 0 256 512 0 512 1024 0 1024 4096 0 4096 16384 80</span></span></code> </pre> <br><h4 id="otchety-o-zaderzhkah-na-osnove-percentiley">  Percentile-based latency reports </h4><br><p>  As can be seen from the example of ApacheBench, some load testing tools display only the mean value and the standard deviation.  However, these metrics <a href="http://www.brendangregg.com/FrequencyTrails/mean.html">are usually irrelevant in estimating delays</a> that do not follow the law of normal distribution and often have very long tails. </p><br><p>  In <em>slow_cooker,</em> we do not use the mean and standard deviation, but instead display the minimum, maximum, and several percentiles of high order (P50, P95, P99, and P99.9).  This approach is increasingly used in modern software, where one request can generate dozens or even hundreds of calls to other systems and services.  In such situations, metrics like the 95th and 99th percentiles provide the dominant delay value. </p><br><h4 id="zaklyuchenie">  Conclusion </h4><br><p>  Although nowadays writing a load testing tool is not too difficult (especially when using modern programming languages ‚Äã‚Äãthat have built-in support for parallelism and are focused on networking, such as Go, for example), the implementation of the measurement system and report structure can significantly affect on the utility of such a program. </p><br><p>  We are currently using <em>slow_cooker extensively</em> to test <em>linkerd</em> and other services (for example, nginx).  <em>Linkerd is</em> tested in 24x7 mode in terms of interaction with various services, and <em>slow_cooker</em> helped us not only prevent code deployment with serious errors, but also <a href="https://github.com/BuoyantIO/linkerd/issues/392">find performance problems in existing releases</a> .  <em>Buoyant's</em> use of <em>slow_cooker</em> has become so ubiquitous that we began to call load testing programs "sounding." </p><br><p>  <em>You</em> can start working with <em>slow_cooker</em> by visiting the <a href="https://github.com/buoyantio/slow_cooker/releases">releases page on Github</a> .  Download the tool and start testing your favorite server to see if it has performance problems.  When testing <em>linkerd</em> <em>slow_cooker</em> helped us a lot, and we hope that you will find it equally useful. </p><br><h4 id="materialy-dlya-dalneyshego-chteniya-na-angliyskom">  Materials for further reading (in English) </h4><br><ul><li>  <a href="http://perfdynamics.blogspot.com/2012/01/throughput-delay-curves.html">Throughput-delay curves</a> </li><li>  <a href="http://www.brendangregg.com/FrequencyTrails/mean.html">Frequency Trails: What the Mean Really Means</a> </li><li>  <a href="http://saladwithsteve.com/2008/06/simulating-byzantine-failure-with.html">Simulating Byzantine Failure with SIGSTOP</a> </li><li>  <a href="http://bravenewgeek.com/everything-you-know-about-latency-is-wrong/">Everything You Know About Latency Is Wrong</a> </li><li>  <a href="https://www.youtube.com/watch%3Fv%3DlJ8ydIuPFeU%26feature%3Dyoutu.be">How NOT to measure latency</a> </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/318158/">https://habr.com/ru/post/318158/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../318144/index.html">Lecture by Charles Moore, creator of Forth: 144-core processor, why? Is it difficult to program 144 cores?</a></li>
<li><a href="../318146/index.html">Quake Live Server Setup - Step-by-Step Guide</a></li>
<li><a href="../318148/index.html">Fast course Redux + websockets for backend</a></li>
<li><a href="../318150/index.html">Poisson distribution and football betting</a></li>
<li><a href="../318154/index.html">Practical interpretation of the method and indicators of mastered volume</a></li>
<li><a href="../318162/index.html">Smart home NooLite. Scenario number 1 - "Master of the house"</a></li>
<li><a href="../318164/index.html">Why Hackintosh is already relevant. Debunking Myths</a></li>
<li><a href="../318168/index.html">DotNext 2016 Moscow: Calm after a storm</a></li>
<li><a href="../318170/index.html">How ‚Äúinterface‚Äù differs from ‚Äúintermordia‚Äù: our approach to documenting and localizing software products</a></li>
<li><a href="../318172/index.html">Methbot advertising botnet brings $ 3- $ 5 million per day to its owners</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>