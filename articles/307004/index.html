<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Mathematics for artificial neural networks for beginners, part 1 - linear regression</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Table of contents 
 Part 1 - linear regression 
 Part 2 - Gradient Descent 
 Part 3 - Gradient Descent continued 

 Introduction 
 With this post I wi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Mathematics for artificial neural networks for beginners, part 1 - linear regression</h1><div class="post__text post__text-html js-mediator-article"><h5>  Table of contents </h5><br>  Part 1 - linear regression <br>  <a href="https://habrahabr.ru/post/307312/">Part 2 - Gradient Descent</a> <br>  <a href="https://habrahabr.ru/post/308604/">Part 3 - Gradient Descent continued</a> <br><br><h4>  Introduction </h4><br>  With this post I will start the cycle ‚ÄúNeural networks for beginners‚Äù.  It is dedicated to artificial neural networks (suddenly).  The purpose of the cycle is to explain this mathematical model.  Often, after reading such articles, I still had a feeling of understatement, misunderstandings - the National Assembly was still a ‚Äúblack box‚Äù - it is generally known how they are structured, what they do, what they know and what the input and output data are known for.  But nevertheless a complete, comprehensive understanding is missing.  And modern libraries with very pleasant and convenient abstractions only reinforce the feeling of the ‚Äúblack box‚Äù.  I can not say that this is definitely bad, but it‚Äôs also never too late to understand the tools used.  Therefore, my primary goal is to provide a detailed explanation of the structure of neural networks so that absolutely no one has any questions about their structure;  so that the NA does not seem like magic.  Since this is not a mathematical treatise, I will confine myself to describing several methods in simple language (but not excluding formulas, of course), providing explanatory illustrations and examples. <br><br>  The cycle is designed for the basic university level of mathematical reading.  The code will be written in Python3.5 with numpy 1.11.  The list of other auxiliary libraries will be at the end of each post.  Absolutely everything will be written from scratch.  The MNIST base is chosen as the test subject. These are black and white, centered images of handwritten numerals of 28 * 28 pixels.  By default, 60,000 images are marked for training, and 10,000 for testing.  In the examples, I will not change the default distribution. <br><a name="habracut"></a><br>  Sample images from MNIST: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/b1f/29c/ced/b1f29cced9254432bcd6ce3fb338a0ed.png"><br><br>  I will not focus on the structure of MNIST and just lay out the code that loads the database and saves it in the right format.  This format will be used in the following examples: <br><br><div class="spoiler">  <b class="spoiler_title">loader.py</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> struct <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gzip <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle TRAIN_IMAGES_URL = <span class="hljs-string"><span class="hljs-string">"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz"</span></span> TRAIN_LABELS_URL = <span class="hljs-string"><span class="hljs-string">"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz"</span></span> TEST_IMAGES_URL = <span class="hljs-string"><span class="hljs-string">"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz"</span></span> TEST_LABELS_URL = <span class="hljs-string"><span class="hljs-string">"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">downloader</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url: str)</span></span></span><span class="hljs-function">:</span></span> response = requests.get(url, stream=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> response.status_code != <span class="hljs-number"><span class="hljs-number">200</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Response for"</span></span>, url, <span class="hljs-string"><span class="hljs-string">"is"</span></span>, response.status_code) exit(<span class="hljs-number"><span class="hljs-number">1</span></span>) print(<span class="hljs-string"><span class="hljs-string">"Downloaded"</span></span>, int(response.headers.get(<span class="hljs-string"><span class="hljs-string">'content-length'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)), <span class="hljs-string"><span class="hljs-string">"bytes"</span></span>) decompressed = gzip.decompress(response.raw.read()) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> decompressed <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_url: str, labels_url: str)</span></span></span><span class="hljs-function"> -&gt; (np.array, np.array):</span></span> images_decompressed = downloader(images_url) <span class="hljs-comment"><span class="hljs-comment"># Big endian 4   unsigned int,   4  magic, size, rows, cols = struct.unpack("&gt;IIII", images_decompressed[:16]) if magic != 2051: print("Wrong magic for", images_url, "Probably file corrupted") exit(2) image_data = np.array(np.frombuffer(images_decompressed[16:], dtype=np.dtype((np.ubyte, (rows * cols,)))) / 255, dtype=np.float32) labels_decompressed = downloader(labels_url) # Big endian 2   unsigned int,   4  magic, size = struct.unpack("&gt;II", labels_decompressed[:8]) if magic != 2049: print("Wrong magic for", labels_url, "Probably file corrupted") exit(2) labels = np.frombuffer(labels_decompressed[8:], dtype=np.ubyte) return image_data, labels with open("test_images.pkl", "w+b") as output: pickle.dump(load_data(TEST_IMAGES_URL, TEST_LABELS_URL), output) with open("train_images.pkl", "w+b") as output: pickle.dump(load_data(TRAIN_IMAGES_URL, TRAIN_LABELS_URL), output)</span></span></code> </pre> <br></div></div><br><br><h4>  Linear regression </h4><br>  Linear regression is a method for restoring dependency between two variables.  Linear means that we assume that variables are expressed through an equation of the form: <img src="https://habrastorage.org/files/8c4/5ac/db7/8c45acdb73ed43cdb1681fdd40238c7c.png">  Epsilon here is a model error.  Also, for clarity and simplicity, we will deal with a one-dimensional model - multidimensionality does not add complexity, but the illustration will not work.  For a moment, we‚Äôll forget about MNIST and generate some data stretched into a line.  We also rewrite the regression model (hypothesis) as follows: <img src="https://habrastorage.org/files/a2f/09c/780/a2f09c780ce64c318767d83edd313fe3.png">  .  y with a cap is the predicted value of the model. <img src="https://habrastorage.org/files/055/53d/a7c/05553da7c2b243a2b3a39536b55731e9.png">  1 and 2 - unknown parameters - the main task is to find these parameters, and x is a free variable, its values ‚Äã‚Äãare known to us.  We formulate the problem again and in a slightly different language - we have a set of experimental data in the form of pairs of values <img src="https://habrastorage.org/files/cf3/81f/50a/cf381f50ad1946999b466658a3d63d66.png">  and you need to find a straight line on which these values ‚Äã‚Äãare located, to find a line that would best summarize the experimental data.  Some code to generate data: <br><br><div class="spoiler">  <b class="spoiler_title">generate_linear.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt TOTAL = <span class="hljs-number"><span class="hljs-number">200</span></span> STEP = <span class="hljs-number"><span class="hljs-number">0.25</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.2</span></span> * x + <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generate_sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(total=TOTAL)</span></span></span><span class="hljs-function">:</span></span> x = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> x &lt; total * STEP: <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> func(x) + np.random.uniform(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) * np.random.uniform(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>) x += STEP X = np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, TOTAL * STEP, STEP) Y = np.array([y <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> generate_sample(TOTAL)]) Y_real = np.array([func(x) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X]) plt.plot(X, Y, <span class="hljs-string"><span class="hljs-string">'bo'</span></span>) plt.plot(X, Y_real, <span class="hljs-string"><span class="hljs-string">'g'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">2.0</span></span>) plt.show()</code> </pre><br></div></div><br><br>  As a result, something like this should turn out - quite accidentally for an unprepared human eye: <br><br><img src="https://habrastorage.org/files/619/e50/5fd/619e505fd9a043e3aaba9c91d5e8f0e1.png"><br><br>  The green line is ‚Äúbase‚Äù - data is randomly distributed above and below this line, the distribution is uniform.  The equation for the green line is: <img src="https://habrastorage.org/files/078/9fa/304/0789fa3044a741eeb12ac666401f5f21.png"><br><br><h4>  Least square method </h4><br>  The essence of MNCs is to find such parameters. <img src="https://habrastorage.org/files/c10/905/40f/c1090540f0894d4890a6c0595b0abe76.png">  so that the predicted value is closest to real.  Graphically, it expresses something like this: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt plt.plot([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>], [<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'bo'</span></span>) plt.plot([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>], [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>], <span class="hljs-string"><span class="hljs-string">'-ro'</span></span>) plt.show()</code> </pre><br></div></div><br><br><img src="https://habrastorage.org/files/384/33e/76f/38433e76f019465a901fd6b9149c9323.png"><br><br>  The closest - means that the vector <img src="https://habrastorage.org/files/46e/bfe/349/46ebfe349e5d40dc8b5c5ae2e112931b.png">  should have the shortest possible length.  Since the vector is not the only one, it is postulated that the sum of the <i>squares of the</i> lengths of all vectors should tend to the minimum, taking into account the vector of parameters <img src="https://habrastorage.org/files/c10/905/40f/c1090540f0894d4890a6c0595b0abe76.png">  .  In my opinion, quite logical method, speculative.  Nevertheless, there is a mathematical proof of the correctness of this <i>Remarque</i> method: by length we mean the <a href="https://ru.wikipedia.org/wiki/%25D0%2595%25D0%25B2%25D0%25BA%25D0%25BB%25D0%25B8%25D0%25B4%25D0%25BE%25D0%25B2%25D0%25B0_%25D0%25BC%25D0%25B5%25D1%2582%25D1%2580%25D0%25B8%25D0%25BA%25D0%25B0">Euclidean metric</a> , although this is not necessary.  <i>Remark 2</i> : note that the sum of the squares.  Again, no one forbids trying to minimize just the <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BD%25D0%25B0%25D0%25B8%25D0%25BC%25D0%25B5%25D0%25BD%25D1%258C%25D1%2588%25D0%25B8%25D1%2585_%25D0%25BC%25D0%25BE%25D0%25B4%25D1%2583%25D0%25BB%25D0%25B5%25D0%25B9">sum of the lengths</a> .  In this picture, the red dots are the predicted value ( <img src="https://habrastorage.org/files/94b/afc/814/94bafc814ece473ea868c446f05ba9f7.png">  ), blue - obtained as a result of the experiment (y without a cap). <img src="https://habrastorage.org/files/092/270/b05/092270b05729423a87d18191c7413bc3.png">  - this is just the difference between them, the length of the vector. <br>  Mathematically, it looks like this: <img src="https://habrastorage.org/files/4d6/df4/454/4d6df4454ed844798c8a5c47d638a28c.png">  - it is required to find such a vector <img src="https://habrastorage.org/files/db1/1f1/9df/db11f19df492419bbbe446412f565fe4.png">  in which the expression <img src="https://habrastorage.org/files/790/30e/696/79030e6960af4a8e8518c78745761b57.png">  reaches a minimum.  The function f in this expression is: <br><br><img src="https://habrastorage.org/files/89a/91f/0fb/89a91f0fb0f04659ba5f67861ebda926.png">  or <br><img src="https://habrastorage.org/files/ded/59c/f03/ded59cf03fb742d19005507a7d0e0d5d.png"><br><br>  I had been thinking for a long time whether it was worth going straight to the vectorization of the code and as a result the article would be too long without it.  Therefore, we introduce new notation: <br><img src="https://habrastorage.org/files/1c3/315/cd7/1c3315cd7e894aafb9fdaf4de136cbc2.png">  - vector consisting of the values ‚Äã‚Äãof the dependent variable y - <img src="https://habrastorage.org/files/25d/1dc/17b/25d1dc17b3c34c479a3ee005a4a05d50.png"><br><img src="https://habrastorage.org/files/db1/1f1/9df/db11f19df492419bbbe446412f565fe4.png">  - vector of parameters - <img src="https://habrastorage.org/files/3b0/0d3/d43/3b00d3d439114fa1abfed39895235480.png"><br>  A is the matrix of the values ‚Äã‚Äãof the free variable x.  In this case, the first column is 1 (x_0 is missing) - <img src="https://habrastorage.org/files/bf9/536/c68/bf9536c68cab45c7b765ed8091834430.png">  .  In the one-dimensional case in matrix A there are only two columns - <img src="https://habrastorage.org/files/805/0e0/ad1/8050e0ad168a48749a2ce8de106f57f9.png"><br><br>  After the new notation, the equation of the line goes to the matrix equation of the following form: <img src="https://habrastorage.org/files/e38/1f8/3a5/e381f83a570247498a06618af38caf15.png">  .  In this equation, 2 unknowns are predicted values ‚Äã‚Äãand parameters.  We can try to find out the parameters from the same equation, but with known values: <img src="https://habrastorage.org/files/4cc/6bb/35b/4cc6bb35babd480f84fe466b28f6af44.png">  Otherwise, it can be represented as a system of equations: <img src="https://habrastorage.org/files/ea6/1db/9ed/ea61db9ed9744c0bb23bc9833022b163.png"><br><br>  It would seem that everything is known - both the vector Y and the vector X - it remains only to solve the equation.  The big problem is that the system may not have solutions - otherwise, the matrix A may not have an inverse matrix.  A simple example of a system without a solution ‚Äî any three \ four \ n points not on the same straight line \ plane \ hyperplane ‚Äî this causes the matrix A to become non-square, which means by definition there is no inverse matrix <img src="https://habrastorage.org/files/cfc/925/709/cfc925709586475eb87d298478316e3f.png">  . <br><br>  A vivid example of the impossibility of solving the ‚Äúsimple way‚Äù (using some Gauss method to solve a system): <img src="https://habrastorage.org/files/5ee/5b3/af5/5ee5b3af5a374494bbfa07bc1db8d5dc.png"><br>  The system looks like this: <img src="https://habrastorage.org/files/006/d22/cc9/006d22cc9e054276a518d12270ce0660.png">  - It is unlikely to find solutions for such a system. <br>  As a result, it is impossible to build a line through these three points - one can only construct an approximately correct solution. <br><br>  Such a digression is an explanation of why the MNC and its brothers were needed at all.  Minimizing the cost function (loss function) and the impossibility (unnecessary, harmful) of finding an absolutely exact solution are one of the most basic ideas that underlie neural networks.  But they are still far away, but for now let us return to the method of least squares. <br><br>  OLS tells us that it is necessary to find the minimum of the sum of squares of the vectors of the form: <img src="https://habrastorage.org/files/83e/9fa/3fe/83e9fa3fe9d44e1ca1266eff76e748e9.png">  The sum of squares, taking into account that everything is transformed into a vector \ matrix can be written as follows: <img src="https://habrastorage.org/files/a02/bb5/3b4/a02bb53b48f74f44ab079de7f1cfda1b.png">  . <br>  I will not turn the language to call it a trivial transformation, it can be quite difficult for beginners to get away from simple variables to vectors, so I will write out all this expression completely in ‚Äúopen‚Äù vectors.  Again, so that not a single line is misunderstood by "magic." <br>  To begin with, simply ‚Äúuncover‚Äù the vectors in accordance with their definition: <img src="https://habrastorage.org/files/a3c/885/96c/a3c88596cdb9479cacdd9f660200eb41.png">  . <br>  Check the dimension - for the matrix A it is equal to (n; p), and for the vector <img src="https://habrastorage.org/files/db1/1f1/9df/db11f19df492419bbbe446412f565fe4.png">  - (p; 1), and for vector <img src="https://habrastorage.org/files/1c3/315/cd7/1c3315cd7e894aafb9fdaf4de136cbc2.png">  - (n; 1).  As a result, we obtain the difference of two vectors of dimension (n; 1) - <br><img src="https://habrastorage.org/files/758/f24/717/758f2471788044b59d4ba3919947af7d.png"><br>  Checking the definition - by definition it turns out that each row of the right matrix is ‚Äã‚Äãequal to <img src="https://habrastorage.org/files/f36/880/bf2/f36880bf23474afc95655b89ec77d21c.png">  .  We write further: <img src="https://habrastorage.org/files/f53/b1c/a29/f53b1ca29e22455693c229044c026285.png"><br><br><img src="https://habrastorage.org/files/bce/a84/be5/bcea84be52dd4491aaab398ddfbd985a.png"><br><br><img src="https://habrastorage.org/files/e0d/d07/0f4/e0dd070f4dcb49cb88339c693fdbeef2.png"><br><br><img src="https://habrastorage.org/files/e6c/1fc/678/e6c1fc678230406d926a1c7f43c7b0d1.png"><br><br><img src="https://habrastorage.org/files/198/5d0/566/1985d0566f414e788357aac4e4a07538.png"><br><br>  As a result, the last line is the sum of squares of length, as we need.  Each time, of course, such tricks in the mind turn for a long time, but you can get used to the vector notation quickly.  This has a plus for the programmer - it is more convenient to work and port the code for the GPU, where the vector traveled through the vector.  I somehow ported the Perlin noise generation to the GPU and a rough understanding of the vector notation made the work quite well.  There is also a minus - you have to constantly climb on the Internet to recall the identities and rules of linear algebra.  After proving the fidelity of the vector notation, we proceed to further transformations: <br><br><img src="https://habrastorage.org/files/ab7/6d6/f24/ab76d6f24d164ba690e82295c1cde3b6.png"><br><img src="https://habrastorage.org/files/0d7/807/73b/0d780773b5e34470a8f73fbf258dd233.png"><br><br>  Here the <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D1%2580%25D0%25B0%25D0%25BD%25D1%2581%25D0%25BF%25D0%25BE%25D0%25BD%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D1%2582%25D1%2580%25D0%25B8%25D1%2586%25D0%25B0">properties of matrix transposition</a> are used - namely, the transposition of the sum and product.  And also the fact that expressions <img src="https://habrastorage.org/files/58a/62a/ad4/58a62aad427845b592a6864c0c3d381d.png">  and <img src="https://habrastorage.org/files/ef2/def/500/ef2def50032a4cd1b7afc4a317f6131e.png">  there is a constant.  You can prove it by taking the dimension of the matrices from their definition and calculating the dimension of the expression after all multiplications: <br><img src="https://habrastorage.org/files/75b/e04/b20/75be04b2008941e3a027422f57f66c36.png"><br>  The constant can be represented as a symmetric matrix, therefore: <br><img src="https://habrastorage.org/files/08b/f4f/4d4/08bf4f4d40ae47aca630756ddbb6d504.png"><br><br>  After the transformations and disclosure of brackets, it is time to solve the posed problem ‚Äî to find the minimum of this expression, given <img src="https://habrastorage.org/files/a77/498/ddc/a77498ddc5504ce8aac2b0e97372784d.png">  .  The minimum is quite casual - equating the first differential over <img src="https://habrastorage.org/files/a77/498/ddc/a77498ddc5504ce8aac2b0e97372784d.png">  to zero.  In an amicable way, you must first prove that this minimum exists at all, I propose to omit the proof and spy it in the literature <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D1%2581%25D1%2582%25D1%2580%25D0%25B5%25D0%25BC%25D1%2583%25D0%25BC">yourself</a> .  Intuitively, it is clear that the quadratic function is a parabola, and it has a minimum. <br><br>  So, <br><br><img src="https://habrastorage.org/files/aa4/dfe/ec8/aa4dfeec8dc348e68d8f661b27eb9d1b.png"><br><br><img src="https://habrastorage.org/files/e3e/135/310/e3e135310be94b1082abbac0e4e84aee.png"><br><br><img src="https://habrastorage.org/files/680/eca/b56/680ecab564ce4b379dcafbed9ecc2ca3.png"><br><br><img src="https://habrastorage.org/files/9e7/3ad/81d/9e73ad81dc0c4cf398e26d8e234115aa.png"><br><br><img src="https://habrastorage.org/files/146/694/43c/14669443c3fd4307979635139dc7d49b.png"><br><br><img src="https://habrastorage.org/files/5b3/404/178/5b34041783234f8ba413ead773f47b17.png"><br><br>  Part <img src="https://habrastorage.org/files/ec3/f2b/b5e/ec3f2bb5ed5f4ac89e6dc53368b5ca35.png">  called a pseudo-inverse matrix. <br><br>  Now available all the necessary formulas.  The sequence of actions is as follows: <br>  1) Generate a set of experimental data. <br>  2) Create a matrix A. <br>  3) Find the pseudo-inverse matrix <img src="https://habrastorage.org/files/bf3/a89/b1c/bf3a89b1c63f448d95359e5f1c859cb5.png">  . <br>  4) Find <img src="https://habrastorage.org/files/a77/498/ddc/a77498ddc5504ce8aac2b0e97372784d.png"><br>  After this, the problem will be solved - we will have at our disposal the parameters of a straight line that best summarizes the experimental data.  Otherwise, we will have the parameters for the direct, best expressing the linear dependence of one variable on another - this is exactly what was required. <br><br><div class="spoiler">  <b class="spoiler_title">generate_linear.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt TOTAL = <span class="hljs-number"><span class="hljs-number">200</span></span> STEP = <span class="hljs-number"><span class="hljs-number">0.25</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.2</span></span> * x + <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prediction</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(theta)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> theta[<span class="hljs-number"><span class="hljs-number">0</span></span>] + theta[<span class="hljs-number"><span class="hljs-number">1</span></span>] * x <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generate_sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(total=TOTAL)</span></span></span><span class="hljs-function">:</span></span> x = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> x &lt; total * STEP: <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> func(x) + np.random.uniform(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) * np.random.uniform(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>) x += STEP X = np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, TOTAL * STEP, STEP) Y = np.array([y <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> generate_sample(TOTAL)]) Y_real = np.array([func(x) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X]) A = np.empty((TOTAL, <span class="hljs-number"><span class="hljs-number">2</span></span>)) A[:, <span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span> A[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] = X theta = np.linalg.pinv(A).dot(Y) print(theta) Y_prediction = A.dot(theta) error = np.abs(Y_real - Y_prediction) print(<span class="hljs-string"><span class="hljs-string">"Error sum:"</span></span>, sum(error)) plt.plot(X, Y, <span class="hljs-string"><span class="hljs-string">'bo'</span></span>) plt.plot(X, Y_real, <span class="hljs-string"><span class="hljs-string">'g'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">2.0</span></span>) plt.plot(X, Y_prediction, <span class="hljs-string"><span class="hljs-string">'r'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">2.0</span></span>) plt.show()</code> </pre><br></div></div><br>  And the results: <br><br><img src="https://habrastorage.org/files/7c2/d3d/f3b/7c2d3df3b13f4a46ade26320ec02717b.png"><br><br>  The red line was predicted and almost coincides with the green ‚Äúbase‚Äù.  The parameters in my launch are equal: [3.40470411, 0.19575733].  Try to predict the values ‚Äã‚Äãwill not work, because while the distribution of model errors is unknown.  All that can be done is to check if OLS is true for a given case, the OLS will be the appropriate and best method for generalization.  <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D0%25BE%25D1%2580%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%2593%25D0%25B0%25D1%2583%25D1%2581%25D1%2581%25D0%25B0_%25E2%2580%2594_%25D0%259C%25D0%25B0%25D1%2580%25D0%25BA%25D0%25BE%25D0%25B2%25D0%25B0">Three conditions</a> : <br>  1) Mat expectation of errors is zero. <br>  2) Error variance - a constant value. <br>  3) There is no correlation of errors in different dimensions.  <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25B2%25D0%25B0%25D1%2580%25D0%25B8%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F">The covariance</a> is zero. <br><br>  To do this, I added an example by calculating the required values ‚Äã‚Äãand carried out measurements twice: <br><br><div class="spoiler">  <b class="spoiler_title">generate_linear.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt TOTAL = <span class="hljs-number"><span class="hljs-number">200</span></span> STEP = <span class="hljs-number"><span class="hljs-number">0.25</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.2</span></span> * x + <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prediction</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(theta)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> theta[<span class="hljs-number"><span class="hljs-number">0</span></span>] + theta[<span class="hljs-number"><span class="hljs-number">1</span></span>] * x <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generate_sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(total=TOTAL)</span></span></span><span class="hljs-function">:</span></span> x = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> x &lt; total * STEP: <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> func(x) + np.random.uniform(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) * np.random.uniform(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>) x += STEP X = np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, TOTAL * STEP, STEP) Y = np.array([y <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> generate_sample(TOTAL)]) Y_real = np.array([func(x) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> X]) A = np.empty((TOTAL, <span class="hljs-number"><span class="hljs-number">2</span></span>)) A[:, <span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span> A[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] = X theta = np.linalg.pinv(A).dot(Y) print(theta) Y_prediction = A.dot(theta) error = Y - Y_prediction error_squared = error ** <span class="hljs-number"><span class="hljs-number">2</span></span> M = sum(error) / len(error) M_squared = M ** <span class="hljs-number"><span class="hljs-number">2</span></span> D = sum([sq - M_squared <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> sq <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> error_squared]) / len(error) print(<span class="hljs-string"><span class="hljs-string">"M:"</span></span>, M) print(<span class="hljs-string"><span class="hljs-string">"D:"</span></span>, D) plt.plot(X, Y, <span class="hljs-string"><span class="hljs-string">'bo'</span></span>) plt.plot(X, Y_real, <span class="hljs-string"><span class="hljs-string">'g'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">2.0</span></span>) plt.plot(X, Y_prediction, <span class="hljs-string"><span class="hljs-string">'r'</span></span>, linewidth=<span class="hljs-number"><span class="hljs-number">2.0</span></span>) plt.show()</code> </pre><br></div></div><br><br><img src="https://habrastorage.org/files/0ab/b58/659/0abb586596ae42ffa2623c65056e9be8.png"><br><br>  Imperfect, but without deception, everything works as expected. <br><br>  <a href="https://habrahabr.ru/post/307312/">The next part.</a> <br><br>  A complete list of libraries to run examples: numpy, matplotlib, requests. <br>  The materials used in the article - <a href="https://github.com/m9psy/neural_nework_habr_guide">https://github.com/m9psy/neural_nework_habr_guide</a> </div><p>Source: <a href="https://habr.com/ru/post/307004/">https://habr.com/ru/post/307004/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../306990/index.html">AWS Server-less API in 15 minutes</a></li>
<li><a href="../306992/index.html">Wordpress multisite with different databases</a></li>
<li><a href="../306996/index.html">Conditional dependency injection in ASP.NET Core. Part 1</a></li>
<li><a href="../306998/index.html">15 Things You Should Know About Ansible</a></li>
<li><a href="../307002/index.html">From registration to showcase: how to put a mobile app in the App Store and Google Play (part 2)</a></li>
<li><a href="../307006/index.html">OneBox opened an official office in Kiev</a></li>
<li><a href="../307008/index.html">BILLmanager. Now with the help of shell scripts you can sell anything</a></li>
<li><a href="../307010/index.html">Proof 2 Cases BTF</a></li>
<li><a href="../307012/index.html">Rating of programming languages ‚Äã‚Äãin 2016</a></li>
<li><a href="../307014/index.html">As one admin zoo tamed</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>