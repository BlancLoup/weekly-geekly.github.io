<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Predictive data analytics - modeling and validation</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I present to you the translation of the chapter from the book Hands-On Data Science with Anaconda 
 "Predictive data analytics - modeling and validati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Predictive data analytics - modeling and validation</h1><div class="post__text post__text-html js-mediator-article">  I present to you the translation of the chapter from the book Hands-On Data Science with Anaconda <br>  <b>"Predictive data analytics - modeling and validation"</b> <br><br><img src="https://habrastorage.org/webt/eg/b0/jk/egb0jk10gh3cnlxzozestcagccc.png" height="500" width="300"><br><br>  Our main goal in conducting various data analyzes is to look for patterns to predict what may happen in the future.  For the stock market, researchers and specialists conduct various tests to understand the market mechanisms.  In this case, you can ask a lot of questions.  What will be the level of the market index in the next five years?  What will be the next IBM price range?  Will market volatility increase or decrease in the future?  What could be the impact if governments change their tax policy?  What is the potential profit and loss if one country starts a trade war with another?  How do we predict consumer behavior by analyzing some related variables?  Can we predict the likelihood of a graduate graduating successfully?  Can we find a connection between the specific behavior of one particular disease? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Therefore, we consider the following topics: <br><br><ul><li>  Understanding Predictive Data Analysis </li><li>  Useful data sets </li><li>  Forecasting future events </li><li>  Model selection </li><li>  Granger causality test </li></ul><a name="habracut"></a><br><h2>  Understanding Predictive Data Analysis </h2><br>  People may have a lot of questions regarding future events. <br><br><ul><li>  An investor, if he can predict the future movement of the stock price, he can get a big profit. </li><li>  Companies, if they could predict the trend of their products, they could increase their stock price and market share. </li><li>  Governments, if they could predict the impact of an aging population on society and the economy, they would have more incentives to develop better policies in terms of the state budget and other relevant strategic decisions. </li><li>  Universities, if they could understand market demand well in terms of quality and skill sets for their graduates, they could develop a set of better programs or launch new programs to meet future needs in terms of labor. </li></ul><br>  For a better prediction, researchers should consider many questions.  For example, is the sample data too small?  How to remove missing variables?  Is this dataset biased in terms of data collection procedures?  How do we treat extreme values ‚Äã‚Äãor outliers?  What is the seasonality and how do we cope with it?  What models should we use?  This chapter will cover some of these issues.  Let's start with a useful dataset. <br><br><h1>  Useful data sets </h1><br>  One of the best data sources is the <a href="https://archive.ics.uci.edu/ml/datasets.html">UCI Machine Learning Repository</a> .  Having visited the site we will see the following list: <br><br><img src="https://habrastorage.org/webt/p2/sa/47/p2sa47ajhhmjdwnigi4vg19raue.png"><br><br>  For example, if you select the first data set (Abalone), we will see the following.  To save space, only the top part is displayed: <br><br><img src="https://habrastorage.org/webt/g2/6i/u4/g26iu42u1yln7fvxz4oj_cybzxm.png"><br><br>  From here, users can download a dataset and find variable definitions.  The following code can be used to load a dataset: <br><br><pre><code class="bash hljs">dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"UCIdatasets"</span></span> path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) dim(.UCIdatasets) head(.UCIdatasets)</code> </pre> <br>  The corresponding output is shown here: <br><br><img src="https://habrastorage.org/webt/sk/rn/8j/skrn8jh3kygkqwxfvpzza2xnnzk.png"><br><br>  From the previous output, we know that there are 427 observations (data sets) in the data set.  For each of these, we have 7 related functions, such as <i>Name, Data_Types, Default_Task, Attribute_Types, N_Instances</i> (number of instances), <i>N_Attributes</i> (number of attributes), and <i>Year</i> .  A variable called <i>Default_Task</i> can be interpreted as the main use of each data set.  For example, the first data set, called <i>Abalone</i> , can be used for <i>Classification</i> .  The <i>unique ()</i> function can be used to search for all possible <i>Default_Task</i> shown here: <br><br><img src="https://habrastorage.org/webt/ul/4-/fj/ul4-fjckb20uvcz1iif9yup4wem.png"><br><br><h3>  R package AppliedPredictiveModeling </h3><br>  This package includes many useful data sets that can be used for this chapter and others.  The easiest way to find these datasets is using the <i>help ()</i> function shown here: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(package=AppliedPredictiveModeling)</code> </pre><br>  Here we show some examples of loading these datasets.  To load a single data set, we use the <i>data ()</i> function.  For the first data set, called <i>abalone</i> , we have the following code: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) data(abalone) dim(abalone) head(abalone)</code> </pre><br>  The output is as follows: <br><br><img src="https://habrastorage.org/webt/wb/ah/sb/wbahsbbuw2teuts6nhjhiqawm4g.png"><br><br>  Sometimes, a large dataset includes several sub-datasets: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) data(solubility) ls(pattern=<span class="hljs-string"><span class="hljs-string">"sol"</span></span>)</code> </pre><br><pre> <code class="bash hljs">[1] <span class="hljs-string"><span class="hljs-string">"solTestX"</span></span> <span class="hljs-string"><span class="hljs-string">"solTestXtrans"</span></span> <span class="hljs-string"><span class="hljs-string">"solTestY"</span></span> [4] <span class="hljs-string"><span class="hljs-string">"solTrainX"</span></span> <span class="hljs-string"><span class="hljs-string">"solTrainXtrans"</span></span> <span class="hljs-string"><span class="hljs-string">"solTrainY"</span></span></code> </pre><br>  To load each data set, we could use the <i>dim ()</i> , <i>head ()</i> , <i>tail (),</i> and <i>summary ()</i> functions. <br><br><h3>  Time Series Analytics </h3><br>  Time series can be defined as a set of values ‚Äã‚Äãobtained at successive times, often with equal intervals between them.  There are different periods, such as annual, quarterly, monthly, weekly and daily.  For time series GDP (gross domestic product), we usually use quarterly or annual.  For quotes - annual, monthly and daily frequency.  Using the following code, we can obtain US GDP data both quarterly and for an annual period: <br><br><pre> <code class="bash hljs">ath&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPannual"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) head(.usGDPannual)</code> </pre> <br><pre> <code class="bash hljs">YEAR GDP 1 1930 92.2 2 1931 77.4 3 1932 59.5 4 1933 57.2 5 1934 66.8 6 1935 74.3</code> </pre><br><pre> <code class="bash hljs">dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPquarterly"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) head(.usGDPquarterly)</code> </pre><br><pre> <code class="bash hljs"> DATE GDP_CURRENT GDP2009DOLLAR 1 1947Q1 243.1 1934.5 2 1947Q2 246.3 1932.3 3 1947Q3 250.1 1930.3 4 1947Q4 260.3 1960.7 5 1948Q1 266.2 1989.5 6 1948Q2 272.9 2021.9</code> </pre><br>  However, we have many questions for analyzing time series.  For example, in terms of macroeconomics, we have business or economic cycles.  Industries or companies may have seasonality.  For example, using the agricultural industry, farmers will spend more in the spring and autumn seasons and less for the winter.  For retail, they would have a huge cash flow at the end of the year. <br><br>  To manipulate time series, we could use many useful functions included in the R package, called <i>timeSeries</i> .  In the example, we take the daily average data with a weekly frequency: <br><br><pre> <code class="bash hljs">library(timeSeries) data(MSFT) x &lt;- MSFT by &lt;- timeSequence(from = start(x), to = end(x), by = <span class="hljs-string"><span class="hljs-string">"week"</span></span>) y&lt;-aggregate(x,by,mean)</code> </pre><br>  We could also use the <i>head ()</i> function to see several observations: <br><pre> <code class="bash hljs">head(x)</code> </pre><br><pre> <code class="bash hljs">GMT Open High Low Close Volume 2000-09-27 63.4375 63.5625 59.8125 60.6250 53077800 2000-09-28 60.8125 61.8750 60.6250 61.3125 26180200 2000-09-29 61.0000 61.3125 58.6250 60.3125 37026800 2000-10-02 60.5000 60.8125 58.2500 59.1250 29281200 2000-10-03 59.5625 59.8125 56.5000 56.5625 42687000 2000-10-04 56.3750 56.5625 54.5000 55.4375 68226700</code> </pre><br><pre> <code class="bash hljs">head(y)</code> </pre> <br><pre> <code class="bash hljs">GMT Open High Low Close Volume 2000-09-27 63.4375 63.5625 59.8125 60.6250 53077800 2000-10-04 59.6500 60.0750 57.7000 58.5500 40680380 2000-10-11 54.9750 56.4500 54.1625 55.0875 36448900 2000-10-18 53.0375 54.2500 50.8375 52.1375 50631280 2000-10-25 61.7875 64.1875 60.0875 62.3875 86457340 2000-11-01 66.1375 68.7875 65.8500 67.9375 53496000</code> </pre> <br><br><h2>  Forecasting future events </h2><br>  There are many methods that we could use when trying to predict the future, such as moving average, regression, autoregression, etc. First, let's start with the simplest for the moving average: <br><br><pre> <code class="bash hljs">movingAverageFunction&lt;- <span class="hljs-keyword"><span class="hljs-keyword">function</span></span>(data,n=10){ out= data <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> n:length(data)){ out[i] = mean(data[(i-n+1):i]) } <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>(out) }</code> </pre> <br>  In the previous code, the default value for the number of periods is 10. We could use a data set, called MSFT, included in the R package, called <i>timeSeries</i> (see the following code): <br><br><pre> <code class="bash hljs">library(timeSeries) data(MSFT) p&lt;-MSFT<span class="hljs-variable"><span class="hljs-variable">$Close</span></span> <span class="hljs-comment"><span class="hljs-comment"># ma&lt;-movingAverageFunction(p,3) head(p)</span></span></code> </pre> <br><pre> <code class="bash hljs">[1] 60.6250 61.3125 60.3125 59.1250 56.5625 55.4375</code> </pre> <br><pre> <code class="bash hljs">head(ma)</code> </pre> <br><pre> <code class="bash hljs">[1] 60.62500 61.31250 60.75000 60.25000 58.66667 57.04167</code> </pre> <br><pre> <code class="bash hljs">mean(p[1:3])</code> </pre> <br><pre> <code class="bash hljs">[1] 60.75</code> </pre> <br><pre> <code class="bash hljs">mean(p[2:4])</code> </pre> <br><pre> <code class="bash hljs">[1] 60.25</code> </pre> <br>  In manual mode, we find that the average of the first three <i>x</i> values ‚Äã‚Äãcoincides with the third value of <i>y</i> .  In a sense, we could use a moving average to predict the future. <br><br>  In the following example, we will show how to estimate the expected profitability of the market next year.  Here we use the S &amp; P500 index and historical average as our expected values.  The first few commands are used to load a related dataset called <i>.sp500monthly</i> .  The aim of the program is to estimate the average annual and 90 percent confidence interval: <br><br><pre> <code class="bash hljs">library(data.table) path&lt;-<span class="hljs-string"><span class="hljs-string">'http://canisius.edu/~yany/RData/'</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">'sp500monthly.RData'</span></span> link&lt;-paste(path,dataSet,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(link)) <span class="hljs-comment"><span class="hljs-comment">#head(.sp500monthly,2) p&lt;-.sp500monthly$ADJ.CLOSE n&lt;-length(p) logRet&lt;-log(p[2:n]/p[1:(n-1)]) years&lt;-format(.sp500monthly$DATE[2:n],"%Y") y&lt;-data.frame(.sp500monthly$DATE[2:n],years,logRet) colnames(y)&lt;-c("DATE","YEAR","LOGRET") y2&lt;- data.table(y) z&lt;-y2[,sum(LOGRET),by=YEAR] z2&lt;-na.omit(z) annualRet&lt;-data.frame(z2$YEAR,exp(z2[,2])-1) n&lt;-nrow(annualRet) std&lt;-sd(annualRet[,2]) stdErr&lt;-std/sqrt(n) ourMean&lt;-mean(annualRet[,2]) min2&lt;-ourMean-2*stdErr max2&lt;-ourMean+2*stdErr cat("[min mean max ]\n")</span></span></code> </pre> <br><pre> <code class="bash hljs">[min mean max ]</code> </pre><br><pre> <code class="bash hljs">cat(min2,ourMean,max2,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">0.05032956 0.09022369 0.1301178</code> </pre><br>  As can be seen from the results, the historical average annual yield for the S &amp; P500 is 9%.  But we cannot say that next year the index yield will be equal to 9%, since  it can be from 5% to 13%, and these are huge fluctuations. <br><br><h3>  Seasonality </h3><br>  In the following example, we will show the use of autocorrelation.  First, we load the R package called <i>astsa</i> , which serves for an applied statistical analysis of time series.  Then we load the US GDP at quarterly frequency: <br><br><pre> <code class="bash hljs">library(astsa) path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPquarterly"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) x&lt;-.usGDPquarterly<span class="hljs-variable"><span class="hljs-variable">$DATE</span></span> y&lt;-.usGDPquarterly<span class="hljs-variable"><span class="hljs-variable">$GDP_CURRENT</span></span> plot(x,y) diff4 = diff(y,4) acf2(diff4,24)</code> </pre> <br>  In the above code, the <i>diff ()</i> function accepts the difference, for example, the current value minus the previous value.  The second input value indicates a delay.  A function called <i>acf2 ()</i> is used to build and print the ACF and PACF time series.  ACF denotes the autocovariance function, and PACF denotes the partial autocorrelation function.  The corresponding graphs are shown here: <br><br><img src="https://habrastorage.org/webt/n6/89/sv/n689svzvvvik4co4abbgzeobtnw.png" height="400" width="300"><br><br><h3>  <b>Component visualization</b> </h3><br>  It is clear that concepts and data sets would be much more comprehensible if we could use graphics.  The first example shows the fluctuations in US GDP over the past five decades: <br><br><pre> <code class="bash hljs">path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPannual"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) title&lt;-<span class="hljs-string"><span class="hljs-string">"US GDP"</span></span> xTitle&lt;-<span class="hljs-string"><span class="hljs-string">"Year"</span></span> yTitle&lt;-<span class="hljs-string"><span class="hljs-string">"US annual GDP"</span></span> x&lt;-.usGDPannual<span class="hljs-variable"><span class="hljs-variable">$YEAR</span></span> y&lt;-.usGDPannual<span class="hljs-variable"><span class="hljs-variable">$GDP</span></span> plot(x,y,main=title,xlab=xTitle,ylab=yTitle)</code> </pre> <br>  The corresponding chart is shown here: <br><br><img src="https://habrastorage.org/webt/rz/9z/h8/rz9zh8qa22budzolcuushzzgwow.png" height="400" width="300"><br><br>  If we used a logarithmic scale for GDP, we would have the following code and graph: <br><br><pre> <code class="bash hljs">yTitle&lt;-<span class="hljs-string"><span class="hljs-string">"Log US annual GDP"</span></span> plot(x,<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(y),main=title,xlab=xTitle,ylab=yTitle)</code> </pre> <br>  The following graph is close to a straight line: <br><br><img src="https://habrastorage.org/webt/ae/f_/a6/aef_a6iuo4ielgslci9ry0vf1c8.png" height="400" width="300"><br><br><h3>  R package - LiblineaR </h3><br>  This package is a linear predictive model based on the LIBLINEAR C / C ++ Library.  Here is one example of using the <i>iris</i> dataset.  The program tries to predict which category a plant belongs to using training data: <br><br><pre> <code class="bash hljs">library(LiblineaR) data(iris) attach(iris) x=iris[,1:4] y=factor(iris[,5]) train=sample(1:dim(iris)[1],100) xTrain=x[train,];xTest=x[-train,] yTrain=y[train]; yTest=y[-train] s=scale(xTrain,center=TRUE,scale=TRUE) <span class="hljs-comment"><span class="hljs-comment"># tryTypes=c(0:7) tryCosts=c(1000,1,0.001) bestCost=NA bestAcc=0 bestType=NA # for(ty in tryTypes){ for(co in tryCosts){ acc=LiblineaR(data=s,target=yTrain,type=ty,cost=co,bias=1,cross=5,verbose=FALSE) cat("Results for C=",co,": ",acc," accuracy.\n",sep="") if(acc&gt;bestAcc){ bestCost=co bestAcc=acc bestType=ty } } } cat("Best model type is:",bestType,"\n") cat("Best cost is:",bestCost,"\n") cat("Best accuracy is:",bestAcc,"\n") # Re-train best model with best cost value. m=LiblineaR(data=s,target=yTrain,type=bestType,cost=bestCost,bias=1,verbose=FALSE) # Scale the test data s2=scale(xTest,attr(s,"scaled:center"),attr(s,"scaled:scale")) pr=FALSE; # Make prediction if(bestType==0 || bestType==7) pr=TRUE p=predict(m,s2,proba=pr,decisionValues=TRUE) res=table(p$predictions,yTest) # Display confusion matrix print(res) # Compute Balanced Classification Rate BCR=mean(c(res[1,1]/sum(res[,1]),res[2,2]/sum(res[,2]),res[3,3]/sum(res[,3]))) print(BCR)</span></span></code> </pre><br>  The conclusion is the following.  BCR is a balanced classification rate.  For this bet, the higher the better: <br><br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best model type is:"</span></span>,bestType,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best model <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> is: 4</code> </pre> <br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best cost is:"</span></span>,bestCost,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best cost is: 1</code> </pre> <br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best accuracy is:"</span></span>,bestAcc,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best accuracy is: 0.98</code> </pre> <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(res) yTest setosa versicolor virginica setosa 16 0 0 versicolor 0 17 0 virginica 0 3 14 <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(BCR)</code> </pre><br><pre> <code class="bash hljs">[1] 0.95</code> </pre> <br><h3>  R package - eclust </h3><br>  This package is a medium-oriented clustering for interpreted predictive models in high-dimensional data.  First, let's look at a dataset named <i>simdata</i> that contains simulated data for a package: <br><br><pre> <code class="bash hljs">library(eclust) data(<span class="hljs-string"><span class="hljs-string">"simdata"</span></span>) dim(simdata)</code> </pre><br><pre> <code class="bash hljs">[1] 100 502</code> </pre> <br><pre> <code class="bash hljs">simdata[1:5, 1:6]</code> </pre><br><pre> <code class="bash hljs"> YE Gene1 Gene2 Gene3 Gene4 [1,] -94.131497 0 -0.4821629 0.1298527 0.4228393 0.36643188 [2,] 7.134990 0 -1.5216289 -0.3304428 -0.4384459 1.57602830 [3,] 1.974194 0 0.7590055 -0.3600983 1.9006443 -1.47250061 [4,] -44.855010 0 0.6833635 1.8051352 0.1527713 -0.06442029 [5,] 23.547378 0 0.4587626 -0.3996984 -0.5727255 -1.75716775</code> </pre><br><pre> <code class="bash hljs">table(simdata[,<span class="hljs-string"><span class="hljs-string">"E"</span></span>])</code> </pre><br><pre> <code class="bash hljs">0 1 50 50</code> </pre><br>  The previous output shows that the data dimension is 100 by 502. <b>Y</b> is the continuous response vector, and <b>E</b> is the binary environment variable for the ECLUST method.  <b>E = 0</b> for unexposed (n = 50) and <b>E = 1</b> for exposed (n = 50). <br><br>  The following R program estimates Fisher's z-transform: <br><br><pre> <code class="bash hljs">library(eclust) data(<span class="hljs-string"><span class="hljs-string">"simdata"</span></span>) X = simdata[,c(-1,-2)] firstCorr&lt;-cor(X[1:50,]) secondCorr&lt;-cor(X[51:100,]) score&lt;-u_fisherZ(n0=100,cor0=firstCorr,n1=100,cor1=secondCorr) dim(score)</code> </pre> <br><pre> <code class="bash hljs">[1] 500 500</code> </pre><br><pre> <code class="bash hljs">score[1:5,1:5]</code> </pre><br><pre> <code class="bash hljs"> Gene1 Gene2 Gene3 Gene4 Gene5 Gene1 1.000000 -8.062020 6.260050 -8.133437 -7.825391 Gene2 -8.062020 1.000000 9.162208 -7.431822 -7.814067 Gene3 6.260050 9.162208 1.000000 8.072412 6.529433 Gene4 -8.133437 -7.431822 8.072412 1.000000 -5.099261 Gene5 -7.825391 -7.814067 6.529433 -5.099261 1.000000</code> </pre><br>  Define the Fisher z-transform.  Assuming that we have a set of <b>n</b> pairs <b>x</b> <i>i</i> and <b>y</b> <i>i</i> , we could evaluate their correlation using the following formula: <br><br><img src="https://habrastorage.org/webt/rn/7c/gq/rn7cgq57sb0htzxqrypdk20keqo.png"><br><br>  Here <b>p</b> is the correlation between the two variables, and <img src="https://habrastorage.org/webt/f5/uq/fm/f5uqfmo1am-aj0zhkkrswmlglka.png" height="30" width="20">  and <img src="https://habrastorage.org/webt/ew/sg/o0/ewsgo0q-nftlketprnpqlgvxgw4.png" height="20" width="20">  are sample averages for random variables <b>x</b> and <b>y</b> .  The value of <b>z</b> is defined as: <br><br><img src="https://habrastorage.org/webt/se/u4/-t/seu4-tahwcqhc9iz0sgcw7lnmsi.png" height="400" width="500"><br><br>  <b>ln</b> is the natural logarithm function, and <b>arctanh ()</b> is the inverse hyperbolic tangent function. <br><br><h1>  Model selection </h1><br>  When finding a good model, sometimes we are faced with a lack / excess of data.  The following example is borrowed <a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html">from here</a> .  It demonstrates the challenges of working with this and how we can use linear regression with polynomial features to approximate nonlinear functions.  The specified function: <br><br><img src="https://habrastorage.org/webt/s8/cx/ey/s8cxeys7x5so7oet9x1gywgjle4.png" height="200" width="300"><br><br>  In the next program, we try to use linear and polynomial models to approximate an equation.  Slightly modified code is shown here.  The program illustrates the effect of lack / excess of data on the model: <br><br><pre> <code class="bash hljs">import sklearn import numpy as np import matplotlib.pyplot as plt from sklearn.pipeline import Pipeline from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.model_selection import cross_val_score <span class="hljs-comment"><span class="hljs-comment"># np.random.seed(123) n= 30 # number of samples degrees = [1, 4, 15] def true_fun(x): return np.cos(1.5*np.pi*x) x = np.sort(np.random.rand(n)) y = true_fun(x) + np.random.randn(n) * 0.1 plt.figure(figsize=(14, 5)) title="Degree {}\nMSE = {:.2e}(+/- {:.2e})" name1="polynomial_features" name2="linear_regression" name3="neg_mean_squared_error" # for i in range(len(degrees)): ax=plt.subplot(1,len(degrees),i+1) plt.setp(ax, xticks=(), yticks=()) pFeatures=PolynomialFeatures(degree=degrees[i],include_bias=False) linear_regression = LinearRegression() pipeline=Pipeline([(name1,pFeatures),(name2,linear_regression)]) pipeline.fit(x[:,np.newaxis],y) scores=cross_val_score(pipeline,x[:,np.newaxis],y,scoring=name3,cv=10) xTest = np.linspace(0, 1, 100) plt.plot(xTest,pipeline.predict(xTest[:,np.newaxis]),label="Model") plt.plot(xTest,true_fun(xTest),label="True function") plt.scatter(x,y,edgecolor='b',s=20,label="Samples") plt.xlabel("x") plt.ylabel("y") plt.xlim((0,1)) plt.ylim((-2,2)) plt.legend(loc="best") plt.title(title.format(degrees[i],-scores.mean(),scores.std())) plt.show()</span></span></code> </pre><br>  The resulting graphs are shown here: <br><br><img src="https://habrastorage.org/webt/nz/4q/io/nz4qioulhxn9jmgwprxj2e_zffo.png"><br><br><h3>  Python package - model-catwalk </h3><br>  An example can be found <a href="">here</a> . <br><br>  The first few lines of code are shown here: <br><br><pre> <code class="bash hljs">import datetime import pandas from sqlalchemy import create_engine from metta import metta_io as metta from catwalk.storage import FSModelStorageEngine, CSVMatrixStore from catwalk.model_trainers import ModelTrainer from catwalk.predictors import Predictor from catwalk.evaluation import ModelEvaluator from catwalk.utils import save_experiment_and_get_hash <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(FSModelStorageEngine)</code> </pre> <br>  The corresponding output is shown here.  To save space, only the upper part is presented: <br><br><pre> <code class="bash hljs">Help on class FSModelStorageEngine <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> module catwalk.storage: class FSModelStorageEngine(ModelStorageEngine) | Method resolution order: | FSModelStorageEngine | ModelStorageEngine | builtins.object | | Methods defined here: | | __init__(self, *args, **kwargs) | Initialize self. See <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>(self)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> accurate signature. | | get_store(self, model_hash) | | ----------------------------------------------------------------------</code> </pre><br><pre> <code class="bash hljs">| Data descriptors inherited from ModelStorageEngine: | | __dict__ | dictionary <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance variables (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined) | | __weakref__ | list of weak references to the object (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined)</code> </pre><br><h3>  Python package - sklearn </h3><br>  Since <i>sklearn</i> is a very useful package, it is worthwhile to show more examples of using this package.  The example here shows how to use a package to classify documents by topic using the bag-of-words approach. <br>  This example uses the <i>scipy.sparse</i> matrix for storing objects and demonstrates various classifiers that can efficiently handle sparse matrices.  This example uses a data set of 20 newsgroups.  It will be automatically loaded and then cached.  The zip file contains input files and can be downloaded <a href="">here</a> .  The code is available <a href="https://scikit-learn.org/0.16/auto_examples/text/document_classification_20newsgroups.html">here</a> .  To save space, only the first few lines are shown: <br><br><pre> <code class="bash hljs">import logging import numpy as np from optparse import OptionParser import sys from time import time import matplotlib.pyplot as plt from sklearn.datasets import fetch_20newsgroups from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.feature_extraction.text import HashingVectorizer from sklearn.feature_selection import SelectFromModel</code> </pre><br>  The corresponding output is shown here: <br><br><img src="https://habrastorage.org/webt/i-/tb/sv/i-tbsvgaud04-iz5chghtgp2zqq.png"><br><br>  There are three indicators for each method: assessment, training time and testing time. <br><br><h3>  Julia Package - QuantEcon </h3><br>  Take for example the use of Markov chains: <br><br><pre> <code class="bash hljs">using QuantEcon P = [0.4 0.6; 0.2 0.8]; mc = MarkovChain(P) x = simulate(mc, 100000); mean(x .== 1) <span class="hljs-comment"><span class="hljs-comment"># mc2 = MarkovChain(P, ["employed", "unemployed"]) simulate(mc2, 4)</span></span></code> </pre> <br>  Result: <br><br><img src="https://habrastorage.org/webt/6x/ru/4p/6xru4ppkn3ebq_sa6etrwlefdeu.png"><br><br>  The purpose of the example is to see how a person transforms from one economic status into another in the future.  First, let's look at the following chart: <br><br><img src="https://habrastorage.org/webt/1y/so/ho/1ysoho1nccj6fr7_zyh_ebvrcbu.png"><br><br>  Let's look at the leftmost oval with the status of "poor".  0.9 means that a person with this status has a 90% chance of remaining poor, and 10% goes into the middle class.  It can be represented by the following matrix, the zeros are where there is no edge between the nodes: <br><br><img src="https://habrastorage.org/webt/5o/cn/m4/5ocnm45t6i6i_nalizeusknyjxi.png" height="200" width="400"><br><br>  It is said that the two states, x and y, are related to each other if there are positive integers j and k, such as: <br><br><img src="https://habrastorage.org/webt/rb/d9/_l/rbd9_lo7hsj78rafch1eposdsgy.png"><br><br>  A Markov chain <i>P</i> is called irreducible if all states are connected;  that is, if <i>x</i> and <i>y are</i> reported for each (x, y).  The following code will confirm this: <br><br><pre> <code class="bash hljs">using QuantEcon P = [0.9 0.1 0.0; 0.4 0.4 0.2; 0.1 0.1 0.8]; mc = MarkovChain(P) is_irreducible(mc)</code> </pre><br>  The following chart represents an extreme case, since the future status for a poor person will be 100% poor: <br><br><img src="https://habrastorage.org/webt/xj/1h/u_/xj1hu_jmqywzhb1plv68dvy0sgk.png" height="600" width="400"><br><br>  The following code will also confirm this, since the result will be <i>false</i> : <br><br><pre> <code class="bash hljs">using QuantEcon P2 = [1.0 0.0 0.0; 0.1 0.8 0.1; 0.0 0.2 0.8]; mc2 = MarkovChain(P2) is_irreducible(mc2)</code> </pre><br><h1>  Granger causality test </h1><br>  The Granger causality test is used to determine whether one time series is a factor and provides useful information for predicting the second.  The following code uses a <i>dataset</i> named <i>ChickEgg</i> as an illustration.  The data set has two columns, the number of chicks and the number of eggs, with a time stamp: <br><br><pre> <code class="bash hljs">library(lmtest) data(ChickEgg) dim(ChickEgg)</code> </pre><br><pre> <code class="bash hljs">[1] 54 2</code> </pre> <br><pre> <code class="bash hljs">ChickEgg[1:5,]</code> </pre> <br><pre> <code class="bash hljs">chicken egg [1,] 468491 3581 [2,] 449743 3532 [3,] 436815 3327 [4,] 444523 3255 [5,] 433937 3156</code> </pre> <br>  The question is, can we use the number of eggs this year to predict the number of chickens next year? <br><br>  If so, the number of chickens will be caused by Granger for the number of eggs.  If this is not the case, we say that the number of chickens is not the cause of the Granger for the number of eggs.  Here is the corresponding code: <br><br><pre> <code class="bash hljs">library(lmtest) data(ChickEgg) grangertest(chicken~egg, order = 3, data = ChickEgg)</code> </pre> <br><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: chicken ~ Lags(chicken, 1:3) + Lags(egg, 1:3) Model 2: chicken ~ Lags(chicken, 1:3) Res.Df Df F Pr(&gt;F) 1 44 2 47 -3 5.405 0.002966 ** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  In model 1, we attempt to use chick lags plus egg lags to explain the number of chickens. <br><br>  Since  the value of <b>P is</b> quite small (it is significant at 0.01); we say that the number of eggs is the cause of the Granger for the number of chickens. <br><br>  The following test shows that chick data cannot be used to predict the next period: <br><br><pre> <code class="bash hljs">grangertest(egg~chicken, order = 3, data = ChickEgg)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: egg ~ Lags(egg, 1:3) + Lags(chicken, 1:3) Model 2: egg ~ Lags(egg, 1:3) Res.Df Df F Pr(&gt;F) 1 44 2 47 -3 0.5916 0.6238</code> </pre><br>  In the following example, we check the profitability of IBM and S &amp; P500 in order to find out what their cause is the Granger reason for the other. <br><br>  First we define the yield function: <br><br><pre> <code class="bash hljs">ret_f&lt;-<span class="hljs-keyword"><span class="hljs-keyword">function</span></span>(x,ticker=<span class="hljs-string"><span class="hljs-string">""</span></span>){ n&lt;-nrow(x) p&lt;-x[,6] ret&lt;-p[2:n]/p[1:(n-1)]-1 output&lt;-data.frame(x[2:n,1],ret) name&lt;-paste(<span class="hljs-string"><span class="hljs-string">"RET_"</span></span>,toupper(ticker),sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) colnames(output)&lt;-c(<span class="hljs-string"><span class="hljs-string">"DATE"</span></span>,name) <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>(output) }</code> </pre><br><pre> <code class="bash hljs">&gt;x&lt;-read.csv(<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/data/ibmDaily.csv"</span></span>,header=T) ibmRet&lt;-ret_f(x,<span class="hljs-string"><span class="hljs-string">"ibm"</span></span>) x&lt;-read.csv(<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/data/^gspcDaily.csv"</span></span>,header=T) mktRet&lt;-ret_f(x,<span class="hljs-string"><span class="hljs-string">"mkt"</span></span>) final&lt;-merge(ibmRet,mktRet) head(final)</code> </pre><br><pre> <code class="bash hljs"> DATE RET_IBM RET_MKT 1 1962-01-03 0.008742545 0.0023956877 2 1962-01-04 -0.009965497 -0.0068887673 3 1962-01-05 -0.019694350 -0.0138730891 4 1962-01-08 -0.018750380 -0.0077519519 5 1962-01-09 0.011829467 0.0004340133 6 1962-01-10 0.001798526 -0.0027476933</code> </pre><br>  The function can now be called with input values.  The goal of the program is to check whether we can use market lags to explain IBM's profitability.  Similarly, we check, explain IBM's backlog of market revenues: <br><br><pre> <code class="bash hljs">library(lmtest) grangertest(RET_IBM ~ RET_MKT, order = 1, data =final)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: RET_IBM ~ Lags(RET_IBM, 1:1) + Lags(RET_MKT, 1:1) Model 2: RET_IBM ~ Lags(RET_IBM, 1:1) Res.Df Df F Pr(&gt;F) 1 14149 2 14150 -1 24.002 9.729e-07 *** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  The results show that the S &amp; P500 can be used to explain IBM‚Äôs return over the next period, since it is statistically significant at 0.1%.  The following code will check if the IBM lag explains the change to the S &amp; P500: <br><br><pre> <code class="bash hljs">grangertest(RET_MKT ~ RET_IBM, order = 1, data =final)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: RET_MKT ~ Lags(RET_MKT, 1:1) + Lags(RET_IBM, 1:1) Model 2: RET_MKT ~ Lags(RET_MKT, 1:1) Res.Df Df F Pr(&gt;F) 1 14149 2 14150 -1 7.5378 0.006049 ** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  The result suggests that during this period, IBM's profitability can be used to explain the S &amp; P500 index of the next period. </div><p>Source: <a href="https://habr.com/ru/post/428321/">https://habr.com/ru/post/428321/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../428311/index.html">TrustZone: trusted OS and its applications</a></li>
<li><a href="../428313/index.html">Telegram on MacOS [presumably] also locally stores correspondence in an accessible form</a></li>
<li><a href="../428315/index.html">5 fears of developers that we have overcome</a></li>
<li><a href="../428317/index.html">React hooks - win or lose?</a></li>
<li><a href="../428319/index.html">"Yandex" was thinking about protection from acquisitions, if Sberbank allows</a></li>
<li><a href="../428325/index.html">Roskomnadzor interested in leaking the base of employees of Sberbank</a></li>
<li><a href="../428327/index.html">What to do: the eIDAS European Electronic Identification Regulation</a></li>
<li><a href="../428329/index.html">Training with reinforcements: parse on video games</a></li>
<li><a href="../428331/index.html">Roscosmos has established the cause of the accident "Union-FG"</a></li>
<li><a href="../428333/index.html">The results of the AI ‚Äã‚Äãhackathon RAIF Hackathon 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>