<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Machine learning: predict stock prices in the stock market</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Translator Polina Kabirova, specifically for Netologiya , adapted the article by Cambridge University engineer Vivek Palaniappan on how to create a mo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Machine learning: predict stock prices in the stock market</h1><div class="post__text post__text-html js-mediator-article">  <i>Translator Polina Kabirova, specifically for <a href="https://netology.ru/%3Futm_source%3Dblog%26utm_medium%3D747%26utm_campaign%3Dhabr">Netologiya</a> , adapted the <a href="https://towardsdatascience.com/neural-networks-to-predict-the-market-c4861b649371">article</a> by Cambridge University engineer Vivek Palaniappan on how to create a model using neural networks that can predict stock prices on the stock exchange.</i> <br><br>  Machine and deep learning has become a new efficient strategy that many investment funds use to increase revenues.  In the article I will explain how neural networks help predict the situation on the stock market - for example, the price of shares (or index).  At the heart of the text is my <a href="https://github.com/VivekPa/NeuralNetworkStocks">project</a> written in Python.  The full code and program guide can be found on GitHub.  For more related articles, read the <a href="https://medium.com/engineer-quant">Medium</a> blog. <br><a name="habracut"></a><br><h2>  Neural networks in economics </h2><br>  Changes in finance occur nonlinearly, and sometimes it may seem that stock prices are formed in a completely random fashion.  Traditional time series methods such as the ARIMA and GARCH models are effective when the series is stationary ‚Äî its basic properties do not change over time.  And this requires that the series be pre-processed using <code>log returns</code> or brought to stationarity in another way.  However, the main problem arises when these models are implemented in a real trading system, since when adding new data stationarity is not guaranteed. <br><br>  The solution to this problem can be neural networks that do not require stationarity.  Neural networks are initially very effective in finding connections between data and are able to predict (or classify) new data based on them. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Usually data science project consists of the following operations: <br><br><ol><li>  Data collection - provides a set of necessary properties. </li><li>  Preliminary data processing is often a frightening, but necessary step before using data. </li><li>  Development and implementation of the model - the choice of the type of neural network and its parameters. </li><li>  Backtesting models (testing on historical data) are the key step of any trading strategy. </li><li>  Optimization - search for suitable parameters. </li></ol><br>  The input to our neural network is the stock price data for the last 10 days.  With their help, we predict prices the next day. <br><br><h2>  Data collection </h2><br>  Fortunately, the data required for this project can be found at Yahoo Finance.  Data can be collected using their Python API <code>pdr.get_yahoo_data(ticker, start_date, end_date)</code> or directly from the site. <br><br><h2>  Preliminary data processing </h2><br>  In our case, the data should be broken down into training sets consisting of 10 past prices and the next day prices.  For this, I have defined the <code>Preprocessing</code> class, which will work with training and test data.  Inside the class, I defined a <code>get_train(self, seq_len)</code> method that converts the training input and output data to <code>NumPy</code> arrays, specifying a specific window length (in our case 10).  All code looks like this: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen_train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, seq_len)</span></span></span><span class="hljs-function">:</span></span>  <span class="hljs-string"><span class="hljs-string">"""  Generates training data  :param seq_len: length of window  :return: X_train and Y_train  """</span></span>  <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range((len(self.stock_train)//seq_len)*seq_len - seq_len - <span class="hljs-number"><span class="hljs-number">1</span></span>):      x = np.array(self.stock_train.iloc[i: i + seq_len, <span class="hljs-number"><span class="hljs-number">1</span></span>])      y = np.array([self.stock_train.iloc[i + seq_len + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]], np.float64)      self.input_train.append(x)      self.output_train.append(y)  self.X_train = np.array(self.input_train)  self.Y_train = np.array(self.output_train)</code> </pre> <br>  Similarly, I defined a method that converts <code>X_test</code> and <code>Y_test</code> test data. <br><br><h2>  Neural network models </h2><br>  For the project, I used two models of neural networks: the Rumelhart Multilayer Perceptron (MLP) and the Long Short Term Model (LSTM) perceptron.  Briefly tell about how these models work.  Read more about MLP in <a href="https://medium.com/engineer-quant/multilayer-perceptron-4453615c4337">another article</a> , and about the work of LSTM - in the <a href="https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks">material by</a> Jacob Aungiers. <br><br>  MLP is the simplest form of neural networks.  The input data gets into the model and with the help of certain weights the values ‚Äã‚Äãare transmitted through hidden layers to get the output data.  The learning algorithm comes from back propagation through hidden layers to change the value of the weights of each neuron.  The problem with this model is the lack of ‚Äúmemory‚Äù.  It is impossible to determine what the previous data was and how they can and should affect the new ones.  In the context of our model, 10-day differences between the two datasets may be important, but MLPs are not able to analyze such relationships. <br><br>  For this, LSTM or Recurrent Neural Networks (RNN) is used.  RNNs retain certain information about the data for later use, which helps the neural network to analyze the complex structure of relationships between share price data.  But with RNN, a disappearing gradient problem arises.  The gradient decreases because the number of layers increases and the level of learning (value less than one) is multiplied several times.  Solve this problem LSTM, increasing efficiency. <br><br><h2>  Model implementation </h2><br>  To implement the model, I used <code>Keras</code> , because there the layers are added gradually, rather than defining the entire network at once.  So we can quickly change the number and type of layers, optimizing the neural network. <br><br>  An important stage in dealing with stock prices is data normalization.  Usually for this you subtract the average error and divide by the standard error.  But we need this system to be used in real trading for a certain period of time.  Thus, using statistics may not be the most accurate way to normalize data.  Therefore, I simply divided all data into 200 (an arbitrary number, compared to which all other numbers are small).  And although it seems that such a normalization is not justified by anything and does not make sense, it is effective to make sure that the weights in the neural network do not become too large. <br><br>  Let's start with a simpler model - MLP.  In Keras, a sequence is built and dense layers are added on top of it.  The full code looks like this: <br><br><pre> <code class="python hljs">model = tf.keras.models.Sequential() model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">100</span></span>, activation=tf.nn.relu)) model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">100</span></span>, activation=tf.nn.relu)) model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=tf.nn.relu)) model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, loss=<span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>)</code> </pre> <br>  Using Keras in five lines of code, we created MLPs with hidden layers, one hundred neurons each.  And now a little about the optimizer.  The Adam (adaptive moment estimation) method is gaining popularity. It is a more efficient optimization algorithm compared to <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%25A1%25D1%2582%25D0%25BE%25D1%2585%25D0%25B0%25D1%2581%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B3%25D1%2580%25D0%25B0%25D0%25B4%25D0%25B8%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D1%258B%25D0%25B9_%25D1%2581%25D0%25BF%25D1%2583%25D1%2581%25D0%25BA">stochastic gradient descent</a> .  There are two other extensions of the stochastic gradient descent - the advantages of Adam are immediately visible against their background: <br><br>  <b>AdaGrad</b> - maintains a set learning rate, which improves results when gradients <b>differ</b> (for example, problems with natural language and computer vision). <br><br>  <b>RMSProp</b> - maintains a set learning rate, which can vary depending on the average values ‚Äã‚Äãof recent gradients for weight (for example, how fast it changes).  This means that the algorithm copes well with unsteady problems (for example, noise). <br><br>  Adam combines the benefits of these extensions, so I chose it. <br><br>  Now we customize the model to our training data.  Keras simplifies the task again, only the following code is needed: <br><br><pre> <code class="python hljs">model.fit(X_train, Y_train, epochs=<span class="hljs-number"><span class="hljs-number">100</span></span>)</code> </pre> <br>  When the model is ready, you need to test it on test data to determine how well it worked.  This is done like this: <br><br><pre> <code class="python hljs">model.evaluate(X_test, Y_test)</code> </pre> <br>  Information obtained as a result of the test can be used to evaluate the model's ability to predict stock prices. <br><br>  A similar procedure is used for the LSTM model, so I will show the code and explain it a little: <br><br><pre> <code class="python hljs">model = tf.keras.Sequential() model.add(tf.keras.layers.LSTM(<span class="hljs-number"><span class="hljs-number">20</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(tf.keras.layers.LSTM(<span class="hljs-number"><span class="hljs-number">20</span></span>)) model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=tf.nn.relu)) model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, loss=<span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>) model.fit(X_train, Y_train, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>) model.evaluate(X_test, Y_test)</code> </pre> <br>  Please note that Keras needs data of a certain size, depending on your model.  It is very important to change the shape of the array with NumPy. <br><br><h2>  Backtesting models </h2><br>  When we have prepared our models with the help of training data and tested them on test data, we can test the model on historical data.  This is done as follows: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">back_test</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(strategy, seq_len, ticker, start_date, end_date, dim)</span></span></span><span class="hljs-function">:</span></span>  <span class="hljs-string"><span class="hljs-string">"""  A simple back test for a given date period  :param strategy: the chosen strategy. Note to have already formed the model, and fitted with training data.  :param seq_len: length of the days used for prediction  :param ticker: company ticker  :param start_date: starting date  :type start_date: "YYYY-mm-dd"  :param end_date: ending date  :type end_date: "YYYY-mm-dd"  :param dim: dimension required for strategy: 3dim for LSTM and 2dim for MLP  :type dim: tuple  :return: Percentage errors array that gives the errors for every test in the given date range  """</span></span>  data = pdr.get_data_yahoo(ticker, start_date, end_date)  stock_data = data[<span class="hljs-string"><span class="hljs-string">"Adj Close"</span></span>]  errors = []  <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range((len(stock_data)//<span class="hljs-number"><span class="hljs-number">10</span></span>)*<span class="hljs-number"><span class="hljs-number">10</span></span> - seq_len - <span class="hljs-number"><span class="hljs-number">1</span></span>):      x = np.array(stock_data.iloc[i: i + seq_len, <span class="hljs-number"><span class="hljs-number">1</span></span>]).reshape(dim) / <span class="hljs-number"><span class="hljs-number">200</span></span>      y = np.array(stock_data.iloc[i + seq_len + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) / <span class="hljs-number"><span class="hljs-number">200</span></span>      predict = strategy.predict(x)      <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> predict == <span class="hljs-number"><span class="hljs-number">0</span></span>:          predict = strategy.predict(x)      error = (predict - y) / <span class="hljs-number"><span class="hljs-number">100</span></span>      errors.append(error)      total_error = np.array(errors)  print(<span class="hljs-string"><span class="hljs-string">f"Average error = </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{total_error.mean()}</span></span></span><span class="hljs-string">"</span></span>)</code> </pre> <br>  However, this is a simplified version of testing.  For a complete backtesting system, factors such as ‚Äúsurvival error‚Äù (survivorship bias), tendentiousness (look ahead bias), changing market conditions and transaction costs should be taken into account.  Since this is just an educational project, there is enough back-testing. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qw/_9/hy/qw_9hyxncpkhgxv_rvsxxtxrhlk.png"></div><br>  <i>Forecast of my LSTM model for Apple stock prices in February</i> <br><br>  For a simple LSTM model without optimization, this is a very good result.  It shows that neural networks and machine learning models are capable of building complex stable connections between parameters. <br><br><h2>  Hyperparameter Optimization </h2><br>  To improve model results after testing, optimization is often needed.  I did not include it in the open source version so that readers can try to optimize the model themselves.  Those who do not know how to optimize will have to find hyper parameters that will improve the performance of the model.  There are several methods for searching hyper parameters: from the selection of parameters by the grid to stochastic methods. <br><br>  I am confident that with the optimization of models of knowledge in the field of machine learning, they are reaching a new level.  Try to optimize the model so that it works better than mine.  Compare the result with the schedule above. <br><br><h2>  Conclusion </h2><br>  Machine learning is constantly evolving - new methods are emerging every day, so it is very important to constantly learn.  The best way to do this is to create interesting projects, for example, to build models for predicting stock prices.  And although my LSTM model is not good enough for use in real trading, the foundation laid in developing such a model may help in the future. <br><br><h2>  From the Editor </h2><br>  Courses "Netology" on the topic: <br><br><ul><li>  online profession " <a href="https://netology.ru/programs/data-analyst%3Futm_source%3Dblog%26utm_medium%3D747%26utm_campaign%3Dhabr">Data Analyst</a> " </li><li>  online profession " <a href="https://netology.ru/programs/data-scientist%3Futm_source%3Dblog%26utm_medium%3D747%26utm_campaign%3Dhabr">Data Scientist</a> " </li></ul></div><p>Source: <a href="https://habr.com/ru/post/428227/">https://habr.com/ru/post/428227/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../428217/index.html">Million video calls per day or ‚ÄúCall Mom!‚Äù</a></li>
<li><a href="../428219/index.html">Where did the practice of mass relocation of qualified personnel come from?</a></li>
<li><a href="../428221/index.html">Generating arbitrary realistic entities using AI</a></li>
<li><a href="../428223/index.html">Cities and their ‚Äúbig data‚Äù</a></li>
<li><a href="../428225/index.html">How to do web analytics for SaaS through Google Analytics: introducing and tracking funnels</a></li>
<li><a href="../428229/index.html">How Lisp became a programming language for God</a></li>
<li><a href="../428231/index.html">Beautiful and clean: tools that help achieve near-perfect code</a></li>
<li><a href="../428233/index.html">Five reasons to fall in love with regional IT parties</a></li>
<li><a href="../428235/index.html">Why did I get a call from the NSA in the middle of the night and asked for the source code?</a></li>
<li><a href="../428237/index.html">Board game scrum mitap: welcome to the Scrum Values ‚Äã‚ÄãGame</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>