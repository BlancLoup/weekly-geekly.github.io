<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Automatic Relevance Determination or machine learning when there is very little data</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When it comes to machine learning, usually involve large amounts of data - millions or even billions of transactions, from which you need to make a co...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Automatic Relevance Determination or machine learning when there is very little data</h1><div class="post__text post__text-html js-mediator-article"><p>  When it comes to machine learning, usually involve large amounts of data - millions or even billions of transactions, from which you need to make a complex conclusion about the behavior, interests or current state of the user, buyer or some device (robot, car, drone or machine). <br>  However, in the life of the ordinary analyst of the most ordinary company a lot of data is rare.  Rather, on the contrary - you will have little or very little data - literally dozens or hundreds of records.  But the analysis still needs to be done.  And not some kind of analysis, but a qualitative and reliable one. </p><br><p>  Often, the situation is aggravated by the fact that you can easily generate many features for each record (most often polynomials are added, the difference with the previous value and the value for the last year, one-hot-encoding for categorical features, etc.).  That's just not at all easy to figure out which of them are really useful, and which only complicate the model and increase the errors of your prognosis. </p><br><p>  To do this, you can use the methods of Bayesian statistics, for example, <strong>Automatic Relevance Determination</strong> . <a name="habracut"></a>  This is a relatively new method proposed in 1992 by David Mackay (it all started with his <a href="http://www.inference.phy.cam.ac.uk/mackay/thesis.pdf">doctoral dissertation (PDF)</a> ).  A very brief but incomprehensible presentation of the method can be found <a href="http://www.cis.hut.fi/Opinnot/T-61.6040/presentations_s06/presentation_elia.pdf">in this PDF presentation</a> .  A clear, but overly verbose explanation can be found <a href="https://www.youtube.com/watch%3Fv%3D2gT-Q0NZzoE">here</a> : </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/2gT-Q0NZzoE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  If it is quite simple, then in the ARD for each coefficient a posteriori estimate of the variance is displayed, and then the coefficients with a small variance are zeroed. </p><br><p>  Let's see how it works in practice.  So, we have the initial data - only 30 points (for example, data on 30 stores).  And each store has 30 signs.  And your task is to create a regression model (for example, to predict sales volume according to location, format, sales area, configuration, number of personnel and other store parameters). <br>  Building ordinary linear regression under such conditions will be pure insanity.  Let us further exacerbate the problem by the fact that only 5 signs really matter, and the rest are completely irrelevant data. </p><br><p>  Thus, let the real dependence be represented by the formula <em>Y = w * X + e</em> , where <em>e</em> is a random normal error, and the coefficients <em>w</em> are equal [1, 2, 3, 4, 5, 0, 0, ...., 0], that is, only the first five coefficients are nonzero, and the signs from the 6th to the 30th do not affect the real value of <em>Y at all</em> .  However, we do not know.  We only have data - <em>X</em> and <em>Y</em> - and we need to calculate the coefficients <em>w</em> . </p><br><p>  Now run ARD: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ARDRegression N = <span class="hljs-number"><span class="hljs-number">30</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (   ) X = np.random.random(size=(N,N)) * 10 + 1 #   [1 2 3 4 5 0 0 ... 0] w = np.zeros(N) w[:5] = np.arange(5) + 1 #    e = np.random.normal(0, 1, size=N) #    Y = np.dot(X, w) + e ard = ARDRegression() ard.fit(X, Y) print ard.coef_</span></span></code> </pre> <br><p>  And we get just an impressive result: </p><br><pre> <code class="python hljs">array([ <span class="hljs-number"><span class="hljs-number">1.01</span></span>, <span class="hljs-number"><span class="hljs-number">2.14</span></span>, <span class="hljs-number"><span class="hljs-number">2.95</span></span>, <span class="hljs-number"><span class="hljs-number">3.89</span></span>, <span class="hljs-number"><span class="hljs-number">4.79</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.01</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.31</span></span>, <span class="hljs-number"><span class="hljs-number">0.04</span></span>, <span class="hljs-number"><span class="hljs-number">-0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.01</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.01</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.17</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> ])</code> </pre> <br><p>  Let me remind you that the real coefficients are equal: </p><br><pre> <code class="python hljs">array([ <span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">2.</span></span>, <span class="hljs-number"><span class="hljs-number">3.</span></span>, <span class="hljs-number"><span class="hljs-number">4.</span></span>, <span class="hljs-number"><span class="hljs-number">5.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> ])</code> </pre> <br><p>  Thus, having only 30 points in a 30-dimensional space, we were able to build a model that almost exactly repeats the real dependence. </p><br><p>  For comparison, I will give the coefficients calculated using ordinary linear regression: </p><br><pre> <code class="python hljs">array([ <span class="hljs-number"><span class="hljs-number">0.39</span></span> <span class="hljs-number"><span class="hljs-number">2.07</span></span> <span class="hljs-number"><span class="hljs-number">3.16</span></span> <span class="hljs-number"><span class="hljs-number">2.86</span></span> <span class="hljs-number"><span class="hljs-number">4.8</span></span> <span class="hljs-number"><span class="hljs-number">-0.21</span></span> <span class="hljs-number"><span class="hljs-number">-0.13</span></span> <span class="hljs-number"><span class="hljs-number">0.42</span></span> <span class="hljs-number"><span class="hljs-number">0.6</span></span> <span class="hljs-number"><span class="hljs-number">-0.21</span></span> <span class="hljs-number"><span class="hljs-number">-0.96</span></span> <span class="hljs-number"><span class="hljs-number">0.03</span></span> <span class="hljs-number"><span class="hljs-number">-0.46</span></span> <span class="hljs-number"><span class="hljs-number">0.57</span></span> <span class="hljs-number"><span class="hljs-number">0.89</span></span> <span class="hljs-number"><span class="hljs-number">0.15</span></span> <span class="hljs-number"><span class="hljs-number">0.24</span></span> <span class="hljs-number"><span class="hljs-number">0.11</span></span> <span class="hljs-number"><span class="hljs-number">-0.38</span></span> <span class="hljs-number"><span class="hljs-number">-0.36</span></span> <span class="hljs-number"><span class="hljs-number">-0.28</span></span> <span class="hljs-number"><span class="hljs-number">-0.01</span></span> <span class="hljs-number"><span class="hljs-number">0.43</span></span> <span class="hljs-number"><span class="hljs-number">-1.22</span></span> <span class="hljs-number"><span class="hljs-number">0.23</span></span> <span class="hljs-number"><span class="hljs-number">0.15</span></span> <span class="hljs-number"><span class="hljs-number">0.12</span></span> <span class="hljs-number"><span class="hljs-number">0.43</span></span> <span class="hljs-number"><span class="hljs-number">-1.11</span></span> <span class="hljs-number"><span class="hljs-number">-0.3</span></span> ])</code> </pre> <br><p>  linear regression with L2 regularization: </p><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">-0.36</span></span> <span class="hljs-number"><span class="hljs-number">1.48</span></span> <span class="hljs-number"><span class="hljs-number">2.67</span></span> <span class="hljs-number"><span class="hljs-number">3.44</span></span> <span class="hljs-number"><span class="hljs-number">3.99</span></span> <span class="hljs-number"><span class="hljs-number">-0.4</span></span> <span class="hljs-number"><span class="hljs-number">1.01</span></span> <span class="hljs-number"><span class="hljs-number">0.58</span></span> <span class="hljs-number"><span class="hljs-number">-0.81</span></span> <span class="hljs-number"><span class="hljs-number">0.78</span></span> <span class="hljs-number"><span class="hljs-number">-0.13</span></span> <span class="hljs-number"><span class="hljs-number">-0.23</span></span> <span class="hljs-number"><span class="hljs-number">-0.26</span></span> <span class="hljs-number"><span class="hljs-number">-0.24</span></span> <span class="hljs-number"><span class="hljs-number">-0.38</span></span> <span class="hljs-number"><span class="hljs-number">-0.24</span></span> <span class="hljs-number"><span class="hljs-number">-0.38</span></span> <span class="hljs-number"><span class="hljs-number">-0.25</span></span> <span class="hljs-number"><span class="hljs-number">0.54</span></span> <span class="hljs-number"><span class="hljs-number">-0.31</span></span> <span class="hljs-number"><span class="hljs-number">-0.21</span></span> <span class="hljs-number"><span class="hljs-number">-0.42</span></span> <span class="hljs-number"><span class="hljs-number">0.14</span></span> <span class="hljs-number"><span class="hljs-number">0.88</span></span> <span class="hljs-number"><span class="hljs-number">1.09</span></span> <span class="hljs-number"><span class="hljs-number">0.66</span></span> <span class="hljs-number"><span class="hljs-number">0.12</span></span> <span class="hljs-number"><span class="hljs-number">-0.07</span></span> <span class="hljs-number"><span class="hljs-number">0.08</span></span> <span class="hljs-number"><span class="hljs-number">-0.58</span></span>])</code> </pre> <br><p>  And they both do not hold water. </p><br><p>  But linear regression with L1 regularization gives a similar result: </p><br><pre> <code class="python hljs">array([ <span class="hljs-number"><span class="hljs-number">0.68</span></span> <span class="hljs-number"><span class="hljs-number">1.9</span></span> <span class="hljs-number"><span class="hljs-number">2.88</span></span> <span class="hljs-number"><span class="hljs-number">3.86</span></span> <span class="hljs-number"><span class="hljs-number">4.88</span></span> <span class="hljs-number"><span class="hljs-number">-0.05</span></span> <span class="hljs-number"><span class="hljs-number">0.09</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.01</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> ])</code> </pre> <br><p>  As you can see, L1-regularization even better nullifies insignificant coefficients, but significant coefficients can be calculated with a slightly larger error. </p><br><p>  In general, ARD is a wonderful method, but there is a nuance.  Like many (one might even say almost all) Bayesian methods, ARD is extremely complex from a computational point of view (although it is well parallelized).  Therefore, it works quickly on data of several tens or hundreds of points (fractions of a second), on several thousand - slowly (tens to hundreds of seconds), and on tens and hundreds of thousands - ooh-oh-so-so (minutes and hours).  In addition, he needs a huge amount of RAM. </p><br><p>  However, this is not so scary.  If you have a lot of data, then you can safely use classical statistical methods, and they will give a fairly good result.  Serious problems begin when data is scarce and conventional methods no longer work.  And then Bayes comes to the rescue. </p><br><p>  ARD is actively used in a variety of kernel-methods, for example, Relevance Vector Machine (RVM) - this is the Support Vector Machine (SVM) along with ARD.  It is also convenient in classifiers, when you need to evaluate the significance of the available features.  In general, try it and you will like it. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/313566/">https://habr.com/ru/post/313566/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../313554/index.html">Introduction to DPI: System Composition and Connection Diagrams</a></li>
<li><a href="../313556/index.html">Introduction to DPI: System Usage Scenarios</a></li>
<li><a href="../313558/index.html">Deep Packet Inspection: Equipment and Application</a></li>
<li><a href="../313562/index.html">A little about the types of DDoS-attacks and methods of protection</a></li>
<li><a href="../313564/index.html">Installing Jenkins and Bonobo Git Server under Windows for building Android applications</a></li>
<li><a href="../313568/index.html">News of Mail.Ru Group online courses on Stepik</a></li>
<li><a href="../313570/index.html">Restore a domain controller from backup using Veeam</a></li>
<li><a href="../313574/index.html">October 27, Digital October will host Russian FinTech Meetup # 1</a></li>
<li><a href="../313576/index.html">On the way to a successful project: 11 tips for effective communication with the client and the team</a></li>
<li><a href="../313578/index.html">Slate - Silver Bullet for positioning windows on OS X screens</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>