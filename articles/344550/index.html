<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The history of victory in the international competition for the recognition of documents of the SmartEngines company</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! Today we will talk about how our Smart Engines team managed to win the international binarization of documents DIBCO17 held at the ICDAR con...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The history of victory in the international competition for the recognition of documents of the SmartEngines company</h1><div class="post__text post__text-html js-mediator-article"><p>  Hi, Habr!  Today we will talk about how our <a href="http://smartengines.ru/">Smart Engines</a> team managed to win the international binarization of documents <a href="http://vc.ee.duth.gr/dibco2017">DIBCO17</a> held at the <a href="http://u-pat.org/ICDAR2017/index.php">ICDAR</a> conference.  This competition is held regularly and already has a solid history (it has been held for 9 years), during which many incredibly interesting and insane (in a good way) binarization algorithms were proposed.  Despite the fact that we do not use such algorithms in our document recognition projects using mobile devices, the team seemed to have something to offer the world community, and this year we made the decision to participate in the competition for the first time. </p><br><img src="https://habrastorage.org/webt/f-/xn/0g/f-xn0gbg5kiw-hvtwgtpai4iimw.gif"><a name="habracut"></a><br><p>  To begin with, let us briefly explain what its essence is: given a lot of color images of documents <em>S</em> prepared by the organizers (an example of one of these images is shown in the figure to the left) and a lot of binary images <em>I</em> (ground truth, the expected result for an example is shown in the figure to the right)  It is required to construct an algorithm <em>A</em> that translates the source images from <em>S</em> into two-level black-and-white <em>a</em> ( <em>A</em> ) (i.e., solve the problem of classifying each pixel as belonging to an object or background) so that these resulting images are as close as possible to corresponding to the ideal of <em>i</em> .  The set of metrics by which this proximity is evaluated is, of course, recorded in the conditions of competition.  The peculiarity of this competition is that no test image is provided in advance to the contestants, data from past contests are available for setup and preparation.  At the same time, the new data each time contains its own ‚Äúzest‚Äù, which distinguishes them from previous contests (for example, the presence of thin ‚Äúwatercolor‚Äù text styles or characters that appear translucent on the opposite side) and present new challenges for participants.  The competition regularly gathers about two to three dozen participants from around the world.  The following is a description of our competitive decision. </p><br><p><img src="https://habrastorage.org/webt/rk/wz/am/rkwzamntrgonynmflydopues_co.png" width="350"><img src="https://habrastorage.org/webt/ih/hb/2b/ihhb2boqfjnziuy9q8awdxfnnng.png" width="350"></p><br><h3 id="shema-resheniya">  Solution scheme </h3><br><p>  The first step was collected data from all previous contests.  In total, we managed to upload 65 images of handwritten documents and 21 images printed.  Obviously, in order to achieve high results, it was necessary to look at the problem with a wider view, therefore, in addition to analyzing the images from the organizers, we searched for open data with archival printed and handwritten documents.  The organizers did not prohibit the use of third-party datasets.  Several thousand images were successfully found that, by their nature, fit the conditions of the competition (data from various thematic competitions organized by ICDAR, the <a href="https://read.transkribus.eu/">READ</a> project, and others).  After studying and classifying these documents, it became clear which classes of problems we could encounter in principle, and which of them remained until now ignored by the organizers of the competition.  For example, in none of the previous competitions the documents contained no elements of the graphic, although the tables are often found in the archives. </p><br><p>  In preparation for the competition, we walked in parallel in several ways.  In addition to the classical algorithmic approaches that we have studied well before, it was decided to try out machine learning methods for pixel classification of object-background, despite the very small amount of data originally provided.  Since in the end it was precisely this approach that turned out to be the most effective, we will tell about it. </p><br><h3 id="vybor-arhitektury-seti">  Selection of network architecture </h3><br><p>  As the initial version, the neural network of the <a href="https://arxiv.org/abs/1505.04597">U-net</a> architecture was chosen.  Such architecture has proven itself in solving segmentation problems in various competitions (for example, <a href="https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection">1</a> , <a href="https://www.kaggle.com/c/ultrasound-nerve-segmentation">2</a> , <a href="https://www.kaggle.com/c/data-science-bowl-2017">3</a> ).  An important consideration was the fact that a large class of well-known binarization algorithms is explicitly expressed in such an architecture or a similar architecture (as an example, we can take a modification of the Niblack algorithm with the replacement of the standard deviation by the mean deviation modulus, in this case the network is especially simple). </p><br><img src="https://habrastorage.org/webt/s0/py/un/s0pyun0a0rnbvep0fcobuvmfylc.png" width="700"><br><p>  <em>An example of a neural network U-net architecture</em> </p><br><p>  The advantage of this architecture is that for network training you can create a sufficient amount of training data from a small number of source images.  At the same time, the network has a relatively small number of weights due to its convolutional architecture.  But there are some nuances.  In particular, the artificial neural network used, strictly speaking, does not solve the problem of binarization: it assigns to each pixel of the original image a certain number from 0 to 1, which characterizes the degree of belonging of this pixel to one of the classes (meaningful filling or background) and still convert to final binary answer. </p><br><p>  As a training sample, 80% of the original images were taken.  The remaining 20% ‚Äã‚Äãof the images were allocated for validation and testing.  Images from color were converted to grayscale to avoid retraining, after which they were all cut into non-overlapping windows of 128x128 pixels.  The optimal window size was chosen empirically (windows from 16x16 to 512x512 were tried).  Initially, no augmentation methods were used, and thus, from a hundred of initial images, about 70 thousand windows were obtained, which were fed to the input of the neural network.  Each such window of the image was assigned a binary mask cut from the markup. </p><br><img src="https://habrastorage.org/webt/dh/fz/fy/dhfzfyhxea7h8d5lg583wgldyt0.png" width="700"><br><p>  <em>Window samples</em> </p><br><p>  The parameters of the neural network, the learning process and data augmentation took place in manual mode, since each experiment (data augmentation, training / further training of the network, validation and testing of the solution) took several hours, and the principle of ‚Äúlooking at carefully and understanding what is happening‚Äù in our opinion is preferable to running <a href="https://github.com/hyperopt/hyperopt">hyperopt</a> for a week.  <a href="https://arxiv.org/pdf/1412.6980v8.pdf">Adam</a> was chosen as the method of stochastic optimization.  Cross-entropy was used as a metric for the loss function. </p><br><h3 id="pervichnye-eksperimenty">  Primary experiments </h3><br><p>  Already the first experiments showed that such an approach allows achieving higher quality than the simplest non-learning methods (such as <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%259E%25D1%2586%25D1%2583">Father</a> or Niblack).  The neural network was well trained and the learning process quickly converged to an acceptable minimum.  The following are some examples of animation of the network learning process.  The first two images are taken from the original datasets, the third is found in one of the archives. </p><br><p>  Each of the animations was obtained as follows: in the process of learning the neural network, as the quality improves, the same source image is run through the network.  The results of the network are glued together in one gif animation. </p><br><img src="https://habrastorage.org/webt/8n/hd/yf/8nhdyfsdcxa8cehhhu3rnqmjqk4.png" width="750"><br><p> <em>Original handwriting image with complex background</em> </p><br><img src="https://habrastorage.org/webt/aw/ab/us/awabusapzsv7u4fvjn5lhovmlia.gif"><br><p>  <em>The result of binarization as learning network</em> </p><br><p>  The complexity of the binarization of the above example is to distinguish the heterogeneous background from the ornate handwriting.  Part of the letters is blurred, text appears on the other page, blots.  The one who wrote this manuscript is clearly not the most accurate person of his time =). </p><br><img src="https://habrastorage.org/webt/mm/65/an/mm65ano44_lygmtftrbs0qbe48c.png" width="700"><br><p>  <em>Original printed text image with previous page's treads</em> </p><br><img src="https://habrastorage.org/webt/0s/tp/6h/0stp6hjas0a-nvkebbjfp0q3uy4.gif"><br><p>  <em>The result of binarization as learning network</em> </p><br><p>  In this example, in addition to the non-uniform background, there is also text that appeared from the previous page.  The difference by which it can be determined that the shrunk text needs to be classified as "background" is the wrong "mirror" character. </p><br><p><img src="https://habrastorage.org/webt/xb/_d/zv/xb_dzv5yjq1s7hft2wofpuok4bs.jpeg" width="350"><img src="https://habrastorage.org/webt/6q/q1/yq/6qq1yq8jsjryl3q8rfjpw9ncgf8.gif" width="350"><br>  <em>Image with a table and the result of its binarization in the process of network learning</em> </p><br><p>  After each experiment, we additionally evaluated the relevance of the obtained model on a set of selected data from open archives and on various types of printed documents and questionnaires.  It was noted that when applying a network to examples from this data, the result of the algorithm was often unsatisfactory.  It was decided to add such images to the training set.  The most problematic cases were the edges of the pages of documents and their marking lines.  A total of 5 additional images were selected containing the objects of interest.  Primary binarization was performed using the existing network version, after which the pixels were verified by an expert, and the resulting images were added to the training sample. </p><br><p><img src="https://habrastorage.org/webt/al/ax/oz/alaxozzlrkoswdcgvbhjaxpoqum.jpeg" width="350"><img src="https://habrastorage.org/webt/p3/5u/7a/p35u7ag_dkt9a9emdbf2hp6uyn0.jpeg" width="350"><br>  <em>In the example above, you can see that the network highlights the edges of the pages, which is an error</em> </p><br><p><img src="https://habrastorage.org/webt/1n/k9/fh/1nk9fhxsmi5kh8eybxrhrwuctai.jpeg" width="350"><img src="https://habrastorage.org/webt/sf/f-/vi/sff-viibqzxrzunbvwq5iujxkai.jpeg" width="350"><br>  <em>Here, in addition to network errors at the edges of the pages, there is still a very "uncertain" selection of the lines of the table and the text inside it.</em> </p><br><h3 id="primenyaemye-tehniki-augmentacii-i-kak-oni-pomogayut">  Used augmentation techniques and how they help </h3><br><p>  In the process of network training and error analysis, data augmentation methods were used to improve the quality.  The following types of distortion were used: reflections of images relative to the axes, brightness, projective, noise (Gaussian noise, salt-pepper), elastic transformations, like such ones, were tried out, a variation of the image scale.  The use of each of them is due to the specifics of the problem, the observed errors in the network, as well as common practices. </p><br><img src="https://habrastorage.org/webt/rx/nt/de/rxntdetz95hjy4du4t-m-wcxrzc.gif"><br><p>  <em>An example of a combination of several augmentation methods that are applied ‚Äúon the fly‚Äù in the network learning process</em> </p><br><p>  Since when generating data with all the various distortions and their combinations, the number of examples grows rapidly, augmentation is applied on the fly, in which the sample is blown up just before the examples for training are given.  Schematically, this can be represented as: </p><br><img src="https://habrastorage.org/webt/p5/m1/y4/p5m1y4z0rboo2erxe0yda0uzjqm.png"><br><p>  <em>Diagram showing the process of blowing up data on the fly and issuing for training</em> </p><br><p>  This approach allows you to optimize the process of data swelling and network training, because: </p><br><ul><li>  the number of accesses to the disk array decreases and it occurs sequentially, which makes it possible to speed up data loading many times. </li><li>  parallel data augmentation in mini-batches occurs independently and efficiently uses all the cores of the machine.  Some of the most resource-intensive operations can be rewritten using theano / tensorflow and calculated on the 2nd gpu. </li><li>  Periodically, individual mini-batches are saved to disk, which allows checking the learning process and data blowing up. </li><li>  Most of the memory remains empty, since at the same time it stores about 20% of all data (validation set and current batch).  This allows <del>  shake 5 experiments at once </del>  Efficient use of server computing resources. </li></ul><br><p>  In general, I would like to note the importance of proper augmentation - thanks to this technique, you can train a more complex and intelligent network on the one hand, and on the other, avoid retraining and be sure that the quality of network operation on a test sample is no worse than during training and validation.  Some experts, for unknown reasons, neglect the work with data and are looking for a way to improve the system only by changing the architecture of networks.  <a href="http://www.scs-europe.net/dlib/2015/ecms2015acceptedpapers/0516-is_ECMS2015_0110.pdf">From</a> <a href="http://itas2012.iitp.ru/pdf/1569605195.pdf">our</a> <a href="https://habrahabr.ru/company/smartengines/blog/264677/">point of</a> <a href="https://habrahabr.ru/company/smartengines/blog/328000/">view</a> , working with data is no less, and more often, more important than a thoughtful selection of network architecture parameters. </p><br><h3 id="povyshenie-kachestva">  Quality improvement </h3><br><p>  The process of improving the quality of the decision took place iteratively.  Most of the work went in three directions: </p><br><ul><li>  Analysis of network errors and work with data. </li><li>  Refinement of network architecture, setting up hyperparameters of layers and regularization mechanisms. </li><li>  Construction of the ensemble on the basis of neural network and conventional methods. </li></ul><br><p>  Work with the data occurred in the following cycles: </p><br><img src="https://habrastorage.org/webt/sz/jn/wz/szjnwzdwqlx0mh5eebsufnyaqs8.png"><br><p>  <em>The process of analyzing system errors to eliminate them</em> </p><br><p>  The work with the data can be described in detail as follows: after each significant stage of the system change (with quality improvement, as we hoped each time), various metrics and statistics were calculated by cross-validation.  About 2000 ‚Äúwindows‚Äù (but not more than 50 windows from one image) were written, on which the error reached the maximum value according to the quadratic metric and the images from which these windows were cut out.  Then the analysis of these images and their classification by the type of error was carried out.  The result looked like this: </p><br><img src="https://habrastorage.org/webt/qn/ds/sm/qndssmr0q76gvyvi35xx3pfch8g.png"><br><p>  <em>Sample Error Distribution Diagram</em> </p><br><p>  Next, select the most common type of error.  A distortion is created that mimics images with this type of error.  It is checked that the current version of the system is really wrong on the distorted image and the error occurs due to the added distortion.  Then, the created augmentation procedure is added to the set of existing ones and is used in the learning process.  After learning a new network and updating the system trim parameters, a new analysis and classification of errors occurs.  As the final stage of the cycle - we check that the quality grows and the number of errors of a particular type has greatly decreased.  Naturally, a very ‚Äúidealistic‚Äù course of events is described here =).  For example, for some types of errors, it is extremely difficult to create suitable distortions or when adding distorted images one type of errors may disappear and the other three may appear.  Nevertheless, this methodology allows to level 80% of errors that occur at different stages of the system construction. </p><br><p>  Example: in some images there is noise from a heterogeneous background, blots and, in particular, parchment grit.  Errors that appear in such examples can be suppressed by additional noise in the original image. </p><br><img src="https://habrastorage.org/webt/pk/id/4h/pkid4hzqxm58nrqgqbpnqaz7r8w.png"><br><p>  <em>An example of imitation of ‚Äúgranular parchment‚Äù using distortion</em> </p><br><p>  The process of optimization of the neural network architecture and layer hyperparameters was carried out in several directions: </p><br><ul><li>  Variation of the current network architecture in depth / number of layers / number of filters, etc. </li><li>  Checking other architectures to solve our problem (VGG, Resnet, etc.).  To test the possibility of using already trained neural networks, the networks of VGG and Resnet architectures were investigated.  Two approaches were used: <br><ol><li>  From the outputs of the different layers of each network, the vector signs were written off, which were used as the input of a fully connected neural network trained to solve the classification problem.  In this case, only the ‚Äúfinal‚Äù fully connected neural network was trained, and the networks supplying the signs remained unchanged.  To reduce the dimension of the input space of a fully connected network, singular decomposition was used. </li><li>  The second approach was that we replaced the last N layers of one of the networks (for example, VGG) with fully connected ones and retrained the entire network.  Those.  just used ready weights as the initial initialization. </li></ol></li></ul><br><p>  In general, it must be said that both approaches gave some results, but in terms of quality and reliability they were inferior to the U-net training approach ‚Äúfrom scratch‚Äù. </p><br><h3 id="process-ensembling">  Process ensembling </h3><br><p>  The next step in creating the final solution is to build an ensemble from several solutions.  To build the ensemble, we used 3 U-net networks, different architectures, trained on different data sets, and one non-learning binarization method, which was used only at the edges of the image (for clipping pages edges). <br>  We tried to build an ensemble in two different ways: </p><br><ul><li>  Averaging the answers. </li><li>  Weighted sum of responses.  The contribution to the final answer was determined by the quality of work on the validation sample. </li></ul><br><p>  In the process of working on the ensemble, we were able to achieve improved quality compared to a single U-net network.  However, the improvement was very insignificant, and the work time of the ensemble consisting of several networks was extremely great.  Even despite the fact that in this competition there was no limit on the running time of the algorithm, the conscience did not allow us to commit such a decision. </p><br><h3 id="vybor-finalnogo-resheniya">  The choice of the final decision </h3><br><p>  As we move to the final version of the algorithm, each of the stages (adding additional delimited data, structure variation, blow-up, etc.) was subjected to a process of cross-validation, in order to understand whether we are doing everything correctly. <br>  The final decision was chosen based on these statistics.  They were exactly one U-net network, well trained with the application of everything described above + clipping on the threshold. </p><br><p>  One possible way to provide a solution to the organizers was to create a docker container with a solution image.  Unfortunately, it was not possible to use the container with gpu support (the organizers' requirement), and the final calculation was only for cpu.  In this regard, some clever tricks were also removed, which allows a little higher quality.  For example, initially, each image we chased through the grid several times: </p><br><ul><li>  normal image </li><li>  mirrored </li><li>  upside down </li><li>  slightly reduced </li><li>  slightly enlarged </li></ul><br><p>  Then the results were averaged. </p><br><p>  As the subsequent results showed, even without such tricks, the quality of the network‚Äôs operation was enough to take first place on both test datasets =) </p><br><h3 id="rezultaty">  results </h3><br><p>  This year, 18 teams from around the world took part in the competition.  There were participants from the USA, China, India, Europe, countries of the Middle East and even from Australia.  A variety of solutions were proposed using neural network models, modifications of classical adaptive methods, game theory, and combinations of various approaches.  At the same time, a large variability was observed in the types of architectures used by neural networks.  Both fully connected, convolutional, and recurrent variants with LSTM layers were used.  As a preprocessing stage, for example, filtering and morphology were used.  In the original article, they briefly described all the methods used by the participants - often they are so different that one can only wonder how they show a similar result. </p><br><p>  Our solution managed to take the first place both on handwritten documents and on printed documents.  The following are the final results of the measurement solutions.  The description of the metrics can be found in the works of the organizers of the competition published in previous years.  We briefly describe only the top 5 results, the rest can be read in the original article (a link to it should soon appear on the <a href="https://vc.ee.duth.gr/dibco2017/">official website of the competition</a> ).  As a guideline, the organizers provide measurements for the classic Otsu classical zero-parametric global method and Sauvola's local low-parametric authorship (unfortunately, the exact values ‚Äã‚Äãof the tuning coefficients are unknown). </p><br><table><thead><tr><th>  No </th><th>  Brief description of the method </th><th>  Score </th><th>  FM </th><th>  Fps </th><th>  PSNR </th><th>  DRD </th></tr></thead><tbody><tr><td>  <strong>one</strong> </td><td>  <strong>Our method (U-net network)</strong> </td><td>  <strong>309</strong> </td><td>  <strong>91.01</strong> </td><td>  <strong>92.86</strong> </td><td>  <strong>18.28</strong> </td><td>  <strong>3.40</strong> </td></tr><tr><td>  2 </td><td>  FCN (VGG similar architecture) <br>  + postfiltering </td><td>  455 </td><td>  89.67 </td><td>  91.03 </td><td>  17.58 </td><td>  4.35 </td></tr><tr><td>  3 </td><td>  Ensemble of 3 DSN, <br>  with 3-level output, <br>  working on patches of various scales </td><td>  481 </td><td>  89.42 </td><td>  91.52 </td><td>  17.61 </td><td>  3.56 </td></tr><tr><td>  four </td><td>  Ensemble of 5 FCN - entrance: <br>  patches of different scales <br>  + binarized by howe method <br>  + RD signs. </td><td>  529 </td><td>  86.05 </td><td>  90.25 </td><td>  17.53 </td><td>  4.52 </td></tr><tr><td>  five </td><td>  Similar to the previous method, <br>  but added CRF construction processing </td><td>  566 </td><td>  83.76 </td><td>  90.35 </td><td>  17.07 </td><td>  4.33 </td></tr><tr><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td><td>  ... </td></tr><tr><td>  7 </td><td>  Morphology + Howe + post processing </td><td>  635 </td><td>  89.17 </td><td>  89.88 </td><td>  17.85 </td><td>  5.66 </td></tr><tr><td></td><td>  Otsu </td><td></td><td>  77.73 </td><td>  77.89 </td><td>  13.85 </td><td>  15.5 </td></tr><tr><td></td><td>  Sauvola </td><td></td><td>  77.11 </td><td>  84.1 </td><td>  14.25 </td><td>  8.85 </td></tr></tbody></table><br><p>  The best method, not using any way neural nets, took the 7th place. </p><br><p>  The following demonstrates the operation of our algorithm on a number of test images. </p><br><p><img src="https://habrastorage.org/webt/w-/_2/1f/w-_21f_c-7rupa_apzcxfplyjhk.png" width="350"><img src="https://habrastorage.org/webt/0q/29/q_/0q29q_waciv_41n-ezpy8il0rl8.png" width="350"></p><br><p><img src="https://habrastorage.org/webt/gs/3r/vx/gs3rvxt-9a7l7ywzkrx4zhevi4w.png" width="350"><img src="https://habrastorage.org/webt/oc/xw/mg/ocxwmgfucm0vbag9pqcom0ymie0.png" width="350"></p><br><p><img src="https://habrastorage.org/webt/rh/6q/rc/rh6qrc8gob7laq7n2jrit9ktze4.png" width="350"><img src="https://habrastorage.org/webt/z2/ff/8k/z2ff8kekmjt0uodw9mt3yzimk0y.png" width="350"></p><br><p><img src="https://habrastorage.org/webt/gq/bj/vc/gqbjvcex-pp7xfchu8eonjssdle.png" width="350"><img src="https://habrastorage.org/webt/eg/p2/kp/egp2kp-5_x5keo2vghenqsqkulc.png" width="350"></p><br><p><img src="https://habrastorage.org/webt/8n/hd/yf/8nhdyfsdcxa8cehhhu3rnqmjqk4.png" width="350"><img src="https://habrastorage.org/webt/gf/57/5o/gf575oy06vgnlymxksikklt_f1o.png" width="350"></p><br><p>  Well, the testimony that we were presented at the ICDAR 2017 conference in Japan: </p><br><img src="https://habrastorage.org/webt/wg/cy/es/wgcyesj2jiikg2n566agkzx5qci.jpeg"></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/344550/">https://habr.com/ru/post/344550/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../344538/index.html">How I realized what distributed systems are</a></li>
<li><a href="../344540/index.html">Are you still Java code? It's time to change</a></li>
<li><a href="../344542/index.html">The human factor in information security</a></li>
<li><a href="../344546/index.html">What hurts a business?</a></li>
<li><a href="../344548/index.html">Zabbix: LLD monitoring of disks without UserParameter and agent scripts</a></li>
<li><a href="../344552/index.html">OSU! Relax (basics)</a></li>
<li><a href="../344556/index.html">[DotNetBook] Type Instance Structure and VMT</a></li>
<li><a href="../344558/index.html">Garland generation algorithm for the New Year puzzle</a></li>
<li><a href="../344560/index.html">IQ correlation with our life (Feature ranking)</a></li>
<li><a href="../344562/index.html">Lua and Corona SDK (3/3 part)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>