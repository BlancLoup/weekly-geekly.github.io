<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep Dream: how to train a neural network to dream not only about dogs</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In July, everyone was pleased with the deep dream article or introspection from Google. The article described in detail and showed how neural networks...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep Dream: how to train a neural network to dream not only about dogs</h1><div class="post__text post__text-html js-mediator-article">  In July, everyone was pleased with the deep dream article or introspection from Google.  The article described in detail and showed how <a href="https://onthe.io/learn/en/category/qna/Neural-Network-Starter-Guide-%25E2%2580%2593-What-Is-It%252C-Where-It%25E2%2580%2599s-Used">neural networks</a> draw pictures and why they were forced to do it.  Here <a href="http://habrahabr.ru/company/io/blog/262267/">this article</a> on Habr√©. <br><br>  Now everyone who has a caffe environment, who is bored and who has free time can make their own photos of intrestingism.  One problem - almost all the pictures are dogs.  How can you get rid of the elements with dogs in deep dream images and <a href="https://onthe.io/learn/en/category/qna/Top---10-machine---learning-and-data---mining-algorithms">train</a> your neural network to use other pictures? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a66/b7b/686/a66b7b6862620b1e19cff2f43a47da8d.jpg" alt="image"><br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Step-by-step instruction </h4><br>  For this task, you do not need to train the network from scratch - just tune the parameters in Googlenet.  Building a network from scratch requires a lot of time, hundreds of hours.  Read <a href="http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html">this</a> before you begin. <br><br>  The most difficult part is to download 200-1000 images that you want to use for training.  The author came to the conclusion that similar images work well.  You can use faces, pornographic pictures, letters, animals, firearms, and so on. <br><br>  Resize all images to 256x256.  Save them as Truecolor JPG (but not in Grayscale, even if the image is black and white). <br><br>  Calculate the average colors of all your images (this is optional).  You need to know about the average red, green and blue in the set of pictures.  For this, the author uses the convert and identify tools in <a href="https://onthe.io/learn/en/category/graphic/ImageMagick-vs.-GraphicsMagick%253A-benchmarks">ImageMagick</a> : <br><br><pre><code class="bash hljs">convert *.jpg -average res.png identify -verbose res.png</code> </pre> <br>  So you can see the average figure for each color channel. <br><br>  Create a folder <code>&lt;caffe_path&gt;/models/MYNET. <br></code> <code>&lt;caffe_path&gt;/models/MYNET. <br></code>  This is a working folder.  All created folders and files will be placed in MYNET. <br><br>  Create a folder called <code>'images' <br></code> <code>'images' <br></code>  (in the working folder in MYNET). <br><br>  For each of the images you need to create a separate folder inside the 'images' folder.  The author uses numbers starting from 0. For example, <code>'images/0/firstimage.jpg', <br></code> <code>'images/0/firstimage.jpg', <br></code> <code>'images/1/secondimage.jpg', <br></code>  and so on.  Each folder is a category, so that you end up with many folders, each containing one image at a time. <br><br>  Create a text file called <code>train.txt <br></code> <code>train.txt <br></code>  (and place it in the working folder).  Each line in this file must contain the path to the image with the image category number.  It looks like this: <br><br><pre> <code class="bash hljs">images/0/firstimage.jpg 0 images/1/secondimage.jpg 1 ‚Ä¶</code> </pre><br>  Copy the contents of the <code>train.txt <br></code> file <code>train.txt <br></code>  in the file <code>val.txt. <br></code> <code>val.txt. <br></code>  Copy the files <code>deploy.prototxt, <br></code> <code>deploy.prototxt, <br></code> <code>train_val.prototxt <br></code>  and <code>solver.prototxt <br></code> <code>solver.prototxt <br></code>  into the working folder <a href="https://gist.github.com/tsulej/ff2b3e37aa76e8fbb244">from here</a> . <br><br><h4>  How to edit files </h4><br><h5>  1. train_val.prototxt </h5><br>  Lines 13-15 (and 34-36) determine the average values ‚Äã‚Äãfor your set of pictures for the blue, green, and red channels (in this sequence).  If you do not know the values, simply set ‚Äú129‚Äù everywhere. <br><br>  In line 19, specify the number of simultaneously processed images.  A 4-gigabyte graphics processor can handle 40 images, well, and if the processor is 2 GB, the number will need to be reduced to 20. If the number you enter is too high, the program will generate an ‚Äúout of memory‚Äù error and you will need to enter a smaller value.  Any number of pictures, even 1, will do. <br><br>  Lines 917, 1680, and 2393. <code>num_output <br></code> <code>num_output <br></code>  must match the number of your categories, i.e.  number of folders in the image directory. <br><br><h5>  2. deploy.prototxt </h5><br>  Line 2141, <code>num_output <br></code> <code>num_output <br></code>  should be the same as in the previous file. <br><br><h5>  3. solver.prototxt </h5><br>  It is very important to change the following values: <br><br><ul><li>  display: 20 - print statistics after every 20 iterations </li><li>  base_lr: 0.0005 - learning rate (learning rate), it can be changed.  base_lr can be adapted based on the results (see strategy below) </li><li>  max_iter: 200000 - the maximum number of iterations for training.  Here you can specify at least 1,000,000. </li><li>  snapshot: 5000 - how often progress will be maintained.  (in this case, every 5000 iterations).  This value is absolutely necessary if you need to stop learning at any point. </li></ul><br><h4>  Almost everything is ready </h4><br>  Still need googlenet.  Open <code>caffe/models/bvlc_googlenet <br></code> <code>caffe/models/bvlc_googlenet <br></code>  and save this file <a href="http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel">here</a> . <br><br>  Go to the working folder and execute this command: <br><br><pre> <code class="bash hljs">../../build/tools/caffe train -solver ./solver.prototxt -weights ../bvlc_googlenet/bvlc_googlenet.caffemodel</code> </pre><br>  Progress will be saved every 5000 iterations.  When it continues, you can interrupt training and run Deep Dream on the network.  The first results should be visible in the <code>inception_5b/output <br></code> layer <code>inception_5b/output <br></code>  . <br>  To resume learning, use the latest save progress with the following command: <br><br><pre> <code class="bash hljs">../../build/tools/caffe train -solver ./solver.prototxt -snapshot ./MYNET_iter_5000.solverstate</code> </pre><br><h4>  Strategies for base_lr </h4><br>  There are several strategies for <code>base_lr <br></code> <code>base_lr <br></code>  during the first 1000 iterations.  Watch the percentage of losses.  During training, the value should gradually decrease to 0.0, however: <br><br><ul><li>  If you see that the percentage of losses is higher and higher, interrupt the training and set the value to <code>base_lr <br></code> <code>base_lr <br></code>  five times lower than the current. </li><li>  If the loss percentage is ‚Äústuck‚Äù at the same level and decreases very slowly, interrupt the training and set the value to <code>base_lr <br></code> <code>base_lr <br></code>  5 times higher than the previous value. </li><li>  If none of the above strategies worked, then there is probably a problem and the training failed.  Change image set and try again. </li></ul><br><h4>  Some insights </h4><br>  The graphics processor of the author - NVIDIA GTX960 with 4 GB of RAM.  Caffe is compiled with the CuDNN library.  Every 5,000 iterations took about an hour.  When using the CPU, the calculations were 40 times slower. <br><br>  The author advises to stop learning after 40 thousand iterations, but once made 90 thousand.  The user with the nickname DeepDickDream took 750 thousand iterations to add the portrait of <a href="http://deepdickdreams.tumblr.com/">Hulk Hogan</a> from the members. <br><br>  You have little chance to make a set of images visible, if you do less than 100,000 iterations, but there is a good chance to see something new ... and without dogs. <br><br>  In one category may be more images than others.  For example, you can use 20 categories with two hundred pictures in them.  You can train the network on random images, identical or similar - in general, whatever.  The author failed to isolate the rule that provides the best result.  Maybe it all depends on the content. <br><br><h4>  Examples </h4><br>  Network trained with images from the British Library.  11 categories.  100 thousand images (each image had 10 options).  The inception layers 3, 4 and 5 have been cleared.  The result was after 25 thousand iterations.  The faces from the portrait album are clearly visible.  Here is the image from layer <code>5b/output <br></code> <code>5b/output <br></code>  . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05a/308/39f/05a30839fc040922f5279e2db0a210aa.jpg" alt="image"><br><br>  Subdivision of the British Library, containing only letters.  750 categories, one image each.  40 thousand iterations.  Only the classification layer is cleared.  I wonder why butterflies are clearly visible?  Layer 5b. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f33/5e0/b04/f335e0b04a081d7be61448bff2ee4d8e.jpg" alt="image"><br><br>  The same picture, but with an hourglass.  Layer 5a. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/faa/023/442/faa023442b7989d654f0ee2599a4e395.jpg" alt="image"><br><br>  But a set of pornographic nature.  94 categories, 100 images each.  90 thousand iterations.  Layer 5b. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8d9/8cc/861/8d98cc861c00c081093c4f1687b14f62.jpg" alt="image"><br><br>  The image is similar to the previous one, but with a modified set of images (the effects of image rotation, reflection, normalization, blur, etc.) are used.  40 thousand iterations.  Layer 5b. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e4f/100/961/e4f10096170c3ae3cf02761775a7a4d3.jpg" alt="image"><br><br>  4 categories of distorted images, 1000 each, 65 thousand iterations.  Pool5 layer. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2f5/9de/ccc/2f59decccf5ccdae45b58a161389958e.jpg" alt="image"><br><br>  An image similar to the previous one.  80 thousand iterations.  With empty 3.4 and 5 layers.  Layer 5b. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/183/116/a2a/183116a2a44617e136181570f19c0b00.jpg" alt="image"><br><br><h4>  Abstract </h4><br><ol><li>  For this task, you do not need to train the network from scratch - just tune the parameters in Googlenet. </li><li>  The most difficult part is to download 200-1000 images that you want to use for training. </li><li>  Good work the same type of images. </li><li>  The size of all the pictures you need to change to 256x256. </li><li>  You can train the network on random images, identical or similar. </li></ol></div><p>Source: <a href="https://habr.com/ru/post/264757/">https://habr.com/ru/post/264757/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../264741/index.html">How to become a cool designer for 365 days</a></li>
<li><a href="../264743/index.html">Fresh sections for the 2nd quarter of the popularity of CMS-systems, meters / systems analytics and online consultants</a></li>
<li><a href="../264747/index.html">Juniper Workshop: JunOS as a second language</a></li>
<li><a href="../264749/index.html">Huawei Enterprise Server Unit</a></li>
<li><a href="../264753/index.html">Cloud server in the Netherlands and the USA free of charge until October for registered users of habrahabr</a></li>
<li><a href="../264759/index.html">How to get rid of interfaces</a></li>
<li><a href="../264763/index.html">How Windows 10 collects user data</a></li>
<li><a href="../264767/index.html">JetBrains Product Pack for Students and how to get it</a></li>
<li><a href="../264773/index.html">Apple fixed a major vulnerability in OS X</a></li>
<li><a href="../264775/index.html">Comparison of Drupal code execution speed for PHP 5.3-5.6 and 7.0. "Battle of code optimizers" apc vs xcache vs opcache</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>