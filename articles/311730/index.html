<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>OpenGL ES 2.0. Deferred lighting</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article we will look at one of the options for implementing deferred lighting on OpenGL ES 2.0. 

 Deferred lighting 


 The traditional way o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>OpenGL ES 2.0. Deferred lighting</h1><div class="post__text post__text-html js-mediator-article"><p>  In this article we will look at one of the options for implementing deferred lighting on OpenGL ES 2.0. </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/GXV0x_QblWg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h2>  Deferred lighting </h2><br><p>  The traditional way of rendering a scene (forward rendering) involves drawing an individual object in one or several passes, depending on the number and nature of the processed light sources (the object receives lighting from one or several sources at each pass).  This means that the amount of resources spent on a single pixel-type light source is of the order of growth O (L * N), where N is the number of illuminated objects, and L is the number of illuminated pixels. </p><br><p>  The main task of <a href="https://en.wikipedia.org/wiki/Deferred_shading">deferred lighting (deferred shading / lighting / rendering) is to</a> more efficiently process a large number of light sources using the means of separating the rendering of scene geometry from lighting rendering.  Thereby, reducing the amount of resources expended to O (L). </p><br><p>  In general, the technique consists of two passes. </p><br><ul><li>  <strong>Geometry pass</strong> .  Objects are drawn to create buffers of screen space (G-buffer) with depth, normals, positions, albedo and degree of specularity. </li><li>  <strong>Lighting pass</strong> .  Buffers created in the previous pass are used to calculate the lighting and get the final image. </li></ul><br><p>  To use this technology in full and build buffers, you need hardware support for <a href="https://en.wikipedia.org/wiki/Multiple_Render_Targets">Multiple Render Targets (MRT)</a> . </p><br><p>  Unfortunately, MRT is supported only on processors compatible with OpenGL ES 3.0. </p><br><p>  In order to circumvent this hardware limitation, we will use a modified delay lighting technique, known as <a href="http://diaryofagraphicsprogrammer.blogspot.ru/2008/03/light-pre-pass-renderer.html">Light Pre-Pass (LPP)</a> . </p><br><h2>  Light pre pass </h2><br><p>  So, based on the fact that in the first pass we will not be able to build all the necessary buffers <em>for the final image</em> , we build only those that are necessary to <em>calculate the lighting</em> .  In the second pass we form only an illumination buffer.  And unlike the general case (where, the geometry is drawn only once), we, on the third pass, draw all the objects again, forming the final image.  Objects get calculated lighting from the previous passage, combine it with color textures.  The third pass compensates for what we could not (due to hardware limitations) to do on the first. </p><br><ul><li>  <strong>Geometry pass</strong> .  Objects are drawn to create buffers of screen space with only depth and normals. </li><li>  <strong>Lighting pass</strong> .  Build an illumination buffer.  To calculate the light, in addition to data from the previous passage (depth and normal buffers), we also need the three-dimensional position of the pixel.  The technique assumes the restoration of the position on the depth buffer. </li><li>  <strong>Final pass</strong> .  Objects are drawn to create the final image, based on the illumination buffer and color textures of the objects. </li></ul><br><p>  Before examining each pass in detail, we should mention the additional constraints imposed on the buffers in OpenGL ES 2.0.  We will need to support two additional extensions <a href="https://www.khronos.org/registry/gles/extensions/OES/OES_rgb8_rgba8.txt">OES_rgb8_rgba8</a> and <a href="https://www.khronos.org/registry/gles/extensions/OES/OES_packed_depth_stencil.txt">OES_packed_depth_stencil</a> . </p><br><ul><li>  <strong>OES_rgb8_rgba8</strong> .  Allow us to support textures with pixel data format RGBA8 as buffers.  We will use such textures as a normal buffer and an illumination buffer. </li><li>  <strong>OES_packed_depth_stencil</strong> .  Allow us to use the depth buffer along with the <a href="https://www.opengl.org/wiki/Stencil_Test">stencil buffer</a> and the pixel data format UNSIGNED_INT_24_8_OES.  (24 bits - depth, 8 bits - the value of the stencil).  The buffer is required at the second stage of optimization.  Also, because of the 24-bit depth buffer, we will need support for high-precision computations in the fragment shader. </li></ul><br><p>  Currently, these extensions support more than 95% of existing devices. </p><br><h3>  Geometry pass </h3><br><p>  Creating a buffer for off-screen rendering </p><br><pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//      glBindTexture(GL_TEXTURE_2D, shared_depth_buffer); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT24_OES, cx, cy, 0, GL_DEPTH_STENCIL_OES, GL_UNSIGNED_INT_24_8_OES, nullptr); glBindTexture(GL_TEXTURE_2D, 0); //      glBindTexture(GL_TEXTURE_2D, normal_buffer); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, cx, cy, 0, GL_RGBA, GL_UNSIGNED_BYTE, nullptr); glBindTexture(GL_TEXTURE_2D, 0); //     . glBindFramebuffer(GL_FRAMEBUFFER, pass_fbo); //       glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, normal_buffer, 0); //      . //                glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, shared_depth_buffer, 0); glBindFramebuffer(GL_FRAMEBUFFER, 0);</span></span></code> </pre> <br><p>  Rendering. </p><br><pre> <code class="hljs pgsql">//   <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec3 a_vertex_pos; <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec3 a_vertex_normal; uniform mat4 u_matrix_mvp; uniform mat4 u_matrix_model_view; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec3 v_normal; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { gl_Position = u_matrix_mvp * vec4(a_vertex_pos, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); v_normal = vec3(u_matrix_model_view * vec4(a_vertex_normal, <span class="hljs-number"><span class="hljs-number">0.0</span></span>)); } //   <span class="hljs-type"><span class="hljs-type">precision</span></span> lowp <span class="hljs-type"><span class="hljs-type">float</span></span>; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec3 v_normal; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { //      gl_FragColor = vec4(v_normal * <span class="hljs-number"><span class="hljs-number">0.5</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); }</code> </pre> <br><p>  Result </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/43e/74b/1b3/43e74b1b31f148a797bc28a995d17ed6.jpeg"></div><br><h3>  Lighting pass </h3><br><p>  Creating a buffer for off-screen rendering </p><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//              ... //     . glBindFramebuffer(GL_FRAMEBUFFER, pass_fbo); //       glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, light_buffer, 0); //         . glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, shared_depth_buffer, 0); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_STENCIL_ATTACHMENT, GL_TEXTURE_2D, shared_depth_buffer, 0); glBindFramebuffer(GL_FRAMEBUFFER, 0);</span></span></code> </pre> <br><p>  Drawing </p><br><p>  At this stage, we will draw each light source separately.  To draw a source, it is necessary to express its volume in any way.  This can be done in different ways, using screen-oriented rectangles, cubes, spheres. </p><br><p>  As an approximation of the light volumes of point sources of light, we will use a primitive called <a href="https://en.wikipedia.org/wiki/Icosphere">Icosphere</a> </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/fac/51c/dd7/fac51cdd7d8a4e9ebdffa0feac3f62b6.jpeg"></div><br><div class="spoiler">  <b class="spoiler_title">Shaders</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">//   <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec3 a_vertex_pos; uniform mat4 u_matrix_mvp; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec4 v_pos; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { v_pos = u_matrix_mvp * vec4(a_vertex_pos, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); gl_Position = v_pos; } //   <span class="hljs-type"><span class="hljs-type">precision</span></span> highp <span class="hljs-type"><span class="hljs-type">float</span></span>; //    uniform <span class="hljs-type"><span class="hljs-type">float</span></span> u_camera_near; //    uniform <span class="hljs-type"><span class="hljs-type">float</span></span> u_camera_far; //   c      // u_camera_view_param.x = tan(fov / <span class="hljs-number"><span class="hljs-number">2.0</span></span>) * aspect; // u_camera_view_param.y = tan(fov / <span class="hljs-number"><span class="hljs-number">2.0</span></span>); uniform vec2 u_camera_view_param; // u_light_inv_range_square = <span class="hljs-number"><span class="hljs-number">1.0</span></span> / light_radius^<span class="hljs-number"><span class="hljs-number">2</span></span> //   c   uniform <span class="hljs-type"><span class="hljs-type">float</span></span> u_light_inv_range_square; //   uniform vec3 u_light_intensity; //      uniform vec3 u_light_pos; //   uniform sampler2D u_map_geometry; //   uniform sampler2D u_map_depth; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec4 v_pos; const <span class="hljs-type"><span class="hljs-type">float</span></span> shininess = <span class="hljs-number"><span class="hljs-number">32.0</span></span>; //    <span class="hljs-type"><span class="hljs-type">float</span></span> fn_get_attenuation(vec3 pos) { vec3 direction = u_light_pos - pos; <span class="hljs-type"><span class="hljs-type">float</span></span> <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> = dot(direction, direction) * u_light_inv_range_square; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.0</span></span> - clamp(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>, <span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); } //       near  far <span class="hljs-type"><span class="hljs-type">float</span></span> fn_get_linearize_depth(<span class="hljs-type"><span class="hljs-type">float</span></span> depth) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">2.0</span></span> * u_camera_near * u_camera_far / (u_camera_far + u_camera_near - (depth * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>) * (u_camera_far - u_camera_near)); } //        vec2 fn_get_uv(vec4 pos) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (pos.xy / pos.w) * <span class="hljs-number"><span class="hljs-number">0.5</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span>; } //   vec3 fn_get_view_normal(vec2 uv) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> texture2D(u_map_geometry, uv).xyz * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; } //        vec3 fn_get_view_pos(vec2 uv) { <span class="hljs-type"><span class="hljs-type">float</span></span> depth = texture2D(u_map_depth, uv).x; depth = fn_get_linearize_depth(depth); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> vec3(u_camera_view_param * (uv * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>) * depth, -depth); } <span class="hljs-type"><span class="hljs-type">void</span></span> main() { //   vec2 uv = fn_get_uv(v_pos); vec3 normal = fn_get_view_normal(uv); vec3 pos = fn_get_view_pos(uv); <span class="hljs-type"><span class="hljs-type">float</span></span> attenuation = fn_get_attenuation(pos); vec3 lightdir = normalize(u_light_pos - pos); <span class="hljs-type"><span class="hljs-type">float</span></span> nl = dot(normal, lightdir) * attenuation; vec3 reflectdir = reflect(lightdir, normal); <span class="hljs-type"><span class="hljs-type">float</span></span> spec = pow(clamp(dot(normalize(pos), reflectdir), <span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>), shininess); gl_FragColor = vec4(u_light_intensity * nl, spec * nl); }</code> </pre> </div></div><br><p>  Result for one source. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/88f/99f/a1b/88f99fa1be0f4eef87c05902baf1aff1.jpeg"></div><br><p>  The volume on the left is the pixels for which the luminance was calculated.  The right shows the pixels that actually received the light.  You may notice that the lit pixels are much smaller than those that participated in the calculations. </p><br><p>  To solve this problem, we will use the stencil buffer, with which we will cut off unnecessary pixels in depth. </p><br><p>  Then the whole process of source light drawing will look like this: </p><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// 0.          // (     ) glEnable(GL_STENCIL_TEST); glDepthMask(GL_FALSE); //       // ------------------------------------------------------------------------ // 1.    glEnable(GL_DEPTH_TEST) // 2.     ,       glColorMask(GL_FALSE, GL_FALSE, GL_FALSE, GL_FALSE); // 3.  .      glClear(GL_STENCIL_BUFFER_BIT); // 4.     glStencilFunc(GL_ALWAYS, 0, 0); glStencilOpSeparate(GL_BACK, GL_KEEP, GL_INCR_WRAP, GL_KEEP); glStencilOpSeparate(GL_FRONT, GL_KEEP, GL_DECR_WRAP, GL_KEEP); // 5.   ... // 6.     , //     ,    glStencilFunc(GL_NOTEQUAL, 0, 0xFF); // 7.    glDisable(GL_DEPTH_TEST); // 8.      glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE); //    // ---------------------------------------------------------------------- // 1.           glEnable(GL_CULL_FACE); // 2.       glCullFace(GL_FRONT); // 3.   (      ). // ,        ... // 4.     glCullFace(GL_BACK); // 5.    glDisable(GL_CULL_FACE);</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Shaders for drawing volume to stencil buffer</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">//   <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec3 a_vertex_pos; uniform mat4 u_matrix_mvp; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { gl_Position = u_matrix_mvp * vec4(a_vertex_pos, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); } //   <span class="hljs-type"><span class="hljs-type">precision</span></span> lowp <span class="hljs-type"><span class="hljs-type">float</span></span>; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { }</code> </pre> </div></div><br><p>  Result </p><br><div style="text-align:center;"><img src="https://habrastorage.org/files/7e6/e05/e7c/7e6e05e7c16a41af98c57deee8392316.jpeg"></div><br><p>  In addition to everything, we note, taking into account the fact that the buffer of the trafeet is filled without excluding surfaces, and the illumination is calculated only on the back, this also solves the problem of rendering the light source, if there is a camera inside. </p><br><h3>  Final pass </h3><br><p>  With the final pass, we once again draw all the objects, restoring the pixel illumination from the buffer from the previous pass. </p><br><pre> <code class="hljs pgsql">//   <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec3 a_vertex_pos; uniform mat4 u_matrix_mvp; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec4 v_pos; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { v_pos = u_matrix_mvp * vec4(a_vertex_pos, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); gl_Position = v_pos; } //   <span class="hljs-type"><span class="hljs-type">precision</span></span> lowp <span class="hljs-type"><span class="hljs-type">float</span></span>; uniform sampler2D u_map_light; uniform vec3 u_color_diffuse; uniform vec3 u_color_specular; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec4 v_pos; vec2 fn_get_uv(vec4 pos) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (pos.xy / pos.w) * <span class="hljs-number"><span class="hljs-number">0.5</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span>; } <span class="hljs-type"><span class="hljs-type">void</span></span> main() { vec4 color_light = texture2D(u_map_light, fn_get_uv(v_pos)); vec3 color = color_light.rgb; gl_FragColor = vec4(u_color_diffuse * color + u_color_specular * (color * color_light.a), <span class="hljs-number"><span class="hljs-number">1.0</span></span>); }</code> </pre> <br><hr><br><p>  The project ID can be found on <a href="https://github.com/PkXwmpgN/elements">GitHub</a> . </p><br><p>  I would be happy for comments and suggestions (you can mail yegorov.alex@gmail.com) <br>  Thank! </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/311730/">https://habr.com/ru/post/311730/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../311718/index.html">How much does it cost to enter the top cash categories of the app store and is there any point?</a></li>
<li><a href="../311720/index.html">WordCamp Europe in Vienna and the WordPress Development Vector</a></li>
<li><a href="../311722/index.html">All about Cisco FastLocation</a></li>
<li><a href="../311726/index.html">libsodium: Public-key authenticated encryption or how I decrypted the message without the private key</a></li>
<li><a href="../311728/index.html">Proof of Fermat's Big Theorem for a cube, as a key</a></li>
<li><a href="../311732/index.html">Docker in production: ‚ÄúWhen you eat it, you are at least not disgusted, especially if you know how to cook‚Äù</a></li>
<li><a href="../311734/index.html">Implementation of alpha testing and alpha lab in projects</a></li>
<li><a href="../311736/index.html">Report from Moscow Python Meetup September 22</a></li>
<li><a href="../311738/index.html">Backup and restore mail from the cloud using Veeam Backup for Microsoft Office 365</a></li>
<li><a href="../311740/index.html">Opus about startaparstvom and competitions in one part</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>