<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>From parser posters of the theater in Python to Telegram-bot. Part 1</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I love opera and ballet, but not very much - to give a lot of money for tickets. The daily viewing of the theater site with a poke into each button wa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>From parser posters of the theater in Python to Telegram-bot. Part 1</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/en/ph/hi/enphhiao8qi4l5r9iao0vbrskhg.jpeg"><br>  I love opera and ballet, but not very much - to give a lot of money for tickets.  The daily viewing of the theater site with a poke into each button was terribly tiring, and the suddenly appearing tickets of 170 rubles for the super-trains stirred up the soul. <br>  To automate this business a script appeared, which runs along the billboard and collects information on the cheapest tickets for the selected month.  Inquiries from the series ‚Äúgive out a list of all operas in March on the old and new stages up to 1000 rubles‚Äù.  A friend dropped "and you do not Telegram-bot?".  This was not the plan, but why not.  The bot was born, although it was spinning on a home laptop. <br>  Then Telegram blocked.  The idea of ‚Äã‚Äãpushing a bot to a working server has melted away, and the interest to bring the functionality to mind has died away.  Under the cut, I tell about the fate of a cheap ticket detective from the very beginning and about what happened to him after a year of use. <br><a name="habracut"></a><br><h3>  1. The origin of the idea and the formulation of the problem <br></h3><br>  In the original formulation, the whole story had one task - to form a list of performances filtered by price, in order to save time on manually viewing each performance of the poster separately.  The only theater whose billboard interested, was and remains the Mariinsky.  Personal experience quickly showed that the budget "gallery" opens on random days for random performances, and bought up quickly enough (if the composition is worthwhile).  To not miss anything, and you need an automatic collector. <br><div class="spoiler">  <b class="spoiler_title">View of the poster with the buttons that you had to manually navigate</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/4fa/35a/13e/4fa35a13ede41a01443fbc3e91450d3c.jpg" alt="image"><br></div></div><br>  I wanted to get a limited set of interesting performances for running the script.  The main criterion, as already mentioned, was the price of the ticket. <br>  The API of the site and the ticket system is not in the public domain, so it was decided (without further ado) to parse the HTML pages, pulling out the necessary tags.  Open the main one, press F12 and study the structure.  It looked adequate, so it quickly came to the 1st implementation. <br>  It is clear that this approach does not scale to other sites with posters and will fall down if the current structure is decided to change.  If readers have ideas on how to make it more stable without an API, write in the comments. <br><br><h3>  2. First implementation.  Minimum functionality </h3><br>  She came to the implementation with experience in working with Python only for solving problems related to machine learning.  Yes, and some deep understanding of html and web-architecture was not (and did not appear).  Therefore, everything was done according to the principle ‚ÄúI know where I am going, but we will find how to go now‚Äù <br>  For the first sketches it took 4 evening hours and familiarity with the modules of requests and Beautiful Soup 4 (not without the help of a good <a href="https://habr.com/ru/post/280238/">article</a> , thanks to the author).  To finish the sketch - still a day off.  I'm not sure that the modules are the most optimal in their segment, but they have closed the current needs.  That's what happened in the first stage. <br>  What information and where to pull can be understood by the structure of the site.  First of all - we collect addresses of representations which are in the poster for the chosen month. <br><div class="spoiler">  <b class="spoiler_title">The structure of the poster page in the browser, everything is conveniently highlighted</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/3f8/142/fda/3f8142fdad0789bac8558d2f0481b021.jpg" alt="image"><br></div></div><br>  From the html page, we need to read the blank URLs, then to go over them and see the price tag.  This is how the link list is built. <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_text</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># URL  html r = requests.get(url) text=r.text return text def get_items(text,top_name,class_name): """   html-  "" url-, ..  - .       top_name  class_name   -  &lt;a class="c_theatre2 c_chamber_halls" href="//tickets.mariinsky.ru/ru/performance/WWpGeDRORFUwUkRjME13/"&gt; &lt;/a&gt; """ soup = BeautifulSoup(text, "lxml") film_list = soup.find('div', {'class': top_name}) items = film_list.find_all('div', {'class': [class_name]}) dirty_link=[] for item in items: dirty_link.append(str(item.find('a'))) return dirty_link def get_links(dirty_list,start,end): # ""    URL- links=[] for row in dirty_list: if row!='None': i_beg=row.find(start) i_end=row.rfind(end) if i_beg!=-1 &amp; i_end!=-1: links.append(row[i_beg:i_end]) return links # ,    ,      num=int(input('    : ')) #URL  .      ,    =) url ='https://www.mariinsky.ru/ru/playbill/playbill/?year=2019&amp;month='+str(num) #    top_name='container content gr_top' class_name='t_button' start='tickets' end='/"&gt;' #  text=get_text(url) dirty_link=get_items(text,top_name,class_name) #   URL-,     links=get_links(dirty_link,start,end)</span></span></code> </pre> <br>  After studying the structure of the page with the purchase of tickets, in addition to the threshold for the price, I decided to allow the user to also choose: <br><br><ul><li>  type of performance (1-opera, 2-ballet, 3-concert, 4-lecture) </li><li>  venue (1-old stage, 2-new stage, 3-concert hall, 4-chamber halls) </li></ul><br>  Information is entered through the console in a numeric format, you can select multiple numbers.  Such variability is dictated by the difference in the pricing policy for opera and ballet (opera is cheaper) and the desire to watch their lists separately. <br>  The result is <b>4 questions and 4 filters per data</b> ‚Äî a month, a threshold by price, type, location. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Next we go through all the links received.  We make get_text and look for a lower price on it, and also pull out the related information.  Due to the fact that you have to look at each URL and convert it to text, the program‚Äôs running time is not instantaneous.  It would be nice to optimize, but I did not think of how. <br>  I will not give the code itself; it will turn out to be rather long, but there everything is really adequate and ‚Äúintuitively clear‚Äù with Beautiful Soup 4. <br>  If the price is less than the one declared by the user and the type-place corresponds to the set, then the console displays a message about the performance.  There was another option to save all this in .xls, but it did not stick.  It is more convenient to look in the console and immediately follow the links than to poke into the file. <br><img src="https://habrastorage.org/getpro/habr/post_images/f61/dd4/a76/f61dd4a7602bc435bfe445d32aa35c51.jpg" alt="image"><br><br>  About 150 lines of code are out.  In this variant, with the described minimal functions, the script is more alive than all the living and runs regularly with a period of a couple of days.  All other modifications were either not finished (the awl died down) and therefore inactive, or no more advantageous in function. <br><br><h3>  3. Expansion of functionality </h3><br>  At the second stage, I decided to track the price change, keeping the links to the performances of interest in a separate file (more precisely, the URL to them).  First of all, this is true for ballets - they are rarely very cheap and will not fall into the overall budget issue.  But from 5 thousand to 2x the fall is significant, especially if the performance is with a star composition, and it wanted to be tracked. <br>  To do this, you must first add the URLs for tracking, and then periodically ‚Äúshake up‚Äù them and compare the new price with the old one. <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">add_new_URL</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(user_id,perf_url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#user_id ,        - WAITING_FILE = "waiting_list.csv" with open(WAITING_FILE, "a", newline="") as file: curent_url='https://'+perf_url text=get_text(curent_url) #      - , ,,   minP, name,date,typ,place=find_lowest(text) user = [str(user_id), perf_url,str(m)] writer = csv.writer(file) writer.writerow(user) def update_prices(): #        print(' ') WAITING_FILE = "waiting_list.csv" with open(WAITING_FILE, "r", newline="") as file: reader = csv.reader(file) gen=[] for row in reader: gen.append(list(row)) L=len(gen) lowest={} with open(WAITING_FILE, "w", newline="") as fl: writer = csv.writer(fl) for i in range(L): lowest[gen[i][1]]=gen[i][2] #   URL  for k in lowest.keys(): text=get_text('https://'+k) minP, name,date,typ,place=find_lowest(text) if minP==0: #     ,      "" minP=100000 if int(minP)&lt;int(lowest[k]): #   ,    lowest[k]=minP for i in range(L): if gen[i][1]==k: #  -  URL   gen[i][2]=str(minP) print('   '+k+'    '+str(minP)) writer.writerows(gen) add_new_URL('12345','tickets.mariinsky.ru/ru/performance/ZVRGZnRNbmd3VERsNU1R/') update_prices()</span></span></code> </pre> <br>  The price update was launched at the beginning of the main script, it was not separately submitted.  Maybe not as elegant as we would like, but it solves its problem.  So the second additional functionality was the monitoring of price cuts for interesting performances. <br><br>  Next was born Telegram-bot, not so easily, quickly, defiantly, but still born.  In order not to collect everything in one pile, the story about it (as well as about unrealized ideas and an attempt to do this with the Bolshoi Theater website) will be in the second part of the article. <br><br>  <b>RESULT: the</b> idea was a success, the user (s) are satisfied.  It took a couple of days off to figure out how to interact with html pages.  The benefit of Python is a language for almost everything and ready-made modules help drive a nail without thinking about the physics of the hammer. <br><br>  I hope the case will be useful to habravchanam and, perhaps, will work as a magic Pendel, to finally make a wishlist that has long been sitting in my head. </div><p>Source: <a href="https://habr.com/ru/post/444460/">https://habr.com/ru/post/444460/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../444446/index.html">Making a modern web application from scratch</a></li>
<li><a href="../444448/index.html">Mirai clone adds dozens of new exploits to targeted corporate IoT devices</a></li>
<li><a href="../444452/index.html">"Kaspersky Lab" complained to Apple on FAS</a></li>
<li><a href="../444454/index.html">Mining on the ESP32 microcontroller was not very profitable</a></li>
<li><a href="../444456/index.html">Atari 65XE - USB Keyboard</a></li>
<li><a href="../444462/index.html">Testing the Samsung Galaxy S10 - when will smartphones catch up with the cameras?</a></li>
<li><a href="../444464/index.html">Another way to shoot yourself a leg is using std :: thread</a></li>
<li><a href="../444466/index.html">Sorry, but all of your databases belong to Google. Google Presentation at Game Development Conference 2019, Stadia Project</a></li>
<li><a href="../444468/index.html">Nvidia's neural network turns simple sketches into beautiful landscapes</a></li>
<li><a href="../444470/index.html">20 habits of attention hygiene: how to use technology, but do not allow them to select their time and attention</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>