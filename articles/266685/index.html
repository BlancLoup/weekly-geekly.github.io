<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Accelerate vectorization and memory accesses in DL_MESO: optimization examples with Vectorization Advisor on a large project</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We have already written about Vectorization Advisor and examples of its use in simple samples . Today we will share information about how Intel engine...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Accelerate vectorization and memory accesses in DL_MESO: optimization examples with Vectorization Advisor on a large project</h1><div class="post__text post__text-html js-mediator-article">  We have already written <a href="http://habrahabr.ru/company/intel/blog/255731/">about Vectorization Advisor</a> and examples of its use <a href="http://habrahabr.ru/company/intel/blog/257309/">in simple samples</a> .  Today we will share information about how Intel engineers, together with researchers from STFC Daresbury Laboratory in the UK, optimized the DL_MESO package. <br><br><img src="https://habrastorage.org/files/e72/343/cf4/e72343cf40df43378e0b666b41d56d39.png"><br><br>  <a href="http://www.scd.stfc.ac.uk/40694.aspx">DL_MESO</a> is a scientific package for simulating condensed media at the mesoscopic level (forgive me, chemists and physicists, if not correctly translated).  The package was developed in the Daresbury laboratory and is widely used both in the research community and in the industry (by Unilever, Syngenta, Infineum).  With this software, optimal formulas for shampoos, fertilizers and fuel additives are sought.  This process is called ‚ÄúComputer Aided Formulation‚Äù (CAF) - I translated it as ‚ÄúCAD in the field of developing chemical formulas‚Äù. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      CAF simulation is a very resource-intensive computation, so developers were immediately interested in the most productive design.  And DL_MESO was chosen as one of the joint projects in the ‚ÄúIntel Parallel Computing Center‚Äù (IPCC) between Intel and Hartree. <br>  The developers of DL_MESO wanted to take advantage of the hardware capabilities of vector parallelism, because future technologies like AVX-512 can potentially make code 8 times faster on double-precision numbers (compared to non-vectorized code). <br><br>  In this post we will describe how scientists from Darsbury used Vectorization Advisor to analyze Lattice Boltzmann Equation code in DL_MESO, what specific problems they found, and how to fix their code to overclock it 2.5 times. <br><a name="habracut"></a><br><h1>  Survey Profile </h1><br>  What is the Vectorization Advisor, read the <a href="http://habrahabr.ru/company/intel/blog/255731/">first article</a> .  Here we go straight to the Surt profile of the Lattice Boltzman component.  About half of the total execution time falls on ten ‚Äúhot‚Äù cycles, among which there are no obvious leaders, each spending no more than 12% of the total program time.  This picture is close to the ‚Äúflat profile‚Äù (flat profile), which is usually bad for a programmer.  After all, to achieve significant acceleration, it is necessary to optimize each of the cycles separately. <br><br><img src="https://habrastorage.org/files/64e/ff5/54a/64eff554a958495bbb3ce195f3774eae.png"><br><br>  But, fortunately for developers from Darsbury, Vectorization Advisor can quickly characterize the cycles as follows: <br><br><ol><li>  <b>Vectorized</b> but <b>not vectorized</b> cycles that require minimal code changes (usually using OpenMP4.x) to enable the generation of a SIMD code.  The first 4 cycles (CPU time) fall into this category. </li><li>  <b>Vectorized</b> cycles, the performance of which can be improved by simple manipulations. </li><li>  <b>Vectorized</b> loops whose performance is limited by the data layout structure.  Optimization of such cycles requires more serious processing of the code.  As we will see later, after eliminating problems with the first two categories, the two most loaded cycles will become such. </li><li>  Vectorized cycles that already work well. </li><li>  All other cases (including non-vectorized cycles). </li></ol><br>  Vectorization Advisor not only provides information on cycles.  The Recommendations and Compiler Diagnostic Details tabs let you know about specific problems and how to solve them. <br><br>  In our case, the third hotspot (‚Äúhot‚Äù cycle, forgive me the guardians of the purity of the language) in fGetSpeedSite could not vectorize because the compiler could not estimate how many iterations it would have.  Compiler Diagnostic Details describes the essence of the problem with an example and suggestions for solving it - add the "#pragma loop count" directive.  Following the advice, this cycle was quickly vectorized and moved from category 2 to category 4. <br><br><img src="https://habrastorage.org/files/3cf/f1a/d65/3cff1ad65a26408c9c273ca0b46901a4.png"><br><br>  Even when the code can be vectorized, this does not necessarily immediately lead to an increase in productivity (categories 2 and 3).  Therefore, it is important to investigate already vectorized cycles for their effectiveness. <br><br><h1>  Simple optimization: padding in the equilibrium distribution core </h1><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fGetEquilibriumF</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *feq, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *v, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params"> rho)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> modv = v[<span class="hljs-number"><span class="hljs-number">0</span></span>]*v[<span class="hljs-number"><span class="hljs-number">0</span></span>] + v[<span class="hljs-number"><span class="hljs-number">1</span></span>]*v[<span class="hljs-number"><span class="hljs-number">1</span></span>] + v[<span class="hljs-number"><span class="hljs-number">2</span></span>]*v[<span class="hljs-number"><span class="hljs-number">2</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> uv; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;lbsy.nq; i++) { uv = lbv[i*<span class="hljs-number"><span class="hljs-number">3</span></span>] * v[<span class="hljs-number"><span class="hljs-number">0</span></span>] + lbv[i*<span class="hljs-number"><span class="hljs-number">3</span></span>+<span class="hljs-number"><span class="hljs-number">1</span></span>] * v[<span class="hljs-number"><span class="hljs-number">1</span></span>] + lbv[i*<span class="hljs-number"><span class="hljs-number">3</span></span>+<span class="hljs-number"><span class="hljs-number">2</span></span>] * v[<span class="hljs-number"><span class="hljs-number">2</span></span>]; feq[i] = rho * lbw[i] * (<span class="hljs-number"><span class="hljs-number">1</span></span> + <span class="hljs-number"><span class="hljs-number">3.0</span></span> * uv + <span class="hljs-number"><span class="hljs-number">4.5</span></span> * uv * uv - <span class="hljs-number"><span class="hljs-number">1.5</span></span> * modv); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; }</code> </pre> <br>  The lbv array stores speeds for the spatial grid in all dimensions.  The variable lbsy.nq contains the number of speeds.  The model represents a three-dimensional 19-speed grid (scheme D3Q19).  Those.  The value lbsy.nq is 19. The resulting equilibrium is stored in the array feq [i]. <br><br>  In the first analysis, the cycle was scalar, not vectorized.  By simply adding "#pragma omp simd" before the loop, it was vectorized, and its share in total CPU time dropped from 13% to 9%.  But even with these changes, there is still room for improvement. <br><br>  New result Advisor XE showed that the compiler generated not one, but two cycles: <br><br><ul><li>  Vectorized loop body with a long vector (Vector Length - VL) equal to 4 - 4 doubles in the 256-bit AVX register. </li><li>  Scalar remainder, consuming 30% of the time of this cycle. </li></ul><br>  This Scalar remainder is an unnecessary overhead.  Its presence is detrimental to parallel efficiency.  Such a large "weight" remainder is caused by the fact that the number of iterations is not divisible by VL (vector length) exactly.  The compiler generates vector instructions for iterations 0-15, and the remaining iterations from 16 to 18 are executed in the scalar remainder.  3 iterations, and even slowly running consistently, and make up 30% of the cycle time.  Ideally, all iterations should be executed in a vector code, and there should be no remainder at all. <br><br>  We can apply the data padding technique to our cycle.  Increase the number of iterations to 20, which will be a multiple of VL (4).  Advisor XE explicitly advises doing this in the Recommendations tab: <br><br><img src="https://habrastorage.org/files/0ef/4e1/9ff/0ef4e19ff42b401cac38d3581d17871c.png"><br><br>  To tamper with the data, you will need to increase the size of the feq [], lbv [], and lbw [] arrays in order not to get a segmentation fault.  The table at the end of the article shows the changes in the code.  The value of lbsy.nqpad is the sum of the original number of iterations and the value of padding (NQPAD_COUNT). <br><br>  In addition, the DL_MESO developers added a ‚Äú#pragma loop count‚Äù directive before the loop.  Clearly seeing that the number of iterations is a multiple of VL, the compiler generates a vector code, and the remainder is not executed. <br><br>  In the DL_MESO code there are many of the same constructions that can be improved in the same way.  We fixed three other cycles in the same source file and received 15% acceleration of each of them. <br><br><h1>  Overhead balancing and optimization tradeoffs </h1><br>  The tamping technique used for the first two cycles has its price: <br><br><ul><li>  In terms of performance, we eliminate the overhead in the scalar remainder, but introduce additional calculations in the vector part. </li><li>  From the point of view of supporting the code, we redid the allocation of data structures and potentially included values ‚Äã‚Äãin the compiler directives, depending on the size of the input data and the type of load. </li></ul><br>  In our case, the positive effect on performance outweighed the cons, and the code complication was acceptable. <br><br><h1>  Optimizing data layout: array structures </h1><br>  Vectorization, data padding and data alignment improved the performance of No. 1 hotspot by 25‚Äì30%, the vectorization efficiency according to Advisor XE increased to 56%. <br><br>  Since  56% is still far from 100%, the developers decided to investigate what blocks productivity growth.  Looking again at ‚ÄúVector Issues / Recommendation‚Äù, they discovered a new problem - ‚ÄúPossible inefficient memory access patterns present‚Äù.  The recommendation is to run the ‚ÄúMemory Access Pattern‚Äù (MAP) analysis.  The same advice was in the Traits column: <br><br><img src="https://habrastorage.org/files/bc3/4bd/1dd/bc34bd1dd3fc40059b203291501c2e22.png"><br><br>  To start the MAP analysis, the developer marks the desired cycles and presses the MAP start button on the Workflow panel. <br><br><img src="https://habrastorage.org/files/9db/5d4/717/9db5d4717c444377bf6fdf53aacf7e97.png"><br><br>  The distribution of strides as a result of the MAP shows the presence of a unit-stride (sequential access) and non-unit ‚Äúconstant‚Äù stride - memory accesses with a constant step: <br><br><img src="https://habrastorage.org/files/e51/dd0/795/e51dd079513e4002b975221739a8f837.png"><br><br>  The MAP data in the source code indicates that there are references to strayd 3 (for the original scalar version) and strajd 12 (for the vectorized version with padding) when accessing the lbv array (see table at the end). <br><br>  The call in step 3 occurs to the elements of the velocity array lbv.  Each new iteration is shifted by 3 elements of the array.  Where 3 comes from is clear from the expression lbv [i * 3 + X], to which our memory references are attributed. <br><br>  Such inconsistent access is not very good for vectorization, because it does not allow to load all the elements into the vector register for one instruction of the type mov (its ‚Äúpacked‚Äù version is called differently).  But treatment with a constant step can often be converted to sequential access by applying a transformation from an ‚Äúarray of structures‚Äù to a ‚Äústructure of arrays‚Äù.  Note that after the MAP analysis, the recommendations window advises exactly this (AoS-&gt; SoA) to solve the problem of inefficient memory access - see the screenshot above. <br><br>  The developers applied this conversion to the lbv array.  To do this, the lbv array, initially containing the speeds for X, Y, and Z, was divided into three arrays: lbvx, lbvy, and lbvz. <br><br>  The developers of DL_MESO say that the transformation of the structure of arrays was laborious compared to padding, but the result justified the efforts - the cycle in fGetEquilibrium became 2 times faster, and similar improvements happened with several more cycles working with the lbv array. <br><br>  The results of data structure transformation and loop optimization (padding, leveling), along with performance metrics and memory access patterns Advisor XE: <br><br><img src="https://habrastorage.org/files/f5f/88b/909/f5f88b90975d44e5bcecf5e670d427cc.png"><br><br>  The evolution of the source code of the considered cycle - vectorization directives, alignment, padding, AoS -&gt; SoA transformation, along with the results of the MAP from Advisor XE: <br><br><img src="https://habrastorage.org/files/475/19c/1e6/47519c1e6c7b4f5dac1783c2eba79ec3.png"><br><br><img src="https://habrastorage.org/files/378/561/7c8/3785617c8a4c4fc9ad8c2c89d76df5ce.png"><br><br><h1>  Summary </h1><br>  Using the DL_MESO analysis in Vectorization Advisor and adding a few directives to the code, we managed to reduce the time of the three hottest cycles by 10-19%.  All optimizations were based on Advisor recommendations.  Work was done on ‚Äúturning on‚Äù vectorization and improving loop performance using ‚Äúdata padding‚Äù (padding).  By applying similar techniques to several more cycles, the acceleration of the entire application by 18% was obtained. <br><br>  The following major improvement was obtained when data was transformed: the ‚Äúarray of structures‚Äù into the ‚Äústructure of arrays‚Äù.  Again, based on the recommendation of Advisor XE. <br><br>  In addition, the work and tests were originally conducted on servers with Xeon processors (Advisor does not work on the coprocessor).  When the same thing was done for the code running on the Xeon Phi coprocessor, about the same gain was obtained - the coprocessor was optimized without additional efforts. <br><br>  Below is the acceleration obtained on a regular server (labeled AVX) and on a Xeon Phi map (labeled KnC).  On the Xeon CPU they accelerated 2.5 times, on the Xeon Phi - 4.1 times: <br><br><img src="https://habrastorage.org/files/438/18c/a4f/43818ca4f45b4b2fb0f580ad373d22cb.png"><br><br>  This is a quote from the DL_MESO developer: ‚ÄúLuke Mason, computational scientists in Daresbury lab). <br><br>  <i>This post is a translation of an article by Zakhara Matveyev (Intel Corporation).</i> </div><p>Source: <a href="https://habr.com/ru/post/266685/">https://habr.com/ru/post/266685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../266673/index.html">A small Java-RuleZ FAQ - or why Java is used in 1C: Programmers' Club to prepare for school computer science competitions</a></li>
<li><a href="../266675/index.html">Security Week 37: Bug-bugzilla, Karbanak from back, C & C on fishing</a></li>
<li><a href="../266677/index.html">A little ZPL guide</a></li>
<li><a href="../266681/index.html">Correct work with date and time in Ruby on Rails</a></li>
<li><a href="../266683/index.html">React v0.14 release candidate overview</a></li>
<li><a href="../266687/index.html">Memory Profiling with Intel¬Æ VTune ‚Ñ¢ Amplifier XE</a></li>
<li><a href="../266689/index.html">Rating of data center operators in Russia by the degree of readiness to interact with foreign customers</a></li>
<li><a href="../266693/index.html">Under the hood rendering navigation data in MAPS.ME</a></li>
<li><a href="../266695/index.html">VAD (Voice Application Designer). Part 2 components (Call Related)</a></li>
<li><a href="../266699/index.html">Why the SoundCloud team switched to microservices</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>