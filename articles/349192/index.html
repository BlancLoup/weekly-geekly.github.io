<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Archiving and restoring indexes in Elasticsearch</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="One day, one fine morning, we faced the question of archiving Elasticsearch indexes. I wanted to see in the repository slender rows of compressed file...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Archiving and restoring indexes in Elasticsearch</h1><div class="post__text post__text-html js-mediator-article">  One day, one fine morning, we faced the question of archiving Elasticsearch indexes.  I wanted to see in the repository slender rows of compressed files, one for each index. <br><br>  ‚ÄúOut of the box‚Äù Elastic does not offer such a solution, at least in version 5.x.  After asking a little from Google Almighty, we decided to create our own bike.  Let a little awkward, but native. <br><br><img src="https://habrastorage.org/webt/p5/rl/oc/p5rlocuimoyv18tskvihpu3ytvc.jpeg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><br>  <b>So, given:</b> <br>  Server with Linux OS installed on it.  On the server, version 5.x is installed, configured and running, Elasticsearch stores indexes with names like project_name-yyyy.mm.dd <br><br>  <b>Task:</b> <br>  Archive each index older than N days, compressing it into a separate file to be able to restore this particular index for the desired date.  When the archiving process is complete, remove the index from Elasticsearch. <br><br><h2>  Decision </h2><br><h3>  Indexing Archiving </h3><br>  To work with indexes, we need curator version older than 5.0. <br>  We will pull out indexes from Elasticsearch through snapshots.  Therefore, to begin with, make sure that the configuration file, elasticsearch, is usually the file /etc/elasticsearch/elasticsearch.yml, the path to the file repository is registered: <br><br><pre><code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">path</span></span>.repo: /opt/elasticsearch/snapshots</code> </pre> <br>  If there is no such line, register and restart elasticsearch. <br><br>  Next, create a repository in which we will place snapshots: <br><br><pre> <code class="hljs coffeescript">mkdir -p <span class="hljs-regexp"><span class="hljs-regexp">/opt/elasticsearch/snapshots/repository curl -XPUT 'http:/</span></span>/localhost:<span class="hljs-number"><span class="hljs-number">9200</span></span>/_snapshot/repository<span class="hljs-string"><span class="hljs-string">' -H '</span></span>Content-Type: application/json<span class="hljs-string"><span class="hljs-string">' -d '</span></span>{ <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"fs"</span></span>, <span class="hljs-string"><span class="hljs-string">"settings"</span></span>: { <span class="hljs-string"><span class="hljs-string">"location"</span></span>: <span class="hljs-string"><span class="hljs-string">"repository"</span></span>, <span class="hljs-string"><span class="hljs-string">"compress"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span> } }<span class="hljs-string"><span class="hljs-string">'</span></span></code> </pre><br>  And immediately create another repository called ‚Äúrecovery‚Äù, we will need it to restore the indexes: <br><br><pre> <code class="hljs coffeescript">mkdir -p <span class="hljs-regexp"><span class="hljs-regexp">/opt/elasticsearch/snapshots/recovery curl -XPUT 'http:/</span></span>/localhost:<span class="hljs-number"><span class="hljs-number">9200</span></span>/_snapshot/recovery<span class="hljs-string"><span class="hljs-string">' -H '</span></span>Content-Type: application/json<span class="hljs-string"><span class="hljs-string">' -d '</span></span>{ <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"fs"</span></span>, <span class="hljs-string"><span class="hljs-string">"settings"</span></span>: { <span class="hljs-string"><span class="hljs-string">"location"</span></span>: <span class="hljs-string"><span class="hljs-string">"recovery"</span></span>, <span class="hljs-string"><span class="hljs-string">"compress"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span> } }<span class="hljs-string"><span class="hljs-string">'</span></span></code> </pre><br>  Well, the script itself is archiving indexes.  From the list of indexes to be archived, exclude the indexes <i>.kibana</i> and <i>elastalert_status</i> .  The values ‚Äã‚Äãof the variables specified in the header of the script, of course, can be pulled out and passed to the script as arguments, a matter of taste. <br><br>  The local folder is specified as the archive storage in the script, but this, of course, is not very good practice, and it is better to put the archives somewhere far away in a safe place. <br><br>  The archiving process is logged, the log file is specified by the $ LOG variable.  Do not forget to configure the rotation for the log file. <br><br>  The logic of the script is described in the comments.  Do not forget to correct the values ‚Äã‚Äãof variables, if your settings will be different from the default. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash DAYS=31 # ,   ,      SNAPSHOT_DIRECTORY="/opt/elasticsearch/snapshots" BACKUP_DIR="/opt/elasticsearch/elasticsearch_backup" REPOSITORY="repository" LOG="/var/log/elasticsearch/elasticsearch_backup.log" DATE=`date` #       ,   if ! [ -d $BACKUP_DIR ]; then mkdir -p $BACKUP_DIR fi #  ,   $DAYS INDICES=`curator_cli --config /etc/elasticsearch/curator-config.yml --host localhost --port 9200 show_indices --filter_list "[{\"filtertype\":\"age\",\"source\":\"creation_date\",\"direction\":\"older\",\"unit\":\"days\",\"unit_count\":\"$DAYS\"},{\"filtertype\":\"kibana\",\"exclude\":\"True\"},{\"filtertype\":\"pattern\",\"kind\":\"regex\",\"value\":\"elastalert_status\",\"exclude\":\"True\"}]"` #,     TEST_INDICES=`echo $INDICES | grep -q -i "error" &amp;&amp; echo 1 || echo 0` if [ $TEST_INDICES == 1 ] then echo "$DATE     " &gt;&gt; $LOG exit else #        $INDICES for i in $INDICES do #     $i curator_cli --config /etc/elasticsearch/curator-config.yml --timeout 600 --host localhost --port 9200 snapshot --repository $REPOSITORY --filter_list "{\"filtertype\":\"pattern\",\"kind\":\"regex\",\"value\":\"$i\"}" #        $i SNAPSHOT=`curator_cli --config /etc/elasticsearch/curator-config.yml --host localhost --port 9200 show_snapshots --repository $REPOSITORY` #         cd $SNAPSHOT_DIRECTORY/$REPOSITORY &amp;&amp; tar cjf $BACKUP_DIR"/"$i".tar.bz" ./* #  snapshot curator_cli --config /etc/elasticsearch/curator-config.yml --host localhost --port 9200 delete_snapshots --repository $REPOSITORY --filter_list "{\"filtertype\":\"pattern\",\"kind\":\"regex\",\"value\":\"$SNAPSHOT\"}" #   curator_cli --config /etc/elasticsearch/curator-config.yml --host localhost --port 9200 delete_indices --filter_list "{\"filtertype\":\"pattern\",\"kind\":\"regex\",\"value\":\"$i\"}" #    rm -rf $SNAPSHOT_DIRECTORY/$REPOSITORY/* done fi</span></span></code> </pre><br><h3>  Deleting obsolete archives </h3><br>  Fine!  We received archives of indexes in storage, but they too need to be periodically cleaned too.  Let's create for this a separate script /opt/elasticsearch/delete_archives.sh <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash #    $DAYS  # !          "-"  .      "yyyy.mm.dd". # : aaa_bbb.ccc-yyyy.mm.dd.tar.bz DAYS=91 BACKUP_DIR="/opt/elasticsearch/elasticsearch_backup" #      THRESHOLD=$(date -d "$DAYS days ago" +%Y%m%d) #echo "THRESHOLD=$THRESHOLD" FILES=`ls -1 $BACKUP_DIR` TODELETE=`for i in $FILES; do echo $i | awk -F- '{printf "%s\n",$2 ;}' | awk -F. '{printf "%s%s%s \n",$1,$2,$3 ;}' | sed "s/$/$i/"; done` echo -e "$TODELETE" |\ while read DATE FILE do [[ $DATE -le $THRESHOLD ]] &amp;&amp; rm -rf $BACKUP_DIR/$FILE done</span></span></code> </pre><br>  Well, now it remains to install the scripts in kroner.  We have them run once a day at night.  Script output will redirect to log file <br><br><pre> <code class="bash hljs">0 1 * * * /bin/bash /opt/elasticsearch/backup_snapshot.sh &gt;&gt; /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/elasticsearch/elasticsearch_backup.log 0 3 * * * /bin/bash /opt/elasticsearch/delete_archive.sh &gt;&gt; /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/elasticsearch/elasticsearch_backup.log</code> </pre><br><h3>  Recovery of indexes from archive </h3><br>  The process of restoring indexes is also simple.  For convenience, we wrap the process of restoring the index from the archive to the script, which will be passed as an argument to the file name of the archive file.  For the script to work, you must install the <b>jq</b> utility.  The repository folder / opt / elasticsearch / snapshots / recovery to restore the index and the repository itself in Elasticsearch we created earlier. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash #  ARCHIVE=$1 BACKUP_DIR="/opt/elasticsearch/elasticsearch_backup" RECOVERY_DIR="/opt/elasticsearch/snapshots/recovery/" #       rm -rf $RECOVERY_DIR/* #      tar xjf $BACKUP_DIR/$ARCHIVE -C $RECOVERY_DIR #    $SNAPSHOT     SNAPSHOT=`curl -s -XGET "localhost:9200/_snapshot/recovery/_all?pretty" | jq '.snapshots[0].snapshot' | sed 's/\"//g'` #     curl -XPOST "localhost:9200/_snapshot/recovery/$SNAPSHOT/_restore?pretty" #    ,  Elasticsearch       sleep 30 #     curl -XDELETE "localhost:9200/_snapshot/recovery/$SNAPSHOT?pretty" #    rm -rf $RECOVERY_DIR/*</span></span></code> </pre><br>  <b>Summarize</b> <br><br>  We made archiving of each index into a separate file, set up the removal of obsolete archives and learned how to restore the index for the desired date from the archive. <br>  You can afford to take a pie from the shelf. </div><p>Source: <a href="https://habr.com/ru/post/349192/">https://habr.com/ru/post/349192/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../349178/index.html">Mobile communications in the USSR</a></li>
<li><a href="../349180/index.html">Online consultants on the company's website</a></li>
<li><a href="../349182/index.html">The evolution of traffic jams rendering in MAPS.ME</a></li>
<li><a href="../349184/index.html">How to choose a PoE switch for projects of different scale. Examples from practice</a></li>
<li><a href="../349186/index.html">Comparison of the top 4 popular BI platforms. Which one to choose?</a></li>
<li><a href="../349194/index.html">Three unusual examples of using the blockchain</a></li>
<li><a href="../349196/index.html">Make me think</a></li>
<li><a href="../349198/index.html">Design Patterns in React</a></li>
<li><a href="../349200/index.html">Veeam Academy: from basic knowledge of C # to team development in 2.5 months</a></li>
<li><a href="../349202/index.html">Installation of a certification authority in the enterprise. Part 3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>