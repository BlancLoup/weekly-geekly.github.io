<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Ultrafast speech recognition without servers using a real example</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article I will tell you in detail and show you how to quickly and correctly fasten the recognition of Russian speech on the Pocketsphinx engin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Ultrafast speech recognition without servers using a real example</h1><div class="post__text post__text-html js-mediator-article"><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/gYIj6usRqPc%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700253&amp;usg=ALkJrhhZQAIDJBvwagmhzRqDXbdbZGIDPw" frameborder="0" allowfullscreen=""></iframe><br>  In this article I will tell you in detail and show you how to quickly and correctly fasten the recognition of Russian speech on <a href="http://cmusphinx.sourceforge.net/">the Pocketsphinx engine</a> (for iOS, the <a href="http://www.politepix.com/openears/">port OpenEars</a> ) with a real <s>Hello World</s> example of home appliances control. <br>  Why home appliances?  Yes, because thanks to such an example, one can estimate the <b>speed and accuracy</b> that can be achieved using <b>completely local</b> speech recognition without servers such as <i>Google ASR</i> or <i>Yandex SpeechKit</i> . <br>  <i>I also attach <a href="https://github.com/Morfeusys/veravoice">all source codes of the program and assembly under Android</a> to article.</i> <br><br><a name="habracut"></a><br><br><h4>  Why should I? </h4><br>  Having stumbled upon <a href="http://habrahabr.ru/company/papabubadiop/blog/236079/">an article about screwing Yandex SpeechKit to an iOS application</a> , I <a href="http://habrahabr.ru/company/papabubadiop/blog/236079/">asked the</a> author why he wanted to use server-based speech recognition for his program (in my opinion, this was unnecessary and led to some problems).  To which I <a href="http://habrahabr.ru/company/papabubadiop/blog/236079/">received a counter question</a> about whether I could describe in more detail the use of alternative methods for projects where there is no need to recognize anything, and the dictionary consists of a finite set of words.  Yes, and with an example of practical application ... 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Why do we need something else besides Yandex and Google? </h4><br>  As the very ‚Äúpractical application‚Äù I chose the topic of <b>voice control of the smart home</b> . <br>  Why such an example?  Because on it you can see those several advantages of completely local speech recognition before recognition using cloud solutions.  Namely: <br><ul><li>  <b>Speed</b> - we do not depend on servers and therefore do not depend on their availability, bandwidth, etc.  factors </li><li>  <b>Accuracy</b> - our engine works only with the dictionary that interests our application, thereby improving the quality of recognition </li><li>  <b>Cost</b> - we do not have to pay for each request to the server </li><li>  <b>Voice activation</b> - as an additional bonus to the first points - we can constantly ‚Äúlisten to the broadcast‚Äù without spending our traffic and not loading the server </li></ul><br><div class="spoiler">  <b class="spoiler_title">Note</b> <div class="spoiler_text">  At once I will make a reservation that these advantages can be considered as advantages <i>only for a certain class of projects</i> , where we <i>know in advance exactly</i> which dictionary and grammar the user will operate on.  That is, when we do not need to recognize an arbitrary text (for example, an SMS message, or a search query).  In the opposite case, cloud recognition is indispensable. <br></div></div><br><br><h5>  So Android is able to recognize speech without the Internet! </h5><br>  Yes ... only on JellyBean.  And only half a meter, no more.  And this recognition is the same dictation, only using a much smaller model.  So we cannot control it and tune it either.  And what she will return to us next time is unknown.  Although for SMS ok just right! <br><br><h4>  What do we do? </h4><br><img src="https://habrastorage.org/files/b7f/7cd/961/b7f7cd9611ec4de39c44a3e2541e0d21.jpg"><br>  We will implement a voice remote control home appliances, which will work accurately and quickly, from several meters, and even on <s>cheap brake stuff</s> very inexpensive Android smartphones, tablets and watches. <br>  The logic will be simple, but very practical.  Activate the microphone and pronounce one or more device names.  The application recognizes them and turns them on / off depending on the current state.  Or receives from them a condition and says it in a pleasant female voice.  For example, the current temperature in the room. <br><br>  We will activate the microphone either by voice, or by clicking on the microphone icon, or even just putting a hand on the screen.  The screen in turn can be completely turned off. <br><br><div class="spoiler">  <b class="spoiler_title">Variants of practical use mass</b> <div class="spoiler_text">  In the morning, without opening the eyes, they slammed the palm of the smartphone on the bedside table and commanded ‚ÄúGood morning!‚Äù - the script is launched, the coffee maker is switched on and buzzes, pleasant music is heard, the curtains are moved apart. <br>  Hang on a cheap (thousands of 2, no more) smartphone in each room on the wall.  We go home after work and command the emptiness ‚ÄúSmart home!  Light, TV! ‚Äù- what happens next, I think, no need to say. <br></div></div><br><br>  <a href="https://www.youtube.com/watch%3Fv%3DgYIj6usRqPc">The video shows what happened in the end</a> .  Further, we will discuss the technical implementation with excerpts from the actually working code and some theory. <br><br><h4>  What is Pocketsphinx </h4><br><img src="https://habrastorage.org/files/af1/c77/e7e/af1c77e7ea8340db8faa486fe6782cfa.png"><br>  <a href="http://cmusphinx.sourceforge.net/">Pocketsphinx</a> is an open source recognition engine for Android.  It also has a <a href="http://www.politepix.com/openears/">port for iOS</a> , <a href="http://cmusphinx.sourceforge.net/2014/09/cmusphinx-is-available-on-windows-phone-platform/">WindowsPhone</a> , and even <a href="http://syl22-00.github.io/pocketsphinx.js/">JavaScript</a> . <br>  It will allow us to start speech recognition directly on the device and at the same time configure it specifically for our tasks.  It also offers the function of voice activation "out of the box" (see below). <br><br>  We will be able to feed the Russian language model of the recognition engine (you can find it in the source code) and the grammar of user queries.  This is exactly what our application will recognize.  It can recognize nothing else.  And therefore, almost never give out something that we do not expect. <br><br><div class="spoiler">  <b class="spoiler_title">JSGF Grammar</b> <div class="spoiler_text">  <a href="http://www.w3.org/TR/jsgf/">The JSGF grammar format is</a> used by Pocketsphinx, as well as by many other similar projects.  It is possible to describe with sufficient flexibility those phrases that the user will pronounce.  In our case, the grammar will be built from the names of devices that are in our network, like this: <br><pre><code class="hljs xml"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">commands</span></span></span><span class="hljs-tag">&gt;</span></span> =  |  | ;</code> </pre> <br></div></div><br><br>  Pocketsphinx can also work on the statistical model of the language, which allows you to recognize spontaneous speech, which is not described by context-free grammar.  But for our task it is just not necessary.  Our grammar will consist only of device names.  After the recognition process, Pocketsphinx will return us a regular line of text where the devices will go one by one. <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta">#JSGF V1.0; grammar commands; public </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;command&gt;</span></span></span><span class="hljs-meta"> = </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;commands&gt;</span></span></span><span class="hljs-meta">+; </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;commands&gt;</span></span></span><span class="hljs-meta"> =  |  | ;</span></span></code> </pre><br><br>  <i>The plus sign</i> means that the user can name not one, but several devices in a row. <br>  The application receives a list of devices from the smart home controller (see below) and generates such grammar in the <a href="">Grammar</a> class. <br><br><h4>  Transcriptions </h4><br><img src="https://habrastorage.org/files/7c1/26b/9a3/7c126b9a349a4f84bb9660f767233a2c.JPG"><br>  A grammar describes what the <b>user can say</b> .  In order for the Pocketsphinx to know <b>how</b> it will be pronounced, it is necessary to write for each word from the grammar how it sounds in the corresponding language model.  That is the <i>transcription of</i> each word.  This is called a <i>dictionary</i> . <br><br>  Transcriptions are described using special syntax.  For example: <br><pre> <code class="hljs matlab"> uu mn ay <span class="hljs-built_in"><span class="hljs-built_in">j</span></span>  d oo m</code> </pre><br><br>  In principle, nothing complicated.  A double vowel in transcription denotes stress.  Double consonant is a soft consonant followed by a vowel.  All possible combinations for all sounds of the Russian language <a href="https://sourceforge.net/projects/cmusphinx/files/Acoustic%2520and%2520Language%2520Models/Russian%2520Voxforge/">can be found in the language model itself</a> . <br><br>  It is clear that we cannot describe in advance all the transcriptions in our application, because we do not know in advance the names that the user will give to their devices.  Therefore, we will generate ‚Äúon the fly‚Äù such transcriptions according to some rules of Russian phonetics.  To do this, you can implement the following <a href="">PhonMapper</a> class, which can receive a line at the input and generate the correct transcription for it. <br><br><h4>  Voice activated </h4><br>  This is the ability of the speech recognition engine to ‚Äúlisten to the air‚Äù all the time in order to react to a predetermined phrase (or phrases).  In this case, all other sounds and speech will be discarded.  This is not the same as describing a grammar and simply turning on a microphone.  I will not give here the theory of this problem and the mechanics of how it works.  I can only say that recently programmers working on Pocketsphinx have implemented such a function, and now it is available out of the box in the API. <br><br>  One thing worth mentioning is.  For an activation phrase, you need not only to specify the transcription, but also to select the appropriate <b>threshold value</b> .  Too small a value will lead to a lot of false positives (this is when you did not say the activation phrase, but the system recognizes it).  Too high for immunity.  Therefore, this setting is of particular importance.  The approximate range of values ‚Äã‚Äãis from 1e-1 to 1e-40 <b>, depending on the activation phrase</b> . <br><br><div class="spoiler">  <b class="spoiler_title">Activation by proximity sensor</b> <div class="spoiler_text">  This task is specific to our project and is not directly related to recognition.  The code can be seen right in the <a href="">main activity</a> . <br>  It implements a <i>SensorEventListener</i> and at the time of approaching (the sensor value is less than the maximum) turns on the timer, checking after some delay whether the sensor is still blocked.  This is done to eliminate false positives. <br>  When the sensor is not blocked again, we stop the recognition, getting the result (see the description below). <br></div></div><br><br><h4>  We start recognition </h4><br>  Pocketsphinx provides a convenient API for configuring and running the recognition process.  These are the <i>SppechRecognizer</i> and <i>SpeechRecognizerSetup classes</i> . <br>  Here is how the configuration and the launch of recognition: <br><br><pre> <code class="java hljs">PhonMapper phonMapper = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> PhonMapper(getAssets().open(<span class="hljs-string"><span class="hljs-string">"dict/ru/hotwords"</span></span>)); Grammar grammar = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Grammar(names, phonMapper); grammar.addWords(hotword); DataFiles dataFiles = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataFiles(getPackageName(), <span class="hljs-string"><span class="hljs-string">"ru"</span></span>); File hmmDir = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> File(dataFiles.getHmm()); File dict = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> File(dataFiles.getDict()); File jsgf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> File(dataFiles.getJsgf()); copyAssets(hmmDir); saveFile(jsgf, grammar.getJsgf()); saveFile(dict, grammar.getDict()); mRecognizer = SpeechRecognizerSetup.defaultSetup() .setAcousticModel(hmmDir) .setDictionary(dict) .setBoolean(<span class="hljs-string"><span class="hljs-string">"-remove_noise"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>) .setKeywordThreshold(<span class="hljs-number"><span class="hljs-number">1e-7f</span></span>) .getRecognizer(); mRecognizer.addKeyphraseSearch(KWS_SEARCH, hotword); mRecognizer.addGrammarSearch(COMMAND_SEARCH, jsgf);</code> </pre><br><br>  Here we first copy all the necessary files to disk (Pocketpshinx requires an acoustic model, grammar and dictionary with transcriptions on the disk).  Then the recognition engine itself is configured.  The paths to the model and dictionary files are indicated, as well as some parameters (the sensitivity threshold for the activation phrase).  Next, configure the path to the file with the grammar, as well as the activation phrase. <br><br>  As can be seen from this code, one engine is configured immediately for both grammar and recognition of the activation phrase.  Why is this done?  So that we can quickly switch between what we need to recognize at the moment.  Here is the start of the activation phrase recognition process: <br><br><pre> <code class="java hljs">mRecognizer.startListening(KWS_SEARCH);</code> </pre><br>  And this is how the speech is interpreted according to a given grammar: <br><br><pre> <code class="java hljs">mRecognizer.startListening(COMMAND_SEARCH, <span class="hljs-number"><span class="hljs-number">3000</span></span>);</code> </pre><br>  The second argument (optional) is the number of milliseconds, after which the recognition will automatically terminate if no one says anything. <br>  As you can see, you can use only one engine for solving both tasks. <br><br><h4>  How to get the recognition result </h4><br>  To get the recognition result, you must also specify an event listener that implements the <i>RecognitionListener</i> interface. <br>  It has several methods that are called pocketsphinx when one of the events occurs: <br><ul><li>  <b>onBeginningOfSpeech</b> - the engine has heard some sound, maybe it is speech (or maybe not) </li><li>  <b>onEndOfSpeech</b> - the sound is over </li><li>  <b>onPartialResult</b> - there are intermediate recognition results.  For an activation phrase, this means that it worked.  <i>Hypothesis</i> argument contains recognition data (string and score) </li><li>  <b>onResult</b> is the final result of recognition.  This method will be called after calling the <i>stop</i> method of <i>SpeechRecognizer</i> .  <i>Hypothesis</i> argument contains recognition data (string and score) </li></ul><br><br>  By implementing the onPartialResult and onResult methods in one way or another, you can change the recognition logic and get the final result.  Here is how it is done in the case of our application: <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onEndOfSpeech</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Log.d(TAG, <span class="hljs-string"><span class="hljs-string">"onEndOfSpeech"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (mRecognizer.getSearchName().equals(COMMAND_SEARCH)) { mRecognizer.stop(); } } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onPartialResult</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Hypothesis hypothesis)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (hypothesis == <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; String text = hypothesis.getHypstr(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (KWS_SEARCH.equals(mRecognizer.getSearchName())) { startRecognition(); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { Log.d(TAG, text); } } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onResult</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Hypothesis hypothesis)</span></span></span><span class="hljs-function"> </span></span>{ mMicView.setBackgroundResource(R.drawable.background_big_mic); mHandler.removeCallbacks(mStopRecognitionCallback); String text = hypothesis != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> ? hypothesis.getHypstr() : <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; Log.d(TAG, <span class="hljs-string"><span class="hljs-string">"onResult "</span></span> + text); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (COMMAND_SEARCH.equals(mRecognizer.getSearchName())) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (text != <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>) { Toast.makeText(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, text, Toast.LENGTH_SHORT).show(); process(text); } mRecognizer.startListening(KWS_SEARCH); } }</code> </pre><br><br>  When we receive the onEndOfSpeech event, and if in this case we recognize the command to be executed, then it is necessary to stop recognition, after which onResult will be immediately called. <br>  In onResult you need to check what has just been recognized.  If this is a command, then you need to run it on execution and switch the engine to recognition of the activation phrase. <br>  In onPartialResult, we are only interested in recognizing an activation phrase.  If we find it, we immediately start the process of recognizing the command.  Here is what it looks like: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">synchronized</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">startRecognition</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (mRecognizer == <span class="hljs-keyword"><span class="hljs-keyword">null</span></span> || COMMAND_SEARCH.equals(mRecognizer.getSearchName())) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; mRecognizer.cancel(); <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ToneGenerator(AudioManager.STREAM_MUSIC, ToneGenerator.MAX_VOLUME).startTone(ToneGenerator.TONE_CDMA_PIP, <span class="hljs-number"><span class="hljs-number">200</span></span>); post(<span class="hljs-number"><span class="hljs-number">400</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Runnable() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ mMicView.setBackgroundResource(R.drawable.background_big_mic_green); mRecognizer.startListening(COMMAND_SEARCH, <span class="hljs-number"><span class="hljs-number">3000</span></span>); Log.d(TAG, <span class="hljs-string"><span class="hljs-string">"Listen commands"</span></span>); post(<span class="hljs-number"><span class="hljs-number">4000</span></span>, mStopRecognitionCallback); } }); }</code> </pre><br>  Here we first play a small signal to alert the user that we heard him and are ready for his team.  At this time, the microphone should be turned off.  Therefore, we start the recognition after a short timeout (slightly longer than the signal duration, so as not to hear its echo).  A thread is also started, which will stop recognition if the user speaks for too long.  In this case, it is 3 seconds. <br><br><h4>  How to turn a recognized string into commands </h4><br>  Well, everything is already specific to a specific application.  In the case of the naked example, we simply pull out the device names from the line, look for the device we need and either change its state using an HTTP request to the smart home controller, or report its current state (as in the case of the thermostat).  This logic can be seen in the <a href="">Controller</a> class. <br><br><h4>  How to synthesize speech </h4><br>  Speech synthesis is the inverse operation of recognition.  Here is the opposite - you need to turn a line of text into speech, so that the user can hear it. <br>  In the case of a thermostat, we need to make our Android device speak the current temperature.  Using the <i>TextToSpeech</i> API <i>,</i> this is quite easy to do (thanks to Google for the beautiful female TTS for the Russian language): <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">speak</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String text)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">synchronized</span></span> (mSpeechQueue) { mRecognizer.stop(); mSpeechQueue.add(text); HashMap&lt;String, String&gt; params = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashMap&lt;String, String&gt;(<span class="hljs-number"><span class="hljs-number">2</span></span>); params.put(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, UUID.randomUUID().toString()); params.put(TextToSpeech.Engine.KEY_PARAM_STREAM, String.valueOf(AudioManager.STREAM_MUSIC)); params.put(TextToSpeech.Engine.KEY_FEATURE_NETWORK_SYNTHESIS, <span class="hljs-string"><span class="hljs-string">"true"</span></span>); mTextToSpeech.speak(text, TextToSpeech.QUEUE_ADD, params); } }</code> </pre><br><br>  I will say probably a commonplace, but <b>before the synthesis process it is necessary to turn off recognition</b> .  On some devices (for example, all samsung) in general it is not possible to simultaneously listen to the microphone and synthesize something. <br>  The end of speech synthesis (that is, the end of the process of speaking the text with a synthesizer) can be tracked in the listener: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> TextToSpeech.OnUtteranceCompletedListener mUtteranceCompletedListener = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> TextToSpeech.OnUtteranceCompletedListener() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onUtteranceCompleted</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String utteranceId)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">synchronized</span></span> (mSpeechQueue) { mSpeechQueue.poll(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (mSpeechQueue.isEmpty()) { mRecognizer.startListening(KWS_SEARCH); } } } };</code> </pre><br><br>  In it, we simply check if there is still something in the synthesis queue, and turn on the recognition of the activation phrase, if there is nothing else. <br><br><h4>  And it's all? </h4><br>  Yes!  As you can see, to quickly and accurately recognize speech directly on the device is not difficult, thanks to the presence of such wonderful projects as Pocketsphinx.  It provides a very convenient API that can be used in solving problems associated with the recognition of voice commands. <br><br>  In this example, we screwed the recognition to a completely coherent task - <i>voice control of smart home devices</i> .  Due to local recognition, we achieved a very high speed and minimized errors. <br>  It is clear that the same code can be used for other tasks related to voice.  It does not have to be exactly smart home. <br><br>  <i>All source codes, and also assembly of the application you can find <a href="https://github.com/Morfeusys/veravoice">in a repository on GitHub</a> .</i> <i><br></i>  <i>Also on my YouTube channel you can see some other voice control implementations, and not just smart home systems.</i> </div><p>Source: <a href="https://habr.com/ru/post/237589/">https://habr.com/ru/post/237589/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../237577/index.html">The evolution of IT-infrastructure of our retail - consistent "molting"</a></li>
<li><a href="../237579/index.html">How we disaccustomed outsourcing to throw the ball to the internal IT department</a></li>
<li><a href="../237581/index.html">Review of the most interesting materials on high performance (September 15-21, 2014)</a></li>
<li><a href="../237583/index.html">Review of the most interesting materials on data analysis and machine learning ‚Ññ14 (September 15 - 21, 2014)</a></li>
<li><a href="../237585/index.html">Semi-automatic incrementing of the project version when working with GIT in Visual Studio</a></li>
<li><a href="../237593/index.html">ThinkPads and Windows 8.x</a></li>
<li><a href="../237595/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ126 (September 15 - 21, 2014)</a></li>
<li><a href="../237599/index.html">Sol 752: a "live" panorama of Mars from the hills of Parampa</a></li>
<li><a href="../237601/index.html">How different privacy policies affect conversion: 4 A / B test results!</a></li>
<li><a href="../237603/index.html">The digest of interesting news and materials from the world of PHP No. 48 (September 7 - 21, 2014)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>