<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>You and Brad Pitt look like 99%</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We in the analytics department of the Okko online cinema like to automate as much as possible the calculations of the fees of the Alexander Nevsky fil...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>You and Brad Pitt look like 99%</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/bg/8z/-p/bg8z-pmvxneor2kulnu9tmg3qoy.jpeg" alt="Tomorrow on vacation"></p><br><p>  We in the analytics department of the <a href="https://okko.tv/">Okko</a> online cinema like to automate as much as possible the calculations of the fees of the Alexander Nevsky films, and in the time that has become free to learn new things and implement cool things that for some reason usually translate into bots for Telegram.  For example, before the start of the 2018 World Cup, we rolled out a bot to the working chat, which collected bets on the distribution of the final places, and after the finals, we calculated the results on a preconceived metric and determined the winners.  Croatia in the four did not put one. </p><br><p>  The recent free time from the compilation of the TOP-10 Russian comedies, we have devoted to the creation of a <a href="http://t.me/okkofacebot">bot</a> , which finds the celebrity to which the user is most like a person.  In the working chat, everyone appreciated the idea so much that we decided to make the bot publicly available.  In this article, we briefly recall the theory, tell you about the creation of our bot and how to do this yourself. </p><a name="habracut"></a><br><h1 id="nemnogo-teorii-v-osnovnom-v-kartinkah">  A bit of theory (mostly in pictures) </h1><br><p>  In detail about how the facial recognition systems are arranged, I told in <a href="https://habr.com/post/317798/">one of my previous articles</a> .  An interested reader can follow the link, and I will set out below only the main points. </p><br><p>  So, you have a photo, which may even show a face, and you want to know whose it is.  To do this, you need to perform 4 simple steps: </p><br><ol><li>  Select the rectangle bounding the face. </li><li>  Highlight key point faces. </li><li>  Align and trim the face. </li><li>  Convert a face image into some machine interpretable representation. </li><li>  Compare this view with others you have available. </li></ol><br><h3 id="vydelenie-lica">  Face highlighting </h3><br><p>  And although convolutional neural networks have recently learned to find faces in an image as well as classical methods, they are still inferior to classic <a href="http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf">HOG</a> in speed and ease of use. </p><br><p>  HOG - Histograms of Oriented Gradients.  To each pixel of the original image, this guy sets his gradient in correspondence - a vector in the direction of which the brightness of the pixels changes the most.  The advantage of this approach is that it does not matter the absolute brightness values ‚Äã‚Äãof the pixels, just their relationship is enough.  Therefore, both normal and darkened, and poorly lit, and a noisy face will be displayed in approximately the same gradient histogram. </p><br><p><img src="https://habrastorage.org/webt/ke/_h/b_/ke_hb_cyd3odkvkwmqb0soancka.png" alt="Histogram of gradients aimed face faces"></p><br><p> There is no need to count the gradient for each pixel; it suffices to calculate the average gradient for each small square <code>n</code> by <code>n</code> .  You can then walk along the received vector field with a certain detector with a window and determine for each window how likely a face is in it.  SVM, random forest, and anything else can act as a detector. </p><br><p><img src="https://habrastorage.org/webt/mz/hk/2y/mzhk2ycaurneywpy32a0linnm3o.png" alt="Face detection"></p><br><h3 id="vydelenie-klyuchevyh-tochek">  Highlight key points </h3><br><p><img src="https://habrastorage.org/webt/wd/bi/dc/wdbidcix45fpf74iglc7f0f1rpg.png" alt="Key points of the face of the face"></p><br><p>  Key points are points that help identify a person in space.  Weak and insecure date, the scientists usually need 68 key points, and in particularly neglected cases, and even more.  But the normal and self-confident boys, who earn 300k per second, always had five: the inner and outer corners of the eyes and nose. </p><br><p><img src="https://habrastorage.org/webt/6t/tb/-8/6ttb-8bq0ugffanbs0qcrihy2a4.jpeg" alt="Old meme"></p><br><p>  You can extract such points, for example, by a <a href="http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf">cascade of regressors</a> . </p><br><h3 id="vyravnivanie-lica">  Face alignment </h3><br><p>  Kleil childhood application?  Here everything is exactly the same: you build an affine transformation that takes three arbitrary points to their standard positions.  The nose can be left as it is, and for the eyes to count their centers - three points are ready. </p><br><p><img src="https://habrastorage.org/webt/ms/3q/s7/ms3qs7hagupsaooas-eqrjjmqpy.png" alt="Rotate the face of the face"></p><br><h3 id="preobrazovanie-izobrazheniya-lica-v-vektor">  Convert a face image to a vector </h3><br><p><img src="https://habrastorage.org/webt/ab/8w/jo/ab8wjody73ybfs_opnftpipbcz0.png" alt="Less old meme"></p><br><p>  Three years have passed since the publication of the article about <a href="https://arxiv.org/abs/1503.03832">FaceNet</a> , during which time many interesting learning schemes and loss functions have appeared, but it is she who dominates among the available OpenSource solutions.  Apparently, the whole thing in a combination of ease of understanding, implementation and decent results achieved.  Thanks at least for the fact that the architecture in these three years has been changed to ResNet. </p><br><p><img src="https://habrastorage.org/webt/af/pt/cx/afptcx5ixcu2r0_mjkckckpt2zo.jpeg" alt="New meme"></p><br><p>  FaceNet learns from triples of examples: (anchor, positive, negative).  Anchor and positive examples belong to one person, negative is chosen as the face of another person, which for some reason is located too close to the first network.  The loss function is designed in such a way as to correct this misunderstanding, bring together the necessary examples and move away from them unnecessary. </p><br><p><img src="https://habrastorage.org/webt/tp/yf/sw/tpyfswhgnyco4w_0ap3zy8i5zhs.png" alt="GucciNet"></p><br><p><img src="https://habrastorage.org/webt/gj/fi/zq/gjfizqzcwjybnypbv-ugovr5hl0.png" alt="Faces of the person and Dmitry Malikov"></p><br><p>  The output of the last layer of the network is called embedding - a representative representation of a face in a certain space of small dimension (usually 128-dimensional). </p><br><h3 id="sravnenie-lic">  Comparison of individuals </h3><br><p>  The beauty of well-trained embeddings is that the faces of one person are displayed in some small neighborhood of space, which is distant from the embeds of the faces of other people.  So, for this space, you can enter a measure of similarity, the inverse distance: Euclidean or cosine, depending on what distance the network was taught. </p><br><p><img src="https://habrastorage.org/webt/pn/u8/ba/pnu8barwdzvdryma24yezil7kvo.jpeg" alt="A completely artificial example of embedding"></p><br><p>  Thus, we need to build in advance embedings for all the people, among whom a search will be made, and then, for each query, find the nearest vector among them.  Or, in another way, to solve the problem of finding <code>k</code> nearest neighbors, where <code>k</code> can be equal to one, or maybe not, if we want to use some more advanced business logic.  The person who owns the result vector is the most similar to the request person. </p><br><p><img src="https://habrastorage.org/webt/6f/uz/nx/6fuznxdig3uiw1mjuv1eezx5h3u.jpeg" alt="Facial similarity of face on face not face"></p><br><h3 id="kakuyu-biblioteku-ispolzovat">  What library to use? </h3><br><p>  The choice of open libraries that implement various parts of the pipeline is great.  <code>dlib</code> and <code>OpenCV</code> are able to <code>dlib</code> faces and key points, and pre-trained versions of networks can be found for any large neural network framework.  There is a project <a href="https://cmusatyalab.github.io/openface/">OpenFace</a> , where you can choose the architecture for your requirements of speed and quality.  But only one library allows you to implement all 5 points of face recognition in the calls of three high-level functions: <code>dlib</code> .  At the same time, it is written in modern C ++, uses BLAS, has a Python wrapper, does not require a GPU, and works quite quickly on the CPU.  Our choice fell on her. </p><br><h1 id="delaem-sobstvennogo-bota">  We make our own bot </h1><br><p>  This section has already been described in literally every guide to creating bots, but once we write the same, we will have to repeat it.  We write <a href="http://t.me/BotFather">@BotFather</a> and ask him for a token for our new bot. </p><br><p><img src="https://habrastorage.org/webt/um/qe/ew/umqeewdk64wtealh1ldudqsv0m8.png" alt="Blurred token xs why"></p><br><p>  The token looks something like this: <code>643075690:AAFC8ola8WRdhGbJtzjmkOhne1FGfu1BFg</code> .  It is required for authorization with each request to the Telegram bots API. </p><br><p>  I hope no one at this stage will have any thoughts when choosing a programming language.  Of course, you need to write on Haskell.  Let's start with the main module. </p><br><pre> <code class="haskell hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> System.Process main :: IO () main = do (<span class="hljs-title"><span class="hljs-title">_</span></span>, <span class="hljs-title"><span class="hljs-title">_</span></span>, <span class="hljs-title"><span class="hljs-title">_</span></span>, <span class="hljs-title"><span class="hljs-title">handle</span></span>) &lt;- createProcess (<span class="hljs-title"><span class="hljs-title">shell</span></span> "<span class="hljs-title"><span class="hljs-title">python</span></span> <span class="hljs-title"><span class="hljs-title">bot</span></span>.<span class="hljs-title"><span class="hljs-title">py</span></span>") _ &lt;- waitForProcess handle putStrLn "Done!"</code> </pre> <br><p>  As can be seen from the code, in the future we will use a special <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a> for writing telegram bots.  The code on this DSL is written in separate files.  Install the domain language and everything you need. </p><br><pre> <code class="bash hljs">python -m venv .env <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> .env/bin/activate pip install python-telegram-bot</code> </pre> <br><p>  <code>python-telegram-bot</code> is currently the most convenient framework for creating bots.  It is easy to learn, flexible, scalable, supports multithreading.  Unfortunately, at the moment there is not a single normal asynchronous framework, and instead of the divine korutin have to use the ancient threads. </p><br><p><img src="https://habrastorage.org/webt/t2/8b/qv/t28bqvhxxznqmzsobr4hjmuxlta.jpeg" alt="asyncio is my god"></p><br><p>  Starting to write a bot with <code>python-telegram-bot</code> very simple.  Add the following code to <code>bot.py</code> </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Updater <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MessageHandler, Filters <span class="hljs-comment"><span class="hljs-comment">#      TOKEN = '&lt;TOKEN&gt;' def echo(bot, update): bot.send_message(chat_id=update.message.chat_id, text=update.message.text) updater = Updater(token=TOKEN) dispatcher = updater.dispatcher echo_handler = MessageHandler(Filters.text, echo) dispatcher.add_handler(echo_handler)</span></span></code> </pre> <br><p>  Run the bot.  For debugging purposes, this can be done with the <code>python bot.py</code> , without running the Haskell code. </p><br><p>  Such a simple bot is able to maintain a minimal conversation, and, therefore, a front-end developer can work easily. </p><br><p><img src="https://habrastorage.org/webt/xs/pk/sm/xspksm1d8ehnslmqjsj33dzyekm.png" alt="Typical dialog with front-end developer"></p><br><p>  But the frontend of developers is already too much, so let's kill it as soon as possible and get down to implementing the main functionality.  For the sake of simplicity, our bot will only respond to messages containing photos and ignore any others.  Change the code to the next. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Updater <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MessageHandler, Filters <span class="hljs-comment"><span class="hljs-comment">#      TOKEN = '&lt;TOKEN&gt;' def handle_photo(bot, update): bot.send_message(chat_id=update.message.chat_id, text='nice') updater = Updater(token=TOKEN) dispatcher = updater.dispatcher photo_handler = MessageHandler(Filters.photo, handle_photo) dispatcher.add_handler(photo_handler) updater.start_polling() updater.idle()</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/-8/1k/hq/-81khq5z9redcz29_ut7sunfrpg.png" alt="Already not frontend developer"></p><br><p>  When the picture gets on the Telegram server, it is automatically adjusted to several pre-defined sizes.  A bot in turn can download an image of any size from those contained in the <code>message.photo</code> list sorted in ascending order.  The easiest option: take the largest image.  Of course, in the product environment you need to think about the load on the network and the load time and choose the image of the minimum suitable size.  Add an image download code to the beginning of the <code>handle_photo</code> function. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io</code> </pre> <br><pre> <code class="python hljs">message = update.message photo = message.photo[~<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.BytesIO() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> fd: file_id = bot.get_file(photo.file_id) file_id.download(out=fd) fd.seek(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  The image is downloaded and stored in memory.  For its interpretation and representation in the form of a matrix of pixel intensity, we will use the <code>Pillow</code> and <code>numpy</code> libraries. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><p>  The following code must be added to the <code>with</code> block. </p><br><pre> <code class="python hljs">image = Image.open(fd) image.load() image = np.asarray(image)</code> </pre> <br><p>  It's time to dlib.  Outside the function, create a face detector. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> dlib</code> </pre> <br><pre> <code class="python hljs">face_detector = dlib.get_frontal_face_detector()</code> </pre> <br><p>  And inside the function we use it. </p><br><pre> <code class="python hljs">face_detects = face_detector(image, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p>  The second parameter of the function is the increase that must be applied before attempting to detect faces.  The larger it is, the smaller and more complex faces the detector will be able to detect, but the longer it will work.  <code>face_detects</code> - a list of persons, sorted in descending order of detector confidence that there is a face in front of it.  In a real application, you will most likely want to apply some logic for choosing the main person, and in the learning example we will limit ourselves to choosing the first one. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> face_detects: bot.send_message(chat_id=update.message.chat_id, text=<span class="hljs-string"><span class="hljs-string">'no faces'</span></span>) face = face_detects[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  We proceed to the next stage - the search for key points.  We download the <a href="">trained model</a> and we take out its loading out of function limits. </p><br><pre> <code class="python hljs">shape_predictor = dlib.shape_predictor(<span class="hljs-string"><span class="hljs-string">'path/to/shape_predictor_5_face_landmarks.dat'</span></span>)</code> </pre> <br><p>  Find key points. </p><br><pre> <code class="python hljs">landmarks = shape_predictor(image, face)</code> </pre> <br><p>  It remains for the small: align the face, drive it through ResNet and get 128-dimensional embedding.  Fortunately, dlib allows you to do all this in one call.  You only need to download the <a href="">pre-trained model</a> . </p><br><pre> <code class="python hljs">face_recognition_model = dlib.face_recognition_model_v1(<span class="hljs-string"><span class="hljs-string">'path/to/dlib_face_recognition_resnet_model_v1.dat'</span></span>)</code> </pre> <br><pre> <code class="python hljs">embedding = face_recognition_model.compute_face_descriptor(image, landmarks) embedding = np.asarray(embedding)</code> </pre> <br><p>  Just see what a wonderful time we live in.  The entire complexity of convolutional neural networks, the method of support vectors and affine transformations applied to face recognition, is encapsulated in three library calls. </p><br><p>  Since we are not yet able to do anything meaningful, let's return to the user the average value of embedding, multiplied by a thousand. </p><br><pre> <code class="python hljs">bot.send_message( chat_id=update.message.chat_id, text=<span class="hljs-string"><span class="hljs-string">f'yours embedding mean: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{embedding.mean() * </span></span><span class="hljs-number"><span class="hljs-string"><span class="hljs-subst"><span class="hljs-number">1e3</span></span></span></span><span class="hljs-string"><span class="hljs-subst">:</span></span><span class="hljs-number"><span class="hljs-string"><span class="hljs-subst"><span class="hljs-number">.2</span></span></span></span><span class="hljs-string"><span class="hljs-subst">f}</span></span></span><span class="hljs-string">'</span></span> )</code> </pre> <br><p><img src="https://habrastorage.org/webt/ud/av/o6/udavo6i5srwrl93jbopenn84tae.png" alt="I don't know what I'm doing"></p><br><p>  In order for our bot to be able to identify which celebrities look like users, we now need to find at least one photo of each celebrity, build an embedding on it and save it somewhere.  We will add 10 celebrities to our training bot, finding their photos with our hands and putting them in the <code>photos</code> directory.  This is how it should look like: </p><br><p><img src="https://habrastorage.org/webt/yz/rd/1o/yzrd1ockvqezvybwzo-yulsivqq.png" alt="Look, I didn‚Äôt have enough money for MacBook"></p><br><p>  If you want to have a million celebrities in the database, everything will look exactly the same, only larger files and you can hardly look for them with your hands.  Now we will create the <code>build_embeddings.py</code> utility, using the <code>dlib</code> calls already known to us and save the embeddings of celebrities together with their names in binary format. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> dlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image face_detector = dlib.get_frontal_face_detector() shape_predictor = dlib.shape_predictor(<span class="hljs-string"><span class="hljs-string">'assets/shape_predictor_5_face_landmarks.dat'</span></span>) face_recognition_model = dlib.face_recognition_model_v1(<span class="hljs-string"><span class="hljs-string">'assets/dlib_face_recognition_resnet_model_v1.dat'</span></span>) fs = os.listdir(<span class="hljs-string"><span class="hljs-string">'photos'</span></span>) es = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> fs: print(f) image = np.asarray(Image.open(os.path.join(<span class="hljs-string"><span class="hljs-string">'photos'</span></span>, f))) face_detects = face_detector(image, <span class="hljs-number"><span class="hljs-number">1</span></span>) face = face_detects[<span class="hljs-number"><span class="hljs-number">0</span></span>] landmarks = shape_predictor(image, face) embedding = face_recognition_model.compute_face_descriptor(image, landmarks, num_jitters=<span class="hljs-number"><span class="hljs-number">10</span></span>) embedding = np.asarray(embedding) name, _ = os.path.splitext(f) es.append((name, embedding)) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'assets/embeddings.pickle'</span></span>, <span class="hljs-string"><span class="hljs-string">'wb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: pickle.dump(es, f)</code> </pre> <br><p>  Let's add embeddings to our bot code. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'assets/embeddings.pickle'</span></span>, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: star_embeddings = pickle.load(f)</code> </pre> <br><p>  And by the exhaustive search method, we will find who our user still looks like. </p><br><pre> <code class="python hljs">ds = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> name, emb <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> star_embeddings: distance = np.linalg.norm(embedding - emb) ds.append((name, distance)) best_match, best_distance = min(ds, key=itemgetter(<span class="hljs-number"><span class="hljs-number">1</span></span>)) bot.send_message( chat_id=update.message.chat_id, text=<span class="hljs-string"><span class="hljs-string">f'your look exactly like *</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{best_match}</span></span></span><span class="hljs-string">*'</span></span>, parse_mode=<span class="hljs-string"><span class="hljs-string">'Markdown'</span></span> )</code> </pre> <br><p>  Please note that as a distance we use the Euclidean distance, since  the network in dlib was trained precisely by it. </p><br><p><img src="https://habrastorage.org/webt/yd/fl/wi/ydflwigundswx6_qbctjir_itge.png" alt="I was disappointed in the article"></p><br><p>  That's all, congratulations!  We have created the simplest bot that can determine which celebrity the user looks like.  It remains to find more photos, add branding, scalability, a pinch of logging and everything can be produced in production.  All these topics are too voluminous to tell in detail about them with huge code listings, so I‚Äôll just explain the main points in a question-answer format in the next section. </p><br><p>  The full code for the training bot is available on <a href="https://github.com/meownoid/simplest-face-similarity-bot">github</a> . </p><br><h1 id="rasskazyvaem-pro-nashego-bota">  We tell about our bot </h1><br><h3 id="skolko-u-vas-v-baze-znamenitostey-gde-vy-ih-nashli">  How many celebrities do you have?  Where did you find them? </h3><br><p>  The most logical decision when creating a bot seemed to take data on celebrities from our internal content database.  It is in the graph format stores films and all entities that are associated with films, including actors and directors.  For each person we know her name, login and password from iCloud, related movies and alias, which can be used to generate a link to the site.  After cleaning and extracting only the necessary information, a <code>json</code> file of the following content remains: </p><br><pre> <code class="json hljs">[ { <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"alias"</span></span>: <span class="hljs-string"><span class="hljs-string">"tilda-swinton"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"role"</span></span>: <span class="hljs-string"><span class="hljs-string">"actor"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"n_movies"</span></span>: <span class="hljs-number"><span class="hljs-number">14</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"alias"</span></span>: <span class="hljs-string"><span class="hljs-string">"michael-shannon"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"role"</span></span>: <span class="hljs-string"><span class="hljs-string">"actor"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"n_movies"</span></span>: <span class="hljs-number"><span class="hljs-number">22</span></span> }, ... ]</code> </pre> <br><p>  There are <strong>22,000</strong> such entries in the catalog.  By the way, not a directory, but a directory. </p><br><h3 id="gde-nayti-fotografii-dlya-vseh-etih-lyudey">  Where to find photos for all these people? </h3><br><p><img src="https://habrastorage.org/webt/vj/tx/74/vjtx74feo5erwuwrhmd85ongcti.jpeg" alt="I wonder if I will be allowed to leave this picture."></p><br><p>  Well, you know, <em>here and there</em> .  There is, for example, an <a href="https://github.com/hardikvasa/google-images-download">excellent library</a> that allows you to upload pictures of the query results from Google.  22 thousand people - not so much, using 56 streams, we managed to download photos for them in less than an hour. </p><br><p>  Among the downloaded photos, you need to discard broken, noisy, photos in the wrong format.  Then leave only those where there are faces and where these faces satisfy certain conditions: the minimum distance between the eyes, the inclination of the head.  All this leaves us with <strong>12,000</strong> photos. </p><br><p>  Of the 12 thousand celebrities, users currently only found 2. That is, there are approximately 8 thousand celebrities who are not yet similar.  Do not leave it just like that!  Open telegrams and find them all. </p><br><h3 id="kak-opredelit-procent-shozhesti-dlya-evklidovoy-distancii">  How to determine the percentage of similarity for the Euclidean distance? </h3><br><p>  Great question!  Indeed, the Euclidean distance, in contrast to the cosine, is not limited from above.  Therefore, a reasonable question arises, how to show the user something more meaningful than "Congratulations, the distance between your embedding and the embedding of Angelina Jolie is 0.27635462738"?  One of our team members proposed the following simple and ingenious solution.  If you build the distribution of distances between embeddings, it will be normal.  This means that it is possible to calculate the average and standard deviation for it, and then for each user, according to these parameters, <em>how many percent of people are less similar to their celebrities than he is</em> .  This is equivalent to integrating the probability density function from <code>d</code> to plus infinity, where <code>d</code> is the distance between the embeddings of the user and the celebrity. </p><br><p><img src="https://habrastorage.org/webt/fh/yc/4r/fhyc4r87otryweg9v-xznackhfq.png" alt="This is not seaborn"></p><br><p>  Here is the exact function we use: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_transform_dist_to_sim</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, dist)</span></span></span><span class="hljs-function">:</span></span> p = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * (<span class="hljs-number"><span class="hljs-number">1</span></span> + erf((dist - self._dist_mean) / (self._dist_std * <span class="hljs-number"><span class="hljs-number">1.4142135623730951</span></span>))) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> max(min(<span class="hljs-number"><span class="hljs-number">1</span></span> - p, <span class="hljs-number"><span class="hljs-number">1.0</span></span>), self._min_similarity)</code> </pre> <br><h3 id="neuzheli-nuzhno-perebirat-spisok-vseh-embedingov-chtoby-nayti-sovpadenie">  Is it really necessary to go through the list of all embedings to find a match? </h3><br><p>  Of course not, this is not optimal and takes a lot of time.  The easiest way to optimize calculations is to use matrix operations.  Instead of subtracting the vectors from one another, you can compose a matrix from them and subtract a vector from the matrix, and then calculate the L2 norm in rows. </p><br><pre> <code class="python hljs">scores = np.linalg.norm(emb - embeddings, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) best_idx = scores.argmax()</code> </pre> <br><p>  This already gives a huge performance boost, but it turns out you can be even faster.  The search can be greatly accelerated by losing a bit of accuracy with the <a href="https://github.com/nmslib/nmslib">nmslib</a> library.  It uses the <a href="https://arxiv.org/abs/1603.09320">HNSW</a> method for an approximate search for <code>k</code> nearest neighbors.  For all existing vectors should be built so-called index, which then will be searched.  You can create and save to disk an index for the Euclidean distance as follows: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nmslib index = nmslib.init(method=<span class="hljs-string"><span class="hljs-string">'hnsw'</span></span>, space=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, data_type=nmslib.DataType.DENSE_VECTOR) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx, emb <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(embeddings): index.addDataPoint(idx, emb) index_time_params = { <span class="hljs-string"><span class="hljs-string">'indexThreadQty'</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-string"><span class="hljs-string">'skip_optimized_index'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">'post'</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'delaunay_type'</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'M'</span></span>: <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-string"><span class="hljs-string">'efConstruction'</span></span>: <span class="hljs-number"><span class="hljs-number">2000</span></span> } index.createIndex(index_time_params, print_progress=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) index.saveIndex(<span class="hljs-string"><span class="hljs-string">'./assets/embeddings.bin'</span></span>)</code> </pre> <br><p>  The parameters <code>M</code> and <code>efConstruction</code> are described in detail in the <a href="">documentation</a> and are selected experimentally based on the required accuracy, the time to build the index, and the search speed.  Before using the index must be loaded: </p><br><pre> <code class="python hljs">index = nmslib.init(method=<span class="hljs-string"><span class="hljs-string">'hnsw'</span></span>, space=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, data_type=nmslib.DataType.DENSE_VECTOR) index.loadIndex(<span class="hljs-string"><span class="hljs-string">'./assets/embeddings.bin'</span></span>) query_time_params = {<span class="hljs-string"><span class="hljs-string">'efSearch'</span></span>: <span class="hljs-number"><span class="hljs-number">400</span></span>} index.setQueryTimeParams(query_time_params)</code> </pre> <br><p>  The <code>efSearch</code> parameter affects the accuracy and speed of requests and may not coincide with <code>efConstruction</code> .  Now you can make requests. </p><br><pre> <code class="python hljs">ids, dists = index.knnQuery(embedding, k=<span class="hljs-number"><span class="hljs-number">1</span></span>) best_dx = ids[<span class="hljs-number"><span class="hljs-number">0</span></span>] best_dist = dists[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  In our case, <code>nmslib</code> is 20 times faster than the vectorized linear version, and one request is performed on average <code>0.005</code> seconds. </p><br><h3 id="kak-sdelat-moego-bota-gotovym-k-prodakshenu">  How to make my bot ready for production? </h3><br><h5 id="1-asinhronnost">  1. Asynchrony </h5><br><p>  First, you need to make the <code>handle_photo</code> function asynchronous.  As I said before, <code>python-telegram-bot</code> suggests using multithreading for this and implements a convenient decorator. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext.dispatcher <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> run_async @run_async <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">handle_photo</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bot, update)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><p>  Now the framework will start your handler in a separate thread in its pool.  The size of the pool is set when creating the <code>Updater</code> .  "But in python there is no multithreading!"  the most impatient of you have already exclaimed.  And this is not entirely true.  Because of the <a href="https://wiki.python.org/moin/GlobalInterpreterLock">GIL, the</a> usual Python code really cannot be executed in parallel, but the GIL is released to wait for all IO operations, and it can also be released by libraries that use C extensions. </p><br><p>  Now analyze our <code>handle_photo</code> function: it only consists of waiting for IO operations (loading a photo, sending a response, reading a photo from disk, etc.) and calling functions from the <code>numpy</code> , <code>nmslib</code> and <code>Pillow</code> libraries. </p><br><p>  I did not mention <code>dlib</code> for a reason.  The library that calls the native code is not required to release GIL, and <code>dlib</code> this right.  She does not need this lock, she just does not let it go.  The author <a href="https://github.com/davisking/dlib/issues/1403">says</a> that he will gladly accept the appropriate pull request, but I'm too lazy. </p><br><h5 id="2-mnogoprocessnost">  2. Multiprocessing </h5><br><p>  The easiest way to deal with <code>dlib</code> is to encapsulate the model into a separate entity and run it in a separate process.  And better in the process pool. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_worker_initialize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model model = Model(config) model.load_state() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_worker_do</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model.process_image(image) pool = multiprocessing.Pool(<span class="hljs-number"><span class="hljs-number">8</span></span>, initializer=_worker_initialize, initargs=(config,))</code> </pre> <br><pre> <code class="python hljs">result = pool.apply(_worker_do, (image,))</code> </pre> <br><h5 id="3-zhelezo">  3. Iron </h5><br><p>  If your bot needs to constantly read photos from the disk, make sure that this disk is an SSD.  Or even mount them into RAM.  Also important is the ping to the telegraph servers and the quality of the channel. </p><br><h5 id="4-flood-control">  4. Flood control </h5><br><p>  Telegrams do not allow bots to send more than 30 messages per second.  If your bot is popular and a lot of people use it at the same time, then it is very easy to catch the ban for a few seconds, which will result in frustration from waiting for many users.  To solve this problem, <code>python-telegram-bot</code> offers us a queue that is capable of not sending more than a specified limit of messages per second, maintaining an equal interval between sending. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext.messagequeue <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MessageQueue</code> </pre> <br><p>  To use it, you need to define your own bot and replace it when creating a <code>Updater</code> . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.utils.promise <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Promise <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MQBot</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Bot)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super().__init__(*args, **kwargs) self._message_queue = MessageQueue( all_burst_limit=<span class="hljs-number"><span class="hljs-number">30</span></span>, all_time_limit_ms=<span class="hljs-number"><span class="hljs-number">1000</span></span> ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__del__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: self._message_queue.stop() <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: super().__del__() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send_message</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> is_group = kwargs.get(<span class="hljs-string"><span class="hljs-string">'chat_id'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>) &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self._message_queue(Promise(super().send_message, args, kwargs), is_group)</code> </pre> <br><pre> <code class="python hljs">bot = MQBot(token=TOKEN) updater = Updater(bot=bot)</code> </pre> <br><h5 id="5-web-hooks">  5. Web hooks </h5><br><p>  In the product environment, Web Hooks should be used instead of Long Polling as a way to get updates from the Telegram servers.  What it generally is and how to use it can be read <a href="https://github.com/python-telegram-bot/python-telegram-bot/wiki/Webhooks">here</a> . </p><br><h5 id="6-melochi">  6. Trivia </h5><br><p>  During communication with the telegraph server, tons of <code>json</code> messages are read every second.    ,      <a href="https://github.com/esnme/ultrajson">ultrajson</a> . </p><br><p>          IO-:    ,  ,  .      ,         . </p><br><h5 id="6-analitika"> 6.  </h5><br><p>   ,   .        ,   ,  ,       .        ,        . </p><br><p> , ,      BI-tool <a href="https://www.splunk.com/">Splunk</a>     . </p><br><p><img src="https://habrastorage.org/webt/oh/8e/ve/oh8eve_hczr4pahrzum56fonxxg.jpeg" alt="  (   )"></p><br><p>   ,         .     ,                       . </p><br><p>    ,         .      ,    : <a href="http://t.me/OkkoFaceBot">@OkkoFaceBot</a> . </p><br><p><del>        </del> ,     . ,      . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/417329/">https://habr.com/ru/post/417329/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../417319/index.html">Systems in the case or What is actually under the cover of the microprocessor case</a></li>
<li><a href="../417321/index.html">How do we look for online course teachers among developers?</a></li>
<li><a href="../417323/index.html">Problems of ensuring 100% availability of the project</a></li>
<li><a href="../417325/index.html">Open Day at Netology, Data Science theme</a></li>
<li><a href="../417327/index.html">Budget monitoring of temperature in the server room (MP707 + nettop with Linux + PRTG)</a></li>
<li><a href="../417331/index.html">Security Week 26: Specter updated, now tastefully written</a></li>
<li><a href="../417333/index.html">Social rating</a></li>
<li><a href="../417337/index.html">Principles of operation and application features of atomic swap</a></li>
<li><a href="../417339/index.html">3DTouch - Scales on the iPhone: Completion</a></li>
<li><a href="../417345/index.html">Threat Hunting with the new Cisco Visibility solution</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>