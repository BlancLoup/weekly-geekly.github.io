<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neuroculture Part 0. Or neuro-free chicken coop</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Or how to smoke in the neural network? 

 The chicken laid a testicle. The process itself looks terrible. The result is edible. Mass genocide of chick...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neuroculture Part 0. Or neuro-free chicken coop</h1><div class="post__text post__text-html js-mediator-article"><h3>  Or how to smoke in the neural network? </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/094/465/a05/094465a0553b8ee70153ac1aa3e5fb49.jpg" alt="image"><br>  <i>The chicken laid a testicle.</i>  <i>The process itself looks terrible.</i>  <i>The result is edible.</i>  <i>Mass genocide of chickens.</i> <br><br>  <b>This article will describe:</b> <br><br><ol><li>  Where, how and why you can get a little quality self-education in the field of work with neural networks for FREE, NOW and NOT FAST; </li><li>  The logic of recursion will be described and books on the topic will be recommended; </li><li>  A list of basic terms will be described that need to be broken down into levels 2-3 abstraction; </li><li>  Ipynb-notebook, which contains the necessary links and basic approaches, will be shown; </li><li>  There will be some peculiar sarcastic humor; </li><li>  Some simple patterns that you will encounter when working with neural networks will be described; </li></ol>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>Articles about neurocooler</b> <br><div class="spoiler">  <b class="spoiler_title">Spoiler header</b> <div class="spoiler_text"><ol><li>  <b><a href="https://habrahabr.ru/post/328138/">Intro</a> to learning about neural networks</b> </li><li>  <b><a href="https://habrahabr.ru/post/327978/">Iron, software and config</a> for monitoring chickens</b> </li><li>  <a href="https://habrahabr.ru/post/328940/"><b>A bot</b></a> that posts events from the life of chickens - without a neural network </li><li>  Dataset markup </li><li>  A working <a href="https://habrahabr.ru/post/330738/"><b>model</b></a> for the recognition of chickens in the hen house </li><li>  The result - a working bot that recognizes chickens in the hen house </li></ol><br></div></div><a name="habracut"></a><br><cut><br><br><h3>  Philosophical introduction begins here. </h3><br>  Where to begin? <br><br><div class="spoiler">  <b class="spoiler_title">Spoiler header</b> <div class="spoiler_text">  <b>You can start by saying</b> that my girlfriend wrote an excellent <a href="http://spark-in.me/post/neuro-chicken-coop">article</a> about her journey and the installation of a chicken observation system in the hen house.  What for?  Because the applied task motivates much more than the tasks on Kaggle, where everything is also far from ideal (faces in 1/2 tasks, winning architectures are stacks of 15 models, overfitting to search for unscalable regularities, etc., etc.).  My task is to write neural networks and python code that will distinguish chickens, and, perhaps, log events in the life of chickens into our favorite <a href="http://spark-in.me/post/postgresql-for-dummies">DBMS</a> .  In the process, you can learn a lot of interesting things and, perhaps, even change your life by sharing your mini-experiences.  <b>And nice, and useful and fun.</b> <br><br>  <b>You can also start by saying</b> that, in principle, there is now a new branch of the ‚Äúbubble‚Äù in the technology market - everyone abruptly ran ‚Äúinto AI‚Äù.  Previously, everyone fled to IT, online, to Bigdat, to Skolkovo, to AR / VR.  If you sit in the thematic Russian chats, then there people usually either write everything from scratch to { <b>insert their exotic language</b> } or make one-time chat bots, mastering the means of emerging corporations.  But if you follow <a href="http://spark-in.me/post/%2520epistemic%2520responsibility">such</a> principles in your self-education, then you need to learn from ardent fans of their work, who do what they do, <b>not for profit, but for the sake of beauty</b> . <br><br>  And then an unknown person came to help me, who inserted a line into my <a href="http://goo.gl/5VGU5A">file</a> , where I collected educational utilities in the field of work with data.  Surprisingly, these <a href="http://www.fast.ai/">people</a> (fast.ai is a link someone put in) did a tremendous job of promoting and learning even from scratch, following the principle of <b>inclusiveness and integrity of education</b> against <b>exclusivity and the principle of the ivory tower</b> .  But about everything in order. <br><img src="https://habrastorage.org/getpro/habr/post_images/93c/f8d/fde/93cf8dfdee5e7f360c3aff8aa150eb12.png" alt="image"><br>  <i>Approach to education in a nutshell.</i> <i><br></i> <br><iframe width="560" height="315" src="https://www.youtube.com/embed/kzt3-FHdAeM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>The authors themselves will tell better than me.</i> <br><br>  I saw once in how in the ods chat (if you know what it is, you will understand) a team was formed that ranked second in the satellite image recognition competition, but the total number of man-hours needed for such a performance does not motivate to participate in such contests, taking into account non-ideality of the world.  Also, in principle, the ratio of the remuneration of researchers to the total price of the competition does not inspire enthusiasm. <br><br>  Therefore, all of the following is done for the neurocooler and only for him. <br><br>  Just in case, I‚Äôll clarify that my tasks are NOT included: <br><div class="spoiler">  <b class="spoiler_title">Very thick layer of sarcasm</b> <div class="spoiler_text"><ul><li>  Write a course to then sell the leads of its young graduates in Mail.ru xD; </li><li>  To write about how I like Caffe vs. Theano or Tensorflow - all this does not make a difference to an industrial professional level, if you are not a researcher in this field with experience and do not write scientific articles; </li><li>  Write neural networks from scratch to {your exotic language}; </li><li>  Sell ‚Äã‚Äãyou something for money (only ideas and for free); </li></ul><br></div></div><br><br>  <b>I want to share wonderful things and attach the maximum number of people to them, giving the simplest and widest possible description of the path that worked for me.</b> <br><br></div></div><br><h3>  The philosophical introduction ends here. </h3><br><h4>  Description of how to learn how to train neural networks </h4><br>  <b>TLDR (in install / learn order from easy to hard)</b> <br><br>  If you want to train neural networks efficiently and modernly for an applied purpose (rather than rewrite everything to {X} or build a PC with 10 video cards), here‚Äôs a short and very recursive guide: <br><br><div class="spoiler">  <b class="spoiler_title">List here</b> <div class="spoiler_text"><ul><li>  1. Learn at least the basic concepts: <ol><li>  Linear algebra.  <a href="https://www.youtube.com/playlist%3Flist%3DPLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Loop</a> intro video.  Start at least with them; </li><li>  Mathematical analysis.  Introductory video <a href="https://www.youtube.com/playlist%3Flist%3DPLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">loop</a> ; </li><li>  Read about gradient descent.  Here is an <a href="http://sebastianruder.com/optimizing-gradient-descent/">overview of the</a> methods and here is a <a href="https://youtu.be/V2h3IOBDvrA%3Ft%3D703">visualization</a> .  You will find the rest yourself in the courses; </li></ol></li><li>  2. If you do not know about anything from the list at all, be prepared to invest 200-300 hours of your time.  If only neural networks and / or python - then 50-100 hours; </li><li>  3. Get yourself Ubuntu or its equivalent (long live the comments in the "no tru" style).  My brief overview <a href="http://spark-in.me/post/ubuntu-wot-girlfriend">guide</a> (the Internet will help to find more detailed technical guides).  Of course, you can also pervert through virtualka, dockers, Mac, etc. and so on; </li><li>  4. Set yourself the third python (usually already out of the box, 2017).  It is the third.  But it is better to say it again.  Do not try to change the system python in Linux - everything will break; </li><li>  5.If you are not very familiar with the python, then (everything, again, is googled): <ol><li>  The easiest and free source of the ‚Äúbase‚Äù level and free (no courses for 30-50k rubles, then to go to work as an instructor for the same courses for 30k rubles, when the average salary is allegedly 100k rubles); </li><li>  The ideal recursion entry <a href="https://ru.coursera.org/learn/python-data-analysis">point</a> for using python to work with data; </li></ol></li><li>  6. Put yourself a jupyter <a href="http://jupyter.org/install.html">notebook</a> and this <a href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions">extension</a> ( <b>you need code folding</b> ).  Extremely shortens work time.  <b>True</b> ; </li><li>  7. Buy yourself a video card (now it is more profitable to buy than to rent - the beginning of 2017): <ol><li>  What I collected in 1 <a href="https://t.me/snakers4/735">post</a> on the channel; </li><li>  The best <a href="http://timdettmers.com/category/hardware/">post</a> about iron; </li><li>  The best <a href="http://forums.fast.ai/t/making-your-own-server/174/184">thread</a> about setting up software and assembly; </li><li>  My <a href="https://t.me/snakers4/702">post</a> with links and configs; </li></ol></li><li> 8. The best educational (FREE) resources: <ol><li>  <a href="http://www.fast.ai/">www.fast.ai</a> is the entry <a href="http://www.fast.ai/">point for</a> recursion.  There is a lot of crazy information in a blog, in a video, on a forum, on wikis and notes; </li><li>  A great <a href="http://neuralnetworksanddeeplearning.com/chap5.html">book</a> about neural networks and the first <a href="https://t.me/snakers4/765">code</a> from it on the third python (google, maybe someone zadabazhil all the code, I got mad after the first two chapters); </li><li>  Magnificent <a href="https://t.me/snakers4/765">course</a> Andrew Ng and his <a href="https://github.com/jdwittenauer/ipython-notebooks/tree/50a83a2ed3f9b66aee3909d9bf1e7978a0c9d315">interpretation</a> on python; </li></ol></li><li>  9. Jupyter notebook ( <a href="https://goo.gl/nQeRXQ">html</a> <a href="https://goo.gl/EVSpGv">ipynb</a> ), which: <ol><li>  It contains a hierarchical structure of cells, each of which describes what is being done and why; </li><li>  The main inclusions, utilities and libraries are divided into types; </li><li>  There are links to the main sources needed to understand what is happening; </li><li>  Sugar is given to work with Keras (in more detail without selling <a href="https://t.me/snakers4/852">here</a> , the people from fast.ai recommend it); </li><li>  For the <a href="https://t.me/snakers4/742">dataset of</a> cars passing through the window, a prediction grade accuracy of ~ 80% was obtained (randomly gives 50%, but the pictures are shitty and small); </li><li>  For datasets from the <a href="https://www.kaggle.com/c/state-farm-distracted-driver-detection/kernels">distracted driving</a> competition, the obtained accuracy of prediction of 10 classes in ~ 50% and an error that exactly ranks among the top 15-20% of decisions in the world; </li></ol></li></ul><br></div></div><br>  <b>To-do list for best results (for distracted driving, for example, you can get ~ 60-75% accuracy):</b> <br><br><div class="spoiler">  <b class="spoiler_title">List of improvements for the future</b> <div class="spoiler_text"><ol><li>  Using visualizations to understand what the network is learning; </li><li>  Using a training set of 300-500 images to quickly understand which image distortion parameters are best suited; </li><li>  Use test dataset (or cross-validation) to increase accuracy.  It is necessary to add no more than 25-30% of such pictures (semi-supervised learning); </li><li>  Using imagenet tweaking as an option for the model; </li></ol><br></div></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/22c/7f2/0af/22c7f20af42d7f0aedf952984e3a7335.jpg" alt="image"><br>  <i>If you have read this far, then here is a hen from which suspicions were removed that it is not rushing.</i>  <i>In the soup, it will go much later due to this.</i> <br><br>  <b>I will describe now what seemed to be interesting from the process of directly learning neural networks (not those in the head, but those in python):</b> <br><br><div class="spoiler">  <b class="spoiler_title">List here</b> <div class="spoiler_text"><ol><li>  Dataset with cars showed that if the pictures are small and the selection of classes is offset (one class is more than another), then the model will well define only one class; </li><li>  Start with a small set, so that the model will train for several tens of seconds and set up the meta-parameters for changing images; </li><li>  If you have a certain application of motion recognition + neural network, then it is better to immediately cut the pictures in open-cv, do not leave for later; </li><li>  Neural networks have a so-called ‚Äúeasy way out‚Äù effect, when the bone-function can stay in a local minimum for a relatively long time, because it is easier to predict the 50% chance of falling permanently into grade 1 than learning; </li><li>  Try first simple architecture, complicate gradually.  If you train slowly, take a small sample or check your model; </li><li>  Simple architecture + try different meta-parameters (learning rate); </li><li>  If the bone-function does not decrease at all, then somewhere in the model if there is an annoying typo.  It's easier to find it by comparing your model with the model of another person; </li><li>  Now at the level of software sugar (keras) there are already a huge number of state-of-the-art features, such as: <ol><li>  Image normalization; </li><li>  Image distortion; </li><li>  Dropout; </li><li>  Convolutions; </li><li>  Iterators for sequential reading of files; </li></ol></li><li>  From the interesting (not from the field of the stacking of 15 models) in Kaggle competitions, I would note the use of combinations of such things as: </li><li>  Image preprocessing, contour and shape search using open-cv; </li><li>  Convolutional neural networks for the main classification; </li><li>  Neural networks for creating meta-data about images - for example, first they search for whales' heads, and only then determine the whale; </li><li>  Gathered <a href="https://t.me/snakers4/881">here an</a> interesting about the latest architecture on Kaggle </li></ol><br></div></div><br><h3>  But a set of pictures </h3><br><div class="spoiler">  <b class="spoiler_title">Spoiler header</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/8a4/f70/1a0/8a4f701a001c0e4e407d76c15f2399ac.png" alt="image"><br>  <i>The first 285 cars have modest dimensions in pixels + everything is blurry ...</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b69/31f/367/b6931f36749fb8ed609d3634de457b33.png" alt="image"><br>  <i>When you want to quickly cut the picture, but I do not want to think that such ugly decisions are born</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb3/8a1/3d3/cb38a13d3f9f6e6dac720ff8c7894662.png" alt="image"><br>  <i>The difference in training and validation hints that it is skewed, small and general.</i>  <i>But a beautiful progress indicator.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cbf/576/a06/cbf576a065ff799f8e3422bf792c636a.jpg" alt="image"><br>  <i>Not chickens, but heroes of the occasion.</i>  <i>Very blurry - in motion</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4de/64d/662/4de64d662fea57aff21329b86aa5d4bf.jpg" alt="image"><br>  <i>Joy has no boundaries, when bydlokod, the writing of which stretched for an hour, began to work and trim the car.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d9b/26f/46e/d9b26f46e981d822e929e5fc2489cbae.png" alt="image"><br>  <i>In practice, there is enough space in the memory of a video card either with a margin, or there is not enough of it at once.</i>  <i>It is difficult to choose the size of the image and the size of the batch to eat the fish and ...</i> <i><br><br></i>  <i>Finger rule - convolutional layers require a lot of memory, and dense layers - a lot of time.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5d0/61c/9ac/5d061c9acf0ae63d9e7e421d85c81ce8.png" alt="image"><br>  <i>Compare the usable area on this picture ...</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/103/4c1/9e0/1034c19e0d77ed52ae95d34034784179.jpg" alt="image"><br>  <i>And how many useful pixels are there =) Yes, the chicken's head is bigger than the machine (in pixels) - my video card will suffer</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/19c/00f/c79/19c00fc7959f42905a2e4b9363a10737.png" alt="image"><br>  <i>Not calculated - the memory is over and everything fell.</i>  <i>A cleaning function, except as a restart, I have not found yet</i> <br></div></div></cut></div><p>Source: <a href="https://habr.com/ru/post/328138/">https://habr.com/ru/post/328138/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../328122/index.html">We do GraphQL API on PHP and MySQL. Part 1: Installation, layout and queries</a></li>
<li><a href="../328126/index.html">Parallels Mac Management: Transition Difficulties</a></li>
<li><a href="../328128/index.html">Quake 2 source code overview</a></li>
<li><a href="../328130/index.html">Pygest # 8. Releases, articles, interesting projects from the world of Python [April 11, 2017 - May 7, 2017]</a></li>
<li><a href="../328134/index.html">Recovering data from damaged RAID 5 to Linux NAS</a></li>
<li><a href="../328144/index.html">Docker containers slightly increase server power consumption</a></li>
<li><a href="../328146/index.html">A simple model of the adaptive Kalman filter by means of Python</a></li>
<li><a href="../328148/index.html">BK-0010 emulator on FPGA - part 2</a></li>
<li><a href="../328152/index.html">As I wrote my Redux</a></li>
<li><a href="../328156/index.html">How Studying Smalltalk Can Improve Your Programming Skills</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>