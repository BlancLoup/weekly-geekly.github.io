<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How SSD caching by means of a hypervisor in the VMware cloud works</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="VMware, with the release of VMware vSphere 5.1, announced several new initiatives in the field of virtual machine data storage, including the possibil...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How SSD caching by means of a hypervisor in the VMware cloud works</h1><div class="post__text post__text-html js-mediator-article">  VMware, with the release of VMware vSphere 5.1, announced several new initiatives in the field of virtual machine data storage, including the possibility of using a distributed cache on SSD-drives of local disks of ESXi servers.  This technology had the working name vFlash and was in the Tech Preview stage, later becoming the full vSphere Flash Read Cache (vFRC) feature of the VMware vSphere 5.5 platform.  And it is quite a working tool that can be used in tasks of various levels. <br><a name="habracut"></a><br><blockquote>  The vFRC technology is designed to increase the efficiency of client applications with the disk subsystem by caching read data, while significantly increasing the performance of applications that are actively performing read operations. </blockquote><br>  Flash Read Cache works at the hypervisor level, while significantly improving the performance of virtual machines that heavily use the I / O system for read operations.  For caching, PCIe flash cards and SAS / SATA SSDs locally installed in the host can be used.  Devices are combined into a flash pool from which VMDK disks of virtual machines are allocated space for data caching. <br><blockquote>  Recall that VMDK (Virtual Machine Disk) is a file format developed by VMware for use as a disk image in its virtual machines. </blockquote><br>  In terms of performance, the SSD cache is located between the RAM and regular disks. <br><br><h1>  VFRC Architecture Overview </h1><br><br><img src="https://habrastorage.org/files/da4/e1f/9f9/da4e1f9f9fa94adca10f95be2ee234d7.jpg" alt="  vFRC" title="VFRC Architecture Overview">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The architectural feature of the vFRC is as follows: <br><blockquote>  When a read request comes to the VMDK disk with vFRC enabled, it first turns out whether there is the required data on the vFlash. </blockquote><br><ul><li>  If yes, then the virtual machine receives data from the cache.  This event is called ‚Äúhit‚Äù (vFRC hit). </li><li>  If there is no data in the cache, then ESXi reads it from the VMDK disk and gives it to the machine, while simultaneously writing data to the cache.  This event is called a ‚Äúmiss‚Äù (vFRC miss).  When a write request arrives, the data is written to the VMDK disk and asynchronously to the cache. </li></ul><br><h1>  What is needed for vFRC? </h1><br>  In order to activate the vFRC functionality, the following conditions must be met: <br><ul><li>  Have a configured host with at least one SSD or PCIe SSD. </li><li>  Use vSphere 5.5 (vCenter 5.5 and ESXi 5.5). </li></ul><br><h1>  How does vFRC turn on? </h1><br>  After the device is physically connected to the server with ESXi, it must be added to the vSphere Flash Infrastructure layer.  You can do this on the Virtual Flash Resource Management tab in the host settings. <br><br><img src="https://habrastorage.org/files/5b9/e30/d94/5b9e30d9462b4148867e2675123f68a4.jpg" alt=" vFRC   " title="Enabling vFRC in host settings"><br><br>  To enable vFRC in a virtual machine, the Virtual Flash Read Cache item is used in the hard disk parameters, where you can specify the amount of allocated space for caching and the block size.  The block size for vFRC should be selected depending on which blocks the application writes data to disk.  The block statistics for each disk can be compiled using the vscsiStats utility on ESXi. <br><br><img src="https://habrastorage.org/files/79b/606/d01/79b606d010a240508cf400495dd523fc.jpg" alt="  vFRC" title="Defining vFRC Parameters"><br><br><h1>  Configuration Features </h1><br>  When configuring vSphere Flash Read Cache, the following features must be considered: <br><ul><li>  The host server must have VMware ESXi 5.5 installed in Enterprise Plus. </li><li>  The vFRC is configured and managed only through the vSphere Web Client, so VMware vCenter Server is required. </li><li>  The maximum cache size for one virtual disk is 400 GB. </li><li>  The maximum cache size per host is 2 TB. </li><li>  The maximum size of a virtual disk is 16 TB. </li><li>  The maximum number of SSD drives used for cache is 8. </li><li>  You need to update the Hardware Version of the virtual machine to version 10. </li><li>  You must manually configure the cache for each virtual disk, the minimum value is 1 GB. </li></ul><br><h1>  vFRC in practice in IT-GRAD </h1><br>  And a little from personal experience.  How did we test SSD cache in the VMware cloud and what pitfalls did we encounter in practice? <br><br>  Before offering any solution to customers, it is necessary to ensure its full functionality and performance, which means to test and understand that the result obtained fully complies with the stated capabilities and meets the requirements of the customer.  And if there is a new product that no one has yet tested or introduced, it should be run in with particular attention.  After all, it is no secret to anyone that in everything new there may be hidden flaws, bugs and other unpleasant trifles. <br><br>  As soon as VMware announced a new possibility of using distributed cache on SSD-drives of local disks of ESXi servers, we decided to test this functionality.  Since this technology was in the Tech Preview stage before the release of vSphere 5.5, I wanted to test the already revised solution.  We were faced with the task of testing the operation of the vFRC on the constructed stand. <br><br>  For testing, SSDs were connected to a Dell PERC H710P RAID controller.  We created a RAID-0 group by the number of SSD disks, each group has one disk. <br><br><img src="https://habrastorage.org/files/72a/d99/e11/72ad99e1105648d689ac769df033d909.png" alt="   SSD   RAID- Dell PERC H710P" title="For testing, SSDs were connected to a Dell PERC H710P RAID controller."><br><br>  Since the Dell PERC H710P RAID Controller cannot provide information about the physical type of media connected to it, I had to manually note that the disks connected to the ESXI are SSD disks.  To do this, run the esxcl command: <br><br><img src="https://habrastorage.org/files/dbe/ec8/347/dbeec83478b6488eb9b4a046b21b0189.png" alt="  esxcli" title="Run the esxcli command"><br><br>  After launching the command in the device parameters, the ‚ÄúIs SSD‚Äù flag value has changed to ‚ÄúTrue‚Äù: <br><br><img src="https://habrastorage.org/files/32e/450/fc8/32e450fc89f147f0ad8cd6b0ac07c7ed.png" alt="   ‚ÄúIs SSD‚Äú   " title="Change the value of the flag ‚ÄúIs SSD‚Äú in the device parameters"><br><br>  Then they added devices to the vSphere Flash Infrastructure layer.  The current procedure was performed in the host settings through the option Virtual Flash Resource Management: <br><br><img src="https://habrastorage.org/files/b9c/26a/229/b9c26a22921c49138bace1ac7d72aebd.png" alt=" vFRC   " title="Configuring vFRC in host settings"><br><br>  In advance for testing SSD-cache, we prepared a booth with virtual machines based on Windows Server 2008 R2 x64 OS and two VMDK-disks with a capacity of 100 GB each allocated for each virtual machine: <br><ul><li>  VMDK1 is defined under OS, </li><li>  VMDK2 - under the data. </li></ul><br>  Further, in the VMDK2 hard disk parameters of virtual machines, vFRC was turned on, allocating 100 GB for the cache, while determining the block size to be 4 KB. <br><br><img src="https://habrastorage.org/files/88e/d85/126/88ed851260674d22914fe4f346617420.png" alt="  vFRC" title="Defining vFRC Parameters"><br><br>  Basic configuration steps are performed.  Next was the task of checking the functionality of the included functionality.  However, when launching virtual machines, one simply refused to start, instead of the welcome window, a ‚Äúblue screen‚Äù appeared with the following contents: <br><br><img src="https://habrastorage.org/files/5bb/d38/41b/5bbd3841b3034a53a9490442a4554cb8.jpg" alt="¬´ ¬ª       " title="&quot;Blue screen&quot; when trying to start one of the virtual machines"><br><br>  On the other virtual machines, no obvious problems were observed. <br>  Then we decided to use the tools sharpened by monitoring the SSD cache, and compare the test results.  First, in one of the virtual machines, we launched the FIO utility, which generates the necessary amount of data on the VMDK2 disk.  As mentioned earlier, it was he who was allocated for useful data.  The FIO utility can work in various modes, we were interested in the ‚Äúrandom read‚Äù procedure.  That is why they launched it in rand-read mode. <br><blockquote>  Note: More information about the FIO utility can be found at <a href="http://freecode.com/projects/fio">http://freecode.com/projects/fio</a> . </blockquote><br>  The FIO utility implies the use of a job-file (or, more simply, a configuration file), in which parameters are written for testing.  The utility performs read operations on randomly generated VMDK2 disk data.  In the configuration file for reading, the read block size is fixed (in our case, equal to 4 KB).  After that, they started an arbitrary read operation.  The test time was 6 hours and 46 minutes. <br><br><img src="https://habrastorage.org/files/2f8/18e/6ba/2f818e6ba24c48b683876f8979286616.png" alt="  FIO" title="Running FIO Utility"><br><br>  I was interested in the question: did the read data get into the cache and if so, what percentage of the hit? <br>  To find the answer, we used the virtual disk performance graph of the machine using the vSphere WEB client. <br><br><img src="https://habrastorage.org/files/79d/e31/655/79de31655a624fbe815289cf93c0109b.png" alt="   vSphere WEB client" title="Performance graph in vSphere WEB client"><br><br>  It was interesting to look at the following counters: the average number of output operations per second, the read delay and the counter, which gives statistics on the use of the cache.  The latter was somewhat disappointing, showing a very small percentage of the data in the cache.  With an average number of output operations per second (18,689,328), the value for the cached data was 4,439,389, which is only 23% of the hit.  According to this statistical alignment, the cache can simply be considered non-functional. <br><br>  Since the standard tool did not show the expected results, they turned to another tool: the esxcli team.  It also works with statistics on a specific VMDK disk with the vFRC option enabled.  Run the command with the following parameters: <br>  <b><i>~ # esxcli storage vflsh cache stats get</i></b> <br><br><img src="https://habrastorage.org/files/604/2a7/f7a/6042a7f7af3146e691d617ff86d14481.png" alt="  esxcli" title="Run the esxcli command"><br><br>  In this figure, you can see the cache hit rate, represented as a percentage.  It shows the so-called "hit" vFRC hit, that is, the percentage of data from the cache that is used by the virtual machine.  The team under consideration had to be run several times, since the results at the next launch turned out to be completely different.  For one value, the cache did not work at all, as in the first case, for others it worked, with the percentage of data getting into the cache equal to 96%. <br><br>  We did not dwell on the received one, used another utility: esxtop (with sending an interactive command ‚Äúu‚Äù (u: disk device)) to display statistics on the use of the cache.  According to the information displayed on the screen, we got the following result: when reading, the data was retrieved directly from the cache.  Given that the average number of output operations per second was 18,689.328, and the volume of operations for data read from an SSD cache was 18,184.03, the percentage of data getting into the cache was approximately 97%. <br><br><img src="https://habrastorage.org/files/519/149/aac/519149aac99748b181c15e2f23950013.png" alt="  esxtop" title="Using the esxtop utility"><br><br>  The test results did not fully meet our expectations, and we, as a major service provider, VMware partner, turned to colleagues on the vendor side for help. <br><br>  VMware has a fairly extensive experience of interacting with its customers and partners.  In the case of detection of bugs, bottlenecks and other points in terms of product functionality, the developers make every effort to make the necessary corrections. <br><br>  As a result, in the autumn of 2014, an update of VMware ESXi 5.5 Update 2 was released, which eliminates the described problem on a blue screen of a virtual machine running Windows Server 2008 R2 x64. <br><br>  The released update, of course, interested us.  We decided to test it by installing it on a previously reviewed test site with vFRC enabled.  What is the result?  All virtual machines started as one.  We put a ‚Äú+‚Äù in this test and move in the direction of the meter readings.  As well as at the very beginning of testing, we launched the FIO utility in the rand-read mode with the configuration file used earlier, and then we launched the random read operation.  The counters for the most part showed working statistics and only occasionally indicated incorrect values.  That is, VMware ESXi 5.5 Update 2 did not fix the described problem by displaying vFRC statistics.  Despite this bug, the vSphere Flash Read Cache technology, as further practice of using this functionality has shown, significantly improves the performance of virtual machines by reducing the latency rate. <br><br>  After the next tests, we proceeded to the introduction of SSD caching on the hosts in an industrial environment.  Today, several projects have been successfully implemented at our sites using the vSphere Flash Read Cache for our customers who are particularly demanding of performance.  The latter, in turn, are pleased with the results of the acceleration of their systems and applications. <br>  You can read about other caching mechanisms in the article: <a href="http://iaas-blog.it-grad.ru/ssd-keshirovanie-v-oblake-vmware/">‚ÄúSSD caching in the VMware cloud‚Äù</a> in the <a href="http://iaas-blog.it-grad.ru/">first corporate IaaS blog</a> . </div><p>Source: <a href="https://habr.com/ru/post/250499/">https://habr.com/ru/post/250499/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../250489/index.html">Effective code review: 9 tips from a reformed skeptic</a></li>
<li><a href="../250491/index.html">Reduce the number of errors using the Code Review checklist</a></li>
<li><a href="../250493/index.html">Containerize it! What Fuel is and what it uses for Docker</a></li>
<li><a href="../250495/index.html">Security links for email newsletters</a></li>
<li><a href="../250497/index.html">[Moscow, 02.19.2015] Dmitry Lenev - Lock Managers in MySQL</a></li>
<li><a href="../250501/index.html">Application Insights - we collect telemetry of Windows Phone and Windows applications</a></li>
<li><a href="../250505/index.html">Convenient use of WPS in Mikrotik</a></li>
<li><a href="../250507/index.html">Arduino Leonardo as a SegaMegaDrive Gamepad Adapter-> USB</a></li>
<li><a href="../250511/index.html">How to start developing iron using FPGAs - step by step instructions</a></li>
<li><a href="../250513/index.html">Node v0.12.0</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>