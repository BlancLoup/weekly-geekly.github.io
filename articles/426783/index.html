<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neurotic Bikes: Genesis</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The other day, Youtube thought it would seem interesting to me a video called ‚ÄúAI Learns to play Hill Climb Racing‚Äù. It's funny, because a couple of m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neurotic Bikes: Genesis</h1><div class="post__text post__text-html js-mediator-article">  The other day, Youtube thought it would seem interesting to me a video called ‚ÄúAI Learns to play Hill Climb Racing‚Äù.  It's funny, because a couple of minutes before that, I committed another change to the project, where my colleagues and I, in the breaks between work and work, solve exactly this problem.  No ‚ÄúAI‚Äù in that <a href="https://youtu.be/BP6xtp_9UME">video</a> , however, was revealed - the author entertained the public with pampering with Box2D and calmed down on that.  Nevertheless, I propose to consider this fact as convincing evidence of the relevance of the topic and disassemble the structure of our rattles. <br><br>  Briefly about the task: the vehicle - in our case it is either Alien, or the Zinger sewing machine on wheels, let's call it simply ‚Äúagent‚Äù - must travel along the perichind <a href="https://habr.com/post/342906/">noise of the</a> same name from the dunes from start to finish.  This is what an agent looks like in his sandbox: <br><br><img src="https://habrastorage.org/webt/jh/s6/wr/jhs6wrc1jgvt42qg2hrpbmlfr1e.png" align="left">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      An agent who has touched the back of the track or does not demonstrate proper zeal in moving towards the goal is removed from the track. <br><a name="habracut"></a><br>  We will solve the problem using neural networks, but optimized by a genetic algorithm (GA) - this process is called <em>neuroevolution</em> .  We used the NEAT method (NeuroEvolution of Augmenting Topologies), invented by Kenneth Stanley and Risto Miikkulainen at the beginning of the century <a href="https://habr.com/ru/post/426783/">[1]</a> : firstly, he had a good account of important <a href="https://habr.com/post/381315/">problems</a> for the national economy, secondly, to start working on the project in our country already had its own framework implementing NEAT.  So, to be honest, we didn‚Äôt choose the solution method - rather, we chose a task where we could drive the ready one. <br><br>  The figure shows an approximate scheme of the work of genetic algorithms: <br><br><img src="https://habrastorage.org/webt/wp/ee/ym/wpeeymuty6mhrjjl0ipfcucksp8.png"><br><br>  It is seen that any decent GA starts with the initial population (the <em>population</em> is a set of potential solutions).  Let us create it and at the same time get acquainted with the <b>first principle of NEAT</b> .  According to this principle, all agents of the starting population should have the simplest, ‚Äúminimal‚Äù topology of the neural network.  What does it have to do with topology?  The fact is that in NEAT, along with the optimization of link weights, the network architecture evolves.  This, by the way, eliminates the need to design it for a task.  To go from simple architectures to complex ones is not only logical, but also practical (less search space), and therefore it is necessary to begin with the minimum possible topology - this is how the authors of the method argued. <br><br>  For our and all similar cases, this minimal topology is derived from the following considerations.  To do something meaningful agent need: <br><br><ul><li>  have environmental and state data, </li><li>  process this information </li><li>  interact with your world. </li></ul><br>  The first role is played by the <em>sensors</em> - the neurons of the input layer, to which we will provide useful information to the agent.  The neurons of the <em>output</em> layer will process the data from the sensors.  For interaction with the environment, <em>actuators</em> are responsible - devices that perform mechanical actions in response to a signal from "their" neuron of the output layer.  The general principle of building the initial configuration is thus the following: we determine the sensors and actuators, initiate one neuron for the actuator, all sensors and another special neuron - <em>displacement neuron</em> ( <em>bias</em> , about it - below) are connected with random weights with all neurons output layer.  Something like this: <br><br><img src="https://habrastorage.org/webt/8f/ll/kr/8fllkroieolrvzfobd1lguz6p4s.png"><br><br>  <i>b - bias, s - sensors, o - neurons of the output layer, a - actuators, n - number of sensors, k - number of actuators</i> <br><br>  And this is what the minimum NA looks like for our task: <br><br><img src="https://habrastorage.org/webt/g0/bi/2q/g0bi2qjph_pspxohzjn9gm0ypoc.png"><br><br>  We have only one actuator - this is the engine of our wheeled creation.  Shoot, jump and play the tune it still does not know how.  On the engine from a single neuron of the output layer (it is embarrassing to call it a layer), this value is given here: <br><br><img align="right" src="https://habrastorage.org/getpro/habr/post_images/bb8/192/9fa/bb81929fa089459264878faba089e694.svg"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ee6/6f0/9de/ee66f09de65cabf580cd1e9633a1fe86.svg" alt="f (w_b + \ sum \ limits_ {i = 1} ^ {n} {s_iw_i})"></div><br>  Here w <sub>b</sub> is the value of the weight of the connection going from bias to the output neuron, multiplied by what every bias ‚Äúproduces‚Äù, i.e.  +1, s <sub>i</sub> is the value normalized to the range [0,1] on the i-th sensor, w <sub>i</sub> is the weight value of the connection from the i-th sensor to the output neuron, and f is the activation function. <br><br>  As an activation function, we use this fantasy on the subject of softsign: <br><br><img align="right" src="https://habrastorage.org/getpro/habr/post_images/a79/caf/e65/a79cafe65ea1ccf1f75352901195b537.svg"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/824/77c/5e3/82477c5e3154e860b0b7254a38b56d11.svg" alt="f (x) = \ frac {1} {2} + \ frac {1} {2} \ left (\ frac {x} {0.2 + | x |} \ right)"></div><br>  - it demonstrated the best performance in the tests of a neuroevolutionist well-known in narrow circles <a href="https://habr.com/ru/post/426783/">[2]</a> .  And to compare the soft-looking softness of the curves and the symmetry of the graph of this function with the angular-crooked Leaky ReLU makes no sense at all: <br><br><img src="https://habrastorage.org/webt/bd/t1/zo/bdt1zorx3q6i45dqdevrkwijyoq.png"><br><br>  This figure shows the agent's reaction to different values ‚Äã‚Äãof the activation function.  At close to unity values, the engine turns the wheels clockwise, accelerating the agent forward and strongly deflecting the body backwards, so that the mentally minded, but the brave quickly overturned on his back and die.  At values ‚Äã‚Äãclose to 0, the opposite is true, and at a value of 0.5, the agent motor does not work. <br><br>  The same figure shows the role of the displacement neuron - the weight of the connection going from it to the neuron of the output layer is responsible, as follows from (1), for the magnitude and direction of displacement f (x) along the abscissa axis.  The dotted line in the figure shows the graph of the activation function when w <sub>b</sub> = -1.  It turns out that even in the absence of a signal on the sensors, an agent with such a connection would rather quickly go back: f (x) = f (-1 + 0) ‚âà0.083 &lt;0.5.  In general, the horizontal shift of the function values ‚Äã‚Äãallows the bias communication to be fine (well, or thick ‚Äî depending on weight) to adjust the response of the engine to all sensor values ‚Äã‚Äãand the weights of their connections at once.  It seems that a new dimension has been added to the search space (the ‚Äúcorrect‚Äù value for w <sub>b</sub> will have to be searched for), but the benefit in the form of an additional degree of freedom from the possibility of such displacements outweighs. <br><br>  Great, we introduced the neural networks of agents of a future initial population.  But NEAT is a genetic algorithm, and it works with <em>genotypes</em> ‚Äî the structures that make up networks or, more generally, <em>phenotypes</em> in the decoding process.  Since we started with the phenotype, let's do everything backwards: we will try to encode the network presented above in the genotype.  Here, one cannot do without the <b>second principle of NEAT</b> , the main essence of which is as follows: in the genotype, in addition to the structure of the neural network and the weights of its connections, information is stored about the history of the origin of all its elements.  With the exception of this historical aspect, the phenotype is encoded in the genotype almost ‚Äúone to one‚Äù, therefore, we will illustrate the second principle for the time being with fragments of neural networks. <br><br>  The value of this principle is difficult to overestimate - it provides agents with the possibility of sexual reproduction.  The topic is rather delicate, therefore we will first consider <em>asexual</em> reproduction.  It happens like this: a copy of all the genes of the agent is made, one of several types of changes is made on them - <em>mutations</em> .  The following mutations are possible in our version of NEAT: <br><br><ul><li>  change in bond weight, </li><li>  removing a connection </li><li>  adding a connection </li><li>  neuron insertion. </li></ul><br>  The first three types of mutations are simple and understandable without further explanation.  The neuron insertion is shown in the figure below, it always takes place in place of the existing connection, the connection is removed, and two new ones appear in its place: <br><br><img src="https://habrastorage.org/webt/xg/3c/j1/xg3cj1mbkl1djxzmkke_uf7o3ek.png"><br><br>  Here h is a <em>hidden</em> ( <em>hidden</em> ) neuron. <br><br>  Two agents participate in sexual reproduction or <em>interbreeding</em> - parents, and as a result a third one appears - a child.  In the process of the formation of a child's genotype, an exchange occurs, let's say, with the same <em>within the meaning of the</em> genes or groups of genes of the parents.  The second principle is just needed to search for genes with the same meaning. <br><br>  Imagine that we want to cross agents with genotypes that have undergone different mutation series from the list above: <br><br><img src="https://habrastorage.org/webt/a4/wx/kd/a4wxkdythyj2m92enwg1-gpt4m4.png"><br><br>  It seems logical to look for some common from the point of view of topology fragments from both parents and take a piece of these fragments for the genotype of the unborn child.  It will be difficult to do this, even <a href="https://habr.com/post/421263/">NP is</a> difficult in the general case, but suppose we managed.  In this case, we find that in the parent on the right there are two subgraphs isomorphic to the graph of the left parent.  In the figure below, the arcs of these subgraphs are highlighted in different colors: <br><br><img src="https://habrastorage.org/webt/d8/32/6s/d8326stmtwrnsmq2f2vzretjghy.png"><br><br>  Which one to choose for recombination with the genes of the left parent? <br><br>  Let us turn to the history of the emergence of these genotypes: <br><br><img src="https://habrastorage.org/webt/z1/tr/fs/z1trfsqjs7h0qz6njdwrgo-z4eq.png"><br><br>  Both ancestors of the parent agents started, as expected, with a minimum NA (T <sub>0</sub> ).  Their genomes somehow mutated there, and at the time T <sub>1</sub> in the ancestor of the left parent, a hidden neuron was inserted into the connection s <sub>1</sub> -&gt; o.  At this dramatic moment, the genes encoding the connections s <sub>1</sub> -&gt; h and h -&gt; o acquire their meaning in the ancestor of the left parent: the <em>substitution of the connection s <sub>1</sub> -&gt; o</em> . <br>  The s <sub>1</sub> -&gt; h <sub>1</sub> and h <sub>1</sub> -&gt; o genes in the genotype of the right parent at the time point T <sub>2 had the</sub> same meaning.  The further destinies of our ancestors do not particularly interest us - we already know what we can mix with: <br><br><img src="https://habrastorage.org/webt/l_/lt/8z/l_lt8z9o2jugahg1frf-pjqu0s4.png"><br><br>  The next time it will be possible to make out how to write a genetic history, all the more so since we have some small finds in this area, they are connected with the adaptation of the original technique to a stable reproduction scheme. <br><br>  It's time to wrap up.  The article began with Youtube - they will complete it.  In the early version of the simulator, a colleague who wrote the track generation code ended it with a bottomless abyss.  The reaction of the neural network, which has evolved for a long time in the presence of the earth, under the wheels, can be called a ‚Äúpattern break‚Äù for such a design of its small universe: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/DHnwJpi8PVE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  An extensive collection of other anecdotal stories from the life of cybernaturalists can be found in <a href="https://habr.com/ru/post/426783/">[3]</a> . <br><br><h2>  Sources </h2><br><anchor>  [one] </anchor>  KO Stanley and R .. Miikkulainen, "Evolving Neural Networks through Augmenting Topologies" Evolutionary Computation, vol.  10, no.  2, pp.  99-127, 2002. <br><anchor>  [2] </anchor>  <a href="http://sharpneat.sourceforge.net/research/activation-fn-review/activation-fn-review.html">C. Green, ‚ÄúA Review of Activation Functions in SharpNEAT,‚Äù 19 June 2017.</a> <br><anchor>  [3] </anchor>  J. Lehman et al, ‚ÄúThe Surprising Creativity of the Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities,‚Äù arXiv: Neural and Evolutionary Computing, 2018. </div><p>Source: <a href="https://habr.com/ru/post/426783/">https://habr.com/ru/post/426783/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../426771/index.html">Making a machine learning project in Python. Part 3</a></li>
<li><a href="../426773/index.html">Tips for professional use RecyclerView. Part 2</a></li>
<li><a href="../426777/index.html">Bad advice on communication with technical support</a></li>
<li><a href="../426779/index.html">How does the station</a></li>
<li><a href="../426781/index.html">Google will separately sell licenses for the Google Apps package and search with a browser</a></li>
<li><a href="../426785/index.html">How can LIGO see gravitational waves, if in GRT the light is stretched along with the space?</a></li>
<li><a href="../426787/index.html">3 key skills for effective Customer Success Manager</a></li>
<li><a href="../426791/index.html">How to build IT architecture in a company using SAP Enterprise Architecture Designer</a></li>
<li><a href="../426793/index.html">DotNext - there are other heroes</a></li>
<li><a href="../426797/index.html">Neural network using TensorFlow: image classification</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>