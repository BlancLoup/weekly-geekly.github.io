<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Java: keyed executor</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="There is a typical problem in a large class of tasks that occurs when processing a message flow: 

 - you can not push through a big elephant through ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Java: keyed executor</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/53b/1ec/b64/53b1ecb64cf75d108634e26051c12992.png" alt="image"><br><br>  There is a typical problem in a large class of tasks that occurs when processing a message flow: <br><br>  - you can not push through a big elephant through a small pipe, or in other words, the processing of messages does not have time to <i>"swallow"</i> all the messages. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      However, there are some restrictions on the data flow: <br><br><ul><li>  the flow is not uniform and consists of events of different types. </li><li>  the number of event types is not known in advance, but some finite number </li><li>  each type of event has its own <i>relevance</i> in time </li><li>  all event types have equal priority </li></ul><br><br>  The diagram shows an example of resolving the problem: a <i>rake (tm)</i> running on a <b>T <sub>1</sub></b> string, while a <i>rake (tm)</i> runs on a <b>T <sub>2</sub></b> string <ul><li>  during the processing of event type <b>A,</b> new events both type <b>B</b> and <b>A</b> have time to arrive. </li><li>  after processing an event of type <b>B,</b> you must handle the most current event of type <b>A</b> </li></ul><br><blockquote>  So  the task is to perform tasks by key, so that only the <b>most</b> current of all tasks on this key is performed. </blockquote><br>  The <b>ThrottlingExecutor</b> created by us is presented to the public. <br><br>  <i>Terminology note:</i> <i>stream</i> is a <i>data stream</i> , while <i>thread</i> is a <i>thread</i> or a <i>thread of execution</i> .  And do not confuse threads with threads. <br><br>  <i>Note 1: the</i> problem is further complicated by the fact that there may be several <i>Nagrebator (tm)</i> , while each <i>Nagrebator (tm)</i> can only generate events of the same type;  on the other hand, there is a need for several (of course, for simplicity, you can choose <b>N = 1</b> ) <i>diggers (tm)</i> . <br><br>  <i>Note 2:</i> not only does this code have to work in a multi-threaded (competitive) environment - that is, the set of <i>diggers (tm)</i> - <i>diggers (tm)</i> , the code should work with maximum performance and low latency.  It is reasonable to add all these qualities to the <i>garbage less</i> property. <br><br>  And in almost every project this problem somehow arises, and each one solves it differently, but all of them are either not effective, or slow, or both of them taken together. <br><br><a name="habracut"></a><br><blockquote>  A small lyrical digression. <br>  In my opinion, the task is very interesting, quite practical and, moreover, from our specific work.  And that's why we ask our candidates for an interview.  However, we are not asking to literally code everything inside and out, but to build a general design of the solution, if possible highlighting the key points of the solution with pieces of code.  After several months of interviews, we decided to put the ideas into code in java. </blockquote><br><br>  However, the code cannot yet be opened publicly, therefore ideas are general and can be applied and implemented in many other programming languages. <br><br>  Since everything is already set, and perhaps it remains to bring a little marafet, I will describe the key points of the decision. <br><br>  So, looking around, we didn‚Äôt find how to do what we want with the high-level data structures available in <b>jdk</b> , so we will construct from the most basic blocks. <br><br>  Picture of the design as a whole: <br><ul><li>  because  there is no need to store all obtained values, but only the most relevant ones are needed - then it would be good to store key-value pairs in some associative array, rubbing the old values ‚Äã‚Äãwith new ones </li><li>  run on an associative array, take (marking a cell with a special value, for example, <b>null</b> ) the most recent values ‚Äã‚Äãand return to the handler. </li></ul><br><br><h3>  Associative array </h3><br><br>  Key aspect: storing key-value pairs.  You can neglect the order of storage, while winning at the rate of update - so  This suggests the use of a hash structure, the complexity of which is <i>O (1)</i> . <br><br>  A negative effect on the performance of the hash structure is caused by the collision of hash codes on the selected size.  The two most common methods for resolving collisions are: <br><ul><li>  <a href="http://en.wikipedia.org/wiki/Hash_table">chains</a> - each element of the array is a <i>linked list</i> that stores elements with the <i>same</i> (up to the module size of the array) hash codes </li><li>  <a href="http://en.wikipedia.org/wiki/Hash_table">open addressing</a> - when a collision occurs, the first free cell is searched for (or in front of) the cell of the corresponding hash code.  As a rule, in favor of productivity limit the number of samples of the free cell.  When the number of samples to find a free cell to insert a new element is exceeded, the array is expanded. </li></ul><br><br>  <i>The chain method is</i> more stable, since  It does not stumble over the problem of poor distribution of <i>hash codes</i> , while <i>open addressing will</i> clearly not survive if all the keys have a <i>hash code</i> equal, for example, to <a href="http://en.wikipedia.org/wiki/42_(number)">some constant</a> .  On the other hand, <i>open addressing</i> has significantly less memory overhead. <br><br>  Another plus in favor of <i>open addressing</i> is the cache locality, the data in the array are sequentially in memory and will also be sequentially loaded into cpu cache, so  fast sequential iteration as opposed to <i>chaining</i> , where pointers to linked lists are somehow scattered in memory. <br><br>  Based on the general principles of adequacy of application, we can safely assume that the function <i>hash codes</i> will not be degenerate and the choice falls on the <i>public addressing</i> . <br><br>  Now consider the array element: <br><br><h4>  atomic refs </h4><br><br>  Since there is a requirement to work in a multi-threaded and high-loaded environment, you don‚Äôt bother with <i>synchronized blocks</i> and work through <i>Compare-And-Swap</i> , so each element is an <i>AtomicReference</i> extension with a <i>key</i> : <br><br><pre><code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Entry</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">K</span></span></span><span class="hljs-class">&gt; </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AtomicReference</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> K key; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Entry</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">final</span></span></span></span><span class="hljs-function"><span class="hljs-params"> K key)</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.key = key; } }</code> </pre> <br><br><h4>  atomic array ref </h4><br><br>  Another way to ensure the consistency and atomicity of the memory is to use not the <i>AtomicReference</i> array, but <i>AtomicReferenceArray</i> . <br><br>  Motives - less additional overhead for the occupied memory, the sequence in memory.  At the same time, the scheme for expansion / compression of the array becomes much more complicated. <br><br><h3>  Card mark </h3><br>  The basic idea: not to iterate over all elements, but only over the modified elements (ideally), or segments (consisting of a small reasonable number of elements) that contain modified elements. <br><br><h4>  Simple card mark </h4><br>  An easy-to-implement approach using <b><i>AtomicLong</i></b> as a mask allows you to cover up to 64 modified segments. <br><br>  However, with an array already in 4096 elements, the segment consists of 64 elements, so  potentially, you can do a lot of <i>empty</i> readings. <br><br><h4>  Binary heap card mark </h4><br>  The next step I wanted to expand the number of segments, while maintaining the compactness of storage in memory and ease of traversal.  In this case, the selected data structure should be convenient from the point of view of the <i>wait strategy</i> . <br><br>  From these points of view, the <i>binary heap</i> is very convenient - the zero element indicates whether there were any changes at all or not (if not, you can gnaw a stone / fall asleep = apply <i>a waiting strategy</i> ) and already subsequent elements indicate changed segments of the original array. <br><br>  So, if there is a second level and the size of the array is 4096 elements, the segment contains exactly one element. <br><br>  So  <i>simple card mark</i> should be good for small sizes of the array, and <i>binary heap card mark</i> for large sizes. <br><br><h3>  Wait Strategy </h3><br>  Another aspect and direct <i>reference to D.</i> , which should not be mentioned in conjunction with the <i>card mark</i> , is the application <i>of the waiting strategy for</i> changed segments: you should not immediately fall into a state of passive waiting (that is, call <b>wait</b> on the monitor) if there are no changes, it is possible That will be able to get a change actively poll'ya card mark. <br><br>  For example, <i>busy spin</i> polls the root element <i>card card mark</i> in the loop - if there are changes, we exit - we process the elements.  If not, continue the cycle.  By limiting the cycle, for example, by hundreds of attempts, we fall into a state of passive waiting for the <b>wait</b> , and let us wake up the <i>nagbator (tm)</i> , seeing that the <i>card mark</i> was crystal clear and empty. <br><br>  However, the strategy may change in each case. <br><br><h4>  tricks and tricks </h4><br><ul><li>  maintaining the sizes of the array and binary heap as 2 <sup>K,</sup> you can avoid using <i>division</i> , <i>multiply</i> and <i>mod</i> operations and use <i>cheaper</i> bit analogues: <i>right shift K</i> , <i>left shift K</i> and use bit masks ( <i>&amp; ((1 &lt;&lt; K) - 1)</i> ) </li><li>  the main and most frequent operation in the stable phase - the <b>replace / replace</b> operation occurs only at the expense of <b>CAS</b> for the found array element without capturing any monitor </li><li>  subtracting the value from a cell or card mark instead of an unconditional <i>get-and-set (0)</i> sometimes (when the array is very low) it is more sensible to do <i>test-n-get-n-set</i> to avoid unnecessary (and more expensive) volatile write </li><li>  array expansion / contraction (in the context of <b>JMM</b> correctness) refers to the initial phase <br><ul><li>  <b>volatile</b> array reference - fast volatile read </li><li>  updating <b>volatile</b> links with <b>AtomicReferenceFieldUpdater</b> magic </li><li>  Given that the number of keys is limited, you can scale the array to produce under the monitor </li></ul><br></li></ul><br><br>  At the end of the latency distribution graphics: <br><ul><li>  1 <i>rake (tm)</i> - 1 <i>rake (tm)</i> </li><li>  700 unique keys, hash collisions &lt;1% </li><li>  warming up jvm: 20,000 first iterations ignored when measuring latency </li><li>  The task transferred to the executor: fix the time (in ms) of passing through the executor - that is, fix the latency </li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/784/630/7e0/7846307e03f91d05ab56dbb14c93ad4e.gif"><br>  Histogram of latency distribution in ThrottlingExecutor, <br>  simple card mark, size 4096 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ad/fa3/594/6adfa359434d2b3c6fe07cdc3e64615a.gif"><br>  Histogram of latency distribution in ThrottlingExecutor, <br>  card mark on binary heap, size 4096 <br><br>  In a highly sparse array: <br><img src="https://habrastorage.org/getpro/habr/post_images/06b/33e/7c3/06b33e7c336e33f983d5ff4b7ee32a28.gif"><br>  Histogram of latency distribution in ThrottlingExecutor, <br>  simple card mark, size 16384 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8e4/0ff/4b3/8e40ff4b393edd4a2f87077e3371896e.gif"><br>  Histogram of latency distribution in ThrottlingExecutor, <br>  card mark on binary heap, size 16384 <br><br>  Until the end, I could not find all the reasons for such a different behavior of the array of atomic references and the atomic array (we expected rather to see that an atomic array with a binary heap would work much better). <br><br>  It is possible, and I hope very much, when we can open the code, we will find errors or get answers. <br><br>  <b>PS</b> It is worth noting that by testing existing <i>ThrottlingExecutor</i> solutions in this <i>benchmark</i> , they gave an almost even distribution of up to 300 ¬µs. </div><p>Source: <a href="https://habr.com/ru/post/172209/">https://habr.com/ru/post/172209/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../172197/index.html">Frontender Magazine: let's talk about the frontend</a></li>
<li><a href="../172199/index.html">Connect to the IT Camp ‚ÄúNew Private Cloud‚Äù online broadcast today at 10:15</a></li>
<li><a href="../172201/index.html">Kinect Fusion can help surgeons</a></li>
<li><a href="../172203/index.html">Lenovo ThinkPad Twist S230u Ultrabook Video Review</a></li>
<li><a href="../172205/index.html">Denial of standard authorization in favor of social</a></li>
<li><a href="../172211/index.html">Behavioral factors and what they eat</a></li>
<li><a href="../172213/index.html">Drupal + Omega + Bootstrap: the rapid creation of fully custom themes without layout (Part 1. Omega)</a></li>
<li><a href="../172215/index.html">Programming Arduino from Linux, gentoo-way, quick start</a></li>
<li><a href="../172217/index.html">Photo archive metadata. XMP tags of individuals. [HowTo]</a></li>
<li><a href="../172219/index.html">Displaying python projects with pip and wheel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>