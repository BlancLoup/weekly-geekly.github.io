<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>DZ Online Tech: ABBYY. How not to get lost in neural networks?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We (DZ Systems) have been shooting a series of programs on digital transformation for the second year. Usually, these are ‚Äúpro-business‚Äù broadcasts, m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>DZ Online Tech: ABBYY. How not to get lost in neural networks?</h1><div class="post__text post__text-html js-mediator-article"> We (DZ Systems) have been shooting a series of programs on digital transformation for the second year.  Usually, these are ‚Äúpro-business‚Äù broadcasts, mostly focused on top managers and designed to help understand the business value of what is called digital transformation. <br><br>  But this year we also remove the second ‚Äúline‚Äù of broadcasts - DZ Online Tech, now focused on the technological aspects of the same topic.  In short - that is "under the hood." <br><br>  Below is the decoding of the next such program, in which Ivan Yamshchikov and I (Yandex, ABBYY, and indeed a high-class professional) talk about the use of neural networks in the modern world. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      If interested, <a href="https://youtu.be/C70HIuVRbSE">you can see the transfer itself</a> . <br><br>  And for those who like to read - the decoding below: <br><br>  <b>- Hello.</b>  <b>Our today's guest is Ivan Yamshchikov from ABBYY, who</b> <b><br></b>  <b>will tell us how modern artificial intelligence works.</b> <b><br></b>  <b>In relation to AI, there are conditionally two positions: people who say: ‚ÄúWe do not want</b> <b><br></b>  <b>understand anything about the essence of what is happening in the system.</b>  <b>We have statistical methods</b> <b><br></b>  <b>who themselves removed the model from the outer life.</b>  <b>This model will be correct, it will be</b> <b><br></b>  <b>feel all the semantic subtleties. "</b>  <b>And there are people who say, "No, so</b> <b><br></b>  <b>can not.</b>  <b>We understand what is happening.</b>  <b>We have to put this understanding into the system.</b> <b><br></b>  <b>artificial intelligence, and then it will be more valuable, better and better. "</b>  <b>This battle</b> <b><br></b>  <b>does it have any criteria within itself?</b> <br><br>  - Let me explain in a less philosophical language.  There are people who say, ‚ÄúWe need more <br>  stronger, more efficient algorithms and large amounts of data.  We will take more <br>  productive algorithm, and on a larger scale it will give us a higher quality target <br>  metrics no matter what. "  I don't know people who say they don't need data or <br>  algorithms.  Therefore, the second group of people, in my opinion, has the following approach: ‚ÄúBesides <br>  Of all this, we would be nice to still human marking in one form or another, some kind of <br>  expert knowledge, add on top. " <br><a name="habracut"></a><br>  There‚Äôs a joke on Google that is often quoted: the fewer linguists working on <br>  the better the final quality will be.  This joke is probably justified by the practice. <br>  bulk B2C services.  But when we talk about B2B in the context of narrow grocery <br>  solutions, in the context of a very clearly defined task and a well-defined field, <br>  expert knowledge begins to play a rather important role.  We combine inside ABBYY and <br>  ontological models that linguists build and pure machine learning approaches. <br><br>  <b>- I want to give an example: we did a project for Mosvodokanal.</b>  <b>There was such a task:</b> <b><br></b>  <b>Mosvodokanal has a complex network, it somehow works and somehow behaves.</b>  <b>And I want something</b> <b><br></b>  <b>understand something about it, it is desirable to predict accidents, to feel when something is wrong</b> <b><br></b>  <b>going on.</b> <br><br>  - You made a monitoring system. <br><br>  <b>- Yes, we did some kind of behavior analysis system, which was supposed to say: ‚ÄúIn this</b> <b><br></b>  <b>The corner is something wrong. "</b>  <b>We really can't say if it's an accident or just a fluctuation.</b> <b><br></b>  <b>behaviors because they are physically indistinguishable ...</b> <br><br>  - I did about the same system for monitoring traffic. <br><br>  <b>- A very similar theme.</b>  <b>During the project, we fought with engineers who said:</b> <b><br></b>  <b>‚ÄúListen, you are doing garbage.</b>  <b>It is necessary to measure all the pipes, their external diameters and</b> <b><br></b>  <b>internal, then make information about the smoothness of the walls.</b>  <b>And then count</b> <b><br></b>  <b>hydrodynamic model, and it will show everything. "</b>  <b>And we said: ‚ÄúDon't.</b> <b><br></b>  <b>Give us the data from the sensors, we will drive them into the stat model, and she, without knowing anything about</b> <b><br></b>  <b>physics, will still work, because it will take out the real behavior ".</b>  <b>It's straight</b> <b><br></b>  <b>the ultimate case of what we're talking about.</b>  <b>On the one hand, this is the ultimate knowledge.</b> <b><br></b>  <b>physics of the work of the phenomenon, which we pack semantically directly, and the second</b> <b><br></b>  <b>the side is the ultimate misunderstanding.</b>  <b>We do not really understand how it works.</b> <b><br></b>  <b>hydrodynamics - we didn‚Äôt even want to understand this.</b> <br><br>  - Arrogance is very peculiar to people who know the statistics well.  As Mark said <br>  Twain: "There are three kinds of lies - lies, shameless lies and statistics." <br><br>  <b>- We eventually won them for one very simple reason: to collect information about all</b> <b><br></b>  <b>these pipes is impossible.</b>  <b>But, on the other hand, some depth of knowledge of the subject</b> <b><br></b>  <b>area can not help.</b> <br><br>  - People who are guides of this knowledge, believe that it is true, because it <br>  their area of ‚Äã‚Äãexpertise.  But at the same time, in fact, we understand about natural language, with <br>  computer science is much smaller than we would like because many <br>  terms and categories are not defined mathematically, but intuitively.  This leads to the fact that <br>  those people who completely come from the computer sciences, there is an understandable <br>  distrust of people who come from the side of linguistics and vice versa.  In abbyy this <br>  is solved by the fact that both of them work on the product, are responsible for different parts, and you <br>  It is possible to measure how much quality this adds to you and this.  This is the way <br>  tests and experiments. <br><br>  <b>- This is also a big trouble.</b>  <b>We all know that there is a local optimization problem.</b> <br><br>  - Of course.  This is retraining.  But just very often things related to common <br>  linguistic approaches allow to fight retraining.  Because linguists often try to create some general rule, and then there is a great and beautiful story. <br>  about exceptions.  Anyone who read Rosenthal's book about the Russian language at school is perplexed: <br>  my god, what do philologists do?  They call the rules what really <br>  is an‚Ä¶ <br><br>  <b>- A set of exceptions.</b> <br><br>  - But in essence, this is exactly the same story about the error on the test.  If you look at it with <br>  in terms of machine learning, a very large number of linguistic rules <br>  cover a fairly large number of examples and leave some error on <br>  test data.  If you take these rules and apply to the data that your model <br>  never seen a model in this place is wrong.  But many linguistic heuristics <br>  allow you to protect yourself from retraining. <br><br>  <b>- I heard you correctly, that if we take a book on the Russian language and chase it</b> <b><br></b>  <b>in the model, then, by extrapolating these rules, will the model necessarily make a mistake?</b> <br><br>  - Of course.  Exactly.  Any rigid rules will always lead to errors, because, <br>  unfortunately or fortunately, artificial intelligence is much more flexible than some kind of set <br>  simple rules. <br><br>  <b>- This is also due to the fact that when we speak about the formalization of the rules of the natural</b> <b><br></b>  <b>language, we in this place are inevitably engaged in an unsolvable task.</b>  <b>Depth of this</b> <b><br></b>  <b>The process is endless.</b> <br><br>  - This is a philosophical question.  At the machine level, the depth seems not infinite, but there is <br>  An interesting article, in my opinion, in 2015.  A brief digression: there is such a section of mathematics, <br>  which is called information theory.  In particular, it is used in coding theory. <br>  In Russia, Kolmogorov and his companions did it, in the USA - Shannon.  First of all, his <br>  came up with in the context of cryptography. <br><br>  In information theory there is such a thing as ‚Äúgeneral information‚Äù.  If at all on the fingers <br>  say: imagine how you correlate the meanings of a word in the text in <br>  depending on the distance between them.  Imagine this metric.  If i have here <br>  it says "Petya", then n-words, and then the word "ate."  In fact, the words "ate" and "Peter" <br>  correlate, despite the fact that the word "eaten" can be quite far from "Petit". <br>  If we statistically construct a model of these correlations, it turns out that, as a function of <br>  distances this general information in texts decreases rather slowly - not polynomially, but <br>  slower  Roughly speaking, in natural language texts there is a correlation between the words, <br>  far apart. <br><br>  Approximately the same is observed in the "texts" of DNA: our nucleotides also correlate on <br>  relatively long distance.  In particular, this kind of system tries to describe <br>  theory of complexity, etc. The whole story about the butterfly effect - it‚Äôs about that, that you have a small <br>  a deviation in one place can lead to some significant changes far. <br>  Natural language is described by this kind of dependencies.  And now, let's say, LSTM (Long <br>  Short-Term Memory Network) is considered the most advanced, in terms of memory, neural <br>  network, which is used to analyze the language just to ensure that these far-reaching ones <br>  from the other correlation to catch.  Here it is, infection, memory decreases faster than necessary. <br>  This is a big research topic.  In particular, we at Max Planck Institute are trying to <br>  to do  There is an interesting result from graph theory, which says that if you have cycles in your network, then it should have more memory.  We know that we have some <br>  these are characteristic frequencies, and there are cycles in the brain.  A signal runs through them, neurons stimulate <br>  each other in a circle with a given frequency.  In artificial neural networks, we are still <br>  can not play. <br><br>  <b>- Why can not we?</b>  <b>Add cycles!</b>  <b>Please pour the bag out of the bag.</b> <br><br>  - I'll tell you.  How do we learn neural networks?  With back propagation <br>  mistakes.  Reverse error propagation is when you have a neural direct pass. <br>  network and reverse. <br><br>  <b>- As soon as there are cycles, problems immediately begin with the looping of this very</b> <b><br></b>  <b>mistakes?</b> <br><br>  - Yes!  What to do?  How to make back propagation? <br>  Friends, make back propagation on the cycle, and you will make a powerful development breakthrough. <br>  artificial intelligence.  I tell everyone: you need to do this, it's very cool.  This is real <br>  difficult task. <br><br>  <b>- And if these people who are engaged in the brain understand how it works in the brain, it‚Äôs</b> <b><br></b>  <b>can I put?</b>  <b>It would seem that today the anthropomorphism of what we do,</b> <b><br></b>  <b>very low.</b> <br><br>  - Come this way: what is common between ImageNet from Google and clam?  Turns out more or less <br>  everything.  Initially, the mollusk was disassembled and saw that its visual fields are arranged as <br>  modern convolutional networks, if you like.  Sometime in the 50s Rosenblatt and his comrades <br>  disassembled, and invented the perceptron, in many ways looking at the living and very simple things.  They <br>  thought that we now understand how primitive organisms work, and then we will begin to build <br>  complex. <br><br>  <b>‚ÄúWhy didn't they do it?‚Äù</b>  <b>In those days it was believed that the perceptron is not alive.</b> <b><br></b>  <b>Power is not enough?</b> <br><br>  - There are a lot of problems.  Come this way: there were several AI-winters, that is, people every time <br>  coming up with some kind of new breakthrough in the field of artificial intelligence, and they think: ‚ÄúEverything, <br>  tomorrow jarvis will be my best friend and will communicate with me better than my <br>  psychoanalyst".  And then something happens, like that of Jarvis.  I really love this joke <br>  from the movie "Iron Man", where everything goes well first, and then you pronounce some <br>  some cranberries  So Jarvis tells the main character when he asks if he debugged <br>  all systems. <br><br>  <b>- What does it look like in practice?</b>  <b>Where are the restrictions, if you take the application</b> <b><br></b>  <b>the side?</b> <br><br>  - First, now even the most powerful things that we collect artificially, strongly <br>  smaller than our brain just in order of magnitude. <br>  And the second point is related to the fact that we do not understand why they work.  This is a separate <br>  large area of ‚Äã‚Äãresearch. <br><br>  <b>- It would seem, are already starting to tell.</b> <br><br>  - First, we found out what works, then began to understand how it works. <br>  There is a separate direction about how to visualize the work of a neural network.  There is a separate <br>  mathematical formalism, called Information Decomposition, which attempts to describe <br>  how information is decomposed into different streams within the network in order to understand that <br>  what layers going on.  With images, it starts to turn out and it turns out the last <br>  some years.  The lyrics are more complicated. <br><br>  Why we do not understand how it works?  Because we do not have mathematical good <br>  a result that would explain everything to us.  We do not have a proven theorem that would say <br>  that it works.  Because, for example, at the level of the convolutional neural network: you have <br>  picture, on her doggy is drawn.  This picture has so many pixels, each <br>  A pixel has so many values.  If you combinatorially try to count the number <br>  combinations of pixels that still add up to a dog - you get tired.  Have <br>  you, in theory, have a fairly large dimension of space and a lot of options <br>  solutions.  Moreover, if you start to train a convolutional neural network with the number <br>  the parameters are much smaller than the number of potential images of the dog you train <br>  its relatively simple way.  She tells you at the exit whether it's a dog or not a dog, but <br>  you tell her yes or no.  Suddenly, after a while, it turns out that she can <br>  to give very good quality in the pictures of dogs that she did not see. <br><br>  <b>- Is the degree of generalization unexpectedly high?</b> <br><br>  - Yes, this is an unexpected degree of generalization.  Everyone has already come to terms with the fact that it works, everything <br>  apply it everywhere, but strictly grounded mathematical result, which would <br>  explained why such a degree of generalization is possible, no.  And there are several hypotheses, one <br>  of which seems to me the most interesting.  It's not about what's happening in everyone. <br>  neuron, and how you connect these neurons.  The structure of the network itself, apparently, you <br>  allows you to achieve a certain generalization at a certain level.  This is interesting <br>  hypothesis, because if it is correct, then it is well associated with neurophysiology, and then <br>  you can take and try something else from neurophysiology.  There are some other <br>  assumptions, but this is a question: people are still writing kilograms of articles a month about how <br>  works. <br><br>  <b>- There is a feeling that the Python language is an AI language.</b>  <b>Is it a coincidence or not?</b>  <b>Why</b> <b><br></b>  <b>Python, because there are a lot of Basic.</b> <br><br>  - Because quite a large part of the work of Data scientist is now <br>  prototyping.  It is convenient to prototype in Python, it was created as a language for <br>  prototyping, not as a language for industrial solutions.  We have people at ABBYY <br>  who prototype in Python, and there are people who write the final modelki in C ++, <br>  which are implemented.  The Python community is actively using this wave and there is positive feedback.  There is a demand, i.e. data science is increasingly being done on <br>  Python, respectively, the community begins to be saturated with people who are trying <br>  develop the language itself.  All this is connected. <br><br>  <b>- When we talk about prototyping, it involves running a large</b> <b><br></b>  <b>the number of tests, experiments.</b>  <b>Here a computational problem arises</b> <b><br></b>  <b>resources.</b> <br><br>  - The computational resources themselves became cheaper, cloud solutions appeared that made <br>  their affordable.  To put it bluntly, a student with internet access can be briefly reasonable <br>  money to get a fairly powerful server, in order to run something on it and some <br>  get the model, and screw the AI, for example, to the coffee maker.  Many factors have come together that <br>  drive each other.  At the expense of the Internet, the threshold for entering programming and <br>  technology in general.  There was a lot of relatively cheap iron, it also went to <br>  cloud.  You can buy time, not iron.  There was a lot of live data. <br><br>  For example, in the 80s, people involved in data science had a fundamental problem: where <br>  take the data?  And now for a heap of applied tasks it is clear where to get them. <br>  Key elements for machine learning: the algorithm, data and hardware on which this <br>  the algorithm is working.  All these three parameters have become more accessible.  In this case, the algorithm became <br>  more affordable, in the sense that good quality box solutions have appeared.  They <br>  implemented in a language with an intuitively simple syntax, low <br>  level of entry and a bunch of educational resources. <br><br>  <b>- The guys from Microsoft told the story of how a small group took a neural network.</b> <b><br></b>  <b>and the business model of a small, uncomplicated company that delivered bread.</b>  <b>And from the sticks and</b> <b><br></b>  <b>the ropes turned out to build a model that optimized this business and gave + 10%</b> <b><br></b>  <b>to efficiency.</b>  <b>Are such pictures an exception or a rule?</b> <br><br>  - This is more of a rule.  In my opinion, Kelly (a famous futurist) has a good lecture about <br>  the future of AI, in which he says that in 20 years we will be treated the same way as we <br>  We treat those who were pioneers of the Internet.  We are now saying, "How easy it was for you in the 90 <br>  e years to do internet business. "  And after 20 years, they will also treat us, saying: ‚ÄúHow <br>  it was easy for you to do business with AI.  I took everything, added AI to it and became the leader in this <br>  categories".  At least this is Kelly's opinion, and I share it. <br><br>  <b>- You and I experienced a certain amount of what is happening in the industry, and we saw this</b> <b><br></b>  <b>the picture, when what is now commodity, was once the state of art.</b>  <b>Based on his</b> <b><br></b>  <b>of experience, can we advise people who are now part of AI technology where</b> <b><br></b>  <b>and how should they move?</b> <br><br>  - I have two tips that seem reasonable to me.  First, do not do one in the corner. <br>  Find a couple of like-minded people, work with each other and show out <br>  what you do in the wider community.  And secondly, think less about <br>  specific models that you will use, because they will change, <br>  to become better.  And if you are not at the level to improve them yourself, you <br>  you need to know less about exactly how this model works and why it is better.  You need <br>  think more about the problem you are solving. </div><p>Source: <a href="https://habr.com/ru/post/418935/">https://habr.com/ru/post/418935/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../418925/index.html">Big Data - Bro or Not Bro</a></li>
<li><a href="../418927/index.html">Amazon's dark patterns</a></li>
<li><a href="../418929/index.html">Unit Testing and Python</a></li>
<li><a href="../418931/index.html">RubyMine 2018.2: attaching a debugger to remote processes, chruby, improved code analysis, and more</a></li>
<li><a href="../418933/index.html">Review of OnePlus 6. When the Chinese did the same thing as last time</a></li>
<li><a href="../418937/index.html">Celebrating the 8th anniversary of the first release at GeekUniversity</a></li>
<li><a href="../418941/index.html">Do not be afraid of microservice: Alexey Baitov on the use of microservice architecture in practice</a></li>
<li><a href="../418943/index.html">Singing computer, cyborgs and music of the waves - we discuss unusual sounds and audio gadgets</a></li>
<li><a href="../418945/index.html">Best ICO August 2018 (Voting)</a></li>
<li><a href="../418949/index.html">Javascript: tracking variable value changes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>