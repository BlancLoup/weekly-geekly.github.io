<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using Intel Movidius for Neural Networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 We are developing deep neural networks for analyzing photos, videos and texts. Last month we bought a very interesting thing for one of...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using Intel Movidius for Neural Networks</h1><div class="post__text post__text-html js-mediator-article"><h2>  Introduction </h2><br>  We are developing deep neural networks for analyzing photos, videos and texts.  Last month we bought a very interesting thing for one of the projects: <br>  <a href="https://developer.movidius.com/">Intel Movidius Neural Compute Stick</a> . <br><img src="https://habrastorage.org/webt/is/wa/oi/iswaoido0yocnykcomdjbvjmkw0.png" alt="Intel MNCS"><br><br>  This is a specialized device for neural network computing.  In fact, the external video card, sharpened by neural networks, is very compact and inexpensive (~ $ 83).  We want to share the first impressions of working with Movidius.  All interested in asking under the cat. <br><a name="habracut"></a><br><h2>  Computing power of the device </h2><br>  In terms of computing, neurons are extremely voracious: they need GPUs for learning, and for use in real-world tasks, they are also GPUs or powerful CPUs.  Movidius NCS allows you to use deep neural networks on devices that were not originally designed for it, for example: Raspberry Pi, DJI Phantom 4, DJI Spark.  We are talking only about the prediction stage (inference of a pre-trained network): the training of neural networks on Movidius is not yet supported. <br><br>  The chip's performance is about 100 gigaflops, 10 ^ 9 FLOPS, (this roughly corresponds to the level of top-end supercomputers of the early 90s, now it is in the order of hundreds of petaflops, 10 ^ 15). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>For reference: FLOPS is the number of computational operations or instructions that are performed on floating-point (FP) operands per second.</i>  <i>To go deeper into the topic, I recommend the Intel <a href="https://habrahabr.ru/company/intel/blog/144388/">article</a> .</i> <br><br>  The piece of iron is based on the Myriad 2 chip. The Myriad 2 configuration includes 12 specialized programmable vector processors.  The components of the SoC are connected to a high-speed internal connection that works with minimal delays.  Myriad 2 is positioned as a coprocessor in conjunction with an application processor in mobile devices, or as a stand-alone processor in wearable or embedded electronics devices. <br><br><img src="https://habrastorage.org/webt/zj/qk/eb/zjqkebv6rdwfeq5q5jv8nqxwuyu.png" alt="Myriad 2"><br>  <i>Myriad 2 processor itself</i> <br><br>  But in the form factor flash drives (Neural Compute Stick) it can be used to embed neural networks in drones, for example, together with the Raspberry Pi. <br><br><h2>  Let's start the installation and launch of the first program on NCS </h2><br><h4>  What we need </h4><br><ul><li>  Intel Movidius.  Find out where it is sold, you can <a href="https://developer.movidius.com/buy">link</a> .  We took on Amazon. </li><li>  Ubuntu 16.04 LTS or Raspbian OS.  Officially, only they are supported, but in principle, you can try to use on other Linux. </li><li>  SDK from the official repository of the company.  We download it further from the console. </li><li>  Exported from Tensorflow or Caffe binary with neural network weights graph.  The latest version of Movidius only supports Tensorflow or Caffe model formats.  Since we will run the standard example, we will not have to build the graph ourselves. </li></ul><br><h4>  Training </h4><br>  We connect Movidius to the USB 3.0 connector.  Next, write to the console: <br><br><pre><code class="bash hljs">$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/movidius/ncsdk.git $ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ncsdk $ sudo make install</code> </pre> <br>  These commands will install: <br><br><ul><li>  NCS Libraries ‚Üí / usr / local / lib </li><li>  NCS Toolkit binaries ‚Üí / usr / local / bin </li><li>  NCS Include files ‚Üí / usr / local / include </li><li>  NCS Python API ‚Üí / opt / movidius </li></ul><br>  And also add the path to Movidius python-lib in PYTHONPATH. <br><br><h4>  Run an example </h4><br>  In the same folder, run the command to build the examples: <br><br><pre> <code class="bash hljs">$ make examples</code> </pre> <br>  To prepare a standard example ‚Äî an implementation of inception_v1 trained on ImageNet ‚Äî we will execute the following commands: <br><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> examples/tensorflow/inception_v1 $ make all</code> </pre><br>  The last command uses the grid description and the already trained weights and compiles the binary graph, which we can then run on Myriad 2 VPU. <br><br>  Now we run the <a href="https://github.com/movidius/ncsdk/blob/master/examples/tensorflow/inception_v1/run.py">test script run.py.</a>  Briefly tell what happens in the script as a whole (some parts of the script are omitted): <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  NCS, numpy, sys  opencv from mvnc import mvncapi as mvnc import sys import numpy import cv2 #/  / #     graph_filename = 'graph' #      image_filename = path_to_images + 'mouse.jpg' #  NCS-,     , #     devices = mvnc.EnumerateDevices() if len(devices) == 0: print('No devices found') quit() device = mvnc.Device(devices[0]) device.OpenDevice() #   ,   TensorFlow #(  Caffe) with open(path_to_networks + graph_filename, mode='rb') as f: graphfile = f.read() #/  / #      graph = device.AllocateGraph(graphfile) #         img = cv2.imread(image_filename).astype(numpy.float32) dx,dy,dz= img.shape delta=float(abs(dy-dx)) if dx &gt; dy: #crop the x dimension img=img[int(0.5*delta):dx-int(0.5*delta),0:dy] else: img=img[0:dx,int(0.5*delta):dy-int(0.5*delta)] img = cv2.resize(img, (reqsize, reqsize)) img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB) #  for i in range(3): img[:,:,i] = (img[:,:,i] - mean) * std print('Start download to NCS...') graph.LoadTensor(img.astype(numpy.float16), 'user object') #  output, userobj = graph.GetResult() #        NCS- top_inds = output.argsort()[::-1][:5] print(''.join(['*' for i in range(79)])) print('inception-v1 on NCS') print(''.join(['*' for i in range(79)])) for i in range(5): print(top_inds[i], categories[top_inds[i]], output[top_inds[i]]) print(''.join(['*' for i in range(79)])) graph.DeallocateGraph() device.CloseDevice() print('Finished')</span></span></code> </pre><br>  When we collected the example, we entered the command <i>make all</i> into the console, after which useful information was output to the console, for example, you can see how quickly data passes through each layer of the network using the <i>Detailed Per Layer Profile</i> .  Useful for debugging and optimizing stuff. <br><br>  Run the script: <br><br><pre> <code class="bash hljs">$ python3 run.py</code> </pre> <br>  The test image is loaded onto NCS, passes through Inception, and the recognition result is displayed in the console (probability distribution over 1000 + 1 categories of ImageNet dataset). <br><br><div class="spoiler">  <b class="spoiler_title">Console output</b> <div class="spoiler_text"><pre> <code class="bash hljs">Number of categories: 1001 Start download to NCS... ******************************************************************************* inception-v1 on NCS ******************************************************************************* 674 mouse, computer mouse 0.99512 663 modem 0.0037899 614 joystick 0.00031853 528 desktop computer 0.00021553 623 lens <span class="hljs-built_in"><span class="hljs-built_in">cap</span></span>, lens cover 0.0001626 ******************************************************************************* Finished</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Test picture</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/56/mx/ob/56mxobplb7ovdce3uyd0yc_tsqi.jpeg" alt="image">  <i>We uploaded this photo to Movidius and drove it through Inception.</i> </div></div><br>  It can be seen that the network with ~ 99% confidence believes that the picture shows a computer mouse (thanks to our hint :)), the modem is in second place with close to 0% confidence, and so on.  The grid is right, so congratulations on your first neuron, successfully launched on this device! <br><br><h2>  Conclusion </h2><br>  In the end I would like to list the main advantages and disadvantages of the device. <br><br>  First bad news: <br><br><ul><li>  The device officially supports work only with Raspbian OS or Ubuntu 16.04 LTS. </li><li>  The device and its SDK currently only support files with weights of neural networks in the Caffe and Tensorflow format. </li><li>  Only predictions (inference) can be made on the device, and models cannot be trained. </li></ul><br>  Good news: <br><br><ul><li>  You can run neurons on the Raspberry Pi! </li><li>  Very simple python / C API. </li><li>  Low power consumption (1 W), the device is powered by USB. </li><li>  Very fast for such a compact device: for example, preprocessing photos ~ 800x800 and running it through Inception_v1 takes ~ 120-130 milliseconds. </li><li>  There is a collection of ready-to-run open-source models (the so-called <a href="https://github.com/movidius/ncappzoo"><i>Model Zoo</i></a> ). </li><li>  Interestingly, you can connect several NCS at once, which will work out of the box in parallel mode.  However, we have not tested it yet. </li></ul><br><img src="https://habrastorage.org/webt/zq/nh/vw/zqnhvwr1lrgrpizpzcy7emwiqc8.png" alt="image"><br>  <i>So Intel suggests using Movidiuses to speed up computing</i> <br><br>  Of course, this device has analogues. <br><br>  One of them - and the most promising so far - is <a href="https://www.ixbt.com/news/2018/01/02/gyrfalcon-technology-laceli-intel-movidius.html">Gyrfalcon Technology Laceli</a> , which has 28 times more performance and 90 times more energy efficiency.  The only obstacle to buying is that the device has not yet entered the market. <br><br>  Another competitor that has long been on the market is <a href="http://www.nvidia.ru/object/jetson-embedded-systems-ru.html">NVIDIA Jetson TX2</a> .  Differences: <br><br><ul><li>  Very different price categories ($ 559 vs. $ 83) </li><li>  Different capacities (two CPU cores on Denver 2 architecture, four ARM Cortex A57 cores and a 256-core Pascal GPU versus one Myriad 2) </li><li>  Different form factor: Jetson is much bigger, NCS compact </li><li>  Both devices solve the same problem - the task of introducing neurons on board something: a car, a UAV, etc. </li></ul><br>  If interested, we will write in the near future another article about using Jetson TX2 for neural networks.  Thank you for your attention and have a nice day) <br><br>  <b>PS</b> Intel announced the launch of a <a href="http://wwwtc.wpengine.com/Intel-Movidius-Challenge">competition</a> for optimizing neural networks for the Intel Movidius Neural Compute Stick.  Registration is until January 26, the end of the competition - March 15. </div><p>Source: <a href="https://habr.com/ru/post/346958/">https://habr.com/ru/post/346958/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../346948/index.html">How the use of the word ‚Äúblockchain‚Äù allows companies to increase capitalization</a></li>
<li><a href="../346950/index.html">Face control for pets</a></li>
<li><a href="../346952/index.html">Amazon MTurk and Emotion Miner: Crowdsourcing, Big Data, Emotional Technologies</a></li>
<li><a href="../346954/index.html">Inventory (business *) processes through updating job descriptions in the interests of information security</a></li>
<li><a href="../346956/index.html">How to speed up site loading: 7 optimization tips for beginners</a></li>
<li><a href="../346960/index.html">How to start developing universal applications with the Next.js library</a></li>
<li><a href="../346962/index.html">Available AI for any company: Cloud AutoML</a></li>
<li><a href="../346964/index.html">Learn OpenGL. Lesson 4.4 - Clipping of faces</a></li>
<li><a href="../346966/index.html">(Non) security monitoring systems: NagiosXI</a></li>
<li><a href="../346968/index.html">‚ÄúKnowledge Day‚Äù for AI: published by the TOP30 of the most impressive machine learning projects over the past year (v.2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>