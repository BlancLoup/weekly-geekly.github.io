<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Atomic reactor in every site</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Everyone has heard that PHP was created to die . So, this is not entirely true. If you want to - PHP may not die, work asynchronously, and even suppor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Atomic reactor in every site</h1><div class="post__text post__text-html js-mediator-article">  Everyone has heard that <a href="http://habrahabr.ru/post/179399/">PHP was created to die</a> .  So, this is not entirely true.  If you want to - PHP may not die, work asynchronously, and even supports honest multithreading.  But not all at once, this time we will talk about how to make it live for a long time, and the atomic reactor will help us in this! <br><br><img src="https://habrastorage.org/files/3f0/155/79a/3f015579a35b4bea8ca3c9595d78740f.png"><br><a name="habracut"></a><br>  A nuclear reactor is a <a href="https://github.com/reactphp/react">ReactPHP</a> project, the description states ‚ÄúNuclear Reactor Written in PHP‚Äù.  <a href="http://marcjschmidt.de/blog/2014/02/08/php-high-performance.html">This</a> article pushed me to get to know him (the picture above is from there).  I re-read it several times throughout the year, but I could not get to the implementation in practice, although the productivity growth by more than an order of magnitude over the long term was very pleasing. <br><br><h4>  The initial state </h4><br>  CleverStyle CMS, APCu caching engine, version in development, that is, all possible components are installed as the experimental system, the Static pages module page opens in the tests. <br>  A working laptop with a Core i7 4900MQ (4 cores, 8 threads), Ubuntu 15.04 x64 OS acts as a test piece, the disk subsystem consists of two SATA3 SSD in RAID0 (soft, btrfs, while not the best option for the database, turned out to be quite a bottleneck in tests, but there is something there), before each test, sudo sync is run, with each request, 2-4 queries are made to the database (creating a visitor session, not cached at the database level), Nginx has 16 workers. <br>  The conditions are not laboratory, but you need to work with something) <br>  Test performance will be a simple Apache Benchmark. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      First, PHP-FPM (PHP 5.5, 16 workers, statically): <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  nazar-pc @ nazar-pc ~&gt; ab -n5000 -c128 <a href="http://cscms.org/">cscms.org</a> : 8080 / uk <br>  This is ApacheBench, Version 2.3 &lt;$ Revision: $ 1604373&gt; <br>  Copyright 1996 Adam Twiss, Zeus Technology Ltd, <a href="http://www.zeustech.net/">www.zeustech.net</a> <br>  Licensed to The Apache Software Foundation, <a href="http://www.apache.org/">www.apache.org</a> <br><br>  Benchmarking cscms.org (be patient) <br>  Completed 500 requests <br>  Completed 1000 requests <br>  Completed 1500 requests <br>  Completed 2000 requests <br>  Completed 2500 requests <br>  Completed 3000 requests <br>  Completed 3500 requests <br>  Completed 4000 requests <br>  Completed 4500 requests <br>  Completed 5000 requests <br>  Finished 5000 requests <br><br>  Server Software: nginx / 1.6.2 <br>  Server Hostname: cscms.org <br>  Server Port: 8080 <br><br>  Document Path: / uk <br>  Document Length: 99320 bytes <br><br>  Concurrency Level: 128 <br>  Time taken for tests: 22.280 seconds <br>  Complete requests: 5000 <br>  Failed requests: 4239 <br>  (Connect: 0, Receive: 0, Length: 4239, Exceptions: 0) <br>  Total transferred: 498328949 bytes <br>  HTML transferred: 496603949 bytes <br>  Requests per second: 224.41 [# / sec] (mean) <br>  Time per request: 570.373 [ms] (mean) <br>  Time per request: 4.456 [ms] (mean, across all concurrent requests) <br>  Transfer rate: 21842.25 [Kbytes / sec] received <br><br>  Connection Times (ms) <br>  min mean [¬± sd] median max <br>  Connect: 0 0 0.5 0 3 <br>  Processing: 26,563 101.6 541 880 <br>  Waiting: 24,559 101.3 537 872 <br>  Total: 30,564 101.4 541 881 <br><br>  Percentage of the requests served within a certain time (ms) <br>  50% 541 <br>  66% 559 <br>  75% 572 <br>  80% 584 <br>  90% 759 <br>  95% 795 <br>  98% 817 <br>  99% 829 <br>  100% 881 (longest request) <br></div></div><br>  Competitiveness 128, because with 256 PHP-FPM just falls. <br><br>  Now HHVM, for the beginning we will warm up HHVM with the help of 50,000 queries ( <a href="http://hhvm.com/blog/1817/fastercgi-with-hhvm">why</a> ), then we will run the test: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  nazar-pc @ nazar-pc ~&gt; ab -n5000 -c256 <a href="http://cscms.org/">cscms.org</a> : 8000 / uk <br>  This is ApacheBench, Version 2.3 &lt;$ Revision: $ 1604373&gt; <br>  Copyright 1996 Adam Twiss, Zeus Technology Ltd, <a href="http://www.zeustech.net/">www.zeustech.net</a> <br>  Licensed to The Apache Software Foundation, <a href="http://www.apache.org/">www.apache.org</a> <br><br>  Benchmarking cscms.org (be patient) <br>  Completed 500 requests <br>  Completed 1000 requests <br>  Completed 1500 requests <br>  Completed 2000 requests <br>  Completed 2500 requests <br>  Completed 3000 requests <br>  Completed 3500 requests <br>  Completed 4000 requests <br>  Completed 4500 requests <br>  Completed 5000 requests <br>  Finished 5000 requests <br><br>  Server Software: nginx / 1.6.2 <br>  Server Hostname: cscms.org <br>  Server Port: 8000 <br><br>  Document Path: / uk <br>  Document Length: 99309 bytes <br><br>  Concurrency Level: 256 <br>  Time taken for tests: 20.418 seconds <br>  Complete requests: 5000 <br>  Failed requests: 962 <br>  (Connect: 0, Receive: 0, Length: 962, Exceptions: 0) <br>  Total transferred: 498398875 bytes <br>  HTML transferred: 496543875 bytes <br>  Requests per second: 244.88 [# / sec] (mean) <br>  Time per request: 1045.408 [ms] (mean) <br>  Time per request: 4.084 [ms] (mean, across all concurrent requests) <br>  Transfer rate: 23837.54 [Kbytes / sec] received <br><br>  Connection Times (ms) <br>  min mean [¬± sd] median max <br>  Connect: 0 0 1.5 0 8 <br>  Processing: 505 1019 102.6 1040 1582 <br>  Waiting: 505 1017 102.9 1039 1579 <br>  Total: 513 1019 102.5 1040 1586 <br><br>  Percentage of the requests served within a certain time (ms) <br>  50% 1040 <br>  66% 1068 <br>  75% 1080 <br>  80% 1087 <br>  90% 1108 <br>  95% 1126 <br>  98% 1179 <br>  99% 1397 <br>  100% 1586 (longest request) <br></div></div><br>  We received 245 requests per second, and we will work with this. <br><br><h4>  The first steps </h4><br>  I want the code not to depend on whether it is launched from under the HTTP server written in PHP, or in a more familiar mode. <br>  For this, headers_list () / header_remove () and http_response_code (), superglobal $ _GET, $ _POST, $ _REQUEST, $ _COOKIE, $ _SERVER were manually reclaimed. <br>  System classes were destroyed after each request and created with the new. <br>  In general, it worked, but there were nuances: <br><ul><li>  In the case of asynchronous operations where more than one request will be executed simultaneously, everything will be covered with a copper basin </li><li>  Creating all system objects still created significant overhead, although this worked faster than restarting the script. </li><li>  It did not run from PHP-CLI, to send headers you need PHP-CGI, which has memory flowing (for some unknown reason) during a long-running process </li><li>  If someone decides to call exit () / die (), everything dies. </li></ul><br><h4>  Optimization, asynchronous support </h4><br>  Firstly, the system objects were divided into two groups - the first, requests that depend on the user and the specific request, the second - completely independent. <br>  Independent objects ceased to collapse after each request, which gave a significant increase in speed. <br>  The object that receives the request from ReactPHP and forms the response received an additional __request_id field.  Upon receipt of a system object that depends on a specific request using debug_backtrace (), this __request_id is obtained, which makes it possible to separate these objects for each individual request, even when asynchronous. <br>  Also, the system functions that work with the global state were singled out separately; for HTTP servers, modified versions of them were connected, which take into account __request_id.  The _header () functions were added instead of header () (for PHP-CLI headers to work), _http_response_code () instead of http_response_code (), the existing _getcookie () and _setcookie () were modified, the latter under the hood manually forms headers to modify the cookie and sends them to _header (). <br>  Superglobal variables are replaced by array-like objects, and when accessing the elements of such a strange array, we get data corresponding to a specific query - compatibility with regular code is high, the main thing is not to overwrite superglobal variables, and keep in mind that there may not be an array at all (for example, if used with array_merge ()). <br>  As another compromise solution, \ ExitException was added to the system, which replaces exit () / die () calls (including modifying third-party libraries when needed, except for situations when you really need to complete the entire script), this allows you to intercept the output at the top , and avoid executing the script. <br><br>  We test the result on a pool of 16 running Http servers (HHVM interpreter), Nginx balances requests (warming up 50,000 requests to the pool): <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  nazar-pc @ nazar-pc ~&gt; ab -n5000 -c256 <a href="http://cscms.org/">cscms.org</a> : 9990 / uk <br>  This is ApacheBench, Version 2.3 &lt;$ Revision: $ 1604373&gt; <br>  Copyright 1996 Adam Twiss, Zeus Technology Ltd, <a href="http://www.zeustech.net/">www.zeustech.net</a> <br>  Licensed to The Apache Software Foundation, <a href="http://www.apache.org/">www.apache.org</a> <br><br>  Benchmarking cscms.org (be patient) <br>  Completed 500 requests <br>  Completed 1000 requests <br>  Completed 1500 requests <br>  Completed 2000 requests <br>  Completed 2500 requests <br>  Completed 3000 requests <br>  Completed 3500 requests <br>  Completed 4000 requests <br>  Completed 4500 requests <br>  Completed 5000 requests <br>  Finished 5000 requests <br><br>  Server Software: nginx / 1.6.2 <br>  Server Hostname: cscms.org <br>  Server Port: 9990 <br><br>  Document Path: / uk <br>  Document Length: 99323 bytes <br><br>  Concurrency Level: 256 <br>  Time taken for tests: 16.092 seconds <br>  Complete requests: 5000 <br>  Failed requests: 1646 <br>  (Connect: 0, Receive: 0, Length: 1646, Exceptions: 0) <br>  Total transferred: 498418546 bytes <br>  HTML transferred: 496643546 bytes <br>  Requests per second: 310.71 [# / sec] (mean) <br>  Time per request: 823.928 [ms] (mean) <br>  Time per request: 3.218 [ms] (mean, across all concurrent requests) <br>  Transfer rate: 30246.49 [Kbytes / sec] received <br><br>  Connection Times (ms) <br>  min mean [¬± sd] median max <br>  Connect: 0 0 0.9 0 6 <br>  Processing: 100 804 308.3 750 2287 <br>  Waiting: 79 804 308.2 750 2285 <br>  Total: 106 804 308.1 750 2287 <br><br>  Percentage of the requests served within a certain time (ms) <br>  50% 750 <br>  66% 841 <br>  75% 942 <br>  80% 990 <br>  90% 1180 <br>  95% 1381 <br>  98% 1720 <br>  99% 1935 <br>  100% 2287 (longest request) <br></div></div><br>  Already not bad, 310 requests per second is 1.26 times more than HHVM in normal mode. <br><br><h4>  Optimize further </h4><br>  Since initially the code was not written asynchronous - one request before another does not pop up, so you can add the usual, not asynchronous mode, and assume that the requests will be executed strictly in turn. <br>  In this case, we can do with regular arrays in superglobal variables, no need to do debug_backtrace () when creating system objects, and some system objects instead of full re-creation can be partially reinitialized and also save. <br>  This is the result of this on a pool of 16 running Http servers (HHVM), Nginx balances requests (warming up 50,000 requests to the pool): <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  nazar-pc @ nazar-pc ~&gt; ab -n5000 -c256 <a href="http://cscms.org/">cscms.org</a> : 9990 / uk <br>  This is ApacheBench, Version 2.3 &lt;$ Revision: $ 1604373&gt; <br>  Copyright 1996 Adam Twiss, Zeus Technology Ltd, <a href="http://www.zeustech.net/">www.zeustech.net</a> <br>  Licensed to The Apache Software Foundation, <a href="http://www.apache.org/">www.apache.org</a> <br><br>  Benchmarking cscms.org (be patient) <br>  Completed 500 requests <br>  Completed 1000 requests <br>  Completed 1500 requests <br>  Completed 2000 requests <br>  Completed 2500 requests <br>  Completed 3000 requests <br>  Completed 3500 requests <br>  Completed 4000 requests <br>  Completed 4500 requests <br>  Completed 5000 requests <br>  Finished 5000 requests <br><br>  Server Software: nginx / 1.6.2 <br>  Server Hostname: cscms.org <br>  Server Port: 9990 <br><br>  Document Path: / uk <br>  Document Length: 8497 bytes <br><br>  Concurrency Level: 256 <br>  Time taken for tests: 5.716 seconds <br>  Complete requests: 5000 <br>  Failed requests: 4983 <br>  (Connect: 0, Receive: 0, Length: 4983, Exceptions: 0) <br>  Total transferred: 44046822 bytes <br>  HTML transferred: 42381822 bytes <br>  Requests per second: 874.69 [# / sec] (mean) <br>  Time per request: 292.676 [ms] (mean) <br>  Time per request: 1.143 [ms] (mean, across all concurrent requests) <br>  Transfer rate: 7524.85 [Kbytes / sec] received <br><br>  Connection Times (ms) <br>  min mean [¬± sd] median max <br>  Connect: 0 0 0.9 0 7 <br>  Processing: 6,284,215.9,241 976 <br>  Waiting: 6 284 215.9 241 976 <br>  Total: 6,284,215.8,241 976 <br><br>  Percentage of the requests served within a certain time (ms) <br>  50% 241 <br>  66% 337 <br>  75% 409 <br>  80% 442 <br>  90% 623 <br>  95% 728 <br>  98% 829 <br>  99% 869 <br>  100% 976 (longest request) <br></div></div><br>  875 requests per second, this is 3.57 times more than the original version with HHVM, which is good (sometimes there are a couple hundred more requests per second, sometimes a couple hundred less, the weather on the desktop is different, but at the time of writing this article such are). <br><br>  There are also prospects for even greater productivity gains (for example, support for keep-alive and other things in ReactPHP is expected), but much depends on the project where it is used. <br><br><h4>  Restrictions </h4><br>  Since we maintain maximum compatibility with any existing code, asynchronous mode with different time zones requires users to use them explicitly, otherwise date () may return an unexpected result. <br>  Also, downloading files is not supported yet, but 2 pull requests for multipart support already exist, may soon be included in react / http, then it will work here. <br><br><h4>  Underwater rocks </h4><br>  The main pitfall in this mode is a memory leak.  When after completing 1000 requests, the memory consumption was one, and after 5000 requests, a couple of megabytes more. <br>  Tips for catching leaks: <br><ul><li>  Trim the amount of executable code to a minimum, run 5000 requests, log the amount of memory after each execution, compare consumption </li><li>  Add a little executable code, repeat </li><li> Continue until the entire code is checked, the number of requests can be lowered gradually up to 2000 (in order not to wait long), but in case there are doubts, throwing a few thousand more requests will not be superfluous </li><li>  Several requests may be required to stabilize memory consumption, first up to 100 requests, sometimes when you run a full system, up to 800 requests to stabilize memory consumption occurred, after which the amount of memory consumed stops growing. </li><li>  Since the situation is not very mainstream, it may happen that the memory is not flowing in your code, but in a third-party library, or in general PHP extension (PHP-CGI as an example) - here you can wish good luck and not forget about the supervisor on the server :) </li></ul><br>  The second is the connection to the database - it may come off, be prepared to lift it when it falls.  This is absolutely not relevant with the popular approach, it can immediately create problems. <br>  Third, catch errors and do not use exit () / die () unless you mean exactly that. <br>  Fourth, you need to somehow separate the global state of different requests if you are going to work with asynchronous code, if there is no asynchronous code ‚Äî you simply need to fake a global state, the main thing is not to use request-dependent constants, static variables in functions and similar things, unless want to suddenly make a guest admin :) <br><br><h4>  Conclusion </h4><br>  With a similar approach, significant productivity growth can be achieved either without changes or with minimal ones (automatic search and replacement), and with Request / Response frameworks it is even easier to do. <br>  The speed increase depends on the interpreter and what the code does - with heavy calculations, HHVM compiles heavy parts into machine code, when requests to external APIs you can use a less efficient asynchronous mode, but asynchronously load data from an external API (if the request to the API takes hundreds of milliseconds this will give a significant increase in the overall query processing speed). <br>  If you want to try - in CleverStyle CMS this and much more is available out of the box and just works. <br><br><h4>  Sources </h4><br>  <a href="https://github.com/nazar-pc/CleverStyle-CMS/tree/master/components/modules/Http_server">There are not many sources</a> , if desired, it can be modified and used in many other systems. <br>  The class in Request.php accepts a request from ReactPHP and sends the response, functions.php contains functions for working with the global context (including several CleverStyle CMS-specific), Superglobals_wrapper.php contains a class that is used for massive-like superglobal objects, Singleton .php is a modified version of the trait, which is used instead of the system one to create system objects (it also determines which objects are common to all requests and which are not). </div><p>Source: <a href="https://habr.com/ru/post/252013/">https://habr.com/ru/post/252013/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../251993/index.html">Tank Masters - Mobile Tank Puzzle</a></li>
<li><a href="../251995/index.html">"Heavy" applied software: everyday development and implementation</a></li>
<li><a href="../251997/index.html">How to increase advertising revenue in mobile applications</a></li>
<li><a href="../252001/index.html">Automate and speed up the process of setting up cloud servers with Ansible. Part 3: Variables and the inventory file</a></li>
<li><a href="../252003/index.html">Tomorrow at 10:00, see the online broadcast: Cross-Platform Development with Visual Studio 2015</a></li>
<li><a href="../252015/index.html">Overview of glands for practicing robotics with children - 2</a></li>
<li><a href="../252017/index.html">DevCon 2015 Conference: Internet of Things in the World of Living Code</a></li>
<li><a href="../252019/index.html">5 demons in the soul of a support worker</a></li>
<li><a href="../252021/index.html">We write a multiplayer chat on C # in 15 minutes</a></li>
<li><a href="../252023/index.html">Configuring TeamCity in Azure - a constantly available system for team work in the cloud</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>