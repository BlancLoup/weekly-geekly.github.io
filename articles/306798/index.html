<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How many neurons do you need to recognize a bridge summary?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The story began when I moved to live on the island of the Decembrists in St. Petersburg. At night, when the bridges were built, this island together w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How many neurons do you need to recognize a bridge summary?</h1><div class="post__text post__text-html js-mediator-article"><p>  The story began when I moved to live on the island of the Decembrists in St. Petersburg.  At night, when the bridges were built, this island together with Vasilyevsky was completely isolated from the mainland.  At the same time, bridges are often reduced ahead of time, sometimes an hour earlier than the published schedule, but there is no operational information about this anywhere. </p><br><p>  After the second "tardiness" of the bridges, I thought about the sources of information about the early bridges report.  One of the options that came to mind was information from public webcams.  Armed with this data and residual knowledge from <a href="https://habrahabr.ru/company/mipt/blog/298544/">ML specialization from MIPT</a> <a href="https://habrahabr.ru/company/yandex/blog/277427/">and Yandex</a> , I decided to try to solve the problem head on. </p><br><img alt="0, Palace" src="https://habrastorage.org/files/94d/ed4/0df/94ded40dfb2a4326ba69a19493d410a2.JPG"><a name="habracut"></a><br><h2>  First, the cameras </h2><br><p>  With webcams in Petersburg now it is not thick, I managed to find only two live cameras aimed at bridges: from <a href="http://vpiter.com/">vpiter.com</a> and <a href="http://www.rshu.ru/"><abbr title="Russian State Hydrometeorological University">RSHU</abbr></a> .  A few years ago, there were cameras from Skylink, but now they are not available.  On the other hand, even information on the Palace Bridge with vpiter.com alone can be useful.  And it turned out to be more useful than I expected - a comrade-paramedic said that his crew was ambulance, including thanks to operational information about the bridges saved, plus two Petersburgers and one Swede in a week. </p><br><p>  More cameras tend to fall off, give the video stream in a nasty format flv, but all this is very easy to manage ready-made cubes.  Literally two lines of a shell script from a video stream is a set of frames received for classification every 5 seconds: </p><br><pre><code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-literal"><span class="hljs-literal">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> curl --connect-timeout <span class="hljs-variable"><span class="hljs-variable">$t</span></span> --speed-limit <span class="hljs-variable"><span class="hljs-variable">$x</span></span> --speed-time <span class="hljs-variable"><span class="hljs-variable">$y</span></span> http://url/to | \ ffmpeg -loglevel warning -r 10 -i /dev/stdin -vsync 1 -r 0.2 -f image2 $(date +%s).%06d.jpeg <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre> <br><p>  True, there is no classification yet.  First, in the "sausage machine" you need to put the marked data, so leave the script to work at night for a week, and optionally follow the #PeteRT mantra, checking that the pictures are loaded. </p><br><pre> <code class="python hljs">x = io.imread(fname)</code> </pre> <br><p> <a href=""><img alt="1, frame" src="https://habrastorage.org/files/dd7/eb9/fe2/dd7eb9fe235a4cadabc3021df55111c6.jpeg"></a> </p><br><h2>  Secondly - image processing </h2><br><p>  Anyway, having spread my hands and the method of dividing the photos in half into the folders UP, MOVING, DOWN, I received a marked selection.  Andrew Eun <a href="https://www.coursera.org/learn/machine-learning">in his course</a> offered good heuristics "if you can distinguish object A from object B in the picture, then the neural network has a chance."  Let's call this rule of thumb <em>naive UN test</em> . </p><br><p>  First of all, it seems reasonable to crop the image so that it only had a section of the drawbridge.  The TV tower is beautiful, but it doesn't look practical.  Let's write the first line of code that has at least something to do <em>with</em> image <em>processing</em> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[<span class="hljs-number"><span class="hljs-number">40</span></span>:<span class="hljs-number"><span class="hljs-number">360</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>:<span class="hljs-number"><span class="hljs-number">630</span></span>]</code> </pre> <br><p> <a href=""><img alt="2, bridge" src="https://habrastorage.org/files/6a8/67e/1cd/6a867e1cd0e64024bdc37e0d02813eef.jpeg"></a> </p><br><p>  I vaguely heard that real experts take OpenCV, extract features and get decent quality.  But, starting to read the documentation for OpenCV, I felt sad - quite quickly, I realized that I would not be able to work with OpenCV in the set limit ‚Äúto make a prototype in a couple of evenings‚Äù.  But in the library used for reading jpeg-s, skimage for the word <code>feature</code> also <a href="http://scikit-image.org/docs/dev/api/skimage.feature.html">something</a> .  What is the difference between a divorced bridge and a mixed bridge?  Contour against the sky.  Well, let's take <code>skimage.feature.canny</code> , writing a task to read a notebook after a prototype about how the <a href="https://ru.wikipedia.org/wiki/%25D0%259E%25D0%25BF%25D0%25B5%25D1%2580%25D0%25B0%25D1%2582%25D0%25BE%25D1%2580_%25D0%259A%25D1%258D%25D0%25BD%25D0%25BD%25D0%25B8">operator</a> <code>skimage.feature.canny</code> . </p><br><pre> <code class="python hljs">lambdax x: feature.canny(color.rgb2gray(x[<span class="hljs-number"><span class="hljs-number">40</span></span>:<span class="hljs-number"><span class="hljs-number">360</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>:<span class="hljs-number"><span class="hljs-number">630</span></span>]))</code> </pre> <br><p> <a href=""><img alt="3, canny" src="https://habrastorage.org/files/166/27f/33f/16627f33f79b41e29229c6c3421a64ae.png"></a> </p><br><p>  A trolley bus traveling over shaded water looks pretty nice.  Perhaps, bored by this beauty, <a href="https://habrahabr.ru/users/mkot/" class="user_link">mkot</a> regrets that <a href="https://habrahabr.ru/post/252837/">he moved from St. Petersburg,</a> but this picture does not pass the naive UN test - it looks visually noisy.  We'll have to read the <a href="http://scikit-image.org/docs/dev/api/skimage.feature.html">documentation</a> beyond the first argument of the function.  It seems logical that if there are too many borders, then you can blur the image with the proposed Gauss filter.  The default value is <code>1</code> , try to increase it. </p><br><pre> <code class="hljs dos">lambdax x: feature.canny(<span class="hljs-built_in"><span class="hljs-built_in">color</span></span>.rgb2gray(x[<span class="hljs-number"><span class="hljs-number">40</span></span>:<span class="hljs-number"><span class="hljs-number">360</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>:<span class="hljs-number"><span class="hljs-number">630</span></span>]), sigma=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br><p> <a href=""><img alt="4, sigma" src="https://habrastorage.org/files/ae0/3ed/143/ae03ed14321341919f234c8c1770c574.png"></a> </p><br><p>  This is more like data than strokes with a pencil.  But there is another problem, this picture has 166400 pixels, and a couple of thousands of frames are collected overnight, because  Disk space is not infinite.  Surely, if you take these binary pixels as-is, the classifier will simply retrain.  Let us apply the "forehead" method once more - we compress it 20 times. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: transform.downscale_local_mean(feature.canny(color.rgb2gray(x[<span class="hljs-number"><span class="hljs-number">40</span></span>:<span class="hljs-number"><span class="hljs-number">360</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>:<span class="hljs-number"><span class="hljs-number">630</span></span>]), sigma=<span class="hljs-number"><span class="hljs-number">2</span></span>), (<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>))</code> </pre> <br><p> <a href=""><img alt="5, features" src="https://habrastorage.org/files/4b3/637/ce6/4b3637ce685748f7a2ad41af70502a23.png"></a> </p><br><p>  It still looks like bridges, but the image is now only 16x26, 416 pixels.  Having several thousand frames on such a multitude of under-features is no longer very scary to learn and cross-validate.  Now it would be nice to choose the topology of the neural network.  Once Sergei Mikhailovich Dobrovolsky, who gave us lectures on the mat.  analysis, joked that to predict the outcome of the election of the President of the United States is enough one neuron.  It seems that the bridge is not much more complicated construction.  I tried to train a <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">logistic regression model</a> .  As expected, the bridge is not much more complicated than the election, and the model gives quite decent quality with two or three nines on <a href="http://scikit-learn.org/stable/modules/classes.html">all sorts of different metrics</a> .  Although this result looks suspicious (for sure, everything in the data is bad with multicollinearity).  A nice side effect is that the model predicts the probability of the class, not the class itself.  This allows you to draw a funny graph of how the layout of the Palace Bridge looks like for a robot's ‚Äúneuron‚Äù in real time. </p><br><p> <a href=""><img alt="6, wiring" src="https://habrastorage.org/files/06e/1c8/9fb/06e1c89fb85b4931bf6d537f39110f73.png"></a> </p><br><p>  It remains to fasten to this design a push-notification and some kind of interface that allows you to look at the bridge with your eyes if the classifier failed.  The first turned out to be the easiest to do with the Telegram bot, which sends notifications to <a href="https://telegram.me/SpbBridge">the @SpbBridge channel</a> .  The second - from crutches, bootstrap and jquery to make a <a href="http://darkk.net.ru/bridge/now.html">web-snout with live broadcast</a> . </p><br><h2>  Why did I write all this? </h2><br><p>  I wanted to remind you that every problem has a simple, understandable, wrong solution, which nevertheless can be practical. </p><br><p>  And yet, while I was writing this text, the rain, it seems, washed the camera into Neva, which looked at the Palace Bridge together with the server vpiter.tv, which the robot promptly reported. </p><br><p> <a href=""><img alt="7, nomorecam" src="https://habrastorage.org/files/f30/db9/4ea/f30db94ea1814bd7a36c3546bf15764c.jpeg"></a> </p><br><p>  I will be glad if you, in the name of failover, want to share your webcam, which is looking at some drawbridge.  Suddenly, for example, you work in <a href="http://spb112.ru/catalogue/4/"><abbr title="St. Petersburg State Treasury &quot;City Monitoring Center&quot;">St. Petersburg State Medical University "GMC"</abbr></a> . </p><br><p>  PS: And here is the <a href="https://habrahabr.ru/post/307218/">version with a slightly larger number of neurons</a> , but more automatic feature extraction. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/306798/">https://habr.com/ru/post/306798/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../306788/index.html">How to display dynamic unloading from the database on Atlassian Confluence pages?</a></li>
<li><a href="../306790/index.html">Expanded commentary on the articles "Systematization of publications in the web"</a></li>
<li><a href="../306792/index.html">We create stub services for integration testing on Apache Camel (using Scala DSL)</a></li>
<li><a href="../306794/index.html">July update of Microsoft Azure and VNET peering</a></li>
<li><a href="../306796/index.html">Introducing 3CX Phone System v15 SP1 and test the system on a mini PC instead of a server</a></li>
<li><a href="../306802/index.html">The digest of interesting materials for the mobile # 164 developer (July 25-31)</a></li>
<li><a href="../306804/index.html">Myths about FreeBSD</a></li>
<li><a href="../306806/index.html">"Working with a microscope": The data storage revolution</a></li>
<li><a href="../306808/index.html">Remote control server daemon do it yourself</a></li>
<li><a href="../306810/index.html">De-anonymize Windows users and get Microsoft and VPN account credentials</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>