<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Myths about Spark, or Can a Sparkle Java Developer Use Spark?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We continue to decode and in some places improve the hardcore reports of speakers of JPoint 2016. Today the report is smaller, only an hour with a pen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Myths about Spark, or Can a Sparkle Java Developer Use Spark?</h1><div class="post__text post__text-html js-mediator-article">  We continue to decode and in some places improve the hardcore reports of speakers of JPoint 2016. Today the report is smaller, only an hour with a penny, respectively, the concentration of benefit and annealing for one minute exceeds the limit. <br><br>  So, Evgeny <a href="https://habrahabr.ru/users/evgenyborisov/" class="user_link">EvgenyBorisov</a> Borisov about Spark, myths and a little about whether Pink Floyd's texts are more <a href="https://habrahabr.ru/users/evgenyborisov/" class="user_link">valid</a> than Katy Perry‚Äôs. <br><br><hr><br><iframe width="560" height="315" src="https://www.youtube.com/embed/XLSQJQjmFFw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      This will be an unusual report on Spark. <br><br>  Usually they talk a lot about Spark, how cool it is, they show Scala code.  But I have a slightly different goal.  First, I will talk about what Spark is and why it is needed.  But the main goal is to show that you, as Java developers, can perfectly use it.  In this report we will dispel a few myths about Spark. <br><a name="habracut"></a><br><h2>  Briefly about yourself </h2><br>  I have been a Java programmer since 2001. <br>  By 2003, he started teaching in parallel. <br>  Since 2008, began to engage in consultations. <br>  Since 2009, engaged in the architecture of different projects. <br>  Startup opened in 2014. <br>  Since 2015, I have been the technical leader for Big data at Naya Technologies, which implements big data wherever it can.  We have a huge number of clients who want us to help them.  We are sorely lacking people who understand new technologies, so we are constantly looking for employees. <br><br><h2>  Myths about Spark </h2><br>  There are quite a few myths about Spark. <br><br>  First, there are some conceptual myths about which we will talk in more detail: <br><br><ul><li>  that Spark is some kind of lotion for Hadoop.  Many have heard that Spark and Hadoop seem to be together.  Talk about whether this is true; <br><br></li><li>  that Spark should be written on Scala.  Everyone has probably heard that Spark can be written not only on Scala, but it is right to do it on Scala, because the native API, etc.  We'll talk whether this is right; <br><br></li><li>  I love Spring and wherever possible, I use post-processors.  Will post-processors really bring any benefits here? <br><br></li><li>  Let's talk about what's happening with Spark testing.  Since Spark is big data, it is not very clear how to test it.  There is a myth that it is impossible to write tests at all, and if you write, then everything will look completely different from what we are used to. <br></li></ul><br>  There are a number of technical myths (this is for people who work with Spark or more or less know it): <br><br><ul><li>  about Broadcast - that in certain cases it must be used, otherwise everything will crash down.  Let's talk about whether this is so. <br><br></li><li>  about data frames - They say that data frames can only be used for files that have a scheme, and we will talk about whether you can use them in other cases. <br></li></ul><br>  And the most important myth is about the Pink Floyd group.  There is a myth that Pink Floyd wrote (wrote) clever texts, not at all like Britney Spears or Katie Perry.  And today we will write a sentence on Spark, which will help analyze the lyrics of all these musicians and reveal similar words in them.  Let's try to prove that Pink Floyd is writing the same rubbish as pop performers. <br><br>  Let's see which of these myths will turn out to be refuted. <br><br><h3>  Myth 1. Spark and Hadoop </h3><br>  By and large, Hadoop is just a repository of information.  This is a distributed file system.  Plus, it offers a specific set of tools and an API, with which this information can be processed. <br><br>  In the context of Spark, it is more correct to say that it is not Spark that needs Hadoop, but vice versa, because information that can be stored in Hadoop and processed using its tools (when faced with a performance problem) can be processed faster using Spark. <br>  The question is, does Spark need Hadoop to work? <br><br>  Here is the definition of Spark: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4dc/3f5/634/4dc3f5634009923c1e5d5c8f5d3eeecb.png"><br><br>  Is there the word Hadoop?  There are Spark modules here: <br><br><ul><li>  Spark Core is a specific API that allows you to process your data; <br><br></li><li>  Spark SQL, which makes it possible to write SQL-like syntax for people who are familiar with SQL (we‚Äôll talk separately about whether this is good or bad); <br><br></li><li>  Machine Learning module; <br><br></li><li>  Streaming so that you can thrust information using Spark or listen to something. <br></li></ul><br>  But here there is no word Hadoop. <br><br>  Let's just talk about Spark. <br>  This idea originated at the University of Berkeley around 2009.  The first release was released not so long ago - in 2012. Today we are on version 2.1.0 (it was released at the end of 2016).  At the time of the dubbing of this report, version 1.6.1 was relevant, but they promised a speedy release of Spark 2.0, where they cleaned the API and added many new useful things (Spark 2.0 innovations are not taken into account here). <br><br>  Spark itself is written on Scala, which explains the myth that using Spark is better with Scala, because it turns out the native API.  But besides the Scala API exists for: <br><br><ul><li>  Python <br></li><li>  Java, <br></li><li>  Java 8 (separately) <br></li><li>  and R (statistical tool). <br></li></ul><br>  You can write Spark in InteliJ, which I will do today in the report.  You can use Eclipse, and there are more special things for Spark - this is Spark-shell, which now comes with certain versions of Hadoop, where you can write Spark live commands and get instant results, and Notebooks very similar to it - there you can still save what you write for reuse. <br><br>  You can run Spark in Spark-shell and Notebooks - there it is embedded;  using the Spark-submit command, you can start the Spark application on the cluster, you can run it as a normal Java process (java -jaar and say what main is called and where your code is written).  Today we will launch Spark in the report.  For those tasks that we want to solve, the local machine is enough.  But if we wanted to run it on a cluster, we would need a cluster manager.  This is the only Spark need.  Therefore, it is often the illusion that without Hadoop in any way, because  Hadoop has Yarn, a cluster manager that can be used to distribute Spark tasks across the entire cluster.  But there is an alternative option - Mesos - cluster manager, which has no relation to Hadoop.  It has existed for a long time, and about a year ago they received $ 70 million, which indicates a good development of technology.  In principle, who really dislikes Hadoop, can run Spark tasks on a cluster with absolutely no Yarn and Hadoop. <br><br>  I will say literally two words about data locality.  What is the idea of ‚Äã‚Äãprocessing big data, which are not on the same machine, but on a large number of them? <br><br>  When we write some code that works, for example, with jdbc or ORM, what actually happens?  There is a machine that starts the Java process, and when the code that accesses the database runs in this process, all data is read from the database and transferred to where the Java process is running.  When we talk about big data, it is impossible to do this, because there is too much data - it is inefficient and we have a bottle neck.  In addition, data is already distributed and is initially located on a large number of machines, so it‚Äôs better not to pull data to this process, but to distribute the code to the machines on which we want to process this ‚Äúdate‚Äù.  Accordingly, this happens in parallel on many machines, we use an unlimited amount of resources, and here we need a cluster manager who will coordinate these processes. <br><br>  In this picture you see how it all works in the world of Spark. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/273/74c/9ac/27374c9acabcdb78000c60175852f048.png"><br><br>  We have a Driver - our main, which runs on a separate machine (not related to the cluster).  When we submit our Spark application, we turn to Yarn, who is a resource manager.  We tell him how many workers to use under our Java process (for example, 3).  He chooses one machine from the cluster machines, which will be called the Application Master.  Its task is to get the code and find three machines in the cluster for its execution.  There are three machines, three separate Java-processes rise (three executor), where our code is launched.  Then this is all returned by the Application Master, and eventually it returns it directly to the Driver if we want the result of the operation on big data to get back to where the code came from. <br><br>  This is not directly related to what I will talk about today.  Just in a nutshell, how Spark works with Cluster Manager (in this example with Yarn) and why we are not limited in resources (except in cash - how much we can afford machines, memory, etc.).  It's all a bit like the classic MapReduce - the old API that was in Hadoop (in principle, it still exists now), with the only difference being that when this API was written, the machines were not strong enough, the intermediate results of the data could only be stored on disk because there was not enough space in the RAM.  Therefore, it all worked slowly.  As an example, I can say that we recently rewrote the code that was written in the old MapReduce and it ran around 2.5 hours.  He now works 1.5 minutes on Spark, because Spark stores everything in RAM - it turns out much faster. <br><br>  It is very important to understand when you write code that one part of it will be executed on the cluster, and the other part on the Driver.  For people who do not understand this, very often OutOfMemory happens, etc.  (we'll talk about it - I will show examples of these errors). <br><br>  So, Spark ... let's go <br><br>  RDD (resilient distributed dataset) is the main component that runs the entire Spark. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/389/22c/216/38922c216ba4a7d882563aa1069e2779.png"><br><br>  Let's start with the term dataset - it's just a repository of information (Collection).  His API is very similar to Stream.  In fact, like Stream, it is not a data warehouse, but a kind of abstraction on data (in this case also distributed) and allows you to run all sorts of functions on this data.  Unlike Stream, RDD was initially Distributed ‚Äî it was not on one RDD machine, but on the number of machines that we allowed to use when Spark was started. <br><br>  Resilient says that you won‚Äôt kill him, because if some machine turned off during data processing (something happened there, for example, they turned out the lights), the cluster manager will be able to pick up another machine and transfer the java-process there, and RDD will recover.  We will not even feel it. <br>  Where can I get RDD? <br><br><ul><li>  the most common option is from a file or directory in which there are files of a certain type.  I can create RDD from some file (just like Stream needs a data source); <br><br></li><li>  from memory - from some collection or list.  It is most often used for tests.  For example, I wrote some service that accepts RDD as input with some initial data and returns RDD with processed data as output.  When I test it, I really don‚Äôt want to read data from a disk.  I want to create a collection in the test.  I have the opportunity to turn this collection into RDD and test my service; <br><br></li><li>  from another RDD in the same way as streams.  Most stream methods return the stream back - everything is very similar. <br></li></ul><br>  Here are some examples of how we create RDD: <br><br><pre><code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">// from local file system JavaRDD&lt;String&gt; rdd = sc.textFile("file:/home/data/data.txt"); // from Hadoop using relative path of user, who run spark application rdd = sc.textFile("/data/data.txt") // from hadoop rdd = sc.textFile("hdfs://data/data.txt") // all files from directory rdd = sc.textFile("s3://data/*") // all txt files from directory rdd = sc.textFile("s3://data/*.txt")</span></span></code> </pre> <br>  We will discuss what sc is a bit later (this is such a Spark starting object).  Here we create an RDD: <br><br><ul><li>  from a text file that is in the local directory (there is nothing to do with Hadoop); <br><br></li><li>  from file by relation path; <br><br></li><li>  with Hadoop - here I take the file that is in Hadoop.  It is actually broken into pieces, but it will assemble into one RDD.  Most likely the RDD will be located on the machines where this data is located; <br><br></li><li>  You can read it with s3 storage, you can use any wildcard or take only text files from the data directory. <br></li></ul><br>  What will this RDD be?  It says here that it is RDD (there is a string in the text file).  Moreover, it does not matter if I created RDD from a file (these are the lines of the given file) or from a directory (these are the lines of all the files in this directory). <br><br>  This is how RDD is created from memory: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cf1/d77/acf/cf1d77acfa9838dedcd05939915b22ca.png"><br><br>  You have a parallelize method that takes a list and turns it into RDD. <br><br>  Now we come to the question of what sc is, which we constantly used to get RDD.  If we work with Scala, this object is called SparkContext.  In the Java API world, it is called JavaSparkContext.  This is the main point from which we start writing the code associated with Spark, because from there we get RDD. <br><br>  Here is an example of how a Java Spark context object is configured: <br><br><pre> <code class="java hljs">SparkConf conf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SparkConf(); conf.setAppName(<span class="hljs-string"><span class="hljs-string">"my spark application"</span></span>); conf.setMaster(<span class="hljs-string"><span class="hljs-string">"local[*]"</span></span>); JavaSparkContext sc = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaSparkContext(conf);</code> </pre><br>  The Spark-configuration object is created first, it is configured (you say what the application is called), then you specify whether we work locally or not (the asterisk says how many threads you will find, so much you can use; you can specify 1, 2, etc. d.).  And then I create a JavaSparkContext and pass the configuration here. <br><br>  Then the first question arises: how to divide everything?  If I create SparkContext in this way and give it a configuration here, it will not work on a cluster.  I need to separate it so that I don‚Äôt have anything written on the cluster here (because when the Spark process starts, I need to say how many machines to use, who is the master, who is the cluster manager, and so on).  I do not want this configuration to be here;  I want to leave only the application name. <br><br>  And here Spring comes to the rescue: we make two beans.  We have one under the production profile (it generally does not convey any information about who the master is, how many machines, etc.), the other under the local profile (and here I pass on this information; you can easily share it immediately).  For tests, one bean will work from SparkContext, and for production - another. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-meta"><span class="hljs-meta">@Profile</span></span>(<span class="hljs-string"><span class="hljs-string">"LOCAL"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> JavaSparkContext </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ SparkConf conf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SparkConf(); conf.setAppName(<span class="hljs-string"><span class="hljs-string">"music analyst"</span></span>); conf.setMaster(<span class="hljs-string"><span class="hljs-string">"local[1]"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaSparkContext(conf); } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-meta"><span class="hljs-meta">@Profile</span></span>(<span class="hljs-string"><span class="hljs-string">"PROD"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> JavaSparkContext </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ SparkConf conf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SparkConf(); conf.setAppName(<span class="hljs-string"><span class="hljs-string">"music analyst"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaSparkContext(conf); }</code> </pre><br>  Here is a list of the features that RDD has. <br><br><pre> <code class="java hljs">map flatMap filter mapPartitions, mapPartitionsWithIndex sample union, intersection, join, cogroup, cartesian (otherDataset) distinct reduceByKey, aggregateByKey, sortByKey pipe coalesce, repartition, repartitionAndSortWithinPartitions</code> </pre><br>  They are very similar to the Stream functions: also all Immutable, also return RDD (in the Stream world this was called intermediate operations, and here - transformations).  We will not go into details now. <br><br>  There are also Actions (in the Stream world, this was called terminal operations). <br><br><pre> <code class="java hljs">reduce collect count, countByKey, countByValue first take, takeSample, takeOrdered saveAsTextFile, saveAsSequenceFile, saveAsObjectFile foreach</code> </pre><br>  How to determine what is Action, and what is Transformation?  As in streams, if the RDD method returns an RDD, this is a Transformation.  If not, then this is Action. <br><br>  Action exists of two types: <br><br><ul><li>  those that return something back to the Driver (it is important to emphasize that this will not be on the cluster; the answer will return to the Driver).  For example, reduce takes the function of how to collect all the data, and eventually one answer will return (in general, it does not have to be one); <br><br></li><li>  those that do not return a response to the Driver.  For example, you can save the data after processing to the same Hadoop or another storage (for this is the saveAsTextFile method). <br></li></ul><br>  How does everything work? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e27/0c6/aa7/e270c6aa71a2ddb610ac56458d696aed.png"><br><br>  This scheme is similar to streams, but there is one small nuance.  We have some kind of data, which is, for example, in s3 storage.  Using SparkContext, I created my first RDD1.  Then I do all sorts of different transformations, each of which returns me an RDD.  In the end, I do Action and get some kind of benefit (saved, printed out or sent what I did).  This piece, of course, runs on the cluster (all RDD methods run on the cluster).  A small piece at the end will run on the Driver in the event that the result will be some kind of answer.  Anything to the left of Data (that is, before I started using the Spark code) will also run on the Driver, and not on the cluster. <br><br>  All this is Lazy - just like in a stream.  Each RDD method, which is a transformation, does nothing, but waits for Action.  When there is an Action, the whole chain will start.  And here comes the classic question: what are we doing here in this case? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12f/42c/a4a/12f42ca4ae164684c9ca66b49782a263.png"><br><br>  Imagine that my data is all monetary transactions for the last 5 years in some bank.  And I need to conduct a fairly long treatment, and then it is divided: for all men, I want to make one Action, and for all women - another.  Suppose my first part of the process takes 10 minutes.  The second part of the process will require a minute.  It would seem that we should have a total of 12 minutes? <br><br>  No, we have 22 minutes, because Lazy - every time an Action is launched, the whole chain is run from beginning to end.  In our case, the common piece runs only 2 times, but if we had 15 branches? <br><br>  Naturally, it is very hard on performance.  In the Spark world, it is very easy to write code, especially for people who are familiar with functional programming.  But the nonsense is obtained.  If you want to write effective code, you need to know many features. <br><br>  Let's try to solve the problem.  What do we do in stream?  They would make some kind of collect, collect it all in a collection, and then pull it out of it. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0af/5f6/79f/0af5f679f99e6e2f9093274ab0a5df5d.png"><br><br>  In GetTaxi tried, but it turned out like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6c9/e95/dfe/6c9e95dfe8e38bf032e9c7f765085ef8.png"><br><br>  Moreover, they were going to buy more machines per cluster, so that there were 40 of them and each with 20 gigabytes of RAM. <br><br>  It is necessary to understand: if we are talking about big data, at the moment when you do collect, all the information from all RDDs is returned to you at the Driver.  Therefore, jigabytes and machines do not help them at all: when they make a collect, all the information is merged into one place from which the application started.  Naturally, it turns out out of memory. <br><br>  How to solve this problem (you do not want to drive the chain twice, 15 - all the more, and you can't do collect)?  For this, Spark has a persist method: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/03f/6ce/48e/03f6ce48e2aba1bec7cb0df87f6997fc.png"><br><br>  Persist allows you to save the state RDD, and you can choose where to save.  There are many options for saving.  The most optimal is in memory (there is memory only, but there is memory only 2 - with two backups).  You can even write your custom storage and tell how to save it.  You can save memory and disk - try to save to memory, but if this worker (the machine that runs this RDD) does not have enough RAM, some will be written into memory, and the remnants will be dumped to disk.  You can save data as an object or do serialization.  Each of the options has its pros and cons, but there is such an opportunity, and it is wonderful. <br><br>  We beat this problem.  Persist is not an action.  If there is no action, persist will do nothing.  When the first action starts, the whole chain is run and at the end of the first part of the RDD chain it persists on all machines where data is located.  When we start the action RDD6, we start already with persist (if there were other branches, we would continue from the point that we have ‚Äúremembered‚Äù or ‚Äúmarked‚Äù persist). <br><br><h3>  Myth 2. Spark write only on Scala </h3><br>  Spark is great, it can be used even for some local needs, not necessarily for big data.  You can simply use its API for data processing (it is really convenient).  The question arises: what to write?  Python and R I dismissed immediately.  We will find out: Scala or Java? <br>  What does a regular Java developer think about Scala? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f0/7fe/71d/3f07fe71db379b9f820d728028c49eb8.png"><br><br>  An advanced Java-developer sees a little more.  He knows that there is some kind of play, some cool frameworks, lambdas and a lot of Chinese. <br><br>  Remember the ass?  Here she is.  This is what Scala code looks like. <br><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> lines = sc.textFile(<span class="hljs-string"><span class="hljs-string">"data.txt"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> lineLengths = lines.map(_.length) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> totalLength = lineLengths.reduce(_+_)</code> </pre><br>  I will not go into the Scala API now, because my ultimate goal is to convince you that writing in Java is no worse, but this code considers the length of each line and summarizes the whole thing. <br><br>  A very strong argument against Java is that the same Java code looks like this: <br><br><pre> <code class="java hljs">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="hljs-string"><span class="hljs-string">"data.txt"</span></span>); JavaRDD&lt;Integer&gt; lineLengths = lines.map(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Function&lt;String, Integer&gt;() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Integer </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String lines)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lines.length(); } }); Integer totalLength = lineLengths.reduce(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Function2&lt;Integer, Integer, Integer&gt;() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Integer </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Integer a, Integer b)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a + b; } });</code> </pre><br>  When I started the first project, the bosses asked if I was sure?  After all, when we write, the code will be more and more.  But this is all a lie.  Today's code looks like this: <br><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> lines = sc.textFile(<span class="hljs-string"><span class="hljs-string">"data.txt"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> lineLengths = lines.map(_.length) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> totalLength = lineLengths.reduce(_+_)</code> </pre><br><pre> <code class="java hljs">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="hljs-string"><span class="hljs-string">"data.txt"</span></span>); JavaRDD&lt;Integer&gt; lineLengths = lines.map(String::length); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> totalLength = lineLengths.reduce((a, b) -&gt; a + b);</code> </pre><br>  Do you see a strong difference between Scala and Java 8?  It seems to me that for Java programmers this is more readable.  But even despite Java 8, we come to the myth that Spark should be written on Scala.  How do people who know that Java 8 is not so bad argue that you need to write on Scala? <br><br>  For Scala: <br><br><ul><li>  Scala is cool, hipster, fashionable, right, you have to move forward.  Nafig this Groovy, in Scala everything is definitely cooler; <br><br></li><li>  Scala - concise and convenient syntax.  There is a butt; <br><br></li><li>  Spark API, because it is written in Scala, is primarily sharpened for Scala.  This is a serious plus; <br><br></li><li>  Java API comes out a little later, because they have to file it, fake it.  There is not always everything. <br></li></ul><br>  For Java: <br><br><ul><li>  most java programmers know java.  These people do not know Scala.  In large companies, a bunch of Java programmers, who more or less understood Java.  Giving them Scala to write Spark?  Not; <br><br></li><li>  familiar world - there is Spring, familiar design patterns, Maven or even better - Gradle, singleton, etc.  We used to work there.  And Scala is not only a different syntax, it is a lot of other concepts.  In Scala, control inversion is not needed, since  everything is different there. <br></li></ul><br>  Why is Java still better?  Because we, of course, love Scala, but the money in Java. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/1ec/411/9d71ec411c7f24dfad6fe5e9d1380f6e.png"><br><br>  Listen to the podcast - <a href="http://razbor-poletov.com/2016/08/episode-114.html">Issue 104</a> - which discusses what happened. <br><br>  I will tell you in a few words. <br><br>  A year ago, Martin Odersky, who opened Typesafe in 2010, closed it.  No more Typesafe company that supports Scala. <br><br>  This does not mean that Scala died, because instead of Typesafe another company opened - Lightbend, but it has a completely different business model.  They came to the conclusion that even thanks to the cool things written on Scala, like Play, Akka and Spark, and even thanks to the pope mentioned above, it is impossible to get the masses to go to work on Scala.  A year ago, Scala was at the peak of its popularity, despite that it was not even included in the first 40 places in the ranking.  For comparison - Groovy was on the twentieth, Java - on the first. <br><br>  When they realized that even at the peak of popularity they still didn‚Äôt force people to use Scala among the masses, they recognized their business model as wrong.  The company, which today will cut Scala, has a different business model.  They say that all products that will be made for the masses, like Spark, will have an excellent Java API.  And when we get to the data frames, you will see that there is no longer any difference whether to write in Scala or in Java. <br><br><h3>  Myth 3. Spark and Spring are incompatible. </h3><br>  First, I have already shown you that I have a SparkContext, which is registered as a bean.  Next we will see how, with a postprocessor bean, we can support some functionality for Spark. <br><br>  Let's write the code. <br><br>  We want to write a service (auxiliary) that accepts RDD lines and the number of top words.  His task is to return top words.  Let's see in the code what we are doing. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;String&gt; lines, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lines.map(String::toLowerCase) .flatMap(WordsUtil::getWords) .mapToPair(w -&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple2&lt;&gt;(w, <span class="hljs-number"><span class="hljs-number">1</span></span>)) .reduceByKey((a, b) -&gt; a + b) .mapToPair(Tuple2::swap) .sortByKey().map(Tuple2::_2).take(x); } }</code> </pre><br>  Firstly, since we do not know whether the words of the songs are in lowercase or uppercase, we need to translate everything into lowercase so that we do not count words from a capital letter and a small letter two times.  Therefore, we use the map function.  After that, you need to turn strings into words using the flatmap function. <br><br>  Now we have an RDD with words in it.  We map it against their number.  But first you just need to assign each word to one.  It will be a classic pattern: we will have the word - 1, the word - 1, then all units against the same words will have to be summed and sorted (everything works in memory, and no intermediate results are stored on the disk if there is enough memory). <br><br>  We have a mapToPair function - now we will create pairs.  The problem is that in Java there is no class Pair.  In fact, this is a big omission, because very often we have some information that we want to combine in a specific context, but writing a class is stupid. <br><br>  The Rock has ready-made classes (there are a lot of them) - Tuple.  There are Tuple2, 3, 4, etc.  to 22. Why to 22?  No one knows.  We need Tuple2, because we map 2. <br><br>  Now all this must reduce-it.  We have a reduceByKey method, which will leave all the same words as the key, and with all the values ‚Äã‚Äãwill do what I ask.  We need to fold.  We have made a pair: the word - the amount. <br><br>  Now you need to sort.  Here we have again a small problem with Java, since  the only thing we have sort is sorkByKey.  The Scala API is just sortby and there you take this Tuple and pull everything you want out of it.  And here - only SortByKey. <br><br>  As I said, we still feel in some places that the Java API is not rich enough.  But you can get out.  For example, you can turn our pair.  To do this, we once again do mapToPair, and Tuple has a built-in swap function (it turned out a couple number - words).  Now we can do sortByKey. <br><br>  After that, you need to pull out not the first, but the second part.  Therefore, we make a map.  For pulling out the second part, Tuple has a ready-made function "_2".  Now we do Take (x) (we only need x words - the method is called TopX), and this can all be returned. <br><br>  I'll show you how the test is done.  But before that, look at what's in my Java config on Spring (we work on Spring, and this is not just a class, but a service). <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Configuration</span></span> <span class="hljs-meta"><span class="hljs-meta">@ComponentScan</span></span>(basePackages = <span class="hljs-string"><span class="hljs-string">"ru.jug.jpoint.core"</span></span>) <span class="hljs-meta"><span class="hljs-meta">@PropertySource</span></span>(<span class="hljs-string"><span class="hljs-string">"classpath:user.properties"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AppConfig</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> JavaSparkContext </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ SparkConf conf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SparkConf().setAppName(<span class="hljs-string"><span class="hljs-string">"music analytst"</span></span>).setMaster(<span class="hljs-string"><span class="hljs-string">"local[*]"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> JavaSparkContext(conf); } <span class="hljs-meta"><span class="hljs-meta">@Bean</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> PropertySourcesPlaceholderConfigurer </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">configurer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> PropertySourcesPlaceholderConfigurer(); } }</code> </pre> <br>  In Java config, I read some user.properties (I will explain later why; now I don‚Äôt use it anyway).  I also scan all classes and prescribe two beans: PropertySourcePlceholderConfigurer - so that you can inject something from a property file, this is not yet relevant;  and the only bean that interests us right now is the usual JavaSparkContext. <br><br>  I created SparkConf, set it up (the program is called music analyst), told him that we have a master (we work locally).  We created a JavaSparkContext - everything is great. <br><br>  Now watch the test. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@RunWith</span></span>(SpringJUnit4ClassRunner.class) <span class="hljs-meta"><span class="hljs-meta">@ContextConfiguration</span></span>(classes = AppConfig.class) <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsServiceImplTest</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> JavaSparkContext sc; <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> PopularWordsService popularWordsService; <span class="hljs-meta"><span class="hljs-meta">@Test</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">textTopX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ JavaRDD&lt;String&gt; rdd = sc.parallelize(Arrays.asList(‚Äújava java java scala grovy grovy‚Äù); List&lt;String&gt; top1 = popularWordsService.topX(rdd, <span class="hljs-number"><span class="hljs-number">1</span></span>); Assert.assertEquals(‚Äújava‚Äù,top1.get(<span class="hljs-number"><span class="hljs-number">0</span></span>)); } }</code> </pre> <br>  Since we are working with Spring, the runner is naturally spring.  Our configuration is AppConfig (it would be correct to make different configurations for testing and for production).  Next, we inject here a JavaSparkContext and the service we want to check.  With SparkContext, I use the parallelize method and pass the string ‚Äújava java java scala grovy grovy‚Äù there.  Next, I run the method and check that Java is the most popular word. <br><br>  The test fell.  Because the most popular is scala. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd2/ae7/cdc/cd2ae7cdc9270b87830dc6264efca597.png"><br><br>  What did I forget to do?  When I did Sort, I had to sort it the other way. <br>  We fix in our service: <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;String&gt; lines, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lines.map(String::toLowerCase) .flatMap(WordsUtil::getWords) .mapToPair(w -&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple2&lt;&gt;(w, <span class="hljs-number"><span class="hljs-number">1</span></span>)) .reduceByKey((a, b) -&gt; a + b) .mapToPair(Tuple2::swap).sortByKey(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>).map(Tuple2::_2).take(x); } }</code> </pre> <br>  The test passed. <br><br>  Now let's try to start main and see the result on a real song.  I have a data directory, there is a folder called Beatles, which contains the text of a single song: yesterday.  What do you think is the most popular word in yesterday? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a67/ca5/9bb/a67ca59bb86b91b81db87f35df7e6f94.png"><br><br>  Here I have the service ArtistsJudge.  We have implemented the TopX method - it takes the name of the artist, adds the directory in which the songs of this artist are located, and then uses the topX method of the service already written. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ArtistJudgeImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ArtistJudge</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> PopularDFWordsService popularDFWordsService; <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> WordDataFrameCreator wordDataFrameCreator; <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${path2Dir}"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String path; <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String artist, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ DataFrame dataFrame = wordDataFrameCreator.create(path + <span class="hljs-string"><span class="hljs-string">"data/songs/"</span></span> + artist + <span class="hljs-string"><span class="hljs-string">"/*"</span></span>); System.out.println(artist); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> popularDFWordsService.topX(dataFrame, x); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compare</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String artist1, String artist2, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ List&lt;String&gt; artist1Words = topX(artist1, x); List&lt;String&gt; artist2Words = topX(artist2, x); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> size = artist1Words.size(); artist1Words.removeAll(artist2Words); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> size - artist1Words.size(); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span></span>{ List&lt;String&gt; list = Arrays.asList(<span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>); Comparator&lt;String&gt; cmp = Comparator.nullsLast(Comparator.naturalOrder()); System.out.println(Collections.max(list, cmp)); <span class="hljs-comment"><span class="hljs-comment">/* System.out.println(list.stream().collect(Collectors.maxBy(cmp)).get()); System.out.println(list.stream().max(cmp).get()); */</span></span> } }</code> </pre> <br>  Main looks like this: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> ru.jug.jpoint; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.springframework.context.annotation.AnnotationConfigApplicationContext; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ru.jug.jpoint.core.ArtistJudge; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.List; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.Set; <span class="hljs-comment"><span class="hljs-comment">/** * Created by Evegeny on 20/04/2016. */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Main</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span></span>{ AnnotationConfigApplicationContext context = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AnnotationConfigApplicationContext(AppConfig.class); ArtistJudge judge = context.getBean(ArtistJudge.class); List&lt;String&gt; topX = judge.topX(<span class="hljs-string"><span class="hljs-string">"beatles"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>); System.out.println(topX); } }</code> </pre><br><br>  So, the most popular word is not yesterday, it is ‚Äúi‚Äù: <br><br><pre> <code class="hljs json">[i, yesterday, to]</code> </pre><br>  Agree, this is not very good.  We have junk words that do not carry a semantic load (in the end, we want to analyze how much the Pink Floyd songs are deeper and such words will hinder us very much). <br><br>  Therefore, I had a userProperties file in which garbage words are defined: <br><br><pre> <code class="hljs pgsql">garbage = the,you,<span class="hljs-keyword"><span class="hljs-keyword">and</span></span>,a,<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>,got,m,chorus,<span class="hljs-keyword"><span class="hljs-keyword">to</span></span>,i,<span class="hljs-keyword"><span class="hljs-keyword">in</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">of</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">on</span></span>,me,<span class="hljs-keyword"><span class="hljs-keyword">is</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">all</span></span>,your,my,that,it,<span class="hljs-keyword"><span class="hljs-keyword">for</span></span></code> </pre><br>  It would be possible to immediately inject this garbage into our service, but I don‚Äôt like to do that.  We have a UserConfig that will be transferred to different services.  Everyone will pull out of him what he needs. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Component</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">UserConfig</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Serializable</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> List&lt;String&gt; garbage; <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${garbage}"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setGarbage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] garbage)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.garbage = Arrays.asList(garbage); } }</code> </pre><br>  Pay attention, I use private for the setter and public for the property itself.  But let's not dwell on it. <br><br>  We go to our PopularWordsServiceImpl, autowired to this UserConfig and filter all words. <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;String&gt; lines, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lines.map(String::toLowerCase) .flatMap(WordsUtil::getWords) .mapToPair(w -&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple2&lt;&gt;(w, <span class="hljs-number"><span class="hljs-number">1</span></span>)) .reduceByKey((a, b) -&gt; a + b) .mapToPair(Tuple2::swap).sortByKey(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>).map(Tuple2::_2).take(x); } }</code> </pre><br>    main. <br><br> ,     (  ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5e9/93f/d2a/5e993fd2a7235f5d872e43cf9d650636.png"><br><br>  ,   not serializable.    .    , UserConfig ‚Äî serializable. <br><br><pre> <code class="java hljs">Component <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">UserConfig</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Serializable</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> List&lt;String&gt; garbage; <span class="hljs-meta"><span class="hljs-meta">@Value</span></span>(<span class="hljs-string"><span class="hljs-string">"${garbage}"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setGarbage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] garbage)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.garbage = Arrays.asList(garbage); } }</code> </pre><br>     serializable  PopularWordsServiceImpl: <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsService</span></span></span><span class="hljs-class"> </span></span>{</code> </pre><br>     serializable: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsService</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Serializable</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-function">List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;String&gt; lines, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span></span>; }</code> </pre><br>    map- (   ,    )   state- - ,        .  Those.    UserConfig   ,    serializable.    ,   UserConfig    ,     .    ,    serializable. <br><br>    .     yesterday.    ‚Äî oh,   ‚Äî believe.     oh  -,         . <br>   ,   ,  UserConfig     worker?       ?       ?      ,     Spark ,      ,  - . <br>     ,    broadcast-. <br><br><h3>  4.  ,   broadcast   </h3><br>     ,   worker-     data ( UserConfig   ).   ,  ,     broadcast,     .     (  ), broadcast   . <br><br>  2 ,   : <br><br><ul><li>    . Spark  ; <br><br></li><li>    ,   , ,  ‚Äî  .    broadcast. <br></li></ul><br>   : <br><br><pre> <code class="hljs">Israel, +9725423632 Israel, +9725454232 Israel, +9721454232 Israel, +9721454232 Spain, +34441323432 Spain, +34441323432 Israel, +9725423232 Israel, +9725423232 Spain, +34441323432 Russia, +78123343434 Russia, +78123343434</code> </pre><br>        . <br><br>       (  ),      .     ,    .   ‚Äî     - property-       worker-.                  ,     ,  : <br><br><pre> <code class="hljs">Israel, Orange Israel, Orange Israel, Pelephone Israel, Pelephone Israel, Hot Mobile Israel, Orange Russia, Megaphone Russia, MTC</code> </pre><br>    - Excel-,  ,  054 ‚Äî  Orange,  911 ‚Äî  .       (10 ;      2  ‚Äî        big data)    . <br><br>          : <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Orange</span></span> Orange Pelephone Pelephone Hot Mobile Orange Megaphone MTC</code> </pre><br>     ? <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CommonConfig</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-function">Operator </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOperator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String phone)</span></span></span></span>; <span class="hljs-function"><span class="hljs-function">List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">countries</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; }</code> </pre><br>   CommonConfig,        ,    . <br><br>     ,      : <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HrenoviyService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> CommonConfig config; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> JavaRDD&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">resolveOperatorNames</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;Tuple2&lt;String,String&gt;&gt; pairs)</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pairs.filter(pair-&gt; config.countries().contains(pair._1)) .map(pair-&gt; config.getOperator(pair._2).getName()); } }</code> </pre><br>  -   Spring,         ,   ,    data. <br><br>  !  ,  (       broadcast). <br><br>     ?     Driver  Worker-, ,    ,  ,  1 .   . ,            .        , ,  1000  .      Spark-,     10 Worker-. <br><br> Worker-  -  .  10,  1000,     100 .       ,   ,    ,     ..       -   (  1 ,  2, ..    2 ).   ,     worker-      ,    broadcast. <br><br>       : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/289/2cc/987/2892cc987ba25cde581b20cb56da70eb.png"><br><br>    context, ,   broadcast,      ,   broadcast-.    ,     worker-       . <br><br>  What is the problem?   : <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HrenoviyService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> JavaSparkContext sc; <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> CommonConfig commonConfig; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Broadcast&lt;CommonConfig&gt; configBroadcast; <span class="hljs-meta"><span class="hljs-meta">@PostConstruct</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">wrapWithBroadCast</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ configBroadcast = sc.broadcast(commonConfig); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> JavaRDD&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">resolveOperatorNames</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;Tuple2&lt;String,String&gt;&gt; pairs)</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pairs.filter(pair-&gt; configBroadcast.value().countries().contains(pair._1)) .map(pair-&gt; configBroadcast.value().getOperator(pair._2).getName()); } }</code> </pre><br>    context (,  ,    Spring).   broadcast-   ,      PostConstruct,   wrapWithBroadcast.   SparkContext   ,   .      PostConstruct. <br>     (  broadcast   ,   ): <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">return</span></span> pairs.filter(pair-&gt; configBroadcast.value().countries().contains(pair._1)) .map(pair-&gt; configBroadcast.value().getOperator(pair._2).getName());</code> </pre><br>     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/402/cde/a22/402cdea22d26d3c628c0390a2ba8e320.png"><br><br>    SparkContext,    .    .   copy-paste,  ,    broadcast,      . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3ad/67c/3a1/3ad67c3a17b5573ca23029cb44cf281c.png"><br><br>    copy-past . <br><br> ,    Spark   - ( broadcast ‚Äî   ).   ,        SparkContext,   . <br><br>     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5f4/f3e/6f3/5f4f3e6f3ac9a78f69c1faa613e0225b.png"><br><br>    SparkContext  ,    serializable. <br><br>   ,     ,   ,     .     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7c9/944/95b/7c994495be24a7942eeec3f4f48f9763.png"><br><br>   broadcast?   ,     bean: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e8/efd/1f8/6e8efd1f8ef9390a38c211cb860a0daf.png"><br><br>      broadcast-,             bean      ,   broadcast. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e3/5bf/a4b/6e35bfa4bd3860f87b80c62aacfbcaef.png"><br><br>   ,   ,      broadcast? ,  ,     <a href="https://habrahabr.ru/users/service/" class="user_link">Service</a> ,      ,    broadcast. <br><br>       . <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@AutowiredBroadcast</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Broadcast&lt;UserConfig&gt; userConfig;</code> </pre><br>     broadcast  UserConfig     AutowiredBroadcast.  , ? <br>   : <br><br><pre> <code class="java hljs"> <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(JavaRDD&lt;String&gt; lines, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lines.map(String::toLowerCase) .flatMap(WordsUtil::getWords) .filter(w -&gt; !userConfig.value().garbage.contains(w)) .mapToPair(w -&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple2&lt;&gt;(w, <span class="hljs-number"><span class="hljs-number">1</span></span>)) .reduceByKey((a, b) -&gt; a + b) .mapToPair(Tuple2::swap).sortByKey(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>).map(Tuple2::_2).take(x); } }</code> </pre><br>    UserConfig.value,     . <br><br> ,   bean-,    . <br><br>     . <br><br><pre> <code class="java hljs">lines.map(String::toLowerCase) .flatMap(WordsUtil::getWords) .filter(word-&gt; !Arrays.asList(garbage).contains(word)) .mapToPair(word-&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Tuple2&lt;&gt;(word, <span class="hljs-number"><span class="hljs-number">1</span></span>)) .reduceByKey((x, y)-&gt;x+y) .mapToPair(Tuple2::swap) .sortByKey(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>) .map(Tuple2::_2) .take(amount);</code> </pre><br><br><pre> <code class="hljs swift">lines.<span class="hljs-built_in"><span class="hljs-built_in">map</span></span>(<span class="hljs-number"><span class="hljs-number">_</span></span>.toLowerCase()) .flatMap(<span class="hljs-string"><span class="hljs-string">"\\w+"</span></span>.r.findAllIn(<span class="hljs-number"><span class="hljs-number">_</span></span>)) .<span class="hljs-built_in"><span class="hljs-built_in">filter</span></span>(!garbage.<span class="hljs-built_in"><span class="hljs-built_in">contains</span></span>(<span class="hljs-number"><span class="hljs-number">_</span></span>)) .<span class="hljs-built_in"><span class="hljs-built_in">map</span></span>((<span class="hljs-number"><span class="hljs-number">_</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)).reduceByKey(<span class="hljs-number"><span class="hljs-number">_</span></span>+<span class="hljs-number"><span class="hljs-number">_</span></span>) .sortBy(<span class="hljs-number"><span class="hljs-number">_._2</span></span>,ascending = <span class="hljs-literal"><span class="hljs-literal">false</span></span>) .take(amount)</code> </pre><br>  ,     Java (    ..).  ‚Äî      Scala.   ,   Java 8,     2  .  ,      : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f40/0cb/a1a/f400cba1a0eb6bba0489c512f30c5a2f.png"><br><br>  Java     GetWords,          .   Scala           .   Scala  SortBy,    Tuple,    Scala    ( ascending false,    false). <br><br>   ?    . <br><br> DataFrames ‚Äî  API,         Spark 1.3.     ,      (  Tuple).    RDD,  ..  RDD   ,    ‚Äî    .      (   ),           task-    . <br><br>    : <br><br><ul><li> hive-; <br></li><li> json- ; <br></li><li> RDD; <br></li><li>   ; <br></li><li>     . <br></li></ul><br>     DSL    SQLContext (    ). <br> ,    : <br><br><pre> <code class="hljs pgsql">Agg, <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>, count, <span class="hljs-keyword"><span class="hljs-keyword">distinct</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">drop</span></span>, dropDuplicates, <span class="hljs-keyword"><span class="hljs-keyword">filter</span></span> groupBy, orderBy, registerTable, <span class="hljs-keyword"><span class="hljs-keyword">schema</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">show</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">select</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">where</span></span>, withColumn</code> </pre><br>  SQL    : <br><br><pre> <code class="hljs sql">dataFrame.registerTempTable("finalMap"); DataFrame frame = sqlContext.sql("<span class="hljs-keyword"><span class="hljs-keyword">select</span></span> cl_id, cl_grp_id, dk_org_snw, dk_org_hnw, dk_org_cnp, dk_dir, dk_dat, DK_TIM_HR <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> dk_tim_hr, dk_spe, dk_sgt, dk_pet, dk_sgs, dk_sbp,\n<span class="hljs-string"><span class="hljs-string">" + "</span></span><span class="hljs-keyword"><span class="hljs-keyword">SUM</span></span>(slu_atpt) slu_atpt, <span class="hljs-keyword"><span class="hljs-keyword">SUM</span></span>(slu_succ) slu_succ, <span class="hljs-keyword"><span class="hljs-keyword">SUM</span></span>(slu_fail) slu_fail, <span class="hljs-keyword"><span class="hljs-keyword">SUM</span></span>(slu_dly) slu_dly\n<span class="hljs-string"><span class="hljs-string">" + "</span></span><span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> finalMap f <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> tdtim t <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> f.dk_tim = t.DK_TIM\n<span class="hljs-string"><span class="hljs-string">" + "</span></span><span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dk_pet <span class="hljs-keyword"><span class="hljs-keyword">IN</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>)\n<span class="hljs-string"><span class="hljs-string">" + "</span></span><span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> cl_id, cl_grp_id, dk_org_snw, dk_org_hnw, dk_org_cnp, dk_dir, dk_dat, DK_TIM_HR, dk_spe, dk_sgt, dk_pet, dk_sgs, dk_sbp<span class="hljs-string"><span class="hljs-string">").toDF();</span></span></code> </pre><br>   ,        SQL   sqlContext. <br> ,    : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6c/012/9be/b6c0129be73fe2d3715aac8f67db39f7.png"><br><br>       : <br><br><pre> <code class="hljs lua"><span class="hljs-built_in"><span class="hljs-built_in">abs</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">cos</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">asin</span></span>, isnull, <span class="hljs-keyword"><span class="hljs-keyword">not</span></span>, rand, <span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>, when, expr, bin, <span class="hljs-built_in"><span class="hljs-built_in">atan</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">ceil</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">floor</span></span>, factorial, greatest, least, <span class="hljs-built_in"><span class="hljs-built_in">log</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">log10</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>, round, <span class="hljs-built_in"><span class="hljs-built_in">sin</span></span>, toDegrees, toRadians, md5, ascii, base64, <span class="hljs-built_in"><span class="hljs-built_in">concat</span></span>, length, <span class="hljs-built_in"><span class="hljs-built_in">lower</span></span>, ltrim, unbase64, <span class="hljs-keyword"><span class="hljs-keyword">repeat</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">reverse</span></span>, split, substring, trim, <span class="hljs-built_in"><span class="hljs-built_in">upper</span></span>, datediff, year, month, hour, last_day, next_day, dayofmonth, explode, udf</code> </pre><br>    ,   .        : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c2/288/03c/8c228803c864ea5ef4147ba5d52b98eb.png"><br><br>     keywords (,    ). <br><br>    main. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0cb/74a/c9f/0cb74ac9fbe941499c9f75ad0c80dfa4.png"><br><br> -,         ,   .    sqlContext.read.json    ( ,     json,    ‚Äî       ;  json    ).     show.    : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/757/1ce/1d8/7571ce1d897bffbf81bdf01a3f62c579.png"><br><br>      : , keywords, .      .        ,      30  (     ),     . <br>     .    linkedIn.   select,      keywords.   ,       ,    explode (    keyword   ). <br><br><pre> <code class="hljs pgsql">linkedIn.<span class="hljs-keyword"><span class="hljs-keyword">select</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">functions</span></span>.explode(<span class="hljs-keyword"><span class="hljs-keyword">functions</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">column</span></span>(‚Äúkeywords‚Äù)).<span class="hljs-keyword"><span class="hljs-keyword">as</span></span>(‚Äúkeyword‚Äù));</code> </pre><br>    . ,   : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/898/8de/503/8988de5031fda203892002926faf273d.png"><br><br>        sort  ..      . <br>    .    keyword: <br><br><pre> <code class="java hljs">DataFrame orderedBy = keywords.groupBy(‚Äúkeyword‚Äù) .agg(functions.count(‚Äúkeyword‚Äù).as(‚Äúamount‚Äù)) .orderBy(functions.column(‚Äúamount‚Äù).desc()); orderedBy.show();</code> </pre><br>   ,      .    keyword-     amount.        amount  descended  ( false).   : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e9a/0a5/e19/e9a0a5e19dfb53b96645d6fa48993aea.png"><br><br>           .       : <br><br><pre> <code class="java hljs">String mostPopularWord = orderedBy.first().getString(<span class="hljs-number"><span class="hljs-number">0</span></span>); System.out.println(‚ÄúmostPopularWord = ‚Äú + mostPopularWord);</code> </pre><br>    first ‚Äî   ,      string (   resultset-).       ,    : <br><br><pre> <code class="java hljs">linkedIn.where{ functions.column(‚Äúage‚Äù).leq(<span class="hljs-number"><span class="hljs-number">30</span></span>).and(functions.array_contains(functions.column(‚Äúkeywords‚Äù).mostPopularWord))) .select(‚Äúname‚Äù).show(); }</code> </pre><br>      30      .    ,   functions.array_contains.    show.  Here is the result: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8bc/a97/e68/8bca97e684a86dde4bf2893c9c549e96.png"><br><br>      .  :  XML-,  JSON-,    .       (   )?    ,   Java   Scala?   ,       . <br><br>       WordDataFrameCreator. <br><br> ,   : <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Component</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">WordDataFrameCreator</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> SQLContext sqlContext; <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> JavaSparkContext sc; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> DataFrame </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String pathToDir)</span></span></span><span class="hljs-function"> </span></span>{ JavaRDD&lt;Row&gt; rdd = sc.textFile(pathToDir).flatMap(WordsUtil::getWords).map(RowFactory::create); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sqlContext.createDataFrame(rdd, DataTypes.createStructType(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StructField[]{ DataTypes.createStructField(<span class="hljs-string"><span class="hljs-string">"words"</span></span>, DataTypes.StringType, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>) })); } }</code> </pre><br>   .    RDD       map-  .      ,   RowFactory ‚Äî       RDD.     RDD,    RDD ,     ,  ,    , ..  ,        ‚Äî    .    SqlContext. <br><br> ,  SqlContext  JavaSparkContext   (   AppConfig,    SqlContext    ). ,   : <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SQLContext </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sqlContext</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SQLContext(sc()); }</code> </pre><br>   SqlContext   ,   RDD,    ,  ,    ‚Äî    (    ,   words,   string    ‚Äî true). <br><br>       API :    ,    - . <br><br>        : <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularDFWordsServiceImpl</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularDFWordsService</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@AutowiredBroadcast</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Broadcast&lt;UserConfig&gt; userConfig; <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">topX</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(DataFrame lines, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> x)</span></span></span><span class="hljs-function"> </span></span>{ DataFrame sorted = lines.withColumn(<span class="hljs-string"><span class="hljs-string">"words"</span></span>, lower(column(<span class="hljs-string"><span class="hljs-string">"words"</span></span>))) .filter(not(column(<span class="hljs-string"><span class="hljs-string">"words"</span></span>).isin(userConfig.value().garbage.toArray()))) .groupBy(column(<span class="hljs-string"><span class="hljs-string">"words"</span></span>)).agg(count(<span class="hljs-string"><span class="hljs-string">"words"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"count"</span></span>)) .sort(column(<span class="hljs-string"><span class="hljs-string">"count"</span></span>).desc()); sorted.show(); Row[] rows = sorted.take(x); List&lt;String&gt; topX = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HashSet&lt;&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Row row : rows) { topX.add(row.getString(<span class="hljs-number"><span class="hljs-number">0</span></span>)); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> topX; } }</code> </pre><br>  ,    ,    RDD,   . API  . <br><br>     lower case  . withColumn ‚Äî  ,   .     ,  ,     .    ,     count   ,   ‚Äî   descended-.   - . <br><br>     .     ,  ?  . ,    custom-,   ,    . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d0/615/510/6d0615510fde8717706883e228f2e59d.png"><br><br> ustom- (   udf)   ‚Äî ,   .          .       notGarbage.  ,    udf1,    string (),    ‚Äî boolean (   ). <br><br> ,     : <br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Service</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PopularWordsResolverWithUDF</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> GarbageFilter garbageFilter; <span class="hljs-meta"><span class="hljs-meta">@Autowired</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> SQLContext sqlContext; <span class="hljs-meta"><span class="hljs-meta">@PostConstruct</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">registerUdf</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ sqlContext.udf().register(garbageFilter.udfName(),garbageFilter, DataTypes.BooleanType); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> List&lt;String&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mostUsedWords</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(DataFrame dataFrame, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> amount)</span></span></span><span class="hljs-function"> </span></span>{ DataFrame sorted = dataFrame.withColumn(<span class="hljs-string"><span class="hljs-string">"words"</span></span>, lower(column(<span class="hljs-string"><span class="hljs-string">"words"</span></span>))) .filter(callUDF(garbageFilter.udfName(),column(<span class="hljs-string"><span class="hljs-string">"words"</span></span>)))‚Ä¶</code> </pre><br> ,     ,    PostConstruct   . <br><br>    callUDF       ‚Äî   .      ‚Äî      ,   -   .    udf-. <br><br>      UDF   ,   ,    ,       @RegisterUDF   BPP       . <br><br>         ,     (       Tomcat,  ): <br><br>  10     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed0/df0/7fb/ed0df07fb552c926c9ee6b0995317e61.png"><br><br>        (    ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/641/f10/b34/641f10b3430f9228df78ff5dee14b611.png"><br><br>   ,         .        6  4 . <br><br>  : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8b3/4f8/8eb/8b34f88eb2c1369f0c07cdb4ac505c62.png"><br><br>  : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/554/36f/497/55436f497ab97fb49aee4d911a3415cb.png"><br><br>   Pink Floyd 0     . ,     : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd8/4a8/9a1/cd84a89a1d6c065f6e75c301fda0279e.png"><br><br><h3>  findings </h3><br><ul><li> Hadoop   Spark,  Spark    Hadoop.      Yarn,     ,   ‚Äî    ; <br><br></li><li>     Scala,     .     ; <br><br></li><li>    :  , Spring,  , ,   ..; <br><br></li><li>   .   - ,    bean,   ,     ; <br><br></li><li>      (  ,       ). <br></li></ul><br>    : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/690/45d/894/69045d894fcbf1cd61e678ecc11099d5.png"><br><hr><br> <i>          : <br><br> ‚Äî 5   Spark-.      , ,    ,    .       Spark     ,    -  .    ,     :     ,     ,     , ‚Äî    <a href="https://jpoint.ru/trainings/welcome-to-spark/"> ¬´   Spark!¬ª</a> . <br><br> ‚Äî 7-8   <a href="https://jpoint.ru/">JPoint 2017</a> .        : <a href="https://jpoint.ru/talks/spring-deep-and-not-very/">¬´Spring ‚Äì    ¬ª</a>  <a href="https://jpoint.ru/talks/spring-test-horror/">¬´ Spring Test¬ª</a> .               ,   ! <br><br>  ,  JPoint           Java ‚Äî      <a href="https://habrahabr.ru/company/jugru/blog/323040/">  </a> ,        <a href="https://jpoint.ru/"></a> .</i> </div><p>Source: <a href="https://habr.com/ru/post/325070/">https://habr.com/ru/post/325070/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../325058/index.html">User Interface Cards</a></li>
<li><a href="../325062/index.html">How to collect statistics from the website and not to fill yourself cones</a></li>
<li><a href="../325064/index.html">Everything you wanted to know about stack traces and hip dumps. Part 2</a></li>
<li><a href="../325066/index.html">Release DataGrip 2017.1</a></li>
<li><a href="../325068/index.html">[Translation of the article] 4 tips that we received while talking to business representatives on 4YFN 2017</a></li>
<li><a href="../325072/index.html">Runtyper - a tool for checking types when executing JavaScript code</a></li>
<li><a href="../325074/index.html">Machine Design Tools</a></li>
<li><a href="../325076/index.html">We start the flow velocity sensor</a></li>
<li><a href="../325078/index.html">MEPhI organizes information security competition for students</a></li>
<li><a href="../325080/index.html">How to let cryptographers sink a company</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>