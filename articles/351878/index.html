<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Terraform: a new approach to Infrastructure as code</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello colleagues! While brilliant Ilon Mask is carrying ambitious plans for the terraforming of Mars , we are interested in new opportunities related ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Terraform: a new approach to Infrastructure as code</h1><div class="post__text post__text-html js-mediator-article">  Hello colleagues!  While brilliant Ilon Mask is carrying ambitious plans for the <a href="https://lenta.ru/articles/2016/09/28/uodobybis/">terraforming of Mars</a> , we are interested in new opportunities related to the paradigm " <a href="https://en.wikipedia.org/wiki/Infrastructure_as_Code">Infrastructure as Code</a> " and want to offer you a translation of an article about one of the representatives of the "magnificent seven" - <a href="https://www.terraform.io/">Terraform</a> .  Eugene Brickman's <a href="https://www.amazon.com/Terraform-Running-Writing-Infrastructure-Code/dp/1491977086/">book</a> on the topic is not bad, but she will soon be a year, so please speak up - do you want to see it in Russian? <br><br>  The word Kamal Marhubi (Kamal Marhubi) from the company Heap. <br><a name="habracut"></a><br>  Our infrastructure is powered by AWS, and we manage it with Terraform.  In this publication, we have selected for you practical tips and tricks that were useful to us in the course of work. <br><br><h3>  Terraform and code level infrastructure </h3><br>  <a href="https://www.terraform.io/">Terraform</a> is a tool from Hashicorp that helps declaratively manage the infrastructure.  In this case, you do not have to manually create instances, networks, etc.  in the console of your cloud provider;  it is enough to write a configuration that will set out how you see your future infrastructure.  This configuration is created in human-readable text format.  If you want to change your infrastructure, then edit the configuration and run the <code>terraform apply</code> .  Terraform will send API calls to your cloud provider to bring the infrastructure in line with the configuration specified in this file. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      If we transfer the management of the infrastructure to text files, then we have the opportunity to arm ourselves with all the favorite tools for managing the source code and processes, after which we redirect them to work with the infrastructure.  Now the infrastructure is subject to version control systems, just like the source code, it can be reviewed in the same way or rolled back to an earlier state if something goes wrong. <br><br>  Here's how, for example, an EC2 instance with an EBS volume is defined in Terraform: <br><br><pre> <code class="go hljs">resource <span class="hljs-string"><span class="hljs-string">"aws_instance"</span></span> <span class="hljs-string"><span class="hljs-string">"example"</span></span> { ami = <span class="hljs-string"><span class="hljs-string">"ami-2757f631"</span></span> instance_type = <span class="hljs-string"><span class="hljs-string">"t2.micro"</span></span> ebs_block_device { device_name = <span class="hljs-string"><span class="hljs-string">"/dev/xvdb"</span></span> volume_type = <span class="hljs-string"><span class="hljs-string">"gp2"</span></span> volume_size = <span class="hljs-number"><span class="hljs-number">100</span></span> } }</code> </pre> <br>  If you have not tried Terraform yet, then this <a href="https://www.terraform.io/intro/getting-started/install.html">beginner's guide</a> will do <a href="https://www.terraform.io/intro/getting-started/install.html">for</a> you and will help you quickly get comfortable with the flow of tasks in this tool. <br><br><h3>  Terraform data model </h3><br>  In a common perspective, the Terraform data model is simple: Terraform manages resources, and resources have attributes.  Some examples from the AWS world: <br><br><ul><li>  EC2 instance is a resource with attributes such as machine type, boot image, availability zone, and security groups </li><li>  EBS volume is a resource with attributes such as volume size, volume type, IOPS </li><li>  The elastic load balancer is a resource with attributes for backup instances, the characteristics of their health, and some other phenomena. </li></ul><br>  Terraform provides a mapping of the resources described in the configuration file with the corresponding cloud provider resources.  This mapping is called a <a href="https://www.terraform.io/docs/state/">state</a> , it is a giant JSON file.  When you start <code>terraform apply</code> Terraform updates the state by sending the corresponding request to the cloud provider.  It then compares the returned resources with the information recorded in your Terraform configuration.  If any difference is found, a plan is created, in essence, a list of changes that need to be made to the resources of the cloud provider in order for the actual configuration to match that indicated in your configuration.  Finally, Terraform applies these changes, directing the appropriate calls to the cloud provider. <br><br><h3>  Not every Terraform resource is an AWS resource. </h3><br>  Understanding such a data model with resources and attributes is not so difficult, however, it may not quite coincide with the cloud provider API.  In fact, a single Terraform resource can correspond to one or several basic objects of a cloud provider ‚Äî or even not even one.  Here are some examples from AWS: <br><br><ul><li>  <code>aws_ebs_volume</code> in Terraform matches one AWS EBS volume </li><li>  <code>aws_instance</code> in Terraform with the built-in <code>ebs_block_device</code> block as in the previous example corresponds to two EC2 resources: an instance and that </li><li>  <code>aws_volume_attachment</code> in Terraform does not match any object in EC2! </li></ul><br>  The latter may seem surprising.  When creating <code>aws_volume_attachment</code> Terraform will make an <code>AttachVolume</code> request;  at destruction of this volume - will make request <code>DetachVolume</code> .  No EC2 object is involved in this: <code>aws_volume_attachment</code> is completely synthetic in Terraform!  Like all resources in Terraform, it has an ID.  But, while in most cases the ID is acquired from the cloud provider, the ID <code>aws_volume_attachment</code> is just a <a href="">hash from the volume ID, the instance ID, and the device name</a> .  There are other cases where synthetic resources appear in Terraform - for example, <code>aws_route53_zone_association</code> , <code>aws_elb_attachment</code> and <code>aws_security_group_rule</code> .  To find them, you can search in the resource name <code>association</code> or <code>attachment</code> , which, however, does not always help. <br><br><h3>  All problems are solved in several ways, so when choosing, be careful! </h3><br>  When working with Terraform, exactly the same infrastructure can be represented in several different ways.  Here is another description of our example instance with the EBS volume in Terraform, which gives exactly the same EC2 resources as output: <br><br><pre> <code class="go hljs">resource <span class="hljs-string"><span class="hljs-string">"aws_instance"</span></span> <span class="hljs-string"><span class="hljs-string">"example"</span></span> { ami = <span class="hljs-string"><span class="hljs-string">"ami-2757f631"</span></span> instance_type = <span class="hljs-string"><span class="hljs-string">"t2.micro"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_ebs_volume"</span></span> <span class="hljs-string"><span class="hljs-string">"example-volume"</span></span> { availability_zone = <span class="hljs-string"><span class="hljs-string">"${aws_instance.example.availability_zone}"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">type</span></span> = <span class="hljs-string"><span class="hljs-string">"gp2"</span></span> size = <span class="hljs-number"><span class="hljs-number">100</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_volume_attachment"</span></span> <span class="hljs-string"><span class="hljs-string">"example-volume-attachment"</span></span> { device_name = <span class="hljs-string"><span class="hljs-string">"/dev/xvdb"</span></span> instance_id = <span class="hljs-string"><span class="hljs-string">"${aws_instance.example.id}"</span></span> volume_id = <span class="hljs-string"><span class="hljs-string">"${aws_ebs_volume.example-volume.id}"</span></span> }</code> </pre> <br>  Now that the EBS volume has become a full resource of Terraform, we have delimited it from the EC2 instance.  There is a third resource, synthetic, linking the first two.  If you submit our instance and volume, we can add and delete volumes by simply adding and removing <code>aws_ebs_volume</code> and <code>aws_volume_attachment</code> . <br><br>  Often, it does not matter which EBS representation you choose.  But sometimes, if the choice was wrong, then it will be quite difficult to change your infrastructure after that! <br><br><h3>  We made a mistake with the choice </h3><br>  This is where we burned.  We work with a large PostgreSQL cluster on AWS, and 18 EBS volumes are attached to each instance as storage.  All of these instances are represented in Terraform as the only aws_instance resource with EBS volumes defined in <code>ebs_block_device</code> blocks. <br><br>  In the instances of our database, information is stored in the ZFS file system.  ZFS allows you to dynamically add block devices to grow your file system without any delay.  In this way, we gradually increase our storage as customers send us more and more data.  Since we are an analytical company and we collect all sorts of information, such an opportunity is a huge help for us.  We <a href="https://heap.engineering/basic-performance-analysis-saved-us-millions/">constantly optimize queries and insert operations in our cluster</a> .  Thus, we will not get bogged down with the hard ratio of the CPU-storage that we chose when we prepared the cluster, but we can correct the balance on the fly in order to effectively use the latest innovations. <br><br>  This process could be even smoother if it were not for the <code>ebs_block_device</code> blocks.  Yes, one can hope that Terraform will add the 19th <code>ebs_block_device</code> block to the aws_instance <code>aws_instance</code> - and everything will just work.  However, Terraform sees an overwhelming change here: he ‚Äúdoes not know‚Äù how to change an instance from 18 volumes to be 19. No, Terraform is going to demolish the entire instance and make a new one in its place!  We least wanted something like this in our database, where terabytes of information are stored! <br><br>  Until recently, we used a workaround and made Terraform synchronize in several stages: <br><br><ol><li>  run a script that used AWS CLI to create and add volumes </li><li>  launch <code>terraform refresh</code> so that <code>terraform refresh</code> state and </li><li>  finally, they changed the configuration so that it corresponded to the new realities </li></ol><br>  Between stages 2 and 3, the <code>terraform plan</code> command will show that Terraform was going to destroy and recreate all the instances of our database.  Thus, it was impossible to work with these instances in Terraform until someone updates the configuration.  Should I say how scary it is to remain permanently in such a state! <br><br><h3>  Terraform condition: go to surgery </h3><br>  Finding an approach with <code>aws_volume_attachment</code> , we decided to restructure our presentation.  Each volume has become two new Terraform resources: <code>aws_ebs_volume</code> and aws_volume_attachment.  We had 18 volumes per instance in the cluster, and we had more than a thousand new resources in front of us.  Rebuilding a view is not just a configuration change for Terraform.  We had to get to the state of Terraform and change its vision of resources. <br><br>  Given that we have added over a thousand resources, we definitely were not going to do it manually.  Terraform state is stored in JSON format.  Although this format is stable, the documentation states that ‚Äúit is <a href="https://www.terraform.io/docs/state/">not recommended to directly edit status files</a> ‚Äù.  We would still have to do it, but we wanted to be sure that we are doing it right.  We decided not to engage in reverse development of the JSON format, but wrote a program that uses the internal elements of Terraform as a library for reading, modifying and writing.  It was not so easy, because for all of us it was the first program on Go that we had a chance to work with!  But we thought it was necessary to make sure: yes, we will not confuse in one heap all the Terraform-states of all the instances of our database. <br><br>  We <a href="https://github.com/heap/terraform-ebs-attachmentizer">put the tool on GitHub</a> , in case you want to play with it and feel yourself in our shoes. <br><br><h3>  Terraform neatly </h3><br>  Running <code>terraform apply</code> is one of the few acts that can seriously damage the entire corporate infrastructure.  There are several tips, following which, the risks can be reduced - and in general it will not be so scary. <br><br><h5>  Always prepare a plan ‚Äì out and follow this plan. </h5><br>  If you run <code>terraform plan -out planfile</code> , Terraform will write the plan to <code>planfile</code> .  Then you can get this plan exactly by running the <code>terraform apply planfile</code> .  Thus, the changes that will be applied at this moment correspond exactly to what Terraform will bring you at the time of planning.  There is no situation in which the infrastructure could suddenly change due to the fact that one of the colleagues corrected it between your ‚Äúplan‚Äù and ‚Äúapply‚Äù operations. <br><br>  However, be careful when working with this file: Terraform variables are included there, so if you write something secret there, <a href="https://www.terraform.io/docs/commands/plan.html">this information will be recorded in the file system in an unencrypted form</a> .  For example, if you pass your credentials as variables to a cloud provider, they will be saved to disk as plain text. <br><br><h5>  To iterate over changes, make the IAM read-only special role. </h5><br>  After launching a <code>terraform plan</code> Terraform updates its view of your architecture.  To do this, it needs only access to your cloud provider with read-only rights.  Having established such a role for it, you can enumerate the changes made in the configuration and check them with a <code>terraform plan</code> , without even risking that the careless <code>apply</code> command will <code>apply</code> out all the work done in a day - or in a week! <br><br>  With AWS, you can manage the IAM roles and associated access rights in Terraform.  The role in Terraform looks like this: <br><br><pre> <code class="go hljs">resource <span class="hljs-string"><span class="hljs-string">"aws_iam_role"</span></span> <span class="hljs-string"><span class="hljs-string">"terraform-readonly"</span></span> { name = <span class="hljs-string"><span class="hljs-string">"terraform-readonly"</span></span> path = <span class="hljs-string"><span class="hljs-string">"/"</span></span>, assume_role_policy = <span class="hljs-string"><span class="hljs-string">"${data.aws_iam_policy_document.assume-terraform-readonly-role-policy.json}"</span></span> }</code> </pre> <br>  In <code>assume_role_policy</code> simply displays a list of users who are entitled to accept this role. <br><br>  Finally, we need a policy that provides read-only access to all AWS resources.  Amazon kindly provides a policy description document that you can just copy and paste - this is exactly the document we used.  We define the <code>aws_iam_policy</code> policy referencing this document: <br><br><pre> <code class="go hljs">resource <span class="hljs-string"><span class="hljs-string">"aws_iam_policy"</span></span> <span class="hljs-string"><span class="hljs-string">"terraform-readonly"</span></span> { name = <span class="hljs-string"><span class="hljs-string">"terraform-readonly"</span></span> path = <span class="hljs-string"><span class="hljs-string">"/"</span></span> description = <span class="hljs-string"><span class="hljs-string">"Readonly policy for terraform planning"</span></span> policy = <span class="hljs-string"><span class="hljs-string">"${file("</span></span>policies/terraform-readonly.json<span class="hljs-string"><span class="hljs-string">")}"</span></span> }</code> </pre> <br>  Then we apply the policy to the <code>terraform-readonly</code> role, while adding <code>aws_iam_policy_attachment</code> : <br><br><pre> <code class="go hljs">resource <span class="hljs-string"><span class="hljs-string">"aws_iam_policy_attachment"</span></span> <span class="hljs-string"><span class="hljs-string">"terraform-readonly-attachment"</span></span> { name = <span class="hljs-string"><span class="hljs-string">"Terraform read-only attachment"</span></span> roles = [<span class="hljs-string"><span class="hljs-string">"${aws_iam_role.terraform-readonly.name}"</span></span>] policy_arn = <span class="hljs-string"><span class="hljs-string">"${aws_iam_policy.terraform-readonly.arn}"</span></span> }</code> </pre><br>  Now you can use the <code>AssumeRole</code> method related to the API Secure Token Service to obtain temporary credentials that only allow you to request AWS, but not make changes.  By launching the <code>terraform plan</code> , we will update the state of Terraform so that it reflects the current state of the infrastructure.  If you are working with a local state, then this information will be written to the <code>terraform.tfstate</code> file.  If you use the remote state, for example, in S3, then your read-only role will also require the right to write - otherwise you will not be able to get to S3. <br><br>  Organizing such a role was much easier than rewriting the entire state of Terraform to use <code>aws_volume_attachment</code> with our database volumes.  We knew that no changes in the AWS infrastructure were planned - only its presentation in Terraform had to change.  In the end, we absolutely did not intend to change the infrastructure - why do we need such an opportunity? <br><br><h2>  Ideas for the future </h2><br>  Our team is growing and new employees are learning how to make changes to the infrastructure with the help of Terraform.  I want this process to be simple and safe.  <a href="http://danluu.com/postmortem-lessons/">Most of the failures are due to human errors and changes in the configuration</a> , and changes using Terraform can be fraught with both of them - this is creepy, agree. <br><br>  For example, in a small team it is easy to ensure that only one person will work with Terraform at any given time.  In a larger team, this will not work - it only remains to rely on it.  If the <code>terraform apply</code> is run from two nodes at the same time, the result can be a terrible non-deterministic hash.  Terraform 0.9 now has the ability to <a href="https://www.terraform.io/docs/state/locking.html">lock the state</a> - it ensures that only one <code>terraform apply</code> command can be applied at a time. <br><br>  Another area of ‚Äã‚Äãwork where you so want to achieve ease and security is the review of changes to the infrastructure.  At this stage, when reviewing, we simply copy the <code>terraform plan</code> output as a comment to the review - and, when the option is approved, we make all the changes manually. <br><br>  We have already adapted to use our continuous integration tool when we validate the Terraform configuration.  For now, just run the <code>terraform validate</code> command, and the tool checks whether there are any syntax errors in the code.  Our next task is to adapt the continuous integration tool to launch the <code>terraform plan</code> and output the changes made to the infrastructure as a comment to the code review.  The continuous integration system should automatically run <code>terraform apply</code> as soon as the change is approved.  So we exclude one of the stages that was required to be done manually, and also provide a more consistent audit trail (change history), which is traceable in the comments.  In the version of Terraform Enterprise there is such an opportunity - so we recommend to take a closer look at it. </div><p>Source: <a href="https://habr.com/ru/post/351878/">https://habr.com/ru/post/351878/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../351868/index.html">We use PHP for its intended purpose</a></li>
<li><a href="../351870/index.html">Simulation systems: choose the appropriate</a></li>
<li><a href="../351872/index.html">CIS Controls V7: Information Security Recommendations</a></li>
<li><a href="../351874/index.html">Tasks with interviews (front-end)</a></li>
<li><a href="../351876/index.html">Aws Lambda Go 1.x, Kinesis, CloudSearch</a></li>
<li><a href="../351880/index.html">As a result of the toxic manual, Telltale Games lost the best developers.</a></li>
<li><a href="../351882/index.html">Vue.js and how to understand it</a></li>
<li><a href="../351884/index.html">This is not ‚Äúa real job, but a better job‚Äù: as a hiring policy, Crossover allows you to pay employees above the market</a></li>
<li><a href="../351886/index.html">Controller for Lego</a></li>
<li><a href="../351888/index.html">Espresso: ‚ÄúCute little animals or dangerous predators?‚Äù</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>