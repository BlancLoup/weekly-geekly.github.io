<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to render the frame of the new Doom</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Released in 1993, the first DOOM made fundamental changes to game development and mechanics, it became a world hit and created new idols, such as John...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to render the frame of the new Doom</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/da5/3aa/c61/da53aac61dcb430bb7e9ed22a2eeaf21.jpg"><br><br>  Released in 1993, the first <a href="https://ru.wikipedia.org/wiki/Doom">DOOM</a> made fundamental changes to game development and mechanics, it became a world hit and created new idols, such as <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B0%25D1%2580%25D0%25BC%25D0%25B0%25D0%25BA,_%25D0%2594%25D0%25B6%25D0%25BE%25D0%25BD">John Carmack</a> and <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25BC%25D0%25B5%25D1%2580%25D0%25BE,_%25D0%2594%25D0%25B6%25D0%25BE%25D0%25BD">John Romero</a> . <br><br>  Today, 23 years later, <a href="https://ru.wikipedia.org/wiki/Id_Software">id Software</a> belongs to <a href="https://ru.wikipedia.org/wiki/ZeniMax_Media">Zenimax</a> , all the founders have already left the company, but this did not prevent the id team from demonstrating all their talent by releasing a great game. <br><a name="habracut"></a><br>  New <a href="https://ru.wikipedia.org/wiki/Doom_(%25D0%25B8%25D0%25B3%25D1%2580%25D0%25B0,_2016)">DOOM</a> perfectly complements the franchise.  It uses the new <a href="https://ru.wikipedia.org/wiki/Id_Tech_6">engine id Tech 6</a> ;  After the departure of John Carmack, he was replaced by former render programmer Crytek developer <a href="https://twitter.com/idSoftwareTiago">Tiago Souza (Tiago Sousa)</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Traditionally, id Software, several years after its creation, published the source code of its engines, which often led to the emergence of <a href="https://www.chocolate-doom.org/wiki/index.php/Chocolate_Doom">interesting remakes</a> and <a href="http://fabiensanglard.net/doomIphone/doomClassicRenderer.php">analytical articles</a> .  It is not known whether id Tech 6 will continue this tradition, but we do not necessarily need the source code to evaluate the curious graphic techniques used in the engine. <br><br><h1>  How is the frame rendered </h1><br>  We will examine the scene from the image below, in which the player attacks <em><a href="http://doom.wikia.com/wiki/Gore_nest">the blood nest</a></em> , guarded by several <em><a href="http://doom.wikia.com/wiki/The_Possessed_(Enemy)">possessed</a></em> , immediately after receiving the <em>Praetorian armor</em> at the beginning of the game. <br><br><img src="https://habrastorage.org/files/da6/93a/a24/da693aa244e8438f86051e6f4e550546.jpg"><br><br>  Unlike most modern games under Windows, DOOM does not use <a href="https://ru.wikipedia.org/wiki/DirectX">Direct3D</a> , but <a href="https://ru.wikipedia.org/wiki/OpenGL">OpenGL</a> and <a href="https://ru.wikipedia.org/wiki/Vulkan_(API)">Vulkan</a> . <br><br>  Vulkan is an amazing new technology, and <a href="https://twitter.com/baldurk">Baldur Karlsson</a> (Baldur Karlsson) just recently added Vulkan support in <a href="https://github.com/baldurk/renderdoc">RenderDoc</a> , so it was difficult to resist the temptation to get inside the DOOM engine.  All the observations below are made in a game launched from Vulkan on the <a href="https://ru.wikipedia.org/wiki/GeForce_900">GTX 980</a> with all the settings set to <em>Ultra</em> , some guesses are taken from the <a href="http://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf">presentation of Thiago Souza and Jean Geffroy on Siggraph</a> . <br><br><h2>  MegaTexture Update </h2><br>  The first stage of rendering is the update of <a href="https://ru.wikipedia.org/wiki/Id_Tech_4">mega-textures</a> ;  This technology, introduced in <a href="https://ru.wikipedia.org/wiki/Id_Tech_5">id Tech 5</a> , was used in <a href="https://ru.wikipedia.org/wiki/Rage_(%25D0%25B8%25D0%25B3%25D1%2580%25D0%25B0)">RAGE</a> , and now in the new DOOM. <br><br>  If to explain briefly, the meaning of this technology is that several huge textures (in DOOM they are 16k x 8k in size) are located in the memory of the video processor;  each of them is a collection of 128x128 tiles. <br><br><img src="https://habrastorage.org/files/489/553/383/4895533831aa46ed98d2c79d8e6a4f00.jpg"><br>  <em>128 x 128 pages stored in a 16k x 8k texture</em> <br><br>  All of these tiles should be an ideal set of actual textures with a good level of mip-texturing, which will later be used by pixel shaders to render the scene that we see. <br><br>  When a pixel shader reads from a ‚Äúvirtual texture‚Äù, it simply reads some of these physical tiles of 128x128 in size. <br><br>  Of course, depending on where the player is looking, the set of these textures will change: new models appear on the screen, referring to other virtual textures, downloading new tiles and unloading old ones is required ... <br><br>  So, at the beginning of the frame, DOOM updates several tiles using the <code>vkCmdCopyBufferToImage</code> instruction to write actual texture data to the memory of the graphics processor. <br><br>  <em>Read in detail about mega-textures <a href="http://www.mrelusive.com/publications/papers/Software-Virtual-Textures.pdf">here</a> and <a href="http://s09.idav.ucdavis.edu/talks/05-JP_id_Tech_5_Challenges.pdf">here</a> .</em> <br><br><h2>  Shadow Atlas </h2><br>  For each light source casting a shadow, a unique <a href="https://en.wikipedia.org/wiki/Depth_map">depth map</a> is created, stored in one huge <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D0%25BA%25D1%2581%25D1%2582%25D1%2583%25D1%2580%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B0%25D1%2582%25D0%25BB%25D0%25B0%25D1%2581">texture atlas</a> tile of 8k x 8k size.  However, not every depth map is calculated for each frame: DOOM actively reuses the results of the previous frame and recalculates only those depth maps that require updating. <br><br><img src="https://habrastorage.org/files/7e7/65c/ff1/7e765cff1e984d91bb1b7e349edea73d.png"><br>  <em>8k x 8k depth buffer (previous frame)</em> <br><br><img src="https://habrastorage.org/files/30e/c80/dee/30ec80deefa045249e443c7d17da313f.png"><br>  <em>8k x 8k depth buffer (current frame)</em> <br><br>  When a light source is static and casts shadows only on static objects, it will be wise to simply keep its depth map ‚Äúas it is‚Äù and not to perform unnecessary recalculations.  However, if the enemy moves to this light, then you will need to create a depth map again. <br><br>  The dimensions of the depth maps can vary greatly depending on the distance from the source to the camera;  In addition, recalculated depth maps do not have to be in the same atlas tile. <br><br>  In DOOM, certain optimizations are used, for example, caching of the static part of the depth map with the calculation of the projections of only dynamic grids and subsequent compositing of the results. <br><br><h2>  Depth Treatment Pre-Pass </h2><br>  All the opaque grids have already been rendered and their depth information has been transferred to the depth map.  First it is the player‚Äôs weapon, then static geometry, and finally dynamic geometry. <br><br><img src="https://habrastorage.org/files/b31/0a5/a74/b310a5a745f74f3084c16a4bbce290d0.png"><br>  <em>Depth map: readiness 20%</em> <br><br><img src="https://habrastorage.org/files/0ff/db8/6cb/0ffdb86cb47a457f990428e3aaa1cd83.png"><br>  <em>Depth Map: 40% Readiness</em> <br><br><img src="https://habrastorage.org/files/8a3/ea8/098/8a3ea809859047cd80806653b510a35d.png"><br>  <em>Depth Map: 60% Readiness</em> <br><br><img src="https://habrastorage.org/files/c80/a6a/d37/c80a6ad373834988af691b5afbd937b7.png"><br>  <em>Depth Map: 80% Readiness</em> <br><br><img src="https://habrastorage.org/files/536/e84/393/536e843931b44d47a7b4e8c649fa5392.png"><br>  <em>Depth Map: 100% Ready</em> <br><br>  But in fact, during the preliminary processing of the depths, not only information about the depths is saved. <br><br>  When rendering to a depth map of dynamically objects ( <em>possessed</em> , cables, and player‚Äôs weapons) their speed per pixel is also computed and written to another buffer to create a velocity map.  Calculations are performed by calculating in the vertex shader the difference between the positions of each vertex between the previous and the current frame. <br><br><img src="https://habrastorage.org/files/37f/383/1c7/37f3831c726e4b8797551a7f18da8d2c.png"><br>  <em>Velocity map</em> <br><br>  To store speed you need only 2 channels: horizontal speed is stored in red, and vertical is stored in green. <br><br>  The obsessed move quickly to the player (therefore it is green), and the weapon is almost motionless (black). <br><br>  And what is this yellow area (red and green are 1)?  In fact, this is the original default color of the buffer, meaning that there are no dynamic grids there: this is the ‚Äúarea of ‚Äã‚Äãstatic grids‚Äù. <br><br>  Why is DOOM not calculating speed for static grids?  Because the speed of a static pixel is easy to find from its depth and the new state of the camera compared to the last frame;  it is not necessary to calculate it for each grid. <br><br>  The velocity map comes in handy later when adding <a href="https://ru.wikipedia.org/wiki/Motion_blur">motion blur</a> . <br><br><h2>  Cut requests </h2><br>  We aim to send as few geometric objects as possible for rendering in the GPU, and the best way to achieve this is to cut off all the grids that are invisible to the player.  Most of the clipping of invisible parts in DOOM is performed by the <a href="http://umbra3d.com/knee-deep-in-the-dead/">Umbra middleware</a> , but still the engine performs <em>clipping requests to the graphics processor</em> to further trim the visible area. <br><br>  What is the meaning of cut-off requests to the graphics processor?  The first step is to group several grids of the world into a virtual area encompassing all these grids, followed by a request to the graphics processor to render this area according to the current depth buffer.  If none of the raster pixels passes the depth test, it means that this area is completely cut off and all the objects in the world contained in this area can be safely ignored during rendering. <br><br>  However, the problem is that the results of these cutback requests are not immediately available, and we don‚Äôt want the GPU pipeline to be idle blocked by these requests.  Usually, the reading of results is postponed for subsequent frames, so it is necessary to have a slightly more conservative algorithm to avoid the appearance of objects on the screen. <br><br><img src="https://habrastorage.org/files/23f/0da/708/23f0da708ccd406a8f6efa618f957233.png"><br>  <em>Check area.</em>  <em>Red - cut off, green - visible.</em> <br><br><h2>  Cluster direct rendering of opaque objects </h2><br>  Now all opaque geometry and decals are rendered.  Lighting information is stored in a floating point <abbr title="High dynamic range">HDR</abbr> buffer: <br><br><img src="https://habrastorage.org/files/ea5/5ae/ff2/ea55aeff25ab405d9bafa0ff240bba7c.jpg"><br>  <em>25% of lighting</em> <br><br><img src="https://habrastorage.org/files/3ff/1d1/2a0/3ff1d12a010142e0aa99dff9f3927cb8.jpg"><br>  <em>50% of lighting</em> <br><br><img src="https://habrastorage.org/files/f78/b88/f07/f78b88f07d894ad6b37f8aaa90d1d416.jpg"><br>  <em>75% of lighting</em> <br><br><img src="https://habrastorage.org/files/691/8bf/ba9/6918bfba9c5a4263bf586a2dd07917fb.jpg"><br>  <em>100% lighting</em> <br><br>  The depth check function is set to <code>EQUAL</code> to avoid unnecessary computation: thanks to the previous preliminary processing of depth processing, we know exactly what depth value each pixel should have.  Decals are also applied directly when rendering grids, they are stored in a textural atlas. <br><br>  The picture already looks good, but we still lack transparent materials, such as glass, particles, and there are no reflections of the medium at all. <br><br>  I will say a few words about this passage: it uses a cluster direct renderer based on the work of <a href="http://www.humus.name/Articles/PracticalClusteredShading.pdf">Emil Person</a> and <a href="http://www.cse.chalmers.se/~uffe/clustered_shading_preprint.pdf">Ola Olsson</a> . <br><br>  The weak point of direct rendering has always been the impossibility of processing a large number of sources of illumination, this task is much easier to accomplish with the help of deferred shading. <br><br>  How does a cluster renderer work?  First, the viewing window is divided into tiles: 16 x 8 areas are created in DOOM.  Some renderers stop at this and calculate the list of sources of illumination per tile, which allows to reduce the amount of illumination calculations, but still have certain problems with borderline cases. <br><br>  Cluster rendering develops this concept deeper, moving from 2D to 3D: without dwelling on the separation of a two-dimensional viewing window, it performs a 3D breakdown of the entire camera visibility pyramid, creating cuts along the Z axis. <br><br>  Each ‚Äúblock‚Äù is called a ‚Äúcluster‚Äù; you can also call them ‚Äú <a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D0%25BE%25D0%25BA%25D1%2581%25D0%25B5%25D0%25BB">voxels</a> in the shape of a pyramid of visibility‚Äù. <br><br>  Below is a simple split of a 4 x 2 viewing window;  5 depth slices divide the visibility pyramid into 40 clusters. <br><br><img src="https://habrastorage.org/files/dac/3cd/d9f/dac3cdd9f11f4d03bfc994d6056b87e8.png"><br><br>  In DOOM, the visibility pyramid of the camera is divided into 3072 clusters (16 x 8 x 24 in size), the depth slices are logarithmically located along the Z axis. <br><br>  In the case of a cluster renderer, a typical algorithm would be: <br><br><ul><li>  First, the CPU calculates a list of elements that affect the lighting in each cluster: light sources, decals and cubic textures ... <br><br>  To do this, all these elements are ‚Äúvoxelized‚Äù, so that their area of ‚Äã‚Äãimpact can be checked for intersection with the clusters.  Data is stored in indexed lists in the buffer of the graphics processor so that shaders can access them.  Each cluster can contain up to 256 light sources, 256 decals and 256 cubic textures. <br><br></li><li>  Then the graphics processor renders the pixel: <br><br><ul><li>  from the coordinates and pixel depth it is calculated which cluster it belongs to </li><li>  reads the list of decals / light sources for this cluster.  It uses indirect addressing with offset and calculation of the index (see illustration below). </li><li>  the code passes through all the decals / light sources in the cluster, calculating and adding the degree of their influence. </li></ul></li></ul><br><div class="spoiler">  <b class="spoiler_title">Using light sources and decals</b> <div class="spoiler_text">  Here's how a pixel shader can get a list of lights and decals on this aisle: <br><br><img src="https://habrastorage.org/files/28e/402/b80/28e402b808ed4b81911d79845ab3227c.jpg"><br><br><img src="https://habrastorage.org/files/407/eed/891/407eed891a034bc494471b4c2b298a09.jpg"><br><br><img src="https://habrastorage.org/files/927/829/602/927829602fb34667888aafc655625684.jpg"><br><br><img src="https://habrastorage.org/files/bef/542/b7e/bef542b7e28241f1bfe925dc1636a6f2.jpg"><br><br><img src="https://habrastorage.org/files/1b4/aeb/8b5/1b4aeb8b5adc48da98bcacdd4321c539.jpg"><br><br><img src="https://habrastorage.org/files/e84/f31/6b9/e84f316b98d144e7ad75dddbe2432f4a.jpg"></div></div><br>  There is also a list of probes (not shown in the diagrams above), access to which is obtained in exactly the same way;  however, it is not used on this passage and we will return to it later. <br><br>  The cost of influencing the CPU by creating the list of items for the clusters pays off by significantly reducing the complexity of rendering calculations in the graphics processor down the pipeline. <br><br>  Clustered direct steel rendering is the last thing to pay attention to: it has a good ability to process more light sources than simple direct rendering;  besides, it works faster than deferred shading, which should write and read from multiple <abbr title="Geometric Buffer">G-buffers</abbr> . <br><br>  However, I did not mention something: on this passage, it is not just a single write operation that is transferred to the lighting buffer;  when it is also executed using <a href="https://en.wikipedia.org/wiki/Multiple_Render_Targets">MRT</a> , two thin G-buffers are created: <br><br><img src="https://habrastorage.org/files/51f/82e/f6f/51f82ef6ffc744f28d4190a672ea0015.jpg"><br>  <em>Normal map</em> <br><br><img src="https://habrastorage.org/files/664/1fc/e01/6641fce01c2d4e8fb582079e3b8b4a70.jpg"><br>  <em>Reflection map</em> <br><br>  The normal map is stored in <abbr title="Red: 16 bits, green: 16 bits">R16G16 floating point format</abbr> , the reflection map is <abbr title="Red, green, blue and alpha, each 8 bits">stored</abbr> in <abbr title="Red, green, blue and alpha, each 8 bits">R8G8B8A8</abbr> , the alpha channel contains a smoothing factor.  So in DOOM, a combination of direct and deferred rendering with a hybrid approach is used.  These new G-buffers will be useful when adding additional effects, such as reflections. <br><br>  I missed one more thing: at the same time, a 160 x 120 feedback buffer is created for the mega-texture system.  It contains information for the streaming system, telling about textures and their mip-texturing, which need to be passed on. <br><br>  The megatexures engine works on the principle of feedback: if after the rendering pass it is reported that there are no textures, the engine loads them. <br><br><h2>  Particles in the GPU </h2><br>  Then a <a href="https://www.opengl.org/wiki/Compute_Shader">compute shader is</a> launched to update the particle simulation: position, velocity, and lifetime. <br><br>  It reads the current states of the particles, as well as the buffers of normals and depths (for collision detection), reproduces the simulation stage and stores new states in the buffers. <br><br><h2>  Ambient light blocking in screen space (SSAO) </h2><br>  At this stage, an <a href="https://ru.wikipedia.org/wiki/SSAO">SSAO</a> map is generated. <br><br>  It is designed to darken the color around narrow seams, folds, etc. <br>  It is also used to apply <a href="http://research.tri-ace.com/Data/cedec2011_RealtimePBR_Implementation_e.pptx">clipping reflections</a> to avoid bright lighting artifacts appearing on clipped grids. <br><br>  The map is calculated at half the original resolution in the pixel shader, which reads data from the depth buffer, normal maps and reflections. <br><br>  The first result is quite noisy. <br><br><img src="https://habrastorage.org/files/21b/d62/cb5/21bd62cb5a134996b155b77298a5c061.png"><br>  <em>SSAO card</em> <br><br><h2>  Reflections in screen space </h2><br>  Now the pixel shader creates an <abbr title="Screen Space Reflections">SSR</abbr> map.  With the help of the information present on the screen, he reyrates the reflections, causing the rays to reflect from each pixel in the viewing window and read the color of the pixels on which the rays fell. <br><table><tbody><tr><td><img width="200" src="https://habrastorage.org/files/536/e84/393/536e843931b44d47a7b4e8c649fa5392.png"><br>  <em>Depths</em> </td><td><img width="200" src="https://habrastorage.org/files/51f/82e/f6f/51f82ef6ffc744f28d4190a672ea0015.jpg"><br>  <em>Normals</em> </td><td><img width="200" src="https://habrastorage.org/files/664/1fc/e01/6641fce01c2d4e8fb582079e3b8b4a70.jpg"><br>  <em>Reflection</em> </td><td><img width="200" src="https://habrastorage.org/files/100/2fb/c6a/1002fbc6aa034c7babc5c2266eb3a76c.jpg"><br>  <em>Previous frame</em> </td></tr><tr><td colspan="4" align="center"><img width="55" src="https://habrastorage.org/files/9ef/c68/250/9efc68250cac422e8041399223d2b826.png"></td></tr><tr><td colspan="4"><img src="https://habrastorage.org/files/916/93c/f04/91693cf0459f4a5d83751f24e248a560.jpg"><br>  <em>SSR card</em> </td></tr></tbody></table>  The input data for the shader are the depth map (to calculate the pixel position in the world space), the normal map (to know how to make the rays reflect), the reflection map (to know the reflection number) and the <em><strong>previous rendered frame</strong></em> (at the stage before tone mapping, but after applying transparency to get some color information).  Also, the camera configuration of the previous frame is transmitted to the pixel shader so that it can track changes in the positions of the fragments. <br><br>  SSR is a good and not very expensive technique for creating dynamic reflections of a scene in real time, creating a constant load;  It greatly enhances the sense of immersion and realism. <br><br>  But she has her own artifacts, as she works only in screen space and lacks ‚Äúglobal‚Äù information.  For example, you can see beautiful reflections in the scene, but when you start to look down, the amount of reflection decreases, and when you look at your feet, you will see almost no reflections.  It seems to me that SSRs are well integrated into DOOM, they improve the quality of the image, but at the same time they are rather inconspicuous, and you will not notice their disappearances, if you do not follow them on purpose. <br><br><h2>  Static Cubic Textures Reflections </h2><br>  After calculating all the dynamic reflections on the previous pass (and their limitations), it is time to create static reflections using <a href="https://en.wikipedia.org/wiki/Image-based_lighting">IBL</a> . <br><br>  This technique is based on the use of 128 x 128 generated cubic textures, which represent information about the lighting of the environment in various places on the map (they are also called ‚Äúenvironment probes‚Äù).  In the same way as light sources with decals at the stage of clustering of the visibility pyramid, the probes are also indexed for each cluster. <br><br>  All cubic level textures are stored in an array;  There are dozens of them, but only 5 contribute to our scene (cubic textures in this room): <br><table><tbody><tr><td><img src="https://habrastorage.org/files/6af/c50/0ae/6afc500ae94a4899914eaff40d5f63bf.png"></td><td><img src="https://habrastorage.org/files/e6a/72c/660/e6a72c660a3c4bbfac0d478d9b075cb9.png"></td><td><img src="https://habrastorage.org/files/b62/f6d/19a/b62f6d19acea4c6c9f9b285f1e10e2df.png"></td><td><img src="https://habrastorage.org/files/f13/bb4/5e0/f13bb45e026b48af97b6a3295d9e68dc.png"></td><td><img src="https://habrastorage.org/files/dad/401/34c/dad40134c66c474fa7534c3dca69b9ca.png"></td></tr></tbody></table>  The pixel shader reads data from the depth, normal and reflection buffers, searches the cluster structure for cubic textures that affect the pixel (the closer the cubic texture is, the stronger the influence) and generates a map of static reflections: <br><br><img src="https://habrastorage.org/files/d73/e0f/8de/d73e0f8de02c48028fed09bdd8dbf115.jpg"><br>  <em>Static reflection map</em> <br><br><h2>  Mixing cards </h2><br>  At this stage, the compute shader combines all previously generated maps.  It reads maps of depths and reflections and mixes the lighting of the straight aisle: <br><br><ul><li>  with SSAO information </li><li>  with SSR for the pixel in question when it becomes available </li><li>  if SSR information is missing, static reflection map data is used as a replacement </li><li>  fog effect is also calculated </li></ul><br><img src="https://habrastorage.org/files/960/d86/c29/960d86c298684cc79b927ee5516c88e5.jpg"><br>  <em>Mixing and fog: up</em> <br><br><img src="https://habrastorage.org/files/b8c/30a/610/b8c30a61006541fa99ec3e79c381abcd.jpg"><br>  <em>Mixing and fog: after</em> <br><br><img src="https://habrastorage.org/files/e62/669/c82/e62669c827be4771be55b6d42569afbf.jpg"><br>  <em>Fog - fog; Probe Reflection - probe reflection</em> <br><br><h2>  Particle lighting </h2><br>  There are smoke particles in our scene and lighting is calculated for each sprite.  Each sprite is rendered as if it is in the space of the world: from its position we obtain a list of sources of illumination and corresponding shadow maps, after which the illumination of the quadrilateral (particles) is calculated.  Then the result is saved in a 4k atlas tile;  Tiles can be of various sizes depending on the distance from the particle to the camera, quality settings, etc.  The atlas has selected areas for sprites of the same resolution, this is what 64 x 64 sprites look like: <br><br><img src="https://habrastorage.org/files/b12/b39/cd8/b12b39cd85ad4621bd4ceed464f4fb7b.png"><br>  <em>Particle Lighting Atlas</em> <br><br>  In such a low resolution only information about the <em>light</em> is stored.  Later, when the particle is actually drawn, the texture is used in full resolution, and the scale of the lighting quadrangle increases and it mixes with the texture. <br><br>  Here, DOOM separates the particle illumination calculation from the main rendering of the game: whatever resolution you play (720p, 1080p, 4k ...), the particle illumination is always calculated and stored in such small fixed-size tiles. <br><br><h2>  Zoom out and blur </h2><br>  The scene is reduced several times in size to 40 pixels.  The smallest zoom levels are blurred by separate vertical and horizontal passes (a ‚Äúblur chain‚Äù is created). <br><br><img src="https://habrastorage.org/files/59d/307/d52/59d307d520c24c838cbf5f0a8207f914.png"><br><br>  Why so early to perform the blur?  This process usually occurs at the end, during post-processing to create a bloom effect in bright areas. <br><br>  But all these different levels of blur will be useful to us in the next passage for rendering refractions in glass. <br><br><h2>  Transparent objects </h2><br>  All transparent objects (glasses, particles) are rendered on top of the scene: <br><br><img src="https://habrastorage.org/files/c86/c79/60a/c86c7960a1d7407981f540e93e008657.jpg"><br>  <em>Transparent objects: up to</em> <br><br><img src="https://habrastorage.org/files/b4f/1a2/673/b4f1a267356048bd8b1e59e4ae4fb58e.jpg"><br>  <em>Transparent objects: after</em> <br><br>  Glasses are very beautifully rendered in DOOM, especially glasses covered with frost or dirt: decals affect only part of the glass to make the refractions more or less blurred.  The pixel shader calculates the coefficient of ‚Äúblurring‚Äù of refraction and selects from the set of ‚Äúchain of blurring‚Äù two cards that are closest to the coefficient of blurring.  It reads these two maps and interpolates the two values ‚Äã‚Äãlinearly to approximate the final color of the refraction blur.  Thanks to this process, glass can create pixel-by-pixel beautiful refractions at various levels of blur. <br><br><h2>  Distortion map </h2><br><img src="https://habrastorage.org/files/ce9/294/81d/ce929481d4dc42a4865b09ddf67638f2.png"><br>  <em>Distortion map</em> <br><br>  Very hot areas can create thermal deformations on the image.  In our scene, the image of a nest of blood distorts a little. <br><br>  Distortion is rendered relative to the depth buffer to create a low-resolution distortion map. <br><br>  The red and green channels represent the value of the distortion along the horizontal and vertical axes.  The blue channel contains the amount of blur applied. <br><br>  This distortion effect is applied later, as post-processing, using a distortion map to move the desired pixels. <br><br>  In this scene, the distortions are quite small and almost imperceptible. <br><br><h2>  User interface </h2><br><img src="https://habrastorage.org/files/19f/879/b16/19f879b16f9c40c1b2b592bbb511cc64.png"><br><br>  The UI is rendered to another render buffer in a mode that is pre-multiplied by an alpha channel ( <a href="https://www.gimp.org/docs/plug-in/appendix-alpha.html">premultiplied alpha mode</a> ) stored in the <abbr title="Low Dynamic Range. 8 bits per channel.">LDR</abbr> format. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The advantage of storing the entire UI in a separate buffer instead of drawing directly on top of the completed frame is that the game can apply filtering / postprocessing, for example, chromatic aberration or optical distortion for all UI widgets in one pass. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rendering does not use some kind of batching technique and simply draws one by one interface elements, for about 120 draw calls. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In subsequent passes, the UI buffer is mixed on top of the game image, creating the final result.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Temporary anti-aliasing (TAA) and motion blur </font></font></h2><br> <a href="https://ru.wikipedia.org/wiki/Temporal_anti-aliasing"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TAA</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><a href="https://ru.wikipedia.org/wiki/Motion_blur"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">motion blur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> are applied using the velocity map and the rendering results of the previous frame. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fragments can be tracked, so that the pixel shader knows where the current pixel being processed was in the previous frame. </font><font style="vertical-align: inherit;">Every second rendering frame slightly shifts the mesh projection by half a pixel: this allows you to eliminate subpixel distortion artifacts. </font></font><br><br><img src="https://habrastorage.org/files/dd9/3a0/a70/dd93a0a704164c7c871fd71774ca9b00.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TAA and motion blur: before </font></font></em> <br><br><img src="https://habrastorage.org/files/c97/d25/2ed/c97d252edbf143cd9e75bddf8fe5bbd1.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TAA and motion blur: after</font></font></em> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The result is very good: not only does the grid become smooth, but the distortion of reflections (at which individual bright pixels may appear in the frame) also decreases. </font><font style="vertical-align: inherit;">The quality is much better than what could be achieved with the FXAA post-processing method.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Scene brightness </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">At this stage, the average </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%25AF%25D1%2580%25D0%25BA%25D0%25BE%25D1%2581%25D1%2582%25D1%258C"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">brightness of the</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> scene is </font><font style="vertical-align: inherit;">calculated </font><font style="vertical-align: inherit;">; this is one of the parameters later transmitted for tone mapping. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The HDR-illumination buffer cyclically decreases twice from its resolution until it becomes a 2 x 2 texture, with each iteration a pixel color value is calculated as the average of the brightness of its four ‚Äúparent‚Äù pixels from a larger map.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Bloom </font></font></h2><br><img src="https://habrastorage.org/files/9ce/200/1ea/9ce2001eacfa444eb325cc179d30de73.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bloom</font></font></em> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Applies a brightness filter to mute the darkest areas of the image. </font><font style="vertical-align: inherit;">The result of using the brightness filter is then cyclically reduced and blurred in a manner similar to that described above. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Layers are blurred using </font></font><a href="https://en.wikipedia.org/wiki/Gaussian_blur"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gaussian blur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> with a vertical and horizontal aisle, on which the pixel shader calculates a weighted average along one axis. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Then blurred layers are combined to create the </font></font><a href="https://ru.wikipedia.org/wiki/Bloom"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bloom</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> effect </font><font style="vertical-align: inherit;">, which is an HDR texture four times smaller than the original resolution.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Final postprocessing </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> All this stage is performed in a single pixel shader: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> heat distortion applied using distortion map data </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The bloom texture is added on top of the HDR lighting buffer. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> apply effects such as vignetting, dirt / highlights </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> average brightness is calculated by sampling the 2x2 brightness map, as well as additional exposure parameters, tone mapping and grading are applied. </font></font></li></ul><br><img src="https://habrastorage.org/files/c48/772/6cc/c487726cccb64750878471f7b021869b.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tone Compression: before </font></font></em> <br><br><img src="https://habrastorage.org/files/6ab/06e/20a/6ab06e20a8a84798b92b1b5c0d4a38d0.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tonal Compression: after</font></font></em> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tonal Compression takes an HDR-lighting buffer containing colors that change over a wide range of brightness, and converts it into 8-bit-per-color (LDR) color so that the frame can be displayed on the monitor. </font></font><br><br> <a href="http://duikerresearch.com/2015/09/filmic-tonemapping-ea-2006/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cinematic tone mapping operator</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> based on an equation </font></font><code>(x(Ax+BC)+DE) / (x(Ax+B)+DF) - (E/F)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, this </font></font><a href="http://filmicgames.com/archives/75"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tone compression Uncharted 2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is also applied to </font></font><a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GTA V</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It should also be noted that the overall red tint of the scene is obtained by color correction.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> UI and film grain </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finally, the UI is located on top of the game frame; </font><font style="vertical-align: inherit;">at the same time, a small </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%2597%25D0%25B5%25D1%2580%25D0%25BD%25D0%25B8%25D1%2581%25D1%2582%25D0%25BE%25D1%2581%25D1%2582%25D1%258C_(%25D1%2584%25D0%25BE%25D1%2582%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%258F)"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">film grain</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> effect is added </font><font style="vertical-align: inherit;">. </font></font><br><br><img src="https://habrastorage.org/files/141/ef2/c13/141ef2c132a24abda9012ac39a974b22.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UI and graininess: before </font></font></em> <br><br><img src="https://habrastorage.org/files/da6/3bd/8c1/da63bd8c1a4d463eb227b659573aa2d4.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UI and graininess: after</font></font></em> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And we have completed frame processing, it is ready to be transferred to a monitor for display; </font><font style="vertical-align: inherit;">a lot of calculations have been done, but it all happened in less than 16 milliseconds. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DOOM manages to create a high-quality picture at a high game speed, because it wisely uses old data calculated in previous frames. </font><font style="vertical-align: inherit;">In total, we had 1331 draw calls, 132 textures, and 50 render buffers.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Bonus Information </font></font></h1><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> More about glass </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The result of glass rendering is very good; </font><font style="vertical-align: inherit;">at the same time, it was achieved in rather simple ways, which we considered above:</font></font><br><br><ul><li>        </li><li>      ¬´ ¬ª      //           ;         . </li></ul><br><img src="https://habrastorage.org/files/705/4d0/c20/7054d0c202ec48648695c043fc714e6d.jpg"><br> <em>: </em> <br><br><img src="https://habrastorage.org/files/d9c/313/1a4/d9c3131a48974778bd19350bd0b59c4b.jpg"><br> <em>: </em> <br><br><h2>   </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The frame we studied doesn‚Äôt see the </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D0%25BB%25D1%2583%25D0%25B1%25D0%25B8%25D0%25BD%25D0%25B0_%25D1%2580%25D0%25B5%25D0%25B7%25D0%25BA%25D0%25BE_%25D0%25B8%25D0%25B7%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D0%25B6%25D0%25B0%25D0%25B5%25D0%25BC%25D0%25BE%25D0%25B3%25D0%25BE_%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D1%2581%25D1%2582%25D0%25B2%25D0%25B0"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">depth of field</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , so let's consider the following scene before and after applying it: </font></font><br><br><img src="https://habrastorage.org/files/5ff/1ca/2a1/5ff1ca2a1456484397089e518f74d9bd.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Depth of field: before </font></font></em> <br><br><img src="https://habrastorage.org/files/aba/f67/d90/abaf67d903bf45e1874e6d371ed5244b.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Depth of field: after</font></font></em> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not all games apply depth of field correctly: the naive approach often consists of using Gaussian blur and performing blurring in one passage depending on pixel depth. </font><font style="vertical-align: inherit;">This approach is simple and economical, but it has some problems:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gaussian blur is good for the bloom effect, it incorrectly creates the </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%2591%25D0%25BE%25D0%25BA%25D0%25B5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bokeh</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : you need a flat center for the light of a bright pixel to spread across the entire disk or hex. </font><font style="vertical-align: inherit;">Gaussian blur is not able to create beautiful forms of bokeh.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> applying a depth of field in a single pixel shader step can easily lead to border artifacts. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In DOOM, depth of field is applied correctly; </font><font style="vertical-align: inherit;">In my experience, one of the approaches that give the best results was chosen: images with large and small depth of field are created: the selection of pixels is made depending on its depth and depth of field parameters.</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> An image with a shallow depth can be very blurred, the more it ‚Äúspreads‚Äù to the pixels behind it, the better. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The image with a large depth is also blurred, but it does not read pixels from the area in focus / shallow depth of field, so it avoids problems with objects in the foreground, mistakenly ‚Äúspreading‚Äù onto the background. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To create a bokeh blur, DOOM works at half resolution and performs a circular blur with 64 texture overlays, each fragment has the same weight, so the brightness actually spreads around, unlike the Gaussian blur. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The diameter of the circle can vary pixel by pixel, depending on the value </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%258F%25D1%2582%25D0%25BD%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D1%2581%25D0%25B5%25D1%258F%25D0%25BD%25D0%25B8%25D1%258F"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">of the</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pixel </font><a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%258F%25D1%2582%25D0%25BD%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D1%2581%25D0%25B5%25D1%258F%25D0%25BD%25D0%25B8%25D1%258F"><font style="vertical-align: inherit;">scattering spot</font></a><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Then the bokeh extends further with a blur of 16 overlays, but this time the weighted average is not calculated, but the sample values ‚Äã‚Äãare accumulated and the largest value of the adjacent overlays is stored; this not only expands the first blur, but also eliminates small artifacts (omissions in sampling) of the first pass. The last part of the algorithm is taken from </font></font><a href="http://ivizlab.sfu.ca/papers/cgf2012.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">McIntosh</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (McIntosh).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This technique of iteration over several passes allows to get very beautiful large blur, while remaining at the same time effective in terms of performance; </font><font style="vertical-align: inherit;">The number of texture overlays per pixel is still quite small, given the large radius of the resulting final circular blur. </font></font><br><br><img src="https://habrastorage.org/files/b8b/b2a/86e/b8bb2a86ec2946d3b7caaa24ff270cf0.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deep Depth of Field </font></font></em> <br><br><img src="https://habrastorage.org/files/1d9/d89/9bf/1d9d899bfb5543468cf411941511948e.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deep Depth of Field and Blur 1 </font></font></em> <br><br><img src="https://habrastorage.org/files/74f/6bb/361/74f6bb361c5c4e1ca0fc165fc7176276.jpg"><br> <em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deep Depth of Field and Blur 1 and 2</font></font></em> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Finally, images with a large and a small depth of field are superimposed on the original scene with alpha channel mixing to create the final depth of field effect. </font><font style="vertical-align: inherit;">This pass is performed right before applying motion blur.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Additional sources </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If you want to dive deeper into idTech 6 technology, then fortunately there are many lectures and publications on this subject: </font></font><br><br><ul><li> <a href="http://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf">The devil is in the details: idTech 666</a> (Siggraph 2016), Tiago Sousa and Jean Geffroy </li><li> <a href="http://www.eurogamer.net/articles/digitalfoundry-2016-doom-tech-interview">Tech Interview: Doom</a> , Digital Foundry </li><li> <a href="http://www.dsogaming.com/interviews/id-software-tech-interview-dx12-vulkan-mega-textures-pbr-global-illumination-more/">id Software Tech Interview</a> , DSOGaming </li><li> <a href="https://www.twitch.tv/bethesda/v/81946710">QuakeCon 2016: Doom Uncapped ‚Äì Part1</a>  <a href="https://t.co/TXcOpgIyG8">Part 2</a> </li><li> <a href="http://venturebeat.com/2016/06/17/the-definitive-interview-on-the-making-of-doom/">Doom: The definitive interview</a> , VentureBeat </li><li> <a href="http://www.crytek.com/download/Sousa_Graphics_Gems_CryENGINE3.pdf">Graphics Gems CryEngine 3</a> (Siggraph 2013),      idTech 6. </li></ul></div><p>Source: <a href="https://habr.com/ru/post/309844/">https://habr.com/ru/post/309844/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../309832/index.html">Blue-green warm</a></li>
<li><a href="../309834/index.html">Understanding Go: the encoding package</a></li>
<li><a href="../309836/index.html">Setting and using speed limit for Open vSwitch with DPDK</a></li>
<li><a href="../309840/index.html">Android Dev: continued podcasts about professional development for Android</a></li>
<li><a href="../309842/index.html">Exit "in the field": How we made a mobile application to increase the efficiency of field workers</a></li>
<li><a href="../309846/index.html">Using blocks in iOS. Part 2</a></li>
<li><a href="../309848/index.html">Three JavaScript performance principles that make Bluebird fast</a></li>
<li><a href="../309850/index.html">1C, .Net Core. Dynamic compilation of a wrapper class for receiving events of a .Net object in 1C</a></li>
<li><a href="../309852/index.html">DevFest season 2016 in 10 cities of Russia</a></li>
<li><a href="../309854/index.html">Five kinds of game crafting systems</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>