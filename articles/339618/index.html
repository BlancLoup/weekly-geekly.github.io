<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Aftertaste from Kotlin, part 3. Korutiny - we divide the processor time</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Java allows you to write serial, parallel and asynchronous code. Asynchronous is when a callback is registered that will start after some event (for e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Aftertaste from Kotlin, part 3. Korutiny - we divide the processor time</h1><div class="post__text post__text-html js-mediator-article"> <a href="https://habrahabr.ru/post/339618/"><img src="https://habrastorage.org/webt/59/da/9a/59da9ab7230c3661009557.jpeg"></a> <br><br>  Java allows you to write serial, parallel and asynchronous code.  Asynchronous is when a callback is registered that will start after some event (for example, the file is read).  This avoids blocking the stream, but breaks the execution sequence, so that such code is written to java rather when there are no other options.  Kotlin gives a solution - <b>corutines</b> , with them the asynchronous code looks almost the same as sequential. <br><br>  There are few articles on Korutin.  There are even fewer specific examples showing their advantages. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      I have found: <br><br><ul><li>  <a href="https://habrahabr.ru/post/314656/">Getting rid of callback hell</a> .  Actual for UI </li><li>  Like the concept of <a href="">channels</a> and <a href="">actors</a> .  They are not new, it is possible without them, but for event systems should be very well suited </li><li>  <a href="https://habrahabr.ru/company/alfa/blog/336228/">Advice from Roman Elizarov</a> : "Korutin are needed for asynchronous tasks that expect something most of the time" </li></ul><br>  The latter is interesting - most enterprise applications are always waiting for something: the database, other applications, and occasionally the file needs to be read.  And all this can be completely asynchronous, which means that the whole application can be translated into asynchronous request processing. <br><br>  So, let's see how the korutiny behave under load. <br><a name="habracut"></a><br><h3>  IO vs NIO </h3><br>  Under NIO there is a <a href="https://github.com/Kotlin/kotlinx.coroutines/tree/master/integration/kotlinx-coroutines-nio">ready strapping for corutin</a> .  Write the code: <br><br><pre><code class="hljs kotlin"><span class="hljs-keyword"><span class="hljs-keyword">suspend</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">readFileAsync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>: String { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> channel = AsynchronousFileChannel.<span class="hljs-keyword"><span class="hljs-keyword">open</span></span>(filePath) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> bytes = ByteArray(size) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> byteBuffer = ByteBuffer.wrap(bytes) channel.aRead(byteBuffer, <span class="hljs-number"><span class="hljs-number">0L</span></span>) <span class="hljs-comment"><span class="hljs-comment">/*(1)*/</span></span> <span class="hljs-comment"><span class="hljs-comment">/*(2)*/</span></span> channel.close() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> bytes.toString(Charset.forName(<span class="hljs-string"><span class="hljs-string">"UTF-8"</span></span>)) } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">readFileSync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> = file.inputStream().use { it.readBytes(size).toString(Charset.forName(<span class="hljs-string"><span class="hljs-string">"UTF-8"</span></span>)) }</code> </pre> <br><h4>  How it works </h4><br>  I will not focus on the syntax, for this there is a short <a href="https://kotlinlang.ru/docs/reference/coroutines.html">guide</a> .  The bottom line is that in line (1) the method from NIO is called, in which a callback is registered, which will continue execution at point (2).  A good compiler saves local method variables and restores them to continue the program.  Between (1) and (2), while the file is being read from the disk, the stream is free and can, for example, start reading the second file.  In the case of blocking for the second reading of the file, until the first reading was completed, one more stream would have to be created and it would also be blocked. <br><br><h4>  Measure performance </h4><br>  Take JMH and <a href="">measure a</a> single call.  Bottom line: for HDD, the difference is within the margin of error, for SSD NIO in coroutine, by 7.5% ¬± 0.01% faster.  The difference is small, but this is not surprising - everything depends on the speed of the disk.  But in the case of coruntine, the threads are not blocked for the time of reading and can do other work. <br><br>  Let's see how much more work can be done while we read a given amount of data from the disk.  To do this, in ForkJoinPool we will throw the IO and CPU tasks in a certain ratio.  When we have completed 400 IO tasks, let's calculate how many purely CPU tasks have been worked out.  <a href="">Benchmark</a> <br><table><tbody><tr><th></th><th colspan="2">  Elapsed time (ms) </th><th colspan="2">  How many CPU tasks managed to perform </th></tr><tr><th>  Share IO tasks </th><th>  Sync </th><th>  Async </th><th>  Sync </th><th>  Async </th></tr><tr><td>  3/4 </td><td>  117 </td><td>  116 </td><td>  497 </td><td>  584 (+ 17%) </td></tr><tr><td>  1/2 </td><td>  128 </td><td>  127 </td><td>  1522 </td><td>  1652 (+ 8%) </td></tr><tr><td>  1/4 </td><td>  163 </td><td>  164 </td><td>  4958 </td><td>  4960 </td></tr><tr><td>  1/8 </td><td>  230 </td><td>  238 (+ 3%) </td><td>  11381 </td><td>  11495 (+ 1%) </td></tr></tbody></table><br>  There is a difference.  Measured on the HDD, in which a single reading almost did not differ.  Separately, I want to note the last line: await generates a relatively large number of objects, which additionally loads GC, this is noticeable against the background of our CPU task, which creates 50 objects.  Measured separately: the more task creates objects, the smaller the difference between Future and await until equality. <br><br><h3>  SQL </h3><br>  There was one <a href="https://github.com/mauricio/postgresql-async">library</a> that can work with the database without locks.  It is written in scala and can work only with MySql and Postgres.  If anyone knows other libraries - write in the comments. <br><br>  Await for Future from scala: <br><br><pre> <code class="hljs kotlin"><span class="hljs-keyword"><span class="hljs-keyword">suspend</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-type"><span class="hljs-function"><span class="hljs-type">&lt;T&gt;</span></span></span><span class="hljs-function"> Future</span><span class="hljs-type"><span class="hljs-function"><span class="hljs-type">&lt;T&gt;</span></span></span><span class="hljs-function">.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">await</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>: T = suspendCancellableCoroutine { cont: CancellableContinuation&lt;T&gt; -&gt; onComplete({ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (it.isSuccess) { cont.resume(it.<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>()) } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { cont.resumeWithException(it.failed().<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>()) } }, ExecutionContext.fromExecutor(ForkJoinPool.commonPool())) }</code> </pre><br>  I made a couple of tablets in Postgres, especially without indexes, so that the timing was noticeable, I launched the database in the docker, issuing 4 logical processors.  onnectionPool limited to 4. Each request to the application made three consecutive calls to the database. <br><br>  Spring makes it quite simple to make an asynchronous http server, for this it is enough to return the DeferredResult instead of the MyClasss from the controller method, and only then fill in the DeferredResult (on another thread).  For convenience, I wrote a small wrapper (indicated by numbers with the actual order of execution): <br><br><pre> <code class="hljs kotlin"><span class="hljs-meta"><span class="hljs-meta">@GetMapping(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"/async"</span></span></span><span class="hljs-meta">)</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">async</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>: DeferredResult&lt;Response&gt; = asyncResponse { (<span class="hljs-number"><span class="hljs-number">4</span></span>) <span class="hljs-comment"><span class="hljs-comment">//code that produce Response } fun &lt;R&gt; asyncResponse(body: suspend CoroutineScope.() -&gt; R): DeferredResult&lt;R&gt; { (1) val result = DeferredResult&lt;R&gt;() //  (2) launch(CommonPool) { //  try { (5) result.setResult(body.invoke(this)) } catch (e: Exception) { (5') result.setErrorResult(e) } } (3) return result // DeferredResult,    }</span></span></code> </pre><br>  A separate problem was to decide how to wait for a connection from the pool for sync and async options.  For sync is set in ms, and for async - in pieces.  I decided that the average request to the database was ~ 30ms, so the time was divided into 30 - I got the pieces (it turned out I was wrong about a third). <br><br>  The application is launched by issuing one logical processor.  On another machine, put the <a href="https://tech.yandex.ru/tank/">Yandex tank</a> and shot the application.  To my surprise, there was no difference ... up to 50 rps (left <a href="https://overload.yandex.net/50485">async</a> , right <a href="https://overload.yandex.net/50480">sync</a> ). <br><img src="https://habrastorage.org/webt/59/da/99/59da99377c378764307410.png"><br>  After 50 rps, 4 connections ceased to be enough (the average timing at this point was 80 rps) and the synchronous version reached 66 seconds for 11 seconds and died ‚Äî only timeout responded to any request (even if the load was removed altogether), and asynchronous to 54 rps went to 730ms and began to process exactly as many requests as the base allowed, for all the rest - 500, while errors were almost always discarded instantly. <br><br>  When you run an application with eight logical processors, the picture has changed a bit ( <a href="https://overload.yandex.net/50488">async</a> on the left, <a href="https://overload.yandex.net/50492">sync</a> on the right) <br><img src="https://habrastorage.org/webt/59/da/99/59da993c7fdfb543219937.png"><br>  The synchronous version from 60 to 80rps answered for 3 seconds, discarding unnecessary requests, and completely stopped responding only to 91rps. <br><br>  Why did this happen?  Tomcat creates up to 200 (default) threads to handle incoming requests.  When requests come in more than can be processed, they are all created and after a while all are blocked.  In this case, each request should receive a connection 3 times and waits every second in a second.  In the case of the asynchronous option, the request does not wait for any time, but looks at how many more people want this resource and sends an error if there are too many people interested.  In my case, the limit was 33 with 4 connections, which is probably a bit too much.  By reducing this number, we get a more acceptable response rate during server overloads. <br><br><h3>  HTTP </h3><br>  Smooth failure is good, but I wonder if it is possible to get a performance boost in regular situations. <br><br>  This time the application went over http to the stub, the stub responded with a delay (from 1.5 ms).  Made two options: 100 consecutive and 100 parallel (batch) requests for a stub.  Measured with JMH in 1 and 6 threads (imitated different loads). <br><table><tbody><tr><th></th><th colspan="3">  Sequentially (avg ms) </th><th colspan="3">  In parallel (avg ms) </th></tr><tr><th></th><th>  Sync </th><th>  Async </th><th>  Œî </th><th>  Sync </th><th>  Async </th><th>  Œî </th></tr><tr><td>  1core / 1 jmh thread </td><td>  160.3 ¬± 1.8 </td><td>  154.1 ¬± 1.0 </td><td>  4.0% ¬± 1.7% </td><td>  163.9 ¬± 2.4 </td><td>  10.7 ¬± 0.3 </td><td>  1438.3% ¬± 4.6% </td></tr><tr><td>  2core / 1 jmh thread </td><td>  159.3 ¬± 1.0 </td><td>  156.3 ¬± 0.7 </td><td>  1.9% ¬± 1.1% </td><td>  57.6 ¬± 0.5 </td><td>  15.4 ¬± 0.2 </td><td>  274.0% ¬± 1.9% </td></tr><tr><td>  4core / 1 jmh thread </td><td>  159.0 ¬± 1.1 </td><td>  157.4 ¬± 1.3 </td><td>  1.0% ¬± 1.5% </td><td>  25.7 ¬± 0.2 </td><td>  14.8 ¬± 0.3 </td><td>  74.3% ¬± 2.8% </td></tr><tr><td>  1core / 6 jmh thread </td><td>  146.8 ¬± 2.5 </td><td>  146.3 ¬± 2.5 </td><td>  0.4% ¬± 3.4% </td><td>  984.8 ¬± 34.2 </td><td>  79.3 ¬± 3.7 </td><td>  1141.6% ¬± 5.1% </td></tr><tr><td>  2core / 6 jmh thread </td><td>  151.3 ¬± 1.6 </td><td>  143.8 ¬± 1.9 </td><td>  5.2% ¬± 2.3% </td><td>  343.9 ¬± 17.2 </td><td>  86.7 ¬± 3.7 </td><td>  296.5% ¬± 6.3% </td></tr><tr><td>  4core / 6 jmh thread </td><td>  152.3 ¬± 1.5 </td><td>  144.7 ¬± 1.2 </td><td>  5.2% ¬± 1.8% </td><td>  135.0 ¬± 3.0 </td><td>  81.7 ¬± 4.8 </td><td>  65.2% ¬± 8.1% </td></tr></tbody></table><br>  Even with successive requests, we get a gain, well, with a batch ... Of course, if we add processors, the picture for the synchronous version will be much better.  So, having increased the resources by 4 times, we will get the increase in the synchronous variant by 6.5 times, but we will not reach the speed async.  The speed of async does not depend on the number of processors. <br><br><h3>  About bad </h3><br><ul><li>  As I already mentioned, doing very small tasks in async is not beneficial.  However, I do not think that this is necessary. </li><li>  It is necessary to monitor the blocking code.  Probably, in this case, you should have a separate threadPool for their execution. </li><li>  ThreadLocal can be forgotten.  Korutina is restored in a random stream from the pool provided (in the case of NIO, you cannot even specify it ...).  RequestScope, I think, will also stop working (did not try).  Nevertheless, there is a <a href="">CoroutineContext</a> to which something can be tied, but it will have to be communicated explicitly anyway. </li><li>  The Java world is used to blocking, so non-blocking libraries are LITTLE. </li></ul><br><h3>  Aftertaste </h3><br>  Korutiny can and should be used.  They can write applications that require fewer processors to run at the same speed.  My impression is that in most cases 1-2 cores will suffice. <br><br>  Yes, also a gift in the form of resiliency. <br><br>  I hope that the best practices will gradually appear, since now it‚Äôs better to look at the patterns for working with channels in Go, async / await - in C #, yield - C # and python. <br><br>  PS: <br>  <a href="https://github.com/gnefedev/experiments/tree/master/coroutine">source code</a> <br>  <a href="https://habrahabr.ru/post/331280/">Kotlin aftertaste, part 1</a> <br>  <a href="https://habrahabr.ru/post/337002/">Kotlin aftertaste, part 2</a> </div><p>Source: <a href="https://habr.com/ru/post/339618/">https://habr.com/ru/post/339618/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../339608/index.html">The digest of interesting materials for the mobile developer # 224 (October 2 - October 8)</a></li>
<li><a href="../339610/index.html">Translation of two articles: ‚ÄúHow to commit changes to a Docker image‚Äù and ‚ÄúGuide for Moving Docker Containers‚Äù</a></li>
<li><a href="../339612/index.html">PGP offline key storage strategies</a></li>
<li><a href="../339614/index.html">Migrating business critical applications to the cloud: VMware tools overview</a></li>
<li><a href="../339616/index.html">At the bottom: what threatens underwater internet cables</a></li>
<li><a href="../339620/index.html">What to do if Instagram did not give access to the API? Addition</a></li>
<li><a href="../339624/index.html">10 famous logos drawn from memory</a></li>
<li><a href="../339626/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ283 (October 2 - 8, 2017)</a></li>
<li><a href="../339628/index.html">We unite Websockets, Lisp and functional programming</a></li>
<li><a href="../339630/index.html">PHP Digest number 118 - the latest news, materials and tools (September 24 - October 9, 2017)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>