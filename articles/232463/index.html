<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Comparison of audio recognition algorithms for Second Screen</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 To date, there are many methods of sound recognition. In the most general form, most of the methods consist of the algorithm for constr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Comparison of audio recognition algorithms for Second Screen</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  To date, there are many methods of sound recognition.  In the most general form, most of the methods consist of the algorithm for constructing a signature (fingerprints) of a signal (the most compact and most accurately describing a set of tracks), its search algorithm in the database and the algorithm for cutting off false positives.  We were faced with the task of choosing a technology for building <a href="http://en.wikipedia.org/wiki/Second_screen">second screen</a> applications. <br><img src="https://habrastorage.org/files/c4e/4c8/05e/c4e4c805e75f401ea582848c5c189512.png"><br>  The comparison of recognition algorithms based on known accuracy characteristics is rather arbitrary, since these characteristics are obtained on different test data and with different errors of the first kind (false positives).  Also, based on the context of the task, we were interested in the efficiency of the algorithm in relation to the recognition of the TV broadcast audio signal, with distortions caused by the parameters of the microphones of modern mobile devices. <br><br>  Since no comparative data was found in open sources that met our requirements, it was decided to conduct our own research of sound recognition algorithms, taking into account the specifics of the audio stream and distortions.  As a potential candidate, we chose the algorithms of J. Haitsma and A. Wang.  Both are widely known and based on the analysis of time-frequency features obtained using the window Fourier transform. <br><a name="habracut"></a><br><h4>  Description of the signature generation methods under consideration </h4><br>  The audio signal signature design scheme proposed by Jaap Haitsma and Ton Kalker in [1] is shown in Figure 1. Table 1 shows the images obtained at each stage of the algorithm. <br><br><table cellpadding="5"><tbody><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/cfa/13e/6be/cfa13e6befa3479ba06f588afeba36a7.jpg"></div></td></tr><tr><td>  Figure 1 - Jaap Haitsma and Ton Kalker signature generation scheme </td></tr></tbody></table><br>  The signal's spectrogram is constructed using the Hanna window with an overlap of 31/32.  For example, for a window size of 0.37 s, the spectrogram discretization step along the time axis is 11.6 ms.  In the next step, the algorithm divides the frequency axis into 33 subranges on the mel scale, and for each point in time, the total energy in the subband is calculated.  The resulting time distribution of energy is encoded in accordance with the expression: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/files/4a8/0cf/c21/4a80cfc217b44b1c8e9661dfb6992e78.png"></div><br>  Where <img src="https://habrastorage.org/files/89b/f42/b94/89bf42b94aa642d9abc182ffac32b01b.png">  - energy <img src="https://habrastorage.org/files/39a/9f3/ff7/39a9f3ff7e5145a1ae1297a5e9fd6c07.png">  th frame in subrange <img src="https://habrastorage.org/files/eb5/9dd/616/eb59dd6169114bd2a3d0474f65b460f7.png">  . <br><br>  Table 1 - The main stages of building a signature Jaap Haitsma and Ton Kalker <br><table border="1" cellpadding="5"><tbody><tr><td colspan="2">  Signal fragment </td></tr><tr><td>  Original </td><td>  Distorted </td></tr><tr><td colspan="2">  Construction of the spectrogram </td></tr><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/30a/28e/e79/30a28ee797e7406299b9088ce51f853e.png"></div></td><td><div style="text-align:center;"><img src="https://habrastorage.org/files/7e8/d06/14c/7e8d0614cebe4cad9bbed8038bf8114f.png"></div></td></tr><tr><td colspan="2">  Calculating the distribution of energy across subranges </td></tr><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/bbf/0e4/264/bbf0e4264f40495c8043fd3a76e32865.png"></div></td><td><div style="text-align:center;"><img src="https://habrastorage.org/files/175/efe/d5a/175efed5af634593adcf0a7ef2493080.png"></div></td></tr><tr><td colspan="2">  Energy distribution coding </td></tr><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/b5a/7d2/e10/b5a7d2e106a04cbcb3474e9478b95d00.png"></div></td><td><div style="text-align:center;"><img src="https://habrastorage.org/files/4a5/53d/868/4a553d86887942129531383f6282732f.png"></div></td></tr></tbody></table><br>  Thus, each signal interval of 11.6 ms is described by a 32-bit word.  As shown by experimental studies [1], 256 words are sufficient for reliable and resistant to many types of recognition distortion, which corresponds to a 3-second query. <br><br>  The approach to recognition proposed by Avery Li-Chun Wang [2] is based on the amplitude peaks of the spectrogram and their connections into pairs, called constellations. <br><br>  The main difficulty in the implementation of this approach lies in the algorithm for searching for peaks that are resistant to distortion.  In [3, 4], examples of relevant techniques are presented.  Among the set of local maxima of the spectrogram, peaks with maximum energy are selected.  At the same time, in order for the track description to be stable to noise, it is necessary to ensure their diversity in frequency and in time.  For this, various techniques of blurring and threshold clipping are used [3, 4].  The spectrogram of the audio track, as a rule, is divided into frames along the time axis, each of which is characterized by a certain number of peaks.  By limiting their density in this way, it is possible to leave the peaks with the maximum probability of survival, while describing in detail the change in the spectrum over time.  As an example, table 2 presents the images obtained at the main stages of the algorithm. <br><br>  Table 2 - The main stages of building a signature proposed by A. Wang <br><table border="1" cellpadding="5"><tbody><tr><td colspan="2">  Signal fragment </td></tr><tr><td>  Original </td><td>  Distorted </td></tr><tr><td colspan="2">  Construction of the spectrogram </td></tr><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/816/1bc/3fa/8161bc3faff64ad7ae5fefb219c161f2.png"></div></td><td><div style="text-align:center;"><img src="https://habrastorage.org/files/6ff/29d/ea9/6ff29dea9125441583bd35f271dfb36f.png"></div></td></tr><tr><td colspan="2">  Peak search </td></tr><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/1b2/221/694/1b22216943174d2185a4c046bbc4aa0f.png"></div></td><td><div style="text-align:center;"><img src="https://habrastorage.org/files/2f0/840/0b2/2f08400b255941369ae7c98198728cbe.png"></div></td></tr><tr><td colspan="2">  Pairing peaks </td></tr><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/files/80c/f91/7cf/80cf917cf3024d4ab41ad3df95455d72.png"></div></td><td><div style="text-align:center;"><img src="https://habrastorage.org/files/ef0/031/4f8/ef00314f81604e1cb199b31b77324b79.png"></div></td></tr></tbody></table><br>  To speed up the search process, the peaks are combined in pairs - each peak is associated with a number of other peaks located to the right along the time axis within a certain target zone.  The acceleration factor is estimated by the equation: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/22e/0b9/247/22e0b924789b42d8ae9e541d2ab5eabe.png"></div><br>  Where <img src="https://habrastorage.org/files/983/7c1/1bb/9837c11bbc7444cd9074a1ced99c211f.png">  and <img src="https://habrastorage.org/files/86b/8c7/3b4/86b8c73b428e4b6bb9ed6576d23a305e.png">  - the number of bits required to encode the peak and their pairs, respectively; <br><img src="https://habrastorage.org/files/202/555/96f/20255596f773493a999f5251d17a44f3.png">  - the number of peaks associated with the reference (branching ratio). <br><br>  At the same time, increasing the uniqueness of the hash is accompanied by a decrease in the probability of its survival, which is approximately estimated as: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/4ee/d6f/a9a/4eed6fa9a5b64463a6c79a6769ddee87.png"></div><br>  Where <img src="https://habrastorage.org/files/ed1/0d9/894/ed10d98940074da8b95abd063fce0134.png">  - the probability of survival of the peak spectrogram. <br>  Therefore, it is necessary to find the values ‚Äã‚Äãof peak density and branching ratio <img src="https://habrastorage.org/files/202/555/96f/20255596f773493a999f5251d17a44f3.png">  , providing a compromise between the search speed and the probability of recognition of the signal. <br><br>  A signal signature consists of two components: a pair hash and its offset code along the time axis.  The minimum number of bits required to encode a pair is determined by the equation: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/653/97a/3c1/65397a3c1d7d48f68fb1bbac492d32f5.png"></div><br>  Where <img src="https://habrastorage.org/files/09f/5c1/ef1/09f5c1ef1c9e41eb8eb691ca236a61ae.png">  - signal sampling frequency; <img src="https://habrastorage.org/files/50d/88a/288/50d88a288974421c9777eb6b6e14f091.png">  , <img src="https://habrastorage.org/files/f2c/6f8/11e/f2c6f811e7eb45dd9d86c9dd8eb9efb2.png">  - the size and pitch of the window used in the construction of the spectrogram; <img src="https://habrastorage.org/files/29d/1ed/c39/29d1edc398c2415996d0872e0040ca61.png">  , <img src="https://habrastorage.org/files/10c/a97/a93/10ca97a933ca4668a00850b0fec3eb26.png">  - respectively, the maximum allowable distance along the time axis and frequency axis between the peaks of the pair; <img src="https://habrastorage.org/files/77c/dce/071/77cdce0714724a98902af05258b5188d.png">  - taking the nearest largest integer. <br><br><h4>  The results of an experimental study </h4><br>  Based on the field of use, the comparison of the above recognition approaches was carried out on the basis of audio tracks of the on-air body for a total duration of 2000 minutes.  As test signals, recordings of original tracks played on TV and recorded on mobile devices of the iPhone 4, Nexus 7, Samsung GT3100 at various distances from the signal source in the presence of extraneous noise inherent in the environment were used.  The test mono signals had a sampling rate of 8 kHz when encoding the amplitude with 16 bits.  Of these, 2000 test queries were generated for a duration of 4 seconds. <br><br>  When using the J. Haitsma signature, the search was carried out using the brute force method ‚Äî directly comparing the query with each fragment in the database based on the Hamming metric.  A query was considered found if, by bit-wise comparison, its signature and the signature of the found fragment coincided by more than 65%. <br><br>  The construction of signatures on the principles of Wang was carried out with a Hanna window size of 64 ms, with a shift of 32 ms.  An own variant of the search of the spectrogram peaks was implemented, which was more suitable for recognizing the audio signal of the TV air as compared to the prototype [3].  A fragment of 4 s on average was characterized by 200 peaks and was described by 1000 pairs.  For decision making, we used the formalization of the concept of uniqueness of a peak in the score graph (score) for each variant of answers available in the database.  The request was considered recognized if the score was unique. <br><br>  Table 3 shows the results of the accuracy of the recognition algorithms obtained.  An audio fragment was considered correctly recognized if the original track was correctly identified and the request offset in it. <br><br>  Table 3 - Comparison of the accuracy of recognition algorithms <br><table border="1" cellpadding="5"><tbody><tr><td rowspan="3">  Algorithm </td><td colspan="6">  Mobile device </td></tr><tr><td colspan="2">  iPhone 4 </td><td colspan="2">  Nexus 7 </td><td colspan="2">  Samsung GT3100 </td></tr><tr><td>  <i>fp</i> ,% </td><td>  <i>fn</i> ,% </td><td>  <i>fp</i> ,% </td><td>  <i>fn</i> ,% </td><td>  <i>fp</i> ,% </td><td>  <i>fn</i> ,% </td></tr><tr><td>  J. Haitsma, T. Kalker </td><td>  0.6 </td><td>  eight </td><td>  0.6 </td><td>  ten </td><td>  0.5 </td><td>  9 </td></tr><tr><td>  On the principles of A. Wang </td><td>  0.6 </td><td>  20 </td><td>  0.6 </td><td>  25 </td><td>  0.6 </td><td>  24 </td></tr><tr><td colspan="7">  Note: <i>fp</i> - errors of the first kind (false positives);  <i>fn</i> - errors of the second kind (false negatives). </td></tr></tbody></table><br><h4>  Conclusion </h4><br>  The J. Haitsma algorithm uses an integral approach to describe the distribution of energy across frequency bands, a differential approach to encode its change in time, and also a comparison of signatures based on the Hamming distance.  All this makes this method potentially resistant to distortion.  While the share of coincident pairs of peaks of the spectrogram ranges from 1% to 3%, which does not have the best effect on noise immunity and leads to a loss in recognition probability. <br><br>  However, to use the full potential of J. Haitsma signatures, a search for a query in the database must be carried out using the brute force method.  Our implementation of the algorithm for the GPU on the video card Radeon R9 290X provides a parallel search for 2048 requests in 0.6 seconds.  Written using the libevent library, the server can handle a load of 1900 rps, with an average response time of 0.8 s.  At the same time, industrial video cards are expensive, and ordinary ones have to be installed in standard ATX packages, which are at least 3 units in size.  In one such case, we managed to place two cards.  At the same time, our implementation of server recognition on the principles of A. Wang, on a Xeon CPU E5-2660 v2 @ 2.20GHz / 32Gb, can withstand a load of 2500 rps with an average response time of 8 ms. <br><br>  I would like to note that we do not exclude the possibility of obtaining more optimal implementations of algorithms, and the results should be regarded as evaluative, not claiming to be absolute. <br><br><h4>  Bibliography </h4><br><ol><li>  <b>Jaap Haitsma, Ton Kalker</b> <a href="http://www.nhchau.com/files/AudioFingerprint-02-FP04-2.pdf">"A Highly Robust Audio Fingerprinting Syste"</a> </li><li>  <b>Avery Li-Chun Wang</b> <a href="http://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">"An Industrial-Strength Audio Search Algorithm"</a> </li><li>  <b>D. Ellis</b> <a href="http://labrosa.ee.columbia.edu/matlab/fingerprint/">"Robust Landmark-Based Audio Fingerprinting"</a> </li><li>  <b>E. Krofto</b> <a href="https://tech.yandex.ru/events/yac/2013/talks/1139/">‚ÄúHow Yandex recognizes music from a microphone‚Äù</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/232463/">https://habr.com/ru/post/232463/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../232451/index.html">Developer Updates for Windows</a></li>
<li><a href="../232453/index.html">We build in local notifications</a></li>
<li><a href="../232455/index.html">Properly choose a cloud call center</a></li>
<li><a href="../232459/index.html">How not to stay hungry or unlimited passage to the dining room</a></li>
<li><a href="../232461/index.html">The first release of Visual Studio Tools for Unity 1.9 after purchasing SyntaxTree</a></li>
<li><a href="../232469/index.html">Saxophone first printed on a 3D printer</a></li>
<li><a href="../232471/index.html">Linguistic riddle. We translate from the "dead" language. [¬ß2] Debriefing</a></li>
<li><a href="../232473/index.html">Electric car SunSwift eVe traveled 500 kilometers in 4 hours and 40 minutes</a></li>
<li><a href="../232475/index.html">How i played bank</a></li>
<li><a href="../232477/index.html">Photo Widget DIY</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>