<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The experience of creating a real-time video sequencer on iOS</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, my name is Anton and I am an iOS developer at Rosberry. Not so long ago, I had the opportunity to work on the Hype Type project and to solve sever...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The experience of creating a real-time video sequencer on iOS</h1><div class="post__text post__text-html js-mediator-article"><p>  Hi, my name is Anton and I am an iOS developer at Rosberry.  Not so long ago, I had the opportunity to work on the Hype Type project and to solve several interesting tasks on working with video, text and animations.  In this article I will talk about the pitfalls and possible ways to circumvent them when writing realtime video sequencer on iOS. </p><a name="habracut"></a><br><h2 id="nemnogo-o-samom-prilozhenii">  A little about the application itself ... </h2><br><p>  Hype Type allows the user to record several short snippets of video and / or photos with a total duration of up to 15 seconds, add text to the resulting clip and apply one of the animations to choose from. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/43e/832/dc7/43e832dc797efdf2ed2f3b9dd35834cc.gif" alt="image"></p><br><p>  The main feature of working with video in this case is that the user should be able to control the video excerpts independently of each other: change the playback speed, reverse, flip and (possibly in future versions) change the passages on the fly. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b43/10d/b08/b4310db08394f20e91ba68acc2a75441.gif" alt="image"></p><br><h2 id="gotovye-resheniya">  Ready solutions? </h2><br><p>  ‚ÄúWhy not use <strong>AVMutableComposition</strong> ?‚Äù You might ask, and, in most <br>  cases, you are right - this is really quite a convenient system video sequencer, but, alas, it has limitations that prevented us from using it.  First of all, it is the inability to change and add tracks on the fly - to get the modified video stream you need to recreate the <strong>AVPlayerItem</strong> and reinitialize the <strong>AVPlayer</strong> .  Also, <strong>AVMutableComposition is</strong> far from ideal work with images - in order to add a static image to the timeline, you have to use <strong>AVVideoCompositionCoreAnimationTool</strong> , which will add a fair amount of overhead and significantly slow down the render. </p><br><p>  A brief search on the Internet did not reveal any other more or less suitable solutions for the problem, so it was decided to write your sequencer. </p><br><h2 id="itak">  So‚Ä¶ </h2><br><p>  First, a little about the render pipeline structure in the project.  I will say straight away that I will not go into the details too much and I will consider that you are already more or less familiar with this topic, otherwise this material will grow to an incredible scale.  If you are a beginner - I advise you to pay attention to the fairly well-known <strong>GPUImage</strong> framework ( <a href="https://github.com/BradLarson/GPUImage">Obj-C</a> , <a href="https://github.com/BradLarson/GPUImage2">Swift</a> ) - this is a great starting point in order to understand <strong>OpenGLES</strong> in an illustrative example. </p><br><p>  View, which is engaged in drawing the received video on the screen on a timer ( <strong>CADisplayLink</strong> ), requests frames from the sequencer.  Since the application works primarily with video, it is most logical to use <strong>YCbCr colorspace</strong> and transfer each frame as <strong>CVPixelBufferRef</strong> .  After receiving the frame, luminance and chrominance textures are created, which are transferred to the shader program.  The output is an RGB image, which the user sees.  In this case, the <strong>refresh loop</strong> will look something like this: </p><br><pre><code class="objectivec hljs">- (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)onDisplayRefresh:(<span class="hljs-built_in"><span class="hljs-built_in">CADisplayLink</span></span> *)sender { <span class="hljs-comment"><span class="hljs-comment">// advance position of sequencer [self.source advanceBy:sender.duration]; // check for new pixel buffer if ([self.source hasNewPixelBuffer]) { // get one PixelBuffer *pixelBuffer = [self.source nextPixelBuffer]; // dispatch to gl processing queue [self.context performAsync:^{ // prepare textures self.luminanceTexture = [self.context.textureCache textureWithPixelBuffer:pixelBuffer planeIndex:0 glFormat:GL_LUMINANCE]; self.chrominanceTexture = [self.context.textureCache textureWithPixelBuffer:pixelBuffer planeIndex:1 glFormat:GL_LUMINANCE_ALPHA]; // prepare shader program, uniforms, etc self.program.orientation = pixelBuffer.orientation; // ... // signal to draw [self setNeedsRedraw]; }]; } if ([self.source isFinished]) { // rewind if needed [self.source rewind]; } } // ... - (void)draw { [self.context performSync:^{ // bind textures [self.luminanceTexture bind]; [self.chrominanceTexture bind]; // use shader program [self.program use]; // unbind textures [self.luminanceTexture unbind]; [self.chrominanceTexture unbind]; }]; }</span></span></code> </pre> <br><p>  Virtually everything here is built on wrappers (for <strong>CVPixelBufferRef</strong> , <strong>CVOpenGLESTexture</strong> , etc.), which allows you to take the main low-level logic to a separate layer and significantly simplify the basic points of working with <strong>OpenGL</strong> .  Of course, this has its drawbacks (mostly - a small loss of performance and less flexibility), but they are not so critical.  What is worth explaining: <strong>self.context</strong> is a fairly simple wrapper over <strong>EAGLContext</strong> that facilitates working with <a href="https://developer.apple.com/reference/corevideo/cvopenglestexturecache-q2r"><strong>CVOpenGLESTextureCache</strong></a> and multithreaded calls to <strong>OpenGL</strong> .  <strong>self.source</strong> is a sequencer that decides which frame from which track to render in view. </p><br><p>  Now about how the reception of frames for rendering is organized.  Since the sequencer should work with both video and pictures, it is most logical to close everything with a general protocol.  Thus, the sequencer's task will be reduced to keeping track of the playhead and, depending on its position, to give a new frame from the corresponding track. </p><br><pre> <code class="objectivec hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">@protocol</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MovieSourceProtocol</span></span></span><span class="hljs-class"> &lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NSObject</span></span></span><span class="hljs-class">&gt; // </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">start</span></span></span><span class="hljs-class"> &amp; </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">stop</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">reading</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">methods</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">void</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">startReading</span></span></span><span class="hljs-class">; - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">void</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">cancelReading</span></span></span><span class="hljs-class">; // </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">methods</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">for</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">getting</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">frame</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rate</span></span></span><span class="hljs-class"> &amp; </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">current</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">offset</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">float</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">frameRate</span></span></span><span class="hljs-class">; - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">float</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">offset</span></span></span><span class="hljs-class">; // </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">method</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">check</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">if</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">we</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">already</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">read</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">everything</span></span></span><span class="hljs-class">... - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">BOOL</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">isFinished</span></span></span><span class="hljs-class">; // ...</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">and</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rewind</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">source</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">if</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">we</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">did</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">void</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rewind</span></span></span><span class="hljs-class">; // </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">method</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">for</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">scrubbing</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">void</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">seekToOffset</span></span></span><span class="hljs-class">:(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CGFloat</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">offset</span></span></span><span class="hljs-class">; // </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">method</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">for</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">reading</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">frames</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PixelBuffer</span></span></span><span class="hljs-class"> *)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">nextPixelBuffer</span></span></span><span class="hljs-class">; @</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">end</span></span></span></span></code> </pre> <br><p>  The logic of how to receive frames falls on objects that implement the <strong>MovieSourceProtocol</strong> .  Such a scheme makes it possible to make the system universal and expandable, since the only difference in image and video processing will be only the method of obtaining frames. </p><br><p>  Thus, the <strong>VideoSequencer</strong> becomes quite simple, and the main difficulty is the definition of the current track and the reduction of all tracks to a single frame rate. </p><br><pre> <code class="objectivec hljs">- (PixelBuffer *)nextPixelBuffer { <span class="hljs-comment"><span class="hljs-comment">// get current track VideoSequencerTrack *track = [self trackForPosition:self.position]; // get track source id&lt;MovieSourceProtocol&gt; source = track.source; // Here's our source // get pixel buffer return [source nextPixelBuffer]; }</span></span></code> </pre> <br><p>  VideoSequencerTrack here is a wrapper over an object that implements a MovieSourceProtocol containing a different metadata. </p><br><pre> <code class="objectivec hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">@interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FCCGLVideoSequencerTrack</span></span></span><span class="hljs-class"> : </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NSObject</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">id</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">initWithSource</span></span></span><span class="hljs-class">:(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">id</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MovieSourceProtocol</span></span></span><span class="hljs-class">&gt;)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">source</span></span></span><span class="hljs-class">; @</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">property</span></span></span><span class="hljs-class"> (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">nonatomic</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">assign</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">BOOL</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">editable</span></span></span><span class="hljs-class">; // ... </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">and</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">other</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">metadata</span></span></span><span class="hljs-class"> @</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">end</span></span></span></span></code> </pre> <br><h2 id="rabotaem-so-statikoy">  We work with statics </h2><br><p>  We now turn directly to the receipt of personnel.  Consider the simplest case - the display of a single image.  It is possible to get it either from the camera, and then we can immediately get the <strong>CVPixelBufferRef</strong> in the <strong>YCbCr</strong> format, which you can simply copy (why this is important, I will explain later) and send on request;  or from the media library - in this case, you have to twist a little and manually convert the image into the desired format.  The conversion from <strong>RGB</strong> to <strong>YCbCr</strong> could be transferred to the GPU, however on modern devices and the CPU it does the job fairly quickly, especially considering the fact that the application additionally sprinkles and compresses the image before using it.  Otherwise, everything is quite simple, all that needs to be done is to give the same frame within the allotted period of time. </p><br><pre> <code class="objectivec hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">@implementation</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ImageSource</span></span></span><span class="hljs-class"> // </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">init</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">pixel</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">buffer</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">from</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">camera</span></span></span><span class="hljs-class"> - (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">id</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">initWithPixelBuffer</span></span></span><span class="hljs-class">:(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PixelBuffer</span></span></span><span class="hljs-class"> *)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">pixelBuffer</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">orientation</span></span></span><span class="hljs-class">:(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AVCaptureVideoOrientation</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">orientation</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">duration</span></span></span><span class="hljs-class">:(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NSTimeInterval</span></span></span><span class="hljs-class">)</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">duration</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> = [<span class="hljs-keyword"><span class="hljs-keyword">super</span></span> init]) { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.orientation = orientation; <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.pixelBuffer = [pixelBuffer <span class="hljs-keyword"><span class="hljs-keyword">copy</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.duration = duration; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>; } <span class="hljs-comment"><span class="hljs-comment">// init with UIImage - (id)initWithImage:(UIImage *)image duration:(NSTimeInterval)duration { if (self = [super init]) { self.duration = duration; self.orientation = AVCaptureVideoOrientationPortrait; // prepare empty pixel buffer self.pixelBuffer = [[PixelBuffer alloc] initWithSize:image.size pixelFormat:kCVPixelFormatType_420YpCbCr8BiPlanarFullRange]; // get base addresses of image planes uint8_t *yBaseAddress = self.pixelBuffer.yPlane.baseAddress; size_t yPitch = self.pixelBuffer.yPlane.bytesPerRow; uint8_t *uvBaseAddress = self.pixelBuffer.uvPlane.baseAddress; size_t uvPitch = self.pixelBuffer.uvPlane.bytesPerRow; // get image data CFDataRef pixelData = CGDataProviderCopyData(CGImageGetDataProvider(image.CGImage)); uint8_t *data = (uint8_t *)CFDataGetBytePtr(pixelData); uint32_t imageWidth = image.size.width; uint32_t imageHeight = image.size.height; // do the magic (convert from RGB to YCbCr) for (int y = 0; y &lt; imageHeight; ++y) { uint8_t *rgbBufferLine = &amp;data[y * imageWidth * 4]; uint8_t *yBufferLine = &amp;yBaseAddress[y * yPitch]; uint8_t *cbCrBufferLine = &amp;uvBaseAddress[(y &gt;&gt; 1) * uvPitch]; for (int x = 0; x &lt; imageWidth; ++x) { uint8_t *rgbOutput = &amp;rgbBufferLine[x * 4]; int16_t red = rgbOutput[0]; int16_t green = rgbOutput[1]; int16_t blue = rgbOutput[2]; int16_t y = 0.299 * red + 0.587 * green + 0.114 * blue; int16_t u = -0.147 * red - 0.289 * green + 0.436 * blue; int16_t v = 0.615 * red - 0.515 * green - 0.1 * blue; yBufferLine[x] = CLAMP(y, 0, 255); cbCrBufferLine[x &amp; ~1] = CLAMP(u + 128, 0, 255); cbCrBufferLine[x | 1] = CLAMP(v + 128, 0, 255); } } CFRelease(pixelData); } return self; } // ... - (BOOL)isFinished { return (self.offset &gt; self.duration); } - (void)rewind { self.offset = 0.0; } - (PixelBuffer *)nextPixelBuffer { if ([self isFinished]) { return nil; } return self.pixelBuffer; } // ...</span></span></code> </pre> <br><h2 id="rabotaem-s-video">  We work with video </h2><br><p>  And now add the video.  For this, it was decided to use <strong>AVPlayer</strong> - mainly due to the fact that it has a quite convenient API for receiving frames and completely takes over the work with sound.  In general, it sounds simple enough, but there are some points that are worth paying attention to. <br>  Let's start with the obvious: </p><br><pre> <code class="objectivec hljs">- (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)setURL:(<span class="hljs-built_in"><span class="hljs-built_in">NSURL</span></span> *)url withCompletion:(<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>(^)(<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span> success))completion { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.setupCompletion = completion; <span class="hljs-comment"><span class="hljs-comment">// prepare asset self.asset = [[AVURLAsset alloc] initWithURL:url options:@{ AVURLAssetPreferPreciseDurationAndTimingKey : @(YES), }]; // load asset tracks __weak VideoSource *weakSelf = self; [self.asset loadValuesAsynchronouslyForKeys:@[@"tracks"] completionHandler:^{ // prepare player item weakSelf.playerItem = [AVPlayerItem playerItemWithAsset:weakSelf.asset]; [weakSelf.playerItem addObserver:weakSelf forKeyPath:@"status" options:NSKeyValueObservingOptionNew context:nil]; }]; } - (void)observeValueForKeyPath:(NSString *)keyPath ofObject:(id)object change:(NSDictionary *)change context:(void *)context { if(self.playerItem.status == AVPlayerItemStatusReadyToPlay) { // ready to play, prepare output NSDictionary *outputSettings = @{ (id)kCVPixelBufferPixelFormatTypeKey: @(kCVPixelFormatType_420YpCbCr8BiPlanarFullRange), (id)kCVPixelBufferOpenGLESCompatibilityKey: @(YES), (id)kCVPixelBufferOpenGLCompatibilityKey: @(YES), (id)kCVPixelBufferIOSurfacePropertiesKey: @{ @"IOSurfaceOpenGLESFBOCompatibility": @(YES), @"IOSurfaceOpenGLESTextureCompatibility": @(YES), }, }; self.videoOutput = [[AVPlayerItemVideoOutput alloc] initWithPixelBufferAttributes:outputSettings]; [self.playerItem addOutput:self.videoOutput]; if (self.setupCompletion) { self.setupCompletion(); } }; } // ... - (void) rewind { [self seekToOffset:0.0]; } - (void)seekToOffset:(CGFloat)offset { [self.playerItem seekToTime:[self timeForOffset:offset] toleranceBefore:kCMTimeZero toleranceAfter:kCMTimeZero]; } - (PixelBuffer *)nextPixelBuffer { // check for new pixel buffer... CMTime time = self.playerItem.currentTime; if(![self.videoOutput hasNewPixelBufferForItemTime:time]) { return nil; } // ... and grab it if there is one CVPixelBufferRef bufferRef = [self.videoOutput copyPixelBufferForItemTime:time itemTimeForDisplay:nil]; if (!bufferRef) { return nil; } PixelBuffer *pixelBuffer = [[FCCGLPixelBuffer alloc] initWithPixelBuffer:bufferRef]; CVBufferRelease(bufferRef); return pixelBuffer; }</span></span></code> </pre> <br><p>  We create <strong>AVURLAsset</strong> , load the information about the tracks, create an <strong>AVPlayerItem</strong> , wait for a notification that it is ready for playback and create an <strong>AVPlayerItemVideoOutput</strong> with suitable parameters for rendering - everything is still quite simple. </p><br><p>  However, the first problem also lies there - <strong>seekToTime</strong> is not fast enough, and there are noticeable delays with the loop.  If you don‚Äôt change the <strong>tolerance</strong> parameters <strong>Before</strong> and <strong>tolerance After</strong> , then it makes little difference, except that, in addition to the delay, positioning inaccuracy is also added.  This is a limitation of the system and it cannot be completely solved, but it is possible to bypass it, for which it‚Äôs enough to cook 2 <strong>AVPlayerItem</strong> 'a and use them one by one - as soon as one of them finishes playing, he immediately starts playing the other while the first one is rewound to the beginning.  And so in a circle. </p><br><p>  Another unpleasant, but solvable problem - <strong>AVFoundation</strong> as it follows (seamless &amp; smooth) supports changing the playback speed and reverse is not for all file types, and if in the case of recording from the camera we control the output format, then if the user downloads video from the media library, we have no such luxury.  Making the users wait until the video is converted - the output is bad, all the more far from the fact that they will use these settings, so it was decided to do it in the background and quietly replace the original video with the converted one. </p><br><pre> <code class="objectivec hljs">- (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)processAndReplace:(<span class="hljs-built_in"><span class="hljs-built_in">NSURL</span></span> *)inputURL outputURL:(<span class="hljs-built_in"><span class="hljs-built_in">NSURL</span></span> *)outputURL { [[<span class="hljs-built_in"><span class="hljs-built_in">NSFileManager</span></span> defaultManager] removeItemAtURL:outputURL error:<span class="hljs-literal"><span class="hljs-literal">nil</span></span>]; <span class="hljs-comment"><span class="hljs-comment">// prepare reader MovieReader *reader = [[MovieReader alloc] initWithInputURL:inputURL]; reader.timeRange = self.timeRange; // prepare writer MovieWriter *writer = [[FCCGLMovieWriter alloc] initWithOutputURL:outputURL]; writer.videoSettings = @{ AVVideoCodecKey: AVVideoCodecH264, AVVideoWidthKey: @(1280.0), AVVideoHeightKey: @(720.0), }; writer.audioSettings = @{ AVFormatIDKey: @(kAudioFormatMPEG4AAC), AVNumberOfChannelsKey: @(1), AVSampleRateKey: @(44100), AVEncoderBitRateStrategyKey: AVAudioBitRateStrategy_Variable, AVEncoderAudioQualityForVBRKey: @(90), }; // fire up reencoding MovieProcessor *processor = [[MovieProcessor alloc] initWithReader:reader writer:writer]; processor.processingSize = (CGSize){ .width = 1280.0, .height = 720.0 }; __weak FCCGLMovieStreamer *weakSelf = self; [processor processWithProgressBlock:nil andCompletion:^(NSError *error) { if(!error) { weakSelf.replacementURL = outputURL; } }]; }</span></span></code> </pre> <br><p>  <strong>MovieProcessor</strong> here is a service that receives frames and audio samples from the reader and gives them to the writer.  (In fact, he also knows how to handle the frames received from the reader on the GPU, but this is used only when rendering the entire project in order to put animation frames on the finished video) </p><br><h2 id="a-teper-poslozhnee">  And now more difficult </h2><br><p>  And what if the user wants to add 10-15 video clips to the project right away?  Since the application should not limit the user in the number of clips that he can use in the application, you need to provide for this scenario. </p><br><p>  If you prepare each passage for playback as needed, there will be too noticeable delays.  Preparing to play all the clips at once does not work either - due to the limitation of iOS on the number of h264 decoders operating at the same time.  Of course, there is a way out of this situation and it is quite simple - to prepare in advance a couple of tracks that will be played next, ‚Äúclearing‚Äù those that are not planned to be used in the near future. </p><br><pre> <code class="objectivec hljs">- (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>) cleanupTrackSourcesIfNeeded { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-built_in"><span class="hljs-built_in">NSUInteger</span></span> cleanupDelta = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">NSUInteger</span></span> trackCount = [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.tracks count]; <span class="hljs-built_in"><span class="hljs-built_in">NSUInteger</span></span> currentIndex = [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.tracks indexOfObject:<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.currentTrack]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (currentIndex == <span class="hljs-built_in"><span class="hljs-built_in">NSNotFound</span></span>) { currentIndex = <span class="hljs-number"><span class="hljs-number">0</span></span>; } <span class="hljs-built_in"><span class="hljs-built_in">NSUInteger</span></span> index = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (FCCGLVideoSequencerTrack *track <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.tracks) { <span class="hljs-built_in"><span class="hljs-built_in">NSUInteger</span></span> currentDelta = MAX(currentIndex, index) - MIN(currentIndex, index); currentDelta = MIN(currentDelta, index + (trackCount - currentIndex - <span class="hljs-number"><span class="hljs-number">1</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (currentDelta &gt; cleanupDelta) { track.playheadPosition = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; [track.source cancelReading]; [track.source cleanup]; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { [track.source startReading]; } ++index; } }</code> </pre> <br><p>  This uncomplicated way was able to achieve continuous playback and loop'a.  Yes, with scrubbing there will inevitably be a small lag, but this is not so critical. </p><br><h2 id="podvodnye-kamni">  Underwater rocks </h2><br><p>  Finally, I will tell you a little about the pitfalls that may occur when solving such problems. </p><br><p>  The first is if you work with pixel buffers received from the camera of the device - either release them immediately or copy them if you want to use them later.  Otherwise, the video stream will freeze - I did not find mention of this restriction in the documentation, but, apparently, the system tracks pixel buffers, which it gives and simply will not give you new ones while the old ones are hanging in memory. </p><br><p>  The second is multithreading when working with <strong>OpenGL</strong> .  <strong>OpenGL</strong> itself is not very friendly, however, this can be circumvented by using different <strong>EAGLContext</strong> , located in the same <a href="https://developer.apple.com/documentation/opengles/eaglsharegroup"><strong>EAGLSharegroup</strong></a> , which allows you to quickly and simply share the logic of drawing what the user sees on the screen, and various background processes (video processing, rendering etc.). </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/332416/">https://habr.com/ru/post/332416/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../332402/index.html">Lunch Break Refactoring: Introduction to Submod Scripts</a></li>
<li><a href="../332406/index.html">How to protect data center from DDoS attacks?</a></li>
<li><a href="../332408/index.html">Video from Avito Data Science meetup</a></li>
<li><a href="../332412/index.html">Virtual site development pipeline and automation</a></li>
<li><a href="../332414/index.html">Announcement of the conference HolyJS 2017 Moscow: Two days of pure JS</a></li>
<li><a href="../332418/index.html">Create a UWP application in SPL</a></li>
<li><a href="../332422/index.html">Integration of HostTracker with Slack. Site stability: how to keep everyone up to date</a></li>
<li><a href="../332426/index.html">Cisco CDR and Asterisk Telephony Analysis with Splunk</a></li>
<li><a href="../332428/index.html">TI SensorTag, Eclipse kura and web parts integration via Apache Camel</a></li>
<li><a href="../332430/index.html">VKontakte data center</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>