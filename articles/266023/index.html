<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Error compensation for floating-point operations</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The work is devoted to rounding errors that occur when calculating floating-point numbers. The following topics will be briefly discussed here: ‚ÄúRepre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Error compensation for floating-point operations</h1><div class="post__text post__text-html js-mediator-article">  The work is devoted to rounding errors that occur when calculating floating-point numbers.  The following topics will be briefly discussed here: ‚ÄúRepresentation of Real Numbers‚Äù, ‚ÄúMethods for Finding Round Offsets of Floating Point Numbers‚Äù and will give an example of compensation for rounding offsets. <br><br>  In this paper, examples are given in the programming language C. <br><a name="habracut"></a><br><h2>  Representation of real numbers </h2><br>  Consider the representation of a finite real number in the IEEE 754-2008 standard as an expression, which is characterized by three elements: <b>S</b> (0 or 1), the mantissa <b>M</b> and the order <b>E</b> : <br><br>  v = -1 <sup>S</sup> * b <sup>(E - BIAS)</sup> * M 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  base <b>b</b> (the standard defines three binary formats and two decimal); </li><li>  the length of the mantissa <b>p</b> , which determines the accuracy of the representation of a number, is measured in numbers (binary or decimal); </li><li>  the maximum value of the order of <b>emax</b> ; </li><li>  the minimum value of the order of <b>emin</b> ;  The standard requires that the condition be met: <br><pre><code class="bash hljs">emin = 1-emax</code> </pre> </li><li>  <b>BIAS</b> (offset);  order is recorded in the so-called.  offset form, i.e. <br>  the real value of the exponent is <b>E-BIAS</b> . </li></ul><br>  The table below shows the parameters of standard floating-point number formats.  Here: <b>w</b> is the width of the bit field to represent the order, <b>t</b> is the width of the bit field to represent the mantissa, <b>k</b> is the full width of the bit string. <br><br><img src="https://habrastorage.org/files/df7/66b/2dd/df766b2dddd748f3a454a304b8216b5f.png"><br><br>  The following table shows the ranges of variation and accuracy of standard 32 and 64-bit floating-point real-format formats. <br><br><img src="https://habrastorage.org/files/8d6/910/e0a/8d6910e0a41e46ea8619591bee037ea9.png"><br><br>  Here "Precision, Epsilon" is the smallest number for which the expression is true: <br><br><pre> <code class="bash hljs">1 + EPSILON != 1</code> </pre> <br><br>  This Epsilon value characterizes the relative accuracy of the operations of addition and subtraction: if the value added to <b>x</b> or subtracted from <b>x</b> is less than <b>epsilon * x</b> , then the result will remain equal to <b>x</b> .  In practice, in some cases, when used in additive operations of quantities approaching in order of <b>epsilon * x</b> , <b>rounding errors of the</b> smaller term begin to affect.  About such situations and will be discussed in this work. <br><br>  Consider the representation of a real number for the float (Binary32) data type. <br><br><img src="https://habrastorage.org/files/47d/c2c/fe9/47dc2cfe9c204406b2c20c8d2786b335.png"><br><br>  In this example: <br><br><ul><li>  Number <b>V</b> = 0.15625 <sub>10</sub> </li><li>  The sign <b>S</b> = 0, i.e.  + </li><li>  Order <b>(E - BIAS)</b> = 01111100 <sub>2</sub> - 01111111 <sub>2</sub> = 124 <sub>10</sub> - 127 <sub>10</sub> = -3 <sub>10</sub> </li><li>  Mantissa <b>M</b> = 1.010000000000000000000 <sub>2</sub> </li></ul><br>  Thus, the number <b>V</b> = 1.01 <sub>2</sub> * 2 <sub>10</sub> <sup>-3 <sub>10</sub></sup> = 101 <sub>2</sub> * 2 <sub>10</sub> <sup>-5 <sub>10</sub></sup> = 5 <sub>10</sub> * 2 <sub>10</sub> <sup>-5 <sub>10</sub></sup> = 0.15625 <sub>10</sub> <br><br>  Note that when performing operations with real numbers, often the result <b>will not fit into N-bit Matisses</b> , i.e.  rounding will occur.  The rounding in one computational operation does not exceed the <b>EPSILON / 2</b> order, but when we need to do a lot of operations, in order to increase the accuracy of the calculation of the result, we need to learn how to find out exactly how the result of each particular operation is rounded. <br><br>  For more information about rounding and violation of axiomatics, <i>see makarov_float.pdf</i> (link to the material below). <br><br><h2>  Ways of finding rounding errors for floating point numbers </h2><br>  This problem was investigated by many specialists, the most famous of which are: David Goldberg, William Kakhen, Jonathan Richard Shevchuk. <br><br>  Below we consider the algorithms for finding rounding errors, given in Shevchuk‚Äôs work, using the example of two functions: <br><br><ul><li>  TwoSum - the function of finding the rounding error when adding. </li><li>  TwoProduct - the function of finding the error of rounding during multiplication. </li></ul><br>  For a proper understanding of these algorithms, we will rely on the theorems considered in the work of Shevchuk.  Theorems are given without proof. <br><br>  Saying that the number <b>a</b> is a <b>p</b> -bit number, it means that the length of the Matisse of the number <b>a</b> is represented by <b>p</b> bits. <br><br><h4>  TwoSum </h4><br>  Theorem: Let the numbers <b>a</b> and <b>b</b> be <b>p-</b> bit floating point numbers, where <b>p</b> &gt; = 3, then following this algorithm we get 2 numbers: <b>x</b> and <b>y</b> , for which the condition is satisfied: <b>a</b> + <b>b</b> = <b>x</b> + <b>y</b> .  Moreover, <b>x</b> is an approximation of the sum of <b>a</b> and <b>b</b> , and <b>y</b> is the rounding error of calculating the number <b>x</b> . <br><br><img src="https://habrastorage.org/files/61b/3a5/0af/61b3a50af2f244b5bd397f34f1eeddef.png"><br><br><h4>  TwoProduct </h4><br>  In fact, the alogrhythm of finding rounding error when multiplying two real numbers consists of 2 functions: Split ‚Äî an auxiliary function and TwoProduct function, where we find the error. <br><br>  Consider the Split function algorithm. <br><br><h6>  Split </h6><br>  Theorem: the number <b>a</b> is a <b>p</b> -bit floating-point number, where <b>p</b> &gt; = 3. Choose a breakpoint <b>s</b> , where <b>p</b> / 2 &lt;= <b>s</b> &lt;= <b>p</b> -1.  Following the algorithm, we obtain ( <b>p</b> - <b>s</b> ) -bit number - the number <b>a_hi</b> and ( <b>s</b> -1) -bit number - <b>a_lo</b> , where |  <b>a_hi</b> |  &gt; = |  <b>a_low</b> |  and <b>a</b> = <b>a_hi</b> + <b>a_low</b> . <br><br><img src="https://habrastorage.org/files/fbd/479/710/fbd4797103ab439cbe23da904bab800e.png"><br><br>  We now turn to the analysis of the TwoProduct function. <br><br><h6>  TwoProduct </h6><br>  Theorem: Let the numbers <b>a</b> and <b>b</b> be <b>p-</b> bit floating-point numbers, where <b>p</b> &gt; = 6. Then, by performing this algorithm, we get 2 numbers: <b>x</b> and <b>y</b> , for which the condition is satisfied: <b>a</b> * <b>b</b> = <b>x</b> + <b>y</b> .  Moreover, <b>x</b> is an approximation of the product of the numbers <b>a</b> and <b>b</b> , and the number <b>y</b> is the rounding error of the calculation of the number <b>x</b> . <br><br><img src="https://habrastorage.org/files/af2/f1d/8ff/af2f1d8ff049407c9d41d30cc90b7ea4.png"><br><br>  It can be seen that the final result is represented by a pair of N-bit real numbers: the result + error.  And the second must have an order of no more than <b>EPSILON</b> in relation to the first. <br><br><h2>  Example of computation of rounding errors for floating point numbers </h2><br>  We now turn to practical calculations that are based on Shevchuk's algorithms.  Find the rounding errors when adding and multiplying floating-point numbers and analyze how the error accumulates. <br><br><h4>  Amount rounding error </h4><br>  Here is an example of the simplest summation program: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; int main() { float val = 2.7892; printf("%0.7g \n", val); val = val/10000000000.0; float result = 0.0; for (long long i = 0; i &lt; 10000000000; i++) { result += val; } printf("%0.7g \n", result); return 0; }</span></span></span></span></code> </pre><br>  As a result of the program, we must get two identical numbers: 2,7892 and 2,7892.  But the console was displayed: 2,7892 and 0,0078125.  This shows that the error has accumulated very large. <br><br>  Now we will try to do the same, but using the Shevchuk algorithm, we will accumulate the error in a separate variable, and then we will compensate the result by adding an error to the main variable sum. <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; float TwoSum(float a, float b, float&amp; error) { float x = a + b; float b_virt = x - a; float a_virt = x - b_virt; float b_roundoff = b - b_virt; float a_roudnoff = a - a_virt; float y = a_roudnoff + b_roundoff; error += y; return x; } int main() { float val = 2.7892; printf("%0.7g \n", val); val = val/10000000000.0; float result = 0.0; float error = 0.0; for (long long i = 0; i &lt; 10000000000; i++) { result = TwoSum(result, val, error); } result += error; printf("%0.7g \n", result); return 0; }</span></span></span></span></code> </pre><br>  As a result, we get 2 numbers: 2,7892 and 0,015625.  The result has improved, but the error still makes itself felt.  In this example, the error arising in the addition operation was not taken into account in the TwoSum () function: <br><br><pre> <code class="cpp hljs">error += y;</code> </pre><br>  We will compensate for the result at each iteration of the loop and rewrite the error in the variable that accumulates the rounding error in the summation operation.  To do this, we modify the TwoSum () function: we add a <b>isnull</b> variable of the <b>bool</b> type, which indicates whether we should accumulate the error or rewrite it. <br><br>  As a result, the <b>result</b> will be represented by 2 variables: <b>result</b> - the main variable, <b>error1</b> - the error of the <b>result</b> operation <b>+ = val</b> . <br><br>  The code will look like this: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; float TwoSum(float a, float b, float&amp; error, bool isNull) { float x = a + b; float b_virt = x - a; float a_virt = x - b_virt; float b_roundoff = b - b_virt; float a_roudnoff = a - a_virt; float y = a_roudnoff + b_roundoff; if (isNull) { error = y; } else { error += y; } return x; } int main() { float val = 2.7892; printf("%0.7g \n", val); val = val/10000000000.0; float result = 0.0; float error1 = 0.0; for (long long i = 0; i &lt; 10000000000; i++) { result = TwoSum(result, val, error1, false); result = TwoSum(error1, result, error1, true); } printf("%0.7g \n", result); return 0; }</span></span></span></span></code> </pre><br>  The program will display the numbers: 2,7892 and 2,789195. <br><br>  Note that the rounding error that occurs in the multiplication operation was not taken into account here: <br><br><pre> <code class="bash hljs">val = val*(1/10000000000.0);</code> </pre><br><br>  We take this error into account by adding multiplication error accounting functions that were developed by D.R.  Shevchuk.  In this case, the val variable will be represented by two variables: <br><br><pre> <code class="bash hljs">val_real = val + errorMult</code> </pre><br>  Thus, <b>result</b> will be represented by 3 variables: <b>result</b> is the main variable, <b>error1</b> is the error of the operation <b>result + = val</b> , <b>error2</b> is the error of the operation of <b>result + = errorMult</b> . <br><br>  We will also add the <b>error1</b> and <b>error2</b> variables <b>,</b> and <b>write the</b> error from this operation into <b>error2</b> . <br><br>  As a result, the code: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; float TwoSum(float a, float b, float&amp; error, bool isNull) { //isNull   ,       //      float x = a + b; float b_virt = x - a; float a_virt = x - b_virt; float b_roundoff = b - b_virt; float a_roudnoff = a - a_virt; float y = a_roudnoff + b_roundoff; if (isNull) { error = y; } else { error += y; } return x; } void Split(float a, int s, float&amp; a_hi, float&amp; a_lo) { float c = (pow(2, s) + 1)*a; float a_big = c - a; a_hi = c - a_big; a_lo = a - a_hi; } float TwoProduct(float a, float b, float&amp; err) { float x = a*b; float a_hi, a_low, b_hi, b_low; Split(a, 12, a_hi, a_low); Split(b, 12, b_hi, b_low); float err1, err2, err3; err1 = x - (a_hi*b_hi); err2 = err1 - (a_low*b_hi); err3 = err2 - (a_hi*b_low); err += ((a_low * b_low) - err3); return x; } int main() { float val = 2.7892; printf("%0.7g \n", val); float errorMult = 0;//  val = TwoProduct(val, 1.0/10000000000.0, errorMult); float result = 0.0; float error1 = 0.0; float error2 = 0.0; for (long long i = 0; i &lt; 10000000000; i++) { result = TwoSum(result, val, error1, false); result = TwoSum(result, errorMult, error2, false); error1 = TwoSum(error2, error1, error2, true); result = TwoSum(error1, result, error1, true); } printf("%0.7g \n", result); return 0; }</span></span></span></span></code> </pre><br>  The following numbers were displayed in the console: 2,7892 and 2,789195. <br><br>  This suggests that the rounding error of multiplication is small enough to occur even at 10 billion iterations.  This result is as close as possible to the original number, if we take into account the errors in the operations of addition and multiplication.  To obtain a more accurate result, you can enter additional variables that take into account the errors.  Say, add a variable that takes into account the error in the operation of accumulating the main error in the TwoSum () function.  Then this error will have the order of <b>EPSILON <sup>2</sup></b> , in relation to the main result (the first error will have the order of <b>EPSILON</b> ). <br><br><h4>  Multiplication rounding error </h4><br>  We calculate the number 1.0012 <sup>101</sup> in the cycle, i.e.  do the following: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; int main() { float val = 1.0012; float result = 1.0012; for (long long i = 0; i &lt; 100; i++) { result *= val; } printf("%0.15g \n", result); return 0; }</span></span></span></span></code> </pre><br>  Note that the exact result, up to the fifteenth decimal place, is 1.128768638496750.  We will receive: 1.12876391410828.  As you can see, the error was quite large. <br><br>  Let's output the val variable, casting it to the double data type, and see what is actually written to it: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">printf</span></span>(<span class="hljs-string"><span class="hljs-string">"%0.15g \n"</span></span>, (<span class="hljs-keyword"><span class="hljs-keyword">double</span></span>)val);</code> </pre><br>  We get the number 1.00119996070862.  This suggests that in programming, even the most accurate constant is neither reliable nor constant.  Therefore, our real exact result will be 1.128764164435784, up to the fifteenth decimal place. <br><br>  Now we will try to improve the result obtained earlier.  To do this, we introduce compensation for the result of calculations, by taking into account the rounding error in the multiplication operation.  We will also try to add the accumulated error to the <b>result</b> variable at each step. <br><br>  Code: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; float TwoSum(float a, float b, float&amp; error, bool isNull) { //isNull   ,       //      float x = a + b; float b_virt = x - a; float a_virt = x - b_virt; float b_roundoff = b - b_virt; float a_roudnoff = a - a_virt; float y = a_roudnoff + b_roundoff; if (isNull) { error = y; } else { error += y; } return x; } void Split(float a, int s, float&amp; a_hi, float&amp; a_lo) { float c = (pow(2, s) + 1)*a; float a_big = c - a; a_hi = c - a_big; a_lo = a - a_hi; } float TwoProduct(float a, float b, float&amp; err) { float x = a*b; float a_hi, a_low, b_hi, b_low; Split(a, 12, a_hi, a_low); Split(b, 12, b_hi, b_low); float err1, err2, err3; err1 = x - (a_hi*b_hi); err2 = err1 - (a_low*b_hi); err3 = err2 - (a_hi*b_low); err += ((a_low * b_low) - err3); return x; } int main() { float val = 1.0012; float result = 1.0012; float errorMain = 0.0; for (long long i = 0; i &lt; 100; i++) { result = TwoProduct(result, val, errorMain); result = TwoSum(errorMain, result, errorMain, true); } printf("%0.15g \n", result); return 0; }</span></span></span></span></code> </pre><br>  The program displays the following number: 1.12876415252686.  We got an error of 1.0e-008, which is less than <b>EPSILON / 2</b> for the <b>float</b> data <b>type</b> .  Thus, this result can be considered quite good. <br><br><h2>  Results </h2><br>  1) In this paper, the presentation of floating-point numbers in the format of IEEE 754-2008 standard was considered. <br>  2) The method of finding rounding errors in the operations of addition and multiplication of floating point numbers was shown. <br>  3) Simple examples of compensation for rounding errors in floating-point numbers were considered. <br><br>  The work was performed by Victor Fadeev. <br>  Advised Makarov A.The. <br><br>  PS Thanks for the errors found by users: <br>  <a href="http://habrahabr.ru/users/xeioex/">xeioex</a> , <a href="http://habrahabr.ru/users/xeioex/">albom</a> . <br><br><h3>  References </h3><br><ul><li>  <a href="https://drive.google.com/folderview%3Fid%3D0B-FvBaefDp3dfktNYmlVMDliRWFRVnpkaVN4VzNlR1BlU3did0ZuUjQwTFJOSzlUMy1aUzA%26usp%3Dsharing">Works</a> Makarov Andrei Vladimirovich on the topic "Representation of real numbers."  The <i>makarov_float .pdf</i> file shows how rounding errors occur in floating-point numbers. </li><li>  <a href="https://ru.wikipedia.org/wiki/%25D0%25A7%25D0%25B8%25D1%2581%25D0%25BB%25D0%25BE_%25D0%25BE%25D0%25B4%25D0%25B8%25D0%25BD%25D0%25B0%25D1%2580%25D0%25BD%25D0%25BE%25D0%25B9_%25D1%2582%25D0%25BE%25D1%2587%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25B8">Wikipedia</a> .  Single precision number. </li><li>  <a href="http://www.cs.berkeley.edu/~jrs/papers/robustr.pdf">Adaptive Precision Floating-Point Arithmetic</a> <a href="http://www.cs.berkeley.edu/~jrs/papers/robustr.pdf"><br></a>  <a href="http://www.cs.berkeley.edu/~jrs/papers/robustr.pdf">and Fast Robust Geometric Predicates</a> <a href="http://www.cs.berkeley.edu/~jrs/papers/robustr.pdf"><br></a>  Jonathan richard shewchuk </li></ul></div><p>Source: <a href="https://habr.com/ru/post/266023/">https://habr.com/ru/post/266023/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../266013/index.html">Digest of grocery design, August 2015</a></li>
<li><a href="../266015/index.html">IBM Watson cognitive system: principles of working with natural language</a></li>
<li><a href="../266017/index.html">Centrifuge + Go = Centrifugo - harder, better, faster, stronger</a></li>
<li><a href="../266019/index.html">The first book of the young programmer. Learning to write programs on Scratch</a></li>
<li><a href="../266021/index.html">Publish DITA to PDF using the DITA Open Toolkit</a></li>
<li><a href="../266025/index.html">Working with text data in scikit-learn (translation of documentation) - part 2</a></li>
<li><a href="../266027/index.html">#NoHacked: eliminating the effects of hacking with loading URLs containing meaningless text</a></li>
<li><a href="../266031/index.html">1C: Summer School 2015 - how to organize a "smart" vacation for young programmers - part 3. Protection and distribution of elephants</a></li>
<li><a href="../266033/index.html">Reliable maintenance of MS SQL Server databases for employees</a></li>
<li><a href="../266035/index.html">The course "Basics of effective work with Wolfram technologies". Session 1: Wolfram Mathematica and Wolfram Cloud Review</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>