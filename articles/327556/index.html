<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Configuring Spark on YARN</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Habr, hello! Yesterday at the Apache Spark mitap from the guys from Rambler & Co, there were quite a lot of questions from the participants related to...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Configuring Spark on YARN</h1><div class="post__text post__text-html js-mediator-article">  Habr, hello!  Yesterday at the <a href="https://www.facebook.com/events/1825957590998380/">Apache Spark mitap</a> from the guys from Rambler &amp; Co, there were quite a lot of questions from the participants related to configuring this tool.  We decided to share our experience in his footsteps.  The topic is not an easy one - therefore, we offer to share our experience in the comments too, maybe we also do something wrong and use it. <br><a name="habracut"></a><br>  A little introduction - how we use Spark.  We have a three-month <a href="http://newprolab.com/ru/bigdata%3Futm_source%3Dhabr%26utm_campaign%3Dspark">‚ÄúBig Data Specialist‚Äù</a> program, and the entire second module our participants work on this tool.  Accordingly, our task, as organizers, is to prepare a cluster for use within such a case. <br><br>  A feature of our use is that the number of people working at Spark at the same time can be equal to the whole group.  For example, at the seminar, when everyone tries something at the same time and repeats after our teacher.  And this is a little bit - under 40 people at times.  Probably not many companies in the world who are faced with such a use case. <br><br>  Next, I will tell you how and why we selected certain parameters of the config. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Let's start from the beginning.  Spark has 3 options to work on the cluster: standalone, using Mesos and using YARN.  We decided to choose the third option, because for us it was logical.  We already had a hadoop cluster.  Our participants are already well acquainted with its architecture.  Let's use YARN. <br><br><pre><code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.master=yarn</code> </pre> <br>  Further more interesting.  Each of these 3 deployment options has 2 deployment options: client and cluster.  Based on the <a href="http://spark.apache.org/docs/latest/running-on-yarn.html">documentation</a> and various links on the Internet, we can conclude that the client is suitable for interactive work - for example, via jupyter notebook, and the cluster is more suitable for production solutions.  In our case, we were interested in interactive work, therefore: <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.deploy-mode=client</code> </pre> <br>  In general, from now on, Spark will somehow work on YARN, but that was not enough for us.  Since we have a program about big data, sometimes the participants did not have enough of what worked in the framework of a uniform cutting of resources.  And here we found an interesting thing - dynamic allocation of resources.  In short, the point is this: if you have a difficult task and the cluster is free (for example, in the morning), then with this option Spark can give you additional resources.  Necessity is considered there according to a cunning formula.  We will not go into details - it works well. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.dynamicAllocation.enabled=true</code> </pre> <br>  We set this parameter, and when Spark was launched, it cursed and did not start.  That's right, because I had to read the <a href="http://spark.apache.org/docs/latest/configuration.html">documentation</a> carefully.  It states that in order for everything to be ok, you need to also include an additional parameter. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.shuffle.service.enabled=true</code> </pre> <br>  Why is it needed?  When our work does not require such a number of resources anymore, Spark should return them to the common pool.  The most time consuming stage in almost any MapReduce task is the Shuffle stage.  This parameter allows you to save data that is formed at this stage and release executors accordingly.  And executor is a process that cheats everything up on a worker.  It has some amount of processor cores and some amount of memory. <br><br>  Added this parameter.  Everything seemed to work.  It became noticeable that participants really got more resources when they needed to.  But another problem arose - at some point other participants woke up and also wanted to use Spark, but everything was taken and they were unhappy.  They can be understood.  Began to look into the documentation.  There it turned out that there are still some number of parameters with which you can influence the process.  For example, if the executor is in standby mode - after what time can it take resources from it? <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.dynamicAllocation.executorIdleTimeout=120s</code> </pre> <br>  In our case - if your executors do nothing for two minutes, then please return them to the common pool.  But this parameter was not always enough.  It was obvious that a person has not done anything for a long time, and resources are not being released.  It turned out that there is still a special parameter - after what time to select executors, which contain cached data.  By default, this parameter was - infinity!  We corrected him. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.dynamicAllocation.cachedExecutorIdleTimeout=600s</code> </pre> <br>  That is, if within 5 minutes your executors are not doing anything, give them to the common pool.  In this mode, the speed of release and the issuance of resources for a large number of users has become decent.  The amount of discontent has declined.  But we decided to go further and limit the maximum number of executors to one application - in fact to one program participant. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.dynamicAllocation.maxExecutors=19</code> </pre> <br>  Now, of course, there were dissatisfied on the other hand - ‚Äúthe cluster is idle, and I have only 19 executors‚Äù, but what to do is need some kind of right balance.  All make happy fail. <br><br>  And another small story related to the specifics of our case.  Somehow several people were late for a practical lesson, and for some reason Spark did not start for them.  We looked at the number of free resources - it seems to be there.  Spark should start.  Fortunately, by that time the documentation was already somewhere enrolled in the subcortex, and we remembered that when Spark was launched, it was looking for a port on which to launch.  If the first port in the range is busy, then it goes to the next in order.  If he is free, then captures.  And there is a parameter that indicates the maximum number of attempts for this.  The default is 16. The number is less than the people in our group in class.  Accordingly, after 16 attempts, Spark threw this case and said that I could not start.  We corrected this parameter. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.port.maxRetries=50</code> </pre> <br>  Then I will talk about some of the settings that are no longer closely related to the specifics of our case. <br><br>  For a quicker start, Spark has a recommendation that the jars folder in the home directory SPARK_HOME be archived and put on HDFS.  Then he will not waste time downloading these jarniki to the workers. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.yarn.archive=hdfs:///tmp/spark-archive.zip</code> </pre> <br>  Also for faster work it is recommended to use kryo as a serializer.  It is more optimized than the default. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.serializer=org.apache.spark.serializer.KryoSerializer</code> </pre> <br>  And there is still the old Spark problem that it often falls down from memory.  Often this happens at the moment when the workers have counted everything and send the result to the driver.  We have made this parameter more.  By default, it is 1GB, we did - 3. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">spark</span></span>.driver.maxResultSize=3072</code> </pre> <br>  And the last, as a dessert.  How to upgrade Spark to version 2.1 on HortonWorks distribution kit - HDP 2.5.3.0.  This version of HDP contains a pre-installed version 2.0, but once we decided for ourselves that Spark is developing quite actively, and each new version fixes some bugs plus gives additional features, including the python API, so we decided you need to do an update. <br><br>  Downloaded the version from an official site under Hadoop 2.7.  Unzipped, thrown in a folder with HDP.  Put the symlink as it should.  We start - it does not start.  Writes a very incomprehensible mistake. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">java</span></span>.lang.NoClassDefFoundError: com/sun/jersey/api/client/config/ClientConfig</code> </pre> <br>  Googling, they found out that Spark decided not to wait until Hadoop was released, and decided to use the new version of jersey.  They themselves there with each other swear on this topic in JIRA.  The solution was to download <a href="">jersey version 1.17.1</a> .  Drop it into the jars folder in SPARK_HOME, zip it again and upload to HDFS. <br><br>  We bypassed this error, but a new and rather streamlined one appeared. <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">org</span></span>.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master</code> </pre> <br>  At the same time try to run version 2.0 - everything is ok.  Try to guess what's the matter.  We got into the logs of this application and saw something like this: <br><br><pre> <code class="apache hljs">/<span class="hljs-attribute"><span class="hljs-attribute">usr</span></span>/hdp/<span class="hljs-variable"><span class="hljs-variable">${hdp.version}</span></span>/hadoop/lib/hadoop-lzo-0.6.0.<span class="hljs-variable"><span class="hljs-variable">${hdp.version}</span></span>.jar</code> </pre> <br>  In general, for some reason hdp.version did not resolve.  Googling, found a solution.  In Ambari, go to the YARN settings and add the parameter to the custom yarn-site there: <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">hdp</span></span>.version=2.5.3.0-37</code> </pre> <br>  This magic helped, and Spark took off.  We tested several of our jupyter laptops.  Everything is working.  We are ready for the first Spark lesson on Saturday (tomorrow)! <br><br>  <b>UPD</b> .  The lesson revealed another problem.  At some point, YARN stopped issuing containers for Spark.  In YARN, it was necessary to correct the parameter, which defaulted to 0.2: <br><br><pre> <code class="apache hljs"><span class="hljs-attribute"><span class="hljs-attribute">yarn</span></span>.scheduler.capacity.maximum-am-resource-percent=0.8</code> </pre> <br>  That is, only 20% of the resources were involved in the distribution of resources.  Changing the parameters, restarted YARN.  The problem was solved, and the other participants were also able to start the spark context. </div><p>Source: <a href="https://habr.com/ru/post/327556/">https://habr.com/ru/post/327556/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327546/index.html">As we "Miss Russia" in the hands of endured</a></li>
<li><a href="../327548/index.html">How to take care of sites during the holidays</a></li>
<li><a href="../327550/index.html">Trend Hyper Convergence: Cisco HyperFlex</a></li>
<li><a href="../327552/index.html">What I learned from the 90s games</a></li>
<li><a href="../327554/index.html">Rise of the Machines: How robots captured accounting</a></li>
<li><a href="../327560/index.html">No need to wrap everything in a promise</a></li>
<li><a href="../327562/index.html">What 2017 Mobius told about mobile development</a></li>
<li><a href="../327564/index.html">Debian developers publish the Stretch preparation report and disable FTP support on their servers.</a></li>
<li><a href="../327566/index.html">Seven times ALTER one DROP</a></li>
<li><a href="../327568/index.html">Contextual interview. Notes for the design of the study</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>