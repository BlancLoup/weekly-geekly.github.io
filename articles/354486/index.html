<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apache Kafka - my summary</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This is my summary in which I briefly and in essence touch on such Kafka concepts as: 

 - Topic (Topic) 
 - Subscribers (consumer) 
 - Publisher (pro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apache Kafka - my summary</h1><div class="post__text post__text-html js-mediator-article">  This is my summary in which I briefly and in essence touch on such Kafka concepts as: <br><br>  - Topic (Topic) <br>  - Subscribers (consumer) <br>  - Publisher (producer) <br>  - Group (partition) <br>  - Streams <br><br><h3>  Kafka - basic </h3><br>  When studying Kafka, there were questions, the answers to which I had to experimentally get on examples, and this is what is outlined in this summary.  How to start and where to start I will give one of the links below in the materials. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Apache Kafka is a Java based message dispatcher.  Kafka has a message <b>subject</b> in which <b>publishers</b> write messages and there are <b>subscribers</b> in topics that read these messages, all messages in the dispatch process are written to disk and are not dependent on consumers. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/g3/lj/mb/g3ljmbhk1e_6ugq_nscpos5xeuk.jpeg" alt="image"><br><br>  Kafka includes a set of utilities for creating topics, sections, ready-made publishers, subscribers for examples, etc. Kafka needs a ZooKeeper coordinator, so first we start ZooKeeper (zkServer.cmd) then Kafka server (kafka-server-start.bat ), batch files are located in the appropriate bin folders, there are utilities. <br><br>  Create a theme Kafka utility, part of <br><blockquote>  kafka-topics.bat --create --zookeeper localhost: 2181 --replication-factor 1 --partitions 1 --topic out-topic <br></blockquote>  here we specify the zookeeper server, replication-factor is the number of replicas of the message log, partitions - the number of sections in the topic (more on this below) and the topic itself is ‚Äúout-topic‚Äù. <br><br>  For simple testing, you can use the included kafka-console-consumer and kafka-console-producer applications, but I'll make my own.  Subscribers in practice are grouped together, this will allow different applications to read messages from the topic in parallel. <br><br><img src="https://habrastorage.org/webt/-g/7u/gn/-g7ugnarc1bpr1wiwv4l5_kdvo0.jpeg" alt="image"><br><br>  For each application, there will be an organized queue, reading from which it performs the movements of the pointer of the last message read (offset), this is called reading commit.  And so if the publisher sends a message to the topic, it will be guaranteed to be read by the recipient of this topic if it is running or as soon as it is connected.  And if there are different clients (client.id) that read from the same topic, but in different groups, then they will receive messages regardless of each other and at the time when they are ready. <br><br><img src="https://habrastorage.org/webt/ex/cw/6g/excw6gbtxqkqvmcfcqodzmggwp8.jpeg" alt="image"><br><br>  So you can submit a follower of messages and independent reading of their consumers from one topic. <br><br>  But there is a situation when messages in a subject can begin to arrive faster than to leave, i.e.  consumers process them longer.  To do this, the topic can provide partitions and run consumers in the same group for this topic. <br><br><img src="https://habrastorage.org/webt/xs/jq/bq/xsjqbqelhvg-kkcjshyuqusxlj0.jpeg" alt="image"><br><br>  Then there will be a load distribution and not all messages in the subject and group will go through one consumer.  And then the strategy will be chosen, how to distribute messages into sections.  There are several strategies: round-robin is in a circle, according to a hash of the key value, or an explicit indication of the section number where to write.  Subscribers in this case are distributed evenly across sections.  If, for example, there are more subscribers in the group than sections, then someone will not receive the message.  Thus, partitions are made to improve scalability. <br><br>  For example, after creating a theme with one section, I changed to two sections. <br><blockquote>  kafka-topics.bat --zookeeper localhost: 2181 --alter --topic out-topic --partitions 2 </blockquote>  I launched my publisher and two subscribers in the same group on the same topic (examples of java programs will be below).  Configuring the group names and client IDs is not necessary, Kafka takes it upon himself. <br><blockquote>  my_kafka_run.cmd com.home.SimpleProducer out-topic (publisher) <br>  my_kafka_run.cmd com.home.SimpleConsumer out-topic testGroup01 client01 (first subscriber) <br>  my_kafka_run.cmd com.home.SimpleConsumer out-topic testGroup01 client02 (second subscriber) <br></blockquote>  Starting to enter a key in the publisher of a key: the value can be observed who gets them.  For example, according to the key distribution strategy of the key hash, the message m: 1 got into the client01 client <br><br><img src="https://habrastorage.org/webt/i1/l1/nt/i1l1ntorry2kmki6i357ciockru.jpeg" alt="image"><br><br>  and message n: 1 to client02 <br><br><img src="https://habrastorage.org/webt/ml/4c/py/ml4cpybtevragz6jgcq3jryi1l0.jpeg" alt="image"><br><br>  If I start typing without specifying the key: value pairs (I did this in the publisher), the strategy will be selected in a circle.  The first message "m" got client01, and already three times client02. <br><br><img src="https://habrastorage.org/webt/ng/q4/gj/ngq4gjsweo6esfmjb0rvs33qaxo.jpeg" alt="image"><br><br>  And another option with the indication of the section, for example in this format key: value: partition <br><br><img src="https://habrastorage.org/webt/z2/_z/5h/z2_z5hja_dypmam2i-06kmp26ga.jpeg" alt="image"><br><br>  Earlier in the hash strategy, m: 1 went to another client (client01), now with the explicit indication of the section (# 1, they are numbered from 0) to client02. <br><br>  If you start a subscriber with a different group name testGroup02 and for the same topic, the messages will go in parallel and independently to the subscribers, i.e.  if the first one is read and the second is not active, then it will read as soon as it becomes active. <br><br><img src="https://habrastorage.org/webt/0o/qw/3d/0oqw3dey87kzs-ymc_yelwjq4we.jpeg" alt="image"><br><br>  You can see the descriptions of groups, topics, respectively: <br><blockquote>  kafka-consumer-groups.bat --bootstrap-server localhost: 9092 --describe --group testGroup01 </blockquote><br><img src="https://habrastorage.org/webt/z1/st/n0/z1stn0zo2vehplme6wx4x8ltyji.jpeg" alt="image"><br><blockquote>  kafka-topics.bat --describe --zookeeper localhost: 2181 --topic out-topic </blockquote><br><img src="https://habrastorage.org/webt/2z/-6/pe/2z-6pe9kfn6-uxqaicotgw1yhku.jpeg" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">SimpleProducer Code</b> <div class="spoiler_text"><pre><code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SimpleProducer</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// Check arguments length value if (args.length == 0) { System.out.println("Enter topic name"); return; } //Assign topicName to string variable String topicName = args[0].toString(); System.out.println("Producer topic=" + topicName); // create instance for properties to access producer configs Properties props = new Properties(); //Assign localhost id props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092"); //Set acknowledgements for producer requests. props.put("acks", "all"); //If the request fails, the producer can automatically retry, props.put("retries", 0); //Specify buffer size in config props.put("batch.size", 16384); //Reduce the no of requests less than 0 props.put("linger.ms", 1); //The buffer.memory controls the total amount of memory available to the producer for buffering. props.put("buffer.memory", 33554432); props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); Producer&lt;String, String&gt; producer = new KafkaProducer(props); BufferedReader br = null; br = new BufferedReader(new InputStreamReader(System.in)); System.out.println("Enter key:value, q - Exit"); while (true) { String input = br.readLine(); String[] split = input.split(":"); if ("q".equals(input)) { producer.close(); System.out.println("Exit!"); System.exit(0); } else { switch (split.length) { case 1: // strategy by round producer.send(new ProducerRecord(topicName, split[0])); break; case 2: // strategy by hash producer.send(new ProducerRecord(topicName, split[0], split[1])); break; case 3: // strategy by partition producer.send(new ProducerRecord(topicName, Integer.valueOf(split[2]), split[0], split[1])); break; default: System.out.println("Enter key:value, q - Exit"); } } } } }</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">SimpleConsumer code</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SimpleConsumer</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (args.length != <span class="hljs-number"><span class="hljs-number">3</span></span>) { System.out.println(<span class="hljs-string"><span class="hljs-string">"Enter topic name, groupId, clientId"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } <span class="hljs-comment"><span class="hljs-comment">//Kafka consumer configuration settings final String topicName = args[0].toString(); final String groupId = args[1].toString(); final String clientId = args[2].toString(); Properties props = new Properties(); props.put("bootstrap.servers", "localhost:9092"); props.put("group.id", groupId); props.put("client.id", clientId); props.put("enable.auto.commit", "true"); props.put("auto.commit.interval.ms", "1000"); props.put("session.timeout.ms", "30000"); //props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); //props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass()); props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer"); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props); //Kafka Consumer subscribes list of topics here. consumer.subscribe(Arrays.asList(topicName)); //print the topic name System.out.println("Subscribed to topic=" + topicName + ", group=" + groupId + ", clientId=" + clientId); SimpleDateFormat sdf = new SimpleDateFormat("HH:mm:ss"); // looping until ctrl-c while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(100); for (ConsumerRecord&lt;String, String&gt; record : records) // print the offset,key and value for the consumer records. System.out.printf("offset = %d, key = %s, value = %s, time = %s \n", record.offset(), record.key(), record.value(), sdf.format(new Date())); } } }</span></span></code> </pre><br></div></div><br>  To run my programs, I made a batch file - my_kafka_run.cmd <br><br><pre> <code class="bash hljs">@<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> off <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> CLASSPATH=<span class="hljs-string"><span class="hljs-string">"C:\Project\myKafka\target\classes"</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> %%i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (C:\kafka_2.11-1.1.0\libs\*) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> ( call :concat <span class="hljs-string"><span class="hljs-string">"%%i"</span></span> ) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> COMMAND=java -classpath %CLASSPATH% %* %COMMAND% :concat IF not defined CLASSPATH ( <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> CLASSPATH=<span class="hljs-string"><span class="hljs-string">"%~1"</span></span> ) ELSE ( <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> CLASSPATH=%CLASSPATH%;<span class="hljs-string"><span class="hljs-string">"%~1"</span></span> )</code> </pre><br>  startup example: <br><blockquote>  my_kafka_run.cmd com.home.SimpleConsumer out-topic testGroup02 client01 </blockquote><h3>  Kafka streams </h3><br>  So, the streams in Kafka are a sequence of events that are obtained from a topic, over which you can perform certain operations, transformations and then return the result further, for example, to another topic or save it to a database, generally anywhere.  Operations can be either for example filtering (filter), transformation (map), or aggregation (count, sum, avg).  To do this, there are corresponding classes KStream, KTable, where KTable can be represented as a table with current aggregated values ‚Äã‚Äãthat are constantly updated as new messages arrive in the topic.  How does this happen? <br><br><img src="https://habrastorage.org/webt/zc/h3/gx/zch3gx2xjr7d611l2lsw7wgcu4a.jpeg" alt="image"><br><br>  For example, the publisher writes to the subject of the event (message), Kafka saves all messages in the message log, which has a retention policy (for example, 7 days).  For example, a quote change event is a stream, then we want to know the average value, then we will create a Stream that will take the history from the magazine and calculate the average, where the key is the share, and the value is the average (this is a table with a status).  There is a feature here - aggregation operations, unlike operations, for example, filtering, retain state.  Therefore, the newly received messages (events) in the topic will be subject to calculation, and the result will be saved (state store), then the newly received messages will be written to the log, Stream will process them, add changes to the already saved state.  Filtering operations do not require state preservation.  And here, too, stream will do this regardless of the publisher.  For example, the publisher writes messages, and the program - stream does not work at this time, nothing is lost, all messages will be saved in the log and as soon as the program-stream becomes active, it will do the calculations, save the state, perform the offset for the messages read (it says they have been read) and in the future it will not return to them, moreover, these messages will leave the log (kafka-logs).  It seems that the main thing is that the log (kafka-logs) and its storage policy allow this.  By default, the state of Kafka Stream is stored in RocksDB.  The message log and everything related to it (themes, offsets, flows, clients, etc.) is located along the path specified in the ‚Äúlog.dirs = kafka-logs‚Äù parameter of the ‚Äúconfig \ server.properties‚Äù configuration file, and the same log storage policy is specified. "Log.retention.hours = 48".  Log example <br><br><img src="https://habrastorage.org/webt/kh/wk/oc/khwkoc2nstwvlbke_ft_p764-xi.jpeg" alt="image"><br><br>  And the path to the database with stream states is specified in the application parameter. <br><blockquote>  config.put (StreamsConfig.STATE_DIR_CONFIG, "C: /kafka_2.11-1.1.0/state"); </blockquote>  States are stored by application IDs independently ( <i>StreamsConfig.APPLICATION_ID_CONFIG</i> ).  Example <br><br><img src="https://habrastorage.org/webt/ox/at/l5/oxatl5sjdouku6haanke110p4tw.jpeg" alt="image"><br><br>  Now let's check how Stream works.  Prepare the Stream application from the example, which is the delivery (with some refinement for the experiment), which counts the number of identical words and the application is the publisher and the subscriber.  Will write in the topic in-topic <br><blockquote>  my_kafka_run.cmd com.home.SimpleProducer in-topic </blockquote>  The Stream application will read this topic count count of identical words, it is not explicit for us to save the state and redirect out-topic to another topic.  Here I want to clarify the relationship of the log and state (state store).  And so ZooKeeper and Kafka server are running.  I launch Stream with App-ID = app_01 <br><blockquote>  my_kafka_run.cmd com.home.KafkaCountStream in-topic app_01 </blockquote>  publisher and subscriber accordingly <br><blockquote>  my_kafka_run.cmd com.home.SimpleProducer in-topic <br>  my_kafka_run.cmd com.home.SimpleConsumer out-topic testGroup01 client01 <br></blockquote>  Here they are: <br><br><img src="https://habrastorage.org/webt/2n/yj/q9/2nyjq9k30vvyzrsq0crlgdbszkw.jpeg" alt="image"><br><br>  We start to enter words and see their counting with an indication of which Stream App-ID counted them <br><br><img src="https://habrastorage.org/webt/hq/zx/ak/hqzxak-4rkummgtmjzap67p_x8g.jpeg" alt="image"><br><br>  The work will go independently, you can stop the Stream and continue to write in the topic, he then at the start will count.  And now we will connect the second Stream with App-ID = app_02 (this is also an application, but with a different ID), it will read the log (a sequence of events that is saved according to the Retention policy), count the number, save the status and issue the result.  Thus, two streams starting to work at different times came to the same result. <br><br><img src="https://habrastorage.org/webt/o7/xg/fc/o7xgfcyyqnxbwsfza2ttctrifwk.jpeg" alt="image"><br><br>  And now let's imagine our magazine is outdated (Retention policy) or we deleted it (which is what needs to be done) and connect the third stream with App-ID = app_03 (I stopped Kafka for this, deleted kafka-logs and started again) and introduce a new topic the message and see the first (app_01) stream continued counting and the new third started from scratch. <br><br><img src="https://habrastorage.org/webt/ke/gc/5h/kegc5hkigqqmnjgyjxdqrb7gufg.jpeg" alt="image"><br><br>  If we then run the app_02 stream, it will catch up with the first one and they will be equal in values.  From the example, it became clear how Kafka processes the current log, adds to the previously saved state and so on. <br><div class="spoiler">  <b class="spoiler_title">KafkaCountStream code</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">KafkaCountStream</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">final</span></span></span></span><span class="hljs-function"><span class="hljs-params"> String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// Check arguments length value if (args.length != 2) { System.out.println("Enter topic name, appId"); return; } String topicName = args[0]; String appId = args[1]; System.out.println("Count stream topic=" + topicName +", app=" + appId); Properties config = new Properties(); config.put(StreamsConfig.APPLICATION_ID_CONFIG, appId); config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092"); config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass()); config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 2000); config.put(StreamsConfig.STATE_DIR_CONFIG, "C:/kafka_2.11-1.1.0/state"); StreamsBuilder builder = new StreamsBuilder(); KStream&lt;String, String&gt; textLines = builder.stream(topicName); // State store KTable&lt;String, Long&gt; wordCounts = textLines .flatMapValues(textLine -&gt; Arrays.asList(textLine.toLowerCase().split("\\W+"))) .groupBy((key, word) -&gt; word) .count(); // out to another topic KStream&lt;String, String&gt; stringKStream = wordCounts.toStream() .map((k, v) -&gt; new KeyValue&lt;&gt;(appId + "." + k, v.toString())); stringKStream.to("out-topic", Produced.with(Serdes.String(), Serdes.String())); KafkaStreams streams = new KafkaStreams(builder.build(), config); // additional to complete the work final CountDownLatch latch = new CountDownLatch(1); // attach shutdown handler to catch control-c Runtime.getRuntime().addShutdownHook(new Thread("streams-shutdown-hook") { @Override public void run() { System.out.println("Kafka Stream close"); streams.close(); latch.countDown(); } }); try { System.out.println("Kafka Stream start"); streams.start(); latch.await(); } catch (Throwable e) { System.exit(1); } System.out.println("Kafka Stream exit"); System.exit(0); } }</span></span></code> </pre><br></div></div><br><br>  The Kafka theme is very extensive, I made the first general presentation for myself :-) <br><br>  Materials: <br><br>  <a href="http://www.w3ii.com/ru/apache_kafka/apache_kafka_introduction.html">How to start and where to start</a> </div><p>Source: <a href="https://habr.com/ru/post/354486/">https://habr.com/ru/post/354486/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../354474/index.html">Splunk 7.1. What's new? New web interface, integration with Apache Kafka and much more ...</a></li>
<li><a href="../354476/index.html">PDF generation for downloading server configs</a></li>
<li><a href="../354478/index.html">When computers were people ...</a></li>
<li><a href="../354480/index.html">Bobaos - KNX TP / UART, Raspberry Pi and Apple HomeKit</a></li>
<li><a href="../354484/index.html">Block the entire Internet, or a monkey with a grenade</a></li>
<li><a href="../354488/index.html">As an entrepreneur to submit reports on the simplified taxation system</a></li>
<li><a href="../354490/index.html">Configure VPN server (GRE / IPSec StrongSwan, OSPF Quagga)</a></li>
<li><a href="../354492/index.html">How to develop a system that recognizes a person by keyboard writing</a></li>
<li><a href="../354494/index.html">GDPR on the nose - stop panic and begin to escape</a></li>
<li><a href="../354498/index.html">HOPE X. Conference "Breaking the elevator: from the basement to the penthouse." Part 2. "Security Systems"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>