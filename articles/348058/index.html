<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Free Tesla K80 GPU for your experiments with neural networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="About a month ago, the Google service Colaboratory, which provides access to Jupyter laptops, included the ability to use the Tesla K80 GPU for free w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Free Tesla K80 GPU for your experiments with neural networks</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/xg/vj/yz/xgvjyzmjnm8ak7zqpkw1cujpd2k.jpeg"><br>  About a month ago, the Google service Colaboratory, which provides access to Jupyter laptops, included the ability to use the Tesla K80 GPU for free with 13 GB of video memory on board.  If until now the only obstacle to immersion in the world of neural networks could be the lack of access to the GPU, now you can safely say, ‚ÄúHold on Deep Learning, I'm coming!‚Äù. </p><br><p>  I tried to use Colaboratory for working on kaggle tasks.  Most of all I lacked the ability to conveniently save the trained tensorflow models and use the tensorboard.  In this post, I want to share experiences and tell you how to add these features to colab.  And finally, I'll show you how you can access the container via ssh and use the usual convenient tools bash, screen, rsync. </p><a name="habracut"></a><br><h2 id="dlya-nachala-pochemu-eto-interesno">  For a start, why is this interesting? </h2><br><p>  The presence of a GPU accelerator is a critical factor for the speed of learning deep learning models.  Without a GPU, neural network training will take many hours / days and will not allow to fully experiment with the structure of the network.  The amount of video memory is also important.  More memory - you can install a larger batch size and use more complex models.  Today, 13G is a good amount, if you want to get about the same on your desk, you will have to buy a GTX 1080 Ti level GPU. </p><br><h2 id="chto-takoe-colaboratory">  What is Collaboration </h2><br><p>  This is a fork of the popular <a href="http://jupyter.org/">Jupyter notebook</a> environment.  Your laptops are available via google drive in .ipynb format and you can run them locally.  Python 2.7 and 3.6 are supported.  The code is executed on the server in the docker container.  You can close the browser, all processes on the server will continue to work, and later you can connect to the server again.  Docker container is given to you for temporary use for 12 hours.  You have root privileges, and you can install and run any program inside the container.  Collaboration (hereinafter referred to as colab) also supports collaboration on a laptop, like google docs.  This is an excellent platform to start learning deep learning, machine learning.  Many free courses, such as the <a href="https://habrahabr.ru/company/ods/blog/322626/">Open Machine Learning Course,</a> use the Jupyter notebook format for their study materials. </p><br><h2 id="zapuskaem-obuchenie">  We start training </h2><br><p>  To create a new laptop, click <a href="https://colab.research.google.com/notebook">on the link</a> .  After a successful login and laptop creation, select Runtime -&gt; Change Runtime Type in the menu, in the opened dialog in the Hardware acceleration option, install the GPU, then save. </p><br><p><img src="https://habrastorage.org/webt/yk/gv/uh/ykgvuhujjzomgscewdqjl2dundm.png"></p><br><p>  Then you can make sure that tensorflow uses the GPU.  Just copy this code into the first cell of the laptop and execute by pressing <em>shift + Enter</em> : </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf tf.test.gpu_device_name()</code> </pre> <br><p>  Now we will try to run a simple tensorflow model from the examples, for this we clone the github repository and run the script. </p><br><pre> <code class="python hljs">! git clone https://github.com/tensorflow/models.git %run models/samples/core/get_started/premade_estimator.py</code> </pre> <br><p>  After executing this command, we will see how the network learns and makes the first predictions.  There are quite a <a href="https://habrahabr.ru/search/%3Fq%3DJupyter">few materials</a> describing the possibilities of Jupyter, so I will not dwell on this in detail. </p><br><h2 id="montiruem-google-drive">  Mount google drive </h2><br><p>  Everything works fine, but after 12 hours, the virtual machine will be taken from you and all data inside the container will be lost.  It would be nice to take care of permanent storage.  In colab there are examples of how to use import data from cloud storage, google sheets.  This implies an explicit invocation of the copy operation, and I would like to be able to mount an external drive to the file system inside the container, here google drive and FUSE driver for it comes to the rescue.  Connect google drive, you can run the code <a href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d">for the recipe from the article</a> </p><br><div class="spoiler">  <b class="spoiler_title">Code to mount google drive</b> <div class="spoiler_text"><pre> <code class="bash hljs">!apt-get install -y -qq software-properties-common python-software-properties module-init-tools !add-apt-repository -y ppa:alessandro-strada/ppa 2&gt;&amp;1 &gt; /dev/null !apt-get update -qq 2&gt;&amp;1 &gt; /dev/null !apt-get -y install -qq google-drive-ocamlfuse fuse from google.colab import auth auth.authenticate_user() from oauth2client.client import GoogleCredentials creds = GoogleCredentials.get_application_default() import getpass !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} &lt; /dev/null 2&gt;&amp;1 | grep URL vcode = getpass.getpass() !<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}</code> </pre> </div></div><br><p>  After that, you will have access to the directory where you can write data, without fear of losing them after the container is stopped.  You can define the model_dir parameter in the model configuration, tensorflow will automatically restore the model state from the last checkpoint.  Thus, you can continue learning the model or run inference at any time. </p><br><h2 id="tensorboard">  Tensorboard </h2><br><p>  I like to use tensorboard in the process of experimenting with the structure and parameters of a neural network.  If you want to know more about this tool, I recommend watching the <a href="https://www.youtube.com/watch%3Fv%3DeBbEDRsCmv4">presentation</a> .  Therefore, I was looking for the possibility of how to run tensorboard in colab.  The answer <a href="https://stackoverflow.com/a/48468512/1334157">was found on SO</a> .  Through the LOG_DIR variable, you need to specify the path to model_dir from the configuration of the tensorflow model, or to the root directory inside which contains a lot of saved models. </p><br><div class="spoiler">  <b class="spoiler_title">The code to run tensorboard.</b> <div class="spoiler_text"><pre> <code class="bash hljs">LOG_DIR = <span class="hljs-string"><span class="hljs-string">'/tmp'</span></span> get_ipython().system_raw( <span class="hljs-string"><span class="hljs-string">'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &amp;'</span></span> .format(LOG_DIR) ) ! wget -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ! unzip -o ngrok-stable-linux-amd64.zip get_ipython().system_raw(<span class="hljs-string"><span class="hljs-string">'./ngrok http 6006 &amp;'</span></span>) ! curl -s http://localhost:4040/api/tunnels | python3 -c \ <span class="hljs-string"><span class="hljs-string">"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"</span></span></code> </pre> </div></div><br><p>  After the execution, the last line will display the URL, opening which in the browser, we will see the usual tensorboard. </p><br><h2 id="dostup-po-ssh">  Ssh access </h2><br><p>  If you have experience using Jupyter.  Then you probably know that, going beyond toy models, some of the advantages of the jupyter format of the notebook become its disadvantages.  The laptop turns into a difficult-to-read mess, the results of calculations become difficult to reproduce.  Jupyter laptops remain an excellent tool for learning, visualization and small experiments.  However, in medium-sized projects, I prefer to structure the python code in the classical way, using a partition into modules and classes.  It is more convenient to work on a serious project in PyCharm / Vim, etc. ... It is not very convenient to synchronize the code constantly through the repository, it is not very convenient to run .py files through jupyter, it is much more comfortable to use familiar tools for this. <br>  Based on the example of running the tensorboard, I wrote code that opens an ssh tunnel into a container. </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#Generate root password import secrets, string password = ''.join(secrets.choice(string.ascii_letters + string.digits) for i in range(20)) #Download ngrok ! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ! unzip -qq -n ngrok-stable-linux-amd64.zip #Setup sshd ! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen &gt; /dev/null #Set root password ! echo root:$password | chpasswd ! mkdir -p /var/run/sshd ! echo "PermitRootLogin yes" &gt;&gt; /etc/ssh/sshd_config ! echo "PasswordAuthentication yes" &gt;&gt; /etc/ssh/sshd_config ! echo "LD_LIBRARY_PATH=/usr/lib64-nvidia" &gt;&gt; /root/.bashrc ! echo "export LD_LIBRARY_PATH" &gt;&gt; /root/.bashrc #Run sshd get_ipython().system_raw('/usr/sbin/sshd -D &amp;') #Ask token print("Copy authtoken from https://dashboard.ngrok.com/auth") import getpass authtoken = getpass.getpass() #Create tunnel get_ipython().system_raw('./ngrok authtoken $authtoken &amp;&amp; ./ngrok tcp 22 &amp;') #Print root password print("Root password: {}".format(password)) #Get public address ! curl -s http://localhost:4040/api/tunnels | python3 -c \ "import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"</span></span></code> </pre> <br><p>  To create a TCP tunnel, you will need to create an account on <a href="https://ngrok.com/">ngrok.com</a> and copy authtoken from there.  In the free version of ngrok, two tunnels are not supported, so if the http tunnel on the tensorboard is still working, you need to disable it, for example, restart the container by pressing <em>Ctrl + M then "."</em>  . </p><br><p>  After starting the tunnel you will see in the laptop something like the following </p><br><pre> <code class="hljs objectivec">Root password: <span class="hljs-number"><span class="hljs-number">3</span></span>KTyBVjtD6zPZX4Helkj tcp:<span class="hljs-comment"><span class="hljs-comment">//0.tcp.ngrok.io:15223</span></span></code> </pre> <br><p>  Now you can log in to the colab container from the work computer using any ssh client and in this example the host 0.tcp.ngrok.io, port 15223. Example for linux </p><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">ssh</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">root</span></span>@<span class="hljs-keyword"><span class="hljs-keyword">0</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">tcp</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">ngrok</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">io</span></span> -p15223</code> </pre> <br><p>  Bonus for kagler, for importing data from <a href="https://kaggle.com/">kaggle</a> and sending submit directly from the laboratory you can use the official API <a href="https://github.com/Kaggle/kaggle-api">client</a> , installed with the command <em>pip install kaggle</em> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/348058/">https://habr.com/ru/post/348058/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../348044/index.html">Rook - "self-service" data store for Kubernetes</a></li>
<li><a href="../348046/index.html">What exactly is personal data?</a></li>
<li><a href="../348052/index.html">Top 5 Information Security Forecasts</a></li>
<li><a href="../348054/index.html">How we adapted the ELK stack to monitor and analyze errors in Java and .NET projects</a></li>
<li><a href="../348056/index.html">How I wrote the Java Olympics or why it is better not to use Scanner</a></li>
<li><a href="../348060/index.html">‚ÄúHurray, we were checkin!‚Äù Or How to change the data center under load and without downtime when everything goes to hell</a></li>
<li><a href="../348062/index.html">Gas savings in smart Ethereum contracts</a></li>
<li><a href="../348064/index.html">Nemesida Scanner - Web Application Vulnerability Scanner</a></li>
<li><a href="../348066/index.html">We count chickens until they are pecked</a></li>
<li><a href="../348068/index.html">Developing a static blog on Gatsby and Strapi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>