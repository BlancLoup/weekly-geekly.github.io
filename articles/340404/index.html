<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Comparison and creation of morphological analyzers in the NLTK</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello. This article is about comparing existing and creating your own morphological analyzers in the NLTK library. 

 Introduction 
 NLTK is a package...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Comparison and creation of morphological analyzers in the NLTK</h1><div class="post__text post__text-html js-mediator-article">  Hello.  This article is about comparing existing and creating your own morphological analyzers in the NLTK library. <br><br><h3>  Introduction </h3><br>  NLTK is a package of libraries and programs for symbolic and statistical processing of natural language written in the programming language Python.  Great for people studying computational linguistics, machine learning, information retrieval [1]. <br>  In this article I will accompany the examples with Python code (version 2.7). <br><a name="habracut"></a><br><h3>  Let's get started </h3><br>  Before you begin the process, you need to install and configure the NLTK package itself. <br><br>  This can be done via pip: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre><code class="dos hljs">pip install nltk</code> </pre> <br>  Now configure the package.  To do this, in the Python GUI you need to enter: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk &gt;&gt;&gt; nltk.download()</code> </pre><br>  A window will open in which you can install packages to the NLTK, including the Brown housing we need.  Mark the desired package and click "Download".  Everything, setup is finished.  Now you can get to work. <br><br><h4>  Sampling and training </h4><br>  How will be tested?  Before testing the analyzer itself, we need to train it.  And learning is done with the help of ready-made tagged words.  We will use Brown‚Äôs corpus, or rather its part called ‚Äúnews‚Äù - this is a fairly large category of material in the corpus, mainly consisting of news texts, oddly enough. <br><br>  90% of the entire sample will be used for training, and the remaining 10% will be used for testing.  We will check the result using the method <br><br><pre> <code class="python hljs">tagger.evaluate(test_sents)</code> </pre> <br>  As a result, we obtain a value from 0 to 1. It can be multiplied by 100 to get the percentage. <br><br>  First, we define training and test sentences.  Find out the number of sentences from 90% of Brown Corps. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>training_count = int(len(nltk.corpus.brown.tagged_sents(categories=<span class="hljs-string"><span class="hljs-string">'news'</span></span>)) * <span class="hljs-number"><span class="hljs-number">0.9</span></span>) &gt;&gt;&gt; training_count <span class="hljs-number"><span class="hljs-number">4160</span></span></code> </pre> <br>  4160 is the number of training sentences for each analyzer.  The rest, as has been said, will be used for testing. <br><br>  We will define the samples, we will work with them.  Add more suggestions themselves to show the work: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>training_sents = nltk.corpus.brown.tagged_sents(categories=<span class="hljs-string"><span class="hljs-string">'news'</span></span>)[:training_count] &gt;&gt;&gt; testing_sents = nltk.corpus.brown.tagged_sents(categories=<span class="hljs-string"><span class="hljs-string">'news'</span></span>)[training_count+<span class="hljs-number"><span class="hljs-number">1</span></span>:] &gt;&gt;&gt; test_sents_notags = nltk.corpus.brown.sents(categories=<span class="hljs-string"><span class="hljs-string">'news'</span></span>)[training_count+<span class="hljs-number"><span class="hljs-number">1</span></span>:]</code> </pre><br><h4>  Existing analyzers </h4><br>  There are several morphological analyzers in the NLTK package.  But the most popular ones are: the default analyzer, Unigram analyzer, N-gram analyzer, regular expression analyzer.  You can also create your own based on them (but more on that later). Let's look at each of them in more detail: <br><br><ol><li>  The default analyzer. <br><br>  Perhaps the easiest of all existing in the NLTK.  Automatically denotes the same tag to every word.  This analyzer can be used if you want to assign the most used tag.  Find it: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>tags = [tag <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (word, tag) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> nltk.corpus.brown.tagged_words(categories=<span class="hljs-string"><span class="hljs-string">'news'</span></span>)] &gt;&gt;&gt; nltk.FreqDist(tags).max() <span class="hljs-string"><span class="hljs-string">'NN'</span></span></code> </pre> <br>  As a result, we get NN (noun, noun).  In the listing we will create a default analyzer.  We will also immediately check his work: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>default_tagger = nltk.DefaultTagger(<span class="hljs-string"><span class="hljs-string">'NN'</span></span>) &gt;&gt;&gt; default_tagger.tag(testing_sents_notags[<span class="hljs-number"><span class="hljs-number">10</span></span>]) [(<span class="hljs-string"><span class="hljs-string">'The'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'evidence'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'in'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'court'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'was'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'testimony'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'about'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'the'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'interview'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'which'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'for'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'Holmes'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'lasted'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'an'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'hour'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'although'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'least'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'one'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'white'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'student'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'Georgia'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'got'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'through'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'this'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'ritual'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'by'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'simple'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'phone'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'conversation'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>)]</code> </pre><br>  As it was said, all words (and not even words) are marked with one tag.  This analyzer is rarely used alone, for it is coarse. <br><br>  Now we find out the accuracy: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>default_tagger.evaluate(testing_sents) <span class="hljs-number"><span class="hljs-number">0.1262832652247583</span></span></code> </pre> <br>  Accuracy of only ~ 13% is a very small indicator. <br>  Let us turn to more complex analyzers. <br></li><li>  Regular expression based analyzer. <br><br>  This is a very interesting analyzer, in my opinion.  It sets the tag based on some pattern.  Suppose we can assume that every word ending in <i>-ed</i> is past participle in verbs; if <i>-ing</i> , then it is a gerund. <br><br>  Let's create a parser and check it right away: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>patterns = [ (<span class="hljs-string"><span class="hljs-string">r'.*ing$'</span></span>, <span class="hljs-string"><span class="hljs-string">'VBG'</span></span>), <span class="hljs-comment"><span class="hljs-comment"># gerunds (r'.*ed$', 'VBD'), # simple past (r'.*es$', 'VBZ'), # 3rd singular present (r'.*ould$', 'MD'), # modals (r'.*\'s$', 'NN$'), # possessive nouns (r'.*s$', 'NNS'), # plural nouns (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers (r'.*', 'NN') # nouns (default) ] &gt;&gt;&gt; regexp_tagger = nltk.RegexpTagger(patterns) &gt;&gt;&gt; regexp_tagger.tag(testing_sents_notags[10]) [('The', 'NN'), ('evidence', 'NN'), ('in', 'NN'), ('court', 'NN'), ('was', 'NNS'), ('testimony', 'NN'), ('about', 'NN'), ('the', 'NN'), ('interview', 'NN'), (',', 'NN'), ('which', 'NN'), ('for', 'NN'), ('Holmes', 'VBZ'), ('lasted', 'VBD'), ('an', 'NN'), ('hour', 'NN'), (',', 'NN'), ('although', 'NN'), ('at', 'NN'), ('least', 'NN'), ('one', 'NN'), ('white', 'NN'), ('student', 'NN'), ('at', 'NN'), ('Georgia', 'NN'), ('got', 'NN'), ('through', 'NN'), ('this', 'NNS'), ('ritual', 'NN'), ('by', 'NN'), ('a', 'NN'), ('simple', 'NN'), ('phone', 'NN'), ('conversation', 'NN'), ('.', 'NN')]</span></span></code> </pre><br>  As you can see, most of the words are still marked with ‚Äúdefault‚Äù tag NN.  But some are marked by others due to the pattern. <br><br>  Check accuracy: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>regexp_tagger.evaluate(testing_sents) <span class="hljs-number"><span class="hljs-number">0.2047244094488189</span></span></code> </pre> <br>  20% - already this analyzer copes well, compared to the default analyzer <br></li><li>  Unigram analyzer. <br><br>  Uses a simple statistical word marking algorithm.  Each word (token) is tagged the most likely for that word. <br><br>  First, we create and train the analyzer, and also show it in our work: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>unigram_tagger = nltk.UnigramTagger(training_sents) &gt;&gt;&gt; unigram_tagger.tag(testing_sents_notags[<span class="hljs-number"><span class="hljs-number">10</span></span>]) [(<span class="hljs-string"><span class="hljs-string">'The'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'evidence'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'in'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'court'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'was'</span></span>, <span class="hljs-string"><span class="hljs-string">'BEDZ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'testimony'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'about'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'the'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'interview'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>), (<span class="hljs-string"><span class="hljs-string">'which'</span></span>, <span class="hljs-string"><span class="hljs-string">'WDT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'for'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'Holmes'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'lasted'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'an'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'hour'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>), (<span class="hljs-string"><span class="hljs-string">'although'</span></span>, <span class="hljs-string"><span class="hljs-string">'CS'</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'least'</span></span>, <span class="hljs-string"><span class="hljs-string">'AP'</span></span>), (<span class="hljs-string"><span class="hljs-string">'one'</span></span>, <span class="hljs-string"><span class="hljs-string">'CD'</span></span>), (<span class="hljs-string"><span class="hljs-string">'white'</span></span>, <span class="hljs-string"><span class="hljs-string">'JJ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'student'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'Georgia'</span></span>, <span class="hljs-string"><span class="hljs-string">'NP-TL'</span></span>), (<span class="hljs-string"><span class="hljs-string">'got'</span></span>, <span class="hljs-string"><span class="hljs-string">'VBD'</span></span>), (<span class="hljs-string"><span class="hljs-string">'through'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'this'</span></span>, <span class="hljs-string"><span class="hljs-string">'DT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'ritual'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'by'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'simple'</span></span>, <span class="hljs-string"><span class="hljs-string">'JJ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'phone'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'conversation'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-string"><span class="hljs-string">'.'</span></span>)]</code> </pre> <br>  Already the result is much better than the default analyzer.  But you can see that as a result there are words that are not tagged (worth None).  This means that these words did not appear during training.  Check the accuracy of the analyzer: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>unigram_tagger.evaluate(testing_sents) <span class="hljs-number"><span class="hljs-number">0.8110236220472441</span></span></code> </pre> <br>  ~ 81% is a very good indicator.  Only 19% of the words are marked or wrong, or the same words did not appear at all during training. <br></li><li>  N-grams. <br><br>  If in the previous analyzer the tag was set on the basis of the word that was encountered in the training, its context was not taken into account.  For example, the word <i>wind</i> will be marked with the same tags, regardless of what it stands before: <i>to</i> or <i>the</i> .  An analyzer based on N-grams allows you to solve this problem.  This is a common case of the Unigram analyzer, when the n-1 tag of the previous words is used to set the tag for the current word. <br><br>  Now let's check the work of the BigramTagger - an analyzer for n and n-1 words. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>bigram_tagger = nltk.BigramTagger(training_sents) &gt;&gt;&gt; bigram_tagger.tag(testing_sents_notags[<span class="hljs-number"><span class="hljs-number">10</span></span>]) [(<span class="hljs-string"><span class="hljs-string">'The'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'evidence'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'in'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'court'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'was'</span></span>, <span class="hljs-string"><span class="hljs-string">'BEDZ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'testimony'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'about'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'the'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'interview'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'which'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'for'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'Holmes'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'lasted'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'an'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'hour'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'although'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'least'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'one'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'white'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'student'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'Georgia'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'got'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'through'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'this'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'ritual'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'by'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'simple'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'phone'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'conversation'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>), (<span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)]</code> </pre><br>  And here the main problem of the analyzer immediately arises - many unmarked words.  As soon as a new word is encountered in the text, the analyzer cannot set a tag for it.  He also does not mark the next tag, because this word was not encountered when testing after the None tag.  And then it turned out such a chain of unmarked words. <br><br>  Because of this problem, this analyzer will have a small accuracy: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>bigram_tagger.evaluate(testing_sents) <span class="hljs-number"><span class="hljs-number">0.10216286255357321</span></span></code> </pre> <br>  Only 10% is a very small figure.  This way of marking words is not used alone due to low accuracy.  But this is a very powerful tool when using a combination of analyzers. <br><br>  There is also the TrigramTagger, which operates on the same principle as the Bigram analyzer, only one and two previous tags are analyzed.  But its accuracy, of course, will be even lower. <br></li></ol><br><h4>  Combinations from different analyzers </h4><br>  Finally, we have reached the most interesting - the creation of combinations of analyzers.  For example, you can combine the results of Bigram analyzer, Unigram analyzer and default analyzer.  This is done using the backoff parameter when creating the analyzer.  Each analyzer (except the default analyzer) may have a pointer to use another analyzer to build a multi-pass analyzer. <br><br>  Let's create it: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>default_tagger = nltk.DefaultTagger(<span class="hljs-string"><span class="hljs-string">'NN'</span></span>) &gt;&gt;&gt; unigram_tagger = nltk.UnigramTagger(training_sents, backoff=default_tagger) &gt;&gt;&gt; bigram_tagger = nltk.BigramTagger(training_sents, backoff=unigram_tagger)</code> </pre><br>  Let's check the analyzer: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>bigram_tagger.tag(test_sents_notags[<span class="hljs-number"><span class="hljs-number">10</span></span>]) [(<span class="hljs-string"><span class="hljs-string">'The'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'evidence'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'in'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'court'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'was'</span></span>, <span class="hljs-string"><span class="hljs-string">'BEDZ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'testimony'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'about'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'the'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'interview'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>), (<span class="hljs-string"><span class="hljs-string">'which'</span></span>, <span class="hljs-string"><span class="hljs-string">'WDT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'for'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'Holmes'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'lasted'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'an'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'hour'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>), (<span class="hljs-string"><span class="hljs-string">'although'</span></span>, <span class="hljs-string"><span class="hljs-string">'CS'</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'least'</span></span>, <span class="hljs-string"><span class="hljs-string">'AP'</span></span>), (<span class="hljs-string"><span class="hljs-string">'one'</span></span>, <span class="hljs-string"><span class="hljs-string">'CD'</span></span>), (<span class="hljs-string"><span class="hljs-string">'white'</span></span>, <span class="hljs-string"><span class="hljs-string">'JJ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'student'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'at'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'Georgia'</span></span>, <span class="hljs-string"><span class="hljs-string">'NP'</span></span>), (<span class="hljs-string"><span class="hljs-string">'got'</span></span>, <span class="hljs-string"><span class="hljs-string">'VBD'</span></span>), (<span class="hljs-string"><span class="hljs-string">'through'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'this'</span></span>, <span class="hljs-string"><span class="hljs-string">'DT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'ritual'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'by'</span></span>, <span class="hljs-string"><span class="hljs-string">'IN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'a'</span></span>, <span class="hljs-string"><span class="hljs-string">'AT'</span></span>), (<span class="hljs-string"><span class="hljs-string">'simple'</span></span>, <span class="hljs-string"><span class="hljs-string">'JJ'</span></span>), (<span class="hljs-string"><span class="hljs-string">'phone'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'conversation'</span></span>, <span class="hljs-string"><span class="hljs-string">'NN'</span></span>), (<span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-string"><span class="hljs-string">'.'</span></span>)]</code> </pre> <br>  As you can see, all words are marked.  Now let's check the accuracy of this analyzer: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>bigram_tagger.evaluate(testing_sents) <span class="hljs-number"><span class="hljs-number">0.8447124489185687</span></span></code> </pre> <br>  As a result, we get ~ 84%.  This is a very good indicator.  You can combine different analyzers, take a more training sample to achieve a better result. <br><br><h3>  Conclusion </h3><br>  What can be concluded?  Best of all, of course, use a combination of analyzers.  But Unigram analyzer coped no worse and less time was spent on it. <br><br>  I hope this article will help in the choice of the analyzer.  Thanks for attention. <br><br><h3>  Links </h3><br><ol><li>  <a href="http://www.nltk.org/">NLTK package.</a>  <a href="http://www.nltk.org/">Official site</a> </li><li>  <a href="http://www.nltk.org/book/ch05.html">NLTK.</a>  <a href="http://www.nltk.org/book/ch05.html">Documentation</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/340404/">https://habr.com/ru/post/340404/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../340390/index.html">On the issue of strangeness and the impossible</a></li>
<li><a href="../340394/index.html">C / C ++ code profiling on * nix-systems</a></li>
<li><a href="../340396/index.html">Writing Arcsight FlexConnector. Log file</a></li>
<li><a href="../340400/index.html">Competition Topcoder "Konica-Minolta Pathological Image Segmentation Challenge". Member Notes</a></li>
<li><a href="../340402/index.html">Open broadcast from the main hall of SmartData 2017: speech is not about solutions - speech is about evolution</a></li>
<li><a href="../340406/index.html">Microsoft and Amazon introduced a new library for machine learning - Gluon</a></li>
<li><a href="../340408/index.html">How to add information about transfers to the game assembly at Unity</a></li>
<li><a href="../340410/index.html">Visual Scripting: The Future Is Now?</a></li>
<li><a href="../340412/index.html">Monday begins on Saturday: 28 years of LANIT</a></li>
<li><a href="../340414/index.html">Two days left until the Moscow Python conference. What is interesting in the program?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>