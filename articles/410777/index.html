<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The primary task of quantum computers is to enhance artificial intelligence</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The idea of ‚Äã‚Äãmerging quantum computing and machine learning is in its prime. Can she live up to high expectations? 


 In the early 1990s, Elizabeth ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The primary task of quantum computers is to enhance artificial intelligence</h1><div class="post__text post__text-html js-mediator-article"><h2>  The idea of ‚Äã‚Äãmerging quantum computing and machine learning is in its prime.  Can she live up to high expectations? </h2><br><img src="https://habrastorage.org/getpro/geektimes/post_images/0d2/202/edd/0d2202edd860f81b4ce1ae73ce84774b.jpg"><br><br>  In the early 1990s, Elizabeth Behrman, a professor of physics at <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25B8%25D1%2587%25D0%25B8%25D1%2582%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D1%2583%25D0%25BD%25D0%25B8%25D0%25B2%25D0%25B5%25D1%2580%25D1%2581%25D0%25B8%25D1%2582%25D0%25B5%25D1%2582">Wichita University,</a> began working on merging quantum physics with artificial intelligence ‚Äî in particular, in the area of ‚Äã‚Äãthe then unpopular neural network technology.  Most people thought she was trying to mix oil with water.  ‚ÄúIt was damn difficult for me to publish,‚Äù she recalls.  ‚ÄúThe journals on neural networks said‚Äú What is this quantum mechanics? ‚Äù, And the journals on physics said‚Äú What is this neural network nonsense? ‚Äù <br><br>  Today, a mixture of these two concepts seems the most natural thing in the world.  Neural networks and other machine learning systems have become the most sudden technology of the 21st century.  Human activities are better for them than people, and they surpass us not only in the tasks in which most of us did not shine - for example, in chess or in-depth analysis of data, but also in those tasks for which the brain evolved - for example, face recognition, translation of languages, and determination of the right of way at a four-way intersection.  Such systems have become possible due to the enormous computing power, so it is not surprising that technology companies began searching for computers not just bigger, but belonging to a completely new class. <br><a name="habracut"></a><br>  After decades of research, quantum computers are almost ready to perform calculations ahead of any other computers on Earth.  As their main advantage, expansion into large numbers is usually given - an operation that is key for modern encryption systems.  True, up to this point there are still at least ten years.  But today's rudimentary quantum processors are mysteriously perfect for machine learning needs.  They manipulate huge amounts of data in a single pass, seek out elusive patterns that are invisible to classic computers, and do not quench themselves before incomplete or undefined data.  ‚ÄúThere is a natural symbiosis between the statistical nature of quantum computing and machine learning,‚Äù says Johann Otterbach, a physicist at Rigetti Computing, a company that deals with quantum computing in Berkeley, California. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      For that matter, the pendulum has already swung to another maximum.  Google, Microsoft, IBM and other tech-giants are pouring funds into quantum machine learning (KMO) and the startup incubator dedicated to this topic, located at the University of Toronto.  ‚ÄúMachine learning‚Äù is becoming a buzzword, ‚Äùsays <a href="http://jotterbach.github.io/">Jacob Biamont</a> , a specialist in quantum physics from the <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BA%25D0%25BE%25D0%25BB%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25B8%25D0%25BD%25D1%2581%25D1%2582%25D0%25B8%25D1%2582%25D1%2583%25D1%2582_%25D0%25BD%25D0%25B0%25D1%2583%25D0%25BA%25D0%25B8_%25D0%25B8_%25D1%2582%25D0%25B5%25D1%2585%25D0%25BD%25D0%25BE%25D0%25BB%25D0%25BE%25D0%25B3%25D0%25B8%25D0%25B9">Skolkovo Institute of Science and Technology</a> .  "And by mixing it with the concept of" quantum ", you will learn the mega-modular word." <br><br>  But the concept of "quantum" never means exactly what is expected of it.  Although you might decide that a CMO system should be powerful, it suffers from "locked up" syndrome.  It works with quantum states, not with <a href="https://ru.wikipedia.org/wiki/%25D0%25A7%25D0%25B5%25D0%25BB%25D0%25BE%25D0%25B2%25D0%25B5%25D0%25BA%25D0%25BE%25D1%2587%25D0%25B8%25D1%2582%25D0%25B0%25D0%25B5%25D0%25BC%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">human-readable</a> data, and the translation between these two worlds can offset all its distinct advantages.  It's like an iPhone X, with all of its impressive features, is no faster than an old phone, because the local network works disgustingly.  In some special cases, physicists can overcome this bottleneck of input-output, but it is not yet clear whether such cases will appear when solving practical problems with MOs.  ‚ÄúWe don‚Äôt have clear answers yet,‚Äù says <a href="https://www.scottaaronson.com/">Scot Aaronson</a> , a computer scientist at the University of Texas at Austin, who is always trying to really look at things in the field of quantum computing.  ‚ÄúPeople are quite cautious about the question of whether these algorithms will give any speed advantage.‚Äù <br><br><h2>  Quantum neurons </h2><br>  The main task of a neural network, be it classical or quantum, is to recognize patterns.  It is created in the image of the human brain and is a grid of basic computational units - "neurons".  Each of them may be no more difficult than an on / off switch.  A neuron monitors the output of many other neurons, as if voting on certain issues, and switches to the ‚Äúon‚Äù position if enough neurons vote ‚Äúfor‚Äù.  Usually neurons are ordered into layers.  The first layer accepts input (for example, image pixels), the middle layers create different combinations of input (representing structures such as faces and geometric shapes), and the last layer produces output (a high-level description of what is contained in the picture). <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/7db/f7b/e08/7dbf7be08420c056575f3d65870fa9e0.jpg"><br>  <i>Deep neural networks are trained by adjusting the weights of their connections so as to best transmit signals through several layers to the neurons associated with the necessary generalized concepts.</i> <br><br>  What is important, this whole scheme is not worked out in advance, but is adapted in the process of learning by trial and error.  For example, we can feed the network images, signed "kitten" or "puppy."  For each picture, it assigns a label, checks whether it has succeeded, and if not, corrects neural connections.  At first it works almost randomly, but then improves the results;  after, say, 10,000 examples, she begins to understand pets.  There can be a billion internal connections in a serious neural network, and all of them need to be adjusted. <br><br>  On a classic computer, these connections are represented by a fabulous matrix of numbers, and the work of the network means performing matrix calculations.  Usually, these operations with the matrix are given for processing to a special chip - for example, a <a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25BF%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581%25D0%25BE%25D1%2580">graphics processor</a> .  But no one can handle matrix operations better than a quantum computer.  ‚ÄúProcessing large matrices and vectors on a quantum computer is exponentially faster,‚Äù says Seth Lloyd, a physicist at MIT and pioneer of quantum computing. <br><br>  To solve this problem, quantum computers are able to take advantage of the exponential nature of the quantum system.  Most of the information capacity of a quantum system is not contained in its individual data units - qubits, quantum analogs of the bits of a classical computer - but in the joint properties of these qubits.  Two qubits jointly have four states: both on, both off, on / off and off / on.  Everyone has a certain weight, or ‚Äúamplitude‚Äù, which can play the role of a neuron.  If you add a third qubit, you can imagine eight neurons;  the fourth is 16. The capacity of the machine grows exponentially.  In fact, neurons are spread throughout the system.  When you change the state of four qubits, you process 16 neurons in one fell swoop, and a classic computer would have to process these numbers one by one. <br><br>  Lloyd estimates that 60 qubits will be enough to encode as much data as mankind produces in a year, and 300 may contain the classic content of the entire Universe.  The largest quantum computer currently available, built by IBM, Intel and Google, has about 50 qubits.  And this is only if we assume that each amplitude represents one classic bit.  In fact, amplitudes are continuous (and represent complex numbers), and with accuracy suitable for practical tasks, each of them can store up to 15 bits, says Aaronson. <br><br>  But the ability of a quantum computer to store information in a compressed form does not make it faster.  You need to be able to use these qubits.  In 2008, Lloyd, physicist <a href="http://www.mit.edu/~aram/">Aram Harrow</a> of MIT and <a href="http://u.cs.biu.ac.il/~avinatan/">Avinathan Hassidim</a> , an informatics specialist at Bar-Ilan University in Israel, <a href="">showed</a> how you can perform an important algebraic operation to invert a matrix.  They broke it into a sequence of logical operations that can be performed on a quantum computer.  Their algorithm works for a huge number of MO technologies.  And he does not need as many steps as, say, the decomposition of a large number of factors.  A computer can quickly perform a classification task before noise ‚Äî a major limiting factor of modern technology ‚Äî can ruin everything.  ‚ÄúBefore you have a completely universal, error-tolerant quantum computer, you may have just a quantum advantage,‚Äù said Kristan Temme from the Research Center.  Thomas Watson's IBM Company. <br><br><h2>  Let nature solve the problem </h2><br>  So far, machine learning based on quantum matrix computing has been demonstrated only on computers with four qubits.  Much of the experimental success of quantum machine learning uses a different approach, in which a quantum system does not just simulate a network, but is a network.  Each qubit is responsible for one neuron.  And although there is no reason to talk about exponential growth, such a device can take advantage of other properties of quantum physics. <br><br>  The largest of these devices, containing about 2000 qubits, was manufactured by D-Wave Systems, located near Vancouver.  And this is not exactly what people imagine, thinking about a computer.  Instead of receiving some input data, performing a sequence of calculations and showing the output, it works by finding internal consistency.  Each of the qubits is a superconducting electrical loop, working like a tiny electromagnet, oriented up, down, or up and down ‚Äî that is, being in a superposition.  Together, qubits are connected by magnetic interaction. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b8f/9a6/8f3/b8f9a68f399b21384517d43a8ae02a26.jpg"><br><br>  To start this system, you first need to apply a horizontally oriented magnetic field that initializes qubits with the same up and down superposition ‚Äî the equivalent of a blank sheet.  There are a couple of ways to enter data.  In some cases, it is possible to fix the layer of qubits in the necessary initial values;  more often, input is included in the interaction force.  Then you allow qubits to interact with each other.  Some try to line up the same way, some - in the opposite direction, and under the influence of a horizontal magnetic field, they switch to their preferred orientation.  In this process, they can force other qubits to switch.  At first, this happens quite often, because so many qubits are located incorrectly.  Over time, they calm down, after which you can turn off the horizontal field and lock them in this position.  At this point, the qubits lined up in a sequence of ‚Äúup‚Äù and ‚Äúdown‚Äù positions, representing the output based on the input. <br><br>  It is not always obvious what the final location of the qubits will be, but this is the point.  The system, simply behaving naturally, solves the problem over which a classical computer would have fought for a long time.  ‚ÄúWe don‚Äôt need an algorithm,‚Äù explains <a href="http://www.stat.phys.titech.ac.jp/~nishimori/index-e.html">Hidetoshi Nisimori</a> , a physicist at the Tokyo Institute of Technology, who developed the principles of D-Wave machines.  - This is a completely different approach from conventional programming.  The problem is solved by nature. ‚Äù <br><br>  The switching of qubits is due to quantum tunneling, the natural tendency of quantum systems to the optimal configuration, the best possible one.  It would be possible to build a classic network that works on analog principles, using random jitter instead of tunneling to switch bits, and in some cases it would actually work better.  But, interestingly, for problems appearing in the field of machine learning, the quantum network seems to reach the optimum faster. <br><br>  The car from D-Wave has its drawbacks.  It is extremely susceptible to noise, and in the current version it can perform few variations of operations.  But machine learning algorithms are noise tolerant by nature.  They are useful precisely because they can recognize the meaning in an untidy reality, separating the kittens from the puppies, despite the distractions.  ‚ÄúNeural networks are known for their resistance to noise,‚Äù said Berman. <br><br>  In 2009, a team led by <a href="https://research.google.com/pubs/HartmutNeven.html">Hartmut Niven</a> , a computer scientist from Google, the pioneer of augmented reality (he co-founded the Google Glass project), who switched to the field of quantum information processing, showed how D-Wave's early prototype is capable of performing quite a real task. machine learning.  They used the car as a single-layer neural network, sorting images into two classes: "car" and "not car" in the library of 20,000 photos taken on the streets.  In the car there were only 52 workers qubit, not enough to fully enter the image.  Therefore, the Niven team combined the machine with a classic computer, analyzed various statistical parameters of the images and calculated how sensitive these values ‚Äã‚Äãare to the presence of a car in the photo - they were usually not particularly sensitive, but at least they differed from the random ones.  Some combination of these values ‚Äã‚Äãcould reliably determine the presence of a car, it was simply not obvious what kind of combination it was.  And the neural network was engaged in the definition of the necessary combination. <br><br>  Each value team associated qubit.  If the qubit was set to 1, he noted the corresponding value as useful;  0 means it is not needed.  The magnetic interactions of qubits encoded the requirements of this problem ‚Äî for example, the need to take into account only the most strongly differing quantities so that the final choice would be the most compact.  The resulting system was able to recognize the car. <br><br>  Last year, a team led by Maria Spiropoulou, a specialist in particle physics from the California Institute of Technology, and Daniel Lidar, a physicist from the University of Southern California, applied an algorithm to solve a practical problem in physics: classifying the collisions of protons into the Higgs boson and non-boson categories Higgs.  By limiting the estimates only to collisions that produced photons, they used the basic theory of particles to predict which properties of the photon should indicate a short-term appearance of the Higgs particle ‚Äî for example, the magnitude of a pulse exceeding a certain threshold.  They examined eight such properties and 28 combinations of them, which together gave 36 candidate signals and allowed the D-Wave chip to find the optimal sample.  He identified 16 variables as useful, and three as the best.  ‚ÄúGiven the small size of the training set, the quantum approach gave an advantage in accuracy over the traditional methods used in the community of specialists in high-energy physics,‚Äù said Lidar. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2f0/c6a/6f9/2f0c6a6f9e018abed46dcdcc062321d9.jpg"><br>  <i>Maria Spiropoulou, a physicist at Caltech, used machine learning to find the Higgs bosons.</i> <br><br>  In December, Rigetti demonstrated a method for automatically grouping objects using a general-purpose quantum computer of 19 qubits.  The researchers fed the car a list of cities and distances between them and asked her to sort the cities into two geographical regions.  The difficulty of this task is that the distribution of one city depends on the distribution of all the others, so you need to look for a solution for the entire system at once. <br><br>  The company's team, in fact, assigned each city a qubit and noted which group it was assigned to.  Through the interaction of qubits (in the Rigetti system, it is not magnetic, but electric), each pair of qubits sought to take opposite values, since in this case their energy was minimized.  Obviously, in any system containing more than two qubits, some pairs will have to belong to the same group.  Closer located cities more willingly agreed to this, since for them the energy cost of belonging to the same group was lower than in the case of distant cities. <br><br>  To bring the system to the smallest energy, the Rigetti team chose an approach that was somewhat similar to the D-Wave approach.  They initialized qubits with a superposition of all possible distributions into groups.  They allowed Qbits to interact with each other for a short time, and this inclined them to accept certain values.  Then they applied an analogue of the horizontal magnetic field, which allowed the qubits to change the orientation to the opposite, if they had such a tendency that it pushed the system a little towards the energy state with minimal energy.  Then they repeated this two-step process ‚Äî interaction and a coup ‚Äî until the system minimized energy, distributing cities to two different regions. <br><br>  Similar classification tasks, although useful, are fairly simple.  Real breakthroughs of MO are expected in generative models that not only recognize puppies and kittens, but are able to create new archetypes - animals that have never existed, but are as cute as they are real.  They are even able to independently bring out such categories as ‚Äúkittens‚Äù or ‚Äúpuppies‚Äù, or reconstruct an image that does not have a paw or tail.  ‚ÄúThese technologies are capable of much and are very useful in MO, but very difficult to implement,‚Äù said <a href="https://www.sfu.ca/physics/people/profiles/amin.html">Mohammed Amin</a> , chief scientist at D-Wave.  The help of quantum computers would come in handy here. <br><br>  D-Wave and other research teams accepted this challenge.  To train such a model is to adjust the magnetic or electrical interactions of the qubits so that the network can reproduce certain test data.  To do this, combine the network with a regular computer.  The network is involved in complex tasks ‚Äî it determines what this set of interactions means in terms of the final network configuration ‚Äî and the partner computer uses this information to fine-tune the interactions.  In one demonstration last year, <a href="https://ti.arc.nasa.gov/profile/aperdomo/">Alejandro Perdomo-Ortiz</a> , a researcher at NASA's Quantum Artificial Intelligence Laboratory, and a team gave D-Wave an image system consisting of hand-written numbers.  She determined that there were a total of ten categories, compared the numbers from 0 to 9, and created her own scribbles in the form of numbers. <br><br><h2>  Bottlenecks leading to tunnels </h2><br>  This is all good news.  And the bad news is that no matter how cool your processor is, if you can't provide it with data to work with.  In matrix algebra algorithms, a single operation can process a matrix of 16 numbers, but it still takes 16 operations to load the matrix.  ‚ÄúThe issue of state preparation ‚Äî the placement of classical data in a quantum state ‚Äî is avoided, and I think this is one of the most important parts,‚Äù said Maria Schuld, a researcher at the Xanadu quantum computer startup and one of the first scientists who received a degree in KMO.  Physically distributed MO systems face parallel difficulties ‚Äî how to introduce a task into a network of qubits and make qubits interact as needed. <br><br>  Once you have been able to enter data, you need to store them in such a way that the quantum system can interact with them without collapsing the current calculations.  Lloyd and his colleagues suggested quantum RAM using photons, but no one has yet an analog device for superconducting qubits or trapped ions ‚Äî technologies used in leading quantum computers.  ‚ÄúThis is another huge technical problem besides the problem of building a quantum computer itself,‚Äù said Aaronson.  - When communicating with experimenters, I get the impression that they are scared.  They have no idea how to approach the creation of this system. ‚Äù <br><br>  And finally, how to display the data?  It means to measure the quantum state of the machine, but the measurement not only returns one number at a time, chosen randomly, it also destroys the entire state of the computer, erasing the rest of the data before you have any chances to claim it.  We'll have to run the algorithm again and again to remove all the information. <br><br>  But all is not lost.  For some types of problems, quantum interference can be used.  You can control the course of operations so that the wrong answers are mutually destroyed, and the correct answers reinforce themselves;  thus, when you measure a quantum state, you will be returned not just a random value, but the desired answer.  But only a few algorithms, for example, brute-force search, can use the interference, and the acceleration is usually small. <br><br>  In some cases, researchers have found workarounds for data entry and output.  In 2015, Lloyd, Silvano Garnerone from the University of Waterloo in Canada and <a href="https://dornsife.usc.edu/cf/faculty-and-staff/faculty.cfm%3Fpid%3D1016223">Paolo Zanardi</a> from the University of Southern California showed that it is not necessary to enter or store the entire data set in certain types of statistical analysis.  Similarly, it is not necessary to read all the data when several key values ‚Äã‚Äãare sufficient.  For example, technocompanies use MOs to issue recommendations for TV shows or products for purchase based on a huge matrix of human habits.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúIf you make such a system for Netflix or Amazon, you need not the matrix itself recorded somewhere, but recommendations for users,‚Äù says Aaronson.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">All this raises the question: if a quantum machine demonstrates its abilities in special cases, maybe the classical machine can also show itself well in these cases? This is the main unresolved issue in this area. After all, ordinary computers can do a lot too. The usual selection method for processing large data sets ‚Äî random sampling ‚Äî is actually very similar in spirit to a quantum computer, which, whatever happens inside it, ultimately produces a random result. Schuld notes: ‚ÄúI implemented a lot of algorithms to which I reacted like:‚Äú This is so great, this is acceleration, ‚Äùand then, just for fun, wrote sampling technology for a classic computer, and understood that the same can be achieved with sampling assistance. "</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">None of the successes achieved by KMO to date is complete without a trick. </font><font style="vertical-align: inherit;">Take the car D-Wave. </font><font style="vertical-align: inherit;">When classifying images of cars and Higgs particles, it worked no faster than a classic computer. </font><font style="vertical-align: inherit;">‚ÄúOne of the topics not discussed in our work is quantum acceleration,‚Äù said Alex Mott, a computer scientist from the Google DeepMind project, who worked on the team that investigated the Higgs particle. </font><font style="vertical-align: inherit;">Approaches with matrix algebra, for example, the Harrow-Hassidimi-Lloyd algorithm demonstrate acceleration only in the case of </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D0%25B7%25D1%2580%25D0%25B5%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D1%2582%25D1%2580%25D0%25B8%25D1%2586%25D0%25B0"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sparse matrices</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äî almost completely filled with zeros. </font><font style="vertical-align: inherit;">"But no one asks the question - are sparse data generally interesting for machine learning?" Schuld said.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Quantum intelligence </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On the other hand, even rare improvements in existing technologies could please tech companies. ‚ÄúThe resulting improvements are modest, not exponential, but at least quadratic,‚Äù says </font></font><a href="https://www.microsoft.com/en-us/research/people/nawiebe/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nathan Wieb</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , a researcher in the field of quantum computers from Microsoft Research. "If we take a sufficiently large and fast quantum computer, we could make a revolution in many areas of MO." And in the process of using these systems, computer scientists will probably solve a theoretical riddle - is it really, by definition, faster, and in what way.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schuld also believes that there is a place on the software side for innovation. MO is not just a bunch of calculations. This is a complex of tasks with its own particular, defined structure. ‚ÄúThe algorithms created by people are separated from those things that make the MoD interesting and beautiful,‚Äù she said. - Therefore, I started working from the other end and thought: If I already have a quantum computer - small-scale - which model of MO can be implemented on it? Maybe this model has not yet been invented. ‚Äù If physicists want to impress experts on MO, they will have to do something more than just create quantum versions of existing models.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Just as many neuroscientists have come to the conclusion that the structure of a person‚Äôs thoughts reflects the need for a body, MO systems also materialize. Images, language and most of the data flowing through them come from the real world and reflect its properties. KMO is also materializing - but in a richer world than ours. One of the areas where it will no doubt shine is in the processing of quantum data. If this data represents not the image, but the result of a physical or chemical experiment, the quantum machine will become one of its elements. The input problem disappears, and classic computers are far behind.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As if in a vicious circle situation, the first KMOs can help develop their successors. ‚ÄúOne of the ways we can really want to use these systems is to create quantum computers themselves,‚Äù said Waibe. ‚ÄúFor some error recovery procedures, this is the only approach we have.‚Äù Maybe they can even eliminate the mistakes in us. Without addressing the subject of whether the human brain is a quantum computer ‚Äî and this is a very controversial issue ‚Äî it still behaves this way sometimes. Human behavior is extremely contextual; our preferences are formed through the choices made available to us and do not follow logic. In this we are like quantum particles. ‚ÄúThe way you ask questions and in what order matters, and this is typical of quantum datasets,‚Äù said Perdomo-Ortiz.Therefore, the KMO system can be a natural method for studying the cognitive distortions of human thinking.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neural networks and quantum processors have something in common: surprisingly, they generally work. </font><font style="vertical-align: inherit;">The ability to train a neural network was never obvious, and for decades most people doubted that it would be possible at all. </font><font style="vertical-align: inherit;">Likewise, it is not obvious that quantum computers can ever be adapted to computing, since the distinguishing features of quantum physics are so well hidden from all of us. </font><font style="vertical-align: inherit;">And yet both of them work ‚Äî not always, but more often than we might expect. </font><font style="vertical-align: inherit;">And considering this, it seems likely that their union will find a place for itself under the sun.</font></font></div><p>Source: <a href="https://habr.com/ru/post/410777/">https://habr.com/ru/post/410777/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../410765/index.html">Programming modern microcontrollers - new course MIREA, Samsung and Unwired Devices</a></li>
<li><a href="../410767/index.html">MIT promises to launch a small thermonuclear power plant in 15 years</a></li>
<li><a href="../410769/index.html">What is "reverse ICO"</a></li>
<li><a href="../410771/index.html">In the atmosphere of exoplanets WASP-39b was three times more water than on Saturn</a></li>
<li><a href="../410773/index.html">rTorrent helps attackers mine cryptocurrency on their users' computers</a></li>
<li><a href="../410779/index.html">How Wild West Farmers Arranged Barbed Wire Telephone Network</a></li>
<li><a href="../410781/index.html">Chemists test retrosynthetic paths fully predicted by AI algorithms.</a></li>
<li><a href="../410783/index.html">Nakraudfandili: the best projects for February 2018</a></li>
<li><a href="../410785/index.html">Blockchain is an ancient Russian invention</a></li>
<li><a href="../410787/index.html">Enthusiast made a new motherboard for the ThinkPad X200s</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>