<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Overview of position tracking techniques and technologies for virtual reality</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Position tracking (positional tracking) is a combination of hardware and software that allows you to determine the absolute position of an object in s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Overview of position tracking techniques and technologies for virtual reality</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/geektimes/post_images/61d/660/b03/61d660b03bab0138ae5dba8e8f84c5c6.png"><br><br>  Position tracking (positional tracking) is a combination of hardware and software that allows you to determine the absolute position of an object in space.  This technology is critical to achieve the effect of immersion in virtual reality.  In combination with orientation tracking, it becomes possible to measure and transmit to the VR all 6 degrees of freedom (6-DoF) of the real world.  In the course of working with virtual reality technologies in our company, we gained some experience in this matter and would like to share them by telling us about the existing ways of tracking the situation for virtual reality, as well as about the pros and cons of a particular solution. <br><a name="habracut"></a><br><h4>  Small classification </h4><br>  The set of methods and approaches to solving this problem can be divided into several groups: <br><ul><li>  Acoustic <br></li><li>  Radio frequency <br></li><li>  Magnetic <br></li><li>  Optical <br></li><li>  Inertial <br></li><li>  Hybrid <br></li></ul><br>  Human perception places high demands on accuracy (~ 1mm) and delays (&lt;20 ms) in BP equipment.  Optical and inertial methods are closest to these requirements, and are most often used together, complementing each other.  Consider the basic principles on which the above methods are built. <br><br><h4>  Acoustic methods </h4><br>  Acoustic tracking devices use ultrasonic (high-frequency) sound waves to measure the position and orientation of a target object.  To determine the position of an object, the time of flight ( <a href="https://en.wikipedia.org/wiki/Time_of_arrival">time-of-arrival</a> ) of the sound wave from the transmitter to the receivers, or the phase difference of a sinusoidal sound wave during transmission and reception, is measured.  <a href="http://www.intersense.com/pages/20/14">Intersense</a> develops ultrasound-based position tracking devices. <br>  Acoustic trackers, as a rule, have a low update rate, caused by the low speed of sound in the air.  Another problem is that the speed of sound in air depends on such environmental factors as temperature, barometric pressure and humidity. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Radio frequency methods </h4><br>  There are many methods based on radio frequencies.  In many respects according to the principles of determining the position, they are similar to acoustic tracking methods (the only difference is in the nature of the wave).  The most promising at the moment are UWB (Ultra-Wide Band) methods, but even in the best solutions based on UWB, accuracy reaches only about centimeters ( <a href="http://www.decawave.com/products/dw1000">DW1000 from DecaWave</a> , <a href="https://www.zebra.com/us/en/products/location-solutions/dart-uwb.html">Dart from Zebra Technologies</a> , <a href="http://ubisense.net/">Series 7000 from Ubisense</a> and others).  Perhaps in the future, startups like <a href="https://www.pozyx.io/">Pozyx</a> or <a href="http://indotraq.com/">IndoTraq</a> will be able to achieve sub-millimeter accuracy.  However, while UWB position tracking solutions are not applicable for virtual reality. <br>  Other methods of positioning at radio frequencies are described in more detail in this <a href="https://habrahabr.ru/company/rtl-service/blog/281837/">article</a> . <br><br><h4>  Magnetic methods </h4><br>  Magnetic tracking is based on measuring the intensity of a magnetic field in various directions.  As a rule, in such systems there is a base station that generates an alternating or permanent magnetic field.  Since the magnetic field strength decreases with increasing distance between the measurement point and the base station, it is possible to determine the location of the controller.  If the measurement point rotates, the distribution of the magnetic field changes along different axes, which allows you to determine the orientation.  The most well-known products based on magnetic tracking are the <a href="http://sixense.com/razerhydra">Razer Hydra</a> controller and the <a href="http://sixense.com/wireless">STEM</a> system from Sixense. <br>  The accuracy of this method can be quite high under controlled conditions (Hydra specifications refer to 1 mm of positional accuracy and 1 degree of orientation accuracy), however magnetic tracking is subject to interference from conductive materials near the emitter or sensor, from magnetic fields created by other electronic devices and ferromagnetic materials in tracking space. <br><br><h4>  Optical methods </h4><br>  Optical methods are a combination of computer vision algorithms and tracking devices, which are visible or infrared cameras, stereo cameras and depth cameras. <br>  Depending on the choice of reference system, two approaches are distinguished for tracking the position: <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/5a5/a46/129/5a5a46129cb63064e4d98818f5bfabfa.png"><br><br><ul><li>  <i>The</i> outside <i>-in</i> approach implies the presence of a fixed external observer (camera) determining the position of a moving object at characteristic points.  Used in Oculus Rift (Constrellation), PSVR, OSVR and many Motion Capture systems. <br></li><li>  <i>The inside-out</i> approach assumes the presence of an optical sensor on a moving object, thanks to which it is possible to track movement relative to fixed points in the surrounding space.  Used in Microsoft Hololens, Project Tango (SLAM), SteamVR Lighthouse (hybrid version, as there are base stations). <br></li></ul><br>  Also, depending on the availability of special optical markers, they are distinguished separately: <br><ul><li>  <i>Marker-free tracking</i> is usually based on complex algorithms using two or more cameras, or stereo cameras with depth sensors. <br></li><li>  <i>Tracking using markers</i> implies a predetermined object model that can be monitored even with a single camera.  Markers usually serve as sources of infrared radiation (both active and passive), as well as visible markers like QR codes.  This type of tracking is possible only within the line of sight of the marker. <br></li></ul><br><h5>  Perspective-n-Point (PnP) Task </h5><br>  In optical tracking, the so-called PnP (Perspective-n-Point) problem is solved to determine the position of an object in space, when it is necessary to determine the position of an object in 3D space from the perspective projection of the object onto the camera's sensor plane. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/69e/e34/a00/69ee34a001e42b494c7c95e8c8b824da.gif"><br><br>  For a given 3D model of the object and a 2D projection of the object on the camera plane, a system of equations is solved.  As a result, there are many possible solutions.  The number of decisions depends on the number of points in the 3D model of the object.  A unique solution for determining the 6-DoF position of an object can be obtained at a minimum of 4 points.  For a triangle there are from 2 to 4 possible solutions, that is, the position cannot be determined unambiguously: <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/98c/63e/2e0/98c63e2e0ada80b066e213b8a011e955.gif"><br><br>  The solution is offered by a sufficiently large number of algorithms implemented as libraries: <br><ul><li>  Posit <br></li><li>  <a href="http://www.ics.forth.gr/~lourakis/posest/">posest</a> <br></li><li>  <a href="http://opencv.org/">OpenCV</a> ( <a href="http://docs.opencv.org/3.1.0/d9/d0c/group__calib3d.html">solvePnP</a> ) <br></li></ul><br><h5>  SLAM - <i>Simultaneous Localization and Mapping</i> </h5><br>  The method of simultaneous localization and mapping (SLAM) is the most popular positioning method in robotics (and not only), which is used to track a position in space. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/ef3/851/c95/ef3851c958ae729b437738e0b7a7b9c6.png"><br><br>  The algorithm consists of two parts: the first is the mapping of an unknown surrounding space based on measurements (data from the odometer or stereo camera), the second is the determination of its location (localization) in space based on a comparison of current measurements with the existing space map.  This cycle is continuously recalculated, with the results of one process involved in the calculations of another process.  The most popular methods for solving a problem include a particle filter and an advanced Kalman filter.  In fact, SLAM is a rather extensive topic, and not just one specific algorithm, and the analysis of all existing solutions on this topic draws on a separate article. <br>  SLAM is convenient for virtual and augmented reality mobile solutions.  However, the disadvantage of this approach is a large computational complexity, which, coupled with demanding VR / AR applications, will greatly load the productive resources of the device. <br><br>  <a href="https://en.wikipedia.org/wiki/Tango_(platform)">Project Tango</a> from Google and Microsoft Hololens are the most famous projects based on SLAM for mobile devices.  SLAM-based tracking support is also expected in Intel's recently announced products ( <a href="https://newsroom.intel.com/press-kits/project-alloy/">Project Alloy</a> ) and Qualcomm ( <a href="https://www.qualcomm.com/news/snapdragon/2016/09/01/new-era-virtual-reality-snapdragon-vr820-reference-platform">VR820</a> ). <br>  Among open-source solutions can be identified <a href="https://github.com/raulmur/ORB_SLAM2">ORB-SLAM</a> , <a href="https://github.com/tum-vision/lsd_slam">LSD-SLAM</a> , <a href="https://github.com/Oxford-PTAM/PTAM-GPL">PTAM-GPL</a> . <br><br><h4>  Inertial tracking </h4><br>  Modern inertial measurement systems ( <a href="https://en.wikipedia.org/wiki/Inertial_measurement_unit">IMU</a> ) based on MEMS technology allow tracking orientation (roll, pitch, yaw) in space with great accuracy and minimal delays. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/bb5/7c3/47b/bb57c347b0b938cdf1b2a39cf3fff905.gif"><br><br>  Thanks to the sensor fusion algorithms based on a complementary filter or <a href="https://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B8%25D0%25BB%25D1%258C%25D1%2582%25D1%2580_%25D0%259A%25D0%25B0%25D0%25BB%25D0%25BC%25D0%25B0%25D0%25BD%25D0%25B0">Kalman filter, the</a> data from the gyroscope and accelerometer successfully correct each other and ensure accuracy for both short-term measurements and for a long period. <br><br>  However, determining the coordinates (displacement) due to the double integration of linear acceleration ( <a href="https://en.wikipedia.org/wiki/Dead_reckoning">dead reckoning</a> ), calculated from raw data from the accelerometer, does not meet the accuracy requirements for long periods of time.  The accelerometer itself gives very noisy data, and when integrated, the error increases quadratically with time. <br>  Combining the inertial approach to tracking with other methods that periodically adjust the so-called accelerometer drift helps solve this problem. <br><br><h4>  Hybrid methods </h4><br>  Since none of the methods is flawless, and they all have their weak points, it is most reasonable to combine different tracking methods.  So inertial tracking (IMU) can provide a high frequency of updating data (up to 1000 Hz), while optical methods can give stable accuracy in long periods of time (drift correction). <br><br>  Hybrid tracking methods are based on " <a href="https://en.wikipedia.org/wiki/Sensor_fusion">Sensor Fusion</a> " algorithms, the most popular of which is the <a href="https://en.wikipedia.org/wiki/Extended_Kalman_filter">Extended Kalman Filter</a> ( <a href="https://en.wikipedia.org/wiki/Extended_Kalman_filter">EKF</a> ). <br><br><h5>  How does the SteamVR Lighthouse work? </h5><br>  The HTC Vive tracking system consists of two base stations, optical sensors and inertial measurement units (IMUs) in controllers and a helmet.  Base stations consist of two rotating lasers and an array of infrared LEDs.  One of the lasers rotates vertically, the second - horizontally.  Thus, lasers in turn "scan" the surrounding space.  Base stations operate synchronously: at a certain point in time, only one of the four lasers ‚Äúscans‚Äù the tracking space.  To synchronize the operation of the entire system between each switching on of the lasers, the entire surrounding space is illuminated by an infrared light pulse. <br><br>  Sensors on the controllers and the helmet capture all optical pulses from the base stations and measure the time between them.  Since the frequency of rotation of lasers is known in advance (60 Hz), the angles of rotation of each of the beams can be calculated from the time between pulses.  What gives us the 2D coordinates of the optical sensor, knowing the relative position of the sensors on the controller, you can easily restore the 3D position of the controller in space (the PnP task).  When two base stations are simultaneously visible, the 3D position of the controller can be calculated from the intersection of two rays, which gives more accurate results and requires less computation.  More clearly the process of tracking is shown below. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/J54dotTt7k0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  A month ago, Valve announced that it was opening its tracking system for third-party developers.  Read more about this <a href="https://geektimes.ru/post/279198/">here</a> . <br><br>  Which of the methods of tracking positions in space is the most promising for virtual / augmented reality in your opinion? <br><br>  This is the first article from the cycle about BP technologists, if there is interest, we will continue to write them further. <br><br>  PS Why there is no virtual reality hub? </div><p>Source: <a href="https://habr.com/ru/post/397757/">https://habr.com/ru/post/397757/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../397743/index.html">YouTube Heroes is a real treat for the watchman</a></li>
<li><a href="../397749/index.html">The structure and initial settings of the brain</a></li>
<li><a href="../397751/index.html">How to make scientific predictions</a></li>
<li><a href="../397753/index.html">China opened the heavenly eye. Today began the world's largest radio telescope</a></li>
<li><a href="../397755/index.html">Underwater Volcanoes - An Oasis in the Deep Sea World</a></li>
<li><a href="../397759/index.html">Cheap flights ... Or a network of fraudulent sites that steal money from cards. My investigation</a></li>
<li><a href="../397761/index.html">The book "Life on the Edge. Your first book on quantum biology. ‚Äù</a></li>
<li><a href="../397763/index.html">Today will be released third "Cossacks"</a></li>
<li><a href="../397765/index.html">Turkish company has developed real autobot transformers</a></li>
<li><a href="../397767/index.html">VKontakte launched money transfer service</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>