<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The system of recommendations online store based on methods of machine learning in the Compute Engine (Google Cloud Platform)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Using the Google Cloud Platform services, you can create an effective scalable recommendation system for an online store. 

 An interesting situation ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The system of recommendations online store based on methods of machine learning in the Compute Engine (Google Cloud Platform)</h1><div class="post__text post__text-html js-mediator-article">  Using the Google Cloud Platform services, you can create an effective scalable recommendation system for an online store. <br><br>  An interesting situation has developed on the e-commerce market.  Although total cash flow increased, so did the number of sellers.  This led to the fact that the share of each store has decreased, and the competition between them is becoming more intense.  One way to increase the average purchase size (and therefore profit) is to offer customers additional products that may interest them. <br><br>  In this article, you will learn how to set up an environment based on the Cloud Platform to support the basic recommendation system, which over time can be refined and expanded. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It describes the solution for the site of a real estate rental agency that allows you to select and offer recommendations to users. <br><br><img src="https://habrastorage.org/files/a09/66e/a3d/a0966ea3d1dc419aa6de610555f48306.png"><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Who is not familiar with the cloud platform Google Cloud Platform - take a look at a series of webinars</b> <div class="spoiler_text"><table><tbody><tr><td>  [January 19, Thursday, 11:00 Moscow time] <br>  <a href="https://goo.gl/sPkA9j">Overview of the Google Cloud Platform</a> <br><ul><li>  What is the Google Cloud Platform, what are its advantages and unique characteristics </li><li>  Overview of infrastructure services Google Cloud (IaaS / PaaS, Storage, Networking) </li><li>  Overview of Big Data and Machine Learning Google Cloud Services </li></ul><br>  <a href="https://webinars.softlinegroup.com/mira/miravr/1963253831">Link to webinar entry</a> <a href="https://webinars.softlinegroup.com/mira/miravr/1963253831"><br></a> <br>  [February 3, Friday, 11:00 Moscow time] <br>  <a href="https://goo.gl/uzI3A9">Cloud Infrastructure Services Google Cloud Platform</a> <br><ul><li>  Infrastructure as a service (IaaS): providing computing power for rent </li><li>  NoOps / PaaS solutions based on Google App Engine </li><li>  Google Container Engine - Docker Container Orchestration Solutions </li></ul><br>  <a href="https://webinars.softlinegroup.com/vfs/download/flash/videoconference.html%3Fe%3DZmlsZXNBZGRyZXNzPWh0dHBzOi8vd2ViaW5hcnMuc29mdGxpbmVncm91cC5jb20vdmZzLyZ1c2Vy%255B%255BSWQ9LTEmcmVjb3JkSWQ9MTQ4NjEwODkxODE4OSZjb25uZWN0aW9ucz1ydG1wdDomc2NvcGVOYW1l%255B%255BPWFIUjBjSE02THk5M1pXSnBibUZ5Y3k1emIyWjBiR2x1WldkeWIzVndMbU52YlM5dGFYSmhMMTFv%255B%255BZEhSd2N6b3ZMM2RsWW1sdVlYSnpbW0xuTnZablJzYVc1bFozSnZkWEF1WTI5dEwyMXBjbUV2W1td%255B%255BMTgyOSQxNzgxMTcyNjk0JDE0ODYxMDg5MTgxODkmd2ViQWRkcmVzcz1odHRwczovL3dlYmluYXJz%255B%255BLnNvZnRsaW5lZ3JvdXAuY29tLyZzZXNzaW9uSWQ9NTQwNDM0ODc0JnNlcnZlckFkZHJlc3M9cnRt%255B%255BcDovL3dlYmluYXJzLnNvZnRsaW5lZ3JvdXAuY29tOjE5MzUvdmlydGNsYXNzLyZmaWxlc1VybD1o%255B%255BdHRwczovL3dlYmluYXJzLnNvZnRsaW5lZ3JvdXAuY29tL3Zmcy8%255B%255B">Link to webinar entry</a> <br><br>  [February 17, Friday, 11:00 Moscow time] <br>  <a href="https://goo.gl/VUW9OE">Tools for working with Big Data and Machine Learning from the Google Cloud Platform</a> <br><ul><li>  BigQuery - Data warehousing solution for storing and retrieving large amounts of data in the cloud </li><li>  Dataproc - Hadoop Cloud Clusters </li><li>  Dataflow - ETL tool for processing streaming and batch data </li><li>  CloudML - a platform for developing and training machine learning models </li><li>  Also at this webinar we will look at various aspects of using storage services in GCP. </li></ul><br>  <a href="https://webinars.softlinegroup.com/mira/miravr/1680923684">Link to webinar entry</a> <br><br>  [March 2, Thursday, 11:00 Moscow time] <br>  <a href="https://goo.gl/0vMPLz">Practical seminar: step-by-step demonstration of Google Cloud Platform services</a> <br><ul><li>  Google Compute Engine - running tasks in managed virtual machine groups, global load balancing and automatic scaling </li><li>  Google App Engine - iterative development and deployment of web applications on the PaaS platform of Google </li></ul></td></tr></tbody></table><br><table><tbody><tr><th colspan="2"><h1>  Webinars lead </h1></th></tr><tr><td><h2>  Oleg Ivonin </h2><br>  @GoogleAmsterdam <br><img src="https://habrastorage.org/files/4d9/219/6e8/4d92196e8b0d49478c8a0d1b02a95046.png"><br>  <b>Cloud Web Solutions Engineer</b> <br>  Oleg is developing tools for analyzing the cost of configurations and planning the cloud architecture of solutions based on the Google Cloud Platform.  Oleg's developments are used in publicly available GCP tools, for example Google Cloud Platform Pricing Calculator </td><td><h2>  Dmitry Novakovsky </h2><br>  @GoogleAmsterdam <br><img src="https://habrastorage.org/files/2de/57e/df4/2de57edf49ca4365b61d51f2c9d2eccf.png"><br>  <b>Customer Engineer</b> <br>  Dmitry is engaged in sales support and development of architectural solutions for business customers of the Google Cloud Platform.  Dmitry's main focus is in the field of infrastructure services: Google Compute Engine (GCE), Google App Engine (GAE) and Google Container Engine (GKE / Kubernetes). <br></td></tr></tbody></table><br></div></div><br><table><tbody><tr><td>  Perhaps, as you read the article, you will have a desire to recreate this scenario in the Google Cloud Platform - by clicking on the <a href="https://goo.gl/iSW6EC">link</a> you will receive $ 300 to test GCP services within 60 days </td></tr></tbody></table><br><h2>  Scenario </h2><br>  Anna is looking for vacation rentals on a specialized website.  Previously, she had already rented accommodation through this site and left a few reviews, so there is enough data in the system to select recommendations based on her preferences.  Judging by the estimates in Anna‚Äôs profile, she usually rents houses, not apartments.  The system should offer her something from the same category. <br><br><h2>  Solution Overview </h2><br>  For the selection of recommendations in real time (on the website) or after the fact (by e-mail), initial data are necessary.  If we still do not know the user's preferences, you can select recommendations simply on the basis of the offers chosen by him.  However, the system must constantly learn and accumulate data on what customers like.  When enough information is gathered in it, it will be possible to analyze and select current recommendations using a machine learning system.  In addition, the system can transmit information about other users, as well as from time to time to retrain.  In our example, the system of recommendations has already accumulated enough data for the application of machine learning algorithms. <br><br>  Data processing in such a system is usually performed in four stages: collection, storage, analysis, selection of recommendations (see figure below). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/dbe/25e/7bf/dbe25e7bf3844d6ebe2860d45a068aff.png"></div><br>  The architecture of such a system can be schematically represented as follows: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/3dd/012/00f/3dd01200f8f146e0a55e5bf052e5f326.png"></div><br>  Each stage can be customized according to specific requirements.  The system consists of the following elements: <br><br><ul><li>  Front-end.  Scalable interface part, where all user actions are recorded, that is, data is collected. </li><li>  Storage.  Permanent storage available for machine learning platform.  Loading data into it can include several steps, such as import, export, and data conversion. </li><li>  Machine learning.  A machine learning platform where analysis of collected data and selection of recommendations is performed. </li><li>  The second element is Storage.  Another storage, which is used by the interface part in real time or after the fact, depending on when you need to provide recommendations. </li></ul><br><h2>  Component selection </h2><br>  To get a quick, convenient, inexpensive and accurate solution, <a href="https://cloud.google.com/appengine/docs">Google App Engine</a> , <a href="https://cloud.google.com/sql/docs">Google Cloud SQL</a> and <a href="https://spark.apache.org/">Apache Spark</a> were chosen based on the <a href="https://cloud.google.com/compute/docs">Google Compute Engine</a> .  The configuration is created using the bdutil script. <br><br>  The App Engine service allows you to handle tens of thousands of requests per second.  At the same time, it is easy to manage and allows you to quickly write and run code to perform any tasks - from creating a site to writing data to internal storage. <br><br>  Cloud SQL also makes it easy to create our solution.  It can deploy 32-core virtual machines with up to 208 GB of RAM and increase storage capacity by request to 10 TB with 30 I / O operations per second for each GB and thousands of simultaneous connections.  This is more than enough for the system under consideration, as well as for many other real cases.  In addition, Cloud SQL supports direct access from Spark. <br><br>  Spark compares favorably with the classic Hadoop handler: its performance is 10-100 times higher, depending on the specific solution.  The <a href="https://spark.apache.org/mllib/">Spark MLlib library</a> allows <a href="https://spark.apache.org/mllib/">you</a> to analyze hundreds of millions of assessments in minutes and run the algorithm more often to keep the recommendations current.  Spark is characterized by simpler programming models, more convenient APIs, and a more universal language.  For calculations, this framework uses memory to the maximum extent, which allows reducing the number of disk accesses.  It also reduces the number of I / O operations.  In this solution, the Compute Engine is used to host the analytical infrastructure.  This allows you to significantly reduce costs, since payment is charged per minute upon use. <br><br>  The following diagram shows the same system architecture, but now with an indication of the technologies used: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/664/cab/532/664cab532e1342ddb336a65649e3ad2a.png"></div><br><h2>  Data collection </h2><br>  The recommendation system may collect user data based on implicit (behavior) or explicit information (ratings and reviews). <br><br>  Collecting data on behavior is quite simple, since all actions can be recorded in journals without the participation of the users themselves.  The disadvantage of this approach is that the collected data is more difficult to analyze, for example, to identify those data that are of the greatest interest.  An example of analyzing data about explicit actions using log entries is available <a href="https://cloud.google.com/solutions/real-time/fluentd-bigquery">here</a> . <br><br>  Collecting ratings and reviews is more difficult, since many users leave them reluctantly.  However, it is this data that best helps to understand customer preferences. <br><br><h2>  Data storage </h2><br>  The more data available to the algorithms, the more accurate the recommendations will be.  This means that very soon you will have to start working with big data. <br><br>  The choice of the type of storage to use depends on what data you create recommendations from.  It can be a NoSQL database, SQL or even an object storage.  In addition to the volume and type of data, factors such as ease of implementation, the ability to integrate into the existing environment and support for the transfer must be taken into account. <br><br>  A scalable managed database is great for storing user ratings and actions, as it is easier to use and allows you to spend more time.  <a href="https://cloud.google.com/sql/">Cloud SQL</a> not only meets these requirements, but also makes it easier to download data from Spark. <br><br>  The sample code below shows the schemas of the Cloud SQL tables.  The rented property is entered in the Accommodation table, and the user rating of this object is entered in the Rating table. <br><br><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-function">CREATE TABLE </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Accommodation</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"> id varchar(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), title </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">varchar</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), location </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">varchar</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), price </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">, rooms </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">, rating </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">, type </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">varchar</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), PRIMARY </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">KEY</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">ID</span></span></span><span class="hljs-function">) )</span></span>; <span class="hljs-function"><span class="hljs-function">CREATE TABLE </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Rating</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"> userId varchar(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), accoId </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">varchar</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), rating </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">, PRIMARY </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">KEY</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">accoId, userId</span></span></span><span class="hljs-function">), FOREIGN </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">KEY</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">accoId</span></span></span><span class="hljs-function">) REFERENCES </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Accommodation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">id</span></span></span><span class="hljs-function">) )</span></span>;</code> </pre> <br>  Spark can extract data from various sources, such as from Hadoop HDFS or Cloud Storage.  In this solution, data is retrieved directly from Cloud SQL using a <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">JDBC connector</a> .  Since Spark jobs run in parallel, this connector must be available for all instances of the cluster. <br><br><h2>  Data analysis </h2><br>  For successful analysis, it is necessary to clearly formulate the requirements for the application, namely: <br><br><ul><li>  <i>Timeliness</i>  How fast should an application make recommendations? </li><li>  <i>Filtering data</i> .  Will the application generate recommendations based only on the tastes of the user, on the opinions of other users or on the similarity of products? </li></ul><br><h3>  Timeliness </h3><br>  The first thing you need to decide is how soon the user should receive recommendations.  Immediately, at the time of viewing the site, or later, by e-mail?  In the first case, of course, the analysis should be more operational. <br><br><ul><li>  <i>Real-time analysis</i> involves processing the data at the time of its creation.  Systems of this type, as a rule, use tools capable of processing and analyzing event streams.  Recommendations in this case are made instantly. <br><br></li><li>  <i>Batch analysis</i> involves periodic data processing.  This approach is appropriate when you need to collect enough data to get the actual result, for example, to find out the daily sales volume.  Recommendations in this case are developed after the fact and are provided in the format of electronic distribution. <br><br></li><li>  <i>An almost real-time</i> analysis involves updating the analytic data every few minutes or seconds.  This approach allows you to provide recommendations during one user session. </li></ul><br>  You can choose any category of timeliness, but for Internet sales, a cross between batch analysis and almost real-time analysis is best suited, depending on the amount of traffic and the type of data being processed.  The analytical platform can work directly with a database or with a dump periodically stored in permanent storage. <br><br><h2>  Data filtering </h2><br>  Filtering is a key component of the recommendation system.  Here are the main approaches to filtering: <br><br><ul><li>  Content, when recommendations are selected by attributes, that is, by similarity with the goods that the user is viewing or evaluating. </li><li>  Cluster, when goods are selected that are well combined with each other.  In this case, the opinions and actions of other users are not taken into account. </li><li>  Collaborative, when products are selected that are viewed or selected by users with similar tastes. </li></ul><br>  The Cloud Platform supports all three types; however, a collaborative filtering algorithm based on Apache Spark was chosen for this solution.  For more information about content and cluster filtering, see the <a href="https://cloud.google.com/solutions/recommendations-using-machine-learning-on-compute-engine">appendix</a> . <br><br>  Collaborative filtering allows you to abstract from the attributes of the product and make predictions, taking into account the tastes of the user.  This approach is based on the premise that the preferences of two users who liked the same product will be the same in the future. <br><br>  Data on assessments and actions can be represented as a set of matrices, and products and users - as values.  The system will fill in the missing cells in the matrix, trying to predict the attitude of the user to the product.  Below are two variants of the same matrix: the first shows the existing estimates;  in the second, they are indicated by a unit, and the missing estimates are zero.  That is, the second option is a truth table, where the unit indicates the interaction of users with the product. <br><br><img src="https://habrastorage.org/files/13f/9d9/642/13f9d9642979475292d2f0b49548c3f3.jpg"><br><br>  In collaborative filtering, two main methods are used: <br><br><ul><li>  <i>Anamnestic</i> - the system calculates matches between products or users; </li><li>  <i>model</i> - the system works on the basis of a model that describes how users evaluate products and what actions they take. </li></ul><br>  This solution uses a model method based on user ratings. <br><br>  All the analysis tools required for this solution are available in <a href="https://spark.apache.org/docs/latest/api/python/pyspark.html">PySpark</a> , the Python API for Spark.  Scala and Java open up additional features;  see the <a href="https://spark.apache.org/docs/latest/programming-guide.html">documentation for Spark</a> . <br><br><h2>  Training models </h2><br>  In Spark MLlib, ALS (Alternating Least Squares) algorithm is used to train models.  In order to achieve the optimal ratio between displacement and dispersion, we need to adjust the values ‚Äã‚Äãof the following parameters: <br><br><ul><li>  <b>Rank</b> - the number of unknown factors that the user was guided by when grading.  In particular, this may include age, gender and location.  To some extent, the higher the rank, the more accurate the recommendation.  The minimum value of this parameter will be 5;  we will increase it in increments of 5 until the difference in the quality of recommendations starts to decrease (or until there is enough memory and processor power). <br><br></li><li>  <b>Lambda</b> is a <i>regularization</i> parameter that allows you to avoid <i>overtraining</i> , that is, a situation with a large <i>variance</i> and a small <i>offset</i> .  Dispersion is the scatter of predictions made (after several passes) with respect to a theoretically correct value for a particular point.  Offset - distance of forecasts from the true value.  Re-training is observed when the model works well on training data with a known level of noise, but in reality it shows poor results.  The more lambda, the less retraining, but the higher the offset.  For testing, values ‚Äã‚Äãof 0.01, 1, and 10 are recommended. </li></ul><br>  The diagram shows the different ratios of dispersion and displacement.  The center of the target is the value that you want to predict using the algorithm. <br><br><img src="https://habrastorage.org/files/476/4ff/c0f/4764ffc0f87a402baa2c0d0f1f2a75aa.png"><br><br><ul><li>  <b>Iteration</b> is the number of learning passes.  In this example, 5, 10, and 20 iterations should be performed for different combinations of the ‚ÄúRank‚Äù and ‚ÄúLambda‚Äù parameters. </li></ul><br>  The following is an example code for running the ALS learning model in Spark. <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pyspark.mllib.recommendation import ALS model = ALS.train(training, rank = <span class="hljs-number"><span class="hljs-number">10</span></span>, iterations = <span class="hljs-number"><span class="hljs-number">5</span></span>, lambda_=<span class="hljs-number"><span class="hljs-number">0.01</span></span>)</code> </pre><br><h3>  Model selection </h3><br>  For ALS-based collaborative filtering, three data sets are used: <br><br><ul><li>  <b>The training set</b> contains data with known values.  This is what the perfect result should look like.  In the solution in question, this sample contains user estimates. </li><li>  <b>The test sample</b> contains data that allows the training sample to be refined in order to obtain the optimal combination of parameters and select the best model. </li><li>  <b>The test sample</b> contains data that allows you to test the performance of the best model.  This is equivalent to real-world analysis. </li></ul><br>  To choose the best model, you need to calculate the root mean square error (RMSE), based on the calculated model, the test sample and its size.  The smaller the RMSE, the more accurate the model. <br><br><h2>  Conclusion of recommendations </h2><br>  To speed up the output of analysis results, they should be loaded into the database with the ability to query on demand.  Cloud SQL is great for this.  Using Spark 1.4, you can write analysis results directly to the database from PySpark. <br><br>  The scheme of the Recommendation table is as follows: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-function">CREATE TABLE </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Recommendation</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"> userId varchar(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), accoId </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">varchar</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">255</span></span></span></span></span><span class="hljs-function">), prediction </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">, PRIMARY </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">KEY</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">userId, accoId</span></span></span><span class="hljs-function">), FOREIGN </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">KEY</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">accoId</span></span></span><span class="hljs-function">) REFERENCES </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Accommodation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">id</span></span></span><span class="hljs-function">) )</span></span>;</code> </pre><br><h2>  Code analysis </h2><br>  Now consider the code for learning models. <br><br><h3>  Extracting data from Cloud SQL </h3><br>  The Spark SQL context makes it easy to connect to a Cloud SQL instance through a JDBC connector.  Data is loaded in a DataFrame format. <br><br><h4>  <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine/blob/master/pyspark/app_collaborative.py">pyspark / app_collaborative.py</a> </h4><br><pre> <code class="cs hljs">jdbcDriver = <span class="hljs-string"><span class="hljs-string">'com.mysql.jdbc.Driver'</span></span> jdbcUrl = <span class="hljs-string"><span class="hljs-string">'jdbc:mysql://%s:3306/%s?user=%s&amp;password=%s'</span></span> % (CLOUDSQL_INSTANCE_IP, CLOUDSQL_DB_NAME, CLOUDSQL_USER, CLOUDSQL_PWD) dfAccos = sqlContext.load(source=<span class="hljs-string"><span class="hljs-string">'jdbc'</span></span>, driver=jdbcDriver, url=jdbcUrl, dbtable=TABLE_ITEMS) dfRates = sqlContext.load(source=<span class="hljs-string"><span class="hljs-string">'jdbc'</span></span>, driver=jdbcDriver, url=jdbcUrl, dbtable=TABLE_RATINGS)</code> </pre><br><h3>  Convert DataFrame to RDD and create datasets </h3><br>  At the core of Spark‚Äôs work is the concept of <a href="https://spark.apache.org/docs/latest/programming-guide.html">RDD (Resilient Distributed Dataset)</a> - an abstraction that allows you to work with elements in parallel.  RDD is a read-only data collection based on persistent storage.  Such collections can be analyzed in memory, which allows for iterative processing. <br><br>  As you remember, to select the best model, you need to divide the data sets into three samples.  The following code uses a helper function that arbitrarily separates non-overlapping values ‚Äã‚Äãas a percentage of 60/20/20: <br><br><h4>  <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine/blob/master/pyspark/app_collaborative.py">pyspark / app_collaborative.py</a> </h4><br><pre> <code class="cs hljs">rddTraining, rddValidating, rddTesting = dfRates.rdd.randomSplit([<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre><br>  <font color="#9cc2ce"><b>Note.</b></font>  <font color="#9cc2ce">In the Rating table, the columns should go in the following order: accoId, userId, rating.</font>  <font color="#9cc2ce">This is due to the fact that the ALS algorithm makes predictions based on the specified product / user pairs.</font>  <font color="#9cc2ce">If the order is broken, you can either change the database or reorder the columns using the map function in RDD.</font> <br><br><h3>  Selection of parameters for training models </h3><br>  As already mentioned, in the ALS method, our task is to adjust the rank, regularization and iteration in such a way as to finally obtain the optimal model.  The system already has user estimates, so the results of the train function should be compared with the test sample.  It is necessary to ensure that the user's tastes are taken into account in the training set. <br><br><h4>  <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine/blob/master/pyspark/find_model_collaborative.py">pyspark / find_model_collaborative.py</a> </h4><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> cRank, cRegul, cIter <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> itertools.product(ranks, reguls, iters): model = ALS.train(rddTraining, cRank, cIter, <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>(cRegul)) dist = howFarAreWe(model, rddValidating, nbValidating) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> dist &lt; finalDist: print(<span class="hljs-string"><span class="hljs-string">"Best so far:%f"</span></span> % dist) finalModel = model finalRank = cRank finalRegul = cRegul finalIter = cIter finalDist = dist</code> </pre><br>  <font color="#9cc2ce"><b>Note.</b></font>  <font color="#9cc2ce">The howFarAreWe function uses the model to predict estimates in a test sample based only on product / user pairs.</font> <br><br><h4>  <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine/blob/master/pyspark/find_model_collaborative.py">pyspark / find_model_collaborative.py</a> </h4><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-function">def </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">howFarAreWe</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">model, against, sizeAgainst</span></span></span><span class="hljs-function">): # Ignore the rating column againstNoRatings</span></span> = against.map(lambda x: (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>(x[<span class="hljs-number"><span class="hljs-number">0</span></span>]), <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>(x[<span class="hljs-number"><span class="hljs-number">1</span></span>])) ) <span class="hljs-meta"><span class="hljs-meta"># Keep the rating to compare against againstWiRatings = against.map(lambda x: ((int(x[0]),int(x[1])), int(x[2])) ) # Make a prediction and map it for later comparison # The map has to be ((user,product), rating) not ((product,user), rating) predictions = model.predictAll(againstNoRatings).map(lambda p: ( (p[0],p[1]), p[2]) ) # Returns the pairs (prediction, rating) predictionsAndRatings = predictions.join(againstWiRatings).values() # Returns the variance return sqrt(predictionsAndRatings.map(lambda s: (s[0] - s[1]) ** 2).reduce(add) / float(sizeAgainst))</span></span></code> </pre> <br><h3>       </h3><br>   ,      ,   ,        .   -,  . <br><br><h4> <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine/blob/master/pyspark/app_collaborative.py">pyspark/app_collaborative.py</a> </h4><br><pre> <code class="cs hljs"><span class="hljs-meta"><span class="hljs-meta"># Build our model with the best found values # Rating, Rank, Iteration, Regulation model = ALS.train(rddTraining, BEST_RANK, BEST_ITERATION, BEST_REGULATION) # Calculate all predictions predictions = model.predictAll(pairsPotential).map(lambda p: (str(p[0]), str(p[1]), float(p[2]))) # Take the top 5 ones topPredictions = predictions.takeOrdered(5, key=lambda x: -x[2]) print(topPredictions) schema = StructType([StructField("userId", StringType(), True), StructField("accoId", StringType(), True), StructField("prediction", FloatType(), True)]) dfToSave = sqlContext.createDataFrame(topPredictions, schema) dfToSave.write.jdbc(url=jdbcUrl, table=TABLE_RECOMMENDATIONS, mode='overwrite')</span></span></code> </pre> <br><h3>     </h3><br>        ,        Cloud SQL,      ,      <br><br><h4> <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine/blob/master/pyspark/app_collaborative.py">pyspark/app_collaborative.py</a> </h4><br><pre> <code class="cs hljs">dfToSave = sqlContext.createDataFrame(topPredictions, schema) dfToSave.write.jdbc(url=jdbcUrl, table=TABLE_RECOMMENDATIONS, mode=<span class="hljs-string"><span class="hljs-string">'overwrite'</span></span>)</code> </pre> <br><h2>   </h2><br>     ,        ,   <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine">GitHub</a> . <br><br>    SQL-              . <br><br>        Cloud Platform   MySQL: <br><br><img src="https://habrastorage.org/files/dd5/66a/a15/dd566aa15d944e27aaaac61781b82d33.png"><br><br>         ,          : <br><br><img src="https://habrastorage.org/files/47f/077/747/47f0777476c2482db79eab9ec1e10d88.png"><br><br>   ,       ,   ,    . <br><br><h2>   </h2><br><h3>    bdutil </h3><br>         SSH.  Spark   ,       -. <br><br>       8080.           .       <a href="https://cloud.google.com/compute/docs/networking%3Fhl%3Den"></a> .   ,      <a href="https://cloud.google.com/compute/docs/instances-and-network"> IP- </a> (, <a href="http://1.2.3.4/">1.2.3.4</a> :8080).      Spark        ,      . <br><br><img src="https://habrastorage.org/files/2e2/922/cfe/2e2922cfe1a24088bc8047f48165666f.png"><br><br> <b> Spark</b> <br><br><h3>   Cloud Dataproc </h3><br>      -      Cloud Dataproc. <br><br><h2>  Manual </h2><br>            <a href="https://github.com/GoogleCloudPlatform/spark-recommendation-engine"> GitHub</a> . <br><br><h2>  application </h2><br><h3>   </h3><br>     ,            .      ,        .        :   .         . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/821/624/023/821624023e7f4e2a92a2a638205bcfc4.png"></div><br><h3>   </h3><br>               .       .             . <br><br>    ,    ,       .      ,    ,   . <br><br>  ,         ,      : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c52/d8f/122/c52d8f12201845509547074820cbdd29.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/dbb/9aa/183/dbb9aa1833e04fdc8138dfd00c2a7e82.png"></div><br>       0  1.    1,    . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/d27/2c8/a8b/d272c8a8b8fc40c79d218f42ea853a9a.png"></div><br>   : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e23/65e/55b/e2365e55b242446c94ced7ecfa4591c9.png"></div><br>   P1  P2    : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/3ee/dbf/3eb/3eedbf3ebb6a4b86b6e4fa4f8585b673.png"></div><br>         .   : <br><br><ul><li> <a href="https://blog.twitter.com/2014/all-pairs-similarity-via-dimsum">        Twitter</a> .  Scala CosineSimilarities,   MLlib,     Spark. </li><li> <a href="https://mahout.apache.org/"> Mahout</a> .   -   MLlib    ,  Mahout   bdutil.   Mahout   ,   GitHub: </li></ul><br><pre> <code class="cs hljs">git clone https:<span class="hljs-comment"><span class="hljs-comment">//github.com/apache/mahout.git mahout export MAHOUT_HOME=/path/to/mahout export MAHOUT_LOCAL=false #For cluster operation export SPARK_HOME=/path/to/spark export MASTER=spark://hadoop-m:7077 #Found in Spark console</span></span></code> </pre><br> <font color="#9cc2ce"><b>.</b>    Mahout  Maven.</font> <br><br><h3>  Clustering </h3><br>      ,    .             ,     .    ,     ,   .     k-           . <br><br> ,     ,         ,         . <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pyspark.mllib.clustering import KMeans, KMeansModel clusters = KMeans.train(parsedData, <span class="hljs-number"><span class="hljs-number">2</span></span>, maxIterations=<span class="hljs-number"><span class="hljs-number">10</span></span>, runs=<span class="hljs-number"><span class="hljs-number">10</span></span>, initializationMode=<span class="hljs-string"><span class="hljs-string">"random"</span></span>)</code> </pre><br><h3>   ? </h3><br>      ,       ,         ,     (, ,   ).            (CRM)   - (ERP). <br><br>   ,        .       ,     ,    .        ,        Cloud Platform  API,  <a href="https://www.breezometer.com/">Breezometer</a> . <br><br><div class="spoiler"> <b class="spoiler_title">Softline - Google Cloud Premier Partner</b> <div class="spoiler_text"><table><tbody><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Softline is the largest Google corporate services provider in Russia and the CIS and the only partner with the status of Google Cloud Premier Partner. </font><font style="vertical-align: inherit;">Over the years, the company was recognized as the best partner of the year in the Enterprise segment, partner of the year in the EMEA region in the SMB segment.</font></font><br><img src="https://habrastorage.org/files/e03/d12/1c7/e03d121c75334dd5a0536be92f14c935.png"><br></td></tr></tbody></table></div></div></div><p>Source: <a href="https://habr.com/ru/post/319704/">https://habr.com/ru/post/319704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../319694/index.html">The continuation of the epic with a USB stack</a></li>
<li><a href="../319696/index.html">How to iterate over all permutations and about factorial decomposition of natural numbers</a></li>
<li><a href="../319698/index.html">Windows has an internal list of undelete root certificates.</a></li>
<li><a href="../319700/index.html">Introduction to the 8pt mesh system</a></li>
<li><a href="../319702/index.html">Duplo Railroad Tycoon: Synthesis of the rail network with maximum coverage</a></li>
<li><a href="../319706/index.html">Auto-find IPs</a></li>
<li><a href="../319708/index.html">Battle of ideas</a></li>
<li><a href="../319710/index.html">8 network resources to remove malicious code and eliminate the consequences of hacking the site</a></li>
<li><a href="../319712/index.html">Crysis at the maximum speed, or why the server needs a video card</a></li>
<li><a href="../319714/index.html">Flash to the head: IBM announced a line of storage arrays for the cloud</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>