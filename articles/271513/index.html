<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Asyncio Tarantool Queue, get in line</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In one of my articles, I talked about asynchronous work with Tarantool in Python . In this article I will continue this topic, but I want to pay atten...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Asyncio Tarantool Queue, get in line</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/efa/035/436/efa035436cca4b3a9f41d64e195f9f69.jpg"><br><br>  In one of my articles, I talked about <a href="http://habrahabr.ru/company/mailru/blog/254727/">asynchronous work with Tarantool in Python</a> .  In this article I will continue this topic, but I want to pay attention to the processing of information through the queues at <a href="http://tarantool.org/">Tarantool</a> .  My colleagues have published several articles about the benefits of queues (The <a href="http://habrahabr.ru/company/mailru/blog/228131/">infrastructure for processing queues on the social network My World</a> and <a href="http://habrahabr.ru/company/mailru/blog/232981/">Push notifications in the REST API using the example of the Target Mail.Ru system</a> ).  I want to add information about queues on the example of solutions to our problems, as well as talk about working with <a href="https://github.com/tarantool/queue/">Tarantool Queue</a> in Python and asyncio.  Why do we choose Tarantool, not Redis or RabbitMQ? <br><a name="habracut"></a><br><h1>  The task of sending messages "throughout the user base" </h1><br>  On Mail.Ru there are many media sites: <a href="https://news.mail.ru/">News</a> , <a href="https://auto.mail.ru/">Auto</a> , <a href="https://lady.mail.ru/">Lady</a> , <a href="https://health.mail.ru/">Health</a> , <a href="https://hi-tech.mail.ru/">Hi-Tech</a> , etc., and every day they are visited by millions of users.  Sites are adapted for mobile devices, for most of them there is a touch-version.  For the convenience of users, we created the <a href="https://news.mail.ru/app/">News mobile application</a> , which is popular on Android and iOS devices.  After the publication of the ‚Äúhot‚Äù news, each user of our application receives a push notification.  It usually looks like this: the chief editor chooses the news, clicks the Fire button in the admin panel, and that's it - let's go!  And what next?  Then you need as quickly as possible to send this news to the entire database of subscribers.  If someone receives a push notification in half an hour, then perhaps the news will not be so hot anymore, and the user will learn about it from another source.  This is not our case. <br><br>  So, there is a database that is stored in our favorite Tarantool.  It is necessary as soon as possible to bypass the entire base and send a push notification to all subscribers.  For each of them, a push-token and a little information about the device are stored in the database in json-format: application version, screen resolution, time zone, time interval in which the user wants to receive notifications.  Specifying the time zone is very important, because sending push notifications at night when everyone is sleeping is not a good idea. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The requirements are clear, we go further. <br><br><h1>  Solve the problem </h1><br>  Usually we begin to solve the problem in the forehead, in a simple way.  Simple code always looks very nice and clear: <br><br><pre><code class="html hljs xml">while ¬´ ¬ª:  ¬´¬ª   -    ¬´¬ª</code> </pre> <br>  The main <code>while</code> will run until it bypasses all users.  If the user base is small, then you can do nothing, the problem is solved.  What can be improved here?  How to speed up such a cycle?  How to send for a fixed time, regardless of the size of the database?  To do this, you need to clarify the details of the process of sending notifications. <br><br>  For simplicity, I‚Äôll focus on two Android and iOS platforms.  What is the "send push"?  How to do it?  There is a description of the <a href="http%3Fhl%3Dru">Google Cloud Messaging</a> and <a href="https://developer.apple.com/library/ios/documentation/NetworkingInternet/Conceptual/RemoteNotificationsPG/Chapters/ApplePushService.html">Apple Push Notification Service</a> protocols.  There are ready-made libraries for sending push notifications in <a href="https://pypi.python.org/pypi/gcm-client/">Android</a> and <a href="">iOS</a> to Python, designed to work in the usual "synchronous" mode.  If you dig deeper, then each platform has its own specifics.  Push to Android is sending json data via https; in iOS, sending binary data to an ssl socket.  Apple soon promises support for the HTTP / 2 protocol.  Under Android, sending to multiple destinations is possible.  IOS has the ability to group multiple users and send notifications to a group.  That is, the grouping for each platform also has its own characteristics. <br><br>  Clearly begs the decision with the queues.  I would like to separate the process of selecting users from the database and the process of sending notifications to the platforms.  But there are many important details.  For the independence of the process of sending one platform from another, we can separate users from the selected ‚Äúpacks‚Äù on iOS and Android, group the users and add a message to send to the queue we need.  Further, the messages can be processed, that is, directly perform the work itself on sending push notifications.  Schematically, all these processes can be represented as follows: <br><br><img src="https://habrastorage.org/files/6fe/28b/a5f/6fe28ba5f0cc42d3a85a68abdfb85c5e.png"><br>  Scheme of crawling user base and processing messages through the queue <br><br>  What will this approach give?  We will separate the process of crawling the user base from sending push notifications.  Thus, we will start to <code>select_range</code> faster (execute <code>select_range</code> ) ‚Äúbundles‚Äù in our initial cycle.  If, when processing messages on one of the platforms, we encounter potential problems (and these are quite often), this will not affect the distribution on the other platform.  Thus, we can easily parallelize the processing of messages on server cores, because we now have logical queues.  If you need to expand our system a little, we will simply add new logical queues. <br><br><h1>  Solve problems with load and scaling </h1><br>  With increasing load on one server, the CPU will end quickly.  Add another server?  Yes, exactly the same.  But it is better to do it at the design stage of the service.  If you make the system work on two servers, then add a couple of dozen is not difficult.  We adhere to this principle: at least two servers, even when there is no real load.  Several servers will also increase service reliability.  The service architecture takes the following form: <br><br><img src="https://habrastorage.org/files/ec3/a7f/124/ec3a7f124647429ea4f22fee8e7ed654.png"><br>  The scheme of bypass of user base on two servers <br><br>  So, we have two servers, each of which has its own queues (there is, of course, a user base, we believe that it is just nearby, is available for <code>select_range</code> , we will not pay much attention to this).  It is very important to run a loop traversal in parallel on two servers.  You can iterate through our cycle on one of the servers, select ‚Äúpacks‚Äù, place each ‚Äúpack‚Äù in different queues, and evenly distribute ‚Äúpacks‚Äù across all servers.  With this approach, we will be forced to ‚Äúchase‚Äù data over the network.  Choosing a ‚Äúpack‚Äù and putting it in a queue on another server is the weak side of this approach.  It is necessary to parallelize <code>select_range</code> across servers. <br><br>  To do this, on one of the servers, you need to select a ‚Äúpack‚Äù, add a small message with the information about the last user id from the current ‚Äúpack‚Äù to the queue on the ‚Äúneighboring‚Äù server.  When processing a small message on the second server, we have to get a ‚Äúnew packet‚Äù starting with the specified id, form a similar message to the ‚Äúneighbor server‚Äù, etc., until we touch through the entire database.  The current ‚Äúpack‚Äù should always be processed locally in its turn.  Thus, we ‚Äúsort of‚Äù move the code to our data, parallelize the generation of ‚Äúpacks‚Äù across the servers and do not drive the data over the network. <br><br>  The sequence diagram will look like this: <br><br><img src="https://habrastorage.org/files/ef8/283/46d/ef828346d95c4d98b92fbe991b36889e.png"><br><br>  The cycle ‚Äúby all users‚Äù is done implicitly via <code>queue.put(last_id)</code> .  The mailing process will end after users end in <code>select_range</code> .  It is very important that in the distribution scheme there are no blockages in the database.  This scheme is very similar to the Hadoop MapReduce process, the same principle of ‚ÄúDivide and Conquer‚Äù. <br><br>  Exactly the same architecture is used in our production.  For each type of mobile application and platform, separate logical queues are used, which allows to achieve independent parallel execution of processes.  It takes about 2 minutes to send push notifications for news about our combat 2 million user base.  Simultaneously with such mailings, a cluster of eight servers sends about 10 thousand push notifications per second. <br><br><h1>  Features of writing code for Tarantool Queue </h1><br>  How to work with a large number of logical queues?  How to simultaneously rake and generate data for all the queues in a single Python process?  Asynchronous programming techniques come to the rescue.  In the examples, I will use Centos 6.4, Python 3, asyncio, <a href="https://github.com/shveenkov/aiotarantool-queue-python">aiotarantool_queue</a> , Tarantool 1.6 and Tarantool Queue. <br><br>  The Tarantool Queue queue withstands quite large loads.  There is a <a href="https://github.com/tarantool/queue">description</a> on github.  In one instance with Tarantool Queue, you can create multiple logical queues by calling <code>queue.create_tube</code> .  Logical queues are called tube.  Several types of logical queues are supported.  Tarantool Queue has a <code>take/ack</code> mechanism.  Call <code>take</code> marks task as ‚Äúin work‚Äù.  The <code>ack</code> call removes the task from the queue, thus confirming its successful execution.  If it does not reach the <code>ack</code> call, another process will ‚Äúpick up‚Äù the task and execute <code>take</code> .  You can delay the execution of a task for some time using the <code>delay</code> parameter.  Not every line has this functionality and performance. <br><br>  Using Tarantool for both the user repository and the queue system makes our service simple in terms of the technologies used.  Use Tarantool Queue is not necessary.  Tarantool and Lua provide the opportunity to implement their own queue. <br><br>  Install Tarantool, place <a href="https://github.com/tarantool/queue">github.com/tarantool/queue</a> in the / usr / local / lua directory.  In the config Tarantool /etc/tarantool/instances.enabled/q1.lua we specify: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env tarantool package.path = package.path .. ';/usr/local/lua/tarantool-queue/?.lua' box.cfg{listen = 3301, slab_alloc_arena = 2} queue = require 'queue' queue.start() box.queue = queue</span></span></code> </pre><br>  We start our instance with the queue: <br><br><pre> <code class="bash hljs">tarantoolctl start q1</code> </pre><br>  Go to the console: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># tarantoolctl enter q1 /usr/bin/tarantoolctl: Connecting to /var/run/tarantool/q1.control /usr/bin/tarantoolctl: connected to unix/:/var/run/tarantool/q1.control unix/:/var/run/tarantool/q1.control</span></span></code> </pre><br>  Allow guest access and create a logical queue <code>q1</code> : <br><br><pre> <code class="bash hljs">q1.control&gt; box.schema.user.grant(<span class="hljs-string"><span class="hljs-string">'guest'</span></span>,<span class="hljs-string"><span class="hljs-string">'read,write,execute'</span></span>,<span class="hljs-string"><span class="hljs-string">'universe'</span></span>) q1.control&gt; queue.create_tube(<span class="hljs-string"><span class="hljs-string">'q1'</span></span>, <span class="hljs-string"><span class="hljs-string">'fifo'</span></span>) ^D</code> </pre><br>  You can rake one queue like this: <br><br><pre> <code class="python hljs">queue = Tarantool.Queue(host=<span class="hljs-string"><span class="hljs-string">"localhost"</span></span>, port=<span class="hljs-number"><span class="hljs-number">3301</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: task = queue.take(tube=<span class="hljs-string"><span class="hljs-string">"q1"</span></span>) process(task) task.ack()</code> </pre><br>  In order to rake N queues, you can create N processes.  In each process, connect to the desired queue and run the exact same cycle.  It is a working approach, but if there are many queues, there will be many connections to Tarantool Queue.  There will also be a lot of processes running that consume physical server memory.  Well, "many connections" does not make working with Tarantool as effective as it can be.  Also in the processes will have to keep connections to the servers of Google and Apple.  And again, the less connections we have to Google or Apple servers, the less we load them, the more resources of our server are available to us. <br><br>  In the article ‚ÄúAsynchronous work with Tarantool on Python‚Äù I described in detail why turning one connection to Tarantool can give a noticeable performance boost (this is very important for our workloads).  This approach can be applied here.  We modify our initial pseudo-code a bit to clear the queue.  Adapt it under asyncio. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> aiotarantool_queue @asyncio.coroutine <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">worker</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(tube)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: task = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tube.take(<span class="hljs-number"><span class="hljs-number">.5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> task: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> <span class="hljs-comment"><span class="hljs-comment"># process(task.data) yield from task.ack() loop = asyncio.get_event_loop() queue = aiotarantool_queue.Queue("127.0.0.1", 3301, loop=loop) workers = [asyncio.async(worker(tube), loop=loop) for tube in (queue.tube('q1'), queue.tube('q2'), queue.tube('q3'))] loop.run_until_complete(asyncio.wait(workers)) loop.run_until_complete(queue.close()) loop.close()</span></span></code> </pre><br>  In one process we create a connection to the queue.  Create coroutines with a take / ack cycle for all logical queues.  We start event loop and we clean all our turns.  This is our queuing pattern. <br><br>  It should be noted that the code remained linear, there are no callbacks.  Also "under the hood" of this code is hidden that the task from the queue will be read in "bundles" - all this comes from the <code>aiotarantool_queue</code> box.  And no expectations, pulling queues and timeouts!  Cool?  To load all the server cores on the CPU, of course, you will have to do several such processes, but this is a matter of technology.  Processing queues on Python processes would look pretty much the same.  Instead of korutin there would be processes.  And with a synchronous approach, the code could get even more confusing, and most importantly - not so productive. <br><br>  But there are downsides to using asyncio.  It is necessary to make third-party libraries work, which is not so difficult to do, but you will have to carefully review the code of these libraries and adapt their work using asyncio calls.  If we need a productive service, then all the efforts to support the work of third-party libraries under asyncio will be justified. <br><br><h1>  What about Redis and RabbitMQ? </h1><br>  Why do we use Tarantool Queue, not Redis or RabbitMQ?  The choice in favor of this or that product is not so easy to make - we considered both Redis and RabbitMQ.  There was even a prototype on Redis.  All these solutions have a fairly good performance.  But it‚Äôs not just ‚Äúwho is faster‚Äù ... <br><br>  First of all, I want the queue to be reliable, and not in the memory.  Tarantool with its WAL looks more reliable than Redis and RabbitMQ. <br><br>  Each of the queue systems has its own characteristics.  Redis has a pub / sub mechanism, but it is not suitable for solving our tasks - we just need a queue.  Redis has lists and rpush / blpop operations with locking and waiting for data to appear, but there is no take / ack mechanism.  In our production, reliability is ensured by this very mechanism - it has repeatedly shown itself from the best side. <br><br>  RabbitMQ is rich in various queue patterns.  To solve our problems, only a part of the RabbitMQ functional is required.  Its performance is really very high, but if you enable saving data to disk, the performance drops dramatically under load.  To operate RabbitMQ, experienced system administrators are needed who can diagnose production problems, and not just restart the RabbitMQ instance. <br><br>  RabbitMQ deserves special attention in its Python API and asyncio connector.  The queue API is implemented on callback.  The code from callbacks becomes complicated and hard to maintain.  To make message.ack in asyncio, you need to create a <a href="https://github.com/Polyconseil/aioamqp/blob/master/aioamqp/tests/test_basic.py">future and wait for it</a> .  This code looks very difficult.  Also, we could not send a few put / take in one connection. <br><br>  Redis with asyncio is much better: there is an excellent connector from the author of asyncio itself.  It works really fast. <br><br>  In Redis and RabbitMQ, there is no such data integration in the database and lua as in Tarantool.  As a rule, production tasks require a bit more ‚Äúlogic‚Äù from the box from the queue.  And in Tarantool this is easy to achieve thanks to lua.  For example, you can start storing counters or a cache with data, or statistics directly on queued instances.  All this makes Tarantool convenient for solving various tasks. <br><br><h1>  Summing up </h1><br>  We looked at the architecture of how to quickly and efficiently parallelize the crawling of the entire user base using the queue system on several servers.  We looked at patterns using Tarantool Queue and asyncio.  We paid attention to the problems of developing code using queue systems.  Considered the problems of RabbitMQ and Redis, as well as the advantages of Tarantool Queue. <br><br>  I hope the information will be useful for Habr's readers.  I would be glad if someone shared their case studies of queues and talked about the reasons for choosing this or that solution. <br><br>  References used in writing this article: <br><ul><li>  Tarantool - A NoSQL database running in a Lua application server <a href="http://tarantool.org/">tarantool.org</a> </li><li>  Python asyncio <a href="http://asyncio.org/">asyncio.org</a> </li><li>  Tarantool connection driver for work with asyncio <a href="http://github.com/shveenkov/aiotarantool">github.com/shveenkov/aiotarantool</a> </li><li>  Tarantool Queue bindings for work with python asyncio <a href="https://github.com/shveenkov/aiotarantool-queue-python">github.com/shveenkov/aiotarantool-queue-python</a> </li><li>  Infrastructure processing queues in the social network My World <a href="http://habrahabr.ru/company/mailru/blog/228131/">habrahabr.ru/company/mailru/blog/228131</a> </li><li>  Push notifications in the REST API on the example of the Target system Mail.Ru <a href="http://habrahabr.ru/company/mailru/blog/232981/">habrahabr.ru/company/mailru/blog/232981</a> </li><li>  Asynchronous work with Tarantool on Python <a href="http://habrahabr.ru/company/mailru/blog/254727/">habrahabr.ru/company/mailru/blog/254727</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/271513/">https://habr.com/ru/post/271513/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../271501/index.html">HV data storage format as an attempt to solve the problem of visual storage of text fields</a></li>
<li><a href="../271505/index.html">Work iOS App in the background</a></li>
<li><a href="../271507/index.html">The world's first floating data center launched</a></li>
<li><a href="../27151/index.html">File hosting</a></li>
<li><a href="../271511/index.html">Superfish: return</a></li>
<li><a href="../271515/index.html">How to solder "bridges" and chips on motherboards using a soldering station</a></li>
<li><a href="../27152/index.html">A new Gpcode virus encrypts files with the RSA-1024 key and extorts money for the decoder. Kaspersky launches the Stop Gpcode project.</a></li>
<li><a href="../271521/index.html">What is the difference between SSL certificates from Namecheap? Encryption, verification and trust</a></li>
<li><a href="../271527/index.html">Manage the real world things from the virtual world of Minecraft (translation)</a></li>
<li><a href="../271529/index.html">Black Friday at the Russian VDS-hoster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>