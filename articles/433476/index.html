<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>50 shades of celery</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="You are here if you want to know how to tame a widely known framework called Pylery in Python-developer circles. And even if in your project Celery co...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>50 shades of celery</h1><div class="post__text post__text-html js-mediator-article">  You are here if you want to know how to tame a widely known framework called Pylery in Python-developer circles.  And even if in your project Celery confidently executes basic commands, then Fintech experience can open up uncharted sides to you.  Because fintech is always Big Data, and with it the need for background tasks, batch processing, asynchronous API, etc. <br><img src="https://habrastorage.org/webt/oc/8a/rn/oc8arnnknqs37365anrx9mvuuru.jpeg"><br><br>  The beauty of Oleg Churkin's story about Celery at <a href="https://conf.python.ru/">Moscow Python Conf ++</a> in addition to detailed instructions on how to configure Celery under load and how to monitor it, is that you can borrow useful ideas. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SxgzHz-zE-c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>About the speaker and the project:</strong> Oleg Churkin ( <a href="https://habr.com/ru/users/bahusss/" class="user_link">Bahusss</a> ) has been developing Python-projects of various complexity for 8 years, worked in many well-known companies: Yandex, Rambler, RBC, Kaspersky Labs.  Now technid in fintech-stapard StatusMoney. <br><a name="habracut"></a><br>  The project works with a large amount of financial user data (1.5 terabytes): accounts, transactions, merchants, etc.  It runs up to a million tasks every day.  Maybe this number will not seem really large to someone, but for a small startup on modest capacities this is a significant amount of data, and the developers had to face various problems on the way to a stable process. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Oleg told about the key points of the work: <br><br><ul><li>  What tasks they wanted to solve with the help of the framework, why they chose Celery. </li><li>  How helped Celery. </li><li>  How to configure Celery under load. </li><li>  How to monitor the status of Celery. </li></ul><br>  And he shared a pair of project utilities that implement the missing functionality in Celery.  As it turned out, in 2018 this could happen.  Further, the text version of the report from the first person. <br><br><h2>  Problematics <br></h2><br>  It was necessary to solve the following tasks: <br><br><ul><li>  Run <strong>separate background tasks</strong> . </li><li>  To do <strong>batch processing of tasks</strong> , that is, to run many tasks at once. </li><li>  Embed the process of <strong>Extract, Transform, Load</strong> . </li><li>  Implement <strong>an asynchronous API</strong> .  It turns out that the asynchronous API can be implemented not only using asynchronous frameworks, but also quite synchronous ones; </li><li>  Perform <strong>periodic tasks</strong> .  No project can do without periodic tasks, for some, you can do Cron, but there are more convenient tools. </li><li>  Build a <strong>trigger architecture</strong> : to trigger the trigger, run a task that updates the data.  This is done to compensate for the lack of runtime capacity by pre-calculating data in the background. </li></ul><br>  <strong>Background tasks</strong> include any type of notification: email, push, desktop ‚Äî all of this is sent in background tasks with a trigger.  In the same way, a periodic update of financial data is launched. <br><br>  In the background, various specific checks are performed, for example, checking a user for fraud.  In financial startups, a <strong>lot of effort and attention is paid to data security</strong> , since we allow users to add their bank accounts to our system, and we can see all their transactions.  Fraudsters can try to use our service for something bad, for example, to check the balance of a stolen account. <br><br>  The last category of background tasks is <strong>maintenance tasks</strong> : tweak something, look, fix, monitor, etc. <br><br>  To send notifications, only mass, <strong>batch processing is used</strong> .  The large amount of data we receive from our users has to be calculated and processed in a certain way, incl.  in batch mode. <br><br>  This concept includes the classic <strong>Extract, Transform, Load</strong> : <br><br><ul><li>  load data from external sources (external API); </li><li>  keep untreated; </li><li>  run tasks that read and process data; </li><li>  We save the processed data in the right place in the right format, so that it is then convenient to use it in the UI, for example. </li></ul><br>  It's no secret that the asynchronous API can be done using simple polling requests: the frontend initiates the process on the backend, the backend runs the task, which periodically launches itself, pollit the results and updates the state in the database.  The frontend shows the user this interactivity - the state is changing.  This allows: <br><br><ul><li>  start polling tasks from other tasks; </li><li>  run different tasks depending on conditions. </li></ul><br>  In our service, this is still enough, but in the future most likely it will be necessary to rewrite something else. <br><br><h2>  Requirements for tools <br></h2><br>  To realize these tasks, we had the following requirements for tools: <br><br><ul><li>  The functionality needed to fulfill our ambitions. </li><li>  <strong>Scalability</strong> without crutches. </li><li>  <strong>Monitoring the</strong> system in order to understand how it works.  We use error reporting, so integration with Sentry is not superfluous, with Django too. </li><li>  <strong>Productivity</strong> , because we have a lot of tasks. </li><li>  Maturity, reliability and active development are obvious things.  We were looking for a tool that would be maintained and developed. </li><li>  The adequacy of the documentation - <strong>without documentation anywhere</strong> . </li></ul><br><h2>  Which tool to choose? <br></h2><br>  What are the options on the market in 2018 to solve these problems? <br><br>  Once upon a time, for less ambitious tasks, I wrote a convenient <a href="https://github.com/Bahus/uwsgi_tasks">library</a> that is still used in some projects.  It is easy to operate and performs tasks in the background.  But at the same time, no brokers are needed (neither Celery, nor others), only the <strong>uwsgi</strong> application server, which has a spooler, is such a thing that runs as a separate worker.  This is a very simple solution - all tasks are stored conditionally in files.  For simple projects, this is enough, but for ours it was not enough. <br><br>  Anyway, we looked at: <br><br><ul><li>  Celery (10K stars on GitHub); </li><li>  RQ (5K stars on GitHub); </li><li>  Huey (2K stars on GitHub); </li><li>  Dramatiq (1K stars on GitHub); </li><li>  Tasktiger (0.5K stars on GitHub); </li><li>  Airflow?  Luigi? </li></ul><br><h2>  Promising Candidate 2018 <br></h2><br>  Now I would draw your attention to <a href="https://dramatiq.io/">Dramatiq</a> .  This is a library from the Celery adept, who learned all the disadvantages of Celery and decided to rewrite everything, only very beautifully.  Advantages of Dramatiq: <br><br><ul><li>  A set of all the necessary features. </li><li>  Clearance for performance. </li><li>  Sentry and metrics support for Prometheus out of the box </li><li>  A small and clearly written codebase, code autoreload. </li></ul><br>  Some time ago, Dramatiq had problems with licenses: first it was AGPL, then it was replaced with LGPL.  But now you can try. <br><br>  But in 2016, apart from Celery, there was nothing special to take.  We liked its rich functionality, and then it ideally suited our tasks, because even then it was mature and functional: <br><br><ul><li>  had periodic tasks out of the box; </li><li>  supported several brokers; </li><li>  integrated with Django and Sentry. </li></ul><br><h2>  Project Features <br></h2><br>  I'll tell you about our context so that the following story is clearer. <br><br>  We use <strong>Redis as a message broker</strong> .  I have heard many stories and rumors that Redis is losing messages, that he is not fit to be a message broker.  In production experience this is not confirmed, and as it turns out, Redis now works more efficiently than RabbitMQ (it is with Celery, at least, apparently, the problem is in the code of integration with brokers).  In version 4, the Redis broker was repaired, it really stopped losing tasks during restarts and works quite stably.  In 2016, Celery was going to abandon Redis and concentrate on integration with RabbitMQ, but, fortunately, this did not happen. <br><br>  In case of problems with Redis, if we need serious high availability, we will switch to Amazon SQS or Amazon MQ because we are using Amazon power. <br><br>  We <strong>do not use result backend to store the results</strong> , because we prefer to store the results ourselves where we want, and check them as we want.  We don't want Celery to do this for us. <br><br>  We use the <strong>pefork pool</strong> , i.e. process-workers, which create separate forks for additional concurrency. <br><br><h2>  Unit of work <br></h2><br>  We will discuss the basic elements to bring up to date those who have not tried Celery, but are only going to.  <strong>Unit of work for Celery is a challenge</strong> .  I will give an example of a simple task that sends email. <br><br>  Simple function and decorator: <br><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@current_app.task def send_email(email: str): print(f'Sending email to email={email}')</span></span></code> </pre> <br>  The task launch is simple: either we call the function and the task is executed at runtime (send_email (email = "python@example.com")), or in a worker, that is, the same effect of the task in the background: <br><br><pre> <code class="python hljs">send_email.delay(email=<span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>) send_email.apply_async( kwargs={email: <span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>} )</code> </pre><br>  During two years of work with Celery under high loads, we derived good tone rules.  There were a lot of rakes, we learned to bypass them, and I will share how. <br><br><h4>  Code design <br></h4><br>  There can be different logic in the task.  In general, Celery helps you keep your puzzles in files or packages, or import them from somewhere.  Sometimes it turns out a jumble of business logic in one module.  In our opinion, the right approach from the point of view of the modularity of the application is to keep a <strong>minimum of logic in the problem</strong> .  We use puzzles only as ‚Äústarters‚Äù of the code.  That is, the task does not carry logic, but triggers the launch of the code on the Background. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@celery_app.task(queue='...') def run_regular_update(provider_account_id, *args, **kwargs): """...""" flow = flows.RegularSyncProviderAccountFlow(provider_account_id) return flow.run(*args, **kwargs)</span></span></code> </pre><br>  All the code we bring to external classes that use some other classes.  All tasks essentially consist of two lines. <br><br><h4>  Simple objects in the parameters <br></h4><br>  In the example above, a certain id is passed to the task.  In all the tasks we use, we <strong>transmit only small scalar data</strong> , id.  We do not serialize Django models to transmit them.  Even in ETL, when it comes from the external service of a large data blob, we first save it and then run a task that reads the entire blob by id and processes it. <br><br>  If you do not do this, then we have seen very large spikes of consumed memory from Redis.  The message starts to occupy more memory, the network is heavily loaded, the number of processed tasks (performance) decreases.  While the object reaches execution, the tasks become irrelevant, the object is already deleted.  The data needed to be serialized - not everything is well serialized to JSON in Python.  When we needed to retry tasks, we needed to quickly decide what to do with this data, get it again, and run some checks on them. <br><br><blockquote>  If you pass big data in parameters, think again!  It is better in the task to transfer a small scalar with a small amount of information, and for this information in the task to get everything necessary. <br></blockquote><br><h4>  Idempotent tasks <br></h4><br>  This approach is recommended by the Celery developers themselves.  When re-running the code segment, no side-effects should occur, the result should be the same.  This is not always easy to achieve, especially if there is interaction with many services, or two-phase commits. <br><br>  But when you do everything locally, you can always check that the incoming data exists and is relevant, you really can do work on it, and use transactions.  If a single task has a lot of queries into the database and something can go wrong at runtime - use transactions to roll back unnecessary changes. <br><br><h4>  backward compatibility <br></h4><br>  We had several interesting side effects with a deploe application.  It doesn't matter what type of deployment you use (blue + green or rolling update), there will always be a situation when the old service code creates messages for the new worker code, and vice versa, the old worker receives messages from the new service code because it rolls out "first" and there the traffic went. <br><br>  We caught mistakes and lost tasks until we learned to maintain <strong>backward compatibility between releases</strong> .  Backward compatibility is that tasks should work safely between releases, no matter what parameters come into this task.  Therefore, in all tasks we are now doing a "rubber" signature (** kwargs).  When in the next release you need to add a new parameter, you will take it from ** kwargs in the new release, and you will not take it in the old one - nothing will break.  As soon as the signature changes, but Celery does not know about it, it falls and gives an error that there is no such parameter in the task. <br><br>  A more strict way to avoid such problems is the versioning of task queues between releases, but it is rather difficult to implement and we have left it in backlog for now. <br><br><h4>  Timeouts <br></h4><br>  Problems may occur due to insufficient or incorrect timeouts. <br><br><blockquote>  Not setting a timeout for a task is evil.  This means that you do not understand what is happening in the task, how business logic should work. <br></blockquote><br>  Therefore, all our tasks are hung with timeouts, including global ones for all tasks, and timeouts are also set for each specific task. <br><br>  <strong>Be sure to include: soft_limit_timeout</strong> and <strong>expires.</strong> <br><br>  Expires is how much a task can live in a queue.  It is necessary that tasks do not accumulate in queues in case of problems.  For example, if we now want to report something to the user, but something has happened, and the task can be completed only tomorrow - there is no point in this, tomorrow the message will be irrelevant.  Therefore, on the notice we have quite a small expires. <br><br>  Note the use of <strong>eta (countdown) + visibility</strong> <strong>_timeout</strong> .  The FAQ describes such a problem with Redis - the so-called visibility timeout at the Redis broker.  By default, its value is one hour: if after an hour the worker does not take the task to execution, then re-adds it to the queue.  Thus, if the countdown is equal to two hours, after an hour the broker will find out that this task has not yet been completed, and will create another one the same.  And in two hours two identical tasks will be executed. <br><br><blockquote>  If the estimation time or countdown exceeds 1 hour, then most likely, using Redis will result in duplication of tasks, if you, of course, have not changed the visibility_timeout value in the broker connection settings. <br></blockquote><br><h4>  Retry policy <br></h4><br>  For those tasks that can be repeated, or that can be performed with errors, we use the Retry policy.  But we use it carefully so as not to overwhelm external services.  If you quickly repeat the task without specifying the exponential backoff, then the external service, or perhaps the internal one, can simply not withstand. <br><br>  The parameters <strong>retry_backoff</strong> , <strong>retry_jitter</strong> and <strong>max_retries</strong> would be nice to specify explicitly, especially max_retries.  retry_jitter is a parameter that allows you to add a little chaos so that tasks do not start repeating at the same time. <br><br><h4>  Memory leaks <br></h4><br><blockquote>  Unfortunately, memory leaks occur very easily, and it is difficult to find and fix them. </blockquote><br>  In general, working with memory in Python is very controversial.  You will spend a lot of time and nerves to understand why a leak occurs, and then it turns out that it is not even in your code.  Therefore, always starting a project, put a <strong>memory limit on the worker</strong> : worker_max_memory_per_child. <br><br>  This ensures that OOM Killer does not come one day, does not kill all the workers, and you do not lose all the tasks.  Celery will restart the workers when needed. <br><br><h4>  The priority of the tasks <br></h4><br>  There are always tasks that need to be performed before everyone, faster than all - they must be completed right now!  There are tasks that are not so important - let them be executed during the day.  To do this, the task has a <strong>priority</strong> parameter <strong>.</strong>  It works quite interestingly in Redis - a new queue is created with the name to which priority is added. <br><br>  We use a different approach - <strong>separate workers for priorities</strong> , i.e.  in the old way, we create workers for Celery with different ‚Äúimportance‚Äù: <br><br><pre> <code class="python hljs">celery multi start high_priority low_priority -c:high_priority <span class="hljs-number"><span class="hljs-number">2</span></span> -c:low_priority <span class="hljs-number"><span class="hljs-number">6</span></span> -Q:high_priority urgent_notifications -Q:low_priority emails,urgent_notifications</code> </pre><br>  Celery multi start is a helper that helps to run the entire Celery configuration on one machine and from one command line.  In this example, we create nodes (or workers): high_priority and low_priority, 2 and 6 - this is concurrency. <br><br>  Two high_priority workers constantly process the urgent_notifications queue.  No one else will take these workers, they will only read important tasks from the urgent_notifications queue. <br><br>  For unimportant tasks, there is a low_priority queue.  There are 6 workers who receive messages from all other queues.  We also subscribe to urgent_notifications low_priority workers so they can help if the workers with high_priority do not cope. <br><br>  We use this classic scheme to prioritize tasks. <br><br><h4>  Extract, Transform, Load <br></h4><br>  Most often, ETL looks like a chain of tasks, each of which receives input from the previous task. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def download_account_data(account_id) ‚Ä¶ return account_id @task def process_account_data(account_id, processing_type) ‚Ä¶ return account_data @task def store_account_data(account_data) ‚Ä¶</span></span></code> </pre><br>  In the example, three tasks.  Celery has an approach to distributed processing and several useful utilities, including the <strong>chain</strong> function, which makes one such pipeline out of three such tasks: <br><br><pre> <code class="python hljs">chain( download_account_data.s(account_id), process_account_data.s(processing_type=<span class="hljs-string"><span class="hljs-string">'fast'</span></span>), store_account_data.s() ).delay()</code> </pre><br>  Celery will disassemble the pipeline itself, perform the first task in order first, then transmit the received data to the second, the data that the second task returns, transfer to the third.  So we implement simple ETL pipelines. <br><br>  For more complex chains, you have to connect additional logic.  But it is important to keep in mind that if this chain has a problem in one task, then the <strong>whole chain will fall apart</strong> .  If you do not want this behavior, then handle exception and continue executing, or stop the entire exception chain. <br><br>  In fact, this chain inside looks like one big task, which contains all the tasks with all the parameters.  Therefore, if you abuse the number of tasks in the chain, you will get a very high memory consumption and slowing down the overall process.  <strong>Creating chains of thousands of tasks is a bad idea.</strong> <br><br><h2>  Batch processing tasks <br></h2><br>  Now the most interesting thing: what happens when you need to send an email to two million users. <br><br>  You write this function to bypass all users: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def send_report_emails_to_users(): for user_id in User.get_active_ids(): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  True, more often than not, the function will receive not only user id, but also flush the entire users table in general.  For each user will run their own task. <br><br>  There are several problems with this task: <br><br><ul><li>  Tasks are launched sequentially, that is, the last task (two millionth user) will start in 20 minutes and maybe by this time the timeout will work. </li><li>  All user IDs are loaded first into the application's memory, and then into the queue - delay () will perform 2 million tasks. </li></ul><br>  I called it Task flood, on the chart it looks like this. <br><img src="https://habrastorage.org/webt/j_/ya/6r/j_ya6r359licn16439uohbpoaow.png"><br>  There is an influx of tasks that the workers quietly begin to handle.  The following happens, if tasks use a master-replica, the whole project starts to just pop - nothing works.  Below is an example from our practice, where DB CPU Usage was 100% several hours, we, frankly, managed to get scared. <br><img src="https://habrastorage.org/webt/ac/wh/jy/acwhjy96edpu3dry_vatxj5z7yw.png"><br>  The problem is that the system greatly degrades with the increase in the number of users.  Task that deals with dispatching: <br><br><ul><li>  requires more and more memory; </li><li>  longer and can be "killed" by timeout. </li></ul><br>  Task flooding occurs: tasks accumulate in queues and create a large load not only on internal services, but also on external ones. <br><br>  We tried <strong>to reduce the competition of workers</strong> , it helps in some sense - reducing the load on the service.  Or you can <strong>scale internal services</strong> .  But this does not solve the problem of the generator problem, which still takes a lot on itself.  And does not affect the dependence on the performance of external services. <br><br><h3>  Task generation <br></h3><br>  We decided to go the other way.  Most often, we do not need to run all 2 million tasks right now.  It is normal that sending notifications to all users will take, for example, 4 hours, if these letters are not so important. <br><br>  At first we tried <strong>Celery.chunks</strong> : <br><br><pre> <code class="python hljs">send_report_email.chunks( ({<span class="hljs-string"><span class="hljs-string">'user_id'</span></span>: user.id} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> user <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> User.objects.active()), n=<span class="hljs-number"><span class="hljs-number">100</span></span> ).apply_async()</code> </pre><br>  This did not change the situation, because, despite the iterator, all user_id will be loaded into memory.  And all workers receive chains of tasks, and although workers will have a little rest, we were not satisfied with this decision as a result. <br><br>  We tried to set <strong>rate_limit</strong> to the workers, so that they process only a certain number of tasks per second, and find out that in fact the rate_limit specified as for the task is the rate_limit for the worker.  That is, if you specify rate_limit for a task, this does not mean that the task will be executed 70 times per second.  This means that the worker will perform it 70 times per second, and depending on what you have with the workers, this limit may change dynamically, i.e.  real limit rate_limit * len (workers). <br><br>  If the worker is started or stopped, then the total rate_limit changes.  Moreover, if your tasks are slow, then the entire prefetch in the queue that the worker fills in will be clogged with these slow tasks.  The worker looks: ‚ÄúOh, I have this task in rate_limit, I can‚Äôt do it anymore.  And all the following tasks in the queue are exactly the same - let them hang! ‚Äù- and waits. <br><br><h3>  Chunkificator <br></h3><br>  In the end, we decided that we would write our own, and made a small library, which we called Chunkificator. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task @chunkify_task(sleep_timeout=...l initial_chunk=...) def send_report_emails_to_users(chunk: Chunk): for user_id in User.get_active_ids(chunk=chunk): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  She takes sleep_timeout and initial_chunk, and calls herself with a new chunk.  Chunk is an abstraction either over integer lists, or over date or datetime lists.  We pass chunk to a function that gets users only with that chunk, and runs tasks for that chunk only. <br><br>  Thus, the task generator runs only the number of tasks that is needed, and does not consume a lot of memory.  The picture has become so. <br><img src="https://habrastorage.org/webt/yh/gg/h_/yhggh__vbzgiexxwskakp1nltrw.png"><br>  The highlight is the fact that we use sparse chunk, that is, we use instances in the database as a chunk id (some of them can be skipped, so there may be fewer tasks).  As a result, the load turned out to be more uniform, the process became longer, but everyone is alive and well, the base is not straining. <br><br>  <a href="https://github.com/Bahus/celery-chunkify-task">The library is</a> implemented for Python 3.6+ and is available on GitHub.  There is a nuance that I plan to fix, but for now, a pickle serializer is needed for a datetime chunk - many will not be able to do this. <br><br>  A couple of rhetorical questions - where did all this information come from?  How do we know that we had problems?  How to find out that the problem will soon become critical and it has to start to solve? <br><br>  The answer is, of course, monitoring. <br><br><h2>  Monitoring <br></h2><br>  I really like monitoring, I like to monitor everything and keep my finger on the pulse.  If you do not keep your finger on the pulse, then you will constantly step on the rake. <br><br>  Standard monitoring issues: <br><br><ul><li>  Does the current worker / concurrency configuration handle the load? </li><li>  What is the degradation of task execution time? </li><li>  How long do tasks hang in the queue?  Suddenly the line is already full? </li></ul><br>  We tried several options.  Celery has a <strong>CLI</strong> interface, it is rich enough and gives: <br><br><ul><li>  inspect - information about the system; </li><li>  control - manage system settings; </li><li>  purge - clear the queues (force majeure); </li><li>  events - console UI to display information about the tasks performed. </li></ul><br>  But it is difficult to really monitor something in it.  It is better suited for local delights, or if you want to change some rate_limit at runtime. <br><br>  <strong>NB: you</strong> need access to a production broker to use the CLI interface. <br><br>  <strong>Celery Flower</strong> allows you to do the same thing as the CLI, only through a web interface, and then not all.  But it builds some simple graphics and allows you to change settings on the fly. <br><br>  In general, Celery Flower is suitable in order to just see how everything works, in small setups.  In addition, it supports the HTTP API, that is, it is convenient if you are writing automation. <br><br>  But we <strong>stopped at Prometheus.</strong>  They took the current <a href="https://github.com/Bahus/celery-prometheus-exporter">exporter</a> : they fixed memory leaks in it;  added metrics for exception types;  added metrics for the number of messages in the queues;  integrated with alerts in Grafana and rejoice.  It is also posted on GitHub, you can see <a href="https://github.com/Bahus/celery-prometheus-exporter/">here</a> . <br><br><h4>  Examples in Grafana <br></h4><br><img src="https://habrastorage.org/webt/wa/i3/yt/wai3ytvm4ewoiumfrlvn2gzq9eg.png"><br>  The above statistics on all exceptions: what exceptions for which tasks.  Below is the time to complete tasks. <br><img src="https://habrastorage.org/webt/ae/l3/sf/ael3sfmjeve51s5jtui9fh_7ydq.png"><br><h2>  What is missing in Celery? <br></h2><br>  This is a spreading framework, it has a lot of things, but we are missing!  Not enough little features, such as: <br><br><ul><li>  <strong>Automatic code reloading during development</strong> - does not support this Celery - restart. </li><li>  <strong>Metrics for Prometheus</strong> out of the box, but Dramatiq knows how. </li><li>  <strong>Support</strong> <strong>task lock</strong> - so that only one task is executed at a time.  This can be done independently, but in Dramatiq and in Tasktiger there is a convenient decorator, which guarantees that all other tasks will be blocked. </li><li>  <strong>Rate_limit for one task</strong> - not for the worker. </li></ul><br><h2>  findings <br></h2><br>  Despite the fact that Celery is a framework that many people use in production, it consists of 3 libraries - Celery, Kombu and Billiard.  All these three libraries are being developed by the co-developers, and they can release one dependency and break your build. <br><img src="https://habrastorage.org/webt/dv/np/52/dvnp52xxgjcwsbdwr3c15a86-ac.png"><br>  Therefore, I hope that you have somehow figured out and made your assemblies deterministic. <br><br>  In fact, the findings are not so sad.  <strong>Celery copes with its tasks</strong> in our fintech project under our load.  We have gained experience that I shared with you, and you can apply our solutions or refine them and also overcome all of your difficulties. <br><br>  Do not forget that <strong>monitoring should be the main part of your project</strong> .  Only with the help of monitoring you will be able to find out where is something wrong with you that needs to be corrected, added, corrected. <br><br>  <strong>Contact speaker Oleg Churkin</strong> : <a href="https://habr.com/ru/users/bahusss/" class="user_link">Bahusss</a> , <a href="https://www.facebook.com/bahusoff">facebook</a> and <a href="https://github.com/Bahus/">github</a> . <br><br><blockquote>  The next big <a href="https://conf.python.ru/">Moscow Python Conf ++</a> will take place in Moscow <b>on April 5th</b> .  This year we are experimentally trying to fit all the benefits in one day.  There will be no less reports, we will allocate a whole stream to foreign developers of famous libraries and products.  In addition, Friday is an ideal day for after-party, which, as it is known, is an integral part of the conference about communication. <br><br>  Join our professional Python conference - submit a report <a href="https://conf.ontico.ru/lectures/propose%3Fconference%3Dmpc2019">here</a> , book a ticket <a href="http://conf.ontico.ru/conference/join/mpc2019.html">here</a> .  In the meantime, preparations are underway, articles on Moscow Python Conf ++ 2018 will appear here. <br></blockquote></div><p>Source: <a href="https://habr.com/ru/post/433476/">https://habr.com/ru/post/433476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../433464/index.html">Subcosmic race</a></li>
<li><a href="../433466/index.html">Compare pages. Simple plugin for Atlassian Confluence</a></li>
<li><a href="../433468/index.html">Fault Injection: your system is unreliable if you have not tried to break it</a></li>
<li><a href="../433472/index.html">Unity 2018.3 has been released</a></li>
<li><a href="../433474/index.html">Pylint from the inside. How he does it</a></li>
<li><a href="../433480/index.html">Holivarny story about the linter</a></li>
<li><a href="../433486/index.html">What's again? Reviving Non-Bank Debit Cards</a></li>
<li><a href="../433488/index.html">Christmas Scrum Meetup UPD Broadcast Mitap</a></li>
<li><a href="../433490/index.html">Creality CR-X 3D Printer Review</a></li>
<li><a href="../433494/index.html">10 English idioms, the value of which you will never guess</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>