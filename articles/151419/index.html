<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Elastic MapReduce. Distributed implementation</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="It so happened that the first film I watched with the mention of the word "supercomputer" was Terminator. But, oddly enough, my (then) unformed psyche...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Elastic MapReduce. Distributed implementation</h1><div class="post__text post__text-html js-mediator-article">  <em>It so happened that the first film I watched with the mention of the word "supercomputer" was Terminator.</em>  <em>But, oddly enough, my (then) unformed psyche did not consider SkyNet a world evil, writing off the aggressive behavior of the world's first AI to insufficient coverage of the unit with tests.</em> <br><br>  At that time I had a ZX Spectrum (whose 128 Kb was clearly not enough to launch something similar to AI) and a lot of (I think 10 years) free time.  Thanks to the latter fact, I happily waited for the era of virtualization.  It was possible to remove at least 10K VPS, establish a communication channel between them and begin to create AI.  But I wanted to do programming, not administration / configuration of the grid system, and I reasonably began to wait for computing resources to be provided as a service. <br><br>  There was no end to my joy when cloud services appeared.  But the joy did not last long: it became clear that so far direct communications between separate computing instances are <strike>fiction</strike> code that you need to write yourself (that is, with high probability it will not work).  Having reared for a couple of years about this, I (we all) waited for Hadoop, first the ‚Äú <em>on-premises</em> ‚Äù, and then the elastic ‚Äú <em>on-demand</em> ‚Äù.  But even there, as it turned out, not everything is so <strike>elastic</strike> smoothly. <a name="habracut"></a>  as we would like.  But this is a completely different story ... about which, having slightly changed the comic tone of the narration, I am going to tell you. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Distributed introduction to Hadoop elastic problems </h2><br>  The symbiosis of cloud technologies and the Apache Hadoop platform for several years now has been viewed as a source of interesting solutions related to Big Data analysis. <br><br>  And the main point, why ‚Äúsymbiosis‚Äù, and not ‚Äúpure‚Äù Hadoop, is, of course, a decrease in the level of input for developers of MPP applications (and not only) both in terms of qualifications (administrator) and initial financial investments in hardware the part on which the application will be executed. <br><br>  The second point is that cloud providers will be able to circumvent some of the limitations of Hadoop * imposed by the <em>master / slave</em> architecture (the master is always a single point of failure and something needs to be done with this) and, perhaps (at Microsoft, due to the parallel developing project Dryad , there was particular hope), even a strong coupling of data storage ( <em>HDFS</em> ) and components of distributed computing ( <em>Hadoop MapReduce</em> ). <br><br>  The hopes related to the first item - reducing the cost of ownership of the Hadoop cluster - came true more than: the largest triple cloud providers, with varying degrees of proximity to the release-mode, began to provide " <em>Hadoop cluster as a Service</em> " (my terminology and conditional) for prices , quite "lifting" for startups and / or research groups. <br><br>  Hopes, connected with circumvention of the <a href="http://www.codeinstinct.pro/2012/08/hadoop-design.html">limitations of the Hadoop platform</a> , did not come true at all. <br><br>  Amazon Web Services, like the IaaS platform, has never sought to provide services as a service (although there is an exception - Amazon S3, Amazon DynamoDB).  And back in 2009, Amazon provided developers with <a href="http://aws.amazon.com/elasticmapreduce/">Amazon Elastic MapReduce</a> as an infrastructure, not as a service. <br><br>  Following Amazon in mid-2010, Google announced an experimental version of the <a href="https://developers.google.com/appengine/docs/python/dataprocessing/">App Engine</a> API <a href="https://developers.google.com/appengine/docs/python/dataprocessing/">MapReduce</a> , as part of its Google App Engine cloud platform. <br><br>  The App Engine MapReduce API provides developers with ‚ÄúHadoop MapReduce‚Äù -like interfaces to their services that are already working on the map / reduce paradigm.  But this did not remove the limitations of the strong connectivity of the data warehouse and the components of the calculations.  Moreover, Google itself added restrictions there ‚Äî the possibilities of redefining only the map-phases **, and the GAE platform itself, with its characteristic quotas, imposed (as I suspect) a couple more restrictions on the App Engine MapReduce API. <br><br>  In 2011, the turn came to Microsoft.  In October 2011, Microsoft announced the opening of the <a href="https://www.hadooponazure.com/">Hadoop on Azure service</a> .  Currently it is in the CTP version.  I did not manage to try this service due to the lack of an invitation (and the presence of laziness).  But, in the absence of articles about the overcome limitations of Hadoop, it is clear that the ‚Äúproblems‚Äù of the Hadoop platform in this case were left to be solved by Hadoop itself. <br><br>  The above limitations of solutions based on "cloud platforms + Hadoop" allow us to understand the range of problems solved by the project <a href="http://code.google.com/p/cloudmapreduce/">Cloud MapReduce</a> , which will be discussed in the rest of the article. <br><br><h2>  1. Cloud MapReduce.  Basic concepts </h2><br>  <strong>Cloud MapReduce</strong> (CMR) is an open source project that implements the map / reduce software paradigm based on (on top) Amazon Web Services cloud services. <br><br>  CMR is based on the concept of a cloud operating system.  If we draw an analogy with traditional OS, then in cloud OS: <br><ul><li>  <em>computing resources</em> are not represented by a CPU, but by Amazon EC2 / Windows Azure Workers / Google Compute Engine instances; <br></li><li>  <em>data storage</em> is not represented by a hard disk (SD, flash drives, etc.), but by Amazon S3 / Windows Azure Blob / Google Cloud Storage services; <br></li><li>  <em>The state store</em> (which is not lost after the OS reload) is not represented by the registry (or local structure with a similar function), but by Amazon SimpleDB / Windows Azure Table / Google BigQuery services; <br></li><li>  <em>The interprocess communication mechanism is</em> implemented using Amazon SQS / Windows Azure Queue / Google App Engine Task Queue API services. <br></li></ul><br>  Having laid the principles of cloud OS in the Cloud MapReduce architecture, the developers got me an impressive result.  In their blog, they cite the following facts from comparing their platform with the Hadoop platform: <br><ul><li>  no single point of failure; <br></li><li>  no need to copy data from storage services (such as Amazon S3) to HDFS before running the MapReduce job; <br></li><li>  acceleration in some cases more than 60 times; <br></li><li>  the project takes only 3000 lines of Java code, while Hadoop is ‚Äúlocated‚Äù as much as 280K of code. <br></li></ul><br>  In addition, Cloud MapReduce, unlike Apache Hadoop, is not designed on the basis of a master / slave architecture.  In addition to the obvious advantages of peer-like architectures (the absence of single point of failure), the developers of CMR lead to the advantages of their implementation of MapReduce, which is simpler than configuration in Hadoop, configuration, redundancy, recovery after failures. <br><br>  The merits of CMR also imply incremental scalability: when adding new computational instances to the cluster, they are "hot" connected to the execution of the map / reduce-task.  Also, CMR does not require (recommends) to have a homogeneous cluster (that is, from machines with the same computing power).  In a cluster of heterogeneous machines, the fastest machine will perform a larger number of tasks than a slower machine. <br><br>  I‚Äôll add that incremental scalability really lacked the Hadoop platform.  But the absence of a requirement (recommendation) for cluster homogeneity is hardly relevant for cloud environments. <br><br><h2>  2. Cloud MapReduce.  Architecture </h2><br>  Cloud MapReduce architecture is divided into the following logical layers: <br><ul><li>  <em>Storage Layer</em> </li><li>  layer processing and computing ( <em>Computing Layer</em> ); </li><li>  <em>Messaging</em> layer. </li></ul><br>  The relationships of these layers, the information flows and the services by which it is represented in AWS are shown in the figure below. <br><img src="https://habrastorage.org/storage2/799/29e/677/79929e6776342a209632daeed9825bc5.png" alt="Cloud MapReduce Design"><br>  Below we analyze in more detail the function of each of the above layers. <br><br><h3>  2.1.  Interaction between nodes </h3><br>  The interaction between the Map Workers and Reduce Workers nodes is based on queues.  Queues in Cloud MapReduce are represented by Amazon SQS. <br><br>  The CMR has the following types of queues: <br><ul><li>  <em>Input / Map Queue</em> - a queue of map tasks; <br></li><li>  <em>Multiple Reduce Queue</em> - queues of intermediate results of map functions; <br></li><li>  <em>Master Reduce Queue</em> - queue of reduce-tasks; <br></li><li>  <em>Output Queue</em> - the output queue. <br></li></ul><br>  Messages in Amazon SQS / Azure Queue queues have an ‚Äúinvisibility timeout‚Äù mechanism.  The logic of the mechanism is as follows: the message is taken from the queue, after which the message becomes invisible in the queue for a while.  Upon successful processing of the message, the last of the queue is deleted, otherwise, after the invisibility timeout expires, the message reappears in the queue. <br><br>  Thanks to the ‚Äúinvisibility timeout‚Äù mechanism provided by the queue services, a very simple support for the processing of Map and Reduce Worker failures is realized and the overall fault tolerance of the cluster is increased. <br><br><h3>  2.2.  Data storage </h3><br>  The data store stores the application's input data and is represented by the Amazon S3 service. <br><br>  Amazon S3 also introduces a cleaner abstraction of the storage layer, because access is provided to data as resources (which are typical of REST services), and not as files (which is typical of file systems).  It should be noted that the approach of storing data in the cloud storage has a downside - less manageability. <br><br>  Amazon S3 stores data analyzed at the map stage.  The Input Queue contains a pair of &lt;k, v&gt;, where k, in general, is the identifier of the map job, and v is the link file in S3 and optionally a pointer to the part inside the file. <br><br>  This approach removes the inconvenience / problem (for whom how) with copying data from Amazon S3 to HDFS at the first stage of launching a MapReduce task in Amazon Elastic MapReduce. <br><br>  The developer also mentioned that the output is also possible to save directly to Amazon S3: <br><blockquote>  We store our input and output data in S3 </blockquote><br>  It follows from the documentation that all the results of the reduce stage are stored in the Reduce Queue as pairs &lt;k ', v'&gt;. <br><br><h3>  2.3.  Compute nodes </h3><br>  User-defined map and reduce tasks are executed on compute nodes.  Compute Nodes are represented by EC2 instances and are divided into 2 types: <em>Map Workers</em> and <em>Reduce Workers</em> .  Map Workers executes map functions on the Map Workers, and reduce functions on the Reduce Workers. <br><br>  On the same EC2 Instance, the Map Worker and the Reduce Worker can consistently play the role. <br><img src="https://habrastorage.org/storage2/5f4/2f9/456/5f42f9456eaed47875210cf75bd442b1.png" alt="Cloud MapReduce Workflow"><br>  The workflows of map and reduce operations are listed below. <br><br>  <em>Mapper workflow:</em> <br><ol><li>  Getting data queuing from map queue for map tasks; <br></li><li>  Extract data from Amazon S3; <br></li><li>  Execution of a user-defined map function; <br></li><li>  Adding the result of executing &lt;k ', v'&gt; to some queue, determined on the basis of the hash k '(if it is not overridden), from among multiple queues Multiple Reduce Queues; <br></li><li>  Remove map job from Map Queue. <br></li></ol><br>  <em>Reducer workflow:</em> <br><ol><li>  Receives from the Master Reduce Queue a reference to the Reduce Queue to which the convolution function should be applied; <br></li><li>  Extracts &lt;k ', v'&gt; - pairs from the corresponding queue of multiple queues Multiple Reduce Queues; <br></li><li>  Performs a user-defined reduce-function and adds output &lt;k '', v ''&gt; pairs to the Output Queue; <br></li><li>  Removes a reduce job from the Master Reduce Queue. <br></li></ol><br><h3>  2.4.  Customer </h3><br>  <em>The client</em> ( <em>Job Client</em> ) is a software client that manages the execution of map / reduce tasks. <br><br>  The client from the CMR documentation is least clear.  But, considering what we know about the Map workflow and reduce Workers and the principles of building such systems, let me make a couple of near-scientific assumptions about the Job Client workflow. <br><br>  The work client job flow is divided into the following stages: <br><ol><li>  Saving input data in Amazon S3; <br></li><li>  Creating a map task for each data split and adding the created task to the Map Queue; <br></li><li>  Creating multiple queues Multiple Reduce Queues; <br></li><li>  Creating the Master Reduce Queue and adding the created reduce queue for each Partition Queue; <br></li><li>  Creating an Output Queue; <br></li><li>  Creating a Job Request and adding the created request to SimpleDB; <br></li><li>  Run EC2 instances for Map Workers and Reduce Workers; <br></li><li>  Poll Map Workers and Reduce Workers to get job execution status; <br></li><li>  When all tasks are completed, load the results from the Output Queue. <br></li></ol><br><h3>  2.5.  Auxiliary operations </h3><br>  The operations of saving / updating the status of execution of map- / reduce-tasks are implemented on the basis of non-relational databases.  AWS nonrelational databases are represented by Amazon SimpleDB (since 2007) and Amazon DynamoDB (since 2012). <br>  Since  the CMR architecture assumes that all nodes in a computing cluster are equivalent, then the center of node coordination is Amazon SimpleDB, which provides distributed non-relational data storage. <br><br><h2>  Conclusion and footnotes </h2><br>  I do not urge to switch to Cloud MapReduce neither today nor tomorrow ***, just as I don‚Äôt intend, when I read a book on Haskell, to become a programmer on this undoubtedly excellent PL. <br><br>  Cloud MapReduce has flaws that make business risks from its use essential (small team, rare updates, lack of an ecosystem like that of Hadoop), and prospects are hazy.  But the ideas drawn from the <s>functional programming</s> of the Cloud MapReduce project architecture make it even more distributed to look at the already established Hadoop-oriented presentation among IT professionals in Data Intensive Computing. <br><br>  * I now do not take into account the alpha-version of Apache Hadoop 2.0, which is ‚Äúdeprived‚Äù (more precisely, to the release-version ‚Äúis going to be deprived‚Äù) of the described architectural constraints. <br>  ** I remember (or maybe I dreamed?) That at the Google I / O 2011 conference, besides mitigating the existing limits of the App Engine platform, Mike Aizatsky (I won‚Äôt even distort it) said that Google engineers are working to provide redefinition and other steps of the map algorithm / reduce in App Engine MapReduce API. <br>  *** Just as I do not call for the opposite. </div><p>Source: <a href="https://habr.com/ru/post/151419/">https://habr.com/ru/post/151419/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../151410/index.html">New Mail.Ru Agent for Mac OS X released</a></li>
<li><a href="../151414/index.html">Skype switches to new Opus codec</a></li>
<li><a href="../151416/index.html">Top 10 Mac OS X Top Tips</a></li>
<li><a href="../151417/index.html">Too much information</a></li>
<li><a href="../151418/index.html">MySQL Query Killer - DBMS Overload Fuse</a></li>
<li><a href="../151420/index.html">Simple way to protect from classic HTTP DDoS</a></li>
<li><a href="../151421/index.html">Compressed Prefix Trees</a></li>
<li><a href="../151422/index.html">Fujifilm stops film production</a></li>
<li><a href="../151423/index.html">Eviterra.com - smart booking form and pleasant things.</a></li>
<li><a href="../151424/index.html">Hybrid "solar" system for producing hydrogen for fuel cells</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>