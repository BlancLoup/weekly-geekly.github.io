<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Big Data - the first experience of ED IB</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! Today we want to tell about our acquaintance with Big Data, which began in 2012, when the market had not yet covered the wave of popularity of ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Big Data - the first experience of ED IB</h1><div class="post__text post__text-html js-mediator-article">  Hello!  Today we want to tell about our acquaintance with Big Data, which began in 2012, when the market had not yet covered the wave of popularity of the topic of big data. <br><br> <a href="http://habrahabr.ru/company/at_consulting/blog/265345/"><img src="https://habrastorage.org/files/809/973/92b/80997392bd5a4e1583016ce1eaccfe39.png"></a> <br><br>  By that time, we already had expertise in the field of building data warehouses.  We considered various ways to improve the standard HD architectures, because the customer wanted to process large amounts of data in a short time and with limited budget.  We understood that large amounts of data for standard storage are perfectly processed on MPP platforms, but de facto it is expensive.  So, we need an inexpensive distributed system.  She turned out to be Hadoop.  It needs minimal initial investment, and first results can be obtained very quickly.  In the longer term, horizontal, almost linear scaling, an open platform and many interesting additional functions: for example, NoSQL, fast data search, a sort of SQL data access language. <br><a name="habracut"></a><br>  The test task was to study data enrichment on Hadoop: we measured how long standard data join-s were working.  For example, the intersection of 100 GB and 10 GB by the standards of relational databases is serious volumes (it is unreasonable to use indexes with full scan).  On our test servers, such tasks were completed in minutes against tens of minutes in relational storage.  Taking into account the money spent on the relational storage and the cost of the mid-range array for HD (exceeds the cost of the local array by an order of magnitude on average), the choice for carrying out such calculations and data storage means was obvious. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      To test the approach to solving the problem, we needed: <br><br><ul><li>  Hadoop development competencies <br></li><li>  test cluster <br></li></ul><br>  We did a pilot project on the Hadoop stack, based on the books we read: " <a href="http://shop.oreilly.com/product/0636920021773.do">Hadoop: The Definitive Guide</a> " and " <a href="http://shop.oreilly.com/product/0636920025122.do">MapReduce Design Patterns</a> ".  Our team already had Java expertise, and the transition to the MapReduce paradigm did not become a problem even for those who came from the Oracle Database.  Then to start it was enough to read and learn a couple of books. <br><br>  To speed up testing, we used Amazon EC2's cloud services, which allowed us to get the hardware without delay and start installing the Hadoop stack from Cloudera.  In two days the stand was ready.  We used 10 instances with 8 GB of RAM and 2 CPUs as hardware.  50 GB disks on each machine, taking into account the triple data replication (by default), was enough with a margin to solve the pilot problem.  10 instances were obtained experimentally, because  while reducing instances, performance dropped dramatically.  Now, with the development of assemblies from vendors, the cluster is put "in a couple of clicks." <br><br>  However, join is not the main vocation of Hadoop.  His strength is in analytic ability.  Well aware of this, we got the first real case.  The pilot task was to track subscribers visiting the departure area at Moscow airports and send them a relevant mobile phone offer.  From the input data were only subscriber traffic and a list of towers that serve the departure zone at the airport.  But this is not Big Data. <br><br>  Big Data appears at the moment of the second requirement for the task: to identify and exclude from the final sample all the mourners, greeters, taxi drivers, shop workers, etc.  The range of cell towers is not limited to the conditional boundaries of the departure zone, therefore all nearby subscribers can get here, including outside the airport building. <br><br>  Everything is great, only Amazon cluster cannot be used for this - because we are dealing with personal data of the cellular operator.  It became obvious that the implementation of Big Data is a matter of time, and the customer decided to buy the first cluster.  The cluster sizing was calculated for the year ahead taking into account the Big Data development strategy and purchased 20 HP 380 G8 machines (2 CPU / 48 G RAM / 12x3 Tb disk). <br><br>  Six months after the start of work with Big Data, we had a team of up to 5 employees, and by the end of 2013 we already had 14 people.  We had to thoroughly understand everything that relates to the Hadoop stack.  Our employees have completed certified courses from Cloudera: cluster management training, development on MapReduce, HBase.  This background allowed us to quickly understand all the subtleties of Hadoop, get an idea of ‚Äã‚Äãthe best development techniques for MapReduce and get down to business.  By the way, now there are a lot of good online courses (for example, on Coursera). <br><br>  The implementation of the first business task implied a permanent job as a trigger: look for the necessary records with the necessary parameters of base stations from the incoming data stream.  In Hadoop, subscriber profiles were considered on a daily basis: manually first, and then using machine learning.  Subscriber profile data was overloaded into the Redis in-memory key / value storage.  The incoming data stream was processed using Apache Storm.  At this stage, the subscriber profile, cell tower and its sector of interest to us were taken into account.  Further, this stream was processed through the subscribers contact policy (for example, so that the subscriber did not receive SMS more than the number of times assigned) and entered the SMS transmission queue. <br><br>  For the sake of experiment, we tried to solve the problem only with MapReduce tools, but it turned out badly: high load on the cluster, long initialization of the Java-machine each time.  Do not do this. <br><br>  Now the customer company has its own industrial cluster, and we test technologies on virtual machines and evaluate the possibilities of using them on real tasks. <br><br>  That somehow our acquaintance and tied. <br><br>  Oh yeah - my name is Aleksey Bednov and I am ready to answer your questions in the comments. </div><p>Source: <a href="https://habr.com/ru/post/265465/">https://habr.com/ru/post/265465/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../265463/index.html">"I came to eat, and stayed to study at the Technopark." Student stories from our educational projects</a></li>
<li><a href="../265469/index.html">Publication of iFrame / HTML5 games on VKontakte. The basics</a></li>
<li><a href="../265471/index.html">Intel Parallel Studio XE 2016 - more free products</a></li>
<li><a href="../265473/index.html">A bit about the underground data center Netflix</a></li>
<li><a href="../265475/index.html">Russian server market: real ways to save</a></li>
<li><a href="../265477/index.html">Tab module on es6 / es2015 without jQuery and other dependencies</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>