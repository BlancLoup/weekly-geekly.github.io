<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Architecture and technological approaches to processing BigData on the example of "1C-Bitrix BigData: Personalization"</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In September of this year, a conference devoted to big data, BigData Conference , was held in Kiev. According to the old tradition, we publish in our ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Architecture and technological approaches to processing BigData on the example of "1C-Bitrix BigData: Personalization"</h1><div class="post__text post__text-html js-mediator-article">  <i>In September of this year, a conference devoted to big data, <a href="http://bigdataconf.com.ua/2015/">BigData Conference</a> , was held in Kiev.</i>  <i>According to the old tradition, we publish in our blog some of the materials presented at the conference.</i>  <i>And we begin with the report of <a href="http://bigdataconf.com.ua/2015/agenda/3124/">Alexander Demidov</a> .</i> <br><br>  Now many online stores have realized that one of the main tasks for them is to increase their own efficiency.  Take two stores, each of which attracted 10 thousand visitors, but one made 100 sales, and the other 200. It seems that the audience is the same, but the second store works twice as efficiently. <br><br>  The topic of data processing, processing models of visitors to stores is relevant and important.  How do traditional models work in which all connections are established manually?  We make up the correspondence of the goods in the catalog, make up bundles with accessories, and so on.  But, as an ordinary joke says: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/80b/17a/5db/80b17a5db445468a965a96ee139a33a7.jpg"><br><a name="habracut"></a><br>  It is impossible to foresee such a connection and sell something completely unrelated to the buyer to the buyer.  But the next woman, who is looking for a green coat, we can recommend the very red bag on the basis of a similar pattern of behavior of the previous visitor. <br><br>  Such an approach very vividly illustrates the case associated with the Target retail chain.  One day an angry visitor came to them and called the manager.  It turned out that the online store in its mailing list of the minor daughter of this very visitor sent an offer for pregnant women.  The father was extremely indignant at this fact: ‚ÄúWhat are you doing?  Is she a minor, how pregnant is she? ‚Äù  He quarreled and left.  After a couple of weeks, it turned out that the girl was actually pregnant.  Moreover, the online store found out about this before her on the basis of an analysis of her preferences: the products she ordered were compared with the models of other visitors who acted roughly according to the same scenarios. <br><br>  The result of the work of analytical algorithms for many looks like magic.  Naturally, many projects want to implement such analytics.  But there are few players on the market with a large enough audience so that you can really count and predict something.  These are mainly search engines, social networks, large portals and online stores. <br><br><h3>  Our first steps in using big data </h3><br>  When we thought about introducing the analysis of big data into our products, we asked ourselves three key questions: <br><br><ul><li>  Do we have enough data? </li><li>  How will we process them?  We do not have mathematicians in our staff, we do not have sufficient competence in working with ‚Äúbig data‚Äù. </li><li>  How to integrate all this into existing products? </li></ul><br>  There are very few large online stores with millions of audiences, including on our platform.  However, the total number of stores using ‚Äú1C-Bitrix: Site Management‚Äù is very large, and all together they cover an impressive audience in various segments of the market. <br><br>  As a result, we organized an internal startup within the project.  Since we did not know which end to take, we decided to start by solving a small problem: how to collect and store data.  This small prototype was drawn in 30-40 minutes: <br><br><img src="https://habrastorage.org/files/ce4/5e8/140/ce45e8140e614c1a9673faebecf2ae72.jpg"><br><br>  There is a term MVP - minimum viable product, a product with minimal functionality.  We decided to start collecting technical metrics, page loading speed from visitors, and provide users with analytics on the speed of their project.  This had nothing to do with personalization or BigData, but it did allow us to learn how to handle the entire audience of all visitors. <br><br>  In JavaScript, there is a tool called the Navigation Timing API, which allows you to collect data on page speed, DNS resolve, network transfer, Backend work, page rendering on the client side.  All this can be broken down into various metrics and then issued to the analyst. <br><br><img src="https://habrastorage.org/files/659/20f/b59/65920fb59a0c4a70876b54dca65535ec.jpg"><br><br>  We figured out how much approximately the stores are working on our platform, how much data we need to collect.  There are potentially tens of thousands of sites, tens of millions of hits per day, 1000-1500 requests for recording data per second.  There is a lot of information, where to save it in order to work with it later?  And how to ensure for the user the maximum speed of the analytical service?  That is, our JS counter is not only obliged to respond very quickly, but it should not slow down the page loading speed. <br><br><h3>  Data recording and storage </h3><br>  Our products are mainly built on PHP and MySQL.  The first desire was to simply save all the statistics in MySQL or in any other relational database.  But even without tests and experiments, we realized that this is a dead end option.  At some point, we simply do not have enough performance either when writing or when retrieving data.  And any failure on the side of this base will lead to the fact that either the service will work extremely slowly, or it will be out of order at all. <br><br><img src="https://habrastorage.org/files/793/bb0/0b6/793bb00b662c497cb174785b163b3f41.jpg"><br><br>  Considered different NoSQL solutions.  Since we have a large infrastructure deployed in Amazon, we first paid attention to DynamoDB.  This product has a number of advantages and disadvantages compared to relational databases.  When recording and scaling, DynamoDB works better and faster, but it will be much more difficult to make some complex samples.  There are also issues with data consistency.  Yes, it is provided, but when you need to constantly select some data, it‚Äôs not a fact that you always select the actual ones. <br><br>  As a result, we began to use DynamoDB for aggregation and subsequent release of information to users, but not as a repository for raw data. <br><br>  We considered column databases that work no longer with strings, but with columns.  But due to poor performance, the recording had to be rejected. <br><br><img src="https://habrastorage.org/files/b5b/da4/f3f/b5bda4f3f117478e8450890abf320874.jpg"><br><br>  Choosing an appropriate solution, we discussed a variety of approaches, starting with writing a text log :) and ending with the services of the ZeroMQ, Rabbit MQ, etc. queues.  However, in the end, they chose a completely different option. <br><br><h3>  Kinesis </h3><br>  Coincidentally, by that time, Amazon had developed the Kinesis service, which was perfectly suited for the primary data collection.  It is a kind of large high-performance buffer, where you can write anything.  He very quickly receives the data and reports on the successful recording.  Then you can quietly work with information in the background: make selections, filter, aggregate, etc. <br><br>  Judging from the data provided by Amazon, Kinesis should have been able to easily handle our workload.  But a number of questions remained.  For example, the end user - the site visitor - could not write data directly to Kinesis;  To work with the service, you need to "sign" requests using a relatively complex authorization mechanism in Amazon Web Services v.  4. Therefore, it was necessary to decide how to make Frontend send data to Kinesis. <br><br>  Considered the following options: <br><br><ul><li>  Write a configuration on pure nginx that will be proxied to Kinesis.  It did not work, the logic is too complicated. </li><li>  Nginx in the form of Frontend + PHP-Backend.  It turned out difficult and expensive in terms of resources, because with so many requests, any Backend will sooner or later fail to cope, it will have to be horizontally scaled.  And we still do not know whether the project will take off. </li><li>  Nginx + its own module in C / C ++.  Long and difficult in terms of development. </li><li> Nginx + ngx_http_perl_module.  Option with the module blocking requests.  That is, the request that came in this thread blocks the processing of other requests.  Here are the same drawbacks as with the use of any Backend.  In addition, the documentation for nginx explicitly stated: "The module is experimental, so anything is possible." </li><li>  Nginx + ngx_lua.  At that time, we had not yet encountered Lua, but this module seemed curious.  The piece of code you need is written directly to the nginx config in a language that is somewhat similar to JavaScript, or placed in a separate file.  Thus you can implement the strangest, extraordinary logic that you need. </li></ul><br>  As a result, we decided to bet on Lua. <br><br><h3>  Lua </h3><br>  The language is very flexible, it allows processing both the request and the response.  It can be embedded in all phases of request processing in nginx at the level of rewriting, logging.  It is possible to write any subqueries, and non-blocking, with the help of some methods.  There is a bunch of additional modules for working with MySQL, with cryptographic libraries, and so on. <br><br>  For two or three days we studied the functions of Lua, found the necessary libraries and wrote a prototype. <br><br>  On the first load test, of course ... everything fell.  I had to configure Linux for heavy loads - to optimize the network stack.  This procedure is described in many documents, but for some reason it is not done by default.  The main problem was the lack of ports for outgoing connections to Kinesis. <br><br><pre><code class="bash hljs">/etc/sysctl.conf (man sysctl) <span class="hljs-comment"><span class="hljs-comment">#     net.ipv4.ip_local_port_range=1024 65535 #   TIME_WAIT  net.ipv4.tcp_tw_reuse=1 #     FIN_WAIT_2 net.ipv4.tcp_fin_timeout=15 #    net.netfilter.nf_conntrack_max=1048576 #       net.core.netdev_max_backlog=50000 #      net.core.somaxconn=81920 #   syncookies  SYN  net.ipv4.tcp_syncookies=0</span></span></code> </pre> <br><br>  We expanded the range, set up timeouts.  If you use a built-in firewall, such as Iptables, then you need to increase the size of the tables for it, otherwise they will overflow with very many requests.  At the same time it is necessary to adjust the size of any backlog for the network interface and for the TCP stack in the system itself. <br><br>  After that, everything worked successfully.  The system began to properly process 1000 requests per second, and for this we had one virtual machine. <br><br><img src="https://habrastorage.org/files/77c/0f6/5ba/77c0f65ba74c4e309620bcb050c86e19.jpg"><br><br>  At some point, we still rested against the ceiling and began to receive errors ‚Äú <code>connect() to [...] failed (99: Cannot assign requested address) while connecting to upstream</code> ‚Äù, although the resources of the system have not yet been exhausted.  According to LA, the load was close to zero, there is enough memory, the processor is far from overload, but it rested on something. <br><br><img src="https://habrastorage.org/files/e5b/938/c32/e5b938c329db4d93ad8b612109c2bb6b.jpg"><br><br>  It was possible to solve the problem by setting up keepalive connections in nginx. <br><br><pre> <code class="html hljs xml">upstream kinesis { server kinesis.eu-west-1.amazonaws.com:443; keepalive 1024; } proxy_pass https://kinesis/; proxy_http_version 1.1; proxy_set_header Connection "";</code> </pre><br><br>  A machine with two virtual cores and four gigabytes of memory easily processes 1000 requests per second.  If we need more, then either we add resources to this machine, or we scale it horizontally and place 2, 3, 5 such machines behind any balancer.  The solution is simple and cheap.  But the main thing is that we can collect and save any data in any quantity. <br><br><img src="https://habrastorage.org/files/c3a/90f/40c/c3a90f40c21c4c678ac3ec86635a416d.jpg"><br><br>  It took about a week to create a prototype collecting up to 70 million hits per day.  Ready service "Speed ‚Äã‚Äãsites" for all customers "1C-Bitrix: Site Management" was created in one month by the efforts of three people.  The system does not affect the speed of display sites, has internal administration.  The cost of Kinesis services is $ 250 per month.  If we did everything on our own hardware, wrote our entire solution on any storage, it would have been much more expensive in terms of maintenance and administration.  And much less reliable. <br><br><img src="https://habrastorage.org/files/902/faa/f1c/902faaf1c1cf4e7488d165f051c24b63.jpg"><br><br><img src="https://habrastorage.org/files/13a/d47/682/13ad4768257a487fa327de72f3ccdbcc.jpg"><br><br><h3>  Recommendations and personalizations </h3><br>  The general scheme of the system can be represented as follows: <br><br><img src="https://habrastorage.org/files/bfa/562/75a/bfa56275a1964ade8a71d1b92f9508ba.jpg"><br><br>  It should register events, save, perform some processing and give something to clients. <br><br>  We created a prototype, now we need to move from technical metrics to the assessment of business processes.  In fact, we do not care what we collect.  You can send anything: <br><br><ul><li>  Cookies </li><li>  Hash license </li><li>  Domain </li><li>  Category, ID and product name </li><li>  ID recommendations </li></ul><br>  and so on. <br><br>  Hits can be categorized by event type.  What we are interested in from the point of view of the store? <br><br><img src="https://habrastorage.org/files/e51/f56/a31/e51f56a310cc4124a81bdfb57525de94.jpg"><br><br>  We can collect and link all technical metrics to business metrics and subsequent analytics that we need.  But what to do with this data, how to process them? <br><br>  A few words about how the recommendation systems work. <br><br>  The key mechanism that allows visitors to recommend some products is the collaborative filtering mechanism.  There are several algorithms.  The simplest is user-user matching.  We compare the profiles of two users, and based on the actions of the first of them, we can predict for another user who performs similar actions, that the next moment he will need the same product that the first user ordered.  This is the most simple and logical model.  But she has some cons. <br><br><img src="https://habrastorage.org/files/871/e78/4ff/871e784ffeda4a63b57acacd5b38ee29.jpg"><br><br><ul><li>  First, there are very few users with the same profiles. </li><li>  Secondly, the model is not very stable.  Users look at a variety of products, the matrix of conformity is constantly changing. </li><li>  If we cover the entire audience of our online stores, then there are tens of millions of visitors.  And in order to find matches for all users, we need to multiply this matrix by itself.  And the multiplication of such millions of matrices is a nontrivial task from the point of view of the algorithms and tools that we will use. </li></ul><br>  Amazon has invented another algorithm for its online store - item-item: matches are established not by users, but by specific products, including those that are bought along with the ‚Äúmain‚Äù ones.  This is most relevant to increase sales of accessories: a person who has bought a phone can be recommended a case, charging, or something else.  This model is much more stable, because goods conformity rarely changes.  The algorithm itself is much faster. <br><br>  There is one more approach - content based-recommendations.  Sections and products that the user was interested in and his search queries are analyzed, after which the user‚Äôs vector is drawn up.  And as prompts are those products whose vectors are closest to the vector of the user. <br><br><img src="https://habrastorage.org/files/66a/260/dbb/66a260dbbbd14bc986109199b5912612.jpg"><br><br>  You can not choose any one algorithm, and use them all, combining with each other.  What are the tools for this: <br><br><ul><li>  ‚Ä¢ MapReduce.  If you fully understand it, the use will not cause difficulties.  But if you ‚Äúfloat‚Äù in theory, the difficulties are guaranteed. <br><br><img src="https://habrastorage.org/files/948/d3d/620/948d3d62009d4a638f98b3b3e94fa34a.jpg"><br><br><img src="https://habrastorage.org/files/3af/6c8/1eb/3af6c81ebd844686b78b9df6d995e2f6.jpg"></li><li>  ‚Ä¢ Spark.  It works much faster than traditional MapReduce, because it stores all structures in memory and can reuse them.  It is also much more flexible, it is more convenient to do complex samples and aggregations. <br><br><img src="https://habrastorage.org/files/43c/d61/df0/43cd61df08814c7c96b094e8fb4dde1d.jpg"><br><br>  If you are programming in Java, then working with Spark will not cause much difficulty.  It uses relational algebra, distributed collections, processing chains. </li></ul><br>  In our project we made a choice in favor of Spark. <br><br><h3>  The architecture of our project </h3><br><img src="https://habrastorage.org/files/e13/e9b/18e/e13e9b18ecd04851816f62f4f6120224.jpg"><br><br>  We read data from Kinesis using simple PHP workers written in PHP.  Why PHP?  Just because it is familiar to us, and so it is more convenient for us.  Although Amazon has an SDK to work with their services for almost all popular languages.  Then we do the primary filtering of hits: we remove the numerous hits of search bots, etc.  Next, send the statistics, which we can immediately give online, to Dynamo DB. <br><br><img src="https://habrastorage.org/files/b98/c0e/498/b98c0e498de3475b9561856771bbf5a5.jpg"><br><br>  The main data array for further processing, for building models in Spark, etc.  we save to S3 (instead of traditional HDFS, we use Amazon‚Äôs storage).  Subsequent math, algorithms for collaborative filtering and machine learning is handled by our cluster of recommendations, built on the basis of Apache Mahout. <br><br><img src="https://habrastorage.org/files/185/9ac/926/1859ac926a6e481b8d0d769dc9039ea2.jpg"><br><br><ul><li>  For data processing, we use Apache Hadoop / MapReduce, Apache Spark, Dynamo DB (NoSQL). </li><li>  Apache Mahout is used for mathematical calculations, and large-scale processing of matrix multiplication is done using the MapReduce paradigm. </li><li>  Data is processed on dynamic computing clusters in the Amazon cloud. </li><li>  Storage is performed in an object Amazon S3 and partially in NoSQL DynamoDB. </li></ul><br>  Using cloud infrastructure and off-the-shelf Amazon AWS services saves us a lot of effort, resources, and time.  We do not need a large staff of administrators to maintain this system, we do not need a large team of developers.  Using all of the above components allows you to get along with a very small number of specialists. <br><br>  In addition, the entire system is much cheaper.  It is more profitable to put all our terabytes of data in S3 than to raise separate servers with disk storages, to take care of backup, etc.  It is much easier and cheaper to raise Kinesis as a ready-made service, start using it literally in a matter of minutes or hours, than setting up the infrastructure, administering it, and solving some low-level maintenance tasks. <br><br>  For the developer of an online store that works on our platform, it all looks like a kind of service.  To work with this service, a set of API is used, with which you can get useful statistics and personal recommendations for each visitor. <br><br> <code><a href="https://analytics.bitrix.info/crecoms/v1_0/recoms.php%3Fop%3Drecommend%26uid%3D"></a> analytics.bitrix.info/crecoms/v1_0/recoms.php?op=recommend&amp;uid=##&amp;count=3&amp;aid=#_#</code> <br> <br><ul><li>  uid - user cookie. </li><li>  aid - license hash. </li><li>  count - the number of recommendations. </li></ul><br><pre> <code class="javascript hljs">{ <span class="hljs-string"><span class="hljs-string">"id"</span></span>:<span class="hljs-string"><span class="hljs-string">"24aace52dc0284950bcff7b7f1b7a7f0de66aca9"</span></span>, <span class="hljs-string"><span class="hljs-string">"items"</span></span>:[<span class="hljs-string"><span class="hljs-string">"1651384"</span></span>,<span class="hljs-string"><span class="hljs-string">"1652041"</span></span>,<span class="hljs-string"><span class="hljs-string">"1651556"</span></span>] }</code> </pre><br>  We can help to recommend similar products, which is convenient for the sales of accessories and some additional components: <br><br> <code><a href="https://analytics.bitrix.info/crecoms/v1_0/recoms.php%3Fop%3Dsimitems%26aid%3D"></a> analytics.bitrix.info/crecoms/v1_0/recoms.php?op=simitems&amp;aid=#_#&amp;eid=#id_#&amp;count=3&amp;type=combined&amp;uid=##</code> <br> <br><ul><li>  uid - user cookie. </li><li>  aid - license hash. </li><li>  eid Item ID </li><li>  type - view | order | combined </li><li>  ount - size of issue. </li></ul><br>  Another useful mechanism is top products in terms of sales.  You can argue that all this can be done without fiddling with big data.  In the store itself - yes, you can.  But the use of our statistics allows you to remove a considerable share of the load from the base of the store. <br><br> <code><a href="https://analytics.bitrix.info/crecoms/v1_0/recoms.php%3Fop%3Dsim_domain_items%26aid%3D"></a> analytics.bitrix.info/crecoms/v1_0/recoms.php?op=sim_domain_items&amp;aid=#_#&amp;domain=##&amp;count=50&amp;type=combined&amp;uid=##</code> <br> <br><ul><li>  uid - user cookie. </li><li>  aid - license hash. </li><li>  domain - the domain of the site. </li><li>  type - view | order | combined </li><li>  ount - size of issue. </li></ul><br>  The client can use all these tools in any combination.  The cloud service of personal recommendations is most fully integrated with the ‚Äú1C-Bitrix: Site Management‚Äù platform itself, the store developer can very flexibly manage the block of recommendations issued: ‚Äúmix in‚Äù the necessary items of products that you should always show;  use sorting by price or by some other criteria, etc. <br><br>  When building a user model, all statistics on his views are taken into account, and not just the current session.  Moreover, all models are depersonalized, that is, each visitor exists in the system only in the form of a faceless ID.  This allows you to keep your privacy. <br><br>  We do not divide visitors depending on the stores that they visit.  We have a single database, and each visitor is assigned a single identifier, no matter what shop he goes.  This is one of the main advantages of our service, because small stores do not have a sufficiently large statistics, allowing reliably predict the behavior of users.  And thanks to our single database, even a store with 10 visits per day can, with a high probability of success, recommend products that are of interest to this particular visitor. <br><br>  The data may become outdated, so when building a user model, we will not take into account statistics a year ago, for example.  Only data for the last month are taken into account. <br><br><h3>  Practical examples </h3><br>  What do the tools we offer look like on the site? <br><br>  Block of personal recommendations, which can be on the main page.  It is individual for each site visitor. <br><br><img src="https://habrastorage.org/files/800/a0b/305/800a0b30589b4fa88ba7f43324d358b6.jpg"><br><br>  It can be displayed in the card of a specific product: <br><br><img src="https://habrastorage.org/files/50c/698/60d/50c69860d4a64710b786fdab673594a4.jpg"><br><br>  Example block of recommended products: <br><br><img src="https://habrastorage.org/files/025/5bf/a65/0255bfa650db46c782da194d027c993c.jpg"><br><br>  Blocks can be combined, looking for the most efficient combination. <br><br>  Orders sold by personal recommendation are noted in the admin panel. <br><br><img src="https://habrastorage.org/files/dde/0b6/c92/dde0b6c92f0d43b393dabb01150bf6f3.jpg"><br><br>  Employee processing orders, you can in the admin panel immediately display a list of goods that can be recommended to the buyer at check-in. <br><br><img src="https://habrastorage.org/files/c63/fe2/fdb/c63fe2fdb6a14a99ad68557f7c7697b6.jpg"><br><br>  Unlike our tools, third-party recommendation services have an important drawback ‚Äî a rather small audience.  To use these services, you need to insert a counter and a widget to display recommendations.  While our toolkit is very closely integrated with the platform, and allows us to refine the recommendations given to visitors.  For example, a store owner can sort recommendations by price or availability;  mix in the issuance of other products. <br><br><h3>  Quality metrics </h3><br>  The main question arises: how effectively does all of the above work?  How to measure efficiency in general? <br><br><ul><li>  We calculate the ratio of views on the recommendations to the total number of views. </li><li>  We also measure the number of orders made on the recommendation, and the total number of orders. </li><li>  We carry out measurements on the state-machines of users.  We have a matrix with behavior models for a period of three weeks, we give some recommendations for them.  Then we assess the state, for example, in a week, and compare the placed orders with the recommendations that we could give in the future.  If they match, then we recommend correctly.  If they do not match, it is necessary to twist or completely change the algorithms. </li><li>  A / B tests.  You can simply divide the visitors of the online store into groups: one to show products without personal recommendations, the other with recommendations, and evaluate the difference in sales. </li></ul><br>  Using A / B tests for working with personal recommendations in the near future will be available to online store owners, you can select and configure the necessary metrics directly in the admin panel, collect data for some time and evaluate the difference by comparing conversions from different audiences. <br><br>  According to our data, our conversion growth is from 10 to 35%.  Even 10% is a huge indicator for an online store in terms of investment.  Instead of putting in more money in advertising and attraction, users work more efficiently with their audience. <br><br>  But why such a large variation in the growth of conversion?  It depends on the: <br><br><ul><li>  variety of assortment, </li><li>  themes, </li><li>  the total amount of goods on the site, </li><li>  the specifics of the audience </li><li>  bundles of goods. </li></ul><br>  In the catalog, where there are few positions and few accessories, the growth will be less.  In stores offering many additional positions, growth will be higher. <br><br><h3>  Other uses </h3><br>  Where else can you use similar tools, in addition to online stores?  Virtually any online project that wants to increase the audience.  After all, a commodity unit can be not only something material.  A product can be an article, any textual material, a digital product, a service, whatever. <br><br><ul><li>  Mobile operators, service providers: identifying customers who are ready to leave. </li><li>  Banking sector: sale of additional services. </li><li>  Content projects. </li><li>  CRM. </li><li>  Trigger mailing. </li></ul><br>  The same models can be used to evaluate the audience and its willingness to move, for example, from free to paid tariffs, and vice versa.  Or you can estimate the likelihood of users leaving to competitors.  This can be prevented by some additional discount marketing action.  Or if a client is about to buy a product or service, then you can make some interesting offer, thereby increasing the loyalty of the audience.  Naturally, as much as possible all this can be used with trigger links.  For example, the user who looked at some product, put it in the basket, but did not place an order, you can make a personal offer. <br><br><h3>  BigData project statistics: Personalization </h3><br>  At the moment, 17 thousand stores operate on our platform, the system cheats up about 440 million events per month.  The general product catalog contains about 18 million items.  The proportion of orders on the recommendation of the total number of orders: 9‚Äì37%. <br><br>  As you can see, there is a lot of data, and they are not a dead weight, but work and benefit.  For the stores working on our platform, this service is now free.  We have an open API that can be modified on the Backend side and provide more flexible recommendations to specific visitors. </div><p>Source: <a href="https://habr.com/ru/post/272041/">https://habr.com/ru/post/272041/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../272031/index.html">AllcountJS: Making a system for point of sale (POS)</a></li>
<li><a href="../272033/index.html">Welcome to Web Standards Day in Moscow, December 13</a></li>
<li><a href="../272035/index.html">Did you receive a-mail? .. Accounting mail</a></li>
<li><a href="../272037/index.html">Release typescript 1.7</a></li>
<li><a href="../272039/index.html">Setting up public Internet access in five minutes</a></li>
<li><a href="../272043/index.html">Record of the webinar "What's new in Kerio Co. Connect 9"</a></li>
<li><a href="../272045/index.html">A bit about Yandex Protect</a></li>
<li><a href="../272047/index.html">From ASP.Net to Node.JS: how we rewrote the server part of ONLYOFFICE editors</a></li>
<li><a href="../272049/index.html">Everything you wanted to know about models and collections in Titanium</a></li>
<li><a href="../272051/index.html">Want to integrate Telegram into Redmine? There is a solution</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>