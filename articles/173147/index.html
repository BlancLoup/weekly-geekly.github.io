<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>MapReduce for processing semistructured data in HDInsight</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this example, we will analyze the creation and execution of a standard MapReduce task in the cloud implementation of Hadoop from Microsoft, which i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>MapReduce for processing semistructured data in HDInsight</h1><div class="post__text post__text-html js-mediator-article">  In this example, we will analyze the creation and execution of a standard MapReduce task in the cloud implementation of Hadoop from Microsoft, which is called HDInsight. <br>  In the <a href="http://blogs.technet.com/b/isv_team/archive/2012/12/29/3543062.aspx">previous example,</a> we created a 3-node Hadoop cluster and uploaded an abstract log of a slightly structured format, which is now to be processed.  The magazine is generally large (in our concrete example it is small, but it does not affect the principle demonstration of the idea) a text file containing lines with TRACE, DEBUG, INFO, WARN, ERROR, FATAL attributes.  Our elementary task will be to count the number of rows with each attribute, i.e.  how many times the WARN situation occurred, how many ERROR, etc. <br><a name="habracut"></a><br>  In terms of SQL, you need to make COUNT () ... GROUP BY across the field of the feature.  It is clear that there is no field as such, since the file is not a nameplate, but a set of strings with a textual description of the problem, in which the substring with the name of the attribute occurs.  It is necessary to run through all the lines, select the substring of the sign and sum up.  Simply put, from <br><br><pre><code class="dos hljs"><span class="hljs-number"><span class="hljs-number">2012</span></span>-<span class="hljs-number"><span class="hljs-number">02</span></span>-<span class="hljs-number"><span class="hljs-number">03</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">35</span></span>:<span class="hljs-number"><span class="hljs-number">34</span></span> SampleClass6 [INFO] everything normal <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> id <span class="hljs-number"><span class="hljs-number">577725851</span></span> <span class="hljs-number"><span class="hljs-number">2012</span></span>-<span class="hljs-number"><span class="hljs-number">02</span></span>-<span class="hljs-number"><span class="hljs-number">03</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">35</span></span>:<span class="hljs-number"><span class="hljs-number">34</span></span> SampleClass4 [FATAL] system problem <span class="hljs-built_in"><span class="hljs-built_in">at</span></span> id <span class="hljs-number"><span class="hljs-number">1991281254</span></span> <span class="hljs-number"><span class="hljs-number">2012</span></span>-<span class="hljs-number"><span class="hljs-number">02</span></span>-<span class="hljs-number"><span class="hljs-number">03</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">35</span></span>:<span class="hljs-number"><span class="hljs-number">34</span></span> SampleClass3 [DEBUG] detail <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> id <span class="hljs-number"><span class="hljs-number">1304807656</span></span> <span class="hljs-number"><span class="hljs-number">2012</span></span>-<span class="hljs-number"><span class="hljs-number">02</span></span>-<span class="hljs-number"><span class="hljs-number">03</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">35</span></span>:<span class="hljs-number"><span class="hljs-number">34</span></span> SampleClass3 [WARN] missing id <span class="hljs-number"><span class="hljs-number">423340895</span></span> <span class="hljs-number"><span class="hljs-number">2012</span></span>-<span class="hljs-number"><span class="hljs-number">02</span></span>-<span class="hljs-number"><span class="hljs-number">03</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">35</span></span>:<span class="hljs-number"><span class="hljs-number">34</span></span> SampleClass5 [TRACE] verbose detail <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> id <span class="hljs-number"><span class="hljs-number">2082654978</span></span> <span class="hljs-number"><span class="hljs-number">2012</span></span>-<span class="hljs-number"><span class="hljs-number">02</span></span>-<span class="hljs-number"><span class="hljs-number">03</span></span> <span class="hljs-number"><span class="hljs-number">18</span></span>:<span class="hljs-number"><span class="hljs-number">35</span></span>:<span class="hljs-number"><span class="hljs-number">34</span></span> SampleClass0 [ERROR] incorrect id <span class="hljs-number"><span class="hljs-number">1886438513</span></span> ...</code> </pre>  Script 1 <br><br>  want to get something like 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="dos hljs">[TRACE] <span class="hljs-number"><span class="hljs-number">10</span></span> [DEBUG] <span class="hljs-number"><span class="hljs-number">20</span></span> [INFO] <span class="hljs-number"><span class="hljs-number">30</span></span> [WARN] <span class="hljs-number"><span class="hljs-number">555</span></span> [ERROR] <span class="hljs-number"><span class="hljs-number">777</span></span> [FATAL] <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre>  Script 2 <br><br>  The idea behind the MapReduce model is very simple.  In the presence of a distributed system, which is the Hadoop cluster, the common task is divided (Map) into parallel subtasks.  As noted in the previous example, to be processed when stored in the Hadoop file system is transparent to the user is divided into fragments by node.  Theoretically, these nodes can be distributed geographically, i.e.  be in different geographic locations.  To minimize the costs associated with transferring data between data centers (or simply between individual nodes), Hadoop takes into account the territorial proximity of data ‚Äî each subjob works with its own piece of data.  In our case there are only 3 nodes in the cluster, not luxury.  Subtasks will be performed on the same nodes where the data fragments are located.  The results of the subtasks are then aggregated by the Reduce functions into a single result returned to the user.  In other words, each node will give its own private result, for example, the first one - <pre> <code class="dos hljs">[TRACE] <span class="hljs-number"><span class="hljs-number">1</span></span> [DEBUG] <span class="hljs-number"><span class="hljs-number">2</span></span> [INFO] <span class="hljs-number"><span class="hljs-number">3</span></span> ...</code> </pre>  Script 3 <br><br>  second - <br><pre> <code class="dos hljs">[TRACE] <span class="hljs-number"><span class="hljs-number">9</span></span> [DEBUG] <span class="hljs-number"><span class="hljs-number">5</span></span> [INFO] <span class="hljs-number"><span class="hljs-number">7</span></span> ...</code> </pre>  Script 4 <br><br>  from which a total result of Script 2 will be compiled in the end. This is a general idea of ‚Äã‚Äãparallel processing, which has been implemented in traditional relational database servers (eg, Oracle RAC, Microsoft SQL Server Parallel Datawarehouse, etc.) and relational cloud services data processing (eg, federated database in Windows Azure SQL Database, previously known as sharding in SQL Azure).  But in this case, we are not dealing with a relational, but with a weakly structured input data format; therefore, instead of SQL scripts, we will have to write functions that perform the Map / Reduce role on our own.  The idea of ‚Äã‚ÄãMapReduce is <a href="http://ru.wikipedia.org/wiki/MapReduce">implemented</a> in various languages.  For example, in the free open-source Apache Hadoop project, Java is used for this purpose.  Since Microsoft HDInsight is compatible with Apache Hadoop, we will also use the Java language and the <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/package-summary.html">org.apache.hadoop.mapreduce</a> package. <br><br>  First, the Map class derived from Mapper is implemented.  <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html">The Mapper class</a> converts the original set of key / value pairs to an intermediate one.  In our case, the input values ‚Äã‚Äãare the text log file lines ‚Äî the value parameter of type Text of the map method.  Inside the method in each value, we look for square brackets, pull out what is between them, compare it with a constant set of attributes, which we initially put in the pattern variable and, if it matches (if (matcher.matches ())), we form the output key- value.  The key is the substring of the TRACE / DEBUG / ... feature (text variable logLevel), and the value is 1. The value is contained in the accumulator variable of the IntWritable type, which we initialized in the constructor as a unit.  IntWriteable is a wrapper around the java int type that implements the Writable interface.  Hadoop uses its own serialization format.  We will add these ones in the Reduce function to count the number of occurrences of each feature.  Intermediate (output) values ‚Äã‚Äãare grouped by Hadoop for each output key.  At the mapping stage, you can pre-aggregate with setCombinerClass to reduce the data.  transmitted to the Reducer.  In this example, this feature is not used.  The Reporter class (the last parameter of the map method) is designed to display the status and progress of the execution, update the counters, etc.  In our simple example, it is also not used. <br>  The Reduce class derived from Reducer solves the inverse problem.  It collects intermediate mapping results and aggregates them, performing in this case the notorious COUNT () values, since  GROUP BY by keys (including sorting) was performed during mapping.  Input types (Text, IntWritable) for Reduce must correspond to output types from Map.  During the merging of the results in the Reduce stage, Hadoop performs a secondary sorting, since the results obtained from different mappers may have the same keys.  Thus, the input result for the Reduce method is a set of strings key - a collection of corresponding values.  For example, one of the strings will be a TRACE (key) and a collection of as many units as the occurrences of this attribute identified one or another instance of the mapper.  It remains for us to run through the collection and sum up the ones in the count variable.  In the OutputCollector, we write the traditional key-value pair, only the value here will be the result of the aggregation by key. <br>  The main () method is used to create a Hadoop job based on the created Map and Reduce classes and its execution.  The JobConf object forms the job specification.  The code is written to a JAR file that Hadoop will distribute across the cluster.  Instead of explicitly specifying a file name, you can pass an enclosing class containing executable code (MapReduceTest) into the JobConf constructor, by which Hadoop will find the corresponding JAR file.  The setOutputKeyClass () and setOutputValueClass () methods set the output types for the Map and Reduce functions.  As a rule, they coincide, i.e.  Map gives the same as Reduce.  If they are different, the output types of the Map function can be specified using the setMapOutputKeyClass () and setMapOutputValueClass () methods.  Which class will do the Map, and which Reduce, as you can guess, is set using the methods setMapperClass () and setReducerClass ().  It remains to register the format of I / O.  This is done using the setInputFormat () and setOutputFormat () methods.  In this case, this could not be done, because  text format is the default.  In conclusion, you need to register the paths to the files with source data and results using the static methods FileInputFormat.setInputPaths () and FileOutputFormat.setOutputPath ().  We will pass file names through command line arguments.  As the name of the method shows, there may be several input files.  There may be a directory, then all files contained in it will be taken.  You can specify a file name pattern.  As a location where the result files will be added, a directory is assigned.  It should not exist, otherwise an error will occur during the execution.  A kind of protection measure so that one task does not fray the result of another.  You can delete a directory using the hadoop fs -rmr command. <br>  Putting this together, we get the following code: <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//   import java.io.IOException; import java.util.Iterator; import java.util.regex.Matcher; import java.util.regex.Pattern; //,   Hadoop import org.apache.hadoop.fs.Path; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.LongWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapred.FileInputFormat; import org.apache.hadoop.mapred.FileOutputFormat; import org.apache.hadoop.mapred.JobClient; import org.apache.hadoop.mapred.JobConf; import org.apache.hadoop.mapred.MapReduceBase; import org.apache.hadoop.mapred.Mapper; import org.apache.hadoop.mapred.OutputCollector; import org.apache.hadoop.mapred.Reducer; import org.apache.hadoop.mapred.Reporter; import org.apache.hadoop.mapred.TextInputFormat; import org.apache.hadoop.mapred.TextOutputFormat; public class MapReduceTest { /* *  */ public static class Map extends MapReduceBase implements Mapper&lt;LongWritable, Text, Text, IntWritable&gt; { private static final Pattern pattern = Pattern.compile("(TRACE)|(DEBUG)|(INFO)|(WARN)|(ERROR)|(FATAL)"); //   private static final IntWritable accumulator = new IntWritable(1); //   - ,    private Text logLevel = new Text(); public void map(LongWritable key, Text value, OutputCollector&lt;Text, IntWritable&gt; collector, Reporter reporter) throws IOException { //    '['  ']' final String[] tokens = value.toString().split("[ \\[\\]]"); if(tokens != null) { //  logLevel for(final String token : tokens) { final Matcher matcher = pattern.matcher(token); if(matcher.matches()) //  { logLevel.set(token); collector.collect(logLevel, accumulator); //  - } } } } } /* *  */ public static class Reduce extends MapReduceBase implements Reducer&lt;Text, IntWritable, Text, IntWritable&gt; { public void reduce(Text key, Iterator&lt;IntWritable&gt; values, OutputCollector&lt;Text, IntWritable&gt; collector, Reporter reporter) throws IOException { int count = 0; //  count    while(values.hasNext()) { count += values.next().get(); } System.out.println(key + "\t" + count); collector.collect(key, new IntWritable(count)); } } /* *   */ public static void main(String[] args) throws Exception { //       ,  Map/Reduce final JobConf conf = new JobConf(MapReduceTest.class); conf.setOutputKeyClass(Text.class); conf.setOutputValueClass(IntWritable.class); conf.setMapperClass(Map.class); conf.setReducerClass(Reduce.class); conf.setInputFormat(TextInputFormat.class); conf.setOutputFormat(TextOutputFormat.class); //-       FileInputFormat.setInputPaths(conf, new Path(args[0])); FileOutputFormat.setOutputPath(conf, new Path(args[1])); //  JobClient.runJob(conf); } }</span></span></code> </pre><br>  Script 5 <br><br>  Let's go to the Khadupov cluster via Remote Desktop, as shown in the previous article, and save this code to the MapReduceTest.java file, say, in the same d: \ Temp.  Java support libraries in HDInsight are located in C: \ apps \ java \ bin.  Hadoop doesn't know about this.  It makes sense to go to the Hadoop command line window ( <pre> <code class="dos hljs"><span class="hljs-function"><span class="hljs-function">D:\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Windows</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">system32</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">cmd.exe</span></span></span><span class="hljs-function"> /</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">k</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pushd</span></span></span><span class="hljs-function"> "</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">c</span></span></span><span class="hljs-function">:\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">apps</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dist</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">hadoop</span></span></span><span class="hljs-function">-1.1.0-</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">SNAPSHOT</span></span></span><span class="hljs-function">" &amp;&amp; "</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">c</span></span></span><span class="hljs-function">:\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">apps</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dist</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">hadoop</span></span></span><span class="hljs-function">-1.1.0-</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">SNAPSHOT</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bin</span></span></span><span class="hljs-function">\</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">hadoop.cmd</span></span></span><span class="hljs-function">"</span></span></code> </pre>  , for convenience, there is a shortcut on the HDInsight desktop) and write this path to the% path% environment variable: <br><br><pre> <code class="dos hljs"><span class="hljs-built_in"><span class="hljs-built_in">set</span></span> <span class="hljs-built_in"><span class="hljs-built_in">PATH</span></span>=<span class="hljs-variable"><span class="hljs-variable">%PATH%</span></span>;C:\apps\java\bin</code> </pre>  Script 6 <br><br>  Go to the d: \ Temp directory and compile the java file into the bytecode class files.  The switch -encoding was needed because I saved Unicode encoding MapReduceTest.java. <br><br><pre> <code class="dos hljs">javac -encoding UNICODE -classpath C:\apps\dist\hadoop-<span class="hljs-number"><span class="hljs-number">1</span></span>.<span class="hljs-number"><span class="hljs-number">1</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span>-SNAPSHOT\hadoop-core-*.jar d:\Temp\MapReduceTest.java</code> </pre>  Script 7 <br><br>  In d: \ Temp, a MapReduceTest.class file and MapReduceTest $ Map.class and MapReduceTest $ Reduce.class files were created, corresponding to the altered classes.  Build the build: <br><br><pre> <code class="dos hljs">jar -cvf MapReduceTest.jar *.class</code> </pre>  Script 8 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/139/210/dc2/139210dc284f126b2188942d2ad44b19.png"><br>  Pic1 <br><br>  On the current d: \ Temp path, a java archive MapReduceTest.jar was formed. <br><br><pre> <code class="dos hljs">hadoop jar MapReduceTest.jar MapReduceTest Sample1/input/Sample.log Sample1/output</code> </pre>  Script 9 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0f9/745/38c/0f974538c0626447ac2ee50948b8cdcb.png"><br>  Pic2 <br><br>  Here, Sample1 / input / Sample.log is the log file to be processed, downloaded from the local d: \ Temp directory to the HDFS / Sample1 / Input directory - see Figure 5 of the previous article.  Last time I forgot to point out that before loading it is necessary to explicitly create the HDFS input directory (hadoop fs -mkdir Sample1 / input /) and only after that put the file into it (hadoop fs -put d: \ Temp \ Sample.log Sample1 / input /).  If you try to load a file without first creating a directory, it is created, but the file is not loaded into it, as hadoop fs -ls Sample1 / input / can be seen. <br>  In the meantime, the task successfully completed.  In the output directory of HDFS Sample1 / output, a file with results was generated, containing the number of occurrences of each attribute in the log, as ordered: <br><br><pre> <code class="dos hljs">hadoop <span class="hljs-built_in"><span class="hljs-built_in">fs</span></span> -cat Sample1/output/part-<span class="hljs-number"><span class="hljs-number">00000</span></span></code> </pre>  Script 10 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a33/db6/854/a33db6854b1d55973c0c0bc1358c4832.png"><br>  Pic.3 </div><p>Source: <a href="https://habr.com/ru/post/173147/">https://habr.com/ru/post/173147/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../173133/index.html">CeBIT 2013. Mobile devices. The final post about the exhibition</a></li>
<li><a href="../173135/index.html">Scoring, assessment of borrowers for the Webmoney system. Short review. Instruments</a></li>
<li><a href="../173137/index.html">NHibernate 3.3.3.GA released</a></li>
<li><a href="../173141/index.html">WebKit for developers</a></li>
<li><a href="../173143/index.html">.SITE i.ONLINE - Cyrillic domains for all</a></li>
<li><a href="../173149/index.html">IRIScan Mouse - mouse and scanner in one bottle</a></li>
<li><a href="../173151/index.html">Blocked by devblog.blackberry.com</a></li>
<li><a href="../173153/index.html">Simple configuration file editor for Yii</a></li>
<li><a href="../173157/index.html">Programming Arduino from the console, gentoo-way, nothing more</a></li>
<li><a href="../173159/index.html">Network Virtualization in Hyper-V. Concept</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>