<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Self-learning chess program</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, Habr! 

 In an article published last year , we solved the problem of determining the mathematically justified values ‚Äã‚Äãof chess pieces. With t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Self-learning chess program</h1><div class="post__text post__text-html js-mediator-article">  Hello, Habr! <br><br>  In an <a href="https://habrahabr.ru/post/254753/">article published last year</a> , we solved the problem of determining the mathematically justified values ‚Äã‚Äãof chess pieces.  With the help of regression analysis of parties played by computers and people, we managed to get the value scale of ‚Äúunits‚Äù, which largely coincides with the traditional values ‚Äã‚Äãknown from books and practical experience. <br><br>  Unfortunately, the direct substitution of the corrected values ‚Äã‚Äãfor the figures did not strengthen the author's program - in any case, more than within the framework of statistical error.  The application of the original method "in the forehead" to other parameters of the evaluation function yielded somewhat absurd results, the optimization algorithm clearly needed some refinement.  Meanwhile, the author decided that the next release of his engine will be the final in a long series of versions originating in the code of a decade ago.  GreKo version 2015 was released, and no further changes were planned in the near future. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/eae/66d/0ed/eae66d0ed4c217b894c9fd0b8c3c661b.jpg" alt="Picture to attract attention"><br><br>  All interested in what happened next - after viewing the picture to attract attention, welcome to the cat. <a name="habracut"></a><br><br>  The motivation for the sudden continuation of the work and, ultimately, the appearance of this article were two events.  One of them thundered to the whole world through the media channels - this is the match in Go of the Korean top player Lee Sedol with the Google <a href="https://deepmind.com/alpha-go">AlphaGo</a> program. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/31a/62d/1fa/31a62d1fa470f055bd5e71e207a8d6fa.jpg" width="500"><br><br>  The developers at Google DeepMind were able to effectively combine two powerful techniques - searching in the tree using the Monte Carlo method and deep learning using neural networks.  The resulting symbiosis led to phenomenal results in the form of a victory over two professional players in Guo (Lee Cedol and Fan Hue) with a total score of 9 - 1. The details of the implementation of AlphaGo were widely discussed, including on Habr√©, so now we will not dwell on them. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c80/940/35d/c8094035dafb7c9c5a447030d6863919.jpg" width="120" align="right">  The second event, not so widely advertised, and seen mainly by chess-programming enthusiasts, is the emergence of the <a href="https://chessprogramming.wikispaces.com/Giraffe">Giraffe</a> program.  Its author, Matthew Lai, actively used the ideas of machine learning, in particular, all the same deep neural networks.  Unlike traditional engines, in which the evaluation function contains a number of predefined characteristics of the position, Giraffe at the training stage independently extracts these signs from the educational material.  In fact, the goal of the automatic derivation of ‚Äúchess knowledge‚Äù in the form in which it is presented in textbooks was stated. <br><br>  In addition to the evaluation function, neural networks in Giraffe were also used to parameterize the search in a tree, which also suggests some parallels with AlphaGo. <br><br>  The program has demonstrated some success, having reached from scratch in a few days of training the strength of an international master.  But, unfortunately, the most interesting research project was prematurely completed ... in connection with the transition of Matthew Lai to work in the Google DeepMind team! <br><br>  Anyway, the information wave that arose in connection with AlphaGo and Giraffe, prompted the author of this article to once again return to the code of his engine and still try to strengthen his game with the methods of machine learning that is so popular today. <br><br><h3>  Algorithm </h3><br><br>  It may disappoint someone, but in the project described there will be neither multilayered neural networks, nor automatic detection of key position attributes, nor the Monte Carlo method.  Random search for wood in chess is practically not required due to the limited task, and well-functioning factors for evaluating the chess position have been known since the days <a href="https://chessprogramming.wikispaces.com/Kaissa">of Kaissa</a> .  In addition, the author was interested in how you can enhance the game of the program within a fairly minimalist set of them, which is implemented in GreKo. <br><br>  The basic method was the algorithm for setting the evaluation function, which was proposed by the Swedish researcher and developer Peter √ñsterlund, the author of the strong Texel program.  The winning sides of this method, according to its creator, are: <br><br><ul><li>  The ability to simultaneously optimize up to several hundred parameters of the evaluation function. </li><li>  The absence of a need for a source of ‚Äúexternal knowledge‚Äù in the form of expert assessments of positions ‚Äî only texts and the results of parties are needed. </li><li>  Correct work with strongly correlated signs - no preliminary preparation like their orthogonalization is required. </li></ul><br><br>  Let <i>Œ∏ = (Œ∏ <sub>1</sub> , ..., Œ∏ <sub>K</sub> )</i> be the vector of parameters of the evaluation function (weight of the material and positional features). <br>  For each position <i>p <sub>i</sub> , i = 1 ... N</i> from the test set, we calculate its static estimate <i>E <sub>Œ∏</sub> (p <sub>i</sub> )</i> , which is a certain scalar value.  Traditionally, the assessment is rationed so that it gives an idea of ‚Äã‚Äãthe advantage of one side or the other in units of chess material - for example, hundredths of a pawn.  We will always consider the evaluation in terms of whites. <br><br>  We now turn from the material representation of the estimate to the probabilistic one.  Using the logistic function, we will do the following conversion: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb2/6a1/03e/eb26a103e7201eaa5860d6b2080016e4.png" alt="R_ {pred} (\ theta, p_i) = \ frac {1} {1 + e ^ {- E _ {\ theta} (p_i) / K}}"><br><br>  The value of <i>R <sub>pred</sub></i> makes sense of the mathematical expectation of the result of the game for white in this position (0 is a defeat, 0.5 is a draw, 1 is a victory).  The normalization constant <i>K</i> can be defined as such a material advantage, in which "everything becomes clear."  In this study, we used the value <i>K = 150</i> , i.e.  one and a half pawns.  Of course, ‚Äúit becomes clear‚Äù only in a statistical sense, in real chess games one can find a huge number of counterexamples, when a much greater material advantage does not lead to a gain. <br><br>  In the original algorithm, instead of a static evaluation function, the result of the so-called PV search was used to calculate <i>R <sub>pred</sub></i> .  The name is associated with the concept of the forced version, in the English version - quiescence search.  This is an alpha-beta search from a given position in which only captures, transformations of pawns, and sometimes shahs and departures from them are considered.  Although the search trees are small, compared to the static estimate, the computation speed decreases by tens and hundreds of times.  Therefore, it was decided to use a faster scheme, and sift out dynamic positions at the stage of preparing the initial data. <br><br>  Now, knowing for each position the predicted <i>R <sub>pred</sub></i> and actual <i>R <sub>fact</sub></i> results of the game in which it met, we can calculate the root-mean-square prediction error: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/72d/0e1/aa9/72d0e1aa9682deb1be9b9f22b240d646.png" alt="Err (\ theta) = \ frac {1} {N} \ sum_ {i = 1} ^ {N} (R_ {pred} (\ theta, p_i) - R_ {fact} (p_i)) ^ 2"><br><br>  In fact, the obtained rms estimate can already be considered as the objective functional to be minimized.  This approach is described in the original description of the method. <br><br>  We will make another small modification - we introduce the accounting of the number of moves remaining until the end of the game.  Obviously, a positional sign that existed on the board at the very beginning of the game may not have any effect on its outcome if the main events in the game occurred much later.  For example, White in the opening may have a proud knight in the center of the board, but lose in the deep endgame, when this knight is already long traded, due to the invasion of the enemy rook into his camp.  In this case, the sign ‚Äúa horse in the center of the board‚Äù should not receive too much punishment compared to the sign ‚Äúa rook on the second rank‚Äù - the horse is not to blame for anything! <br><br>  Accordingly, we add an amendment to our objective function related to the number of moves <i>n <sub>i</sub></i> remaining until the end of the game.  For each position, it will be an exponential decay factor with the parameter <i>Œª</i> .  The ‚Äúphysical meaning‚Äù of this parameter is the number of moves during which a particular positional attribute influences the game.  Again, on average.  In the experiments described below, <i>Œª</i> takes values ‚Äã‚Äãin several dozen half-moves. <br><br>  In the original description of Texel's Tuning Method from the training set, the first moves in the batches were discarded.  The introduction of " <i>Œª-</i> forgetting" allows us not to impose a clear restriction on the moves from the opening book - their influence somehow turns out to be small. <br><br>  The final view of our target functionality: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bbd/1ba/8f9/bbd1ba8f9abbabd4afc223db13ad1ef4.png" alt="J (\ theta) = \ frac {1} {N} \ sum_ {i = 1} ^ {N} (R_ {pred} (\ theta, p_i) - R_ {fact} (p_i)) ^ 2 (e ^ {-n_i / \ lambda})"><br><br>  The task of learning the evaluation function is now reduced to minimizing <i>J</i> in the space of values ‚Äã‚Äãof the vector <i>Œ∏</i> . <br><br>  Why does this method work?  In fact, most of the signs arising in positions on large batches of parties, due to averaging, are mutually neutralized.  Only those of them that actually influenced the result retain their value and receive higher weights.  The sooner the evaluation function starts to notice them during the game - the better the prediction and the more accurate the position estimate, the stronger the program will become. <br><br><h3>  Training and Results </h3><br><br>  As an array of data for training, positions from 20 thousand games played with the program were used.  From their number were excluded positions arising after the capture of a figure or the announcement of the Shah.  This is necessary so that the training set of examples matches as closely as possible with the actual positions from the search tree, for which static evaluation is applied. <br><br>  The result was about 2.27 million positions.  They are not all unique, but this is not critical for the method used.  Positions were randomly divided into training and test sets in the ratio of 80/20, respectively 1.81 million and 460 thousand positions. <br><br>  The minimization of the functional was carried out on a training set by the method of coordinate descent.  It is known that for multi-dimensional optimization problems this method is usually not the best choice.  However, the simplicity of the implementation, as well as an acceptable execution time, played in favor of this algorithm.  On a typical modern PC, optimization for 20 thousand batches takes from one to several hours, depending on the subset of 27 possible weights selected for tuning. <br><br>  Below is a graph of functional changes depending on time.  The criterion for stopping the training is the non-improvement of the result for the test subset after the next cycle of descents in all parameters. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dc0/50a/9e4/dc050a9e49f9dfa7d7eff0f77b6bc576.png"><br><br>  The evolution of a group of parameters related to pawns is shown in the following graph.  It can be seen that the process converges quickly enough - at least to a local minimum.  The task of searching for a global minimum has not yet been set, our goal now is to strengthen the program by at least some amount ... <br><br><img src="https://habrastorage.org/getpro/habr/post_images/94e/fb5/bd7/94efb5bd7c18b05e179a0ef1650c2f3c.png"><br><br><div class="spoiler">  <b class="spoiler_title">Similar graphs for other features.</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/391/615/a96/391615a961cfc6b1240059261aab78a9.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/ba6/120/07a/ba612007ab8b0b01ec7d33b9b549f393.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/b98/63c/087/b9863c0876a4ab9a7cc88f9cfb4b54f8.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/333/20d/771/33320d7719512f8b6bba9ed8761dc831.png"><br><br>  The following graph presents data related to another training session in which material weights were also adjusted.  It can be seen that from the ‚Äúcomputer‚Äù values ‚Äã‚Äãused in GreKo, they gradually converge to more classical values. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8ee/492/209/8ee49220935edefe664f60c5a3c080d8.png"><br></div></div><br><br>  We give a complete list of evaluation parameters with initial and final values.  The meaning of the most part is clear without additional comments, those who wish to familiarize themselves with their exact purpose are invited to the source code of the program - the eval.cpp file, the Evaluate () function. <br><br><table><tbody><tr><th>  room </th><th>  Sign of </th><th>  Description </th><th>  Before training </th><th>  After training </th></tr><tr><td>  one. </td><td>  VAL_P </td><td>  pawn cost </td><td>  100 </td><td>  100 </td></tr><tr><td>  2 </td><td>  VAL_N </td><td>  horse cost </td><td>  400 </td><td>  400 </td></tr><tr><td>  3 </td><td>  VAL_B </td><td>  elephant cost </td><td>  400 </td><td>  400 </td></tr><tr><td>  four. </td><td>  VAL_R </td><td>  rook cost </td><td>  600 </td><td>  600 </td></tr><tr><td>  five. </td><td>  Val_q </td><td>  queen cost </td><td>  1200 </td><td>  1200 </td></tr><tr><td>  6 </td><td>  Pawndoubled </td><td>  double pawn </td><td>  -ten </td><td>  -ten </td></tr><tr><td>  7 </td><td>  PawnIsolated </td><td>  isolated pawn </td><td>  -ten </td><td>  -nineteen </td></tr><tr><td>  eight. </td><td>  Pawnbackback </td><td>  backward pawn </td><td>  -ten </td><td>  -five </td></tr><tr><td>  9. </td><td>  Pawncenter </td><td>  pawn in the center of the board </td><td>  ten </td><td>  9 </td></tr><tr><td>  ten. </td><td>  Pawnpassedfreemax </td><td>  unblocked pass </td><td>  120 </td><td>  128 </td></tr><tr><td>  eleven. </td><td>  Pawnpassedblockedmax </td><td>  locked gate </td><td>  100 </td><td>  101 </td></tr><tr><td>  12. </td><td>  PawnPassedKingDist </td><td>  distance from the opponent's king in the endgame </td><td>  five </td><td>  9 </td></tr><tr><td>  13. </td><td>  Pawnpassedsquare </td><td>  checkpoint, unreachable by the "rule of the square" </td><td>  50 </td><td>  200 </td></tr><tr><td>  14. </td><td>  KnightCenter </td><td>  horse centralization </td><td>  ten </td><td>  27 </td></tr><tr><td>  15. </td><td>  KnightOutpost </td><td>  protected item for a horse </td><td>  ten </td><td>  7 </td></tr><tr><td>  sixteen. </td><td>  KnightMobility </td><td>  horse mobility </td><td>  20 </td><td>  nineteen </td></tr><tr><td>  17 </td><td>  BishopPairMidgame </td><td>  a pair of elephants in the middlegame </td><td>  20 </td><td>  20 </td></tr><tr><td>  18. </td><td>  BishopPairEndgame </td><td>  pair of elephants in the endgame </td><td>  100 </td><td>  95 </td></tr><tr><td>  nineteen. </td><td>  BishopCenter </td><td>  elephant centralization </td><td>  ten </td><td>  9 </td></tr><tr><td>  20. </td><td>  BishopMobility </td><td>  elephant mobility </td><td>  60 </td><td>  72 </td></tr><tr><td>  21. </td><td>  Rook7th </td><td>  rook on the 7th rank </td><td>  20 </td><td>  24 </td></tr><tr><td>  22 </td><td>  Roookopen </td><td>  an open rook </td><td>  ten </td><td>  17 </td></tr><tr><td>  23. </td><td>  Rookmobility </td><td>  rook mobility </td><td>  40 </td><td>  40 </td></tr><tr><td>  24 </td><td>  QueenKingTropism </td><td>  the proximity of the queen to the opponent's king </td><td>  40 </td><td>  99 </td></tr><tr><td>  25 </td><td>  KingCenterMid </td><td>  centralization of the king in the middlegame </td><td>  -40 </td><td>  -41 </td></tr><tr><td>  26 </td><td>  KingCenterEnd </td><td>  centralization of the king in the endgame </td><td>  40 </td><td>  33 </td></tr><tr><td>  27. </td><td>  KingPawnShield </td><td>  king pawn shield </td><td>  120 </td><td>  120 </td></tr></tbody></table><br><br>  The table shows an example for one of the training sessions, in which only the positional parameters of the evaluation were optimized, and the cost of the figures remained unchanged.  This is not a critical requirement; in the tests described below, full training on all 27 parameters was used.  But the best results in the practical game showed a version with a constant scale of material. <br><br>  What conclusions can be drawn from the weights obtained?  It can be seen that some of them have remained almost unchanged compared with the original version of the program.  It can be assumed that over the years of debugging the engine, they were selected intuitively enough.  However, at some points, cold mathematics amended human intuition.  So, the damage of the backward pawns was overrated by the author.  But the following parameters seemed more important to the algorithm, their weights were almost doubled: <br><br><ul><li>  isolated pawn </li><li>  an open rook </li><li>  distance from the opponent's king in the endgame </li><li>  horse centralization </li><li>  the proximity of the queen to the opponent's king </li></ul><br><br>  We should also mention the sign of the checkpoint, which is unattainable according to the ‚Äúrule of the square‚Äù.  Its optimized value has reached the limit of the acceptable interval set by the algorithm.  Obviously, it could be more.  The reason, probably, is that in the training file, in the presence of such a passing pawn, the games were won 100% of the time.  As a weight, the value of 200 was left as quite sufficient - its increase has practically no effect on the strength of the game. <br><br><h3>  Check at the chessboard </h3><br><br>  So, we have trained the evaluation function to predict the outcome of the game based on the position on the board.  But the main test lies ahead - how much this skill will prove useful in a practical game.  For this purpose, several versions of the engine with different settings were prepared, each of which was obtained in its own training mode. <br><br><table><tbody><tr><th>  Version </th><th>  Training file </th><th>  Number of batches </th><th>  Evaluation ratios </th><th>  Scaling constant <i>Œª</i> </th></tr><tr><td>  A </td><td>  20000.pgn </td><td>  20,000 </td><td>  6 ... 27 </td><td>  40 </td></tr><tr><td>  B </td><td>  20000.pgn </td><td>  20,000 </td><td>  1 ... 27 </td><td>  40 </td></tr><tr><td>  C </td><td>  20000.pgn </td><td>  20,000 </td><td>  6 ... 27 </td><td>  20 </td></tr><tr><td>  D </td><td>  20000.pgn </td><td>  20,000 </td><td>  1 ... 27 </td><td>  20 </td></tr><tr><td>  E </td><td>  20000.pgn </td><td>  20,000 </td><td>  6 ... 27 </td><td>  60 </td></tr><tr><td>  F </td><td>  20000.pgn </td><td>  20,000 </td><td>  1 ... 27 </td><td>  60 </td></tr><tr><td>  G </td><td>  gm2600.pgn </td><td>  27202 </td><td>  6 ... 27 </td><td>  20 </td></tr><tr><td>  H1 </td><td>  large.pgn </td><td>  47202 </td><td>  6 ... 27 </td><td>  20 </td></tr><tr><td>  H2 </td><td>  large.pgn </td><td>  47202 </td><td>  1 ... 27 </td><td>  20 </td></tr></tbody></table><br><br>  20000.pgn - program parts with itself (superblits) <br>  gm2600.pgn - grandmasters' games from the Crafty Robert Hyatt FTP site (classic control) <br>  large.pgn - merge the two files <br><br>  Each of the versions played 100 games with the original program GreKo 2015, as well as with a set of other engines with time control "1 second + 0.1 seconds per turn".  The results are shown in the table below.  With the help of the program bayeselo, relative ratings of versions were calculated, the power of GreKo 2015 was fixed as a reference point at the level of 2600. The value of LOS (likelihood of superiority) was also determined - the probability that a particular version plays stronger than GreKo 2015 taking into account the confidence interval of rating calculation. <br><br><table><tbody><tr><th>  Version </th><th>  GreKo 2015 </th><th>  Fruit 2.1 </th><th>  Delfi 5.4 </th><th>  Crafty 23.4 </th><th>  Kiwi 0.6d </th><th>  Rating </th><th>  LOS </th></tr><tr><td>  GreKo 2015 </td><td></td><td>  33 </td><td>  40.5 </td><td>  39.5 </td><td>  73.5 </td><td>  2600 </td><td></td></tr><tr><td>  A </td><td>  53.5 </td><td>  38 </td><td>  49.5 </td><td>  46.5 </td><td>  76 </td><td>  2637 </td><td>  97% </td></tr><tr><td>  B </td><td>  55 </td><td>  43.5 </td><td>  71 </td><td>  36.5 </td><td>  78.5 </td><td>  2667 </td><td>  99% </td></tr><tr><th>  C </th><th>  52.5 </th><th>  39.5 </th><th>  81 </th><th>  42.5 </th><th>  75 </th><th>  2672 </th><th>  99% </th></tr><tr><td>  D </td><td>  42 </td><td>  23.5 </td><td>  58 </td><td>  33.5 </td><td>  68 </td><td>  2574 </td><td>  7% </td></tr><tr><td>  E </td><td>  53.5 </td><td>  37 </td><td>  51.5 </td><td>  46 </td><td>  81.5 </td><td>  2646 </td><td>  99% </td></tr><tr><td>  F </td><td>  59 </td><td>  36.5 </td><td>  63 </td><td>  31.5 </td><td>  79.5 </td><td>  2648 </td><td>  98% </td></tr><tr><td>  G </td><td>  48 </td><td>  24.5 </td><td>  59 </td><td>  43.5 </td><td>  65.5 </td><td>  2602 </td><td>  54% </td></tr><tr><td>  H1 </td><td>  45.5 </td><td>  40 </td><td>  51.5 </td><td>  40.5 </td><td>  75.5 </td><td>  2616 </td><td>  81% </td></tr><tr><td>  H2 </td><td>  55 </td><td>  33.5 </td><td>  65 </td><td>  39 </td><td>  74 </td><td>  2646 </td><td>  99% </td></tr></tbody></table><br><br>  It is seen that the improvement of the game occurred in all cases except one (version D).  It is also interesting that training in the games of grandmasters (version G) had a slight effect.  But the addition to the games of grandmasters of their own games of the program, plus the modification of the values ‚Äã‚Äãof the pieces (version H2) turned out to be a fairly successful combination. <br><br>  The strongest in the aggregate of results was version C, with an increase in the rating of about 70 points.  For a given number of batches, this margin is statistically significant, the error is plus or minus 30 points. <br><br>  We trained and tested the program at ultra-short time control, when one batch lasts a few seconds.  Check how our improvements work in the "serious" game, with longer controls. <br><br><table><tbody><tr><th>  Time control </th><th>  Number of batches </th><th>  Result </th><th>  Rating </th><th>  LOS </th></tr><tr><td>  1 minute.  + 1 sec  / move </td><td>  200 </td><td>  116.5 - 83.5 </td><td>  + 56 </td><td>  99% </td></tr><tr><td>  3 min.  + 2 seconds  / move </td><td>  100 </td><td>  57.5 - 42.5 </td><td>  + 45 </td><td>  94% </td></tr><tr><td>  5 minutes.  on 40 moves </td><td>  100 </td><td>  53.5 - 46.5 </td><td>  + 21 </td><td>  77% </td></tr></tbody></table><br><br>  So, despite a slight drop in efficiency with an increase in the length of the games, the trained version definitely demonstrates a stronger game than the engine with the original settings.  She was released as <i>another</i> final release of the program. <br><br><h3>  GreKo 2015 ML </h3><br><br><img src="http://greko.su/GreKo.bmp" align="right">  The <a href="http://greko.su/">GreKo 2015 ML</a> program can be freely downloaded along with the source code in C ++.  It is a console application for Windows or Linux.  To play with a person, analyze or spar with other engines, you may need a graphical interface - for example, Arena, Winboard, or some other.  However, you can play directly from the command line, introducing moves using standard English notation. <br><br>  GreKo's self-learning function is implemented as a built-in command of the console mode (the author currently does not know other engines that support this functionality).  The vector of 27 coefficients of the evaluation function is stored in the file weights.txt.  To automatically adjust it based on a PGN file, you need to type the command learn, for example: <br><br><pre><code class="html hljs xml">White(1): learn gm2600.pgn</code> </pre> <br><br>  The program will read all batches from the specified file, create an intermediate file with training positions and break it into a training and test subset: <br><br><pre> <code class="html hljs xml">Creating file 'gm2600.fen' Games: 27202 Loading positions... Training set: 1269145 Validation set: 317155</code> </pre><br><br>  It will then save the original values ‚Äã‚Äãof the parameters to the weights.old file, and begin the optimization process.  During operation, intermediate values ‚Äã‚Äãof weights and target functionality are displayed on the screen and in the file learning.log. <br><br><pre> <code class="html hljs xml">Old values saved in file 'weights.old' Start optimization... 0 0.139618890118 0.140022159883 2016-07-21 17:01:16 Parameter 6 of 27: PawnDoubled = -10 Parameter 7 of 27: PawnIsolated = -19 1 0.139602240177 0.140008376153 2016-07-21 17:01:50 [1.7] -20 2 0.139585446564 0.139992945184 2016-07-21 17:01:58 [1.7] -21 3 0.139571113698 0.139980624436 2016-07-21 17:02:07 [1.7] -22 4 0.139559690029 0.139971803640 2016-07-21 17:02:15 [1.7] -23 5 0.139552067028 0.139965861844 2016-07-21 17:02:23 [1.7] -24 6 0.139547879916 0.139964477620 2016-07-21 17:02:32 [1.7] -25 7 0.139543242843 0.139961056939 2016-07-21 17:02:40 [1.7] -26 8 0.139542575174 0.139962314286 2016-07-21 17:02:48 [1.7] -27 Parameter 8 of 27: PawnBackwards = -5 9 0.139531995624 0.139953185941 2016-07-21 17:03:04 [1.8] -4 10 0.139523642489 0.139947035972 2016-07-21 17:03:12 [1.8] -3 11 0.139518695795 0.139943580937 2016-07-21 17:03:21 [1.8] -2 12 0.139517501456 0.139943802704 2016-07-21 17:03:29 [1.8] -1 Parameter 9 of 27: PawnCenter = 9 Parameter 10 of 27: PawnPassedFreeMax = 128 13 0.139515067927 0.139941456600 2016-07-21 17:04:00 [1.10] 129 14 0.139500815202 0.139927669884 2016-07-21 17:04:08 [1.10] 130 ...</code> </pre><br><br>  Upon completion of the training, the weights.txt file will contain the new values ‚Äã‚Äãof the weights, which will take effect the next time the program is launched. <br><br>  The learn command can contain two more arguments, the lower and upper bounds of the optimization interval.  By default, they are 6 and 27 - i.e.  all signs, except the cost of figures, are optimized.  To enable full optimization, you must specify the boundaries explicitly: <br><br><pre> <code class="html hljs xml">White(1): learn gm2600.pgn 1 27</code> </pre><br><br>  The algorithm is randomized (in terms of splitting into training and test samples), therefore, for different starts unequal vectors of coefficients can be obtained. <br><br><h3>  findings </h3><br><br>  To configure the evaluation function, we used self-learning program (reinforcement learning).  The best results were achieved by analyzing the games of the program against itself.  In fact, the only external source of chess knowledge was the opening book of the shell, necessary for the randomization of the games played. <br><br>  We were able to increase the predictive ability of the assessment, which led to a statistically significant increase in the strength of the game at different time controls, both with the previous version and with a set of independent opponents.  The improvement was 50 ... 70 points Elo. <br><br>  It is worth noting that the result was achieved in fairly modest volumes: about 20 thousand parties and 1 million positions (for comparison: AlphaGo studied on 30 million positions from parties of strong amateurs from the server, not counting further games with herself).  The evaluation function of GreKo is also very simple, and includes only 27 independent parameters.  In the strongest chess engines, their score can go on hundreds and thousands.  However, even in such an environment, machine learning methods led to success. <br><br>  Further improvement of the program could include adding new criteria to the evaluation function (in particular, taking into account the stage of the game for all the considered parameters) and using more advanced methods of multidimensional optimization (for example, searching for global extremes).  At the moment, however, the author‚Äôs plans in this direction have not yet been determined. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b82/58d/e44/b8258de4448fa9d3eb68c2b0a364c5bb.jpg" width="350"></div><br><br><h3>  Links </h3><br><ul><li>  <a href="https://habrahabr.ru/post/254753/">Determine the weight of chess pieces by regression analysis</a> - an introductory article on the material evaluation model. </li><li>  <a href="http://greko.su/">GreKo</a> is the <a href="http://greko.su/">GreKo</a> chess program, which we were engaged in in this article. </li><li>  <a href="https://chessprogramming.wikispaces.com/Texel%27s%2BTuning%2BMethod">Texel's Tuning Method</a> - a description of the basic method for optimizing the evaluation function. </li><li>  <a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf">Mastering the Game of the Deep Neural Networks and Tree Search</a> (English) - an original article on AlphaGo in Nature. </li><li>  <a href="https://habrahabr.ru/post/279071/">AlphaGo on fingers</a> - a statement of the basic principles of the AlphaGo device in Russian. </li><li>  <a href="http://arxiv.org/pdf/1509.01549v2.pdf">Giraffe: Using Deep Reinforcement Learning to Play Chess</a> (English) - An article about the Giraffe chess program. </li><li>  <a href="http://www.remi-coulom.fr/Bayesian-Elo/">bayeselo</a> is a utility for calculating ratings based on PGN files. </li></ul><br></div><p>Source: <a href="https://habr.com/ru/post/305604/">https://habr.com/ru/post/305604/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../305594/index.html">Pastilde - open hardware password manager</a></li>
<li><a href="../305596/index.html">iOS 10: new in creating animations</a></li>
<li><a href="../305598/index.html">Citrix and OpenStack History</a></li>
<li><a href="../305600/index.html">Short cheat sheet on locks when reading and changing data depending on the transaction isolation level in MSSQL</a></li>
<li><a href="../305602/index.html">Two in one: USB host and composite USB device</a></li>
<li><a href="../305606/index.html">The final hackathon of the contest "BudgetApps"</a></li>
<li><a href="../305608/index.html">OSX / Keydnap malware used to steal credentials on Apple OS X</a></li>
<li><a href="../305610/index.html">Network Infrastructure Virtualization and SDN Solution</a></li>
<li><a href="../305614/index.html">Go Way: how garbage collection accelerated</a></li>
<li><a href="../305616/index.html">Strange letters of the Russian alphabet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>