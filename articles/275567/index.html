<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Use Apache Spark as SQL Engine</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! We, Wrike , are daily confronted with a stream of data from hundreds of thousands of users. All this information is necessary to preserve, p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Use Apache Spark as SQL Engine</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/6b9/92a/816/6b992a816c524f9c945a0296451bb434.png"><br><br>  Hi, Habr!  We, <a href="https://www.wrike.com/ru%3Futm_source%3Dhabrahabr%26utm_medium%3Dblogposts%26utm_campaign%3DSparkasSqlengine">Wrike</a> , are daily confronted with a stream of data from hundreds of thousands of users.  All this information is necessary to preserve, process and extract value from them.  <a href="http://spark.apache.org/">Apache Spark</a> helps us to cope with this enormous amount of data. <br><br>  We will not give an introduction to Spark or describe its positive and negative aspects.  You can read about it <a href="http://habrahabr.ru/company/mlclass/blog/250811/">here</a> , <a href="http://habrahabr.ru/post/263491/">here</a> or in <a href="http://spark.apache.org/docs/latest/quick-start.html">official documentation</a> .  In this article, we focus on the <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL</a> library and its practical application for analyzing big data. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <a name="habracut"></a><h2>  SQL?  I did not think? </h2><br><br>  Historically, the analytics department of almost any IT company was built on the basis of experts who are well versed in both the subtleties of business and SQL.  The work of BI or the analytical department almost never does without <a href="https://ru.wikipedia.org/wiki/ETL">ETL</a> .  It, in turn, most often works with data sources that are most easily accessed using SQL. <br><br>  Wrike is no exception.  For a long time, the main source of data for us was the shards of our database, combined with ETL and <a href="http://www.google.com/analytics/">Google Analytics</a> , until we were faced with the task of analyzing user behavior based on server logs. <br><br>  One solution to this problem may be hiring programmers who will write Map-Reduce for Hadoop and provide data decision making in the company.  Why do this if we already have a whole group of qualified specialists who are fluent in SQL and understand the intricacies of the business? The alternative solution is to store everything in a relational database.  In this case, your main headache will be to support the schema of both your tables and input logs.  About the performance of the DBMS with tables of several hundred million records, we think you can not even speak. <br><br>  The solution for us was Spark SQL. <br><br><h2>  Ok, what next? </h2><br><br>  The main abstraction Spark SQL, unlike <a href="http://spark.apache.org/docs/latest/programming-guide.html">Spark RDD</a> , is the DataFrame. <br><br>  DataFrame is a distributed collection of data organized in the form of named columns.  DataFrame is conceptually similar to a table in a database, a data frame in R or <a href="http://pandas.pydata.org/">Python Pandas</a> , but, of course, optimized for distributed computing. <br><br>  DataFrame can be initialized on the basis of a variety of data sources: structured or weakly structured files, such as JSON and Parquet, regular databases via JDBC / ODBC, and many other methods through third-party connectors (for example, <a href="https://github.com/datastax/spark-cassandra-connector">Cassandra</a> ). <br><br>  DataFrame APIs are available from Scala, Java, Python, and R. From the point of view of SQL, they can be accessed as ordinary SQL tables with full support for all features of the <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual">Hive dialect</a> .  Spark SQL implements the Hive interface, so you can replace your Hive with Spark SQL without rewriting the system.  If you haven‚Äôt previously worked with Hive but are familiar with SQL, then you probably don‚Äôt need to learn anything further. <br><br><h2>  Can I connect to Spark SQL with% my-favorite-software%? </h2><br><br>  If your favorite software supports the use of arbitrary JDBC connectors, then the answer is yes.  We like <a href="http://dbeaver.jkiss.org/">DBeaver</a> , and our developers like <a href="https://www.jetbrains.com/idea/">IntelliJ IDEA</a> .  And they both connect perfectly to Thrift Server. <br><br>  <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">Thrift Server</a> is part of the standard Spark SQL installation, which turns Spark into a data provider.  Raising it is very simple: <br><br><pre><code class="bash hljs">./sbin/start-thriftserver.sh</code> </pre> <br><br>  Thrift JDBC / ODBC server is fully compatible with <a href="https://cwiki.apache.org/confluence/display/Hive/Setting%2BUp%2BHiveServer2">HiveServer2</a> and can transparently replace it with itself. <br><br>  So, for example, looks like a window connecting DBeaver to SparkSQL: <br><br><img src="https://habrastorage.org/files/cd6/dae/19a/cd6dae19a0e04895add064521f1b901d.png"><br><br><h2>  I want different data providers in one request </h2><br><br>  Easy.  Spark SQL partially expands the Hive dialect so that you can form data sources directly with SQL. <br><br>  Let's create a "table" based on the logs in json-format: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TEMPORARY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> table_form_json <span class="hljs-keyword"><span class="hljs-keyword">USING</span></span> org.apache.spark.sql.json OPTIONS (<span class="hljs-keyword"><span class="hljs-keyword">path</span></span> <span class="hljs-string"><span class="hljs-string">'/mnt/ssd1/logs/2015/09/*/*-client.json.log.gz'</span></span>)</code> </pre><br><br>  Please note that we use not just a single file, but by the mask we get the data available in a month. <br><br>  Let's do the same thing, but with our PostgreSQL database.  As data, we take not the entire table, but only the result of a specific query: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TEMPORARY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> table_from_jdbc <span class="hljs-keyword"><span class="hljs-keyword">USING</span></span> org.apache.spark.sql.jdbc OPTIONS ( <span class="hljs-keyword"><span class="hljs-keyword">url</span></span> <span class="hljs-string"><span class="hljs-string">"jdbc:postgresql://localhost/mydb?user=[username]&amp;password=[password]&amp;ssl=true"</span></span>, dbtable <span class="hljs-string"><span class="hljs-string">"(SELECT * FROM profiles where profile_id = 5) tmp"</span></span> )</code> </pre><br><br>  Now completely free we can execute a query with JOIN, and the Spark SQL Engine will do the rest of the work for us: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> table_form_json tjson <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> table_from_jdbc tjdbc <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> tjson.userid = tjdbc.user_id;</code> </pre><br><br>  It is possible to combine data sources in any order.  We use PostgreSQL databases, json-logs and parquet-files in Wrike. <br><br><img src="https://habrastorage.org/files/a6c/228/fad/a6c228fad5894da8a72814d3c4acede4.png"><br><br><h2>  Anything else? </h2><br><br>  If you, like us, are interested in not only using Spark, but also understanding how it works under the hood, we recommend paying attention to the following publications: <br><br><ul><li>  <a href="http://people.csail.mit.edu/matei/papers/2015/sigmod_spark_sql.pdf">Spark SQL: Relational Data Processing in Spark.</a>  <a href="http://people.csail.mit.edu/matei/papers/2015/sigmod_spark_sql.pdf">Michael Armbrust, Reynold S. Xin, Cheng Lian, Yin Huai, Davies Liu, Joseph K. Bradley, Xiangrui Meng, Tomer Kaftan, Michael J. Franklin, Ali Ghodsi, Matei Zaharia.</a>  <a href="http://people.csail.mit.edu/matei/papers/2015/sigmod_spark_sql.pdf">SIGMOD 2015. June 2015</a> </li><li>  <a href="http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf">Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing.</a>  <a href="http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf">Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCauley, Michael J. Franklin, Scott Shenker, Ion Stoica.</a>  <a href="http://people.csail.mit.edu/matei/papers/2012/nsdi_spark.pdf">NSDI 2012. April 2012. Best Paper Award</a> </li><li>  <a href="http://people.csail.mit.edu/matei/papers/2010/hotcloud_spark.pdf">Spark: Cluster Computing with Working Sets.</a>  <a href="http://people.csail.mit.edu/matei/papers/2010/hotcloud_spark.pdf">Matei Zaharia, Mosharaf Chowdhury, Michael J. Franklin, Scott Shenker, Ion Stoica.</a>  <a href="http://people.csail.mit.edu/matei/papers/2010/hotcloud_spark.pdf">HotCloud 2010. June 2010</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/275567/">https://habr.com/ru/post/275567/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../275553/index.html">How IaaS provider to choose a data center to host the cloud: IT-GRAD Experience</a></li>
<li><a href="../275555/index.html">We do FTP for Windows Azure Pack</a></li>
<li><a href="../275561/index.html">ASP.NET 5 is dead - introducing ASP.NET Core 1.0 and .NET Core 1.0</a></li>
<li><a href="../275563/index.html">Minimal HTTP Endpoint API using Elixir</a></li>
<li><a href="../275565/index.html">A dangerous 0day vulnerability has been discovered in the Linux kernel.</a></li>
<li><a href="../275571/index.html">FlyElephant as a tool for computing in C ++, R, Python or Octave</a></li>
<li><a href="../275573/index.html">How I obtained the status of NCDA (NetApp Certified Data Administrator, Clustered Data ONTAP 8.3)</a></li>
<li><a href="../275577/index.html">Competition GraphHPC-2016 for the fastest implementation of the parallel algorithm Community Detection</a></li>
<li><a href="../275579/index.html">Fighting geolocation services</a></li>
<li><a href="../275587/index.html">go-script that makes an audiobook from a text file using one of the best speech synthesizers - Ivona from Amazon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>