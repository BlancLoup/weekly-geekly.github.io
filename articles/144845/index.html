<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using SURF to create augmented reality marker</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Using SURF to create augmented reality marker 
 This is a continuation of the topic of augmented reality. Here is the first part . In the discussion o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using SURF to create augmented reality marker</h1><div class="post__text post__text-html js-mediator-article"><h4>  Using SURF to create augmented reality marker </h4><br>  This is a continuation of the topic of augmented reality.  Here is the <a href="http://habrahabr.ru/post/135659/">first part</a> .  In the discussion of the topic by the <a href="http://habrahabr.ru/users/inco/" class="user_link">Inco</a> user, interesting results of his work were shown in the direction of recognizing the augmented reality marker <a href="http://www.youtube.com/user/VieInco/videos">Video</a> . At that moment there was no time, but after a couple of months I wondered how it all worked, how stable the approach was, and there were free hours.  I present to you my realization of this idea, which resulted in a report on <a href="http://habrahabr.ru/events/681/">this</a> event. <br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/6JgtyOmxTps%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700191,15700253,15700255,15700259&amp;usg=ALkJrhgzywpVidVfTWKo8o5SDYWpqdwMRA" frameborder="0" allowfullscreen=""></iframe><br><a name="habracut"></a><br>  In this topic, attention will be paid to a brief summary of my report and an explanation of what was not enough time at the meeting: the source code of the program.  Those who want to fully see and listen to the presentation can use the screencast: <br><div class="slideshow"><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=http://www.slideshare.net/slideshow/embed_code/13143898&amp;xid=17259,15700021,15700186,15700191,15700253,15700255,15700259&amp;usg=ALkJrhiB33VMrClbmG6BhDhYk-T-Lo4w6g" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe></div><br><h5>  What is augmented reality? </h5><br>  First of all, I would like to highlight what augmented reality is. <br>  There is our reality - what we see with our eyes, how we interpret it, and how it really is.  In addition, there is a virtual reality.  This is what is generated, what does not exist, what they want to show you. <br>  Here at the junction of these two realities is augmented reality.  It can shift more towards our reality, then it will be augmented reality, or it can shift more towards virtuality ‚Äî then it will be a virtuality supplemented with our reality. <br><br><h5>  What is augmented reality used for now? </h5><br><img src="https://habrastorage.org/storage2/053/4d0/628/0534d06284ac49097a7118d2185365bc.jpg"><br>  Now it is used: <br><ul><li>  For presentations and demonstrations.  The first photo, the dam is shown there, this is a photo from the conference devoted to Avtokad </li><li>  Interfaces  New interfaces that do not need to be projected.  Put a hand, or something else (a piece of paper) under the camera, and you have an interface ready with which you can control the object. </li><li>  Exit to socialization.  That situation, when you drive your phone across the landscape, and you are additionally informed about this landscape. </li></ul><br><h5>  How does augmented reality work? </h5><br><img src="https://habrastorage.org/storage2/9fd/4c6/71d/9fd4c671ddc8f07dbf20808c69049eae.jpg"><br>  First of all, we have an image.  Why is the image - because a person perceives information for 70% of his eyes, that is, the image from the camera.  Further, various sensors, GPS, gyroscopes, accelerometers, compass - they all give information on the device, on its orientation and position in space. <br>  For example, knowing where you are and where your phone is looking, we can tell you what your perspective is, what you see and, accordingly, using this information, bring out the augmented reality about what you see, about what we assume that you see.  For example from the new: <br>  Further, image processing, obtaining sensor information.  In fact, everything is not so simple.  The image we get from the camera often needs to be pre-processed.  The data that the sensors give us - they are not accurate, if we take the same accelerometer, it is godlessly fonit, at high frequencies, i.e. it constantly gives us some not the data we wanted.  Similar to GPS, it has an accuracy threshold, the one who worked with GPS with mobile phones knows.  Gyroscope - everyone imagines that this is a gyroscope as in a jet aircraft, which gives a position in three planes.  Yes, it gives a position in three planes, but without a compass and an accelerometer, it will not be accurate enough.  Again, augmented reality is not only an image, augmented reality takes into account all that happens with the device. <br>  Object identification  This is the answer to the question, but what I see.  This is the most interesting, here in all this augmented reality.  Without this, these are all cool toys, i.e., twist the phone, and you have a car or a motorcycle to the left to the right, and if we identify: <br><br><ul><li>  where we are - we can draw some conclusion about the fact that we have a field of view; </li><li>  what we see - we can show something to a person in the image that he sees. </li></ul><br>  The key problem of augmented reality is what to supplement.  Identify need something.  To do this, there are recognition algorithms in mathematics and computer science.  We found the image, great.  And now we will try to find in the database of images.  So we copied the image, let's say a picture, it would be interesting to know what kind of picture it is.  This is also a difficult task.  How to build an index is also a very interesting direction in computer science, and of course, there are a lot of tasks. <br>  And now how to actually show how to give a user so that the user understands this?  This raises the question of usability. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  How to identify an object? </h5><br><img src="https://habrastorage.org/storage2/690/b22/4c6/690b224c638610ebd8bd5597cfd8deb2.jpg"><br>  Here, we got the image, and we need to identify the object, the marker, i.e., something about which we will complement.  This can be done with markers or without markers.  Here, any barcode, any sign, QR-code, this is already a marker.  The phone can recognize it and, for example, add reality, for example, a translation for ordinary characters.  For example, some information found from the Internet for a car number, a house number, etc. <br>  Geometric figure.  The classic marker of augmented reality is a square.  Why?  Because it's pretty easy to build a plane and find a homography.  Find a position in three coordinates. <br>  The graphic marker that we create, if it has a clear form, such as a square, it stands out from reality, respectively, it brings a dissonance into the interior.  If the marker is close to reality, if it enters this reality, it is better.  Photography is better than a drawn square, the picture is better than a QR code.  Now look, without markers, we can get our coordinates, position in space, and of course a graphic marker, which in fact may not be a marker.  We can recognize part of our reality and then say, yes it was our marker.  Again, you can generate an image in advance if we want people to recognize something.  We create a marker, for example a picture that we hang on the wall. <br><br><h5>  What could be a marker. </h5><br>  If we take augmented reality markers, there are several systems that have been developed since the early nineties.  Here is a <a href="http://habrahabr.ru/post/135659/">link</a> to the topic where I described in detail the augmented reality marker technologies. <br>  Here is Durer's engraving - rhino.  Can it be a marker?  Yes maybe. <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/7JUVAC3aWAI%3Ffeature%3Doembed&amp;xid=17259,15700021,15700186,15700191,15700253,15700255,15700259&amp;usg=ALkJrhhdTj8Qzvq0cMB1qtshKI_tFvmbJg" frameborder="0" allowfullscreen=""></iframe><br>  Accordingly, how?  For this, in fact, there is a method SURF.  <a href="http://habrahabr.ru/post/103107/">Here is a</a> great article that describes very well the technique of finding persistent traits. <br><img src="https://habrastorage.org/storage2/1f1/87d/e5a/1f187de5a78830157d253eee3b8476f3.jpg"><br>  If you thoughtfully understand the method, look at the source ( <a href="">one</a> , <a href="http://www.vision.ee.ethz.ch/~surf/eccv06.pdf">two</a> , <a href="">three</a> ) publications, then such conclusions will appear (for more details, see the screencast): <br><ol><li>  The method has a sensitivity that needs to be adjusted. </li><li>  The method gives false positives. </li><li>  In constructing the method, empirical coefficients are used, which also need to be adjusted for the particular case. </li><li>  The method has prerequisites for paralleling and optimization. </li></ol><br>  And the most important thing - to use in the finished application of augmented reality, it is not enough to recognize the marker, you need to be able to monitor it, make ‚Äútracking‚Äù and extinguish false alarms, anoamous outliers of points that SURF can give us, if we do tracking using these methods. <br><br><h5>  How to find the coordinates of the object in the frame and superimpose video? </h5><br>  <a href="http://habrahabr.ru/post/139429/">Here is an article</a> that describes mathematics for the three-dimensional case (when we try to impose a 3D model on our marker).  For the two-dimensional case, everything is much simpler. <br>  It is necessary at several points (four and more) to find the parameters of affine transformations, which will tell us how to compress, expand, distort the image so that the key points we have found coincide. <br><img src="https://habrastorage.org/storage2/949/0e4/708/9490e47087fd9ea9ddc47579a6f23644.jpg"><br>  This is where the danger of false positives comes from.  If we take the ‚Äúwrong‚Äù points, the result will be an incorrectly found transformation matrix, and our image will not be there.  How to deal with this - there are several approaches, but they all boil down to how to determine the anomalous levels of data in the observations.  Those.  grouping and clustering. <br><br><h5>  Code </h5><br>  To implement this program, we need the installed OpenCV library.  This code was written for Linux, but should also be compiled in Visual C. Link to source: <a href="https://skydrive.live.com/embed%3Fcid%3DBE683AD8462AAEAF%26resid%3DBE683AD8462AAEAF!219">Opensurf.zip</a> <br>  In short, what the code does: <br>  This source code is based on the <a href="http://www.chrisevansdev.com/computer-vision-opensurf.html">OpenSurf</a> project, the main.cpp file has been modified. <br>  Actually, what I would like to touch (fragments of the main.cpp file): <br><br>  Initial data: <br><pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    ,    CvCapture* capture1 = cvCaptureFromFile("imgs/ribky.avi"); //     (capture),        CvCapture* capture = cvCaptureFromFile("imgs/child_book.avi"); //CvCapture* capture = cvCaptureFromCAM( CV_CAP_ANY ); //  -  // This is the reference object we wish to find in video frame IplImage *img = cvLoadImage("imgs/marker6.png");</span></span></code> </pre> <br><br>  We get the key points: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//   img = cvQueryFrame(capture); frm_id++; //    surfDetDes(img, ipts, false, 4, 4, 2, 0.001f); //      getMatches(ipts,ref_ipts,matches);</span></span></code> </pre><br><br>  Building a frame and drawing green dots on the first forty frames is completely transparent, so go straight to overlay frames from the video: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//      frame = cvQueryFrame(capture1); //     pt1.resize(n); pt2.resize(n); //      for(int i = 0; i &lt; n; i++ ) { pt1[i] = cvPoint2D32f(matches[i].second.x, matches[i].second.y); pt2[i] = cvPoint2D32f(matches[i].first.x, matches[i].first.y); } _pt1 = cvMat(1, n, CV_32FC2, &amp;pt1[0] ); _pt2 = cvMat(1, n, CV_32FC2, &amp;pt2[0] ); //  (     ) cvFindHomography(&amp;_pt1, &amp;_pt2, &amp;_h, CV_RANSAC, 5); //  cvZero(frame1); //  ,          0,255,0 cvWarpPerspective(frame, frame1, &amp;_h, CV_WARP_FILL_OUTLIERS,cvScalar(0,255,0) ); //   0,255,0          //    = not (0,253..255,0) imagegr=cvCreateImage(cvGetSize(frame1), frame1-&gt;depth, 1); cvInRangeS(frame1, cvScalar(0, 253, 0), cvScalar(0, 255, 0), imagegr ); cvNot(imagegr, imagegr); //  ,     0,253... 255,0   cvCopy(frame1,img,imagegr);</span></span></code> </pre><br><br>  In light of the creation of Google glasses and the growing interest in augmented reality, the goal of the presentation was to describe the method, to share with people ideas and thoughts that are multiplied many times during the discussion. </div><p>Source: <a href="https://habr.com/ru/post/144845/">https://habr.com/ru/post/144845/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../144837/index.html">Herrmann Dominanz Instrument (HDI). Part I</a></li>
<li><a href="../144838/index.html">Miguel de Icaza about ASP.NET MVC, Moonlight and the trial of Android</a></li>
<li><a href="../144839/index.html">Runetology (149): publisher Woman.ru Inessa Gaevskaya</a></li>
<li><a href="../144842/index.html">Protection of American Industrial Control System</a></li>
<li><a href="../144843/index.html">Google tablet still exists</a></li>
<li><a href="../144847/index.html">Segway X2 - review and demonstration of work</a></li>
<li><a href="../144848/index.html">The dark side of QScintilla</a></li>
<li><a href="../144849/index.html">Zopo ZP100 overview, or how the Chinese learned how to make phones</a></li>
<li><a href="../144850/index.html">Binary tree traversal: recursion, iteration, and parent pointer</a></li>
<li><a href="../144852/index.html">[Translation] CSS Filters</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>