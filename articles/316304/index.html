<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to make PostgreSQL read faster</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Photo source 


 Everyone can count, but not everyone can count quickly. In this article we will take a closer look at the PostgreSQL count optimizati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to make PostgreSQL read faster</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/7ba/0b4/4b2/7ba0b44b294c4c9d8858a4062e51d519.jpg"><br><p>  <em><a href="http://www.wallpaperspick.com/baby-elephant-running-wallpaper.html">Photo source</a></em> </p><br><p>  Everyone can count, but not everyone can count quickly.  In this article we will take a closer look at the PostgreSQL <em>count</em> optimization methods.  There are techniques that can speed up the counting of the number of lines by orders of magnitude. </p><br><p>  If you approach the issue with all seriousness, you need to select several options for the <em>count</em> , each of which has its own methods.  What you need to decide: </p><br><ul><li>  whether an exact number of rows is required or an estimated value will suffice; </li><li>  whether duplicates should be taken into account or only unique values ‚Äã‚Äãare of interest; </li><li>  whether it is necessary to count all the rows of the table or it is necessary to select only those that meet a certain condition </li></ul><br><p>  We will analyze solutions for each specific situation, as well as compare their speed and resource consumption.  Having analyzed the situation from a centralized database, we will use Citus to demonstrate parallel execution of <em>count</em> in a distributed database. </p><a name="habracut"></a><br><p>  <strong>Content</strong> </p><br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">DB Preparation</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Count with duplicates</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Accurate count</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Evaluation</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Score across the table</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Estimate for the sample</a> </li></ul></li></ul></li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Distinct count (no duplicates)</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Accurate count</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Default behavior when there is insufficient memory</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Specialized aggregation</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Hashagregate</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Index-Only Scan</a> </li></ul></li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Evaluation</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">HyperLogLog</a> </li></ul></li></ul></li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Paralleling</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Cluster Setup</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Accurate count</a> <br><ul><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">With duplicates</a> </li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Distinct (no duplicates)</a> </li></ul></li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Evaluation without duplicates</a> </li></ul></li><li>  <a href="https://habr.com/ru/company/southbridge/blog/316304/">Results</a> </li></ul><br><h4 id="preparing">  DB Preparation </h4><br><p>  For the tests, we will use a database called <strong>count</strong> , for which <em>pgbench</em> is initialized: </p><br><pre><code class="bash hljs">[user@comp ~]$ pgbench -i count</code> </pre> <br><p>  Create a test table: </p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">--       CREATE TABLE items AS SELECT (random()*1000000)::integer AS n, md5(random()::text) AS s FROM generate_series(1,1000000); --        VACUUM ANALYZE;</span></span></code> </pre> <br><h4 id="dup_counts">  Count with duplicates </h4><br><h5 id="dup_counts_exact">  Accurate count </h5><br><p>  So, let's start from the beginning: let's consider getting the exact number of rows of the entire table or its part with duplicates - the good old <code>count(*)</code> .  The execution time of this command will give us a basis for estimating the speed of work of other methods of counting the number of rows. </p><br><p>  <em>Pgbench</em> is a handy tool for repeatedly running a query and collecting performance statistics. </p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#     PostgreSQL 9.5.4 echo "SELECT count(*) FROM items;" | pgbench -d count -t 50 -P 1 -f - # average 84.915 ms # stddev 5.251 ms</span></span></code> </pre> <br><p>  A note about <code>count(1)</code> vs <code>count(*)</code> .  You might think that <code>count(1)</code> faster, since <code>count(*)</code> should handle the values ‚Äã‚Äãof all columns in the current row.  In fact, the opposite is true.  Unlike the <code>SELECT *</code> construct, the asterisk in <code>count(*)</code> means nothing.  PostgreSQL treats the <code>count(*)</code> expression as a special case of <em>count</em> with no arguments.  (It would be correct to write this expression in the form of <code>count()</code> ).  On the other hand, <code>count(1)</code> takes one argument, and PostgreSQL must make sure for each line that this argument (1) is indeed not NULL. </p><br><p>  The previous test with <code>count(1)</code> produced the following results: </p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># average 98.896 ms # stddev 7.280 ms</span></span></code> </pre> <br><p>  In any case, both <code>count(1)</code> and <code>count(*)</code> by definition slow.  To ensure the consistency of concurrently running transactions, PostgreSQL uses multiversion concurrency control (MVCC) parallel control.  This means that each transaction can see different rows and even a different number of rows in the table.  Therefore, there is no single correct value for the number of rows that the DBMS could put in the cache, and the system will have to scan all the rows in order to calculate which of them can be seen in a separate transaction.  The execution time of the exact <em>count</em> grows linearly following the increase in the size of the table. </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items; Aggregate (cost=20834.00..20834.01 rows=1 width=0) -&gt; Seq Scan on items (cost=0.00..18334.00 rows=1000000 width=0)</code> </pre> <br><p>  <em>Scan</em> accounts for 88% of the cost of the request.  If you double the size of the table, then the query execution time will increase by about two times with the proportional increase in the cost of <em>scan</em> and <em>aggregate</em> . </p><br><table><tbody><tr><th>  Number of lines </th><th>  Average time </th></tr><tr><td>  1 million </td><td>  85 ms </td></tr><tr><td>  2 million </td><td>  161 ms </td></tr><tr><td>  4 million </td><td>  343 ms </td></tr></tbody></table><br><p>  How to speed it up?  There are two options: decide that the estimated value is enough for us, or put the number of lines in the cache on our own.  In the second case, we will have to separately store the values ‚Äã‚Äãfor each table and each <em>WHERE clause</em> for which we want to quickly perform <em>count</em> . </p><br><p>  Let's look at an example of manually caching the value of <code>count(*)</code> for the entire <code>items</code> table.  The following trigger-based solution is an adaptation of the <a href="http://www.varlena.com/GeneralBits/120.php">method proposed by A. Elein Mustain</a> .  The MVCC PostgreSQL engine will maintain consistency between <code>items</code> and a table containing the number of rows. </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">BEGIN</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> row_counts ( relname <span class="hljs-built_in"><span class="hljs-built_in">text</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, reltuples <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span> ); <span class="hljs-comment"><span class="hljs-comment">--       INSERT INTO row_counts (relname, reltuples) VALUES ('items', (SELECT count(*) from items)); CREATE OR REPLACE FUNCTION adjust_count() RETURNS TRIGGER AS $$ DECLARE BEGIN IF TG_OP = 'INSERT' THEN EXECUTE 'UPDATE row_counts set reltuples=reltuples +1 where relname = ''' || TG_RELNAME || ''''; RETURN NEW; ELSIF TG_OP = 'DELETE' THEN EXECUTE 'UPDATE row_counts set reltuples=reltuples -1 where relname = ''' || TG_RELNAME || ''''; RETURN OLD; END IF; END; $$ LANGUAGE 'plpgsql'; CREATE TRIGGER items_count BEFORE INSERT OR DELETE ON items FOR EACH ROW EXECUTE PROCEDURE adjust_count(); COMMIT;</span></span></code> </pre> <br><p>  The speed of reading and updating cached values ‚Äã‚Äãin this case does not depend on the size of the table, and getting the value of the number of rows is very fast.  However, this technique increases the overhead of inserts and deletes.  Without a trigger, the following command runs 4.7 seconds, while as an insert with a trigger it is <em>fifty times slower</em> : </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> items (n, s) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> (random()*<span class="hljs-number"><span class="hljs-number">1000000</span></span>)::<span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> n, <span class="hljs-keyword"><span class="hljs-keyword">md5</span></span>(random()::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1000000</span></span>);</code> </pre> <br><h5 id="dup_counts_estimated">  Evaluation </h5><br><h6 id="dup_counts_estimated_full">  Score across the table </h6><br><p>  The approach in which we cache the number of rows in a table slows down the insert operation.  If, instead of the exact number, we are ready to be satisfied with the estimated value, then there is an opportunity to get quick read operations without deteriorating the insert operation time.  For this we can use the service data collected by PostgreSQL.  Their sources are <a href="https://www.postgresql.org/docs/9.5/static/monitoring-stats.html">stats collector</a> and <a href="https://www.postgresql.org/docs/9.5/static/routine-vacuuming.html">autovacuum daemon</a> . </p><br><p>  Options for obtaining estimated values: </p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">--   "stats collector" SELECT n_live_tup FROM pg_stat_all_tables WHERE relname = 'items'; --  VACUUM  ANALYZE SELECT reltuples FROM pg_class WHERE relname = 'items';</span></span></code> </pre> <br><p>  But there is a more reliable source, the data in which are updated more often.  Andrew Gierth (RhodiumToad) recommends: </p><br><blockquote>  Remember: the scheduler does not actually use <em>reltuples</em> ;  it multiplies the <em>reltuples / relpages ratio</em> by the current number of pages. </blockquote><p>  The logic is as follows: as the amount of data in a table increases, the average number of rows that fit into a physical page will generally not change as much as their total number.  To get a more accurate estimate of the current number of rows, we can multiply the average number of rows by the actual information about the current number of pages occupied by the table. </p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">-- pg_relation_size  block_size   , --        --      SELECT (reltuples/relpages) * ( pg_relation_size('items') / (current_setting('block_size')::integer) ) FROM pg_class where relname = 'items';</span></span></code> </pre> <br><h6 id="dup_counts_estimated_filtered">  Estimate for the sample </h6><br><p>  In the previous section, we looked at how to obtain an estimated number of rows for an entire table, but is it possible to do the same, but only for rows matching the <code>WHERE</code> condition?  Michael Fuhr came up with an interesting <a href="">way</a> : run <code>EXPLAIN</code> for the query and analyze the result. </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FUNCTION</span></span> count_estimate(<span class="hljs-keyword"><span class="hljs-keyword">query</span></span> <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">RETURNS</span></span> <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> $$ <span class="hljs-keyword"><span class="hljs-keyword">DECLARE</span></span> rec <span class="hljs-built_in"><span class="hljs-built_in">record</span></span>; rows integer; <span class="hljs-keyword"><span class="hljs-keyword">BEGIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FOR</span></span> rec <span class="hljs-keyword"><span class="hljs-keyword">IN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXECUTE</span></span> <span class="hljs-string"><span class="hljs-string">'EXPLAIN '</span></span> || <span class="hljs-keyword"><span class="hljs-keyword">query</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LOOP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> := <span class="hljs-keyword"><span class="hljs-keyword">substring</span></span>(rec.<span class="hljs-string"><span class="hljs-string">"QUERY PLAN"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-string"><span class="hljs-string">' rows=([[:digit:]]+)'</span></span>); EXIT WHEN rows IS NOT NULL; <span class="hljs-keyword"><span class="hljs-keyword">END</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LOOP</span></span>; RETURN rows; <span class="hljs-keyword"><span class="hljs-keyword">END</span></span>; $$ LANGUAGE plpgsql VOLATILE STRICT;</code> </pre> <br><p>  This function can be used as follows: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count_estimate(<span class="hljs-string"><span class="hljs-string">'SELECT 1 FROM items WHERE n &lt; 1000'</span></span>);</code> </pre> <br><p>  The accuracy of this method depends on the scheduler, which uses various <a href="https://www.postgresql.org/docs/9.5/static/row-estimation-examples.html">methods</a> to evaluate the selectivity of the <code>WHERE</code> , and from where the number of rows returned by the query can be obtained. </p><br><h4 id="distinct_counts">  Distinct count (no duplicates) </h4><br><h5 id="distinct_counts_exact">  Accurate count </h5><br><h6 id="distinct_counts_exact_def">  Default behavior when there is insufficient memory </h6><br><p>  Duplicate <em>count</em> can be slow, but <em>count distinct is</em> much worse.  With limited working memory and no indexes, PostgreSQL is not able to perform optimization efficiently.  In the default configuration, the DBMS imposes a hard limit on each parallel request ( <code>work_mem</code> ).  On the computer I use for development, this default value was set at 4 megabytes. </p><br><p>  Let's estimate the performance of working with a million lines on the <code>work_mem</code> factory settings. </p><br><pre> <code class="sql hljs">echo "<span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> n) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items;" | pgbench -d count -t 50 -P 1 -f - <span class="hljs-comment"><span class="hljs-comment"># average 742.855 ms # stddev 21.907 ms echo "SELECT count(DISTINCT s) FROM items;" | pgbench -d count -t 5 -P 1 -f - # average 31747.337 ms # stddev 267.183 ms</span></span></code> </pre> <br><p>  Running <code>EXPLAIN</code> shows that most of the query execution time was spent on aggregation.  Also note that the counting of the number of rows in a <em>text</em> type column is much slower than in the integer one: </p><br><img src="https://habrastorage.org/files/501/8ef/7bc/5018ef7bc1a04d1db91aad4cbfffee2f.png"><br><p><br></p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">--     "integer", n Aggregate (cost=20834.00..20834.01 rows=1 width=4) (actual time=860.620..860.620 rows=1 loops=1) Output: count(DISTINCT n) Buffers: shared hit=3904 read=4430, temp read=1467 written=1467 -&gt; Seq Scan on public.items (cost=0.00..18334.00 rows=1000000 width=4) (actual time=0.005..107.702 rows=1000000 loops=1) Output: n, s Buffers: shared hit=3904 read=4430 --     "text", s Aggregate (cost=20834.00..20834.01 rows=1 width=33) (actual time=31172.340..31172.340 rows=1 loops=1) Output: count(DISTINCT s) Buffers: shared hit=3936 read=4398, temp read=5111 written=5111 -&gt; Seq Scan on public.items (cost=0.00..18334.00 rows=1000000 width=33) (actual time=0.005..142.276 rows=1000000 loops=1) Output: n, s Buffers: shared hit=3936 read=4398</span></span></code> </pre> <br><p>  What happens inside the "aggregate"?  The description of this procedure in the output of <code>EXPLAIN</code> opaque.  Understanding the situation helps to analyze a similar request.  Replace <code>count distinct</code> by <code>select distinct</code> . </p><br><img src="https://habrastorage.org/files/862/fca/e78/862fcae78e044950b38e9f16cf648952.png"><br><p><br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span>, VERBOSE) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items; Unique (cost=131666.34..136666.34 rows=498824 width=4) (actual time=766.775..1229.040 rows=631846 loops=1) Output: n -&gt; Sort (cost=131666.34..134166.34 rows=1000000 width=4) (actual time=766.774..1075.712 rows=1000000 loops=1) Output: n Sort Key: items.n Sort Method: external <span class="hljs-keyword"><span class="hljs-keyword">merge</span></span> Disk: <span class="hljs-number"><span class="hljs-number">13632</span></span>kB -&gt; Seq <span class="hljs-keyword"><span class="hljs-keyword">Scan</span></span> <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> public.items (<span class="hljs-keyword"><span class="hljs-keyword">cost</span></span>=<span class="hljs-number"><span class="hljs-number">0.00</span></span>.<span class="hljs-number"><span class="hljs-number">.18334</span></span><span class="hljs-number"><span class="hljs-number">.00</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>=<span class="hljs-number"><span class="hljs-number">1000000</span></span> width=<span class="hljs-number"><span class="hljs-number">4</span></span>) (actual <span class="hljs-built_in"><span class="hljs-built_in">time</span></span>=<span class="hljs-number"><span class="hljs-number">0.006</span></span>.<span class="hljs-number"><span class="hljs-number">.178</span></span><span class="hljs-number"><span class="hljs-number">.153</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>=<span class="hljs-number"><span class="hljs-number">1000000</span></span> loops=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Output</span></span>: n</code> </pre> <br><p>  Under conditions of insufficient <em>work_mem</em> and the absence of external data structures (eg, indexes), PostgreSQL performs a <em>merge-sort</em> table between memory and disk, and then runs through the result, removing duplicates, that is, acting in much the same way as the classic Unix combination <code>sort | uniq</code>  <code>sort | uniq</code> . </p><br><p>  Most of the time the query is executed is sorting, especially when we use not the integer column <code>n</code> , but the string <code>s</code> .  The removal of duplicates (unique filter) in both cases is performed at approximately the same speed. </p><br><h6 id="distinct_counts_exact_custom">  Specialized aggregation </h6><br><p>  To calculate the number of unique values, Thomas Vondra created a specialized aggregation method that works with types of limited length (must not exceed 64 bits).  This method, even without increasing the working memory or creating indexes, is faster than the default method based on sorting.  To install, follow these steps: </p><br><ol><li>  Create a copy of the <a href="https://github.com/tvondra/count_distinct">tvondra / count_distinct project</a> . </li><li>  Switch to the stable branch: <code>git checkout REL2_0_STABLE</code> . </li><li>  Run <code>make install</code> . </li><li>  In your database run: <code>CREATE EXTENSION. count_distinct;</code> <code>CREATE EXTENSION. count_distinct;</code>  . </li></ol><br><p>  In this <a href="https://blog.pgaddict.com/posts/count-distinct-improvements">article,</a> Thomas explains how aggregation works.  I can only briefly say that his method creates in memory a sorted array of unique elements, compacting it in the process. </p><br><pre> <code class="sql hljs">echo "<span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> COUNT_DISTINCT(n) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items;" | pgbench -d count -t 50 -P 1 -f - <span class="hljs-comment"><span class="hljs-comment"># average 434.726 ms # stddev 19.955 ms</span></span></code> </pre> <br><p>  This works faster than the standard <em>count distinct</em> , which on our test data is performed on average 742 ms.  Note that extensions written in C, such as <em>count_distinct</em> , are not limited to the <em>work_mem</em> parameter, so an array created by a process may take more memory per connection than you originally planned. </p><br><h6 id="distinct_counts_exact_hash">  Hashagregate </h6><br><p>  If all recalculated columns fit in <em>work_mem</em> , to get unique values, PostgreSQL will apply a hash table: </p><br><img src="https://habrastorage.org/files/e2d/5ec/11b/e2d5ec11b5e14268a3d93b850500276b.png"><br><p><br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> work_mem=<span class="hljs-string"><span class="hljs-string">'1GB'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items; HashAggregate (cost=20834.00..25822.24 rows=498824 width=4) Group Key: n -&gt; Seq Scan on items (cost=0.00..18334.00 rows=1000000 width=4)</code> </pre> <br><p>  This is the fastest method we have reviewed.  It runs an average of 372 ms for <code>n</code> and 23 seconds for <code>s</code> .  <code>select distinct n</code> and <code>select count(distinct n)</code> queries will work for about the same amount of time, provided that <code>count distinct</code> aggregation also applies HashAggregate. </p><br><p>  Be careful: setting a high working memory limit can have unpleasant consequences, since <code>work_mem</code> applies to every parallel request.  In addition, we can come up with something better. </p><br><h6 id="distinct_counts_exact_index">  Index-Only Scan </h6><br><p>  This feature appeared in PostgreSQL 9.2.  If the index contains all the data needed for the query, the system can only use it, without touching the table itself (‚Äúthe heap‚Äù).  The index type must support an <em>index-only scan</em> (for example, <em>btree</em> ).  <em>GiST</em> and <em>SP-GiST</em> indexes support <em>index-only scan</em> only for some classes of operators. </p><br><p>  Create a btree index for columns <code>n</code> and <code>s</code> : </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INDEX</span></span> items_n_idx <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> items <span class="hljs-keyword"><span class="hljs-keyword">USING</span></span> btree (n); <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INDEX</span></span> items_s_idx <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> items <span class="hljs-keyword"><span class="hljs-keyword">USING</span></span> btree (s);</code> </pre> <br><p>  A different strategy is now used to select unique values ‚Äã‚Äãfrom these columns: </p><br><img src="https://habrastorage.org/files/c8b/aa2/c18/c8baa2c18d4445a3ad50427c0aa5dd3b.png"><br><p><br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items; Unique (cost=0.42..28480.42 rows=491891 width=4) -&gt; Index Only Scan using items_n_idx on items (cost=0.42..25980.42 rows=1000000 width=4)</code> </pre> <br><p>  But here we come across a strange problem: <code>SELECT COUNT(DISTINCT n) FROM items</code> will not use the index, despite the fact that <code>SELECT DISTINCT n</code> does this by default.  By following the tips on blogs ( <em>‚ÄúThe trick that will speed up your postgres 50x times!‚Äù</em> ), You can give a hint to the planner by rewriting the <code>count distinct</code> in the form of a <code>count</code> on a subquery: </p><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">-- SELECT COUNT(DISTINCT n) FROM items; --      EXPLAIN SELECT COUNT(*) FROM (SELECT DISTINCT n FROM items) t; Aggregate (cost=34629.06..34629.07 rows=1 width=0) -&gt; Unique (cost=0.42..28480.42 rows=491891 width=4) -&gt; Index Only Scan using items_n_idx on items (cost=0.42..25980.42 rows=1000000 width=4)</span></span></code> </pre> <br><p>  Symmetric (in-order) traversal of a binary tree is performed quickly.  This request takes on average 177 ms (270 ms for column <code>s</code> ). </p><br><p>  <em>Remark</em>  If the <em>work_mem</em> value <em>is</em> sufficient to hold the entire table, PostgreSQL will select HashAggregate even if there is an index.  The paradox turns out: allocating more memory to the system can lead to the choice of the worst query plan.  It is possible to force the selection of <em>index-only scan</em> by setting <code>SET enable_hashagg=false;</code>  , but do not forget to return it back to <em>true</em> , so as not to spoil the plans of other requests. </p><br><h5 id="distinct_counts_estimated">  Evaluation </h5><br><h6 id="distinct_counts_estimated_hll">  HyperLogLog </h6><br><p>  The methods discussed earlier depend on indices, hash tables, sorted arrays in memory, or refer to the statistical tables of a centralized database.  When data becomes really a lot and / or they are divided among several nodes of a distributed database, these methods cease to suit us. </p><br><p>  In this case, probabilistic data structures that are able to give rapid approximate estimates and are well parallelized come to the rescue.  Let's try one of these structures at <em>count distinct</em> .  Consider a mechanism for estimating the number of elements (cardinality estimator) called HyperLogLog (HLL).  It uses a small amount of memory to represent a set of elements.  The join operation in this mechanism works without loss, which allows you to combine arbitrary HLL values ‚Äã‚Äãwithout losing the accuracy of quantity estimation. </p><br><p>  HLL uses the properties of ‚Äúgood‚Äù hash functions, in particular the distance between the hashed values.  A function that evenly distributes values ‚Äã‚Äãtends to carry them as far as possible.  As new hashes are added, free space becomes smaller, and the elements begin to cling to each other.  By analyzing the smallest distances between the hashed values, the algorithm can estimate the most probable number of source elements. </p><br><p>  Let's measure the speed.  First install the extension for PostgreSQL. </p><br><ol><li>  Create a copy of the <a href="https://github.com/aggregateknowledge/postgresql-hll">postgresql-hll</a> project. </li><li>  Run <code>make install</code> . </li><li>  Create the <em>hll</em> extension in your database: <code>CREATE EXTENSION hll;</code>  . </li></ol><br><p>  HLL performs fast data aggregation with sequential table scans: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-comment"><span class="hljs-comment">#hll_add_agg(hll_hash_integer(n)) FROM items; Aggregate (cost=23334.00..23334.01 rows=1 width=4) -&gt; Seq Scan on items (cost=0.00..18334.00 rows=1000000 width=4)</span></span></code> </pre> <br><p>  The average HLL speed when performing <code>count distinct</code> was 239 ms in column <code>n</code> and 284 ms in <code>s</code> .  It turned out a little slower than <em>index-only scan</em> on one million records.  The real power of the HLL is manifested due to its associative and commutative unification operations, which pass without loss.  This means that they can be executed in parallel and be combined to calculate the final result. </p><br><h4 id="cluster">  Paralleling </h4><br><p>  Applications that collect analytics in real time, such as, for example, Google Analytics, actively use <em>count</em> , and this operation is well parallelized.  In this section, we will measure the performance of several methods of counting the number of rows based on a small Citus cluster deployed in the <a href="https://www.citusdata.com/product/cloud">Citus Cloud</a> . </p><br><p>  The idea is to deploy the distributed database nodes on multiple machines.  The nodes will have the same scheme, and each of them will contain part of a common data set (shard).  Counting the number of rows will be performed in parallel, i.e., simultaneously on different machines. </p><br><h5 id="cluster_setup">  Cluster Setup </h5><br><p>  For the test, we will make only a small cluster, since our goal is to evaluate comparative performance, and not to get the maximum speed. </p><br><p>  In Citus Cloud, I made a cluster of eight machines, choosing the weakest possible configuration for each of them.  If you want to reproduce this example, <a href="https://console.citusdata.com/users/sign_up">register</a> yourself <a href="https://console.citusdata.com/users/sign_up">here</a> . </p><br><p>  After creating the cluster, I connect to the coordinating node to execute SQL queries.  First create a table. </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> items ( n <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span>, s <span class="hljs-built_in"><span class="hljs-built_in">text</span></span> );</code> </pre> <br><p>  At the moment the table exists only in the database of the coordinator.  We need to break the table and place its parts on the working nodes.  Citus assigns each row to a specific segment (shard) by processing the values ‚Äã‚Äãin the selected <em>column for distribution</em> .  In the example below, we set the task for him to distribute future rows in the <em>items</em> table, using hashes of values ‚Äã‚Äãin column <code>n</code> to determine whether they belong to a particular segment. </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> master_create_distributed_table(<span class="hljs-string"><span class="hljs-string">'items'</span></span>, <span class="hljs-string"><span class="hljs-string">'n'</span></span>, <span class="hljs-string"><span class="hljs-string">'hash'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> master_create_worker_shards(<span class="hljs-string"><span class="hljs-string">'items'</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre> <br><p>  With the help of the coordinating node, we load random data into the database segments.  (Citus also supports <a href="https://www.citusdata.com/blog/2016/09/22/announcing-citus-mx/">MX</a> , masterless mode, which is used to quickly load data, but now it does not interest us). </p><br><p>  After obtaining the URL of the cluster coordinator database, execute the following code on a computer with a fast network connection.  (All generated data will be transmitted over the network from this machine, so you need good speed.) </p><br><pre> <code class="sql hljs">cat &lt;&lt; EOF &gt; randgen.sql COPY ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> (random()*<span class="hljs-number"><span class="hljs-number">100000000</span></span>)::<span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> n, <span class="hljs-keyword"><span class="hljs-keyword">md5</span></span>(random()::<span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">100000000</span></span>) ) <span class="hljs-keyword"><span class="hljs-keyword">TO</span></span> STDOUT; EOF psql $CITUS_URL -q -f randgen.sql | \ psql $CITUS_URL -c "COPY items (n, s) FROM STDIN"</code> </pre> <br><p>  In the central database example, we used a million rows.  This time, let's take a hundred million. </p><br><h5 id="cluster_exact">  Accurate count </h5><br><h6 id="cluster_exact_dup">  With duplicates </h6><br><p>  Normal <em>count</em> (without duplicates) does not cause problems.  The coordinator performs the query on all nodes, and then summarizes the results.  The <code>EXPLAIN</code> output shows the plan selected on one of the work nodes (‚ÄúDistributed Query‚Äù) and the plan selected on the coordinator (‚ÄúMaster Query‚Äù). </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> VERBOSE <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items; Distributed Query into pg_merge_job_0003 Executor: Real-Time Task Count: 32 Tasks Shown: One of 32 -&gt; Task Node: host=*** port=5432 dbname=citus -&gt; Aggregate (cost=65159.34..65159.35 rows=1 width=0) Output: count(*) -&gt; Seq Scan on public.items_102009 items (cost=0.00..57340.27 rows=3127627 width=0) Output: n, s Master Query -&gt; Aggregate (cost=0.00..0.02 rows=1 width=0) Output: (sum(intermediate_column_3_0))::bigint -&gt; Seq Scan on pg_temp_2.pg_merge_job_0003 (cost=0.00..0.00 rows=0 width=0) Output: intermediate_column_3_0</code> </pre> <br><p>  For reference: on our cluster, this query takes 1.2 seconds.  <em>Distinct count</em> is a more serious problem when working with a distributed database. </p><br><h6 id="cluster_exact_distinct">  Distinct (no duplicates) </h6><br><p>  The difficulty in calculating the unique values ‚Äã‚Äãof a column in a distributed database is that duplicates should be searched on different nodes.  However, this is a problem if you count the values ‚Äã‚Äãin the distribution column.  Rows with the same values ‚Äã‚Äãin this column will fall into one segment, thus avoiding intersegment duplication. </p><br><p>  Citus knows that in order to calculate the unique values ‚Äã‚Äãin the distribution column, you need to perform a <code>count distinct</code> query on each node and add the results.  Our cluster performs this task in 3.4 seconds. </p><br><p>  Finding the number of unique values ‚Äã‚Äãin a conventional column (non-distribution) is more difficult.  Logically, there are two possibilities: </p><br><ol><li>  Copy all the lines to the coordinating node and count there. </li><li>     ,        ,         ,    ,    . </li></ol><br><p>         .                . </p><br><p>    ¬´¬ª (repartitioning).    , ,    ,      .           ,      .       .     Citus     ,       . </p><br><h5 id="cluster_estimated">    </h5><br><p>   ,   HLL,     .           (non-distribution),         .   HLL             .     HLL   ,   ,        . </p><br><p>  Citus      postgresql-hll.   <em>citus.count_distinct_error_rate</em>   ,  Citus     <em>count distinct</em>   HLL.  For example: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> citus.count_distinct_error_rate = <span class="hljs-number"><span class="hljs-number">0.005</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> VERBOSE <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">DISTINCT</span></span> n) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> items; Distributed Query into pg_merge_job_0090 Executor: Real-Time Task Count: 32 Tasks Shown: One of 32 -&gt; Task Node: host=*** port=5432 dbname=citus -&gt; Aggregate (cost=72978.41..72978.42 rows=1 width=4) Output: hll_add_agg(hll_hash_integer(n, 0), 15) -&gt; Seq Scan on public.items_102009 items (cost=0.00..57340.27 rows=3127627 width=4) Output: n, s Master Query -&gt; Aggregate (cost=0.00..0.02 rows=1 width=0) Output: (hll_cardinality(hll_union_agg(intermediate_column_90_0)))::bigint -&gt; Seq Scan on pg_temp_2.pg_merge_job_0090 (cost=0.00..0.00 rows=0 width=0) Output: intermediate_column_90_0</code> </pre> <br><p>   : 3,2    <code>n</code>  3,8    <code>s</code> .    100     (non-distribution) ! HLL ‚Äî             . </p><br><h4 id="reference">  Results </h4><br><table><tbody><tr><th>  Method </th><th> /1   </th><th>  </th><th>  </th><th>  Unique </th></tr><tr><td> PG Stats </td><td> 0,3  </td><td>  - </td><td>  - </td><td>  - </td></tr><tr><td>  EXPLAIN </td><td> 0,3  </td><td>  - </td><td>  + </td><td>  - </td></tr><tr><td>   </td><td> 2  (  ) </td><td>  + </td><td>  - </td><td>  - </td></tr><tr><td> count(*) </td><td> 85  </td><td>  + </td><td>  + </td><td>  - </td></tr><tr><td> count(1) </td><td> 99  </td><td>  + </td><td>  + </td><td>  - </td></tr><tr><td> Index Only Scan </td><td> 177  </td><td>  + </td><td>  + </td><td>  + </td></tr><tr><td> HLL </td><td> 239  </td><td>  - </td><td>  + </td><td>  + </td></tr><tr><td> HashAgg </td><td> 372  </td><td>  + </td><td>  + </td><td>  + </td></tr><tr><td> Custom Agg </td><td> 435  ( 64-bit) </td><td>  + </td><td>  + </td><td>  + </td></tr><tr><td> Mergesort </td><td> 742  </td><td>  + </td><td>  + </td><td>  + </td></tr></tbody></table><br><p>   <em>index-only scan</em>         , HyperLogLog (HLL)       (&gt; 100 ).       ,       (distinct count)       . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/316304/">https://habr.com/ru/post/316304/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../316294/index.html">An exciting life story of how we improved service, with a tie, climax and deep morality.</a></li>
<li><a href="../316296/index.html">How I hacked my ip camera and found a backdoor there</a></li>
<li><a href="../316298/index.html">How they wrote their first game and what mistakes could have been avoided. Part 1. Idea</a></li>
<li><a href="../316300/index.html">RamQA # 06 - November 29 at 19:00</a></li>
<li><a href="../316302/index.html">Automate the publication of the application on Google Play - directly from Android Studio</a></li>
<li><a href="../316306/index.html">[Peter, Announcement] Meeting JUG.ru with Andrei Ershov: ‚ÄúHow we made a phone platform using GridGain‚Äù</a></li>
<li><a href="../316308/index.html">Modular CSS: - The toolkit that we have now in the arsenal is just a fairy tale</a></li>
<li><a href="../316310/index.html">From an arbitrator to a company owner with a turnover of $ 100 million</a></li>
<li><a href="../316312/index.html">Apple Watch Application Market: Forecasts and Facts</a></li>
<li><a href="../316314/index.html">FIAS addresses in the PostgreSQL environment. Part 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>