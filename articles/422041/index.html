<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural networks in Android, Google ML Kit and not only</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="So, you have developed and trained your neural network to perform some task (for example, the same object recognition through the camera) and want to ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural networks in Android, Google ML Kit and not only</h1><div class="post__text post__text-html js-mediator-article">  So, you have developed and trained your neural network to perform some task (for example, the same object recognition through the camera) and want to embed it in your application on android?  Then welcome under the cat! <br><a name="habracut"></a><br>  To begin with, it should be understood that the android is currently able to work only with networks of the TensorFlowLite format, which means we need to carry out some manipulations with the original network.  Suppose you already have a trained network in a Keras or Tensorflow framework.  You must save the grid in pb format. <br><br>  Let's start with the case when you write to Tensorflow, then everything is a little easier. <br><br><pre><code class="python hljs">saver = tf.train.Saver() tf.train.write_graph(session.graph_def, path_to_folder, <span class="hljs-string"><span class="hljs-string">"net.pb"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) tf.train.write_graph(session.graph_def, path_to_folder, <span class="hljs-string"><span class="hljs-string">"net.pbtxt"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) saver.save(session,path_to_folder+<span class="hljs-string"><span class="hljs-string">"model.ckpt"</span></span>)</code> </pre> <br>  If you are writing to Keras, you need to create a new session object at the beginning of the file where you train the network, save the link to it, and pass it to the set_session function 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K session = K.get_session() K.set_session(session)</code> </pre> <br>  Great, you saved the network, now you need to convert it to tflite format.  To do this, we need to run two small scripts, the first one will ‚Äúfreeze‚Äù the network, the second one will already translate into the required format.  The essence of the ‚Äúfreeze‚Äù is that tf does not store the weight of the layers in the saved pb file, but saves them in special checkpoints.  For subsequent conversion to tflite, it is necessary that all information about the neural network be in one file. <br><br><pre> <code class="bash hljs">freeze_graph --input_binary=<span class="hljs-literal"><span class="hljs-literal">false</span></span> --input_graph=net.pbtxt --output_node_names=result/Softmax --output_graph=frozen_graph.pb --input_checkpoint=model.ckpt</code> </pre><br>  Note that you need to know the name of the output tensor.  In tensorflow, you can set it yourself; if using Keras, set the name in the layer constructor <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>,activation=<span class="hljs-string"><span class="hljs-string">"softmax"</span></span>,name=<span class="hljs-string"><span class="hljs-string">"result"</span></span>))</code> </pre><br>  In this case, the tensor name usually looks like ‚Äúresult / Softmax‚Äù <br><br>  If not in your case, you can find the name as follows <br><br><pre> <code class="python hljs">[print(n.name) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> session.graph.as_graph_def().node]</code> </pre><br>  It remains to run the second script <br><br><pre> <code class="bash hljs">toco --graph_def_file=frozen-graph.pb --output_file=model.tflite --output_format=TFLITE --inference_type=FLOAT --input_arrays=input_input --output_arrays=result/Softmax --input_shapes=1,784</code> </pre><br>  Hooray!  Now you have a TensorFlowLite model in your folder, it‚Äôs easy to integrate it correctly into your Android application.  You can do this with the new-fashioned Firebase ML Kit, but there is another way, about it a little later.  Add a dependency to our gradle file <br><br><pre> <code class="hljs ruby">dependencies { <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> ... implementation <span class="hljs-string"><span class="hljs-string">'com.google.firebase:firebase-ml-model-interpreter:16.2.0'</span></span> }</code> </pre><br>  Now you need to decide whether you will keep the model somewhere on your server or supply it with the application. <br><br>  Consider the first case: a model on the server.  First of all, do not forget to add to the manifest <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.INTERNET"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre><br><pre> <code class="java hljs"> <span class="hljs-comment"><span class="hljs-comment">//      ,   /  FirebaseModelDownloadConditions.Builder conditionsBuilder = new FirebaseModelDownloadConditions.Builder().requireWifi(); if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.N) { conditionsBuilder = conditionsBuilder .requireCharging(); } FirebaseModelDownloadConditions conditions = conditionsBuilder.build(); //   FirebaseCloudModelSource ,   (    ,  //   Firebase) FirebaseCloudModelSource cloudSource = new FirebaseCloudModelSource.Builder("my_cloud_model") .enableModelUpdates(true) .setInitialDownloadConditions(conditions) .setUpdatesDownloadConditions(conditions) .build(); FirebaseModelManager.getInstance().registerCloudModelSource(cloudSource);</span></span></code> </pre><br>  If you are using the model included in the application locally, do not forget to add the following entry to the build.gradle file so that the model file does not compress. <br><br><pre> <code class="hljs ruby">android { <span class="hljs-regexp"><span class="hljs-regexp">//</span></span> ... aaptOptions { noCompress <span class="hljs-string"><span class="hljs-string">"tflite"</span></span> } }</code> </pre><br>  After that, by analogy with the model in the cloud, our local neuron needs to be registered. <br><br><pre> <code class="java hljs">FirebaseLocalModelSource localSource = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FirebaseLocalModelSource.Builder(<span class="hljs-string"><span class="hljs-string">"my_local_model"</span></span>) .setAssetFilePath(<span class="hljs-string"><span class="hljs-string">"mymodel.tflite"</span></span>) .build(); FirebaseModelManager.getInstance().registerLocalModelSource(localSource);</code> </pre><br>  The code above assumes that your model is in the assets folder, if not, instead of <br><br><pre> <code class="java hljs"> .setAssetFilePath(<span class="hljs-string"><span class="hljs-string">"mymodel.tflite"</span></span>)</code> </pre><br>  use <br><br><pre> <code class="java hljs"> .seFilePath(filePath)</code> </pre><br>  Then we create new FirebaseModelOptions and FirebaseModelInterpreter objects. <br><br><pre> <code class="java hljs">FirebaseModelOptions options = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FirebaseModelOptions.Builder() .setCloudModelName(<span class="hljs-string"><span class="hljs-string">"my_cloud_model"</span></span>) .setLocalModelName(<span class="hljs-string"><span class="hljs-string">"my_local_model"</span></span>) .build(); FirebaseModelInterpreter firebaseInterpreter = FirebaseModelInterpreter.getInstance(options);</code> </pre> <br>  You can use both local and server-based models at the same time.  In this case, the default cloud will be used if it is available, otherwise local. <br><br>  Almost everything, it remains to create arrays for input / output data, and run! <br><br><pre> <code class="java hljs">FirebaseModelInputOutputOptions inputOutputOptions = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FirebaseModelInputOutputOptions.Builder() .setInputFormat(<span class="hljs-number"><span class="hljs-number">0</span></span>, FirebaseModelDataType.BYTE, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">640</span></span>, <span class="hljs-number"><span class="hljs-number">480</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>}) .setOutputFormat(<span class="hljs-number"><span class="hljs-number">0</span></span>, FirebaseModelDataType.FLOAT32, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>}) .build(); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[][][][] input = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">640</span></span>][<span class="hljs-number"><span class="hljs-number">480</span></span>][<span class="hljs-number"><span class="hljs-number">3</span></span>]; input = getYourInputData(); FirebaseModelInputs inputs = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FirebaseModelInputs.Builder() .add(input) <span class="hljs-comment"><span class="hljs-comment">// add() as many input arrays as your model requires .build(); Task&lt;FirebaseModelOutputs&gt; result = firebaseInterpreter.run(inputs, inputOutputOptions) .addOnSuccessListener( new OnSuccessListener&lt;FirebaseModelOutputs&gt;() { @Override public void onSuccess(FirebaseModelOutputs result) { // ... } }) .addOnFailureListener( new OnFailureListener() { @Override public void onFailure(@NonNull Exception e) { // Task failed with an exception // ... } }); float[][] output = result.&lt;float[][]&gt;getOutput(0); float[] probabilities = output[0];</span></span></code> </pre><br>  If you do not want to use Firebase for some reason, there is another way, call the tflite interpreter and feed it directly. <br><br>  Add line to build / gradle <br><br><pre> <code class="hljs nginx"> <span class="hljs-attribute"><span class="hljs-attribute">implementation</span></span> <span class="hljs-string"><span class="hljs-string">'org.tensorflow:tensorflow-lite:+'</span></span></code> </pre><br>  We create the interpreter and arrays <br><br><pre> <code class="java hljs"> Interpreter tflite = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Interpreter(loadModelFile(getContext(), <span class="hljs-string"><span class="hljs-string">"model.tflite"</span></span>)); <span class="hljs-comment"><span class="hljs-comment">//     inputs tflite.run(inputs,outputs)</span></span></code> </pre><br>  The code in this case is much smaller, as you see. <br><br>  That's all you need to use your neural network in android. <br><br>  Useful links: <br><br>  <a href="https://firebase.google.com/docs/ml-kit/android/use-custom-models">Off the docks by ML Kit</a> <br>  <a href="https://www.tensorflow.org/mobile/tflite/">Tensorflow lite</a> </div><p>Source: <a href="https://habr.com/ru/post/422041/">https://habr.com/ru/post/422041/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422027/index.html">Principles of work and life of Ray Dalio, one of the richest and most influential people in the world</a></li>
<li><a href="../422029/index.html">Franchise child robotics from ROBOCOR</a></li>
<li><a href="../422033/index.html">Doom II: Hell on Earth, id Software. Secret No. 4 on Map 15 (Industrial Zone) is open in normal game mode.</a></li>
<li><a href="../422035/index.html">When will NASA refuse to fly on Soyuz?</a></li>
<li><a href="../422037/index.html">Roskomnadzor will not block Yandex.Video, but the claim of Gazprom-Media will remain in force</a></li>
<li><a href="../422043/index.html">The digest of interesting materials for the mobile developer # 268 (August 27 ‚Äî September 2)</a></li>
<li><a href="../422045/index.html">How home cinema works: 15 thematic reviews and guides</a></li>
<li><a href="../422047/index.html">The mystery of a hole in the "Union"</a></li>
<li><a href="../422049/index.html">Error handling in Go 2</a></li>
<li><a href="../422051/index.html">We are testing the creation of a component library for Angular with the help of a new command for Angular / Cli - library</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>