<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep ranking for comparing two images</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! I present to your attention the translation of the article ‚ÄúImage Similarity using Deep Ranking‚Äù by the author Akarsh Zingade. 

 Algorithm ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep ranking for comparing two images</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  I present to your attention the translation of the article <a href="https://medium.com/%40akarshzingade/image-similarity-using-deep-ranking-c1bd83855978">‚ÄúImage Similarity using Deep Ranking‚Äù by the</a> author Akarsh Zingade. <br><br><h2>  Algorithm Deep Ranking </h2><br>  The concept of " <i>similarity of two images</i> " was not introduced, so let's introduce this concept at least within the framework of the article. <br><br>  <b>The similarity of two images</b> is the result of comparing two images according to certain criteria.  Its quantitative measure determines the degree of similarity between the intensity charts of the two images.  Using the measure of similarity, some signs describing the images are compared.  As a measure of similarity is usually used: Hamming distance, Euclidean distance, Manhattan distance, etc. <br><a name="habracut"></a><br>  <b>Deep Ranking</b> - studies the fine-grained similarity of images, characterizing the fine-dispersion ratio of similarity of images using a set of triplets. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  What is a triplet? </h3><br>  A triplet contains a request image, a positive and a negative image.  Where a positive image looks more like a request image than a negative one. <br><br>  <b>An example of a set of triplets:</b> <br><br><img src="https://cdn-images-1.medium.com/max/1000/0*vw4M7uZ5exyLZfLv." alt="image"><br><br>  The first, second and third lines correspond to the request image.  The second line (positive images) looks more like request images than the third (negative images). <br><br><h3>  Deep Ranking Network Architecture </h3><br>  The network consists of 3 parts: triplet sampling, ConvNet and the ranking layer. <br>  The network accepts triples of images as input.  One image triplet contains an image request <math> </math> $ inline $ p_i $ inline $   positive image <math> </math> $ inline $ p_i ^ + $ inline $   and negative image <math> </math> $ inline $ p_i ^ - $ inline $   which are independently transmitted in three identical deep neural networks. <br><br>  The topmost ranking layer - estimates the triplet loss function.  This error is corrected in the lower layers in order to minimize the loss function. <br><img src="https://cdn-images-1.medium.com/max/1000/0*ICR1FjUFC8xHXoh1." alt="image"><br><br>  Let's now take a closer look at the middle layer: <br><br><img src="https://cdn-images-1.medium.com/max/1000/0*tOd5HC3R-kFqobpM." alt="image"><br><br>  ConvNet can be any deep neural network (in this article, one of the implementation of the convolutional neural network VGG16 will be considered).  ConvNet contains convolutional layers, a maximum pool layer, local normalization layers, and fully connected layers. <br>  The other two parts receive images with a reduced sampling rate and carry out the convolution stage and max pooling.  Then the stage of normalization of the three parts occurs and at the end they are merged with the linear layer with the subsequent normalization. <br><br><h3>  Triplet formation </h3><br>  There are several ways to form a triplet file, for example, use an expert assessment.  But this article will use the following algorithm: <br><br><ol><li>  Each image in the class generates an image request </li><li>  Each image, except the request image, will form a positive image.  But you can limit the number of positive images for each image request </li><li>  A negative image is randomly selected from any class that is not a request image class. </li></ol><br><h3>  Triplet loss function </h3><br>  The goal is to train a function that assigns a small distance for the most similar images and a large one for different ones.  This can be expressed as: <br><img src="https://cdn-images-1.medium.com/max/1000/0*kC_DghyAeP7ulsGL." alt="image"><br>  Where <b>l</b> is the loss coefficient for triplets, <b>g</b> is the gap coefficient between the distance between two pairs of images: ( <math> </math> $ inline $ p_i $ inline $   , <math> </math> $ inline $ p_i ^ + $ inline $   ) and ( <math> </math> $ inline $ p_i $ inline $   , <math> </math> $ inline $ p_i ^ - $ inline $   ), <b>f</b> - embedding function, which displays the image in a vector, <math> </math> $ inline $ p_i $ inline $   - this is a request image, <math> </math> $ inline $ p_i ^ + $ inline $   - this is a positive image, <math> </math> $ inline $ p_i ^ - $ inline $   Is a negative image, and <b>D</b> is the Euclidean distance between two Euclidean points. <br><br><h3>  Deep Ranking Algorithm Implementation </h3><br>  Implementing with Keras. <br><br>  Three parallel networks are used for the request, a positive and a negative image. <br><br>  There are three main parts to the implementation: <br><br><ol><li>  Implementation of three parallel multiscale neural networks </li><li>  Implementation of the loss function </li><li>  Triplet generation </li></ol><br>  Learning three parallel deep networks will consume a lot of memory resources.  Instead of three parallel deep networks that receive the image of the request, a positive and a negative image, these images will be fed to the input of the neural network sequentially into one deep neural network.  The tensor transferred to the loss layer will contain an image embedding in each row.  Each line corresponds to each input image in the packet.  Since, the image of the request, the positive image and the negative image are successively transmitted, the first line will correspond to the request image, the second - to the positive image, and the third - to the negative image, and then repeat to the end of the packet.  Thus, in the ranking layer gets an attachment of all images.  After that, the loss function is calculated. <br><br>  To implement the ranking layer, we need to write our own loss function, which will calculate the Euclidean distance between the request image and the positive image, as well as the Euclidean distance between the request image and the negative image. <br><br><div class="spoiler">  <b class="spoiler_title">Implementation of the loss calculation function</b> <div class="spoiler_text"><pre><code class="python hljs">_EPSILON = K.epsilon() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_loss_tensor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_pred = K.clip(y_pred, _EPSILON, <span class="hljs-number"><span class="hljs-number">1.0</span></span>-_EPSILON) loss = tf.convert_to_tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>,dtype=tf.float32) <span class="hljs-comment"><span class="hljs-comment"># initialise the loss variable to zero g = tf.constant(1.0, shape=[1], dtype=tf.float32) # set the value for constant 'g' for i in range(0,batch_size,3): try: q_embedding = y_pred[i+0] # procure the embedding for query image p_embedding = y_pred[i+1] # procure the embedding for positive image n_embedding = y_pred[i+2] # procure the embedding for negative image D_q_p = K.sqrt(K.sum((q_embedding - p_embedding)**2)) # calculate the euclidean distance between query image and positive image D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2)) # calculate the euclidean distance between query image and negative image loss = (loss + g + D_q_p - D_q_n ) # accumulate the loss for each triplet except: continue loss = loss/(batch_size/3) # Average out the loss zero = tf.constant(0.0, shape=[1], dtype=tf.float32) return tf.maximum(loss,zero)</span></span></code> </pre> <br></div></div><br>  The packet size must always be a multiple of 3. Because the triplet contains 3 images, and the triplet images are transmitted sequentially (we send each images a deep neural network in series) <br><br>  <a href="https://github.com/akarshzingade/image-similarity-deep-ranking">The rest of the code link</a> <br><br><div class="spoiler">  <b class="spoiler_title">Bibliography</b> <div class="spoiler_text">  [1] Object Recognition from Local Scale-Invariant Features- <a href="http://www.cs.ubc.ca/~lowe/papers/iccv99.pdf">www.cs.ubc.ca/~lowe/papers/iccv99.pdf</a> <br><br>  [2] Histograms of Oriented Gradients for Human Detection- <a href="https://courses.engr.illinois.edu/ece420/fa2017/hog_for_human_detection.pdf">courses.engr.illinois.edu/ece420/fa2017/hog_for_human_detection.pdf</a> <br><br>  [3] Learning Fine-grained Image Similarity with Deep Ranking- <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42945.pdf">static.googleusercontent.com/media/research.google.com/en//pubs/archive/42945.pdf</a> <br><br>  [4] ImageNet Classification with Deep Convolutional Neural Networks- <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a> <br><br>  [5] Dropout: A Simple Way to Prevent Neural Networks from Overfitting- <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf">www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf</a> <br><br>  [6] ImageNet: A Large-Scale Hierarchical Image Database- <a href="http://www.image-net.org/papers/imagenet_cvpr09.pdf">www.image-net.org/papers/imagenet_cvpr09.pdf</a> <br><br>  [7] Fast Multiresolution Image Querying- <a href="https://grail.cs.washington.edu/projects/query/mrquery.pdf">grail.cs.washington.edu/projects/query/mrquery.pdf</a> <br><br>  [8] Large-Scale Image Retrieval with Compressed Fisher <a href="http://citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.401.9140%26rep%3Drep1%26type%3Dpdf">Vectors-citesex.ist.psu.edu/viewdoc/download?doi=10.1.1.401.9140&amp;rep=rep1&amp;type=pdf</a> <br><br>  [9] Beyond Bags of <a href="http://ieeexplore.ieee.org/document/1641019/">Spam</a> Pyramid Matching for Recognizing Natural Scene Categories- <a href="http://ieeexplore.ieee.org/document/1641019/">ieeexplore.ieee.org/document/1641019</a> <br><br>  [10] Improved Consistent Sampling, Weighted Minhash and L1 Sketching- <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36928.pdf">static.googleusercontent.com/media/research.google.com/en//pubs/archive/36928.pdf</a> <br><br>  [11] Large scale online similarity through ranking- <a href="http://jmlr.csail.mit.edu/papers/volume11/chechik10a/chechik10a.pdf">jmlr.csail.mit.edu/papers/volume11/chechik10a/chechik10a.pdf</a> <br><br>  [12] Learning Fine-grained Image Similarity with Deep Ranking- <a href="https://users.eecs.northwestern.edu/~jwa368/pdfs/deep_ranking.pdf">users.eecs.northwestern.edu/~jwa368/pdfs/deep_ranking.pdf</a> <br><br>  [13] Image Similarity using Deep Ranking- <a href="https://medium.com/%40akarshzingade/image-similarity-using-deep-ranking-c1bd83855978">medium.com/@akarshzingade/image-similarity-using-deep-ranking-c1bd83855978</a> <br></div></div></div><p>Source: <a href="https://habr.com/ru/post/457928/">https://habr.com/ru/post/457928/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457910/index.html">WebFPGA - development on Verilog in the browser</a></li>
<li><a href="../457916/index.html">The solution of the WorldSkills tasks of the Network module in the CICA competency. Part 2 - Basic Setup</a></li>
<li><a href="../45792/index.html">Consumers low cost sites ... who are they?</a></li>
<li><a href="../457920/index.html">Jet World: open free access to Joker 2018 conference reports + review of the top ten</a></li>
<li><a href="../457926/index.html">Comparing Agile Certification Part 1 - ICAgile, Scrum.org, ScrumAlliance and PMI</a></li>
<li><a href="../45793/index.html">A collection of nonsense about my country</a></li>
<li><a href="../457930/index.html">Statically safe dynamic typing √† la Python</a></li>
<li><a href="../457932/index.html">Reviewing the IDS Bypass Competition at Positive Hack Days 9</a></li>
<li><a href="../457936/index.html">We invite you to the first Zabbix conference in Russia</a></li>
<li><a href="../45794/index.html">ExtJS extensions for the Adobe AIR platform</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>