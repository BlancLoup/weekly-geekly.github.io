<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The Big Bang Theory and Python Practice</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 Recently, actively learning the programming language Python. I was especially interested in using Python in recognizing and classifying...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The Big Bang Theory and Python Practice</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  Recently, actively learning the programming language Python.  I was especially interested in using Python in recognizing and classifying faces.  In the article, I will try to apply face recognition for the Big Bang Theory series. <br><br><img src="https://habrastorage.org/webt/vz/k5/xp/vzk5xpg9jwnaulmnyxnpnbz7fqc.png"><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">A little about the series</b> <div class="spoiler_text">  The series tells the story of two young talented physicists (Sheldon Cooper and Leonard Hofstedter), their attractive neighbor on the landing, a waitress and aspiring actress Penny, and their friends astrophysics Radzhesh Kutrappali and engineer Howard Volovice.  The action of the series takes place in Pasadena, California.  At the moment, shot 265 episodes (12 seasons). <br>  IMDB rating - 8.2. <br></div></div><br>  <i>I am a non-professional programmer.</i>  <i>Programming is my hobby.</i>  <i>All code is terrible, but I'm learning and trying to make it better.</i> <br><br>  As a tool for recognizing and classifying faces, I used the <a href="https://github.com/deepinsight/insightface">Face Recognition Project on MXNet</a> . <br><div class="spoiler">  <b class="spoiler_title">Insightface</b> <div class="spoiler_text">  In this repository, we provide training for deep face recognition.  The training data includes the MS1M and VGG2 datasets, which were already packed in the MxNet binary format.  The network backbones include ResNet, InceptionResNet_v2, DenseNet, DPN and MobileNet.  The loss functions include Softmax, SphereFace, CosineFace, ArcFace and Triplet (Euclidean / Angular) Loss. </div></div><br>  Also it needs pre-trained models of <a href="https://github.com/deepinsight/insightface/wiki/Model-Zoo">Face Recognition models</a> and <a href="https://github.com/deepinsight/insightface/tree/master/gender-age/model">Gender-Age model</a> (for determining gender and age). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The rest of the tools: <br><br><ul><li>  laptop (Intel Core i5-7200, NVIDIA GeForce 940MX 2Gb, 8 Gb DDR4 RAM, operating system Manjaro KDE); </li><li>  Python 3; </li><li>  CUDA Toolkit 10.0; </li><li>  mxnet with CUDA support; </li><li>  tensorflow with CUDA support; </li><li>  opencv; </li><li>  pandas; </li><li>  downloaded the series ‚ÄúThe Big Bang Theory‚Äù (265 episodes). </li></ul><br>  Most additional Python packages are installed with the command: <br><br><pre><code class="python hljs">pip install _</code> </pre> <br><h4>  Stage 1. Preparatory </h4><br>  For classification, it is necessary to create a selection of images of persons (different in perspective, season) for each character we are interested in.  For this, I took literally the first video from Youtube that I got at the request ‚Äúfunny moments of the big bang theory‚Äù.  With the help of opencv, I extracted the images from the video at 1 second intervals, manually selected them and renamed them using the script for the characters. <br><br><div class="spoiler">  <b class="spoiler_title">Sample image selection</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/cp/of/bx/cpofbx_ocnysvexrivyzmj-kxbk.png"><br></div></div><br>  Further, with the help of a neural network and the use of a pre-trained model, I walked through all the selected images.  From each detected face, a 512-dimensional vector representation is extracted that characterizes it.  This view and character name is stored in pandas.dataframe. <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> glob.glob(<span class="hljs-string"><span class="hljs-string">'knownimage/*.jpg'</span></span>): img = cv2.imread(filename) ret = detector.detect_face(img, det_type=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ret <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: bbbox, points = ret <span class="hljs-comment"><span class="hljs-comment">#draw = img.copy() for inum, bbox in enumerate(bbbox): bbox = bbox[0:4] #cv2.rectangle(draw, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 255, 255)) pp = points[inum] pp = pp.reshape((2, 5)).T # print(bbox) # print(points) nimg = preprocess(img, bbox, pp, image_size='112,112') nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB) aligned = np.transpose(nimg, (2, 0, 1)) f1 = get_feature(mmodel, aligned) df = df.append({'name': filename.split('.')[0], 'np': f1}, ignore_index=True) df.to_pickle('known.pkl')</span></span></code> </pre> <br></div></div><br>  For the 24 main and minor characters of the series, 382 files were selected. <br><br><div class="spoiler">  <b class="spoiler_title">Character list</b> <div class="spoiler_text"><ul><li>  Howard Joel Wolowitz ( <b>govard</b> , here and hereinafter in brackets indicates the name of the character in the face recognition system) - aerospace systems engineer, husband Bernadette Rostenkovski-Wolowitz, father Halley Wolowitz, best friend Rajesh Kutrappali.  He graduated from the Massachusetts Institute of Technology. </li><li>  Dr. Rajesh Ramayan Kutrappali ( <b>rajesh</b> ) is an astrophysicist from India, the best friend of Howard Wolowitz. </li><li>  Priya Kutrappali ( <b>priya</b> ) is the younger sister of Raja, the daughter of a doctor and Mrs. Kutrappali. </li><li>  Penny Hofstedter ( <b>penny</b> ) - Leonard Hofstedter‚Äôs wife, a sales representative for a pharmaceutical company. </li><li>  Dr. Bernadette Maryann Rostenkovsky-Wolowitz ( <b>bernaded</b> ) is a microbiologist, Howard's wife Wolowitz, mother of Halley Wolowitz and Michael Wolowitz. </li><li>  Dr. Beverly Hofstedter ( <b>mama_leonarda</b> ) - Leonard Hofstedter's mother, psychiatrist and neurobiologist </li><li>  Leonard Leakey Hofstedter ( <b>leonard</b> ) - experimental physicist, employee of the California Institute of Technology, holder of a doctoral degree. </li><li>  Dr. Leslie Winkle ( <b>lesly</b> ) is a University of California employee who works with Leonard Hofstedter. </li><li>  Dr. Sheldon Lee Cooper ( <b>sheldon</b> ) is a theoretical physicist working at the California Institute of Technology.  He has several degrees, including a doctoral degree. </li><li>  Melissa "Missy" Cooper ( <b>sestra_sheldona</b> ) is Sheldon Cooper's twin sister. </li><li>  Mary Cooper ( <b>mama_sheldona</b> ) is Sheldon Cooper's mother. </li><li>  Dr. Amy Farrah Fowler ( <b>emmy</b> ) is a neuroscientist, Sheldon Cooper's wife. </li><li>  Wil Wheaton ( <b>will</b> ) - Star Trek: New Generation actor, whom Sheldon considered his worst enemy. </li><li>  Stuart David Blum ( <b>stuart</b> ) - the owner of a comic book store, after a fire became unemployed and moved to live with Howard Volovitsa. </li><li>  Dr. V. Kutrappali ( <b>papa_rajesh</b> ) - the father of Rajesh Kutrappali. </li><li>  Barry Kripke ( <b>barry</b> ) - a colleague of the main characters in the university. </li><li>  Ramona Nowitzki ( <b>navitsky</b> ) - graduate student of the Department of Physics. </li><li>  Dr. Geiblhauser ( <b>geibelhauser</b> ) - the new head of the Faculty of Physics. </li><li>  Zack ( <b>bivshiy_penny</b> ) - Penny's former boyfriend. </li><li>  Mrs. Kutrappali ( <b>mama_rajesh</b> ) is the mother of Rajesh Kutrappali. </li><li>  Dr.  Stephanie Barnett ( <b>medik_leonarda</b> ) is one of Leonard's girls. </li></ul><br></div></div><br><h4>  Stage 2. Video processing </h4><br>  Now we begin to process the entire series.  With the help of opencv, we extract 1 frame per second from each video and find faces on it.  For these persons, we obtain a 512-dimensional vector representation, which characterizes it and compares it with the base that we obtained in the previous step.  We also determine the estimated age and gender. <br><br><div class="spoiler">  <b class="spoiler_title">Video processing</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/zt/bm/b3/ztbmb3el2elkilygibkxtaqb0dw.png"><br><br><img src="https://habrastorage.org/webt/hn/m5/gm/hnm5gmaqwicuvys-ovsp5cj570g.png"><br><br><img src="https://habrastorage.org/webt/qi/ps/oy/qipsoyyy3jwzt7dsuykicpxycaw.png"><br><br><img src="https://habrastorage.org/webt/4d/hs/bl/4dhsbly7tqy3ximgg2wrhb2cbmy.png"><br></div></div><br>  For each found and classified person in the csv file we save the name, gender, age, frame number, series, season.  Detected but not classified persons are saved in a separate directory. <br><br>  Processing of all series took ~ 30 hours, 263775 frames were extracted, 353031 characters were classified.  Processing of one frame takes from 0.2 to 1 second depending on the number of faces.  In the folder with unclassified persons - ~ 20,000 persons (ie, 6%).  This is mostly extras, rare characters or bad angle of the main characters of the series. <br><br><div class="spoiler">  <b class="spoiler_title">Examples of unclassified face images</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/ka/v4/oe/kav4oes5xjqldqpu4bd-ixffwv4.png"><br><br><img src="https://habrastorage.org/webt/ch/ew/tx/chewtxketbdq8pwpj0lndred3mi.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Piece of code</b> <div class="spoiler_text"><pre> <code class="python hljs">home_video = <span class="hljs-string"><span class="hljs-string">'/run/media/home/DATA/torrent/The.Big.Bang.Theory/'</span></span> all_series = (len(glob.glob(home_video+<span class="hljs-string"><span class="hljs-string">'*.avi'</span></span>))) now_series = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename1 <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> glob.glob(home_video+<span class="hljs-string"><span class="hljs-string">'*.avi'</span></span>): now_series = now_series + <span class="hljs-number"><span class="hljs-number">1</span></span> print(filename1) cam = cv2.VideoCapture(filename1) fps = cam.get(cv2.CAP_PROP_FPS) <span class="hljs-comment"><span class="hljs-comment"># Gets the frames per second fps = fps #print(fps) total_frames = cam.get(7) #print(total_frames) rer = round(total_frames/fps) for kk in range(0,rer): #while True: start_time = time.time() cam.set(1, round(kk*fps)) ret_val, img = cam.read() scale_percent = 170 # percent of original size width = int(img.shape[1] * scale_percent / 100) height = int(img.shape[0] * scale_percent / 100) dim = (width, height) # resize image img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA) #print(ret_val) #img, draw = get_input(detector,img) ret = detector.detect_face(img, det_type = 0) if ret is not None: bbbox, points = ret draw = img.copy() for inum,bbox in enumerate(bbbox): bbox = bbox[0:4] pp = points[inum] pp = pp.reshape((2,5)).T #print(bbox) #print(points) nimg = preprocess(img, bbox, pp, image_size='112,112') nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB) aligned = np.transpose(nimg, (2,0,1)) f1 = get_feature(mmodel,aligned) for index, row in df.iterrows(): np1 = row['np'] name = row['name'] dist = np.sum(np.square(np1 - f1)) if dist&lt;1.1: #print(name, dist) dd = dist nnn = name.split('/')[1] break else: nnn = 'None' dd = dist if (nnn=='None') and (int(bbox[3])-int(bbox[1]))&gt;112: crop_img = draw[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])] cv2.imwrite('unknown/' + str(int(time.time())) + '.jpg', crop_img) #cv2.rectangle(draw, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255, 255, 255)) if (nnn != 'None'): gender, age =3, 100 gender, age = get_ga(mga_model,aligned) font = cv2.FONT_HERSHEY_SIMPLEX bottomLeftCornerOfText = (10, 20) fontScale = 1 fontColor = (255, 255, 255) lineType = 2 cv2.putText(draw, nnn + ' ' + str(round(dd, 2)), (int(bbox[0]), int(bbox[1])), font, fontScale, fontColor, lineType) # with open('test_10_1.txt', "a") as myfile: # myfile.write(name + ';' + str(kk) + ';' + str(age)+';'+str(gender)+';'+ str(dist) + ';' + filename1 + '\n') else: gender, age = 3, 100 if cv2.waitKey(1) == 27: #df.to_pickle('test.pkl') print('exit') cv2.destroyAllWindows() #break # esc to quit quit() cv2.imshow("detection result", draw) tt =round(time.time() - start_time,2) print(' '+ str(kk) + '/'+str(rer) + ' &gt; '+str(now_series)+'/'+str(all_series)+'; ' + '  : '+str(tt)+'; ~~'+str(round((rer*tt)*(all_series-now_series)/60))+'', end= "\r")</span></span></code> </pre><br></div></div><br><h4>  Stage 3. A little analysis </h4><br>  In the beginning I wanted to use Pandas to analyze the data obtained, but, unfortunately, I did not master it to the necessary extent.  On the Internet, the <a href="https://plot.ly/free-sql-client-download/">Falcon SQL Client</a> program was found, into which all the data was downloaded.  Also note that the 12 season is not removed until the end. <br><br><div class="spoiler">  <b class="spoiler_title">Falcon SQL Client</b> <div class="spoiler_text">  Falcon is a free, open-source SQL editor with inline data visualization.  It currently supports connecting to RedShift, MySQL, PostgreSQL, IBM DB2, Impala, MS SQL, Oracle, SQLite and more. <br><img src="https://habrastorage.org/getpro/habr/post_images/066/75c/b51/06675cb518d50a848afe55005d1e2cbb.gif"><br></div></div><br>  The figure below shows a graph of the number of frames with the main and secondary characters in the seasons.  Here it is clearly seen that the share of Sheldon and Leonard is decreasing, but the role of Bernadette and Amy is growing. <br><br><img src="https://habrastorage.org/webt/fd/p1/na/fdp1navkqizcwc_otb9az7uum1u.png"><br><br>  Here, the main characters of the series are taken out separately. <br><br><img src="https://habrastorage.org/webt/ex/vf/4v/exvf4vbdlei5xpu8xcn-wugmvvw.png"><br><br>  The main characters of the series as a percentage.  The clear leader is Sheldon Cooper. <br><br><img src="https://habrastorage.org/webt/yg/73/5y/yg735yz9e_-sp9a5bkopovkpjsa.png"><br><br>  I suggested that the appearance of a ‚Äúpair‚Äù in the series should correlate with the joint appearance in the frame, i.e.  the closer the relationship, the more often they appear together in the same frame.  A schedule was built for the ‚Äúcouples‚Äù: Leonard - Penny, Leonard - Sheldon, Sheldon - Amy, Howard - Rajesh, Howard - Bernadette. <br><br><img src="https://habrastorage.org/webt/ap/qv/tp/apqvtpebmyx7c8fay9kyegwzmfu.png"><br><br>  The graph clearly shows the dependencies.  Let's consider separately the "couples" Leonard - Penny and Leonard - Sheldon. <br><br><img src="https://habrastorage.org/webt/gp/si/bg/gpsibgv5av1drrul-hjt6jskkuw.png"><br><br>  We see that as Leonard and Penny evolve, Sheldon more and more remains in the ‚Äúspan‚Äù.  It is also known that Penny and Leonard begin to meet in season 3, which can also be seen on the chart. <br><br>  Consider separately Sheldon-Amy and Sheldon-Leonard. <br><br><img src="https://habrastorage.org/webt/hp/j0/sv/hpj0svztd4mgwmwbpm1uw-ocbro.png"><br><br>  The peak of the development of Sheldon-Amy relations falls on season 10, which we see on the graph. <br>  The following pair of "pairs", which we consider separately - Howard-Bernadette and Howard-Rajesh. <br><br><img src="https://habrastorage.org/webt/tb/cu/mk/tbcumkkgnzrh2wy4atobgtbvhrc.png"><br><br>  Judging by this schedule, ‚Äústrong male friendship‚Äù no one will destroy and Rajesh continues his communication with Howard.  We also note that the peak of the Howard-Bernadette relationship falls on season 5 (this season they have preparation and the wedding itself). <br><br>  Now let's check how the pre-trained model for determining age and sex works.  Let's start with the age: I took for each main character the average age in the episode and put it in a separate table (the actual age of the hero at the time of the shooting of the season is shown in brackets). <br><br><img src="https://habrastorage.org/webt/du/ve/pe/duvepeywmslctui0euoxsg93j2k.png"><br><br>  It can be seen that the make-up, the right light and the post-processing does its job and the neural network does not do well with the determination of age.  However, she discovers an increase in age with each subsequent season. <br><br>  Let's look at the definition of gender for the main characters (closer to 1 - male, to 0 - female). <br><br><img src="https://habrastorage.org/webt/ow/7e/4u/ow7e4unl-g_fbrbhxu1fyglb0r0.png"><br><br>  Here the neural network does much better and shows results close to real ones.  Only with Amy, the result is a bit suspicious. <br><br>  It seemed to me interesting to use a neural network to detect and classify individuals.  It can be seen that it does not provide 100% accuracy, but this should not be.  In the future, I think to simplify the stage of creating the initial sample, using the search by image on the Internet and using this project in video surveillance. <br>  Thanks for attention. <br><br><h4>  List of materials: </h4><br><ol><li>  <a href="https://github.com/ipazc/mtcnn">MTCNN face detection implementation for TensorFlow, as a PIP package.</a> </li><li>  <a href="https://github.com/deepinsight/insightface">Face Recognition Project on MXNet</a> </li><li>  <a href="https://www.imdb.com/title/tt0898266/">The big bang theory</a> </li><li>  <a href="https://bigbangtheory.fandom.com/ru/wiki/%25D0%259A%25D0%25B0%25D1%2582%25D0%25B5%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%258F:%25D0%259F%25D0%25B5%25D1%2580%25D1%2581%25D0%25BE%25D0%25BD%25D0%25B0%25D0%25B6%25D0%25B8">List of characters of the series</a> </li><li>  <a href="https://plot.ly/free-sql-client-download/">Falcon SQL Client</a> </li><li>  <a href="https://yadi.sk/d/WWs_XBuioW1b7g">Summary CSV file</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/435888/">https://habr.com/ru/post/435888/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../435878/index.html">Amateur in opensource - lessons learned for 3 years</a></li>
<li><a href="../435880/index.html">Changing the schema of PostgreSQL tables without long locks. Yandex lecture</a></li>
<li><a href="../435882/index.html">Review of Xiaomi Mi Box S and a small comparison with Mi Box 3</a></li>
<li><a href="../435884/index.html">Metal search and ... neural network</a></li>
<li><a href="../435886/index.html">SpaceX showed Starship prototype and cut 10% of staff</a></li>
<li><a href="../435890/index.html">Dark sides of the active person</a></li>
<li><a href="../435892/index.html">The digest of interesting materials for the mobile # 281 developer (January 7 - 13)</a></li>
<li><a href="../435894/index.html">Private classes. Hiding in php</a></li>
<li><a href="../435896/index.html">Using the DiagnosticSource in .NET Core: Theory</a></li>
<li><a href="../435898/index.html">What to think on the NALSD interview</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>