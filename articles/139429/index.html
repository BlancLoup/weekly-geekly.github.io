<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>2D-> 3D in Augmented reality</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article, I will tell you how to build a 3D space using the found location of an object in the scene in applications of Augmented reality . To ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>2D-> 3D in Augmented reality</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/geektimes/post_images/c97/c7d/1ee/c97c7d1ee677b1e18a5a8857c4bf8e17.jpg" alt="image"><br><br>  In this article, I will tell you how to build a 3D space using the found location of an object in the scene in applications of <a href="http://habrahabr.ru/blogs/augmented_reality/">Augmented reality</a> .  To do this, you need to get two matrices - projection (GL_PROJECTION) and model (GL_MODELVIEW) for work, for example, in OpenGL.  We will do this by means of the <b>OpenCV library</b> . <br><br>  Recently I had to solve this problem, but I couldn‚Äôt find a resource where I couldn‚Äôt find how to do it in a step-by-step (maybe I was looking badly), and there are enough pitfalls in this problem.  In any case, the article on Habr√© describing this task does not hurt. <br><a name="habracut"></a><br><h3>  Introduction </h3><br>  I myself am an iOS programmer, in my spare time I am developing my own Augmented Reality engine.  For the base I took <a href="http://opencv.willowgarage.com/">OpenCV</a> - an open source library for computer vision. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In general, the most interesting proposal for mobile devices (iOS / Android) in this area are the development of Qualcomm. <br><br>  More recently, they released their own AR SDK under the name <a href="https://developer.qualcomm.com/develop/mobile-technologies/augmented-reality">Vuforia</a> .  At the same time, the use of the SDK is free both for developing and laying out the application in the store (AppStore, AndroidMarket), as the Licensing paragraph proudly declares.  At the same time, they write that you must notify the end user that this SDK may collect some anonymous information and send it to Qualcomm servers.  You can find this section at <a href="https://ar.qualcomm.at/qdevnet/sdk/ios">this link</a> by choosing Getting Started SDK -&gt; Step 3: Compiling &amp; Running ... -&gt; Publish Your Application in the right menu.  And plus to this, you can consider me paranoid, but I am 90% sure that when their SDK gains a certain percentage of popularity, they will say, ‚ÄúEverything, the freebie is over, pay grandmas‚Äù. <br><br>  Therefore, I consider developing my own engine not a waste of time. <br><br>  Actually, to the point! <br><br><h3>  Theory </h3><br>  We believe that by this time you have implemented OpenCV in your project ( <a href="http://habrahabr.ru/blogs/image_processing/135244/">how?</a> ), And have already written a method for recognizing an object in the frame coming from the camera.  That is, about the picture you have: <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/03b/e6b/18a/03be6b18aa80df784a43644e31c36395.jpg" alt="image"><br><br>  The theory on this issue can be found in many sources.  I cited the main links below.  The starting resource is the <a href="http://opencv.willowgarage.com/documentation/cpp/camera_calibration_and_3d_reconstruction.html">OpenCV documentation</a> page, although there will be a lot of reading questions. <br><br>  In a nutshell, in order to build a 3D space using the 2D homography found, we need to know 2 matrices: <br><ul><li>  Intrinsic matrix, or camera matrix ‚Äî this matrix consists of camera parameters ‚Äî the focal distance along two axes ( <i>fx</i> , <i>fy</i> ) and the coordinate of the center of the focus ( <i>cx</i> , <i>cy</i> ). <br>  The structure of this matrix: <br><img src="https://habrastorage.org/getpro/geektimes/post_images/047/c18/904/047c189042eb1bbbd0462b5e7fb0ff29.jpg" alt="image"><br></li><li>  The extrinsic matrix, or model matrix, is a matrix for stretching, rotating, and transferring a model.  It, in fact, uniquely defines the position of the object in space.  Structure: <br><img src="https://habrastorage.org/getpro/geektimes/post_images/1f1/874/c32/1f1874c322df92a06946b2fc906c385e.jpg" alt="image">  , <br>  where the diagonal elements are responsible for stretching, the remaining elements <i>r</i> for rotation, and the elements <i>t</i> for the transfer. <br>  <u>Note:</u> in general, the structure of this matrix may vary depending on the model (coordinate transformation equations).  For example, in the same OpenGL, the matrix is ‚Äã‚Äãtransferred to a slightly different structure, but the key elements are always present in it. <br></li></ul><br><h3>  Practice </h3><br>  In practice, in order for OpenGL to render a 3D model on top of our object, we need to ask it: <br><ul><li>  Projection Matrix - GL_PROJECTION. </li><li>  The model matrix is ‚Äã‚ÄãGL_MODELVIEW. </li></ul><br>  <u>Note:</u> In iOS, you can use 2 versions of OpenGLES - 1.1 and 2.0.  The main difference is the presence of shaders in the second version.  In both cases, we need to specify 2 matrices, only in the first case, they are defined by a type construction: <br><br><pre><code class="cpp hljs">glMatrixMode(GL_PROJECTION); glLoadMatrixf(projectionMatrix); glMatrixMode(GL_MODELVIEW); glLoadMatrixf(modelViewMatrix);</code> </pre> <br><br>  And in the second, you pass them on to the shaders. <br><br>  Further, we will determine the size of the frame that you get from camera cameraSize = (width, height).  In my case, cameraSize = (640, 480). <br><br>  We will understand how to build each matrix. <br><br><h5>  Projection matrix </h5><br>  This matrix is ‚Äã‚Äãbased on the matrix of the camera.  As shown above, the latter consists of certain camera parameters.  In theory, one can calculate these parameters based on the technical characteristics of the camera, but in practice no one does this. <br><br>  The process of finding the parameters of the camera is called its calibration.  All necessary functions are written in OpenCV for calibration.  Also, there is <a href="http://dasl.mem.drexel.edu/~noahKuntz/openCVTut10.html">an example</a> that allows you to simply calibrate your webcam online.  But we need to calibrate the camera on the device - iPhone / iPad / iPod.  And here I went the way described <a href="http://urbanar.blogspot.com/2011/04/offline-camera-calibration-for.html">here</a> . <br><br>  Calibrate the camera, we will be "offline".  This means that we will take pictures of the calibration pattern (chessboard) with the camera of our device, transfer the photos to the computer, and calculate the parameters from these photos.  A few points: <br><ul><li>  Checkerboard pattern print on A4 paper.  The sheet must be clean, it is very desirable that the printer is "not tech". <br></li><li>  Try to keep the sheet of the chessboard on the pictures flat on the surface - the edges were not bent, there were no bends of the sheet.  To do this, you can glue it to a piece of cardboard, or simply put heavy objects on the edges, but so that they do not cover the look of the pattern. <br></li><li>  Images from the camera need to be converted to the size of cameraSize.  This is not an obvious step - for example on iPhone 4, when recognizing I use the camera frame size of 640x480, and when you take a photo with a simple camera and drop it onto a computer, you get larger photos (2592x1936), I compressed them to 640x480, and used these in the program. <br></li><li>  The number of snapshots of the template should be 12-16 + taken from different angles.  Personally, I used 16 shots, while changing the parameters built on 12 and 16, though not large, but present.  In general, the more pictures, the more accurate the parameters, and this accuracy will further affect the presence / absence of shifts when building 3D objects. <br></li><li>  In addition to the camera matrix, at this stage, we find distortion coefficients (distortion coefficients).  In a nutshell, these coefficients describe the distortion of the image by the camera lens.  More details can be found in the <a href="http://opencv.willowgarage.com/documentation/cpp/camera_calibration_and_3d_reconstruction.html">OpenCV documentation</a> and on <a href="http://en.wikipedia.org/wiki/Distortion_(optics)">Wikipedia</a> .  As for mobile devices, most of the cameras are of sufficient quality, and these coefficients are relatively small, so they can be ignored. <br></li></ul><br>  Xcode draft program for calibration you can download <a href="">here</a> .  In this case, you should have compiled OpenCV.  Or you can download the compiled framework <a href="http://www.ient.rwth-aachen.de/cms/software/opencv/">from here</a> . <br>  The photos themselves, you need to put in the folder with the compiled binary, and rename them in order. <br>  If everything is ok, you will get 2 files at the output of the program: <br><ul><li>  Intrinsics.xml - a 3x3 camera matrix will be recorded line by line here <br></li><li>  Distortion.xml - there will be calculated coefficients. <br></li></ul><br>  If a template is not found on some pictures - try replacing these pictures with others, with better lighting, perhaps at a less acute angle to the pattern.  OpenCV should easily find all internal template points. <br>  Having numbers from these files, we can build a projection matrix for OpenGL. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cameraMatrix[<span class="hljs-number"><span class="hljs-number">9</span></span>] = {<span class="hljs-number"><span class="hljs-number">6.24860291e+02</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, cameraSize.width*<span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">6.24860291e+02</span></span>, cameraSize.height*<span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">1.</span></span>}; - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)buildProjectionMatrix { <span class="hljs-comment"><span class="hljs-comment">// Camera parameters double f_x = cameraMatrix[0]; // Focal length in x axis double f_y = cameraMatrix[4]; // Focal length in y axis (usually the same?) double c_x = cameraMatrix[2]; // Camera primary point x double c_y = cameraMatrix[5]; // Camera primary point y double screen_width = cameraSize.width; // In pixels double screen_height = cameraSize.height; // In pixels double near = 0.1; // Near clipping distance double far = 1000; // Far clipping distance projectionMatrix[0] = 2.0 * f_x / screen_width; projectionMatrix[1] = 0.0; projectionMatrix[2] = 0.0; projectionMatrix[3] = 0.0; projectionMatrix[4] = 0.0; projectionMatrix[5] = 2.0 * f_y / screen_height; projectionMatrix[6] = 0.0; projectionMatrix[7] = 0.0; projectionMatrix[8] = 2.0 * c_x / screen_width - 1.0; projectionMatrix[9] = 2.0 * c_y / screen_height - 1.0; projectionMatrix[10] = -( far+near ) / ( far - near ); projectionMatrix[11] = -1.0; projectionMatrix[12] = 0.0; projectionMatrix[13] = 0.0; projectionMatrix[14] = -2.0 * far * near / ( far - near ); projectionMatrix[15] = 0.0; }</span></span></code> </pre><br><br>  A few notes: <br><ul><li>  We replace the coefficients ( <i>cx</i> , <i>cy</i> ) of the camera matrix with the center of our frame.  Then there will be no offset of the 3D model relative to the object in the frame.  The author of the <a href="http://urbanar.blogspot.com/2011/04/offline-camera-calibration-for.html">post</a> came to the same conclusion (see UPDATE: at the end of the article). <br></li><li>  I took the formulas for obtaining the projection matrix <a href="http://opencv.willowgarage.com/wiki/Posit">from here</a> .  In essence, this is how a perspective projection is set, which takes into account the parameters of our camera and the frame size. <br></li><li>  The presented matrix of the camera was obtained by me for the iPhone 4. For other devices, the matrix will be different, although, I think, not much. <br></li></ul><br><br><h5>  Matrix model </h5><br>  When building this matrix, <a href="http://stackoverflow.com/questions/3712049/how-to-use-an-opencv-rotation-and-translation-vector-with-opengl-es-in-android">this</a> question helped me in StackOverflow. <br>  Fortunately, the necessary functions in OpenCV are already implemented. <br><br>  So, the code: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cameraMatrix[<span class="hljs-number"><span class="hljs-number">9</span></span>] = {<span class="hljs-number"><span class="hljs-number">6.24860291e+02</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, cameraSize.width*<span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">6.24860291e+02</span></span>, cameraSize.height*<span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">1.</span></span>}; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> distCoeff[<span class="hljs-number"><span class="hljs-number">5</span></span>] = {<span class="hljs-number"><span class="hljs-number">1.61426172e-01</span></span>, <span class="hljs-number"><span class="hljs-number">-5.95113218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">7.10574386e-04</span></span>, <span class="hljs-number"><span class="hljs-number">-1.91498715e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.66041708e+00</span></span>}; - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)buildModelViewMatrixUseOld:(BOOL)useOld { <span class="hljs-keyword"><span class="hljs-keyword">clock_t</span></span> timer; startTimer(&amp;timer); CvMat cvCameraMatrix = cvMat( <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, CV_32FC1, (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>*)cameraMatrix ); CvMat cvDistortionMatrix = cvMat( <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, CV_32FC1, (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>*)distCoeff ); CvMat* objectPoints = cvCreateMat( <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, CV_32FC1 ); CvMat* imagePoints = cvCreateMat( <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, CV_32FC1 ); <span class="hljs-comment"><span class="hljs-comment">// Defining object points and image points int minDimension = MIN(detector-&gt;modelWidth, detector-&gt;modelHeight)*0.5f; for (int i=0; i&lt;4; i++) { float objectX = (detector-&gt;x_corner[i] - detector-&gt;modelWidth/2.0f)/minDimension; float objectY = (detector-&gt;y_corner[i] - detector-&gt;modelHeight/2.0f)/minDimension; cvmSet(objectPoints, i, 0, objectX); cvmSet(objectPoints, i, 1, objectY); cvmSet(objectPoints, i, 2, 0.0f); cvmSet(imagePoints, i, 0, detector-&gt;detected_x_corner[i]); cvmSet(imagePoints, i, 1, detector-&gt;detected_y_corner[i]); } CvMat* rvec = cvCreateMat(1, 3, CV_32FC1); CvMat* tvec = cvCreateMat(1, 3, CV_32FC1); CvMat* rotMat = cvCreateMat(3, 3, CV_32FC1); cvFindExtrinsicCameraParams2(objectPoints, imagePoints, &amp;cvCameraMatrix, &amp;cvDistortionMatrix, rvec, tvec); // Convert it CV_MAT_ELEM(*rvec, float, 0, 1) *= -1.0; CV_MAT_ELEM(*rvec, float, 0, 2) *= -1.0; cvRodrigues2(rvec, rotMat); GLfloat RTMat[16] = {cvmGet(rotMat, 0, 0), cvmGet(rotMat, 1, 0), cvmGet(rotMat, 2, 0), 0.0f, cvmGet(rotMat, 0, 1), cvmGet(rotMat, 1, 1), cvmGet(rotMat, 2, 1), 0.0f, cvmGet(rotMat, 0, 2), cvmGet(rotMat, 1, 2), cvmGet(rotMat, 2, 2), 0.0f, cvmGet(tvec, 0, 0) , -cvmGet(tvec, 0, 1), -cvmGet(tvec, 0, 2), 1.0f}; cvReleaseMat(&amp;objectPoints); cvReleaseMat(&amp;imagePoints); cvReleaseMat(&amp;rvec); cvReleaseMat(&amp;tvec); cvReleaseMat(&amp;rotMat); printTimerWithPrefix((char*)"ModelView matrix computation", timer); }</span></span></code> </pre><br>  First we need to define 4 pairs of object points and the corresponding position in the frame. <br>  The position points in the frame are the vertices of the quadrilateral describing (bounding) the object in the frame.  To obtain these points, having a homography of the H transformation, you can simply act on the extreme points of the pattern given by the homography: <br><br><img src="http://dl.dropbox.com/u/13584616/formula.jpg" alt="image"><br><br>  Regarding the points of the object itself, there are a couple of moments: <br><ul><li>  Object points are defined in 3D, and points on a frame in 2D.  Accordingly, if we allow it to be given a non-zero value <i>z</i> , then the origin of coordinates on <i>z</i> will be shifted relative to the object plane on the frame.  It is easier to understand from these two pictures: <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b74/aa3/790/b74aa3790e70b0932853307396eb91c1.jpg" alt="image"><br>  <i>z = 1.0</i> <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2bf/896/769/2bf89676910ab862c8918ea3f1626a90.jpg" alt="image"><br>  <i>z = 0.0</i> <br><br></li><li>  Also, we set the points of the object so that we can continue to work in this 3D space further.  For example, I want the origin of coordinates to be right in the center of the template, and the unit of length equal to half the smaller side (in the minDimension code).  In this case, we will not depend on the specific size of the template in pixels, and the 3D space will be scaled on the smaller side. <br></li></ul><br>  The constructed matrices are passed to the <i>cvFindExtrinsicCameraParams2</i> function.  It will build us a rotation vector, and a transfer vector.  From the rotation vector we need to get the rotation matrix.  This is done using the <i>cvRodrigues2</i> function, having previously converted the rotation vector slightly by multiplying the second and third elements by <i>-1</i> .  Further, we can only save the data in the model matrix for OpenGL.  At the same time, the OpenGL matrix must be transposed. <br>  Everything, we delete temporary objects, and the matrix of model is received. <br><br><h3>  Total </h3><br>  Having a procedure for constructing two matrices, we can safely create a GLView, and draw models there.  I note that the function of finding the matrix of the model is not more than 10 milliseconds on the iPhone 4, that is, using it will not lower your recognition FPS significantly. <br>  Thanks for attention. <br><br><h4>  Learn more: </h4><br>  1. <a href="http://old.uvr.gist.ac.kr/wlee/web/techReports/ar/Camera%2520Models.html">http://old.uvr.gist.ac.kr/wlee/web/techReports/ar/Camera%20Models.html</a> <br>  2. <a href="http://www.hitl.washington.edu/artoolkit/mail-archive/message-thread-00653-Re--Questions-concering-.html">http://www.hitl.washington.edu/artoolkit/mail-archive/message-thread-00653-Re--Questions-concering-.html</a> <br>  3. <a href="http://sightations.wordpress.com/2010/08/03/simulating-calibrated-cameras-in-opengl/">http://sightations.wordpress.com/2010/08/03/simulating-calibrated-cameras-in-opengl/</a> <br>  4. <a href="http://www.songho.ca/opengl/gl_projectionmatrix.html">http://www.songho.ca/opengl/gl_projectionmatrix.html</a> </div><p>Source: <a href="https://habr.com/ru/post/139429/">https://habr.com/ru/post/139429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../139424/index.html">Old Dell Latitude XPi CD</a></li>
<li><a href="../139425/index.html">PLC - what is it?</a></li>
<li><a href="../139426/index.html">CodeFest. New season. March 31 ‚Äî April 1, Novosibirsk</a></li>
<li><a href="../139427/index.html">Google Chrome Extension: We are printing articles with habrahabr</a></li>
<li><a href="../139428/index.html">Implementation of the RGB-algorithm for changing the image contrast</a></li>
<li><a href="../139432/index.html">AIDL (Android Interface Definition Language) and Inter-Process Communication (IPC)</a></li>
<li><a href="../139433/index.html">Running multiple node.js sites on the same server</a></li>
<li><a href="../139434/index.html">MIT opened Google App Inventor in beta</a></li>
<li><a href="../139435/index.html">Documentation for Grab - library for parsing sites</a></li>
<li><a href="../139438/index.html">Common work space for home and office</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>