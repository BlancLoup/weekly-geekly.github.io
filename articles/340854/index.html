<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Smart nets for fishermen: how we taught smartphones to recognize fish</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The development of computer vision in the past 10 years, did not pay attention only to a person removed from the world. The pattern recognition techno...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Smart nets for fishermen: how we taught smartphones to recognize fish</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/59/ef/01/59ef01ad09e66558267453.png"><br><br>  The development of computer vision in the past 10 years, did not pay attention only to a person removed from the world.  The pattern recognition technology owes its profound prosperity to its deep learning.  Achievements of machines are amazing. <br><a name="habracut"></a><br><ul><li>  In 2012, there is a competition for the classification of images, where a deep <a href="https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf">neural network</a> wins with a grand margin from second place; </li><li>  Three years later, the machine <a href="https://www.entrepreneur.com/article/283990">classifies</a> 1000 classes of pictures with an accuracy superior to the human one; </li><li>  Recognition of handwritten symbols and road signs exceeded people in accuracy. </li><li>  Eyes of self-driving cars - lidars, radar and cameras are able to recognize the environment, road markings, vehicles, cars, as well as the gender and age of pedestrians. </li><li>  The accuracy of lip reading by a network trained by Google DeepMind and Oxford University is more than human; </li><li>  Recognition of age and sex - accuracy exceeded human; </li><li>  One of the most evolving areas of machine vision technology is face recognition with an emphasis on biometrics due to the growing demand for this technology for security.  Several countries use face recognition technology in their outdoor video surveillance systems.  Thanks to him, even the criminal was caught. </li></ul><br>  This is only the tip of the iceberg of the achievements of computer vision algorithms.  Left without mention achievements in art, medicine, games and impressive generative models, such as the <a href="https://habrahabr.ru/users/sim0nsays/posts/">generator of cats</a> .  Some sources claim that it was thanks to the cats that they managed to borrow the idea of ‚Äã‚Äãconvolutional neural networks from nature, which created the visual cortex of the brain. <br><br><h3>  Computer vision as part of the future world </h3><br>  Technologies for automating tasks that require pattern recognition are in demand at the service of governments and high-tech companies.  They help solve the problems of people in need of help - farmers and environmentalists.  Microsoft's Seeing AI application describes the world for blind people.  A young developer created for parents of farmers sorting vegetables, facilitating the work. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We have been following technology for a long time.  The potential of machine learning inspires us to look for applications of promising technologies in our products for solving everyday tasks of ordinary people.  In 2016, working on a social network for fishermen, we decided to do the best that we can to make our favorite hobby not only more convenient, but also more interesting. <br><br><h3>  Purpose and setting of the problem </h3><br>  Modern fishing communities still live on forums built in the early 2000s.  Themes with stories about the best places for fishing, equipment and photos of the catch are the most active.  People share fish captured on a smartphone, laying out a post on the forum.  Brothers in arms (in this case, a fishing rod) are discussing prey, competing with each other who caught a bigger pike.  We did not want to break such a warm, competitive atmosphere.  Just the opposite, to make fishing more active, more convenient and a bit more modern, at least in this aspect. <br><br>  About 500 million people all over the world are keen on fishing today.  Representatives of one of the largest community have been taking fishing smartphones with them for a long time, however, everyone is also sitting on outdated forums or groups on Facebook.  Surprisingly, there are almost no modern resources and applications for fishermen.  We wanted to correct this unfortunate omission through technology. <br><br>  The application we have created will help fishermen not only determine the type and length of fish, but also leave the trophy on the honor roll.  Every fisherman wants to see prey in his collection.  Scanning the capture, the application adds it to the profile, so that the user can boast of the catch with his friends.  Probably, most fishermen who consider this occupation more than a hobby have a sense of competitive excitement.  Especially for them, we also decided to add ratings.  Users with a large catch will be at the top of the rating, becoming an incentive for the rest.  Stories like "I caught such a fish here" will not be taken seriously.  The app will know who the fisherman caught and how long. <br><br>  A person will no longer be distracted by uploading photos to the forum, determining the type and size of fish - machine learning will do everything.  It will only enjoy your favorite pastime - to catch a fish. <br><br><h3>  Learning the net to catch fish </h3><br>  To teach the network to recognize the length and type of fish, in addition to the powerful video maps, we needed: <br><ul><li>  collect data; </li><li>  process up to a clean set of marked beautiful pictures with fish; </li><li>  select the appropriate architecture; </li><li>  learn and validate; </li><li>  correct errors and try again. </li></ul><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac39e8c2063041201.jpeg"><br><br><h3>  Data collection </h3><br>  There are practically no open datasets with markings of the type of fish or box with its position.  Data can be found at ImageNet and individual laboratories, but the volume, quality of images and markup leaves much to be desired. <br>  A first look at the first hundred photos of the catch will be enough to understand that fishermen from all over the world like to take selfies with fish, but not high-quality photos. <br>  Photos and videos from fishing contain the necessary data, but they have several significant drawbacks: <br><br><ul><li>  Low quality ~ 40% dataset: <br><ol><li>  The fish occupies a small part of the photograph, or is terribly oiled, photographed from afar; </li><li>  Fisherman's hands cover a significant portion of the fish; </li><li>  The fish is partially visible and does not fit in the frame, cut off or blocked in the picture. </li></ol></li></ul><br><ul><li>  Frame not amenable to classification: </li></ul><br>  There are several types in the photo, and we want to define one class for each image. <br>  Fishermen very often confuse similar species, ‚Äúpolluting‚Äù the data. <br><br>  Deep nets are demanding in terms of volume and less demanding in quality.  But raw fishing pictures are not suitable. <br><br>  Our methodology allowed us to solve several problems at once - data collection and their cleaning.  It consists in consistently increasing the quality, models and data: <br>  We manually mark the borders of fish for several different species to avoid retraining for one species.  For example, flounder, pike and carp.  A few days of work is a couple of thousand pictures. <br><br>  <a href="http://slazebni.cs.illinois.edu/spring17/lec07_detection.pdf">We choose the</a> architecture for detection.  Fast and accurate to work with large amounts of data.  R-FCN seemed appropriate. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abfa8cb5537930575.png"><br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac323422533399731.jpeg"><br><br>  We teach the network to distinguish between fish and non-fish (background), to detect the first.  We make a web interface for the inference of media materials of our fishermen.  He can insert into the web interface a link to his video, which will be frame-by-frame through the detection model.  All frames containing fish will be displayed on the screen to remove duplicates and errors ... <br><br>  This admin panel allows you to collect data for the target species, and processed by the network and verified by a person to use for: <br><br><ol><li>  Additional training of our detection model.  Selecting examples of successful work on new types, we transfer to a larger number of types and improve the accuracy and quality of the model; </li><li>  Cutting out a fragment of fish from a photograph is at the exit, setting a high threshold of confidence for the filter of good frames, we get large quality frames with one fish.  What you need to learn the classification model!  Quality images processed in this way are ~ 60%. </li></ol><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac15611a467089321.png"><br><br><h3>  Learning classification </h3><br>  We intend to expand the number of recognizable types, so we chose the classifier architecture among the networks that predicted 1000 classes on ImageNet.  The choice fell on Inception-ResNet-2, as the optimal ratio of size and accuracy. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac124a98587605510.jpeg"><br><br>  TensorFlow, EVGA GeForce GTX 1080 Ti and EVGA GeForce GTX 1080 were used for training. <br><br>  Full model training provided greater accuracy than the training of fully connected layers of the ImageNet model.  Most likely because the network has learned low-level patterns, such as drawing scales.  The training took more than 80 hours on two video cards. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac1d8acf973856821.png"><br><br>  The first results were astounding! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abedf87f888579243.jpeg" width="400"></div><br>  While everyone was admired by the fact that they had trained the neuron to the level of a cartoon abstraction, some doubted that the network had retrained. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abe27992934165697.jpeg" width="400"></div><br>  But in vain, the camera captured the typical Kerry on mid, so everything is fine. <br><br>  The resulting solution suffered from large errors on similar species.  The images represent the legendary ide and the chub, which can only be distinguished by avid fishermen. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac39e8d1583633950.jpeg"><br><br>  The situation is even worse with the trout. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac0197ec287350629.jpeg"><br><br>  More than a dozen popular types of trout and salmon can not only confuse a non-expert, but also are incredibly volatile throughout their lives.  From the stage of the larva to spawning, they change their color and shape dramatically, depending on age, season, and even the composition of the water.  Not every person recognizes the same species of trout at intervals of several years.  Species such as coho and chinook are hard to distinguish even by description.  Because of a human error, the data is confused, for each class the model requires at least 1000 photos for accuracy of more than 80%, with several dozen types of manual, competently view such volumes of resource-intensive. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac06967d523741883.jpeg"><br><br>  Our solution was to iteratively clean the dataset from markup errors using the model itself.  We run the model on our own dataset, we find all the pictures with a mismatch between the model prediction and the markup.  Most of these images are the errors of the latter.  We eliminate them, retrain the model and get high metrics on validation dataset.  As a result, it was possible to obtain model accuracy of more than 90 +%, even for similar species.  The network is able to almost correctly distinguish between 8 similar species of trout and salmon, and more than a dozen perch.  However, in rare cases, the network is still wrong.  The reason is better to show clearly: <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abdbfc90174013584.jpeg"><br><br><h3>  Measure catch </h3><br>  Revaluation of your catch is a very important feature of protein neural networks.  For accurate measurement, you need to know the boundaries of the fish in the photo and have a range finder, like on new smartphones with dual cameras. <br><br>  Our goal is to provide fishers with an accurate measurement of the catch automatically, by simply pointing the phone.  The application must be able to determine when the fish in the frame is classified and localized.  It is necessary to measure the length of fish according to several different standards.  The Faster RCNN architecture with Inception-ResNet-2 shows itself better than its analogs, we translate the classification into it with R-FCN. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac27c425520240479.png"><br><br>  Results on similar data speak for themselves. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abda5c22321204140.jpeg"><br><br>  However, this method of measurement does not suit us, since the boxes correctly determine the length and width only for the horizontal and vertical position; they are not suitable for an arbitrary position and are not able to estimate the length of the bent fish. <br><br><h3>  More precisely measure the catch </h3><br>  We mark out several thousand photos with key points to cover all the measurement methods according to various standards. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac33d628284172790.jpeg"><br><br>  We teach a model for regression by key points, which will increase the accuracy of length measurement and will be able to get into the phone.  If we transfer the detection to the device, then we will be able to send the already trimmed section with fish to the classification, which will increase reliability and help to remove the load from the server.  The phone will only send a request when it detects a fish.  Unfortunately, the point regression model cannot distinguish between fish and non-fish, so we need a model of such a binary classifier for the device. <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abfdb8b0453124029.jpeg"><br><br>  To regress by key points, we take the ‚Äúhead‚Äù of ResNet50 architecture, which was trained on ImageNet, and add 2 fully connected layers on the regression of 14 variables - the coordinates of all points.  MAE loss function.  The weight of the model is ~ megabyte. <br><br>  Augmentation: flips horizontal / vertical, brightness, random crop (well logged), scale.  All coordinates of the points were normalized to [-1, 1] <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0ac460db1195510231.jpeg"><br><br>  To create a binary classifier, we create our own model, similar to AlexNet.  We teach on fish and non-fish. <br><br>  Everything is standard here: binary cross entropy, augmentations, accuracy metric (the samples are balanced) <br><br><img src="https://habrastorage.org/webt/59/ee/0a/59ee0abdcd6fe335320696.jpeg"><br><br>  In the future, we plan to increase the number of recognizable species, exceed the accuracy of the human model and transfer the model completely to the device.  Our goal is not just to create a universal tool for fishermen, but to unite all the community in a single project. </div><p>Source: <a href="https://habr.com/ru/post/340854/">https://habr.com/ru/post/340854/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../340840/index.html">Asynchronous long ears</a></li>
<li><a href="../340842/index.html">Galloping in Europe: the journey of the "Formula Student" from the Czech Republic to Moscow</a></li>
<li><a href="../340846/index.html">Life after banning Google Global Cache: Implications for providers and customers</a></li>
<li><a href="../340850/index.html">Internet content blocking: the situation on the world stage</a></li>
<li><a href="../340852/index.html">Adaptive emails without pain and suffering</a></li>
<li><a href="../340856/index.html">How to tie a normal search to an outdated SQL backend</a></li>
<li><a href="../340858/index.html">As I stopped worrying and started cutting rectangles in Unity correctly</a></li>
<li><a href="../340860/index.html">Forward to the past: IT departments of companies 2018</a></li>
<li><a href="../340862/index.html">Linux Piter # 3: what about this time?</a></li>
<li><a href="../340866/index.html">Google Forms: we fix event of sending the form in Google Analytics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>