<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apache¬Æ Ignite ‚Ñ¢ + Persistent Data Store - In-Memory penetrates discs. Part I - Durable Memory</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In Apache Ignite , starting from version 2.1, there appeared its own persistence implementation. 

 In order to build this mechanism in its modern des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apache¬Æ Ignite ‚Ñ¢ + Persistent Data Store - In-Memory penetrates discs. Part I - Durable Memory</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/59/cd/8a/59cd8a31cdb5b946545722.png"><br><br>  In <a href="https://ignite.apache.org/">Apache Ignite</a> , starting from version 2.1, there appeared its own <a href="https://apacheignite.readme.io/docs/distributed-persistent-store">persistence</a> implementation. <br><br>  In order to build this mechanism in its modern design, dozens of man-years left, which were mainly spent on building distributed fault-tolerant transactional storage with SQL support, left. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It all started with the fundamental problems of the previous mechanism, which allowed to integrate the In-Memory Data Grid with external permanent storage, for example, Cassandra or Postgres. <br><br>  Such an approach imposed certain restrictions - for example, it was impossible to perform SQL or distributed computing on top of data that is not in memory, but in such external storage, cold start and low <a href="https://en.wikipedia.org/wiki/Recovery_time_objective">RTO (Recovery Time Objective)</a> were impossible without significant additional complications. <br><br>  If you use Apache Ignite Persistence, then you keep all the usual Apache Ignite features ‚Äî <a href="https://en.wikipedia.org/wiki/ACID">ACID</a> , distributed transactions, distributed <a href="https://en.wikipedia.org/wiki/SQL:1999">SQL99</a> , access via the Java / .NET API or <a href="https://apacheignite.readme.io/docs/jdbc-driver">JDBC</a> / <a href="https://apacheignite.readme.io/docs/odbc-driver">ODBC</a> interfaces, distributed computing, and so on.  But now what you use can work both on top of memory and on top of a disk that expands memory on installations from one node to several thousand nodes. <br><br>  Let's take a look at how <a href="https://apacheignite.readme.io/docs/distributed-persistent-store">Apache Ignite Persistence works</a> inside.  Today I will consider its basis - Durable Memory, and in the next publication - the disk component itself. <a name="habracut"></a><br><br><div class="spoiler">  <b class="spoiler_title">Terminology</b> <div class="spoiler_text">  I will make a remark about the terminology.  In the context of a cache on an Apache Ignite cluster, I will use the terms ‚Äúcache‚Äù and ‚Äútable‚Äù interchangeably.  I will use ‚Äúcache‚Äù more often with reference to internal mechanics, and ‚Äútable‚Äù to SQL.  In general, outside Apache Ignite, these concepts may have a slightly different meaning, and outside this article may not always be equivalent.  So, taking into account the availability of permanent storage ‚Äúcache‚Äù Apache Ignite does not always fit into the common semantics of the word.  As for the ‚Äútable‚Äù, then on the basis of the Apache Ignite cache, several ‚Äútables‚Äù can be defined with the ability to be accessed using SQL, or no tables are defined at all (then the access will be possible only through the Java / .NET / C ++ API ). <br></div></div><br><h2>  Durable memory </h2><br>  To build efficient mixed storage in memory and on disk, without duplicating a huge amount of code, which would significantly increase the cost of product support, we had to significantly rework the architecture of data storage in memory. <br><br>  The new architecture - <a href="https://apacheignite.readme.io/docs/durable-memory">Durable Memory</a> - like Persistence, was tested on large GridGain clients since the end of last year, and debuted publicly since Apache Ignite 2.0.  It provides off-heap data storage in page format. <br><br><img src="https://habrastorage.org/web/606/c4b/59d/606c4b59d13a4956bfe1fbceb69bc777.png"><br><br><h3>  Memory Pages / Pages </h3><br>  The basic storage unit is the ‚Äúpage‚Äù, which contains actual data or metadata. <br><br>  When data is pushed onto a disk when the allocated memory is exhausted, this happens page by page.  Therefore, the page size should not be too large, otherwise the efficiency of displacement will suffer, since in large pages hot data will be more likely to be mixed with cold data, which will constantly pull the page up into memory. <br><br>  But when the pages become small, there are problems of saving massive entries that do not fit on one page, as well as problems of fragmentation and memory allocation (it is too expensive to request memory from the operating system for every small page that contains 1-2 entries). <br><br>  The first problem - with large records - is solved through the possibility of ‚Äúsmearing‚Äù such a record into several pages, each of which stores only a certain segment.  The flip side of this approach is lower performance when working with such records due to the need to crawl several pages to obtain complete information.  Therefore, if this is a frequent case for you, then it makes sense to consider increasing the default size of the page (initially 2 KiB with the ability to vary from 1-16 KiB) through <code>MemoryConfiguration.setPageSize(‚Ä¶)</code> . <br><br>  In most situations, it makes sense to override the page size also if it is different from the page size on your SSD (most often it is 4 KiB).  Otherwise, some performance degradation may be observed. <br><br>  The second problem - with fragmentation - is partially solved by <a href="https://apacheignite.readme.io/docs/memory-defragmentation">online defragmentation</a> built into the platform, which leaves only some small ‚Äúfireproof residue‚Äù on a data page that is too small to fit anything else. <br><br>  The third problem - the high cost of allocating memory for pages with a large number of them - is solved through the next level of abstraction, "segments". <br><br><h3>  Memory Segments / Segments </h3><br>  Segments are continuous blocks of memory that are an atomic unit of allocated memory.  When the allocated memory ends and if the usage limit has not yet been reached, an additional segment is requested from the OS, which is further internally divided into pages. <br><br>  In the current implementation, it is planned to allocate up to 16 memory segments per region with a segment size of at least 256 MiB.  The actual volume of a segment is defined as the difference between the maximum allowed memory and the original allocation divided by 15 (the 16th segment is the initially allocated memory).  For example, if the upper limit is 512 GiB per node and 16 GiB is initially allocated, then the size of the allocated segments will be (512 - 16) / 15 ‚âà 33 GiB. <br><br>  When we talk about segments, it is impossible not to mention the restrictions on memory consumption.  Let us consider their implementation in more detail. <br><br>  It is not optimal to make global settings for all relevant parameters: maximum and initial volumes, extrusion, and so on, since different data may have different storage requirements.  One example is online and archival data storage.  We may wish to store orders for the last year in the online storage, which is mostly in memory, because there may be hot data, but at the same time, we may want to store the old order history and the past internal transactions on disk, not even temporarily precious memory. <br><br>  It would be possible to set up restrictions at the level of each cache, but then we would get into a situation where, with a large number of tables ‚Äî a few hundred or thousands ‚Äî each would have to allocate a few crumbs of memory, or do overbooking, quickly getting a memory shortage error. <br><br>  A mixed approach was chosen that allows you to define limits for groups of tables, which brings us to the next level of abstraction. <br><br><h3>  Regions Memory </h3><br>  The top level of the <a href="https://apacheignite.readme.io/docs/durable-memory">Durable Memory</a> storage architecture is the ‚Äúmemory region‚Äù logical entity, which groups tables that share a single storage area with its own settings, restrictions, and so on. <br><br>  For example, if you have in your application a cache of goods with data that are critical to reliability and a number of derived aggregates caches that are actively filled but not very critical for loss, then you can define two memory regions: the first, with a 384 GiB consumption restriction and strict guarantees consistency, bind the cache of goods, and to the second, with a limit of 64 GiB and with weakened guarantees, bind all temporary caches that will be shared between these 64 GiB memory. <br><br>  Regions of memory impose restrictions, define storage settings, and group caches into space-related groups in terms of storage space. <br><br><h3>  Page types and data retrieval </h3><br>  Memory pages are divided into several types, the key of which are <i>data pages</i> and <i>indexes</i> . <br><br>  <i>Data pages</i> store data directly; they have already been discussed in general terms above.  If the record does not fit into one page, it will be spread over several, but this is not a free operation.  And if there are a lot of big entries in the application scenario, then it makes sense to increase the page size through <code>MemoryConfiguration.setPageSize(‚Ä¶)</code> .  Data is pushed out to disk by page: the page is either completely in RAM or completely on disk. <br><br>  <i>Index pages</i> are stored as <a href="https://en.wikipedia.org/wiki/B%252B_tree">B + trees</a> , each of which can be spread across multiple pages.  Index pages are always in memory for maximum prompt access when searching for data. <br><br><img src="https://habrastorage.org/web/5d2/cab/c57/5d2cabc57dec452d9a86e79c30db1aba.png"><br><br>  In this scheme, to obtain data by key, we go through the following process: <br><ol><li>  the client calls the <code>cache.get(keyA);</code> method <code>cache.get(keyA);</code> </li><li>  the client determines the server node, which is responsible for this key, using the built-in affinity function, and delegates a request over the network to this server node; </li><li>  the server node determines the region of memory that is responsible for the cache, according to the key in which the request goes; </li><li>  in the corresponding region, the meta-information page is accessed, which contains entry points to B + -trees for the primary key of this cache; </li><li>  the search for the required index page for the given key is performed; </li><li>  in the index page, the actual key search is performed and the data page that contains it is determined, as well as the offset in this page; </li><li>  the data page is accessed, and the value is read from the key. </li></ol><br><img src="https://habrastorage.org/web/8d4/f47/285/8d4f472851cf4987aee2042bf2694b86.png"><br><br><h3>  SQL </h3><br>  SQL queries using <a href="http://www.h2database.com/html/main.html">H2</a> generate a two-stage execution plan (in general), which essentially reduces to a <a href="https://en.wikipedia.org/wiki/MapReduce">MapReduce-like</a> approach.  The first stage of the plan is ‚Äúpoured‚Äù onto all nodes that are responsible for the table, where the definition of the memory region responsible for the table is similarly performed.  Further, if the selection is based on an index, the desired page of indexes is searched for, the locations of the selected values ‚Äã‚Äãare determined, and it is iterated on.  In the case of a full scan, a full iteration occurs over the primary index and, accordingly, all pages are accessed. <br><br><h3>  crowding out </h3><br>  Starting from version 2.0, preemption works page by page, with the removal of a page from memory.  If Persistence is configured, then the copy of the page and the recording in the indexes will remain intact, which will make it possible to later pick up the necessary information from the local disk.  If Persistence is explicitly disabled or not configured, then crowding will completely erase the corresponding data from the cluster. <br><br>  Page-by-page preemption makes it impossible to work with key-value pairs easily, but it is much better placed on Persistence, and with a sufficiently small page size gives good results. <br><br>  Version 2.1 <a href="https://apacheignite.readme.io/docs/evictions">supports 3 wipe modes</a> : <br><br><ul><li>  disabled - wipeout does not occur, if there is a shortage of memory, an error is thrown; </li><li>  random lru - when preempted in a cycle, random 5 data pages are selected, after which one is deleted ‚Äî the one with the smallest access timestamp (accessed most long ago).  The approach with the selection of 5 random pages was chosen because of the complexity of the high-performance implementation of the complete orderliness of access time stamps; </li><li>  random 2 lru is similar to the previous one, but each page has two access time stamps ‚Äî the last and the last but one ‚Äî and the minimum one is used to select it.  This approach allows us to more effectively handle situations, for example, with rare full scans or rare requests for a large part of the data set, which with random lru can create the appearance that some cold pages are hot. </li></ul><br><div class="spoiler">  <b class="spoiler_title">DataPageEvictionMode</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">/** * Defines memory page eviction algorithm. A mode is set for a specific * {</span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@link</span></span></span><span class="hljs-comment"> MemoryPolicyConfiguration}. Only data pages, that store key-value entries, are eligible for eviction. The * other types of pages, like index or meta pages, are not evictable. */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> DataPageEvictionMode { <span class="hljs-comment"><span class="hljs-comment">/** Eviction is disabled. */</span></span> DISABLED, <span class="hljs-comment"><span class="hljs-comment">/** * Random-LRU algorithm. * &lt;ul&gt; * &lt;li&gt;Once a memory region defined by a memory policy is configured, an off-heap array is allocated to track * last usage timestamp for every individual data page. The size of the array is calculated this way - size = * ({</span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@link</span></span></span><span class="hljs-comment"> MemoryPolicyConfiguration#getMaxSize()} / {</span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@link</span></span></span><span class="hljs-comment"> MemoryConfiguration#pageSize})&lt;/li&gt; * &lt;li&gt;When a data page is accessed, its timestamp gets updated in the tracking array. The page index in the * tracking array is calculated this way - index = (pageAddress / {</span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">@link</span></span></span><span class="hljs-comment"> MemoryPolicyConfiguration#getMaxSize()}&lt;/li&gt; * &lt;li&gt;When it's required to evict some pages, the algorithm randomly chooses 5 indexes from the tracking array and * evicts a page with the latest timestamp. If some of the indexes point to non-data pages (index or system pages) * then the algorithm picks other pages.&lt;/li&gt; * &lt;/ul&gt; */</span></span> RANDOM_LRU, <span class="hljs-comment"><span class="hljs-comment">/** * Random-2-LRU algorithm: scan-resistant version of Random-LRU. * &lt;p&gt; * This algorithm differs from Random-LRU only in a way that two latest access timestamps are stored for every * data page. At the eviction time, a minimum between two latest timestamps is taken for further comparison with * minimums of other pages that might be evicted. LRU-2 outperforms LRU by resolving "one-hit wonder" problem - * if a data page is accessed rarely, but accidentally accessed once, it's protected from eviction for a long time. */</span></span> RANDOM_2_LRU; <span class="hljs-comment"><span class="hljs-comment">// ... }</span></span></code> </pre> <br></div></div><br>  * * * <br>  In the next publication, I will discuss in more detail how Durable Memory lays down on the implementation of disk storage ( <a href="https://en.wikipedia.org/wiki/Write-ahead_logging">WAL</a> + Checkpointing), and also focuses on the possibilities of creating snepshots, which provide proprietary GridGain extensions. </div><p>Source: <a href="https://habr.com/ru/post/338606/">https://habr.com/ru/post/338606/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../338596/index.html">Development of profitable Android games by two students</a></li>
<li><a href="../338598/index.html">Illusion of speed</a></li>
<li><a href="../338600/index.html">The 13th article on typical DBA errors MS SQL Server</a></li>
<li><a href="../338602/index.html">Digest KolibriOS # 13</a></li>
<li><a href="../338604/index.html">Is it difficult to make an elephant out of a fly?</a></li>
<li><a href="../338610/index.html">Russian Post: Is it scary to live after Strashnov?</a></li>
<li><a href="../338612/index.html">Deploying ES2015 + code in production today</a></li>
<li><a href="../338614/index.html">Fast pool for php + websocket without node node jua based on lua + nginx</a></li>
<li><a href="../338616/index.html">IBM quantum computer taught to model complex chemical elements</a></li>
<li><a href="../338618/index.html">Supercomputer Cray XC40 will build a map of neurons</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>