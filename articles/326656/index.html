<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Data science and quality code</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Usually, machine learning models are built in jupyter laptops, the code of which looks, to put it mildly, not very good - long sheets of noodles of ex...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Data science and quality code</h1><div class="post__text post__text-html js-mediator-article"><p>  Usually, machine learning models are built in jupyter laptops, the code of which looks, to put it mildly, not very good - long sheets of noodles of expressions and calls "on the knee" of written functions.  It is clear that such code is almost impossible to maintain, so each project is rewritten almost from scratch.  And about the introduction of this code in production even scary to think. </p><br><p>  Therefore, today we are submitting to your strict court a preview of the Python library for working with datasets and data science models.  With it, your python code might look like this: </p><br><pre><code class="python hljs">my_dataset. load(<span class="hljs-string"><span class="hljs-string">'/some/path'</span></span>). normalize(). resize(shape=(<span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>)). random_rotate(angle=(<span class="hljs-number"><span class="hljs-number">-30</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>)). random_crop(shape=(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(MAX_ITER): batch = my_dataset.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  ,     </span></span></code> </pre> <br><p>  In this article you will learn about the main classes and methods that will help make your code simple, understandable and convenient. </p><br><a name="habracut"></a><br><p>  <em>The library is undergoing final polishing and has not yet been made publicly available.</em> <br>  <em>This article is not a complete documentation, but only a brief description of the library and examples of its use.</em> <br>  <em>Your comments will help finalize the library and incorporate the features you need into it.</em> </p><br><h1 id="dataset">  Dataset </h1><br><p>  The amount of data can be very large, and by the beginning of data processing you may not have all the data at all, for example, if they arrive gradually.  Therefore, the <code>Dataset</code> class does not store data in it.  It includes an index - a list of items of your data (these can be identifiers or just ordinal numbers), as well as the <code>Batch</code> class, which defines methods for working with data. </p><br><pre> <code class="python hljs">dataset = Dataset(index = some_index, batch_class=DataFrameBatch)</code> </pre> <br><p>  The main purpose of <code>Dataset</code> is the formation of batches. </p><br><pre> <code class="python hljs">batch = dataset.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment"># batch -   DataFrameBatch, #  BATCH_SIZE  </span></span></code> </pre> <br><p>  or you can call a generator: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset.gen_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, one_pass=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>): <span class="hljs-comment"><span class="hljs-comment"># batch -   DataFrameBatch</span></span></code> </pre> <br><p>  Butches can be collected in a strictly orderly or chaotic manner, iterate endlessly or make exactly 1 cycle according to your data.  You can even create batches of different sizes at every step, if it makes sense in your situation. </p><br><p>  In addition to the iteration in <code>Dataset</code> , another useful operation is <code>cv_split</code> - <code>cv_split</code> - which divides dataset into train, test, and validation.  And, which is especially convenient, each of them is again dataset. </p><br><pre> <code class="python hljs">dataset.cv_split([<span class="hljs-number"><span class="hljs-number">0.7</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>]) <span class="hljs-comment"><span class="hljs-comment">#    70 / 20 / 10 #     for i in range(MAX_ITER): batch = dataset.train.next_batch(BATCH_SIZE, shuffle=True) #  ,     </span></span></code> </pre> <br><h1 id="indeks">  Index </h1><br><p>  Dataset elements are addressed using an index.  This may be a set of identifiers (clients, transactions, CT images) or just sequence numbers (for example, <code>numpy.arange(N)</code> ).  Dataset can be (almost) arbitrarily large and not fit in RAM.  But this is not required.  After all, data processing is performed by batch. </p><br><p>  Creating an index is very simple: </p><br><pre> <code class="python hljs">ds_index = DatasetIndex(sequence_of_item_ids)</code> </pre> <br><p>  The sequence can be a list, <code>numpy</code> array, <code>pandas.Series</code> or any other iterated data type. </p><br><p>  When the source data is stored in separate files, it is convenient to build an index immediately from the list of these files: </p><br><pre> <code class="python hljs">ds_index = FilesIndex(path=<span class="hljs-string"><span class="hljs-string">'/some/path/*.dat'</span></span>, no_ext=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Here, the elements of the index will be the file names (without extensions) from the specified directory. </p><br><p>  It happens that elements of dataset (for example, 3-dimensional CT images) are stored in separate directories. </p><br><pre> <code class="python hljs">ds_index = FilesIndex(path=<span class="hljs-string"><span class="hljs-string">'/ct_images_??/*'</span></span>, dirs=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  This will build the general index of all subdirectories of <code>/ct_images_01</code> , <code>/ct_images_02</code> , <code>/ct_images_02</code> , etc.  The file index remembers the full paths of its elements.  Therefore, later in the <code>load</code> or <code>save</code> method you can conveniently get the path <code>index.get_fullpath(index_item)</code> . </p><br><p>  Although most often you don‚Äôt have to operate with indices at all - all the necessary work is done inside, and you already work only with the whole batch. </p><br><h1 id="klass-batch">  Class batch </h1><br><p>  All storage logic and methods for processing your data are defined in the <code>Batch</code> class.  Let's create a class for working with CT images as an example.  The base class <code>Batch</code> , the descendant of which will become our <code>CTImagesBatch</code> , already has an <code>index</code> attribute that stores the list of elements of this batch, as well as the <code>data</code> attribute, which is initialized to <code>None</code> .  And since this is enough for us, we will not redefine the constructor. </p><br><p>  Therefore, we will immediately proceed to the creation of an <code>action</code> <code>load</code> method: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CTImagesBatch</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Batch)</span></span></span><span class="hljs-class">:</span></span> @action <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, src, fmt)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> fmt == <span class="hljs-string"><span class="hljs-string">'dicom'</span></span>: self.data = self._load_dicom(src) <span class="hljs-keyword"><span class="hljs-keyword">elif</span></span> fmt == <span class="hljs-string"><span class="hljs-string">'blosc'</span></span>: self.data = self._load_blosc(src) <span class="hljs-keyword"><span class="hljs-keyword">elif</span></span> fmt == <span class="hljs-string"><span class="hljs-string">'npz'</span></span>: self.data = self._load_npz(src) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> ValueError(<span class="hljs-string"><span class="hljs-string">"Incorrect format"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self</code> </pre> <br><p>  First, the method must be preceded by the <code>@action</code> decorator (later you will know why). </p><br><p>  Secondly, it must return a <code>Batch</code> object.  This may be a new object of the same class (in this case, CTImagesBatch), or an object of another class (but necessarily a descendant of <code>Batch</code> ), or you can simply return <code>self</code> . </p><br><p>  This approach allows you to describe the chain of actions on data.  Moreover, in the course of processing, data may change not only in content, but also in format and structure. </p><br><p>  We will not spend time on private methods <code>_load_dicom</code> , <code>_load_blosc</code> and <code>_load_npz</code> .  They are able to load data from files of a specific format and return a 3-dimensional <code>numpy</code> array ‚Äî [batch size, image width, image height].  The main thing is that it was here that we determined how the data of each batch is arranged, and we will continue to work with this array. </p><br><p>  Now let's write the <code>very_complicated_processing</code> method, which performs some extremely complex image processing.  Since the images in the batch are independent of each other, it would be convenient to process them in parallel. </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CTImagesBatch</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Batch)</span></span></span><span class="hljs-class">:</span></span> ... @action @inbatch_parallel(target=<span class="hljs-string"><span class="hljs-string">'threads'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">very_complicated_processing</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, item, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#   ... return processed_image_as_array</span></span></code> </pre> <br><p>  That is, the method should be written as if it processes one snapshot, and the index of this snapshot is passed in the first parameter. </p><br><p>  In order for the parallelism magic to work, the method needs to be wrapped by the decorator, where the parallelism technology is defined (processes, threads, etc.), as well as the pre- and post-processing functions that are called before and after the parallelization. </p><br><p>  By the way, it is better to write operations with intensive input-output as <code>async</code> methods and parallelize through <code>target='async'</code> , which will significantly speed up data loading and unloading. </p><br><p>  It is clear that this all adds to the convenience of programming, but it does not at all relieve the ‚Äú <em>thinking</em> ‚Äù, is there any need for parallelism, which one and what will not make it worse? </p><br><p>  When all the <code>action</code> methods are written, you can work with the batch: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(MAX_ITER): batch = ct_images_dataset.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) processed_batch = batch.load(<span class="hljs-string"><span class="hljs-string">'/some/path/'</span></span>, <span class="hljs-string"><span class="hljs-string">'dicom'</span></span>) .very_complicated_processing(some_arg=some_value) .resize(shape=(<span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>)) .random_rotate(angle=(<span class="hljs-number"><span class="hljs-number">-30</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>)) .random_crop(shape=(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>)) <span class="hljs-comment"><span class="hljs-comment">#  ,   processed_batch   </span></span></code> </pre> <br><p>  It looks good ... but somehow it is wrong that the iteration over the batch is mixed with data processing.  Yes, and I want to shorten the cycle of learning the model, so that there is nothing at all except <code>next_batch</code> . </p><br><p>  In general, it is necessary to move the chain of <code>action</code> methods to the dataset level. </p><br><h1 id="payplayn">  Pipeline </h1><br><p>  And it can be done.  It‚Äôs not for nothing that we have guarded all these <code>action</code> decorators.  They contain the cunning magic of transferring methods to the level of dataset.  So just write: </p><br><pre> <code class="python hljs">ct_images_pipeline = ct_images_dataset.pipeline(). .load(<span class="hljs-string"><span class="hljs-string">'/some/path/'</span></span>, <span class="hljs-string"><span class="hljs-string">'dicom'</span></span>) .very_complicated_processing(some_arg=some_value) .resize(shape=(<span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>)). .random_rotate(angle=(<span class="hljs-number"><span class="hljs-number">-30</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>)) .random_crop(shape=(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>)) <span class="hljs-comment"><span class="hljs-comment"># ... for i in range(MAX_ITER): batch = ct_images_pipeline.next_batch(BATCH_SIZE, shuffle=True) #  ,      </span></span></code> </pre> <br><p>  You do not need to create a new descendant class <code>Dataset</code> and describe all these methods in it.  They are in the corresponding <code>Batch</code> classes and are marked by the <code>@action</code> decorator, <code>@action</code> means you can safely call them as if they were in the <code>Dataset</code> class. </p><br><p>  Another trick is that with this approach, all <code>action</code> methods become "lazy" (lazy) and are executed deferred.  That is, loading, processing, resizing and other actions are performed for each batch at the moment of the formation of this batch by calling <code>next_batch</code> . </p><br><p>  And since the processing of each batch can take a lot of time, it would be nice to form the batch in advance.  This is especially important if the model is trained on the GPU, because then a simple GPU, while waiting for a new batch, can easily ‚Äúeat‚Äù all the advantages of its high performance. </p><br><pre> <code class="python hljs">batch = ct_images_pipeline.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, prefetch=<span class="hljs-number"><span class="hljs-number">3</span></span>)</code> </pre> <br><p>  The <code>prefetch</code> parameter indicates that 3 batch should be considered in parallel.  Additionally, you can specify the parallelization technology (processes, threads). </p><br><h1 id="obedinyaem-datasety">  We unite datasets </h1><br><p>  In real machine learning tasks, you rarely have to deal with a single dataset.  Most often you will have at least two data sets: X and Y. For example, data on the parameters of houses and data on their cost.  In computer vision tasks, in addition to the images themselves, there are class labels, segmenting masks and bounding boxes. </p><br><p>  In general, it is useful to be able to form parallel batches from several datasets.  And for this you can perform the <code>join</code> operation or create a <code>JointDataset</code> . </p><br><h2 id="jointdataset">  JointDataset </h2><br><p>  If you need only a parallel iteration of the batches, it will be more convenient to create a single dataset: </p><br><pre> <code class="python hljs">joint_dataset = JointDataset((ds_X, ds_Y))</code> </pre> <br><p>  If <code>ds_X</code> and <code>ds_Y</code> are not based on the same index, then it is important that the indexes are of the same length and are equally ordered, that is, the value of <code>ds_Y[i]</code> corresponds to the value of <code>ds_X[i]</code> .  In this case, the creation of dataset will look a little different: </p><br><pre> <code class="python hljs">joint_dataset = JointDataset((ds_X, ds_Y), align=<span class="hljs-string"><span class="hljs-string">'order'</span></span>)</code> </pre> <br><p>  And then everything happens in a completely standard way: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(MAX_ITER): batch_X, batch_Y = joint_dataset.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Only now <code>next_batch</code> returns not one batch, but a tuple with batches from each dataset. </p><br><p>  Naturally, <code>JointDataset</code> can also consist of pipelines: </p><br><pre> <code class="python hljs">pl_images = ct_images_ds.pipeline() .load(<span class="hljs-string"><span class="hljs-string">'/some/path'</span></span>, <span class="hljs-string"><span class="hljs-string">'dicom'</span></span>) .hu_normalize() .resize(shape=(<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>)) .segment_lungs() pl_labels = labels_ds.pipeline() .load(<span class="hljs-string"><span class="hljs-string">'/other/path'</span></span>, <span class="hljs-string"><span class="hljs-string">'csv'</span></span>) .apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: (x[<span class="hljs-string"><span class="hljs-string">'diagnosis'</span></span>] == <span class="hljs-string"><span class="hljs-string">'C'</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'int'</span></span>)) full_ds = JointDataset((pl_images, pl_labels), align=<span class="hljs-string"><span class="hljs-string">'same'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(MAX_ITER): images_batch, labels_batch = full_ds.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#    ,       </span></span></code> </pre> <br><p>  And since the components of the dataset are pipelines, the loading and processing of images and tags is started only by calling <code>next_batch</code> .  That is, all calculations are performed and the batch is formed only when it is needed. </p><br><h2 id="operaciya-join">  Join operation </h2><br><p>  However, there are other situations when you need to perform an operation with a dataset, applying data from another dataset to it. </p><br><p>  It is better to demonstrate this with the example of CT images.  We load the coordinates and dimensions of the cancer and form three-dimensional masks from them. </p><br><pre> <code class="python hljs">pl_masks = nodules_ds.pipeline() .load(<span class="hljs-string"><span class="hljs-string">'/other/path'</span></span>, <span class="hljs-string"><span class="hljs-string">'csv'</span></span>) .calculate_3d_masks()</code> </pre> <br><p>  Load CT images and apply masks to them to isolate only cancerous areas. </p><br><pre> <code class="python hljs">pl_images = ct_images_ds.pipeline(). .load(<span class="hljs-string"><span class="hljs-string">'/some/path'</span></span>, <span class="hljs-string"><span class="hljs-string">'dicom'</span></span>) .hu_normalize() .resize(shape=(<span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>)) .join(pl_masks) .apply_masks(op=<span class="hljs-string"><span class="hljs-string">'mult'</span></span>)</code> </pre> <br><p>  In <code>join</code> you specify.  Due to this, the next <code>action</code> method (in this example, in <code>apply_masks</code> ) will be passed the batch from this dataset as the first argument.  And not just any batches, but exactly those that are needed.  For example, if the current batch from <code>ct_images_ds</code> contains images 117, 234, 186 and 14, then the attached batch with masks will also apply to images 117, 234, 186 and 14. </p><br><p>  Naturally, the <code>apply_masks</code> method should be written with this argument in mind, because it can be passed explicitly, without first <code>join</code> .  And in the <code>action</code> method you can no longer think about the indices and identifiers of the elements of the batch - you just apply an array of masks to the image array. </p><br><p>  Again, I note that no downloads and calculations, neither with images nor with masks, will be launched until you call <code>pl_images.next_batch</code> </p><br><h1 id="sobiraem-vse-vmeste">  Putting it all together </h1><br><p>  So, let's see how the full workflow data science of the project will look like. </p><br><ol><li>  Create an index and dataset <br><pre> <code class="python hljs">ct_images_index = FilesIndex(path=<span class="hljs-string"><span class="hljs-string">'/ct_images_??/*'</span></span>, dirs=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) ct_images_dataset = Dataset(index = ct_images_index, batch_class=CTImagesBatch)</code> </pre> </li><li><p>  We perform preprocessing and save the processed images. </p><br><pre> <code class="python hljs">ct_images_dataset.pipeline() .load(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-string"><span class="hljs-string">'dicom'</span></span>) <span class="hljs-comment"><span class="hljs-comment">#     dicom     .hu_normalize() .resize(shape=(256, 256, 256)) .segment_lungs() .save('/preprocessed/images', 'blosc') .run(BATCH_SIZE, shuffle=False, one_pass=True)</span></span></code> </pre> <br></li><li><p>  Describe the preparation and augmentation of data for the model. </p><br><pre> <code class="python hljs">ct_preprocessed_index = FilesIndex(path=<span class="hljs-string"><span class="hljs-string">'/preprocessed/images/*'</span></span>) ct_preprocessed_dataset = Dataset(index = ct_preprocessed_index, batch_class=CTImagesBatch) <span class="hljs-comment"><span class="hljs-comment"># ct_images_pipeline = ct_preprocessed_dataset.pipeline() .load(None, 'blosc') .split_to_patches(shape=(64, 64, 64)) # ct_masks_ds = Dataset(index = ct_preprocessed_index, batch_class=CTImagesBatch) ct_masks_pipeline = ct_masks_ds.pipeline(). .load('/preprocessed/masks', 'blosc') .split_to_patches(shape=(64, 64, 64)) # full_ds = JointDataset((ct_images_pipeline, ct_masks_pipeline))</span></span></code> </pre> <br></li><li><p>  We form training batches and train the model </p><br><pre> <code class="python hljs">full_ds.cv_split([<span class="hljs-number"><span class="hljs-number">0.8</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(MAX_ITER): images, masks = full_ds.train.next_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  ,      </span></span></code> </pre> <br></li><li>  Check the quality of the model <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> images, masks <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> full_ds.test.gen_batch(BATCH_SIZE, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, one_pass=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>): <span class="hljs-comment"><span class="hljs-comment">#    </span></span></code> </pre> </li></ol><br><p>  This is such a convenient library that helps to develop significantly faster high-quality code, reuse previously created models with complex data preprocessing, and even develop production-ready systems. </p><br><p>  And now the question: what else should I add to the library?  What are you sorely lacking when working with data and models? </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/326656/">https://habr.com/ru/post/326656/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../326646/index.html">Simplify converters for WPF</a></li>
<li><a href="../326648/index.html">St. Petersburg homeless - in Prague. Continuing the history of self-taught developer</a></li>
<li><a href="../326650/index.html">Introduction to machine learning with tensorflow</a></li>
<li><a href="../326652/index.html">Processing of personal data? No, not to us. Elegant solution from Golos</a></li>
<li><a href="../326654/index.html">About multitenancy</a></li>
<li><a href="../326658/index.html">Resources for startups: action plan in links</a></li>
<li><a href="../326660/index.html">Recover Group Policy Objects (GPOs) with Veeam Explorer for Active Directory</a></li>
<li><a href="../326662/index.html">The book "Extreme programming: development through testing"</a></li>
<li><a href="../326664/index.html">Why site designers give out bad code?</a></li>
<li><a href="../326666/index.html">CIA Board Games</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>