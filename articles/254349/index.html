<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How the process in Data Science works</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! 

 After the last publication, ‚ÄúYour Personal Course on Big Data,‚Äù I received several hundred letters with questions, reading which, I was s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How the process in Data Science works</h1><div class="post__text post__text-html js-mediator-article"><img align="left" src="https://habrastorage.org/files/45c/f8b/f47/45cf8bf47c944737bf9d2881a7fed3d4.png">  Hi, <b>Habr!</b> <br><br>  After the last publication, <a href="http://habrahabr.ru/post/252743/">‚ÄúYour Personal Course on Big Data,‚Äù</a> I received <b>several hundred letters</b> with questions, reading which, I was surprised to find that people immersed themselves in theory very much, taking little time to solve practical problems in which skills are needed <b>completely different</b> .  Today I will tell you what difficulties appear <b>in practice</b> and what you have to work with in solving <b>real problems</b> . <br><a name="habracut"></a><br><br>  Those who have already completed a large number of machine learning courses and started to solve problems at <a href="http://www.kaggle.com/">Kaggle</a> know very well what a typical problem statement looks like: "A set of <b>training sample objects is given</b> , for <b>each</b> of which <b>there are signs</b> , and the <b>values ‚Äã‚Äãof the target variable are given</b> . Also a test sample, for each object of which the value of the target variable must be predicted. "  There are more complex productions, here I just gave the most typical - for regression and classification problems.  This starts solving the problem on kaggle.com - you read the condition of the problem safely, look at the quality metrics, download data, launch <b>IPython Notebook</b> , connect your favorite libraries and start working hard and long with data, select hyper parameters of models, select signs, train a lot of classifiers and weigh them, find complex objects and look at them more carefully, etc. Thus, you struggle to optimize the quality metric and get a decent position in the <b>Leader Board</b> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Unfortunately, in practice, everything looks completely different.  In fact, <b>90% of the work has been done before you</b> .  The skills of building quality models are certainly important, but <b>not paramount</b> .  Pay attention to the words highlighted above in the problem statement - they are not accidental, since  in real life, nothing is ‚Äúgiven to you‚Äù, there is no ‚Äúquality metric‚Äù, there is no ‚Äútraining sample‚Äù, not to mention the fact that <b>there is no task</b> in essence - there is only a vague description of what goal is pursued in solving one or another tasks.  And here begins the real work of the scientist according to the data, in which most of the time is routine, and it is necessary to think far in advance and long before there is a clear statement of the problem and the ‚Äúobject-feature‚Äù matrix is ‚Äã‚Äãbuilt. <br><br>  In short, the most common problems encountered are the following: <br><br><ul><li>  <b>Blurred statement of the problem</b> </li><li>  <b>A large number of degrees of freedom</b> </li><li>  <b>A large number of different data sources</b> </li><li>  <b>Data quality and gaps</b> </li><li>  <b>"Raw" software for working with data</b> </li><li>  <b>Disadvantages of working with big data</b> </li><li>  <b>The presence of the training sample</b> </li></ul><br>  So, let's analyze each of the problems in order: <br><br><h3>  Blurred statement of the problem </h3><br>  The task does not arise by itself - every thing we do - is done for a specific purpose.  And <b>business goals are often formulated quite informally:</b> ‚Äúreduce customer churn,‚Äù ‚Äúincrease revenue from affiliate programs,‚Äù ‚Äúretain users,‚Äù ‚Äúreduce the burden on a particular business department by optimizing business processes.‚Äù  It is in this formulation (more often - a little more precisely) that the task falls to <b>Data Scientist</b> 's.  That is why this person should be familiar with the business in order to understand what is really needed.  If, for example, the task of promoting services is solved or a targeted offer is developed, it is necessary to understand how the process of interaction with the client will be arranged, how the advertising campaign will be conducted, how the criteria for its success will be determined - and why do we need machine learning in the end? all this needs to be known with precision.  But as soon as you start to deal with the details - you have the following problem. <br><br><h3>  A large number of degrees of freedom </h3><br>  What is - "the client went into the outflow" - in the language of business is clear - the business begins to lose money.  But the vaults that contain customer information do not understand this - they store dozens of statuses in which outflows can mean blocking, termination of the contract, non-use of services for a certain period of time, untimely payment of bills - all this can be called customer outflow in one or a different degree.  What do you think - if the formulation of the target parameter and the problem statement allows so many degrees of freedom - how easy is it to generate attributes for the task?  Right!  - it is even harder to do.  Now imagine for a moment that we have decided on the task itself and the signs.  And how will contact with the client be made?  - and here it turns out that the process of retaining a client is a complex procedure that takes time and which has certain features.  If we say, you predict that the client is inclined to go into the outflow with a certain probability on some date, then there is also the likelihood that you simply do not have time to interact with it.  And all this must be considered long before the development of the algorithm.  That is why it is necessary to learn how to quickly dive into a particular subject area in order to know the whole process and all the details.  Suppose that we coped with this, we also decided on what signs we need to solve the problem.  But then a new problem arises. <br><br><h3>  A large number of different data sources </h3><br>  Data, especially in a large company, is not always stored in one source.  And far from always the means for working with this data are the same, because it can be as <b>sequence files</b> in <b>HDFS</b> , <b>noSQL</b> databases, and also relational sources.  But after all, we often need an ‚Äúobject-attribute‚Äù matrix - which means we have to do a large number of all our favorite <b>join</b> 's - which, in the case of big data, makes us think about how to make requests optimally.  It will require skills to work with different tools, ranging from <b>SQL, Hive, Pig</b> and ending with the fact that it is often easier to write code in <b>Java / Scala</b> than to use SQL-like languages.  However, if you are familiar with all these tools and imagine how to write complex <b>join</b> 's correctly, other problems arise. <br><br><h3>  Data quality and gaps </h3><br>  Very often (the larger the company - the more often) you will have a large number of <b>gaps in the data</b> - for example, if the task requires some specific signs to solve - it may turn out that most of these signs are available only for a small group of clients.  Further, even if customer data is available, it turns out that in the data part there are so-called outliers, not to mention the fact that  and data sources are different - the same data can be stored in different formats and you have to <b>join</b> everything to the same form with the same <b>join</b> 'e.  But suppose that you coped with it.  They wrote a good script on Hive / Pig or on <b>Spark</b> and launched.  Think it all?  Not really. <br><br><h3>  "Raw" software for working with data </h3><br>  The main reason for the popularity of Big Data at one time was cheap.  In particular, <b>most of the popular tools for working with big data are open-source development</b> , be it Hive, Pig, or everyone's favorite <b>Apache Spark</b> .  But those who have had experience with open-source tools at least once know perfectly well that it‚Äôs not at all worth counting on them and that from the first time everything does not always start.  For example, if you wrote a simple script that sequentially reads files from HDFS and moved away for several hours.  With the arrival, you can easily find out that the script ‚Äúfell‚Äù simply because, among the folder with files you read, there happened to be some <b>* .tmp</b> file that Pig, for example, could not read.  Everyone who has worked with Apache Spark - can also tell you about the problems of reading small files, about the fact that it is often hard to save built models on it - you have to write your own serializers.  There are many such examples.  But, let's say, you have been running and testing the code for a long time, and here, it seems, you have a long-awaited ‚Äúobject-sign‚Äù matrix. <br><br><h3>  Disadvantages of working with big data </h3><br>  And here you are, imagine that you have a large amount of data.  Suppose even that you have a small training sample that fits in RAM, and you have already built a good model.  As a rule, at the same time you generated a large number of new features (we did the <b>Feature Engineering</b> , which we met <a href="http://habrahabr.ru/post/248129/">here</a> and <a href="http://habrahabr.ru/post/249759/">here</a> ).  And what to do with the very huge sample of objects for which you need to call your long-awaited <b>Predict</b> function?  After all, for it, too, you need to do all the same transformations that you did with the training sample ‚Äî add new columns, fill in the blanks, normalize the data.  When building a model, you probably did this with great packages like <b>Pandas</b> , which dealt with <b>DataFrames</b> .  Everything, now they are no more - everything will have to be done by hand.  The only thing left to rejoice here is that in Apache Spark version 1.3 there is support for DataFrame, which will allow working with big data as fast as it is done in <b>R</b> or <b>Python</b> .  Probably. <br><br><h3>  The presence of the training sample </h3><br>  This is probably not the most unpleasant, but at the same time an important problem that arises in practice - <b>where to get the training sample?</b>  Here you have to think a lot, because  It is important <b>to strike a balance between the size of the training sample and its quality.</b>  For example, in some tasks there is often a certain set of training objects and it is possible by clustering and imposing training objects to try to increase the size of the training sample.  You can also find a training set by solving a variety of auxiliary problems ‚Äî there are no uniform methods here ‚Äî you have to get out of each time for a specific task. <br><br><h3>  Total </h3><br>  So, I hope that after reading this post, you still want to actively engage in data analysis.  After all, all these problems are somehow solved with time (I can say this in my case, as well as by interviewing my colleagues from other companies).  This is always the case when new tools appear, as is the case with Apache Spark.  However, it is important to know about all these features and difficulties in advance. <br><br>  Successes all and excellent beginnings! </div><p>Source: <a href="https://habr.com/ru/post/254349/">https://habr.com/ru/post/254349/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../254335/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ153 (March 22 - 29, 2015)</a></li>
<li><a href="../254337/index.html">PHP Digest number 59 - interesting news, materials and tools (March 16 - 29, 2015)</a></li>
<li><a href="../254339/index.html">Self resettable fuses. Myths and Reality</a></li>
<li><a href="../254343/index.html">Daniil Dubrovkin: "Open source does not mean that it is free and that it does not belong to anyone."</a></li>
<li><a href="../254345/index.html">New in Wolfram Language: WikipediaData feature for integrating with Wikipedia and processing its data</a></li>
<li><a href="../254351/index.html">How to catch what is not. Part Three: Who are the judges?</a></li>
<li><a href="../254353/index.html">Optimization Planning with Unity</a></li>
<li><a href="../254355/index.html">All about collections in Oracle</a></li>
<li><a href="../254357/index.html">Basket for product catalog (minibasket.js)</a></li>
<li><a href="../254361/index.html">Indoor "GPS" with an accuracy of -2 cm</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>