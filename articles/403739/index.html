<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Created a bionic hand with a neural network that instantly recognizes and grabs items</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Past generation bionic prostheses are usually controlled with the help of myoelectric signals, which arise as a result of muscular contractions of the...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Created a bionic hand with a neural network that instantly recognizes and grabs items</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/geektimes/post_images/17b/0b5/4a1/17b0b54a1c514ecd09a61b41fd826fc0.jpg"><br><br>  Past generation bionic prostheses are usually controlled with the help of myoelectric signals, which arise as a result of muscular contractions of the human hand.  To manage such a prosthesis is not easy: it requires a certain concentration, and the effectiveness of successful actions leaves much to be desired.  Not easy from the first time to do what you want.  In terms of the accuracy of such actions, such prostheses are far from the ‚Äúintuitive‚Äù actions of a living real hand. <br><br>  In recent years, researchers have focused mainly on the accuracy of recognition of myoelectric signals, and the accuracy of recognition of movements of individual fingers has reached 90%.  But due to a number of technical reasons, the massive use of such "smart" prostheses is very limited.  <a href="http://iopscience.iop.org/article/10.1088/1741-2552/aa6802">New development of</a> engineers from the University of Newcastle (UK) offers a fundamentally different approach.  A hand equipped with a video camera recognizes an object in front of it - and determines for itself how to grab it most effectively.  It acts automatically and almost instantly, without additional efforts on the part of the person.  In fact, the bionic arm has its own vision. <br><a name="habracut"></a><br>  Previously, scientists experimented with stereo cameras and various object recognition algorithms.  At the same time, new models of manipulators for robots were created - there, computer vision technologies are very similar to bionic prostheses for humans.  It was in the field of robotics that the most promising technologies of machine vision and in-depth training were tested. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Engineers from the University of Newcastle used these developments of their predecessors and aimed the machine vision system to recognize the <i>type of capture</i> for objects of different types, rather than on the basis of a specific measurement of its dimensions.  That is, the objects after learning of the neural network are classified precisely by the type of capture, and not by the type or category of the object.  The authors believe that due to such a fundamentally new approach, they managed to significantly improve the speed of the system, since it ignores unnecessary details. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b4e/190/170/b4e190170729127c1b8f924325161071.jpg"><br>  <font color="gray">For comparison: classification by object category (above) or one of the four types of capture (below)</font> <br><br>  For training the system was used convolutional neural network.  It turned out that its architecture is perfect for this type of task, namely for bionic prosthetic hands.  For example, other methods of computer vision experienced problems when faced with objects that do not fall into any of the known categories.  But the identification of unknown objects is one of the most important qualities of a bionic prosthesis with machine vision.  Therefore, the convolutional neural network is ideal for this task. <br><br>  The training system took place on the <a href="">Amsterdam Image Bank</a> , where there are a large number of home objects. <br><br>  The architecture of a two-layer convolutional neural network for feature extraction and classification is shown in the illustration below. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/eb8/085/42e/eb808542e548fbc160f60375548edfd4.jpg"><br><br>  In tests on real patients with prostheses, the system was tested on 8 known and 16 unknown objects in a random position.  The results for the two volunteers are shown in the graphs on the left and right.  Taking into account the allowable errors, the accuracy of recognition and capture of objects was 88% and 87% for the first and second volunteers, respectively. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/412/3d9/246/4123d924622c5a06283db2866c06f0c4.jpg"><br><br>  Most importantly, such a bionic prosthesis works almost in real time: the choice of the type of capture is carried out in milliseconds, as opposed to 0.75-24 seconds for bionic hands, where machine vision performs the classification of objects.  Even the best bionic prostheses of this type <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1525-1594.2010.01040.x/abstract%3Bjsessionid%3D57D6B616C511415C21409A83C2FD48E6.f04t04">CyberHand</a> and <a href="http://iopscience.iop.org/article/10.1088/1741-2560/11/4/046001/meta">SmartHand</a> cope with recognition in 4 and 1 second, respectively.  They run powerful computers and show capture accuracy of 93% and 94%, respectively.  Although there is a little higher accuracy, but the capture in real time or with a pause of one second is a big difference, so the achievement of British biomedical engineers should not be underestimated.  This is the first bionic hand, which is able to grab objects "intuitively", as if not thinking.  A person only gives a signal with a small movement of the muscle that the object needs to be captured - and a smart hand with a neural network quickly does the rest on its own. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/rBZKrpf3Y4U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  The scientific article was <a href="http://iopscience.iop.org/article/10.1088/1741-2552/aa6802/meta">published</a> on May 3, 2017 in the <i>Journal of Neural Engineering</i> (doi: 10.1088 / 1741-2552 / aa6802). </div><p>Source: <a href="https://habr.com/ru/post/403739/">https://habr.com/ru/post/403739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../403729/index.html">ITER: switching equipment</a></li>
<li><a href="../403731/index.html">What to smear on the teeth so that they do not fall out</a></li>
<li><a href="../403733/index.html">McDonald's and other companies use ultrasound to spy on users.</a></li>
<li><a href="../403735/index.html">Weapons heroes. Maxim's machine gun under X-rays and disassembly of the PPSh-41 to the screw</a></li>
<li><a href="../403737/index.html">Air quality monitor from dj. Carbon Dioxide Measurement</a></li>
<li><a href="../403741/index.html">See the invisible: look inside the thermal imager Seek Thermal (and not just)</a></li>
<li><a href="../403743/index.html">Google AIY: Maker Kit for Voice-activated Gadgets</a></li>
<li><a href="../403745/index.html">Competition for replacing the RD ‚Äì 180: passions</a></li>
<li><a href="../403747/index.html">Amazon's digital assistant Alexa was turned into an assistant in a science lab.</a></li>
<li><a href="../403749/index.html">Tax preparation in 1950: IBM 403 "programming" with a plug-in panel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>