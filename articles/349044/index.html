<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What Robotics Can Teach Game AI</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I am a robotics researcher and at the same time my hobby is game development. My specialization is the planning of multidimensional motion of robot ma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What Robotics Can Teach Game AI</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d8b/6b7/9e2/d8b6b79e2805ee59f3ef01e5d9c28820.png"></div><br>  I am a robotics researcher and at the same time my hobby is game development.  My specialization is the planning of multidimensional motion of robot manipulators.  Traffic planning is a very important topic for game developers, it comes in handy every time you need to move a controlled AI character from one point to another. <br><br>  In the process of studying game development, I found many tutorials telling about motion planning (usually in the game development literature it is called ‚Äúfinding the way‚Äù), but most of them didn‚Äôt go into details of what movement planning is from a theoretical point of view .  As far as I can tell, in most games, some other motion planning is rarely used, except for one of the three serious algorithms: search on A * grids, visibility graphs and flow fields.  In addition to these three principles, there is a whole world of theoretical studies of motion planning, and some of them may be useful to game developers. <br><br>  In this article I would like to talk about the standard techniques of traffic planning in my context and explain their advantages and disadvantages.  I also want to introduce the basic techniques that are not commonly used in video games.  I hope they shed light on how they can be used in game development. <br><a name="habracut"></a><br><h1>  Movement from point A to point B: agents and targets </h1><br>  Let's start with the fact that we have an AI-controlled character in the game, for example, an enemy in a shooter or a unit in a strategic game.  We will call this character an agent.  The agent is located in a specific place in the world called its ‚Äúconfiguration‚Äù.  In two dimensions, the agent configuration can be represented by only two numbers (usually x and y).  The agent wants to get to some other place in the world, which we will call the goal (Goal). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Let's imagine an agent in the form of a circle living in a flat two-dimensional world.  Suppose that an agent can move in any direction he needs.  If there is nothing but empty space between the agent and its target, the agent can simply move in a straight line from its current configuration to the target.  When he reaches the goal, he stops.  We can call this the ‚ÄúWalk To Algorithm‚Äù. <br><br> <code><strong>: WALK TO</strong></code> <br> <br><ol><li> <code><strong>  :</strong></code> <ol> <li> <code><strong>  .</strong></code> </li> </ol></li><li> <code><strong>: .</strong></code> </li> </ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/483/827/844/483827844a9174488787e1e0adcb670d.png"></div><br>  If the world is completely empty, then it fits perfectly.  It may seem obvious that we need to move from the initial configuration to the configuration of the target, but it is worth considering that the agent could move in a completely different way to get from the current configuration to the target.  He could cycle around until he reached the goal or move fifty kilometers away from it before returning and staying on the target. <br><br>  So why do we think the straight line is obvious?  Because in a sense, this is the ‚Äúbest‚Äù way of movement.  If we accept that the agent can only move at a constant speed in any direction, then the straight line is the shortest and fastest way to get from one point to another.  In this sense, the Walk To algorithm <strong>is optimal</strong> .  In this article we will talk a lot about optimality.  In essence, when we speak of the optimality of an algorithm, we mean that it is ‚Äúbetter than everyone‚Äù with a certain criterion of ‚Äúbest‚Äù.  If you want to get from point A to point B as quickly as possible and there is nothing on the way, then nothing compares to a straight line. <br><br>  And in fact, in many games (I would say, even <strong>in most</strong> games), the algorithm for moving along a straight Walk To is ideal for solving a problem.  If you have small 2D-enemies in the corridors or rooms that do not need to wander through the maze or follow the orders of the player, then you will never need anything more complicated. <br><br>  But if something suddenly appeared on the way? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/61b/db3/b2e/61bdb3b2e1b766307631119250b445e0.png"></div><br>  In this case, an object in the path (called an obstacle (Obstacle)) blocks the path of the agent to the target.  Since the agent can no longer move directly to the goal, he simply stops.  What happened here? <br><br>  Although the Walk To algorithm <strong>is optimal</strong> , it is not <strong>complete</strong> .  "Full" algorithm is able to solve all the problems in its field in a finite time.  In our case, an area is circles moving in a plane with obstacles.  Obviously, a simple move directly to the goal does not solve all the problems in this area. <br><br>  To solve all the problems in this area and solve them optimally, we need something more sophisticated. <br><br><h1>  Reactive planning: beetle algorithm </h1><br>  What would we do if there were obstacles?  When we need to get to the goal (for example, to the door), and there is something on the way (for example, a chair), then we just go around it and continue to move towards the goal.  This type of behavior is called "avoiding obstacles."  This principle can be used to solve our problem of moving the agent to the goal. <br><br>  One of the simplest obstacle avoidance <a href="http://www.cs.cmu.edu/~motionplanning/lecture/Chap2-Bug-Alg_howie.pdf">algorithms</a> is <a href="http://www.cs.cmu.edu/~motionplanning/lecture/Chap2-Bug-Alg_howie.pdf">the bug algorithm</a> .  It works as follows: <br><br> <code><strong> : BUG</strong></code> <br> <br><ol><li> <code>      .   M-.</code> </li> <li> <code>     M-        :</code> <br> <ol><li> <code>   ,  .</code> </li> <li> <code>   ,       ,       M-,       ,      M-.    M-,    2.</code> </li> </ol></li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cc4/284/ef4/cc4284ef453c5594ca29d5f555a47276.png"></div><br>  Step 2.2 requires an explanation.  In fact, the agent remembers all cases of meeting with the M-line for the current obstacle, and leaves the obstacle only on the M-line and closer to the target than at any other time before.  This is to avoid getting the agent into an infinite loop. <br><br>  In the figure above, the dotted line shows the M-line, and the orange arrows indicate the steps taken by our agent to achieve the goal.  They are called agent <strong>trajectories</strong> .  Surprisingly, the beetle's algorithm is very easy to solve many problems of this type.  Try to draw a bunch of crazy figures and see how well it works!  But does the bug algorithm work for <em>each</em> task?  And <em>why does</em> it work? <br><br>  The simple beetle algorithm has a lot of interesting features and demonstrates many key concepts to which we will again return in this article.  These concepts are: trajectory, politics, heuristics, completeness and optimality. <br><br>  We have already mentioned the concept of a <strong>trajectory</strong> , which is a simple sequence of configurations or movements made by an agent in its path.  The beetle algorithm can be considered a trajectory planner (Trajectory Planner), that is, an algorithm that obtains the initial configuration and the configuration of the target and returns the trajectory from the beginning to the target.  (In the game development literature, it is also sometimes called the ‚Äúpath planner‚Äù). <br><br>  But we must also mention the concept of <strong>politics</strong> .  If we do not interpret the beetle‚Äôs algorithm as returning the full trajectory from the beginning to the target, but interpret it as sending the agent a set of <em>instructions</em> that allow you to reach the target from <em>any</em> point, simply using your own configuration as a guide, then the beetle‚Äôs algorithm can be called a control policy (Control Policy).  A management policy is simply a set of rules that, based on the state of the agent, determines what actions the agent must perform next. <br><br>  In the beetle's algorithm, the M-line is a clear indicator of where the agent should be located next.  Why did we choose to follow the M-line, and not, say, a line from the current position of the agent to the target?  The answer is that the M-line is just a <strong>heuristic</strong> .  A heuristic is a general rule used to report the next step of the algorithm.  This rule gives some human knowledge of the algorithm.  Choosing a heuristic is often an important part of developing such an algorithm.  When choosing the wrong heuristics, the algorithm may be completely inoperable. <br><br>  Believe it or not (I didn‚Äôt believe at first), but the beetle's algorithm solves <strong>all the</strong> tasks in the field of two-dimensional circles, moving from the beginning to the goal.  This means that regardless of the location of the agent or the goal, if the agent can achieve the goal, the bug‚Äôs algorithm will allow it to do so.  Proof of this is beyond the scope of this article, but you can read about it if you wish.  If an algorithm can solve all the problems in its field for which there are solutions, then it is called a <strong>complete algorithm</strong> . <br><br>  But despite the fact that the beetle's algorithm can solve all the problems of this type, the trajectories it creates are not always the <strong>best</strong> possible categories by which the agent can achieve the goal.  In fact, a bug‚Äôs algorithm can sometimes make an agent do pretty stupid things (just try to create an obstacle, small in a clockwise direction and huge in another direction, and you will understand what I mean. If we define ‚Äúbest‚Äù as ‚Äútaking the shortest time, then the beetle's algorithm is by no means <strong>optimal</strong> . <br><br><h1>  Optimal planning: visibility graph </h1><br>  And if we need to solve the problem of moving circles among the obstacles along the optimal (shortest) path?  To do this, we can involve the geometry in order to estimate what the optimal algorithm for solving this problem should be.  First, note the following: <br><br><ul><li>  On two-dimensional Euclidean planes, the shortest path between two points is a straight line. </li><li>  The length of a sequence of straight-line trajectories is the sum of the lengths of each of the lines. </li><li>  Since a polygon consists of straight lines (or edges), the shortest path that completely circumvents a <strong><a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D1%258B%25D0%25BF%25D1%2583%25D0%25BA%25D0%25BB%25D1%258B%25D0%25B9_%25D0%25BC%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE%25D1%2583%25D0%25B3%25D0%25BE%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B8%25D0%25BA">convex</a></strong> polygon contains all the edges of the polygon. </li><li>  To bypass a <strong>nonconvex</strong> polygon, the shortest path contains all edges of the <strong><a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D1%258B%25D0%25BF%25D1%2583%25D0%25BA%25D0%25BB%25D0%25B0%25D1%258F_%25D0%25BE%25D0%25B1%25D0%25BE%25D0%25BB%25D0%25BE%25D1%2587%25D0%25BA%25D0%25B0">convex hull of the</a></strong> polygon. </li><li>  A point that is exactly on the edge of a polygon touches this polygon. </li></ul><br>  Understanding the definitions of "convexity", "nonconvexity" and "convex hull" is not very important for understanding this article, but these definitions are enough to create an optimal trajectory planner.  Let's make the following assumptions: <br><br><ul><li>  Our agent is a two-dimensional <strong>point of</strong> infinitely small size. </li><li>  All the obstacles of the world can be reduced to closed <strong>polygons</strong> . </li><li>  Our agent can move in any direction in a straight line. </li></ul><br>  Then we can find the optimal plan for the agent to achieve the goal by creating what is called the world <strong><a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D1%2580%25D0%25B0%25D1%2584_%25D0%25B2%25D0%25B8%25D0%25B4%25D0%25B8%25D0%25BC%25D0%25BE%25D1%2581%25D1%2582%25D0%25B8">visibility graph</a></strong> .  In addition to geometry, we also need to know a little about the graphs.  Graph theory is not the topic of this article, but in essence graphs are simply groups of abstract objects (called <strong>nodes</strong> ) connected to other nodes by abstract objects called <strong>edges</strong> .  We can use the power of graphs to describe the world in which the agent lives.  We can say that a node is any place where an agent can be, without touching anything.  An edge is a path between nodes, along which an agent can move. <br><br>  Taking this into account, we can define the visibility graph scheduler as follows: <br><br> <code><strong>: VISIBILITY GRAPH PLANNER</strong></code> <br> <br><ul><li> <code>     G.</code> </li> <li> <code>     G.</code> </li> <li> <code>     G.</code> </li> <li> <code>       .</code> </li> <li> <code>      G     .</code> </li> <li> <code>   V :</code> <br> <ul><li> <code>  V    .           ,         G.</code> </li> <li> <code>            V.        ,       G.</code> </li> <li> <code>    (,    A*)   ,        .</code> </li> </ul></li></ul><br>  The visibility graph is as follows: (dashed lines) <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/324/e97/21c/324e9721c2d867548dc1dd9ee6280b44.png"></div><br>  And the final path looks like this: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c6d/73c/1e6/c6d73c1e68a6412664483cbc91764396.png"></div><br>  Because of the assumptions that an agent is an infinitely small point that can move along straight lines from any one location to any other, we have a trajectory that passes smoothly through corners, faces, and free space, which minimizes the distance goals <br><br>  But what if our agent is not a point?  Notice how the orange path leads the agent between the trapezoid and the rectangle.  Obviously, the agent will not be able to squeeze through this space, so we need to solve this problem in some other way. <br><br>  One solution is to assume that the agent is not a point, but a disk.  In this case, we can simply <strong>inflate</strong> all obstacles to the agent‚Äôs radius, and then plan as if the agent is a point in this new bloated world. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/73a/4c0/c60/73a4c0c60bb07315a9a9ba68f755663b.png"></div><br>  In this case, the agent will choose the path to the left and not to the right of the rectangle, because he simply does not fit in the space between the trapezoid and the rectangle.  This inflating operation is in fact incredibly important.  In essence, we <em>changed the</em> world so that our assumption that the agent is a point remains true. <br><br>  This operation is called the calculation of the <strong><a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25BD%25D1%2584%25D0%25B8%25D0%25B3%25D1%2583%25D1%2580%25D0%25B0%25D1%2586%25D0%25B8%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D1%2581%25D1%2582%25D0%25B2%25D0%25BE">configuration space of the</a></strong> world.  Configuration space (or C-Space) is a coordinate system in which the configuration of our agent is represented by one point.  An obstacle in the workspace is transformed into an obstacle in the configuration space by placing the agent in the conditioned configuration and checking agent collisions.  If in this configuration the agent touches an obstacle in the workspace, then it becomes an obstacle in the configuration space.  If we have a non-circular agent, then we use the so-called <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2583%25D0%25BC%25D0%25BC%25D0%25B0_%25D0%259C%25D0%25B8%25D0%25BD%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B3%25D0%25BE">sum</a> for inflating obstacles. <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2583%25D0%25BC%25D0%25BC%25D0%25B0_%25D0%259C%25D0%25B8%25D0%25BD%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B3%25D0%25BE"><br></a>  <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2583%25D0%25BC%25D0%25BC%25D0%25B0_%25D0%259C%25D0%25B8%25D0%25BD%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B3%25D0%25BE">Minkowski</a> . <br><br>  In the case of two-dimensional space, this may seem boring, but this is exactly what we are doing to ‚Äúinflate‚Äù the obstacles.  The new ‚Äúinflated‚Äù space is actually a configuration space.  In more multidimensional spaces, things get more complicated! <br><br>  The visibility graph scheduler is a great thing.  It is both <strong>optimal</strong> and <strong>complete</strong> , besides, it does not rely on any <strong>heuristics</strong> .  Another great advantage of the visibility graph scheduler is its moderate <strong>multi-query</strong> capability.  The multi-query scheduler can <em>reuse</em> old computations when working with new goals.  In the case of a visibility graph, if the location of the target or agent changes, it is enough for us to just rebuild the edges of the graph from the agent and from the target.  These benefits make this scheduler extremely attractive to game programmers. <br><br>  In fact, in many modern games, visibility graphs are used for planning.  A popular variation of the visibility graph principle is the <strong>Nav (igation) Mesh</strong> .  In Nav Mesh, visibility graphs are sometimes used as a basis (along with other heuristics for the distance to enemies, objects, etc.).  Nav Mesh can be changed by designers or programmers.  Each Nav Mesh is stored as a file and is used for each individual level. <br><br>  Here is a screenshot of the Nav Mesh used in the <a href="https://ru.wikipedia.org/wiki/Overlord_(2007)">Overlord</a> video game: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8c2/aed/892/8c2aed892c36e695363c7e6fe1929f86.png"></div><br>  Despite all its advantages, the methods of visibility graphs have significant drawbacks.  For example, calculating the visibility graph can be quite a costly operation.  With the increase in the number of obstacles, the size of the visibility graph increases significantly.  The cost of calculating the visibility graph increases as a square of the number of vertices.  In addition, when changing any obstacles, in order to maintain optimality, it is likely that a full recalculation of the visibility graph will be required. <br><br>  Game programmers invented all sorts of tricks to speed up the creation of graphs using heuristics for selecting nodes to which you want to try to join through the edges.  Also, game designers can give hints to the visibility graph algorithm so that it determines which nodes to connect in the first place.  All these tricks lead to the fact that the graph of visibility ceases to be optimal and sometimes requires the monotonous work of programmers. <br><br>  However, the most serious problem of visibility graphs (in my opinion) is that they do not generalize well.  They solve one problem (planning on a 2D-plane with polygon obstacles), and solve it incredibly well.  But what if we're not on a two-dimensional plane?  What if our agent cannot be represented as a circle?  What if we do not know what the obstacles will be, or they cannot be represented as polygons?  Then we cannot, without tricks, use visibility graphs to solve our problem. <br><br>  Fortunately, there are other methods that are closer to the ‚Äústarted and forgotten‚Äù principle, which solve some of these problems. <br><br><h1>  Lattice search: A * and its variations </h1><br>  Graphs of visibility work because they use the optimizing qualities of searching in abstract graphs, as well as the fundamental rules of <a href="https://ru.wikipedia.org/wiki/%25D0%2595%25D0%25B2%25D0%25BA%25D0%25BB%25D0%25B8%25D0%25B4%25D0%25BE%25D0%25B2%25D0%25B0_%25D0%25B3%25D0%25B5%25D0%25BE%25D0%25BC%25D0%25B5%25D1%2582%25D1%2580%25D0%25B8%25D1%258F">Euclidean geometry</a> .  Euclidean geometry gives us a ‚Äúfundamentally correct‚Äù search graph.  And the abstract search itself is engaged in optimization. <br><br>  But what if we completely abandon Euclidean geometry and simply solve the entire problem by searching through abstract graphs?  In this way, we can eliminate the middleman in the face of geometry and solve many different types of problems. <br><br>  The problem is that we can use a variety of different approaches to transfer our task to the search area by graphs.  What will be the nodes?  What exactly is considered ribs?  What does connecting one node with another mean?  How we answer these questions largely determines the performance of our algorithm. <br><br>  Even if the graph search algorithm gives us the ‚Äúoptimal‚Äù answer, it is ‚Äúoptimal‚Äù in terms of only its own internal structure.  This does not mean that the ‚Äúoptimal‚Äù according to the graph search algorithm the answer is the answer we need. <br><br>  Given this, let's define the graph in the most common way: as a <strong>lattice</strong> .  Here's how it works: <br><br> <code><strong>: DISCRETIZE SPACE</strong></code> <br> <br><ul><li> <code>,         .</code> </li> <li> <code>   ,       .</code> </li> <li> <code> ,        ,   <strong></strong> .</code> </li> <li> <code>,  ,      ,   <strong></strong> .</code> </li> <li> <code>     .</code> </li> <li> <code>         .</code> </li> </ul><br>  ‚ÄúContiguous‚Äù is another aspect that needs to be attentive.  Most often, it is defined as " <em>any cell that has at least one common angle with the current cell</em> " (this is called "Euclidean adjacency") or as " <em>any cell that has at least one common edge with the current cell</em> " (this is called "Manhattan adjacency" ).  The choice of the definition of adjacency greatly depends on the answer returned by the graph search algorithm. <br><br>  Here is what the sampling stage will look like in our case study: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/096/afc/ae0/096afcae0ebc5f89a837a4a95993fcd8.png"></div><br>  If we search for this column according to the Euclidean adjacency metric, we get something like this: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/61a/b00/bec/61ab00bec2dfe9c15e50a7f68018a5e5.png"></div><br>  There are many other graph search algorithms that can be used to solve the grid search problem, but the most popular is <strong><a href="https://ru.wikipedia.org/wiki/A*">A *</a></strong> .  <b>A *</b> is related <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC_%25D0%2594%25D0%25B5%25D0%25B9%25D0%25BA%25D1%2581%25D1%2582%25D1%2580%25D1%258B">to Dijkstra‚Äôs algorithm</a> , which performs a search on nodes using heuristics, starting with the starting node.  A * is well researched in many other articles and tutorials, so I will not explain it here. <br><br>  A * and other grid graph search methods are one of the most common scheduling algorithms in games, and a discretized grid is one of the most popular ways to structure A *.  For many games, this search method is ideal, because many games still use tiles or voxels to represent the world. <br><br>  The search methods for graphs on a discrete lattice (including A *) are <strong>optimal</strong> according to their internal structure.  They are also <strong>resolution-complete</strong> .  This is a weaker form of completeness, which states that when the fineness of the lattice tends to infinity (that is, when the cells tend to an infinitely small size), the algorithm solves more and more problems to be solved. <br><br>  In our particular example, the grid search method is <strong>single-request</strong> , and not multi- <strong>request</strong> , because the search by column usually cannot reuse old information when generalizing to the new configurations of the goal and the beginning.  However, the sampling stage, of course, can be reused. <br><br>  Another key advantage (in my opinion, mainly) of graph-based methods is that they are completely abstract.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This means that additional costs (such as ensuring security, smoothness, proximity of necessary objects, etc.) can be automatically taken into account and automated. In addition, to solve completely different problems, you can use the same abstract code. In the </font></font><a href="http://www.dwarfcorp.com/site"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DwarfCorp</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> game </font><a href="http://www.dwarfcorp.com/site"><font style="vertical-align: inherit;">,</font></a><font style="vertical-align: inherit;"> we use one A * scheduler for both motion planning and </font></font><strong><a href="https://ru.wikipedia.org/wiki/STRIPS"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">symbolic action planning.</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (used to represent actions that agents can perform as an abstract graph).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">However, a grid search has at least one serious drawback: it is incredibly demanding of memory. If each node is built in a naive way from the beginning, then with an increase in the size of the world, your memory will end very quickly. Most of the problem lies in the fact that the grate must keep large volumes of empty space. To minimize this problem, there are optimization techniques, but in fundamental terms, as the size of the world increases and the number of measurements of the task increases, the memory size in the grid increases monstrously. Therefore, this method is not applicable to many more complex tasks.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another serious disadvantage of the method is that the search in the columns by itself can take quite a long time. </font><font style="vertical-align: inherit;">If there are several thousand agents moving in the world at the same time or a multitude of obstacles changing their position, then a search in a grid may be inapplicable. </font><font style="vertical-align: inherit;">In our game DwarfCorp, several streams are devoted to planning. </font><font style="vertical-align: inherit;">It eats away a bunch of CPU time. </font><font style="vertical-align: inherit;">In your case, this can also be!</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Management Policies: Potential Functions and Flow Fields </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another way to solve the task of planning a movement is to stop thinking about it in the categories of planning trajectories and begin to perceive it in categories </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">by management policy</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Remember, we said that the beetle algorithm can be perceived as both a trajectory planner </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and a</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> control policy? In that paragraph, we defined a policy as a set of rules that takes a configuration and returns an action (or ‚Äúcontrol input‚Äù). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The beetle's algorithm can be perceived as a simple control policy, which simply tells the agent to move towards the target until he stumbles upon an obstacle, and then bypass the obstacle in a clockwise direction. The agent can literally follow these rules, moving along its path to the goal.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The key advantages of management policies are that they generally do not rely on an agent who has something more than </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">local</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> knowledge of the world and that they are incredibly fast in calculations. Thousands (or millions) of agents can easily follow the same management policy.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Can we think of any management policies that work better than the beetle's algorithm? </font><font style="vertical-align: inherit;">It is worth considering one of them, a very useful " </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">potential field policy</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ". </font><font style="vertical-align: inherit;">It simulates an agent in the form of a charged particle, attracted to the target and repelled by obstacles:</font></font><br><br> <code><strong>: POTENTIAL FIELD POLICY</strong></code> <br> <br><ul><li> <code>   a  b</code> </li> <li> <code>             g.</code> </li> <li> <code>           o.</code> </li> <li> <code>   o       r.</code> </li> <li> <code>     u = a * g^ + B * r^,  v^    v.</code> </li> <li> <code>     .</code> </li> </ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Understanding this policy requires some knowledge of </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25B0%25D0%25BB%25D0%25B3%25D0%25B5%25D0%25B1%25D1%2580%25D0%25B0"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">linear algebra</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . In essence, the control input is a weighted sum of two members: a member of </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">attraction</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and a member of </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">repulsion</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . The choice of weights in each member significantly affects the final trajectory of the agent.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e32/f62/ff3/e32f62ff37abb711cd6ae39449d98fd3.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">With the help of a potential field policy, agents can be made to move in an incredibly realistic and smooth manner. You can also easily add additional conditions (proximity to the desired object or the distance to the enemy). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the policy of a potential field is extremely quickly calculated in parallel computing, this method can very effectively control thousands and thousands of agents. Sometimes this control policy is calculated in advance and stored in the grid for each level, after which it can be changed by the designer in the way he needs (then it is usually called </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the flow field</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In some games (especially strategic ones) this method is used with great efficiency. Here is an example of flow fields used in a strategy game.</font></font><a href="https://ru.wikipedia.org/wiki/Supreme_Commander_2"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Supreme Commander 2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , so that units naturally avoid each other, keeping the build:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/282/aa6/d90/282aa6d900543545dcbe98f910aab5c0.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Of course, the functions of the flow fields and the potential fields have serious drawbacks. First, they are by no means </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optimal</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Agents will be distributed by the flow field regardless of how long it takes to get to the goal. Secondly (and, in my opinion, this is the most important), they are by no means </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">complete</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . What if the control input is reset before the agent reaches the target? In this case, we will say that the agent has reached a " </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">local minimum</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ". You may think that such cases are quite rare, but in fact they are quite easy to construct. Simply place a large U-shaped obstacle in front of the agent.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finally, flow fields and other control policies are very difficult to configure. </font><font style="vertical-align: inherit;">How do we choose the weight of each member? </font><font style="vertical-align: inherit;">In the end, they require manual tuning to get good results. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Typically, designers have to manually adjust the flow fields to avoid local minima. </font><font style="vertical-align: inherit;">Such problems limit the possible utility in the general case of flow fields. </font><font style="vertical-align: inherit;">However, in many cases they are helpful.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Configuration Space and Curse of Dimension </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So, we discussed the three most popular motion-planning algorithms in video games: gratings, visibility graphs, and flow fields. These algorithms are extremely useful, simple to implement, and have been well studied. They work ideally in the case of two-dimensional problems with circular agents moving in all directions of the plane. Fortunately, almost all tasks in video games are related to this case, and the rest can be imitated with cunning tricks and designer hard work. It is not surprising that they are so actively used in the gaming industry. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And what did the movement planning researchers have been doing for the last few decades? </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Everyone else</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. What if your agent is not a circle? What if he is not on a plane? What if he can move in any direction? What if goals or obstacles are constantly changing? Answering these questions is not easy. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's start with a very simple case, which seems to be quite simple to solve with the help of the methods we have already described, but which is actually impossible to solve with these methods without fundamentally changing them. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What if the agent is not a circle but a rectangle? What if an </font><font style="vertical-align: inherit;">agent's </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">turn is</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> important </font><font style="vertical-align: inherit;">? Here is what the picture I am describing looks like:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9e4/905/7dc/9e49057dcc66b2543dcfa3e70cb920d6.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the case shown above, the agent (red) looks like a shopping cart, which can move in any direction. We want to move the agent so that it is exactly on top of the target and turned in the right direction. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here we can presumably use the beetle's algorithm, but we will need to carefully handle the turns of the agent so that it does not encounter obstacles. We will quickly become entangled in the chaos of rules that are not quite as elegant as for the case of a round agent. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And what if you try to use the graph of visibility? To do this, the agent must be a point. Remember how we did the trick and inflated the objects for the round agent? Perhaps in this case it will be possible to do something similar. But how much do we need to inflate objects?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A simple solution would be to choose the ‚Äúworst case scenario‚Äù and calculate the planning with this calculation. </font><font style="vertical-align: inherit;">In this case, we simply take the agent, determine the circle that describes it, and accept the agent as an equal circle of this size. </font><font style="vertical-align: inherit;">Then we inflate the obstacles to the desired size.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/200/4be/446/2004be446e40013f4a2d3515107f125e.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It will work, but we will have to sacrifice fullness. </font><font style="vertical-align: inherit;">There will be many tasks that we can not solve. </font><font style="vertical-align: inherit;">Take, for example, such a task, in which a long and thin agent must, in order to achieve a goal, sneak through a ‚Äúkeyhole‚Äù:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5bf/c67/21a/5bfc6721a740e89e8c11c6fb6797007b.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this scenario, the agent can reach the target, penetrate the well, rotate 90 degrees, then reach the next well, rotate 90 degrees and exit. With a conservative approximation of the agent through the circle that describes this problem it will be impossible to solve. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The problem is that we have not correctly taken into account the configuration space of the agent. Up to this point, we have been discussing only 2D planning in the environment of 2D obstacles. In such cases, the configuration space is well transformed from two-dimensional obstacles to another two-dimensional plane and we observe the effect of ‚Äúinflating‚Äù obstacles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But in fact, the following happens here: we added another dimension to our planning task. The agent has not only a position in x and y, but also a rotation. Our task is actually a three-dimensional planning task. Now the transformations between working and configuration spaces are becoming much more complex. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You can take it as follows: Imagine that the agent performed a certain turn (which we denote theta). Now we move the agent to each point of the workspace with a given rotation, and if the agent touches an obstacle, then we consider this point to be a collision in the configuration space. Such operations for polygon obstacles can also be implemented using </font></font><a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2583%25D0%25BC%25D0%25BC%25D0%25B0_%25D0%259C%25D0%25B8%25D0%25BD%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B3%25D0%25BE"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minkowski sums</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e46/1b6/e5a/e461b6e5ae3f7b6ba1db2c5cfdfdae08.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the diagram above, we have one agent passing through an obstacle. </font><font style="vertical-align: inherit;">Red contours of the agent show configurations that are in collision, and green contours show configurations without collisions. </font><font style="vertical-align: inherit;">This naturally leads to another ‚Äúswelling‚Äù of obstacles. </font><font style="vertical-align: inherit;">If we execute it for all possible positions (x, y) of the agent, then we will create a two-dimensional cut of the configuration space. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now we will simply increase the amount of the aunt and repeat the operation, receiving another two-dimensional slice.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b6f/1d5/bbc/b6f1d5bbcb0749e12127bffc10782892.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Now we can put the cuts one on another, aligning their x and y coordinates, as if folded sheets of graph paper: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5e9/574/572/5e957457298cb6bfb54c7945bf809976.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If we cut the aunt infinitely thin, as a result we get the three-dimensional configuration space of the agent. This is a continuous cube, and theta is turned around from bottom to top. Obstacles turn into strange cylindrical shapes. The agent and his goals become just points in this new strange space.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ca0/9a2/546/ca09a254678402a77a8c565b5dd4b312.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It is quite difficult to put in my head, but in a sense, this approach is beautiful and elegant. If we can imagine obstacles in two dimensions, where each dimension is simply the position of the agent in x and y coordinates, then we can also represent obstacles in three dimensions, where the third dimension is the rotation of the agent. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What if we wanted to add another degree of freedom to the agent? Suppose we would like to increase or decrease its length? Or would he have arms and legs that also need to be considered? In such cases, we do the same thing - just add dimensions to the configuration space. At this stage, it becomes completely impossible to visualize, and in order to understand them, you have to use such concepts as ‚Äúhyperplane‚Äù, ‚Äúdiversity with constraints‚Äù and ‚Äúhyperpersons‚Äù.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0f0/e0e/8ee/0f0e0e8eef1b8fe63b2851f3d69ce37b.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An example of a four-dimensional planning problem. </font><font style="vertical-align: inherit;">The agent consists of two segments with the axis connecting them. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now that our agent is just a point in 3D space, we can use ordinary algorithms to find the solution to any motion planning problem. </font><font style="vertical-align: inherit;">If we wanted, we could create a grid of voxels in the new 3D space and use A *. </font><font style="vertical-align: inherit;">If they thought, they could also find a representation of the configuration space in the form of a polygonal mesh, and then use the visibility graph in 3D. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Similarly, for other dimensions, we can do the following:</font></font><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Calculate the agent and obstacle configuration space. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Run A * or Nav Mesh in this space. </font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Unfortunately, these operations have two huge problems: </font></font><br><br><ol><li>  N-    <strong>NP-</strong> . </li><li>    N-    <strong>NP-</strong> . </li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The technical term from computer science " </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NP-complex</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " means that the task as it increases becomes exponentially more difficult, carrying with it many other theoretical difficulties. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In practice, this means that if we start adding measurements to planning tasks, we will very soon exhaust the computational power or memory, or both. This problem is known as the </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">curse of dimension</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . In three dimensions, we can do with A *, but as soon as we get to 4, 5 or 6 dimensions, A * quickly becomes useless (despite recent </font></font><a href="http://www.cs.cmu.edu/~maxim/files/tutorials/robschooltutorial_oct10.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">research by Maxim Likhachev</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which ensured his fairly good performance). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The simplest example of a six-dimensional scheduling problem is called "</font></font><a href="http://mathworld.wolfram.com/PianoMoversProblem.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the task of moving the piano</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ". Its wording: how to move a solid object (say, a piano) from point A to point B in 3D-space, if it can be moved and rotated in any direction?</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/59f/09d/a03/59f09da0331fbf15b21c6c7185ca2274.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An example of the task of moving the piano from the </font></font><a href="http://ompl.kavrakilab.org/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OMPL.</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Surprisingly, despite its simplicity, this task has remained unsolved for decades. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For this reason, the games basically adhere to simple two-dimensional tasks and imitate everything else (even when having a solution to something like the task of moving the piano seems like a fundamental part of the AI ‚Äã‚Äãof a three-dimensional game). </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unresolved Tasks</font></font></strong> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the 70s and 80s, motion planning studies focused on fast ways to calculate configuration space and good compression heuristics for reducing the dimension of some planning tasks. </font><font style="vertical-align: inherit;">Unfortunately, these studies did not lead to the creation of simple common solutions to problems in a large number of dimensions. </font><font style="vertical-align: inherit;">The situation did not change until the 90s and the beginning of zero years, when robotics researchers did not begin to move the progress of solving common multidimensional problems. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Today, planning in multidimensional spaces is much better studied. </font><font style="vertical-align: inherit;">All this happened thanks to two major discoveries: </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">randomized planners</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fast optimizers of trajectories</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">I will talk about them in the following sections.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The difference between finding a way and planning a move </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I noticed that after the publication of the draft of this article, some readers were confused by my terminology. </font><font style="vertical-align: inherit;">In the game development literature, the action of moving from point A to point B is usually called " </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">finding the path</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ", and I called it " </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">motion planning</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ." </font><font style="vertical-align: inherit;">In essence, motion planning is a generalization of a path search with a looser definition of a ‚Äúpoint‚Äù and a ‚Äúpath‚Äù that takes into account spaces of higher dimension (for example, turns and hinges). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Traffic planning can be perceived as a search for a path in the agent's configuration space.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Randomized Planning: Probabilistic Road Maps, PRM </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One of the first common solutions to multidimensional planning problems is called a </font></font><a href="http://en.wikipedia.org/wiki/Probabilistic_roadmap"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">probabilistic roadmap</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . It borrows the ideas of the Navigation Mesh and the visibility graph, adding another component: randomness. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To begin, I will present introductory information. We already know that the most difficult aspects of planning in multidimensional spaces consist in calculating the configuration space and further finding the optimal path through this space.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PRM solves both of these problems, completely rejecting the idea of ‚Äã‚Äãcomputing configuration space and forgetting about the principle of optimality. With this approach, a visibility graph in space is randomly created using distance heuristics, and then a solution is searched for in this visibility graph. You can also make the assumption that we can relatively inexpensively perform </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a collision check of</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> any agent configuration. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is how the entire algorithm looks like:</font></font><br><br> <code><strong>: PROBABALISTIC ROAD MAP (PRM)</strong></code> <br> <br><ul><li> <code>   G</code> </li> <li> <code>   G    .</code> </li> <li> <code> N :</code> <br> <ul><li> <code>  <strong>  </strong>      R.                     .</code> </li> <li> <code>       R,  .</code> </li> <li> <code>  ,  R   G.</code> </li> <li> <code>    G,     d  R.</code> </li> <li> <code>   N,   </code> <br> <ul><li> <code>       R  N</code> </li> <li> <code>    ,     G.</code> </li> <li> <code>    A*       .</code> </li> </ul><br></li></ul><br></li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/458/96e/c77/45896ec775976830902c92b40feae308.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In short, at each stage we create a random point and connect it with the neighbors in the graph based on what neighbors of the graph it ‚Äúsees‚Äù, that is, if we are sure that we can draw a straight line between any new node and neighbors in the graph . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We immediately see that this is very similar to the visibility graph algorithm, except that we never mention ‚Äúfor each obstacle‚Äù or ‚Äúfor each vertex‚Äù, because, of course, such calculations will be NP-complete. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instead, PRM considers only the structure of the random graph created by it and collisions between neighboring nodes. </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PRM Properties</font></font></strong> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We have already said that the algorithm is no longer optimal and is not complete. But what can we say about its performance? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PRM algorithm is so-called "</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">probabilistically complete</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ". This means that when the number of iterations N goes to infinity, the probability that PRM solves any solvable scheduling request is equal to one. This seems to be a very shaky definition (it is), but in practice PRM converges to the correct solution very quickly However, this means that the algorithm will have a random speed and may hang forever without finding a solution. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PRM also has interesting relationships with optimality. As PRM increases in size (and N grows to infinity), the number of possible paths increases. ad infinitum, and the optimal path through PRM becomes the truly optimal path through configuration space.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As you can imagine, because of its randomness, PRM can create very ugly, long and dangerous ways. </font><font style="vertical-align: inherit;">In this respect, PRM is by no means optimal. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Like Nav Mesh visibility graphs, in fundamental terms, PRM are multi-query schedulers. </font><font style="vertical-align: inherit;">They allow the agent to reuse a random graph efficiently for multiple scheduling requests. </font><font style="vertical-align: inherit;">Level designers can also ‚Äúbake‚Äù one PRM for each level.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Why an accident? </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The most important ‚Äútrick‚Äù of PRM (and other randomized algorithms) is that it presents the configuration space statistically and not explicitly. This allows us to sacrifice the optimality of the decision for the sake of speed, making ‚Äúgood enough‚Äù decisions where they exist. This is an incredibly powerful tool, because it allows the programmer to decide how much work the planner must do before returning the solution. This property is called the </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">real-time execution</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> algorithm property </font><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In essence, the complexity of the PRM grows with an increase in the number of samples and the distance parameter d, and not with an increase in the number of dimensions of the configuration space. Compare this with A * or visibility graphs, which spend exponentially more time as the dimension of the task increases.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This property allows PRM to quickly perform scheduling in </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hundreds of</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dimensions. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since the invention of PRM, many different variants of the algorithm have been proposed, increasing its efficiency, the quality of the laid path, and ease of use.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Randomized random study trees (Randomly Exploring Randomized Trees, RRT) </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sometimes PRM multi-request is not required. Quite often, it is preferable to just get from point A to point B, without knowing anything about previous scheduling requests. For example, if the environment between scheduling requests changes, it is often better to simply reschedule from scratch than to recreate stored information obtained from previous scheduling requests. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In such cases, we can change the idea of ‚Äã‚Äãcreating random graphs, given that we only want to plan the movement from point A to point B. Once. One of the ways to do this is to replace the graph with a tree. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A tree is simply a special type of graph in which nodes are ordered into ‚Äúparent‚Äù and ‚Äúchildren‚Äù so that each tree node has exactly one parent node and is from zero and more children.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let's see how our traffic planning can be represented as a tree. Imagine if the agent systematically explores configuration space. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If the agent is in some state, then there are several other states in which he can go from the current (or, in our case, an infinite number of states). From each of these states he can go to other states (but will not go back because he was already in the state from which he came).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If we store the states in which the agent was, as ‚Äúparent‚Äù nodes, and all the states to which the agent passes from them as ‚Äúchildren‚Äù, then we can form a tree-like structure growing from the current state of the agent to all places, in which the agent may potentially be located. Sooner or later, the agent tree will direct it to the goal state and we will have a solution. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This idea is very similar to the A * algorithm, which systematically expands states and adds them to a tree-like structure (from a technical point of view, to a directed acyclic graph). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So can we </font></font><strong><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">randomly grow a tree</font></font></em></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from the initial configuration of the agent to achieve the configuration of the goal?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This task is sought to solve two classes of algorithms. Both were invented in the late 90s and early zero. One of the approaches is ‚Äúnodocentric‚Äù - it selects a random node in the tree and grows in a random direction. This class of algorithms is called ‚ÄúEST‚Äù, that is, ‚ÄúExpansive Space Trees‚Äù (‚Äúexpandable spatial trees‚Äù). The second approach is ‚Äúsample-oriented‚Äù: it starts with a random sample of nodes in space, and then grows the closest node towards this random sample. Algorithms of this type are called " </font></font><a href="http://en.wikipedia.org/wiki/Rapidly_exploring_random_tree"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RRT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " ("Rapidly Exploring Randomized Trees", "randomized random study trees"). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In general, the RRT is much better than EST, but the explanation of the reasons for this are beyond the scope of this article. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is how the RRT works:</font></font><br><br> <code><strong>: RAPIDLY EXPLORING RANDOMIZED TREE (RRT)</strong></code> <br> <br><ul><li> <code>   T.</code> </li> <li> <code>  T   .</code> </li> <li> <code>  N ,     </code> <br> <ul><li> <code>      R.</code> </li> <li> <code>  T   R .   K.</code> </li> <li> <code>     K  R    ,     :</code> <br> <ul><li> <code>       .</code> </li> <li> <code>     T     .</code> </li> <li> <code>     d  K,      .</code> </li> </ul></li></ul></li><li> <code>        d    ,     .</code> </li> </ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/16b/547/8d4/16b5478d425906c486d29153e2055e73.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The pictures above show approximately one step of the algorithm in the middle of its execution. We take a random sample (orange, r), find the node closest to it (black, k), and then add one or more new nodes that take a ‚Äústep in the direction‚Äù of the random sample. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The tree will continue to grow so randomly until it reaches the goal. From time to time we will also perform random sampling to the target, in an eager manner trying to draw a straight line towards it. In practice, the probability of hitting a target in a sample will, at best, be in the range from 30% to 80%, depending on the clutter in the configuration space. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RRT is relatively simple. They can be implemented in just a few lines of code (assuming that we can easily find the closest node in the tree). </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RRT properties</font></font></strong> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You probably will not be surprised that the RRT algorithm is only </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">probabilistically complete</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . It is non-optimal (and in many cases excessively non-optimal).</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/755/525/050/755525050e02ceb57a04ea6d70428720.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robot manipulators are considered very multidimensional systems. In this case, we have two manipulators with seven hinges each, holding single-pliers. The system is 15-dimensional. Modern motion planning studies are studying similar multidimensional systems.</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Due to its simplicity, RRT also usually turns out to be extremely fast (at least for multidimensional systems). When using the fastest variations, RRT solutions for seven-dimensional or more multi-dimensional systems are found in milliseconds. When the number of measurements reaches tens, RRT usually surpasses all other planners in solving such problems. But it is worth considering that ‚Äúfast‚Äù in the community of researchers of multidimensional planning means a </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">second</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">or so to perform the entire pipeline of actions in seven dimensions, or up to a </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">minute</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> with twenty or more measurements. The reason for this is that the RRT paths are often too terrible to use directly, and must go through a long preprocessing stage. This can shock programmers using A *, which returns solutions to two-dimensional problems in milliseconds; but try performing A * for a seven-dimensional task - it will </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">never</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> return a solution </font><font style="vertical-align: inherit;">! </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RRT Variations</font></font></strong> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> After the invention of the RRT algorithm and the conquest of great success, many attempts were made to extend it to other areas or increase its performance. Here are some of the variations of RRT that you should know about: </font></font><br><br> <strong><a href="http://personalrobotics.ri.cmu.edu/courses/papers/Kuffner00-rrtconnect.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RRTConnect</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- grows two trees from the beginning and from the target, and tries to connect them with a straight line at random intervals. </font><font style="vertical-align: inherit;">As far as I know, this is the fastest scheduler for tasks with a high number of measurements. </font><font style="vertical-align: inherit;">Here is a beautiful illustration of the RRT connect I created (white - obstacles, blue - free space):</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a8e/e2f/b20/a8ee2fb20d61fa2dc2614cfe81602f24.png"></div><br> <strong><a href="http://sertac.scripts.mit.edu/web/wp-content/papercite-data/pdf/jeon.karaman.ea-cdc11.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RRT *</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - invented this decade. </font><font style="vertical-align: inherit;">Ensures optimality through rebalancing the tree. </font><font style="vertical-align: inherit;">Thousands of times slower than RRTConnect. </font></font><br><br> <strong><a href="http://homepages.laas.fr/jcortes/Papers/jaillet_aaaiWS08.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T-RRT</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - trying to create high-quality RRT-paths, exploring the gradient of the cost function. </font></font><br><br> <strong><a href="http://www.ri.cmu.edu/pub_files/2009/5/icra09.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Constrained RRT</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - allows you to perform planning with arbitrary restrictions (such as distance, cost, etc.). </font><font style="vertical-align: inherit;">Slower than RRT, but not by much. </font></font><br><br> <strong><a href="http://arxiv.org/pdf/1205.5088.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kinodynamic RRT</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- performs planning in the space of input control signals, and not in the configuration space. </font><font style="vertical-align: inherit;">Allows you to perform planning for cars, carts, ships and other agents who cannot arbitrarily change their turn. </font><font style="vertical-align: inherit;">Actively used in the DARPA Grand Challenge. </font><font style="vertical-align: inherit;">Much, much, much MUCHER slower than non-cynical dynamic planners. </font></font><br><br> <strong><a href="http://dora.cwru.edu/msb/pubs/iros04.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Discrete RRT</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is an implementation of RRT for grids. </font><font style="vertical-align: inherit;">In two-dimensional space, it is comparable in speed with A *, in 3D and in multidimensional systems, faster than it. </font></font><br><br> <strong><a href="http://lis.csail.mit.edu/pubs/barry-iser12.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DARRT</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - invented in 2012. </font><font style="vertical-align: inherit;">Implementing RRT for planning symbolic actions (previously considered to be the A * scope).</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Path cutting and optimization </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Since randomized planners do not guarantee optimality, the trajectories they create can be quite terrible. Therefore, instead of using them directly for agents, the random paths created by randomized planners are often passed on to complex optimization steps that increase their quality. Such optimization steps now take up most of the planning time for randomized planners. A seven-dimensional RRT may take a few milliseconds to return a possible path, but it may take up to five seconds to optimize the final path.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the general case, the trajectory optimizer is an algorithm that obtains the original trajectory and the cost function, modifying the original trajectory so that it has the lowest cost. For example, if the cost function we need is to minimize the length of the trajectory, then the optimizer for this function will take the original trajectory and change this trajectory so that it is shorter. This type of optimizer is called a </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trajectory shortcutter</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One of the most common and extremely simple path cutters (which can be called the ‚Äústochastic climb climber‚Äù, Stochastic Hill Climbing Shortcutter) works as follows:</font></font><br><br> <code><strong>: Stochastic Hill Climbing Shortcutter</strong></code> <br> <br><ul><li> <code>  N :</code> <ul> <li> <code>      T (  t1  t2)</code> </li> <li> <code>    t1  t2    ,  <strong></strong> .</code> </li> <li> <code>  ,   t1  t2  </code> <br> <ul><li> <code>      ,    T  t1  t2,    </code> </li> </ul><br></li></ul><br></li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4d5/de0/8b8/4d5de08b88feeb149304ea59101d2822.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This path cutter can be easily converted by replacing the concept of ‚Äúshort path‚Äù with any other cost function (for example, distance from obstacles, smoothness, safety, etc.). </font><font style="vertical-align: inherit;">Over time, the trajectory will fall into what is called the ‚Äúlocal minimum‚Äù of the cost function. </font><font style="vertical-align: inherit;">The length (or cost) of the trajectory will no longer decrease. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are more complex trajectory optimizers that work much faster than the climb I described. </font><font style="vertical-align: inherit;">Such optimizers often use the knowledge about the scope of the planning task to speed up the work.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Optimization of the trajectory when planning </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another way to solve multidimensional motion planning problems is to step back from the idea of ‚Äã‚Äã‚Äúfinding space‚Äù to find a path, and instead focus directly on optimizing the trajectories. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If it is true that we can optimize the trajectory so that it is shorter or meets some other criterion, is it possible to solve the entire problem using optimization directly? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are a large number of motion planners who use optimization to directly solve planning problems. Usually for this they represent the trajectory using a parametric model, and then intelligently change the parameters of the model until a local minimum is reached. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One of the ways to implement this process is called </font></font><strong><a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D1%2580%25D0%25B0%25D0%25B4%25D0%25B8%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D1%258B%25D0%25B9_%25D1%2581%25D0%25BF%25D1%2583%25D1%2581%25D0%25BA"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gradient descent.</font></font></a></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">If we have a certain cost function </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C (T)</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , where </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is the trajectory, then we can calculate the </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gradient D_C (T)</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which tells us how to change the given trajectory in such a way as to minimize costs. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In practice, this is a very difficult process. </font><font style="vertical-align: inherit;">You can imagine it like this:</font></font><br><br> <code><strong>: Gradient Descent Trajectory Optimizer</strong></code> <br> <br><ol><li> <code>     ,    .</code> </li> <li> <code>       .   T_0.</code> </li> <li> <code>  ,     ,  ,       .</code> </li> <li> <code>,   -    .  ,       ,    3.</code> </li> <li> <code>     4.</code> </li> <li> <code>,        .</code> </li> </ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Over time, the trajectory will gradually ‚Äúpush off‚Äù from obstacles, nevertheless remaining smooth. </font><font style="vertical-align: inherit;">In the general case, such a scheduler cannot be </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">complete</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> or </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optimal</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , because it uses the original straight line hypothesis as a strong heuristic. </font><font style="vertical-align: inherit;">However, it can be </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">locally</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> complete and </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">locally</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> optimal (and in practice it solves most problems).</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/12b/fb0/fb512bfb01d441015b7572870b192c5a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Note that in the image the gradients of the points are * negative * gradient of the cost function) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In practice, optimization of the trajectories as planning is a rather difficult and complicated topic that is difficult to judge in this article. What does trajectory gradient actually mean? What does perception of the trajectory as a rubber band mean? There are very difficult answers to these questions related to variation analysis. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We just need to know that the optimization of trajectories is a powerful alternative to randomized and search planners for multidimensional traffic planning. Their advantages are exceptional flexibility, theoretical guarantees of optimality, extremely high track quality and relative speed.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d8b/6b7/9e2/d8b6b79e2805ee59f3ef01e5d9c28820.png"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CHOMP, used by the robot for raising circles (Illustration from the work of </font></font><a href="http://www.ri.cmu.edu/pub_files/2011/5/icra2011_cam.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dragan et. Al</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In recent years, there have been many very fast trajectory optimizers that have become strong competitors of RRT and PRM in solving multidimensional problems. </font><font style="vertical-align: inherit;">One of them, </font></font><a href="http://www.ri.cmu.edu/pub_files/2009/5/icra09-chomp.pdf"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CHOMP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , uses a gradient descent and a smart view of obstacles using the distance field. </font><font style="vertical-align: inherit;">The other, </font></font><a href="http://www.ros.org/news/2013/04/new-package-trajopt-trajectory-optimization-software-for-motion-planning.html"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TrajOpt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , represents obstacles in the form of convex sets and uses techniques of sequential quadratic programming.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Important topics we didn't cover </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In addition to what I have said, there is still a whole world of theoretical movement planning. Briefly talk about what else is. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nonholonomic planning</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We considered only the case when an agent can move in any direction at any speed. But what if it is not? For example, a car cannot slide sideways, but must move forward and backward. Such cases are called ‚Äúnonholonomic‚Äù planning tasks. There are several solutions to this problem, but none of them is fast! It can take up to a </font></font><u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">minute</font></font></u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to calculate the average plan for a modern car scheduler </font><font style="vertical-align: inherit;">. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Restricted Planning</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nonholonomic planning refers to another set of tasks called ‚Äúplanning tasks with constraints‚Äù. In addition to restrictions in movement, there may also be restrictions on the physical configuration of the agent, the maximum force applied by the agent to the movement, or areas in which the agent is limited to objects other than obstacles. In generalized constrained planning there are also many solutions, but </font><font style="vertical-align: inherit;">only some of them are </font></font><u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fast</font></font></u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Time planning</font></font></strong> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We can add another dimension to our plans, so that agents can, for example, track a moving target or avoid moving obstacles. When properly implemented, such techniques can produce surprising results. However, this problem remains intractable, because the agent often cannot predict the future. </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hybrid planning</font></font></strong> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> What if our agent‚Äôs plan cannot be represented by a single path? What if the agent should interact along the way with other objects (and not just avoid them)? These types of tasks are usually referred to as ‚Äúhybrid planning‚Äù - usually there is some abstract aspect connected by a geometric aspect of the task. For these types of tasks there are also no clear, universally accepted decisions.</font></font><br><br><h1>  findings </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this article, we discussed some basic concepts of motion planning and presented several classes of algorithms that solve the problem of moving an agent from point A to point B, from the simplest to the extraordinarily complex. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modern progress in traffic planning studies has led to the fact that a wide range of previously unsolvable problems can now be solved on personal computers (and potentially in video game engines). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unfortunately, many of these algorithms are still too slow to be applied in real time, especially for cars, ships and other vehicles that cannot move in all directions. All this requires further research. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I hope the article did not seem too complicated to you and you found something useful for yourself in it!</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Here is a summary table of all the algorithms discussed in the article (it is necessary to take into account that only non-dynamical planning is taken into account here): </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/de1/b67/6e7/de1b676e721835245d826400dfdf3755.png"></div></div><p>Source: <a href="https://habr.com/ru/post/349044/">https://habr.com/ru/post/349044/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../349034/index.html">Debug Embox on STM32</a></li>
<li><a href="../349036/index.html">Atlassian User Group Moscow visiting Raiffeisenbank</a></li>
<li><a href="../349038/index.html">Another article about quaternions and Euler angles</a></li>
<li><a href="../349040/index.html">How to become a web developer and not go crazy</a></li>
<li><a href="../349042/index.html">Video from UralJS # 6 mitap - get rid of this, type the Redux application and write on React without brakes</a></li>
<li><a href="../349046/index.html">Analysis of the regulation of cryptocurrency in world markets in early 2018</a></li>
<li><a href="../349048/index.html">Autoencoder in the tasks of political event clustering</a></li>
<li><a href="../349050/index.html">Go 1.10 Release Party @ Badoo February 24</a></li>
<li><a href="../349054/index.html">LL (*) parser using Rust macro</a></li>
<li><a href="../349056/index.html">Open lesson "UML Diagrams"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>