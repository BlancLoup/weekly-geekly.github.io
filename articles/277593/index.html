<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>List of machine learning resources. Part 2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We continue ( 1 , 2 ) to consider the topic of machine learning. Your attention the second part (first here ) adapted selection of useful materials. 
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>List of machine learning resources. Part 2</h1><div class="post__text post__text-html js-mediator-article"> <a href="http://habrahabr.ru/company/spbifmo/blog/277593/"><img src="https://habrastorage.org/files/1f3/c4d/064/1f3c4d064e8c40eb846ffa291e1515b2.jpg" width="700"></a> <br><br>  <i>We continue ( <a href="https://habrahabr.ru/company/spbifmo/blog/271027/">1</a> , <a href="https://habrahabr.ru/company/spbifmo/blog/276479/">2</a> ) to consider the topic of machine learning.</i>  <i>Your attention the second part (first <a href="https://habrahabr.ru/company/spbifmo/blog/277511/">here</a> ) adapted selection of useful materials.</i> <a name="habracut"></a><br><br><blockquote>  miscellanea </blockquote><br><ul><li>  <b><a href="https://github.com/josephmisiti/awesome-machine-learning">The list:</a></b> excellent frameworks, libraries and machine learning applications; </li><li>  <b><a href="https://github.com/fasouto/awesome-dataviz">List:</a></b> excellent libraries and other resources for data visualization; </li><li>  <b><a href="https://github.com/okulbilisim/awesome-datascience">Awesome Data Science:</a></b> data science materials; </li><li>  <b><a href="http://datasciencemasters.org/">Data Science Masters:</a></b> educational materials and datalogy literature; </li><li>  <b><a href="http://stats.stackexchange.com/questions/tagged/machine-learning">Cross Validated:</a></b> Machine Learning FAQ; </li><li>  <b><a href="https://github.com/prakhar1989/awesome-courses">List:</a></b> university courses related to machine learning; </li><li>  <b><a href="https://www.quora.com/What-are-some-Machine-Learning-algorithms-that-you-should-always-have-a-strong-understanding-of-and-why">Quora:</a></b> machine learning algorithms that need to be understood; </li><li>  <b><a href="https://www.psych.umn.edu/faculty/waller/classes/FA2010/Readings/rodgers.pdf">Article: the</a></b> difference between linearly independent, orthogonal, and uncorrelated variables; </li><li>  <b><a href="https://en.wikipedia.org/wiki/List_of_machine_learning_concepts">References:</a></b> machine learning concepts and algorithms; </li><li>  <b><a href="http://www.slideshare.net/pierluca.lanzi/presentations">Presentations:</a></b> various topics; </li></ul><br><ul><li>  <b><a href="http://www.ai.mit.edu/courses/6.867-f04/lectures.html">Presentation:</a></b> MIT Machine Learning Lectures; </li><li>  <b><a href="http://www.dataschool.io/comparing-supervised-learning-algorithms/">Article:</a></b> comparison of learning algorithms with a teacher; </li><li>  <b><a href="http://www.dataschool.io/learning-data-science-fundamentals/">Article: The</a></b> Basics of Data Science; </li><li>  <b><a href="https://medium.com/%40nomadic_mind/new-to-machine-learning-avoid-these-three-mistakes-73258b3848a4">Article:</a></b> Three machine learning errors to be avoided; </li><li>  <b><a href="https://github.com/pedrosan/TheAnalyticsEdge">TheAnalyticsEdge:</a></b> lectures with examples; </li></ul><br><blockquote>  Interview </blockquote><br><ul><li>  <b><a href="https://www.quora.com/How-can-a-computer-science-graduate-student-prepare-himself-for-data-scientist-machine-learning-intern-interviews">Quora:</a></b> how to prepare a student for an interview for the position of data specialist; </li><li>  <b><a href="https://www.quora.com/How-do-I-learn-machine-learning-1/answer/Xavier-Amatriain">Quora:</a></b> where to start familiarity with machine learning; </li><li>  <b><a href="https://www.quora.com/topic/Data-Science-Interviews/faq">Quora:</a></b> Interview FAQ for a Data Specialist; </li><li>  <b><a href="https://www.quora.com/What-are-the-key-skills-of-a-data-scientist">Quora: the</a></b> most important skills for a data processing specialist; </li></ul><br><blockquote>  Artificial Intelligence </blockquote><br><ul><li>  <b><a href="https://github.com/owainlewis/awesome-artificial-intelligence">Repository:</a></b> list of resources on artificial intelligence; </li><li>  <b><a href="https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/info">edX:</a></b> an artificial intelligence course by Dan Klein and Peter Abbel; </li><li>  <b><a href="https://www.udacity.com/course/intro-to-artificial-intelligence--cs271">Udacity:</a></b> Peter Norvig and Sebastian Trun's course; </li><li>  <b><a href="http://www.ted.com/playlists/310/talks_on_artificial_intelligen">TED Talks:</a></b> artificial intelligence; </li></ul><br><blockquote>  Genetic algorithms </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Genetic_algorithm">Wiki:</a></b> genetic algorithms; </li><li>  <b><a href="http://outlace.com/Simple-Genetic-Algorithm-in-15-lines-of-Python/">Outlace: a</a></b> simple implementation of genetic algorithms in Python (Part 1); </li><li>  <b><a href="http://outlace.com/Simple-Genetic-Algorithm-Python-Addendum/">Outlace: a</a></b> simple implementation of genetic algorithms in Python (Part 2); </li><li>  <b><a href="http://www.ai-junkie.com/ga/intro/gat1.html">ai-junkie:</a></b> about genetic algorithms in simple language; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Genetic_programming">Wiki:</a></b> genetic programming; </li><li>  <b><a href="https://github.com/trevorstephens/gplearn">GitHub:</a></b> genetic programming in Python; </li><li>  <b><a href="https://www.quora.com/Whats-the-difference-between-Genetic-Algorithms-and-Genetic-Programming">Quora:</a></b> genetic algorithms and genetic programming; </li></ul><br><blockquote>  Statistics </blockquote><br><ul><li>  <b><a href="http://stattrek.com/">Stat Trek:</a></b> everything about statistics and probabilities; </li><li>  <b><a href="https://github.com/rouseguy/intro2stats">Intro2stats: learn</a></b> statistics with Python; </li><li>  <b><a href="https://speakerdeck.com/jakevdp/statistics-for-hackers">Statistics for Hackers:</a></b> Jake Vanderplas presentation; </li><li>  <b><a href="http://onlinestatbook.com/2/index.html">Online Statistics Book:</a></b> an online multimedia course on statistics; </li><li>  <b><a href="http://stattrek.com/sampling/sampling-distribution.aspx">Article:</a></b> What is a selective distribution; </li><li>  <b><a href="http://stattrek.com/tutorials/ap-statistics-tutorial.aspx">Training: a</a></b> program of advanced study of statistics; </li><li>  <b><a href="http://stattrek.com/tutorials/statistics-tutorial.aspx">Training:</a></b> statistics and probability; </li><li>  <b><a href="http://stattrek.com/tutorials/matrix-algebra-tutorial.aspx">Training:</a></b> matrix algebra; </li><li>  <b><a href="https://www.physicsforums.com/threads/what-is-an-unbiased-estimator.547728/">Forum:</a></b> what is unbiased rating; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Goodness_of_fit">Wiki:</a></b> acceptance criteria; </li><li>  <b><a href="http://onlinestatbook.com/2/advanced_graphs/q-q_plots.html">Article:</a></b> what is quantile-quantile graphics; </li></ul><br><blockquote>  Useful blogs </blockquote><br><ul><li>  <b><a href="http://blog.echen.me/">Edwin Chen's</a></b> blog <b><a href="http://blog.echen.me/">: a</a></b> blog about math, statistics, machine learning, and data science; </li><li>  <b><a href="http://www.dataschool.io/">Data School:</a></b> datalogy for beginners; </li><li>  <b><a href="http://mlwave.com/">ML Wave:</a></b> learning machine learning; </li><li>  <b><a href="http://karpathy.github.io/">Karpathy: a</a></b> blog about deep learning and data science; </li><li>  <b><a href="http://colah.github.io/">Colah: a</a></b> great blog about neural networks; </li><li>  <b><a href="http://alexminnaar.com/">Alex Minaar‚Äôs</a></b> blog <b><a href="http://alexminnaar.com/">:</a></b> machine learning and programming blog; </li><li>  <b><a href="http://andland.github.io/">Statistically Significant:</a></b> Andrew Landgraf's blog on data science; </li><li>  <b><a href="http://simplystatistics.org/">Simply Statistics: a</a></b> blog led by three professors of biostatistics; </li><li>  <b><a href="http://yanirseroussi.com/">Yanir Seroussi:</a></b> a data science blog and more; </li><li>  <b><a href="http://fastml.com/">fastML:</a></b> accessible language about machine learning; </li></ul><br><ul><li>  <b><a href="http://trevorstephens.com/">Trevor Stephens: Trevor Stephens</a></b> Personal Page; </li><li>  <b><a href="http://blog.kaggle.com/">Kaggle:</a></b> everything about data processing and analysis; </li><li>  <b><a href="http://outlace.com/">Outlace:</a></b> a student learning blog about machine learning; </li><li>  <b><a href="http://r4stats.com/">r4stats:</a></b> everything about data science and R; </li><li>  <b><a href="http://varianceexplained.org/">Variance Explained:</a></b> David Robinson blog; </li><li>  <b><a href="http://www.ai-junkie.com/">AI Junkie:</a></b> Artificial Intelligence Blog; </li></ul><br><blockquote>  Quora Resources </blockquote><br><ul><li>  <b><a href="https://www.quora.com/topic/Machine-Learning/writers">Quora: the</a></b> most popular authors who write about machine learning; </li><li>  <b><a href="https://www.quora.com/Data-Science">Data science:</a></b> thematic section; </li><li>  <b><a href="https://www.quora.com/William-Chen-6/answers">Replies from William Chen;</a></b> </li><li>  <b><a href="https://www.quora.com/Michael-Hochster/answers">Answers Michael Hotster;</a></b> </li><li>  <b><a href="https://www.quora.com/Ricardo-Vladimiro-1/answers">Answers Ricardo Vladimiro;</a></b> </li><li>  <b><a href="https://datastories.quora.com/">Blog:</a></b> useful materials and tips on statistics, not only; </li><li>  <b><a href="https://www.quora.com/topic/Data-Science/faq">FAQ:</a></b> on data science; </li><li>  <b><a href="https://www.quora.com/topic/Machine-Learning/faq">FAQ:</a></b> machine learning; </li></ul><br><blockquote>  Kaggle Competitions </blockquote><br><ul><li>  <b><a href="http://yanirseroussi.com/2014/08/24/how-to-almost-win-kaggle-competitions/">Article:</a></b> how to (almost) win the Kaggle Competitions; </li><li>  <b><a href="http://blog.kaggle.com/2015/10/05/grasp-and-lift-eeg-detection-winners-interview-3rd-place-team-hedj/">Article:</a></b> application of convolutional neural networks for decoding EEG signals; </li><li>  <b><a href="http://alexminnaar.com/tag/kaggle-competitions.html">Article:</a></b> Facebook Recruiting III Analysis; </li><li>  <b><a href="http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/">Article:</a></b> predicting the CTR using dynamic machine learning; </li></ul><br><blockquote>  Cribs </blockquote><br><ul><li>  <b><a href="http://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf">Probability;</a></b> </li><li>  <b><a href="https://github.com/soulmachine/machine-learning-cheat-sheet">Machine learning;</a></b> </li></ul><br><blockquote>  Classification </blockquote><br><ul><li>  <b><a href="http://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/">Article:</a></b> does class balancing help to improve the results of the classifier; </li><li>  <b><a href="https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms">Quora: the</a></b> advantages of various classification algorithms; </li><li>  <b><a href="https://ccrma.stanford.edu/workshops/mir2009/references/ROCintro.pdf">Article:</a></b> ROC analysis; </li><li>  <b><a href="http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/">Article:</a></b> Inaccuracy Matrix - Terminology; </li></ul><br><blockquote>  Linear regression </blockquote><br><ul><li>  <b><a href="http://pareonline.net/getvn.asp%3Fn%3D2%26v%3D8">Article:</a></b> conditions for applying linear regression; </li><li>  <b><a href="http://people.duke.edu/~rnau/regintro.htm">duke.edu:</a></b> all about linear regression; </li><li>  <b><a href="http://www.dataschool.io/applying-and-interpreting-linear-regression/">Data School:</a></b> applying and evaluating linear regression results; </li><li>  <b><a href="http://www.researchgate.net/post/Is_linear_regression_valid_when_the_outcome_dependant_variable_not_normally_distributed">ResearchGate:</a></b> what if the dependent variable does not have a normal distribution; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Multicollinearity">Wiki:</a></b> multicollinearity; </li><li>  <b><a href="http://jonlefcheck.net/2012/12/28/dealing-with-multicollinearity-using-variance-inflation-factors/">Article:</a></b> Multicollinearity and Variance Inflation Factor (VIF); </li><li>  <b><a href="https://web.stanford.edu/~hastie/Papers/elasticnet.pdf">Article:</a></b> regularization and selection of variables using the elastic neural network method; </li></ul><br><blockquote>  Logistic regression </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Logistic_regression">Wiki:</a></b> logistic regression; </li><li>  <b><a href="http://florianhartl.com/logistic-regression-geometric-intuition.html">Article:</a></b> geometric interpretation of logistic regression; </li><li>  <b><a href="http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm">FAQ:</a></b> what is a pseudo R-square; </li></ul><br><blockquote>  Model validation using resampling </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Resampling_%2528statistics%2529">Wiki:</a></b> resampling / resampling; </li><li>  <b><a href="http://www.chioka.in/tag/cross-validation/">Chioka:</a></b> good cross-checking materials; </li><li>  <b><a href="http://ai.stanford.edu/~ang/papers/cv-final.pdf">Andrew Eun:</a></b> preventing retraining during cross-checking; </li><li>  <b><a href="http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf">Gavin Cawley: the</a></b> impact of retraining and systematic selection errors on the assessment of model performance; </li><li>  <b><a href="http://www.autonlab.org/tutorials/overfit10.pdf">Andrew Moore:</a></b> cross-check to identify and prevent retraining; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Bootstrapping_%2528statistics%2529">Wiki:</a></b> statistical bootstrap; </li><li>  <b><a href="https://www.stat.auckland.ac.nz/~wild/BootAnim/">Bootstrap:</a></b> animations; </li><li>  <b><a href="http://statistics.about.com/od/Applications/a/Example-Of-Bootstrapping.htm">Example:</a></b> statistical bootstrap; </li></ul><br><blockquote>  Deep learning </blockquote><br><ul><li>  <b><a href="https://github.com/ChristosChristofidis/awesome-deep-learning">List:</a></b> guides, projects and deep learning communities; </li><li>  <b><a href="http://deeplearning4j.org/documentation.html">Deeplearning4j:</a></b> deep learning resources; </li><li>  <b><a href="http://cs224d.stanford.edu/reports.html">Stanford:</a></b> interesting projects on deep learning and processing of natural language; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/">Article:</a></b> key concepts of deep learning; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/">Article:</a></b> Natural Language Processing with Deep Nets on Torch; </li><li>  <b><a href="http://ufldl.stanford.edu/tutorial/">Stanford:</a></b> Deep Learning Guide; </li><li>  <b><a href="https://www.quora.com/topic/Deep-Learning/faq">Quora:</a></b> in-depth training FAQ; </li><li>  <b><a href="https://plus.google.com/communities/112866381580457264725">Google: a</a></b> page on deep learning; </li><li>  <b><a href="http://deeplearning.net/2014/11/22/recent-reddit-amas-about-deep-learning/">Reddit:</a></b> subreddit for deep learning; </li><li>  <b><a href="https://www.reddit.com/r/IAmA/comments/3mdk9v/we_are_google_researchers_working_on_deep/">Reddit:</a></b> another subreddit; </li></ul><br><ul><li>  <b><a href="http://www.kdnuggets.com/2014/05/learn-deep-learning-courses-tutorials-overviews.html">Article:</a></b> where to study deep learning; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/deep-learning-nutshell-core-concepts/">NVidia:</a></b> deep learning concepts; </li><li>  <b><a href="https://github.com/rouseguy/intro2deeplearning">Intro2deeplearning:</a></b> deep learning and Python; </li><li>  <b><a href="https://speakerdeck.com/bargava/introduction-to-deep-learning">Intro2deeplearning:</a></b> great presentation; </li><li>  <b><a href="https://www.youtube.com/playlist%3Flist%3DPLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu">Oxford:</a></b> video lectures 2015; </li><li>  <b><a href="http://videolectures.net/deeplearning2015_montreal/">Video:</a></b> Deep Learning Summer School 2015; </li><li>  <b><a href="http://deeplearning.net/software_links/">List:</a></b> software for deep learning; </li><li>  <b><a href="http://karpathy.github.io/neuralnets/">Article:</a></b> neural networks from the point of view of the programmer; </li><li>  <b><a href="http://www.kdnuggets.com/2015/10/top-arxiv-deep-learning-papers-explained.html">Kdnuggets:</a></b> top 5 works on deep learning; </li><li>  <b><a href="https://www.youtube.com/watch%3Fv%3DIcOMKXAw5VA">Video:</a></b> Jeffrey Hinton on deep learning; </li><li>  <b><a href="http://deeplearning.net/reading-list/">Deeplearning: the</a></b> best materials for deep learning; </li><li>  <b><a href="http://deeplearning.net/">Deeplearning:</a></b> all about machine learning; </li></ul><br><ul><li>  <b><a href="http://deeplearning.net/software_links/">Deeplearning:</a></b> machine learning software; </li><li>  <b><a href="http://deeplearning4j.org/">Deeplearning4j:</a></b> library guide; </li><li>  <b><a href="http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks">Article: a</a></b> striking guide to deep learning; </li><li>  <b><a href="http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html">Article: The</a></b> Basics of Deep Learning; </li><li>  <b><a href="http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/">Stanford:</a></b> an article on deep learning; </li><li>  <b><a href="http://deeplearning.net/tutorial/index.html">Deeplearning:</a></b> deep learning guides; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/">Article:</a></b> neural machine translation using GPU (Part 1); </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/">Article:</a></b> neural machine translation using GPU (Part 1); </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/">Article:</a></b> neural machine translation using GPU (Part 1); </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/deep-speech-accurate-speech-recognition-gpu-accelerated-deep-learning/">Deep Speech:</a></b> GPU speech recognition for deep neural network learning; </li></ul><br><blockquote>  Deep Learning Framework </blockquote><br><ul><li>  <b><a href="http://fastml.com/torch-vs-theano/">FastML:</a></b> Torch or Theano; </li><li>  <b><a href="http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html">Deeplearning4j:</a></b> Dl4j, Torch7 or Theano; </li><li>  <b><a href="http://www.teglor.com/b/deep-learning-libraries-language-cm569/">List:</a></b> libraries for deep learning; </li><li>  <b><a href="http://deeplearning.net/software/theano/">Theano:</a></b> Python library; </li><li>  <b><a href="http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/">Article:</a></b> Introduction to Theano; </li><li>  <b><a href="http://outlace.com/Beginner-Tutorial-Theano/">Theano: a</a></b> guide; </li><li>  <b><a href="http://deeplearning.net/software/theano/tutorial/">Theano:</a></b> another guide; </li><li>  <b><a href="http://deeplearning.net/tutorial/logreg.html">Theano:</a></b> apply logistic regression to classify numbers; </li><li>  <b><a href="http://deeplearning.net/tutorial/mlp.html">Theano:</a></b> multilayer perceptron; </li><li>  <b><a href="http://theano/">Theano:</a></b> convolutional neural networks; </li></ul><br><ul><li>  <b><a href="http://deeplearning.net/tutorial/rnnslu.html">Theano:</a></b> recurrent neural network; </li><li>  <b><a href="http://deeplearning.net/tutorial/lstm.html">Theano:</a></b> LSTM networks for analyzing emotional coloration of statements; </li><li>  <b><a href="http://deeplearning.net/tutorial/rbm.html">Theano:</a></b> Boltzmann limited machine; </li><li>  <b><a href="http://deeplearning.net/tutorial/DBN.html">Theano:</a></b> deep web of trust; </li><li>  <b><a href="https://github.com/lisa-lab/DeepLearningTutorials">Theano:</a></b> more guides; </li><li>  <b><a href="http://torch.ch/">Torch:</a></b> another library for machine learning; </li><li>  <b><a href="http://code.madbits.com/wiki/doku.php">Manual:</a></b> Torch machine learning; </li><li>  <b><a href="http://ml.informatik.uni-freiburg.de/_media/teaching/ws1415/presentation_dl_lect3.pdf">Article:</a></b> Meet Torch; </li><li>  <b><a href="https://github.com/chetannaik/learning_torch">Repository:</a></b> Torch tutorials; </li><li>  <b><a href="https://github.com/carpedm20/awesome-torch">Repository:</a></b> great stuff on Torch; </li></ul><br><ul><li>  <b><a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/">Oxford:</a></b> machine learning lectures using Torch; </li><li>  <b><a href="https://apaszke.github.io/torch-internals.html">Torch:</a></b> small review; </li><li>  <b><a href="https://github.com/torch/torch7/wiki/Cheatsheet">Torch:</a></b> tips and tricks; </li><li> <b><a href="http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/">Torch:</a></b> natural language processing using deep neural networks; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/">Caffe:</a></b> deep learning for solving computer vision problems with Caffe and cuDNN; </li><li>  <b><a href="http://tensorflow.org/">TensorFlow:</a></b> a machine learning library from Google; </li><li>  <b><a href="https://github.com/aymericdamien/TensorFlow-Examples">TensorFlow:</a></b> examples for beginners; </li><li>  <b><a href="https://github.com/chetannaik/learning_tensorflow">Repository:</a></b> TensorFlow study materials; </li><li>  <b><a href="https://github.com/soumith/convnet-benchmarks/issues/66">TensorFlow:</a></b> benchmarks; </li></ul><br><blockquote>  Direct propagation neural networks </blockquote><br><ul><li>  <b><a href="http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/">Lead:</a></b> implementation of the neural network; </li><li>  <b><a href="http://www.wildml.com/2015/09/speeding-up-your-neural-network-with-theano-and-the-gpu/">Article:</a></b> Accelerating a Neural Network with Theano and GPU; </li><li>  <b><a href="https://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/">Article:</a></b> basics of neural networks; </li><li>  <b><a href="http://home.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html">Article:</a></b> back propagation method; </li><li>  <b><a href="http://www.ai-junkie.com/ann/evolved/nnt6.html">AI Junkie:</a></b> neural network in C ++; </li><li>  <b><a href="http://www.codeproject.com/Articles/16419/AI-Neural-Network-for-beginners-Part-of">Code Project:</a></b> neural networks for beginners; </li><li>  <b><a href="http://www.autonlab.org/tutorials/neural13.pdf">Presentation:</a></b> regression and classification algorithms; </li><li>  <b><a href="http://www.doc.ic.ac.uk/~nd/surprise_96/journal/vol4/cs11/report.html">Article:</a></b> acquaintance with neural networks; </li></ul><br><blockquote>  Recurrent and LSTM networks </blockquote><br><ul><li>  <b><a href="https://github.com/kjw0612/awesome-rnn">Awesome-rnn:</a></b> list of resources; </li><li>  <b><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">Manual:</a></b> recurrent neural network (Part 1); </li><li>  <b><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/">Manual:</a></b> recurrent neural network (Part 2); </li><li>  <b><a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/">Manual:</a></b> recurrent neural network (Part 3); </li><li>  <b><a href="http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/">Article:</a></b> natural language processing, recurrent networks and representations; </li><li>  <b><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Article:</a></b> efficiency of recurrent neural networks; </li><li>  <b><a href="http://deeplearning4j.org/recurrentnetwork.html">Deeplearning4j:</a></b> introduction to recurrent neural networks; </li><li>  <b><a href="http://deeplearning4j.org/lstm.html">Deeplearning4j:</a></b> introduction to LSTM networks; </li><li>  <b><a href="http://hackaday.com/2015/10/15/73-computer-scientists-created-a-neural-net-and-you-wont-believe-what-happened-next/">Article:</a></b> application of recurrent neural networks; </li><li>  <b><a href="http://svail.github.io/">Articles:</a></b> optimization of performance of recurrent networks; </li></ul><br><ul><li>  <b><a href="http://outlace.com/Simple-Recurrent-Neural-Network/">Example:</a></b> simple recurrent neural network; </li><li>  <b><a href="http://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/">Article:</a></b> Clickbit header generation using recurrent neural networks; </li><li>  <b><a href="http://www.slideshare.net/indicods/general-sequence-learning-with-recurrent-neural-networks-for-next-ml">Presentation:</a></b> using recurrent networks for text analysis; </li><li>  <b><a href="http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf">Article:</a></b> using recurrent neural networks for machine translation; </li><li>  <b><a href="https://github.com/MattVitelli/GRUV">Keras:</a></b> creating music using recurrent neural networks; </li><li>  <b><a href="http://neuralniche.com/post/tutorial/">Keras:</a></b> using recurrent neural networks to generate dialogue; </li><li>  <b><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Article:</a></b> introduction to LSTM networks; </li><li>  <b><a href="https://apaszke.github.io/lstm-explained.html">Article:</a></b> LSTM networks; </li><li>  <b><a href="http://deeplearning4j.org/lstm.html">Deeplearning4j:</a></b> LSTM networks for beginners; </li><li>  <b><a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/">Article:</a></b> LSTM network implementation from scratch; </li></ul><br><ul><li>  <b><a href="https://github.com/karpathy/char-rnn">GitHub: a</a></b> character model of a language and its implementation of char-rnn in Torch; </li><li>  <b><a href="https://github.com/apaszke/kaggle-grasp-and-lift">GitHub:</a></b> using LSTM networks for decoding EEG signals; </li><li>  <b><a href="http://deeplearning.net/tutorial/lstm.html">Article: The</a></b> use of LSTM networks for analyzing texts on Theano; </li><li>  <b><a href="http://avisingh599.github.io/deeplearning/visual-qa/">Article:</a></b> applying deep learning for image analysis; </li><li>  <b><a href="http://googleresearch.blogspot.in/2015/11/computer-respond-to-this-email.html">Google:</a></b> computer responds to email using LSTM; </li><li>  <b><a href="http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html">Google:</a></b> LSTM networks significantly improve voice search performance; </li><li>  <b><a href="http://deeplearning.net/2015/09/30/long-short-term-memory-dramatically-improves-google-voice-etc-now-available-to-a-billion-users/">Deeplearning:</a></b> another article on the topic of voice search; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/">NVidia:</a></b> natural language processing with LSTM networks on Torch; </li><li>  <b><a href="https://github.com/abhshkdz/neural-vqa">Torch:</a></b> image analysis using convolutional and LSTM networks; </li><li>  <b><a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/">Comparison:</a></b> LSTM or Managed Recurrent Modules (GRU); </li><li>  <b><a href="https://en.wikipedia.org/wiki/Recursive_neural_network">Wiki:</a></b> recursive neural networks; </li><li>  <b><a href="http://deeplearning4j.org/recursiveneuraltensornetwork.html">Deeplearning4j:</a></b> recursive tensor neural network (RNTN); </li><li>  <b><a href="http://deeplearning4j.org/zh-sentiment_analysis_word2vec.html">Deeplearning4j:</a></b> using word2vec, deep trust networks and RNTN for text analysis; </li></ul><br><blockquote>  Limited Boltzmann machine </blockquote><br><ul><li>  <b><a href="http://deeplearning4j.org/restrictedboltzmannmachine.html">Deeplearning4j: a</a></b> guide for beginners on a limited Boltzmann machine; </li><li>  <b><a href="http://deeplearning.net/tutorial/rbm.html">Deep Learning:</a></b> another good guide; </li><li>  <b><a href="http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/">Article:</a></b> introduction to limited Boltzmann machines; </li><li>  <b><a href="https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf">Jeffrey Hinton: a</a></b> training manual for limited Boltzmann machines; </li><li>  <b><a href="https://github.com/zachmayer/rbm">GitHub:</a></b> Limited Boltzmann machines on R; </li><li>  <b><a href="http://deeplearning4j.org/deepbeliefnetwork.html">Deeplearning4j:</a></b> guide to creating deep networks of trust; </li></ul><br><blockquote>  Autocoders </blockquote><br><ul><li>  <b><a href="https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf">Andrew Eun:</a></b> sparse autocoders; </li><li>  <b><a href="http://deeplearning4j.org/deepautoencoder.html">Deeplearning4j:</a></b> guide to deep autocoders; </li><li>  <b><a href="http://deeplearning.net/tutorial/dA.html">Deep Learning:</a></b> noise-canceling autocoders; </li><li>  <b><a href="http://deeplearning.net/tutorial/SdA.html">Deep Learning:</a></b> embedded noise-reducing auto-encoders; </li></ul><br><blockquote>  Convolution networks </blockquote><br><ul><li>  <b><a href="https://github.com/kjw0612/awesome-deep-vision">Awesome Deep Vision: a</a></b> list of resources for machine vision; </li><li>  <b><a href="http://deeplearning4j.org/convolutionalnets.html">Deeplearning4j:</a></b> introduction to convolutional neural networks; </li><li>  <b><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/">Article:</a></b> application of convolutional networks for natural language processing; </li><li>  <b><a href="http://vision.stanford.edu/teaching/cs231n/">Stanford: the</a></b> use of convolutional networks for pattern recognition; </li><li>  <b><a href="http://cs.stanford.edu/people/karpathy/convnetjs/">Stanford:</a></b> a JavaScript library for working with convolutional networks; </li><li>  <b><a href="http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">Article:</a></b> application of convolutional networks for face recognition; </li><li>  <b><a href="http://engineeringblog.yelp.com/2015/10/how-we-use-deep-learning-to-classify-business-photos-at-yelp.html">Article:</a></b> creating a classifier of photos; </li><li>  <b><a href="http://blog.kaggle.com/2014/12/22/convolutional-nets-and-cifar-10-an-interview-with-yan-lecun/">Kaggle:</a></b> interview with Jan Lekun; </li><li>  <b><a href="https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf">Article:</a></b> Visualization of convolutional networks; </li></ul><br><blockquote>  Natural language processing </blockquote><br><ul><li>  <b><a href="https://github.com/edobashira/speech-language-processing">GitHub:</a></b> list of speech and natural language processing resources; </li><li>  <b><a href="http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/">Article:</a></b> Natural Language Processing with Deep Neural Networks on Torch; </li><li>  <b><a href="http://michaelerasm.us/tf-idf-in-10-minutes/">Guide:</a></b> what is TF-IDF; </li><li>  <b><a href="http://cs224d.stanford.edu/reports.html">Stanford:</a></b> interesting projects related to natural language processing; </li><li>  <b><a href="https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/35671.pdf">Google: the</a></b> basics of natural language processing; </li><li>  <b><a href="http://graph-ssl.wdfiles.com/local--files/blog%253A_start/graph_ssl_acl12_tutorial_slides_final.pdf">Manual:</a></b> partial training for processing natural language in graphs; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Model bag-of-words;</a></b> </li><li>  <b><a href="http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/">Manual:</a></b> text classification using the bag-of-words model; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Topic_model">Thematic modeling;</a></b> </li><li>  <b><a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent placement of Dirichlet (LRD);</a></b> </li></ul><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">Latent semantic analysis (LSA);</a></b> </li><li>  <b><a href="https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis">Probabilistic latent semantic analysis (VLSA);</a></b> </li><li>  <b><a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">Article:</a></b> What is LJE; </li><li>  <b><a href="http://confusedlanguagetech.blogspot.in/2012/07/jordan-boyd-graber-and-philip-resnik.html">The article:</a></b> Another good explanation of what is LRD; </li><li>  <b><a href="http://www.matthewjockers.net/2011/09/29/the-lda-buffet-is-now-open-or-latent-dirichlet-allocation-for-english-majors/">Article:</a></b> Intuitive explanation of the LRD; </li><li>  <b><a href="https://www.quora.com/Whats-the-difference-between-Latent-Semantic-Indexing-LSI-and-Latent-Dirichlet-Allocation-LDA">Quora:</a></b> what is the difference between LSA and LRD; </li><li>  <b><a href="https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf">Princeton:</a></b> Dirichlet's latent placement; </li><li>  <b><a href="https://www.quora.com/What-is-an-intuitive-explanation-of-the-Dirichlet-distribution">Quora:</a></b> an intuitive explanation of the Dirichlet distribution; </li><li>  <b><a href="http://tedunderwood.com/2012/04/07/topic-modeling-made-just-simple-enough/">Article:</a></b> Topical modeling is easy; </li></ul><br><ul><li>  <b><a href="http://alexminnaar.com/online-latent-dirichlet-allocation-the-best-option-for-topic-modeling-with-large-data-sets.html">Article:</a></b> Real-time update of the LRD model; </li><li>  <b><a href="http://alexminnaar.com/distributed-online-latent-dirichlet-allocation-with-apache-spark.html">Article:</a></b> Real-time update of the LRD model with Spark; </li><li>  <b><a href="http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-i-the-theory.html">Article:</a></b> LRD on Scala (Part 1); </li><li>  <b><a href="http://alexminnaar.com/latent-dirichlet-allocation-in-scala-part-ii-the-code.html">Article:</a></b> LRD on Scala (Part 2); </li><li>  <b><a href="http://alexperrier.github.io/jekyll/update/2015/09/16/segmentation_twitter_timelines_lda_vs_lsa.html">Article:</a></b> Segmentation of the Twitter event feed using thematic modeling; </li><li>  <b><a href="http://alexperrier.github.io/jekyll/update/2015/09/04/topic-modeling-of-twitter-followers.html">Article:</a></b> building a thematic model of subscribers on Twitter; </li><li>  <b><a href="https://code.google.com/p/word2vec/">Google:</a></b> word2vec; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Wiki:</a></b> bag-of-words model; </li><li>  <b><a href="http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf">Article: a</a></b> thorough analysis of skip-gram models; </li><li>  <b><a href="http://alexminnaar.com/word2vec-tutorial-part-i-the-skip-gram-model.html">Manual:</a></b> skip-gram-modeling; </li></ul><br><ul><li>  <b><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors">Kaggle:</a></b> vector representation of words; </li><li>  <b><a href="http://rare-technologies.com/making-sense-of-word2vec/">Article:</a></b> how to work with word2vec; </li><li>  <b><a href="http://deeplearning4j.org/word2vec.html">Deeplearning4j:</a></b> word2vec algorithm; </li><li>  <b><a href="https://www.quora.com/How-does-word2vec-work">Quora:</a></b> how word2vec works; </li><li>  <b><a href="https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures-in-laymans-terms">Quora:</a></b> about CBOW and skip-gram architectures in simple terms; </li><li>  <b><a href="https://www.quora.com/What-is-the-difference-between-the-Bag-of-Words-model-and-the-Continuous-Bag-of-Words-model">Quora:</a></b> what is the difference between BOW and CBOW; </li><li>  <b><a href="https://www.quora.com/Is-skip-gram-negative-sampling-better-than-CBOW-NS-for-word2vec-If-so-why">Quora:</a></b> which is better for word2vec - CBOW or skip-gram; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Wiki:</a></b> Levenshtein distance; </li></ul><br><ul><li>  <b><a href="http://fastml.com/classifying-text-with-bag-of-words-a-tutorial/">Article:</a></b> classification of texts using the bag-of-words model; </li><li>  <b><a href="http://blog.dennybritz.com/2015/09/11/reimagining-language-learning-with-nlp-and-reinforcement-learning/">Article:</a></b> language learning with natural language processing and reinforcement learning methods; </li><li>  <b><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words">Kaggle:</a></b> vector representation of words and bag-of-words (Part 1); </li><li>  <b><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-2-word-vectors">Kaggle:</a></b> vector representation of words and bag-of-words (Part 2); </li><li>  <b><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-3-more-fun-with-word-vectors">Kaggle:</a></b> vector representation of words and bag-of-words (Part 3); </li><li>  <b><a href="https://gigadom.wordpress.com/2015/10/02/natural-language-processing-what-would-shakespeare-say/">Manual:</a></b> prediction of words in natural language processing; </li><li>  <b><a href="http://homepages.inf.ed.ac.uk/ballison/pdf/lrec_skipgrams.pdf">Article:</a></b> more about skip-gram-modeling; </li></ul><br><blockquote>  Computer vision </blockquote><br><ul><li>  <b><a href="https://github.com/jbhuang0604/awesome-computer-vision">Awesome Computer Vision: a</a></b> list of materials on computer vision; </li><li>  <b><a href="https://github.com/kjw0612/awesome-deep-vision">Awesome Deep Vision: a</a></b> list of resources for image recognition; </li></ul><br><blockquote>  Support Vector Machine </blockquote><br><ul><li>  <b><a href="https://www.quora.com/What-does-support-vector-machine-SVM-mean-in-laymans-terms">Quora:</a></b> support vector machine in simple language; </li><li>  <b><a href="http://alex.smola.org/papers/2003/SmoSch03b.pdf">Guide:</a></b> support vector machine; </li><li>  <b><a href="http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf">Guide:</a></b> support vector machine; </li><li>  <b><a href="http://www.csie.ntu.edu.tw/~cjlin/talks/freiburg.pdf">Presentation:</a></b> support vector method; </li><li>  <b><a href="http://www.statsoft.com/Textbook/Support-Vector-Machines">Article:</a></b> introduction to the support vector method; </li></ul><br><ul><li>  <b><a href="http://www.svms.org/anns.html">Article:</a></b> Comparison of Support Vector and Neural Networks; </li><li>  <b><a href="http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf">Article:</a></b> optimization algorithms in the support vector machine; </li><li>  <b><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM:</a></b> library for classification by the support vector <b><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">machine</a></b> ; </li></ul><br><ul><li>  <b><a href="https://www.quora.com/What-are-Kernels-in-Machine-Learning-and-SVM">Quora:</a></b> what are kernels in machine learning; </li><li>  <b><a href="https://www.quora.com/Support-Vector-Machines/What-is-the-intuition-behind-Gaussian-kernel-in-SVM">Quora:</a></b> Gaussian kernel in the support vector machine; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Platt_scaling">Wiki:</a></b> Platt scaling; </li><li>  <b><a href="http://fastml.com/classifier-calibration-with-platts-scaling-and-isotonic-regression/">Article:</a></b> Calibrating Classifiers Using Platt Scaling; </li></ul><br><blockquote>  Reinforcement training </blockquote><br><ul><li>  <b><a href="https://github.com/aikorea/awesome-rl">Awesome Reinforcement Learning: a</a></b> list of resources for learning with reinforcement; </li><li>  <b><a href="http://outlace.com/Reinforcement-Learning-Part-1/">Manual:</a></b> reinforcement training (Part 1); </li><li>  <b><a href="http://outlace.com/Reinforcement-Learning-Part-2/">Manual:</a></b> reinforcement training (Part 2); </li></ul><br><blockquote>  Decision trees </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Wiki:</a></b> decision trees; </li><li>  <b><a href="http://stats.stackexchange.com/questions/tagged/cart">FAQ:</a></b> decision trees; </li><li>  <b><a href="http://statistical-research.com/a-brief-tour-of-the-trees-and-forests/">Article:</a></b> decisive forests and trees; </li><li>  <b><a href="http://www.statmethods.net/advstats/cart.html">Article:</a></b> methods based on decision trees in R; </li><li>  <b><a href="http://www.aihorizon.com/essays/generalai/decision_trees.htm">Article:</a></b> how decision trees work; </li><li>  <b><a href="http://www.ise.bgu.ac.il/faculty/liorr/hbchap9.pdf">Article:</a></b> algorithms and their essence; </li><li>  <b><a href="http://www.slideshare.net/pierluca.lanzi/machine-learning-and-data-mining-11-decision-trees">Presentation:</a></b> decision trees; </li></ul><br><ul><li>  <b><a href="http://www.salford-systems.com/videos/tutorials/tips-and-tricks/using-surrogates-to-improve-datasets-with-missing-values">Article:</a></b> using surrogates to improve incomplete data sets; </li><li>  <b><a href="https://www.mindtools.com/dectree.html">Article:</a></b> decision trees; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Pruning_%2528decision_trees%2529">Wiki:</a></b> pruning decision tree branches; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Grafting_%2528decision_trees%2529">Wiki:</a></b> reverse process for cutting branches; </li><li>  <b><a href="http://stats.stackexchange.com/questions/12140/conditional-inference-trees-vs-traditional-decision-trees">Comparison:</a></b> CART and CTREE algorithms; </li><li>  <b><a href="http://stats.stackexchange.com/questions/61230/chaid-vs-crt-or-cart">Comparison:</a></b> algorithms CHAID and CART; </li></ul><br><ul><li>  <b><a href="http://www.bzst.com/2006/10/classification-trees-cart-vs-chaid.html">Comparison:</a></b> CART and CHAID algorithms; </li><li>  <b><a href="http://www.ftpress.com/articles/article.aspx%3Fp%3D2248639%26seqNum%3D11">Article:</a></b> another comparison of different algorithms; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Recursive_partitioning">Wiki:</a></b> recursive partitioning; </li><li>  <b><a href="http://documents.software.dell.com/Statistics/Textbook/Classification-and-Regression-Trees">Article:</a></b> CART algorithm; </li><li>  <b><a href="http://stats.stackexchange.com/questions/6478/how-to-measure-rank-variable-importance-when-using-cart-specifically-using">CART:</a></b> assessment of the importance of a variable; </li><li>  <b><a href="http://stats.stackexchange.com/questions/tagged/rpart">FAQ:</a></b> recursive partitioning; </li><li>  <b><a href="https://cran.r-project.org/web/packages/party/party.pdf">Article:</a></b> party package in R; </li><li>  <b><a href="https://en.wikipedia.org/wiki/CHAID">Wiki:</a></b> automatic chi-square interaction detector (CHAID); </li><li>  <b><a href="https://smartdrill.com/Introduction-to-CHAID.html">Article:</a></b> introduction to CHAID; </li><li>  <b><a href="http://www.statsoft.com/Textbook/CHAID-Analysis">Manual:</a></b> CHAID; </li></ul><br><blockquote>  Mars </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines">Wiki:</a></b> Multidimensional Adaptive Regression Splines (MARS); </li></ul><br><blockquote>  Probabilistic decision trees </blockquote><br><ul><li>  <b><a href="http://www.stats.org.uk/bayesian/Jordan.pdf">Article:</a></b> Bayesian learning in probabilistic decision trees; </li><li>  <b><a href="http://people.stern.nyu.edu/adamodar/pdfiles/papers/probabilistic.pdf">Article:</a></b> probabilistic trees; </li></ul><br><blockquote>  Random forest </blockquote><br><ul><li>  <b><a href="https://github.com/kjw0612/awesome-random-forest">GitHub: a</a></b> list of resources for a random forest; </li><li>  <b><a href="https://www.kaggle.com/forums/f/15/kaggle-forum/t/4092/how-to-tune-rf-parameters-in-practice">Kaggle:</a></b> setting parameters of a random forest algorithm; </li><li>  <b><a href="https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v10.2.pdf">Presentation:</a></b> error out-of-bag; </li><li>  <b><a href="http://www.jstatsoft.org/article/view/v050i11">Article:</a></b> Evaluating Random Forest Algorithms for Survival; </li><li>  <b><a href="http://stats.stackexchange.com/questions/tagged/random-forest">FAQ:</a></b> random forest; </li></ul><br><blockquote>  Tree Boosting Algorithms </blockquote><br><ul><li>  <b><a href="http://www.datasciencecentral.com/profiles/blogs/boosting-algorithms-for-better-predictions">Article:</a></b> why you need a boosting; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Boosting_%2528machine_learning%2529">Wiki:</a></b> boosting; </li><li>  <b><a href="https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf">Chen Tianzi:</a></b> "growing" trees; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Gradient_boosting">Wiki:</a></b> gradient boosting; </li><li>  <b><a href="http://www.slideshare.net/mark_landry/gbm-package-in-r">Presentation: A</a></b> generalized enhanced regression GBM model on R; </li><li>  <b><a href="http://stats.stackexchange.com/tags/gbm/hot">FAQ:</a></b> GBM; </li><li>  <b><a href="https://www.kaggle.com/c/higgs-boson/forums/t/9497/r-s-gbm-vs-python-s-xgboost">Kaggle:</a></b> GBM or xgboost; </li><li>  <b><a href="https://www.kaggle.com/khozzy/rossmann-store-sales/xgboost-parameter-tuning-template/log">Kaggle:</a></b> setting parameters xgboost; </li><li>  <b><a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/13012/question-to-experienced-kagglers-and-anyone-who-wants-to-take-a-shot/68296">Kaggle:</a></b> xgboost or GBM; </li><li>  <b><a href="https://www.kaggle.com/c/higgs-boson/forums/t/10335/xgboost-post-competition-survey">Review:</a></b> xgboost; </li><li>  <b><a href="https://en.wikipedia.org/wiki/AdaBoost">Wiki:</a></b> AdaBoost; </li><li>  <b><a href="http://hamzehal.blogspot.com/2014/06/adaboost-sparse-input-support.html">AdaBoost:</a></b> working with a flat data set; </li><li>  <b><a href="https://cran.r-project.org/web/packages/adabag/adabag.pdf">Package:</a></b> adaBag; </li><li>  <b><a href="http://math.mit.edu/~rothvoss/18.304.3PM/Presentations/1-Eric-Boosting304FinalRpdf.pdf">AdaBoost: a</a></b> guide; </li></ul><br><blockquote>  Compositional training </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Ensemble_learning">Wiki:</a></b> compositional learning; </li><li>  <b><a href="http://mlwave.com/kaggle-ensembling-guide/">Kaggle:</a></b> compositional study guide; </li><li>  <b><a href="http://machine-learning.martinsewell.com/ensembles/">Article:</a></b> introduction to compositional learning; </li><li>  <b><a href="http://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/springerEBR09.pdf">Article:</a></b> compositional learning; </li><li>  <b><a href="http://amunategui.github.io/blending-models/">Composite models on R;</a></b> </li><li>  <b><a href="https://www.kaggle.com/c/afsis-soil-properties/forums/t/10391/best-ensemble-references">Kaggle:</a></b> prediction of soil properties in Africa; </li><li>  <b><a href="http://www.chioka.in/which-is-better-boosting-or-bagging/">Comparison:</a></b> boosting and bagging; </li></ul><br><blockquote>  Stacking </blockquote><br><ul><li>  <b><a href="http://www.chioka.in/stacking-blending-and-stacked-generalization/">Article:</a></b> Stacking, Blending and Multi-Layer Generalization; </li><li>  <b><a href="http://machine-learning.martinsewell.com/ensembles/stacking/">Article:</a></b> multi-tiered generalization; </li><li>  <b><a href="http://www.ijcai.org/Past%2520Proceedings/IJCAI-97-VOL2/PDF/011.pdf">Article:</a></b> when to apply a multi-tiered generalization; </li><li>  <b><a href="http://citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.56.1533%26rep%3Drep1%26type%3Dpdf">Article:</a></b> multi-tiered generalization; </li></ul><br><blockquote>  Dimension Vapnik - Chervonenkisa </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/VC_dimension">Wiki: the</a></b> dimension of Vapnik - Chervonenkis; </li><li>  <b><a href="https://www.quora.com/Explain-VC-dimension-and-shattering-in-lucid-Way">Quora:</a></b> an intuitive explanation of the Vapnik-Chervonenkis dimension; </li><li>  <b><a href="https://www.youtube.com/watch%3Fv%3DpuDzy2XmR5c">Video:</a></b> what is the dimension of Vapnik - Chervonenkis; </li><li>  <b><a href="http://www.svms.org/vc-dimension/">Article:</a></b> acquaintance with the dimension of Vapnik - Chervonenkis; </li><li>  <b><a href="http://stats.stackexchange.com/questions/tagged/vc-dimension">FAQ: the</a></b> dimension of Vapnik - Chervonenkis; </li></ul><br><blockquote>  Bayesian machine learning methods </blockquote><br><ul><li>  <b><a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers">GitHub: an</a></b> introduction to Bayesian machine learning techniques; </li><li>  <b><a href="http://videolectures.net/bark08_ghahramani_samlbb/">Video:</a></b> Should all machine learning methods be Bayesian; </li><li>  <b><a href="http://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf">Guide:</a></b> Bayesian optimization; </li><li>  <b><a href="http://blog.shakirm.com/2015/10/bayesian-reasoning-and-deep-learning/">Article:</a></b> Bayesian inference and deep learning; </li><li>  <b><a href="http://greenteapress.com/thinkbayes/">Article:</a></b> Bayesian statistics in simple words; </li><li>  <b><a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python">GitHub:</a></b> Kalman and Bayes filters in Python; </li><li>  <b><a href="https://en.wikipedia.org/wiki/Markov_chain">Wiki:</a></b> Markov chain; </li></ul><br><blockquote>  Partial training </blockquote><br><ul><li>  <b><a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Wiki:</a></b> partial training; </li><li>  <b><a href="http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf">Manual:</a></b> partial training; </li><li>  <b><a href="http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/taxo_%255B0%255D.pdf">Hierarchical clustering (taxonomy);</a></b> </li><li>  <b><a href="https://www.youtube.com/watch%3Fv%3DsWxcIjZFGNM">Video tutorial:</a></b> partial training; </li><li>  <b><a href="http://stats.stackexchange.com/questions/517/unsupervised-supervised-and-semi-supervised-learning">Article:</a></b> training with a teacher, without a teacher and partial training; </li><li>  <b><a href="http://mlg.eng.cam.ac.uk/zoubin/papers/zglactive.pdf">Article:</a></b> combining the possibilities of active and partial learning using the Gaussian random field model; </li><li>  <b><a href="http://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf">Article:</a></b> using the Gaussian random field model in partial learning; </li><li>  <b><a href="http://icml.cc/2012/papers/616.pdf">Article:</a></b> improved partial learning algorithm; </li></ul><br><blockquote>  Optimization </blockquote><br><ul><li>  <b><a href="http://www.wdiam.com/2012/06/10/mean-variance-portfolio-optimization-with-r-and-quadratic-programming/%3Futm_content%3Dbuffer04c12%26utm_medium%3Dsocial%26utm_source%3Dlinkedin.com%26utm_campaign%3Dbuffer">Article:</a></b> Optimization of the portfolio of assets on R using quadratic programming; </li><li>  <b><a href="http://pages.cs.wisc.edu/~swright/nips2010/sjw-nips10.pdf">Article:</a></b> optimization algorithms in machine learning; </li><li>  <b><a href="http://videolectures.net/nips2010_wright_oaml/">Video:</a></b> optimization algorithms in machine learning; </li><li>  <b><a href="http://www.birs.ca/workshops/2011/11w2035/files/Wright.pdf">Article:</a></b> optimization algorithms in data analysis; </li><li>  <b><a href="http://videolectures.net/stephen_j_wright/">Video:</a></b> lectures on optimization; </li><li>  <b><a href="http://pages.cs.wisc.edu/~swright/talks/sjw-complearning.pdf">Article:</a></b> optimization algorithms for the support vector machine; </li><li>  <b><a href="http://jmlr.org/papers/volume7/MLOPT-intro06a/MLOPT-intro06a.pdf">Article: the</a></b> relationship between optimization problems and machine learning; </li></ul><br><blockquote>  Additionally </blockquote><br><ul><li>  <b><a href="https://github.com/ujjwalkarn/DataScienceR">GitHub: a</a></b> collection of guides for using R in data science. </li></ul><br>  <i>PS In our blog, we write about the <a href="https://habrahabr.ru/company/spbifmo/blog/269127/">development</a> of communication systems and the <a href="https://habrahabr.ru/company/spbifmo/blog/275071/">first steps</a> towards advanced programming.</i>  <i>There is still a lot of interesting, subscribe and do not miss our new materials, friends.</i> </div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/277593/">https://habr.com/ru/post/277593/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../277581/index.html">Game development digest</a></li>
<li><a href="../277583/index.html">Parallel execution of tests based on context using Visual Studio 2015 Update 1</a></li>
<li><a href="../277585/index.html">Console management of the DLNA server Mediatomb</a></li>
<li><a href="../277589/index.html">5 educational opportunities abroad for students and recent graduates</a></li>
<li><a href="../277591/index.html">What are the latest changes in the 63-FZ "on electronic signature"</a></li>
<li><a href="../277597/index.html">How we used Git, CI and code review in the learning process</a></li>
<li><a href="../277599/index.html">Hello, World! On FPGA. Blink LED</a></li>
<li><a href="../277601/index.html">How we automate testing with release management - Part 1</a></li>
<li><a href="../277603/index.html">The rules of good tone when writing a plugin on jQuery</a></li>
<li><a href="../277605/index.html">Nuances of developing a plugin for Unity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>