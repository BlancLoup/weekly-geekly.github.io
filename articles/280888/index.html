<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Overview of Local Binary Patterns (LBP) Image Descriptors and Their Variations</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, habrovchane. I invite under the cut programmers interested in computer vision and image processing. Perhaps you missed a simple but ef...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Overview of Local Binary Patterns (LBP) Image Descriptors and Their Variations</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, habrovchane.  I invite under the cut programmers interested in computer vision and image processing.  Perhaps you missed a simple but effective mathematical tool for low-level description of textures and specifying their characteristics for machine learning algorithms. <br><a name="habracut"></a><br><h4>  Introduction </h4><br>  The LBP theme has already been <a href="https://habrahabr.ru/post/153109/">raised</a> on Habr√©, however, I decided to slightly spread the proposed explanation and share some variations of this pattern. <br><br>  As you know, a computer image is the same numerical information.  Each pixel is represented by a number in the case of a black and white image or a triple of numbers in the case of color.  In general, they constitute a pleasant picture for the human eye and it is convenient to carry out transformations on them, but often there is <i>too</i> much information.  For example, in object recognition tasks we rarely care about the value of each pixel separately: images are often noisy, and the desired images may appear in different versions, therefore it is desirable that the algorithms are resistant to errors, the ability to grasp the general trend.  This property of English-speaking sources is called robustness. <br><br>  One way to deal with this problem is to pre-process the image, and leave only significant points, and apply subsequent algorithms to them.  For this purpose, SIFT, SURF and other DAISY, feature descriptors were invented.  With their help, you can stitch pictures, match objects and do a lot of useful things, however these descriptors have their drawbacks.  In particular, it is expected that the points found will be in some sense truly special and unique, reproducible from image to image.  You should not use SIFT to understand that both halves of this image are brick walls. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/d4b/0de/569/d4b0de56980648f99a7e01aec2c0f390.png"><br><br>  In addition, although these descriptors are called local, they still use a fairly large area of ‚Äã‚Äãthe image.  This is not a good computational cost.  Let's weaken this position a little.  Perhaps we can characterize the image, considering even smaller structures? <br><br><h4>  main idea </h4><br>  Again, we want to get a way to describe the structure of the picture, which <br><ol><li>  Quickly considered </li><li>  Invariant under brightness conversions that preserve order ( <img src="https://habrastorage.org/files/8d4/525/cc5/8d4525cc55924dddaf167903d992c2d9.png" width="18%">  ) </li><li>  Noise resistant </li><li>  Resistant to texture variations </li><li>  Strongly reduces the dimension of the problem </li></ol><br>  So what is a local binary pattern?  In short: this is a way for each pixel to describe in which direction the brightness decreases.  Build it is a snap.  Let's do this and do it. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/ee6/1a4/585/ee61a4585dc5492fad741a997e146749.png"></div><br><ul><li>  First you need to choose the radius and the number of points ... stop-stop, who said "rogue"?  Yes, literally a couple of lines above, I wrote that this descriptor is very local, but the definition of what is ‚Äúvery local‚Äù may differ from image to image.  But so be it, let's stop at a radius of one: hereinafter, for each pixel, we will calculate LBP based on 8 adjacent points. </li><li>  Number the selected points. </li><li>  Calculate the difference in brightness values ‚Äã‚Äãbetween each of the extreme pixels and the central one. </li><li>  If the difference is negative (brightness decreases), write one in the mind of the neighbor‚Äôs place, if nonnegative (&gt; = 0) is zero. </li><li>  ‚ÄúPull‚Äù the resulting circle from zeros and ones into a line. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a87/702/260/a87702260cff49aa9e6c28c357cfe5ae.png" width="50%"></div><br>  Wait a second, it's just a binary number!  We will call it the buzzwords of Local Binary Pattern (Timo Ojala, July 2002).  From the point of view of mathematics, it looks like this: <br><img src="https://habrastorage.org/files/d71/458/e37/d71458e372f448c7abc196b57c31a112.png"><br>  where s is a step (x) (step) function, which returns 0 if <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>x</mi><mo>&amp;gt;</mo><mn>0</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.591ex" height="1.937ex" viewBox="0 -728.2 2407.1 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-78" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-3E" x="850" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-30" x="1906" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mo>&gt;</mo><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-1"> x> 0 </script>  and 1 if <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>x</mi><mo>&amp;lt;</mo><mn>0</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.591ex" height="1.937ex" viewBox="0 -728.2 2407.1 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-78" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-3C" x="850" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-30" x="1906" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mo>&lt;</mo><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-2"> x <0 </script>  . <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>g</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>0</mn><mo>,</mo><mn>1</mn><mtext>&amp;#xA0;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mi>s</mi><mn>7</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.867ex" height="2.057ex" viewBox="0 -520.7 3387.2 885.9" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-67" x="0" y="0"></use><g transform="translate(477,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-30" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-2C" x="500" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-31" x="779" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-64" x="1633" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-6F" x="2156" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-74" x="2642" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-73" x="3003" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMAIN-37" x="3473" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>g</mi><mrow class="MJX-TeXAtom-ORD"><mn>0</mn><mo>,</mo><mn>1</mn><mtext>&nbsp;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mi>s</mi><mn>7</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> g_ {0, 1 \ dots 7} </script>  Are the brightness values ‚Äã‚Äãof the pixel numbered neighbors, and <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>g</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.053ex" height="1.817ex" viewBox="0 -520.7 884 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-67" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/280888/&amp;xid=17259,15700021,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjr_u2FWozaLiAscwS_18ZXFL-C9A#MJMATHI-63" x="675" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>g</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> g_ {c} </script>  - the brightness value of the center pixel itself. <br><br>  That's all.  A more savvy math reader would call the bits of the descriptor signs of brightness derivatives in directions, but this is unprincipled.  It is clear that requirements 1-2 are trivially fulfilled.  3, probably, needs some work, we'll talk about it a little later.  But what to do with 4?  So far it is not entirely clear how to work with it.  Yes, and with a decrease in the dimension of the problem, we coped so-so: instead of a byte of pixel brightness values, we got a byte of signs of brightness variation in directions.  There are no invariance on affine transformations, but we didn‚Äôt demand it: after all, the pattern of squares and rhombuses are two different patterns. <br><br>  From the obtained data it is already possible to extract something interesting, let's see how to put them into practice as soon as possible, and, proceeding from this, we will think about how to improve them. <br><br><h4>  Well, I learned to count LBP.  What's next? </h4><br>  Use LBP where you are working with textures.  The most banal option: the program receives a texture at the input, and it determines the texture of what is in front of it.  This may be one of the steps or an aid to a more complex algorithm.  For example, the recognition algorithm in an image of an object that does not have a specific shape, but only some kind of structure: fire, smoke or foliage (Hongda Tian, ‚Äã‚Äã2011).  Alternatively: use LBP when segmenting images to teach the machine to consider a unique object not every line on a zebra, but the whole zebra.  See the trees behind the forest. <br><br>  How exactly this happens depends on the task and the selected type of LBP.  It does not always make sense to look at the pictures for repeating patterns from LBP, and certainly you should not compare descriptors on one image with descriptors on another.  Resistance to noise, we plan to take quantity, and it plays with us a cruel joke: the resulting codes are simply too much.  Good results can be obtained if the neural network autoencoder (autoencoder) is connected to the LBP card, it can extract more information from the prepared patterns than from the raw picture.  A simpler option is to scrape all the resulting codes into one pile (build a histogram), and work with it already. <br><br>  The latter approach looks strange at first.  Is information not lost when we so simply erase information about the relative position of the trace elements in the image?  In general, yes, it is possible to pick up an example from three pictures, that 1 and 2 are visually more similar, but according to the histogram, 1 and 3 are more similar, however, in practice this is unlikely. <br><br>  A full histogram also often carries redundant information, so I advise you to arm yourself with the technique proposed in (S. Liao, May 2009) and developed in (Jinwang Feng, 2015): <br><br><ul><li>  Calculate descriptors for each pixel in the image. </li><li>  Count their histogram </li><li>  Sort the histogram beans descending.  Surprisingly, according to (S. Liao, May 2009), information <i>about</i> which bins can be discarded, their very distribution by the histogram carries enough information.  You can not discard, in my opinion, so reliable. </li><li>  Leave the part of the histogram, which includes a certain predetermined percentage of patterns, discard the rest.  Charts in the same paper claim that 80% is an acceptable number.  The left part of the distribution ([bin number], its percentage) is the so-called dominant patterns (DLBP). </li><li>  DLBP can be fed to a neural network or SVM, which, with the help of machine learning magic and a previously provided training set, will determine what kind of texture is in front of it. </li></ul><br><img src="https://habrastorage.org/files/475/a55/67d/475a5567d8db437dadaa4f52d63589a8.png"><br><br>  In conclusion, I note that no one forces you to dwell on textures.  LBPs are successfully applied instead of and along with Haar-like features in AdaBoost training.  They capture high-frequency information that integral features miss. <br><br><h4>  Variations </h4><br>  So far, the choice of LBP as low-level information for machine learning looks unconvincing.  It's time to fix the flaws that we talked about above!  For such a surprisingly simple descriptor as LBP during its existence, many variations have been invented. <br><br>  We have two conflicting tasks.  First: reduce the number of patterns to make it easier to chew on the machine.  Often we are interested in histograms, and if a histogram of 2 ^ 8 elements is acceptable, then from 2 ^ 24 it takes up a lot of space.  Second: to increase the information content of the patterns.  We would like to distinguish particular points of different types, and, the more they differ, the more patterns should differ.  A separate item should be made resistance to noise. <br><br><h5>  Significant patterns </h5><br>  To begin with, we note that the objects that the human eye can recognize are the most interesting for us: the boundaries of lines, corners, points, or spots.  If you mentally place the center point on the edge of such an object and calculate the LBP, then at the circle stage you can see that the zeros and ones are divided into two groups.  When the circle is ‚Äúdrawn out‚Äù, a number with 0, 1 or 2 transitions 0-1 or 1-0 is formed.  For example, "00111100", "11111111" and "01111111" - refer to the "good" patterns, and "10100000" and "01010101" - no. <br><br>  Rejoice.  Although not that we are the only ones who discovered it.  In the work with which the active LBP study began (Timo Ojala, July 2002), they also noticed that such patterns carry most of the relevant information.  They even came up with a special name: ‚Äúuniform patterns‚Äù (uniform patterns).  Their number is easy to calculate: for 8 neighbors, we have 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 1 = 37 pieces ((P + 1) * P / 2 + 1).  Plus, another label, under which we scrape together all the non-uniform patterns.  It has become much more pleasant. <br><img src="https://habrastorage.org/files/65d/71a/418/65d71a418c884058825690282f6384ba.png" width="50%"><br><br>  There are other ways to thin a set of tags.  For example, if for some reason we don‚Äôt want to remove non-uniform patterns, we can at least get rid of all the patterns that result from rotating the image around the central pixel.  Just enter a one-to-one correspondence that will display the LBP group into one.  Let's say we will consider the ‚Äúreal‚Äù pattern as the one that has the minimum value in cyclic shifts to the right.  Or to the left.  The gift gets the invariance of the descriptor relative to the rotation of the object.  (Junding Sun, 2013) <br><img src="https://habrastorage.org/files/3bf/c99/4cf/3bfc994cf8be4d07983b9ba4dab81c35.png" width="40%"><br><br>  You can also take the same patterns, for cases where the object and the background change colors.  Then it can be considered as a ‚Äúeffective‚Äù minimum pattern from LBP and ~ LBP.  This option was used in the work of detecting smoke, which may look light gray against a dark background or dark gray against a white background (Hongda Tian, ‚Äã‚Äã2011). <br><br>  In (Yiu-ming Cheung, 2014), it is generally proposed to get rid of unnecessary neighbors and count ultra-local descriptors using only a couple of pixels, and then ‚Äúcollect‚Äù features by calculating the coincidence matrices (co-occurrence matrix), but this is more like the usual calculation of the derivative with subsequent frauds over it.  It seems to me difficult to effectively put them into practice. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/07a/c17/9ca/07ac179ca595448baeb302480aae1db0.png" width="30%"></div><br><br>  Alternatively, we can consider the derivative of the brightness of the second order, it needs only 4 directions.  Unfortunately, it is more prone to the negative effects of noise, and is less likely to carry significant information about the image.  The use of this technique also strongly depends on the task. <br><img src="https://habrastorage.org/files/4bf/a2d/230/4bfa2d2302ad4195adf7bdf0ec07d245.png" width="30%"><br><br><h5>  Noise resistance </h5><br>  But in general, the idea of ‚Äã‚Äãchanging the way we consider a derivative was good.  Let us try to return to the first derivative and introduce stricter restrictions on the change of its sign.  We will consider not the directions from the central pixel to the outermost, but the directions from the outermost pixels to the outermost pixels from it (Junding Sun, 2013). <br><div style="text-align:center;"><img src="https://habrastorage.org/files/cb5/d88/138/cb5d8813855a4e6188d2aebea815d675.png" width="20%"></div><br>  We will write a unit for a pixel if the brightness decreases from the first pixel to the central one and from the central one to the second.  If the brightness increases or does not have a specific behavior - zero.  Unfortunately, we lose information about bright and dark lonely points, but if we know that the image contains a lot of noise, it is even good. <br><br>  In general, if a high level of noise is expected, more points can be used to calculate the derivative, averaged with some weights with the values ‚Äã‚Äãof the neighbors or even pixel values ‚Äã‚Äãoutside the selected circle. <br><br>  The way we check whether the brightness changes also seems a bit suspicious.  In fact, if you just use the derivative symbol, then LBP will find phantom patterns even on an absolutely smooth image with even minimal noise.  The usual way to deal with such a problem is to set a threshold with which we compare the change in brightness between pixels.  You can set it from the outside if there is additional information about the character of the image, but this is not too great, since typical guessing on the parameters begins.  The preferred option is to calculate the average value of the derivative over a certain neighborhood or the entire image and compare it with it (Jinwang Feng, 2015). <br><img src="https://habrastorage.org/files/3ad/ce6/66d/3adce666d45a4885a6fd9097f73e1b15.png" width="40%"><br><br>  If you wish, you can use more gradations, but this inflates the maximum number of patterns. <br><br><h5>  More information </h5><br>  Local Binary Pattern is easy to extend to the case of three dimensions (Xiaofeng Fu, 2012), (Guoying Zhao, 2007), (Xie Liping, July 2014).  If you imagine the video as a ‚Äústack‚Äù of frames, then each pixel is not 8, but 9 + 9 + 8 = 26 neighbors (or less, if you remove some corner pixels).  There are different ways to get LBP in this case.  The two most common: <br><ul><li>  Three parallel to the plane.  For each pixel i, j, we calculate by the standard LBP in frames t-1, t, t + 1.  Then we concatenate them and write them down, or, if we are only interested in patterns that do not change from frame to frame, we compare them to each other, and we write only if the resulting LBPs are the same, otherwise we assign a garbage tag. </li><li>  Three orthogonal planes.  For each pixel (i, j, t), we consider three sets of neighbors: those lying in the frame, different in time, the same in a row, different in time and the same in a column.  This method is more suitable for patterns that change over time.  It requires more computational expense than the previous one. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c42/88f/401/c4288f4012e74c17add07b89b03094df.png" width="50%"></div><br>  Finally, the result of some non-local filter can be attached to the descriptor.  For example, in (Xie Liping, July 2014) Gabor filters are used for this.  They are well suited for detecting periodic structures, but they have certain disadvantages, in particular, they ‚Äúring‚Äù on single direct lines.  Proper combined use of LBP and global filters eliminates the drawbacks of both those and those.  On Habr√© about the use of filters Gabor can be read, for example, <a href="https://habrahabr.ru/company/synesis/blog/238129/">here</a> and <a href="https://habrahabr.ru/company/nordavind/blog/248991/">here</a> . <br><br><h4>  Example </h4><br>  Practice without theory is blind, but theory without practice is completely dead, so let's program something already.  This trivial Python 3.4 code (PIL, numpy and matplotlib required) counts and displays the LBP histogram for the image.  For ease of understanding, only optimization was used with setting the minimum difference in brightness proportional to the average difference in brightness in the image.  From the result, you can calculate and use DLBP for machine learning, but in general, this is a very naive implementation.  In real-world applications, pre-processing is required.  Note that zeros, descriptors of a homogeneous region are not recorded: they are almost always very, very much and they bring down the histogram normalization.  They can be used separately as a measure of the scale of the texture. <br><br>  Code: <br><div class="spoiler">  <b class="spoiler_title">(I beg your pardon for deviating from style in the name of simplicity)</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compute_direction</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y, threshold_delta)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x - y &gt; threshold_delta <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment"># 7 0 1 # 6 x 2 # 5 4 3 def compute_lbp(data, i, j, threshold_delta): result = 0 result += compute_direction(data[i, j], data[i-1, j], threshold_delta) result += 2 * compute_direction(data[i, j], data[i-1, j+1], threshold_delta) result += 4 * compute_direction(data[i, j], data[i, j+1], threshold_delta) result += 8 * compute_direction(data[i, j], data[i+1, j+1], threshold_delta) result += 16 * compute_direction(data[i, j], data[i+1, j], threshold_delta) result += 32 * compute_direction(data[i, j], data[i+1, j-1], threshold_delta) result += 64 * compute_direction(data[i, j], data[i, j-1], threshold_delta) result += 128 * compute_direction(data[i, j], data[i-1, j-1], threshold_delta) return result image = Image.open("test.png", "r") image = image.convert('L') #makes it grayscale data = np.asarray(image.getdata(), dtype=np.float64).reshape((image.size[1], image.size[0])) lbps_histdata = [] mean_delta = 0 for i in range(1, image.size[1]-1): for j in range(1, image.size[0]-1): mean_delta += (abs(data[i, j] - data[i, j-1]) + abs(data[i, j] - data[i-1, j-1]) + abs(data[i, j] - data[i-1, j]) + abs(data[i, j] - data[i-1, j+1]) )/4.0 mean_delta /= (image.size[1]-2) * (image.size[0]-2) #normalizing mean_delta *= 1.5 #we are interested in distinct luminosity changes so let's rise up threshold for i in range(0, image.size[1]): for j in range(0, image.size[0]): if i != 0 and j != 0 and i != image.size[1]-1 and j != image.size[0]-1: tmp = compute_lbp(data, i, j, mean_delta) if tmp != 0: lbps_histdata.append(tmp) hist, bins = np.histogram(lbps_histdata, bins=254, normed=True) width = bins[1] - bins[0] center = (bins[:-1] + bins[1:]) / 2 plt.bar(center, hist, align='center', width=width) plt.show()</span></span></code> </pre> <br></div></div><br>  Texture examples and results: <br><div class="spoiler">  <b class="spoiler_title">More pixels</b> <div class="spoiler_text">  And you call this textures?  Well this is just patterns! <br>  Well‚Ä¶ <br><img src="https://habrastorage.org/files/f0c/581/976/f0c581976d0c4f6d94c5cece9cfa399c.jpg" width="30%"><br>  Pictures are specially selected so that the eye can see the similarities / differences.  It is also easy to see why there are many / few LBPs in a particular pattern. <br>  Pattern 1 <br><img src="https://habrastorage.org/files/0cf/879/076/0cf879076f7144a5896f50eeb9644f21.png"><br>  Pattern 1 + noise <br><img src="https://habrastorage.org/files/728/01b/46b/72801b46b0d5429fb1d45fb678424459.png"><br>  Pattern 1 + even more noise and spots <br><img src="https://habrastorage.org/files/8f5/014/466/8f50144669c6475da00008df1bde8296.png"><br>  Pattern 2 <br><img src="https://habrastorage.org/files/dd1/37c/f72/dd137cf72f914ec98201ab97d9d9cdb1.png"><br>  Pattern 3 <br><img src="https://habrastorage.org/files/c2c/155/931/c2c1559315d14a5e9ee6e484381b8806.png"><br></div></div><br><div class="spoiler">  <b class="spoiler_title">More pixels</b> <div class="spoiler_text">  Comparison of LBP histograms of the first three pictures.  The most characteristic bins coincide, but there are several parasitic ones.  Note a large number of LBP = 255, black dots on a white background.  Green coincidence marked, red - extra bins. <br><img src="https://habrastorage.org/files/44b/6e7/2fe/44b6e72fe1984577ab2304dc6e39f839.png"><br>  Comparison of histograms 4 and 5 pictures, then comparison of histograms 1 and 4 pictures.  Greens are coincidences, yellow - differences.  Although these pictures have different textures, 4 and 5 are definitely more similar than 1 and 4. This can be seen both by eye and by comparing histograms. <br><img src="https://habrastorage.org/files/aaf/ead/2ca/aafead2cac9f4695aeeb2642daa07527.png"><br><img src="https://habrastorage.org/files/9d0/faa/1b7/9d0faa1b71da4f2f8094e890636825da.png"><br></div></div><br>  Notice that the same bins often have the highest values ‚Äã‚Äã‚Äî they correspond to the uniform patterns discussed above.  However, the distribution of them for different textures is different.  The higher the noise level and randomness of the texture, the greater the ‚Äúgarbage‚Äù LBPs (see small bins in histograms). <br><br><h4>  List of sources </h4><br><ul><li>  Dong-Chen He, LN (1989).  Texture Unit, Texture Spectrum, And Texture Analysis.  Geoscience and Remote Sensing Symposium. </li><li>  Guoying Zhao, MP (2007).  Dynamic Texture Recognition Using Facial Expressions.  IEEE Transactions on Pattern Analysis and Machine Intelligence. </li><li>  Hongda Tian, ‚Äã‚ÄãWL (2011).  Smoke Detection Using Non-Redundant Local Binary Pattern-Based Features.  Wollongong, Australia: Advanced Multimedia Research Lab, ICT Research Institute. </li><li>  Jinwang Feng, YD (2015).  Dominant ‚Äì Completed Local Binary Pattern for Texture Classification.  Materials of International Conference on Information and Automation.  Lijiang, China. </li><li>  Junding Sun, GF (2013).  New Local Edge Binary Patterns For Image Retrieval. </li><li>  S. Liao, MW (May 2009).  Dominant Local Binary Patterns for Texture Classification.  Transactions on Image Processing, Vol 18, No 5. </li><li>  T. Ojala, MP (1994).  Discrimination based on Kullback discrimination of distributions.  Vol.  1 - Proceedings of the 12th IAPR International Conference on Computer Vision &amp; Image Processing. </li><li>  Timo Ojala, MP (July 2002).  Gray Scale and Rotation Invariant Texture Classification.  IEEE Transactions on Pattern Analysis and Machine Intelligence, 971-987. </li><li>  Xiaofeng Fu, RW (2012).  Spatiotemporal Pattern Orientational Binary Patterns for Facial Expression Recognition from Video Sequences.  International Conference on Fuzzy Systems and Knowledge Discovery. </li><li>  Xie Liping, WH (July 2014).  Facial Expression Recognition Using Histogram Sequence of Biblical Patterns from Three Orthogonal Planes.  Proceedings of the 33rd Chinese Control Conference.  Nanjing, China. </li><li>  Yiu-ming Cheung, JD (2014).  Ultra Local Binary Pattern For Image Texture Analysis.  Materials of IEEE International Conference on Security, Pattern Analysis, and Cybernetics.  Wuhan, Hibei, China. </li></ul></div><p>Source: <a href="https://habr.com/ru/post/280888/">https://habr.com/ru/post/280888/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../280878/index.html">Digital security certificate: what is it for?</a></li>
<li><a href="../280880/index.html">According to Rambler.iOS # 6</a></li>
<li><a href="../280882/index.html">Rust through its founding principles</a></li>
<li><a href="../280884/index.html">4.04</a></li>
<li><a href="../280886/index.html">GSM-traps: another hello from Big Brother</a></li>
<li><a href="../280890/index.html">Coding Dojo meeting in Artec 3D</a></li>
<li><a href="../280892/index.html">How we scored on asynchrony when hiking on backends</a></li>
<li><a href="../280894/index.html">Wi-Fi module WF121 and HTTP server in addition</a></li>
<li><a href="../280896/index.html">Personal data of 50 million Turkish citizens leaked to the network</a></li>
<li><a href="../280898/index.html">Debugging Office Add-ins on iOS (iPad)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>