<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we scored on asynchrony when hiking on backends</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Under the pressure of the emergence of new asynchronous non-blocking frameworks, it may seem that blocking calls are a relic of the past, and all new ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we scored on asynchrony when hiking on backends</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/978/8ba/a19/9788baa1984c49a6af3d6642a5553ee2.jpg" alt="threads"><br><br>  Under the pressure of the emergence of new asynchronous non-blocking frameworks, it may seem that blocking calls are a relic of the past, and all new services need to be written on a fully asynchronous architecture.  In this post, I will tell you how we decided to abandon non-blocking asynchronous calls of backends in favor of the usual blocking. <a name="habracut"></a><br><br>  In the architecture of HeadHunter there is a service that collects data from other services.  For example, to show vacancies for a search query, you need: <br><ol><li>  go to the search backend for vacancies aydis; </li><li>  go to the vacancy backend for a description of them. </li></ol><br>  This is the simplest example.  Often in this service a lot of all logic.  We even called it ‚Äúlogic‚Äù. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It was originally written in python.  For several years of the existence of logic in it has accumulated all those.  debt.  And the developers were not thrilled by the need to dig in both python and java, in which we have written most of the backends.  And we thought, why not rewrite logic to java. <br><br>  And the python logic is progressive, built on an asynchronous non-blocking tornado framework.  The question of ‚Äúblocking or not blocking when going to backends‚Äù did not even stand: because of GIL, in python there is no real parallel execution of threads, so if you want, you don‚Äôt want, and requests must be processed in one thread and not blocked when going to other services. <br><br>  But when switching to java, we decided to once again assess whether we want to continue writing the inverted callback code. <br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">search_vacancies</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(query)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">on_vacancies_ids_received</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vacancies_ids)</span></span></span><span class="hljs-function">:</span></span> get_vacancies(vacancies_ids, callback=reply_to_client) search_vacancies_ids(query, callback=on_vacancies_ids_received)</code> </pre> <br>  Of course the callback hell can be smoothed.  In java 8, for example, appeared CompletableFuture.  You can also look in the direction of Akka, Vert.x, Quasar, etc. But maybe we don‚Äôt need new levels of abstraction, and we can return to normal synchronous blocking calls? <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">search_vacancies</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(query)</span></span></span><span class="hljs-function">:</span></span> vacancies_ids = search_vacancies_ids(query) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> get_vacancies(vacancies_ids)</code> </pre><br>  In this case, we will allocate a stream for processing each request, which, when going to the backend, will be blocked until it receives the result and then continues execution.  Please note that I am talking about blocking the stream at the time of calling the remote service.  Subtracting the query and writing the result to the socket will still be performed without blocking.  That is, the stream will be allocated for the finished request, and not for the connection.  What is potentially bad blocking flow? <br><ol><li>  It will take a lot of memory, since each thread needs a stack memory. </li><li>  Everything will slow down, since switching between thread contexts is not a free operation. </li><li>  If the backends are blunt, then there will be no free threads in the pool. </li></ol><br>  We decided to estimate how many streams we will need, and then we will evaluate whether we notice these problems. <br><br><h1>  How many threads are needed? </h1><br>  The lower limit is easy to estimate. <br>  Suppose now the python logic has such logs: <br><pre> <code class="hljs pgsql"><span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">400</span></span> ms <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /vacancies <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">600</span></span> ms <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /resumes <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">01</span></span> <span class="hljs-number"><span class="hljs-number">500</span></span> ms <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /vacancies <span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">01</span></span> <span class="hljs-number"><span class="hljs-number">600</span></span> ms <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> /resumes</code> </pre><br>  The second column is the time from the request to the response.  That is, the logic processed: <br><pre> <code class="hljs css">15<span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">:04</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">:00</span></span>    <span class="hljs-selector-tag"><span class="hljs-selector-tag">-</span></span> 1000 <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> 15<span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">:04</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">:01</span></span>    <span class="hljs-selector-tag"><span class="hljs-selector-tag">-</span></span> 1100 <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span></code> </pre><br>  If we allocate a stream for processing each request, then: <br><ul><li>  at 3:04:00 pm theoretically we can do with one thread, which first processes the GET / vacancies request, and then processes the GET / resumes request; </li><li>  at 15:04:01, at least 2 streams will have to be allocated, since one stream cannot process more than a second requests in one second. </li></ul><br>  In fact, at the most stressful time on python logic, such a total query duration: <br><br><img src="https://habrastorage.org/files/491/452/747/491452747fd749a6b08931fdc79da507.png" alt="python logic requests sec / wall sec"><br><br>  More than 150 seconds of requests per second.  That is, we need more than 150 threads.  Remember this number.  But we still need to somehow take into account that requests come unevenly, the thread can be returned to the pool not immediately after processing the request, but a little later, and so on. <br><br>  Let's take another service that is blocked when going to the database, see how many threads it needs, and extrapolate the numbers.  For example, the service of invitations and feedback: <br><br><img src="https://habrastorage.org/files/81b/cca/f4e/81bccaf4ec9a46e29e0d809bd4717efd.png" alt="negotiate sec / wall sec"><br><br>  Up to 14 seconds of requests per second.  And what about the actual use of streams? <br><br><img src="https://habrastorage.org/files/e06/816/6fa/e068166faafa4649b8f29edafe3a32f2.png" alt="negotiations negotiations"><br><br>  Up to 54 simultaneously used streams, which is 2-4 times more compared to the theoretically minimal amount.  We looked at other services - there is a similar picture. <br><br>  It is appropriate to make a small digression.  In HeadHunter, jetty is used as the http server, but other http servers have a similar architecture: <br><ul><li>  each request is a task; </li><li>  this task enters the queue before the thread pool; </li><li>  if there is free flow in the pool, it takes the task from the queue and executes it; </li><li>  if there is no free stream, the task is in the queue until the free stream appears. </li></ul><br>  If we are not afraid that the request will be in the queue for some time - you can select a little more threads than the calculated minimum.  But if we want to reduce delays as much as possible, we need to allocate more flows. <br><br>  Let's select 4 times more threads. <br>  That is, if we now translate the entire python logic to java logic with a blocking architecture, then we will need 150 * 4 = 600 threads. <br>  Let's imagine that the load will increase by 2 times.  Then, if we do not rest on the CPU, we will need 1200 threads. <br>  Let's also imagine that our backends are stupid, and it takes 2 times more time to service requests, but more on that later, for as long as there are 2400 threads. <br>  Now the python logic is spinning on four servers, that is, there will be 2400/4 = 600 threads on each server. <br>  600 threads is a lot or a little? <br><br><h1>  Are hundreds of threads a lot or a little? </h1><br>  By default, on 64-bit machines, java allocates 1 MB of memory for the thread stack. <br>  That is, 600 threads will require 600 MB of memory.  Not a disaster.  In addition, it is 600 MB of virtual address space.  Physical RAM will be used only when this memory is actually required.  We almost never need 1 MB of stack, we often pinch it to 512 KB.  In this sense, neither 600 nor even 1000 flows is a problem for us. <br><br>  What about the cost of context switching between threads? <br>  Here is a simple java test: <br><ul><li>  create a pool of threads of 1, 2, 4, 8 ... 4096; </li><li>  we throw 16 384 tasks into it; </li><li>  each task is 600,000 iterations of folding random numbers; </li><li>  we are waiting for all the tasks; </li><li>  run the test 2 times to warm up; </li><li>  we run the test 5 more times and take the average time. </li></ul><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> numOfWarmUps = <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> numOfTests = <span class="hljs-number"><span class="hljs-number">5</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> numOfTasks = <span class="hljs-number"><span class="hljs-number">16_384</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> numOfIterationsPerTask = <span class="hljs-number"><span class="hljs-number">600_000</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> numOfThreads : <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[] {<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">2048</span></span>, <span class="hljs-number"><span class="hljs-number">4096</span></span>}) { System.out.println(numOfThreads + <span class="hljs-string"><span class="hljs-string">" threads."</span></span>); ExecutorService executorService = Executors.newFixedThreadPool(numOfThreads); System.out.println(<span class="hljs-string"><span class="hljs-string">"Warming up..."</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numOfWarmUps; i++) { test(executorService); } System.out.println(<span class="hljs-string"><span class="hljs-string">"Testing..."</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numOfTests; i++) { <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> start = currentTimeMillis(); test(executorService); System.out.println(currentTimeMillis() - start); } executorService.shutdown(); executorService.awaitTermination(<span class="hljs-number"><span class="hljs-number">1</span></span>, TimeUnit.SECONDS); System.out.println(); } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ExecutorService executorService)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ List&lt;Future&lt;Integer&gt;&gt; resultsFutures = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(numOfTasks); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numOfTasks; i++) { resultsFutures.add(executorService.submit(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Task())); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Future&lt;Integer&gt; resultFuture : resultsFutures) { resultFuture.get(); } } <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Task</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Callable</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Integer</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> Random random = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Random(); <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Integer </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> InterruptedException </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> sum = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; numOfIterationsPerTask; i++) { sum += random.nextInt(); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sum; } }</code> </pre><br>  Here are the results on 4-core i7-3820, HyperThreading is disabled, Ubuntu Linux 64-bit.  We expect that the best result will show a pool with four threads (by the number of cores), so we compare the remaining results with it: <br><table><tbody><tr><th>  Number of threads </th><th>  Average time, ms </th><th>  Standard deviation </th><th>  Difference% </th></tr><tr><td>  one </td><td>  109152 </td><td>  9.6 </td><td>  287.70% </td></tr><tr><td>  2 </td><td>  55072 </td><td>  35.6 </td><td>  95.61% </td></tr><tr><td>  four </td><td>  28153 </td><td>  3.8 </td><td>  0.00% </td></tr><tr><td>  eight </td><td>  28142 </td><td>  2.8 </td><td>  -0.04% </td></tr><tr><td>  sixteen </td><td>  28141 </td><td>  3.6 </td><td>  -0.04% </td></tr><tr><td>  32 </td><td>  28152 </td><td>  3.7 </td><td>  0.00% </td></tr><tr><td>  64 </td><td>  28149 </td><td>  6,6 </td><td>  -0.01% </td></tr><tr><td>  128 </td><td>  28146 </td><td>  2.3 </td><td>  -0.02% </td></tr><tr><td>  256 </td><td>  28146 </td><td>  4.1 </td><td>  -0.03% </td></tr><tr><td>  512 </td><td>  28148 </td><td>  2.7 </td><td>  -0.02% </td></tr><tr><td>  1024 </td><td>  28146 </td><td>  2.8 </td><td>  -0.03% </td></tr><tr><td>  2048 </td><td>  28157 </td><td>  5.0 </td><td>  0.01% </td></tr><tr><td>  4096 </td><td>  28160 </td><td>  3.0 </td><td>  0.02% </td></tr></tbody></table><br>  The difference between 4 and 4096 streams is comparable to the error.  So in terms of overhead from switching contexts 600 threads for us is not a problem. <br><br><h1>  And if backends blunted? </h1><br>  Imagine that we have blunted one of the backends, and now requests to it take 2, 4, 10 times more time.  This can lead to the fact that all threads will hang blocked, and we can not handle other requests that this backend is not needed.  In this case, we can do several things. <br><br>  First, keep in reserve even more threads. <br>  Secondly, set hard timeouts.  Timeouts must be monitored, this can be a problem.  Is it worth writing asynchronous code?  The question is open. <br>  Thirdly, no one forces us to write everything in a synchronous style.  For example, we can write some controllers in asynchronous style, if we expect problems with backends. <br><br>  Thus, for the service of hikes on backends under our loads, we made a choice in favor of a predominantly blocking architecture.  Yes, we need to keep track of timeouts, and we cannot quickly scale up to 100 times.  But, on the other hand, we can write simple and clear code, release business features faster and spend less time on support, which, in my opinion, is also very cool. <br><br><h4>  useful links </h4><br><ul><li>  <a href="https://www.youtube.com/watch%3Fv%3DuKc0Gx_lPsg">Heinz Kabutz.</a>  <a href="https://www.youtube.com/watch%3Fv%3DuKc0Gx_lPsg">The Multi-threading, Non Blocking IO.</a> </li><li>  <a href="https://www.youtube.com/watch%3Fv%3DgIh0X-RkftY">Andrey Pangin.</a>  <a href="https://www.youtube.com/watch%3Fv%3DgIh0X-RkftY">Features of the development of high-load server in Java.</a> </li><li>  <a href="http-server-benchmark">Benchmarking High-Concurrency HTTP Servers on the JVM.</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/280892/">https://habr.com/ru/post/280892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../280882/index.html">Rust through its founding principles</a></li>
<li><a href="../280884/index.html">4.04</a></li>
<li><a href="../280886/index.html">GSM-traps: another hello from Big Brother</a></li>
<li><a href="../280888/index.html">Overview of Local Binary Patterns (LBP) Image Descriptors and Their Variations</a></li>
<li><a href="../280890/index.html">Coding Dojo meeting in Artec 3D</a></li>
<li><a href="../280894/index.html">Wi-Fi module WF121 and HTTP server in addition</a></li>
<li><a href="../280896/index.html">Personal data of 50 million Turkish citizens leaked to the network</a></li>
<li><a href="../280898/index.html">Debugging Office Add-ins on iOS (iPad)</a></li>
<li><a href="../280900/index.html">RUVDS introduces new Huawei FusionSphere OpenStack virtualization systems</a></li>
<li><a href="../280902/index.html">Rust and Swift (third, fourth, fifth and sixth parts)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>