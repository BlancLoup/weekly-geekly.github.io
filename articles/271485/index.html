<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A way to quickly measure the performance of a random server</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the world of web development, there is often a problem of selecting a server for a web application, or, in analogy, testing the performance of an e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A way to quickly measure the performance of a random server</h1><div class="post__text post__text-html js-mediator-article">  In the world of web development, there is often a problem of selecting a server for a web application, or, in analogy, testing the performance of an existing server.  Perhaps we need to buy a new server so that it can withstand the expected load.  Maybe the customer sends us his existing server for deployment.  In any case, if after the deployment and launch of the application it will show poor performance, it will be asked from the team. <br><br>  The main problem is that you need to quickly evaluate server performance without using special (read, complicated) tools and, of course, before the release.  We must be able to remove some metrics from the server and, multiplying them by the known indicators of the application, obtain an estimate of the application's performance on this server. <br><br>  In life, not every developer can accomplish this task, and of the rest, not everyone wants to perform it. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In this article I want to talk about the techniques and tools that we use to assess server performance. <br><a name="habracut"></a><br><h4>  Typical situations </h4><br><h5>  ‚Ññ1 </h5><br>  The development team is coming to release and is soon preparing to release the first version of the product.  The next step is to deploy the application on the battle server, which, under the terms of the project, must be purchased and configured.  At the general meeting, the project manager suggests finding the person responsible for solving this ‚Äúsimple‚Äù questions: ‚ÄúSo, who will choose the hosting and server?  I will put the required amount in the budget for the next iteration. ‚Äù  As a rule, there are no applicants for this task :).  Moreover, direct delegation - ‚ÄúVasya, take care of this task!‚Äù - also does not work: Vasya instantly finds and lists at least a dozen urgent / important tasks that now hang on it and hand them in yesterday (‚Äúin general, we - not admins ").  Obeying the general feeling of self-preservation, the team coherently prompts the Project Manager where exactly to find such a specialist (no closer than in the next division), and He will select the perfect server configuration for sure. <br><br><h5>  ‚Ññ2 </h5><br>  Under the terms of the project server provides the customer.  It looks like a great condition at the start of the project, but it is not so when we come to the release.  To the client‚Äôs question ‚ÄúIs the server powerful?‚Äù There should be an invariable answer: ‚ÄúAnd then!‚Äù.  After deployment, the Project Manager looks at the timings of web application responses with sad eyes.  Unpleasant thoughts ‚ÄúWho is to blame?‚Äù And ‚ÄúWhat to do?‚Äù Appear.  There comes an understanding that the server configuration had to be selected by oneself, but, on the other hand, a specialist from the neighboring unit was not found.  In fact, it turns out that this powerful server is a cheap VPS, the parameters of which look good, but it shares the resources of the host with the army of its fellow neighbors.  The client paid for the server for five years ahead :) and is not going to change anything (it was necessary to say before). <br><br><h5>  Number 3 </h5><br>  Advanced level - the client has a server and an admin.  Server settings do not cause complaints, but after application deployment we see terrible brakes, lags, delays.  Our development server is three times weaker in parameters, but the application runs eight times faster.  None of our proposals for replacing the server or buying a new one is not accepted, since the admin has his own opinion - this is hindered by ‚Äúyour‚Äù application.  The client does not know who to believe;  he does not like the idea of ‚Äã‚Äãattracting new expenses either, so the admin's argument counts.  The Project Manager requires the team to clearly explain ‚Äúwhy the application is slowing down‚Äù and the evidence with the server‚Äôs ‚Äúfault‚Äù figures.  The team, as always, has plenty of free time, so everyone eagerly tackles the task and puts a beer to a specialist from the neighboring department for a hint ‚Äúwhere to dig‚Äù. <br><br>  We summarize what situations we face and what tasks need to be able to solve: <br><br>  - Selection of the server for the application and load <br>  - Evaluation of the capabilities of the existing server <br>  - To be able to answer the question "Why so slowly?" <br><br><h4>  Requirements for measurement tools </h4><br>  The most accurate way to measure server performance is at the same time the most obvious: you need to install the application on the server and activate the real load.  This method, although it gives an accurate result, is useless :) for several reasons: <br><br><ul><li>  We want to know the evaluation of the server in advance, before launching into production. </li><li>  The measurement method should be fast and cheap. </li><li>  The measurement tool should be easy to use and install on the server. </li><li>  The measurement result should be easily interpretable and comparable. </li></ul><br><h4>  Measurement object </h4><br>  Server purchased, operating system installed, sshd running.  Open the console and enter the server.  The black console, the green letters and the flashing heading mutely ask you: ‚ÄúWhat's next?‚Äù.  It's time to think about what we will measure and what the performance is made of. <br><br>  Up to this point, the question seemed simple: ‚ÄúI will launch a benchmark and everything will be clear.‚Äù  Now, at the sight of a flashing console cursor, the thought has stopped and can in no way give out the necessary command. <br><br>  What determines the performance of a web application to a greater degree: <br><br><ul><li>  Speed ‚Äã‚Äãof operation of a bunch of CPU + RAM </li><li>  Disk Subsystem Speed </li><li>  The performance of the language execution environment (in our case it is PHP) </li><li>  Setting up the database (we have this is MySQL or PostgreSQL) </li><li>  And, of course, from the application itself (on what resources it uses) </li></ul><br>  We need to have four tools that could measure the speed of work separately: <br><br><ul><li>  for server components: CPU + RAM and Disk subsystem </li><li>  for software components: MySQL and PHP </li></ul><br>  With the measurement results in hand, we can comprehensively talk about the performance of the server as a whole, and we can also predict the performance of the web application. <br><br><h4>  Measurement tools </h4><br><h5>  sysbench </h5><br>  <a href="https://github.com/akopytov/sysbench">github.com/akopytov/sysbench</a> <br><br>  It is impossible to describe the tool better than the author did, therefore I quote: <br><br><blockquote>  SysBench is a modular, cross-platform and multi-threaded benchmark. <br>  Do you want to make a database of database benchmarks? <br></blockquote><br>  This is what you need!  Sysbnech allows you to quickly get an idea of ‚Äã‚Äãsystem performance without installing complex benchmarks and special tools. <br><br>  Installing sysbench is simple: <br> <code>apt-get install sysbench <br></code> <br><br>  You can compile: <br> <code>$ ./autogen.sh <br></code> <br> <code>$ ./configure <br></code> <br> <code>$ make <br></code> <br><br><h5>  Check CPU performance </h5><br>  To do this, run the calculation of twenty thousand prime numbers. <br> <code>$ sysbench --test=cpu --cpu-max-prime=20000 run <br></code> <br><br>  By default, the calculation will be performed in a single thread.  Use the key --num-threads = N if we want to perform parallel computing. <br><br>  The result of the test: <br><br><pre> <code class="bash hljs"> CPU: Test execution summary: total time: 17.3915s total number of events: 10000 total time taken by event execution: 17.3875 per-request statistics: min: 1.66ms avg: 1.74ms max: 4.00ms approx. 95 percentile: 2.03ms</code> </pre><br>  The most interesting thing about this test is the total time value.  By running this test on multiple servers, we can compare the readings. <br><br>  I will give an example of running this test on those servers that I had on hand at the time of preparing the article. <br><br><img src="https://habrastorage.org/files/94b/689/c1e/94b689c1ef874f4dbc9b7de332069a2a.jpg"><br><br>  Notes: <br><br><ul><li>  G2 is about three times faster than A3 </li><li>  A simple VPS'k on regrau for 250 rubles / month is comparable to the G2 :) </li><li>  Virtual netbook based on Xeon X3440 worked the same way as NUC i5 </li><li>  Surprised by the same results on four servers </li><li>  Probably, the calculation of prime numbers takes place on the same CPU blocks, which do not reflect the overall processor performance. </li></ul><br><h5>  Testing the disk subsystem </h5><br>  Checking the disk subsystem is performed in three steps: <br><br><ul><li>  Prepare (generate) a set of test files </li><li>  Perform testing, remove indicators </li><li>  Clean up trash </li></ul><br>  Preparation of test files: <br> <code>$ sysbench --test=fileio --file-total-size=70G prepare <br></code> <br><br>  The command will create a set of files with a total size of 70 gigabytes.  The size should significantly exceed the amount of RAM, so that the test result is not affected by the operating system cache. <br><br>  Test execution: <br> <code>$ sysbench --test=fileio --file-total-size=70G --file-test-mode=rndrw --init-rng=on --max-time=300 --max-requests=0 run <br></code> <br><br>  The test will be performed in a random read mode (rndw) for 300 seconds, after which the totals will be shown.  Again, by default, testing will be performed in one thread (Number of threads: 1). <br><br>  Cleaning up temporary files: <br> <code>$ sysbench --test=fileio cleanup <br></code> <br><br>  Example test result: <br><br><pre> <code class="bash hljs"> FileIO: Operations performed: 249517 Read, 166344 Write, 532224 Other = 948085 Read 3.8073Gb Written 2.5382Gb Total transferred 6.3455Gb (21.659Mb/sec) 1386.18 Requests/sec executed Test execution summary: total time: 300.0045s total number of events: 415861 total time taken by event execution: 178.9646 per-request statistics: min: 0.00ms avg: 0.43ms max: 205.67ms approx. 95 percentile: 0.16ms Threads fairness: events (avg/stddev): 415861.0000/0.00 execution time (avg/stddev): 178.9646/0.00</code> </pre><br>  As a measure of the performance of the disk subsystem, you can use the value of the average data transfer rate (in this example it is 21.659Mb / sec). <br><br>  Let's see what this test showed on my servers: <br><br><img src="https://habrastorage.org/files/330/e4c/f34/330e4cf34eed487da01696543dc81b08.jpg" alt="image"><br><br>  Notes: <br><br><ul><li>  Suspiciously low speeds on all tested servers are striking. </li><li>  The NUC i5 has an ssd disk installed, no matter how many times I run the test, the data transfer rate has always been in the range from 1.5 to 2 Mb / sec </li><li>  On my working MacBook Pro 2015 with ssd, the speed value in this test is 140Mb / sec 8-) </li></ul><br><h5>  MySQL OLTP test </h5><br>  The test checks the execution speed of MySQL server transactions, with each transaction consisting of both read and write requests. <br><br>  It is very convenient to change the server settings in my.cnf, restart it and run a series of tests - you can immediately see how the performance changes. <br><br>  Preparation for testing: <br> <code>$ sysbench --test=oltp --oltp-table-size=1000000 --mysql-db=test --mysql-user=root --mysql-password=pass prepare <br></code> <br><br>  Run test: <br> <code>$ sysbench --test=oltp --oltp-table-size=1000000 --mysql-db=test --mysql-user=root --mysql-password=pass --max-time=60 --oltp-read-only=off --max-requests=0 --num-threads=8 run <br></code> <br><br>  The --oltp-read-only parameter can be set to the value on, then only read requests will be executed, which will allow evaluating the speed of the DBMS operation in the mode, for example, of a slave database. <br><br>  The result of the test: <br><br><pre> <code class="bash hljs">OLTP <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> statistics: queries performed: <span class="hljs-built_in"><span class="hljs-built_in">read</span></span>: 564158 write: 0 other: 80594 total: 644752 transactions: 40297 (671.57 per sec.) deadlocks: 0 (0.00 per sec.) <span class="hljs-built_in"><span class="hljs-built_in">read</span></span>/write requests: 564158 (9402.01 per sec.) other operations: 80594 (1343.14 per sec.) Test execution summary: total time: 60.0040s total number of events: 40297 total time taken by event execution: 479.8413 per-request statistics: min: 1.14ms avg: 11.91ms max: 70.93ms approx. 95 percentile: 15.54ms</code> </pre><br>  The most interesting parameter in the report is the number of transactions per second (transactions per sec). <br><br>  How this test showed itself on the servers: <br><br><img src="https://habrastorage.org/files/faa/222/cd7/faa222cd75a443d0bb6a7af53bd893c7.jpg"><br><br>  Notes: <br><br><ul><li>  MySQL configuration was the same on all servers. </li><li>  Surprised by the lack of significant differences between the servers A3 and G2 </li><li>  NUC i5 is comparable to G2 </li></ul><br><h4>  How to measure PostgreSQL performance? </h4><br>  Unfortunately, the sysbench tool has no built-in tools for testing PostgreSQL.  But this does not bother us at all, since you can use the pgbench utility. <br><br>  Additional Information: <br>  <a href="http://www.postgresql.org/docs/devel/static/pgbench.html">www.postgresql.org/docs/devel/static/pgbench.html</a> <br><br>  The default performance test script repeatedly performs the following transaction: <br><br><pre> <code class="bash hljs">BEGIN; UPDATE pgbench_accounts SET abalance = abalance + :delta WHERE aid = :aid; SELECT abalance FROM pgbench_accounts WHERE aid = :aid; UPDATE pgbench_tellers SET tbalance = tbalance + :delta WHERE tid = :tid; UPDATE pgbench_branches SET bbalance = bbalance + :delta WHERE bid = :bid; INSERT INTO pgbench_history (tid, bid, aid, delta, mtime) VALUES (:tid, :bid, :aid, :delta, CURRENT_TIMESTAMP); END;</code> </pre><br>  To create test data, execute the command: <br> <code>$ pgbench -h localhost -U test_user -i -s 100 test <br></code> <br><br>  Perform testing: <br> <code>$ pgbench -h localhost -U test_user -t 5000 -c 4 -j 4 test <br></code> <br><br>  Command keys mean that 4 clients will perform 5000 transactions in 4 threads.  As a result, 20,000 transactions will be completed. <br><br>  Result: <br><br><pre> <code class="bash hljs">starting vacuum...end. transaction <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>: TPC-B (sort of) scaling factor: 10 query mode: simple number of clients: 4 number of threads: 4 number of transactions per client: 5000 number of transactions actually processed: 20000/20000 latency average: 0.000 ms tps = 3350.950958 (including connections establishing) tps = 3357.677756 (excluding connections establishing)</code> </pre><br>  The most important thing here is tps. <br><br>  Unfortunately, there are no comparative tests on different servers :) <br><br><h4>  What about PHP performance? </h4><br>  Having played enough with sysbench and winding kilowatts of energy on the CPU of many servers, we learned quickly and very adequately assess the performance of a randomly taken server, which, in turn, allows us to give an expert forecast of the performance of a web application on this server. <br><br>  However, there are situations when sysbench showed a good result, and the php application on this server shows very poor performance indicators. <br><br>  Of course, the result is influenced by such parameters as: <br><br><ul><li>  PHP version </li><li>  Presence of accelerator </li><li>  How and what compiled PHP </li><li>  Which extensions are activated </li></ul><br>  I would very much like to have a tool that would be easy to install and, after launch, would produce a clear performance metric for the current PHP on the server.  Moreover, I wanted this tool not to be affected by the performance of the disk subsystem (or network) - we measure only the work of the PHP interpreter on the bundle Processor + Memory. <br><br>  Simple googling / thinking led to the idea that: <br><br><ul><li>  No existing tool </li><li>  Need to write your own reference algorithm (script) </li><li>  By virtue of the invariance of the algorithm, the obtained results can be compared </li></ul><br>  What was done: <a href="https://github.com/florinsky/af-php-bench">github.com/florinsky/af-php-bench</a> <br><br>  The script is compiled into a phar-archive, which makes it easier to download and run on an arbitrary server. <br><br>  The minimum PHP version to run is 5.4. <br><br>  For start: <br> <code><a href=""></a> $ wget github.com/florinsky/af-php-bench/raw/master/build/phpbm.phar <br></code> <br> <code>$ php phpbm.phar <br></code> <br><br>  The script performs ten tests, divided into three groups: <br><br><ul><li>  The first group is common operations (loops, rand, creating / deleting objects) </li><li>  The second group of tests tests string functions, implode / explode, hash calculation </li><li>  Third - work with arrays </li><li>  All measurements are performed in seconds. </li></ul><br>  Test report: <br><br><pre> <code class="bash hljs">[GENERAL] 1/10 Cycles (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">do</span></span>) ...................... 6.72s 2/10 Generate Random Numbers ..................... 3.21s 3/10 Objects ..................................... 4.82s Time: .. 14.76 [STRINGS] 4/10 Simple Strings Functions ................... 13.09s 5/10 Explode/Implode ............................ 15.90s 6/10 Long Strings ............................... 30.37s 7/10 String Hash ................................ 23.57s Time: .. 82.93 [ARRAYS] 8/10 Fill arrays ................................ 22.32s 9/10 Array Sort (Integer Keys and Values) ....... 17.17s 10/10 Array Sort (String Keys and Values) ........ 14.29s Time: .. 53.79 TOTAL TIME: . 151.47</code> </pre><br>  The script allows not only to assess the overall performance of PHP on this server (total time), but also to see what it is made of.  I repeatedly saw that the mediocre overall result was formed only because of one test: somewhere it could be the slow work of a random number generator, and somewhere it was work with long strings. <br><br>  On the results page (https://github.com/florinsky/af-php-bench/blob/master/RESULTS.md) I wrote down the reports I received and grouped them into a general table.  Sometimes the results are surprising :) <br><br><h4>  Conclusion </h4><br>  I would like to add that the above tools allow us to evaluate server performance only right now, at the time of measurement.  It is necessary to understand that the processes running in parallel can influence the operation of the server.  And if the measurement showed you a good result, it does not mean that he will always be like that. <br><br>  This problem is especially acute if you analyze the server of a client that is already being used ‚Äúto its fullest‚Äù.  You do not know what cron-tasks are being performed, what processes are dormant and are waiting for their event to enable a long gzip / tar, the antivirus / spam filter and a dozen virtual machines still work here, in which the mysterious happens. <br><br>  Atop and iostat help us to analyze the server behavior in time.  We collect statistics for several days (or more), after which you can view it. <br><br><h5>  atop </h5><br>  Write data to file: <br> <code>$ atop -w /tmp/atop.raw 1 60 <br></code> <br><br>  Read entry: <br> <code>atop -r /tmp/atop.raw <br></code> <br><br><h5>  iostat </h5><br>  CPU Load Measurement: <br> <code>$ iostat -c 1 <br></code> <br><br>  Conclusion: <br><br><pre> <code class="bash hljs">%user %nice %system %iowait %steal %idle 82.21 0.00 17.79 0.00 0.00 0.00 79.05 0.00 20.70 0.00 0.00 0.25 80.95 0.00 19.05 0.00 0.00 0.00 80.95 0.00 19.05 0.00 0.00 0.00 80.85 0.00 18.91 0.25 0.00 0.00 ...</code> </pre><br>  Measurement of the disk subsystem load: <br> <code>$ iostat -xd /dev/sda 1 <br></code> <br><br>  Conclusion: <br><br><pre> <code class="bash hljs">rkB/s wkB/s await r_await w_await svctm %util 0.00 2060.00 4.05 0.00 4.05 3.98 95.60 0.00 2000.00 3.97 0.00 3.97 3.95 96.40 0.00 1976.00 3.92 0.00 3.92 3.92 95.60 0.00 2008.00 3.95 0.00 3.95 3.93 96.00 0.00 2008.00 3.92 0.00 3.92 3.92 96.80 0.00 2020.00 4.03 0.00 4.03 4.00 97.60 0.00 2016.00 3.97 0.00 3.97 3.97 97.20 ...</code> </pre><br>  And, of course, you can use Munin and his ilk to collect statistics from the server in a long chronological order. <br><br>  Thanks for attention! </div><p>Source: <a href="https://habr.com/ru/post/271485/">https://habr.com/ru/post/271485/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../271475/index.html">Parallel parsing of a large number of HTML pages using Apache Ignite (GridGain) in 200 lines of code</a></li>
<li><a href="../271477/index.html">Cooking ASP.NET 5: Continuous Deployment with Docker and Tutum</a></li>
<li><a href="../271479/index.html">Rabdological abacus Claude Perrot</a></li>
<li><a href="../271481/index.html">Domestic server manufacturer = self-assembly?</a></li>
<li><a href="../271483/index.html">C #, ways to store program settings</a></li>
<li><a href="../271487/index.html">Under the hood Redis: Strings</a></li>
<li><a href="../271489/index.html">How do we live a year without sprockets and with react</a></li>
<li><a href="../271491/index.html">Free Webinars at Startup Week - Connect</a></li>
<li><a href="../271493/index.html">Infrastructure and trading robots: What programming languages ‚Äã‚Äãare used in finance</a></li>
<li><a href="../271495/index.html">The tester is responsible for everything</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>