<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Paparazzo. Powerful, stylish, your own. Part I</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Not so long ago, we were faced with the task of dramatically reworking the process of submitting an ad through the Avito mobile app for iOS. The resul...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Paparazzo. Powerful, stylish, your own. Part I</h1><div class="post__text post__text-html js-mediator-article"> <a href="https://habrahabr.ru/company/avito/blog/326774/"><img src="https://habrastorage.org/getpro/habr/post_images/044/928/8d4/0449288d4aed2d1776f39b5d3620785f.png"></a> <br><br>  Not so long ago, we were faced with the task of dramatically reworking the process of submitting an ad through the Avito mobile app for iOS.  The result should have been a tool that would make this process quick and easy for the user.  Obviously, the buyer prefers to see what he is going to pay for.  Therefore, to give the seller the ability to easily add and edit photos was one of our top priorities.  How we have achieved the desired, read under the cut. <br><a name="habracut"></a><br>  Looking a little further, our media picker is called Paparazzo and we have already posted it <a href="https://github.com/avito-tech/Paparazzo">on Github</a> .  In this part we will reveal the technical details of how we capture the image from the camera and output it to several UIViews at the same time. <br><br><h2>  UIImagePickerController and open source </h2><br>  The simplest standard way to implement a camera is, of course, the UIImagePickerController.  This is a very limited functionality component, which imposes certain restrictions when using it: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/d5e/a13/feb/d5ea13feba7f191b787c1e013f75d587.png" width="360"><img src="https://habrastorage.org/getpro/habr/post_images/08f/60a/c34/08f60ac347f8ce6b9faa98e2b1325130.png" width="360"><br><br><ul><li>  It can work either in camera mode or in gallery mode, and we needed a hybrid of these two modes. <br><br></li><li>  It must be shown modally, because it is a UINavigationController, which cannot be run in another UINavigationController, and our camera must be one of the steps in a linear sequence of screens. <br><br></li><li>  As a result, the UIImagePickerController returns a UIImage.  UIImage is an uncompressed image representation that is stored in memory and takes up a lot of space.  Working with UIImagePickerController in my previous projects, I came across the fact that on weak devices like the iPhone 4, and even sometimes on the iPhone 5, the application crashed due to lack of memory even before the delegate method that directly returns the image to the client code was called .  We also had to avoid the irrational use of RAM in order to eliminate such problems. <br></li></ul><br>  We also looked at some of the off-the-shelf solutions available in open source, but they all didn‚Äôt meet our requirements.  In some, there were no necessary features, like cropping or turning a photo, in some there was a choice of only one photo, there was no ribbon with the selected photos.  In general, the user flow that was implemented in these components did not suit us.  Therefore, we decided to write a camera from scratch, which would guarantee us the possibility of its quick revision as needed. <br><br><h2>  AVFoundation </h2><br>  Another way to implement the camera is to use a low-level AVFoundation framework.  It allows you to get the most out of the recording and playback capabilities of photos, videos and audio that iOS provides. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c8/472/061/8c8472061a1dc79cf7bfb0ebd7462f97.png"><br><br>  The central object in AVFoundation is the AVCaptureSession, which coordinates the flow of data from capture devices to consumers.  But before using it, you need to decide where the record will be made from. <br><br>  Recording sources are represented by AVCaptureDeviceInput objects, and are taken from AVCaptureDevice representing physical devices, such as a front-facing camera, a rear-facing camera, and a microphone.  Just as we say where to record, we also have to tell where to send it then. <br><br>  To do this, on the other side of the AVCaptureSession is one or more AVCaptureOutput.  Examples of output can be AVCaptureStillImageOutput (for photos) and AVCaptureMovieFileOutput (for video).  Each output can receive information from one or several sources (for example, AVCaptureMovieFileOutput can receive both video from a camera and audio from a microphone). <br><br>  The connections between inputs and outputs are set using one or more AVCaptureConnection objects, and if we, for example, need to record video without sound, we can not establish a connection between AVCaptureMovieFileOutput and the microphone input. <br><br>  Configuring AVCaptureSession is pretty simple.  First you need to get a list of devices that support video capture.  Next, look for the rear camera, checking the value of the position parameter for each of the devices found.  Finally, we initialize AVCaptureDeviceInput, passing the camera object as a parameter. <br><br><pre><code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> videoDevices = <span class="hljs-type"><span class="hljs-type">AVCaptureDevice</span></span>.devices(withMediaType: <span class="hljs-type"><span class="hljs-type">AVMediaTypeVideo</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> backCamera = videoDevices?.first { $<span class="hljs-number"><span class="hljs-number">0</span></span>.position == .back } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> input = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> <span class="hljs-type"><span class="hljs-type">AVCaptureDeviceInput</span></span>(device: backCamera)</code> </pre> <br>  Creating output is even simpler: just create an AVCaptureStillImageOutput and set the codec to be used for the capture. <br><br><pre> <code class="hljs objectivec">let output = <span class="hljs-built_in"><span class="hljs-built_in">AVCaptureStillImageOutput</span></span>() output.outputSettings = [<span class="hljs-built_in"><span class="hljs-built_in">AVVideoCodecKey</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">AVVideoCodecJPEG</span></span>]</code> </pre> <br>  Now that we have input and output, we are ready to create an AVCaptureSession. <br><br><pre> <code class="hljs lua">let captureSession = AVCaptureSession() captureSession.sessionPreset = AVCaptureSessionPresetPhoto <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> captureSession.canAddInput(<span class="hljs-built_in"><span class="hljs-built_in">input</span></span>) { captureSession.addInput(<span class="hljs-built_in"><span class="hljs-built_in">input</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> captureSession.canAddOutput(<span class="hljs-built_in"><span class="hljs-built_in">output</span></span>) { captureSession.addOutput(<span class="hljs-built_in"><span class="hljs-built_in">output</span></span>) } captureSession.startRunning()</code> </pre> <br><br>  The sessionPreset property allows you to set the quality, bit rate and other parameters of the output.  There are 14 ready-made presets, which, as a rule, are sufficient for solving typical tasks.  In case they do not give the desired result, there are also specific properties that are set on the AVCaptureDevice instance that represents the physical capture device itself. <br><br>  Before adding inputs and outputs to a session, it is necessary to check the possibility of such an operation with the methods canAddInput and canAddOutput, respectively, otherwise you can run into a crash. <br><br>  After that, you can tell the <code>startRunning()</code> session to start the transfer of data from inputs to outputs.  And there is an important nuance - <code>startRunning()</code> is a blocking call, and its execution can take some time, so it is recommended to set up the session in the background in order not to block the main thread. <br><br>  AVFapation also includes the AVCaptureVideoPreviewLayer class.  This is CALayer‚Äôs successor, which allows you to effortlessly display a preview of the record, initializing it with an AVCaptureSession instance.  We just put this layer in the right place, and everything works automatically.  It would seem that could go wrong?  However, everything is not as cloudless as it seems at first glance. <br><br><h2>  Display camera preview </h2><br>  As you can see, in the lower right corner of the screen, in addition to the icons of the selected photos, there is another one - with a live preview of the camera, which duplicates the main preview.  In the original version of its design was not.  When it appeared as a result of finalizing the layouts, we thought - well, this is easy, we just add another AVCaptureVideoPreviewLayer and associate it with the existing AVCaptureSession.  But we were disappointed.  Because one AVCaptureSession can output only one AVCaptureVideoPreviewLayer. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yc8aBp67rHo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Another thought immediately arose: we will create two sessions, and each of them will output to its own AVCaptureVideoPreviewLayer.  But that doesn't work either.  As soon as the second session starts, the first one automatically stops. <br><br>  In the course of further search, it turned out that there was a solution.  In addition to CaptureStillImageOutput, which was present to our CaptureSession initially, we need to add a new output of type AVCaptureVideoDataOutput. <br><br><img src="https://habrastorage.org/files/831/4ce/093/8314ce09310f4182a76c1bf646c5408f.png"><br><br>  This output has a delegate, and the delegate has a method that allows us to get every frame from the camera, giving you the opportunity to do anything you want with it, including drawing it yourself. <br><br>  The result is given in the form of CMSampleBuffer.  The data represented by this object can be effectively drawn by the graphics processor using OpenGL, as well as a low-level framework from Apple itself - Metal, which was introduced relatively recently.  According to Apple, <a href="https://clearbridgemobile.com/will-apples-metal-framework-fully-replace-opengl-for-ios-development/">Metal can be 10 times</a> faster than OpenGL ES, but it works only from iPhone 5s and up.  Therefore, we stopped at OpenGL. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/88f/8c4/b16/88f8c4b16fbc3707513767f8ee2d1f27.png"><br><br>  As I said, for self-rendering of frames received from the camera, you need to implement the AVCaptureVideoDataOutputSampleBufferDelegate protocol, namely, its captureOutput method (_: didOutputSampleBuffer: from :). <br><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">captureOutput</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params">: AVCaptureOutput?, didOutputSampleBuffer sampleBuffer: CMSampleBuffer?, from </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params">: AVCaptureConnection?)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageBuffer: <span class="hljs-type"><span class="hljs-type">CVImageBuffer?</span></span> = sampleBuffer.flatMap { <span class="hljs-type"><span class="hljs-type">CMSampleBufferGetImageBuffer</span></span>($<span class="hljs-number"><span class="hljs-number">0</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageBuffer = imageBuffer, !isInBackground { views.forEach { $<span class="hljs-number"><span class="hljs-number">0</span></span>.imageBuffer = imageBuffer } } }</code> </pre> <br>  Then you will see that Core Image will undertake all the hard work of drawing frames, but Core Image does not know how to work directly with CMSampleBuffer, but it does work with CVImageBuffer, and here we are converting one object to another. <br><br>  Please note that at this stage we are checking the isInBackground flag.  OpenGL calls cannot be made when the application is in the background, otherwise the system will immediately unload it from memory.  I will tell you how to avoid this in a minute, but for now just remember that this flag is there. <br><br>  Further in the cycle we go through all the views in which the preview will be displayed, and pass on the resulting imageBuffer.  These views are instances of our own GLKViewSubclass class. <br><br>  This class, as you probably guessed from its name, is a successor of GLKView.  Like any other GLKView, this view is initialized by the OpenGL ES context.  What distinguishes it from others is the presence of the Core Image context, which will perform the entire heavy lifting on drawing the contents of the image buffer. <br><br>  With the exception of a few irrelevant details, the full implementation of the draw (_ :) method is shown here. <br><br><pre> <code class="hljs haskell">// <span class="hljs-keyword"><span class="hljs-keyword">instance</span></span> vars: <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> eaglContext = <span class="hljs-type"><span class="hljs-type">EAGLContext</span></span>(api: .openGLES2) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> ciContext = <span class="hljs-type"><span class="hljs-type">CIContext</span></span>(eaglContext: eaglContext) var imageBuffer: <span class="hljs-type"><span class="hljs-type">CVImageBuffer</span></span>? // draw(_:) implementation: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageBuffer = imageBuffer { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> image = <span class="hljs-type"><span class="hljs-type">CIImage</span></span>(cvPixelBuffer: imageBuffer) ciContext.draw( image, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span>: drawableBounds(for: rect), from: sourceRect(<span class="hljs-keyword"><span class="hljs-keyword">of</span></span>: image, targeting: rect) ) }</code> </pre> <br>  The drawableBounds method simply converts the CGRect specified in points to a pixel CGRect, since Core Image deals with pixels and does not know whether we have a screen - retina or not. <br><br>  The sourceRect method returns a rectangle corresponding to a fragment of the displayed frame that will fit in our view, taking into account the ratio of its sides.  That is, if the frame has a 3: 4 format, and our twist is square, then this method will return the frame corresponding to its central part. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ef/adb/a77/9efadba77398026a0ebb82ae63a8b4af.png"><br><br>  As I said, OpenGL calls cannot be made when the application is in the background.  And in order to control this, you need to handle the ApplicationWillResignActive and ApplicationDidBecomeActive events. <br><br><pre> <code class="hljs smalltalk">// <span class="hljs-type"><span class="hljs-type">UIApplicationWillResignActive</span></span> func handleAppWillResignActive(_: <span class="hljs-type"><span class="hljs-type">NSNotification</span></span>) { captureOutputDelegateBackgroundQueue.sync { glFinish() <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.isInBackground = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span> } } // <span class="hljs-type"><span class="hljs-type">UIApplicationDidBecomeActive</span></span> func handleAppDidBecomeActive(_: <span class="hljs-type"><span class="hljs-type">NSNotification</span></span>) { captureOutputDelegateBackgroundQueue.async { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.isInBackground = <span class="hljs-keyword"><span class="hljs-keyword">false</span></span> } }</code> </pre> <br>  Both of these notifications are sent in the main thread, but the AVCaptureSession delegate messages are delivered in the background thread.  To ensure that after exiting the first handler, no drawing will definitely occur, you need to synchronously switch to the delegate's queue, call glFinish (), and set the isInBackground flag, which the output delegate checks before drawing each frame. <br><br>  The second event must also be processed in the delegate's thread, but this can already be done asynchronously, because the delay in this case is not critical and will not lead to unpleasant consequences. <br><br>  So, to summarize all of the above, the general scheme of implementation is as follows: CaptureSession transfers the frame from the camera to the VideoDataOutput, it forwards it to its delegate, and the delegate, in turn, sends the data to the desired views if the application has not gone into the background, after which the views themselves perform frame rendering. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3bf/0e8/ee2/3bf0e8ee2b751e3a6a139518c2f44b60.png"><br><br>  On this our problems with the conclusion of the preview camera ended. <br><br>  So, in the first part, we discussed in detail the use of AVFoundation for capturing an image from a camera, as well as for outputting it to several UIViews simultaneously.  In the second part, we will talk about abstraction, which was done to work equally with photos from different sources, from disk, from photo galleries and from the network. <br><br>  Useful links: <br><br><ul><li>  <a href="https://github.com/avito-tech/Paparazzo">Paparazzo on github</a> <br></li><li>  <a href="https://youtu.be/4x6O0hepp2g">Record of the report</a> Media Picker - to infinity and beyond (CocoaHeads Russia 03/01/2017) <br></li></ul></div><p>Source: <a href="https://habr.com/ru/post/326774/">https://habr.com/ru/post/326774/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../326762/index.html">‚ÄúBig Data is clear and simple‚Äù - an interview with the project manager for big data in QIWI Sergey Chekansky</a></li>
<li><a href="../326764/index.html">GoTo MeetUp: Security by Default</a></li>
<li><a href="../326766/index.html">Bitcoinophobia of St. Petersburg ships with blocking without victims</a></li>
<li><a href="../326768/index.html">Instantly determine your IQ and temperament</a></li>
<li><a href="../326772/index.html">Cheating time: about testing with ‚Äúdummy‚Äù time on Linux and Docker</a></li>
<li><a href="../326776/index.html">Logo for 24 hours. Cheap and tasteful?</a></li>
<li><a href="../326778/index.html">Four years to Djinn, anonymous job search service</a></li>
<li><a href="../326780/index.html">SAP BUILD - user interface building tool</a></li>
<li><a href="../326782/index.html">Creating a Tinkoff Design System. The first steps</a></li>
<li><a href="../326784/index.html">What famous companies use Docker in production and for what?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>