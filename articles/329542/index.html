<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using statistics in PostgreSQL to optimize performance - Alexey Ermakov</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Friends, we continue to publish transcriptions of the most interesting technical reports of past PG Day Russia conferences. Today, your attention is i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using statistics in PostgreSQL to optimize performance - Alexey Ermakov</h1><div class="post__text post__text-html js-mediator-article"> <i>Friends, we continue to publish transcriptions of the most interesting technical reports of past PG Day Russia conferences.</i>  <i>Today, your attention is invited to the <a href="https://pgday.ru/ru/2015/papers/17">report of</a> <b>Alexei Yermakov</b> , a specialist of Data Egret, dedicated to the device and the functioning of the scheduler.</i> <br><br><img src="https://habrastorage.org/web/a5e/553/a01/a5e553a01681493d95bccb95866a3c89.jpg"><br><br>  The statistical information collected by PostgreSQL has a big impact on system performance.  Knowing the statistics of data distribution, the optimizer can correctly estimate the number of rows, the required memory size, and select the fastest query execution plan.  But in some rare cases, he may be wrong, and then DBA intervention is required. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In addition to information about the distribution of data, PostgreSQL also collects statistics on accessing tables and indexes, function calls, and even calls to individual queries (using the pg_stat_statements extension).  This information, unlike distributions, is more needed by administrators than for the operation of the base itself, and it helps a lot to find and fix bottlenecks in the system. <br><br>  The report will show how statistical information is collected, why it is important, and how to read and use it correctly;  which parameters can be ‚Äútweaked‚Äù in certain cases, how to choose the optimal index and how to rewrite the query in order to correct the errors of the scheduler. <br><a name="habracut"></a><br>  The report consists of two parts: <br><br><img src="https://habrastorage.org/web/7f9/3d4/fc2/7f93d4fc20864567b09842c7ee782348.jpg"><br><br>  The first part is very theoretical.  Let's see how the scheduler works, how statistics are collected and why, let us recall a little bit the theory of probability. <br><br>  The second part will be more practical: why the scheduler sometimes mows down, which rakes and how they can be bypassed, and in the end there will be monitoring (how to understand that we have some problems with the base and what they are for). <br><br><img src="https://habrastorage.org/web/0e4/ca6/310/0e4ca631023a4668b991002059095055.jpg"><br><br>  How is the query in PostgreSQL?  First, the application establishes a connection with PostgreSQL, sends the request body directly using the <b>connection pool</b> (pgbouncer, etc.).  Further this request is parsed to tokens and broken into pieces.  The tree is built, transferred to the rewrite system, and then the most interesting part is the <b>planner / optimizer</b> .  In this place, we generate a query plan. <br><br>  The scheduler can perform the same query in a bunch of different ways, and the more tables we have, the more ways we will get, this dependence grows as a factorial.  Five tables - this is, let's say, some kind of constant 120, <i>10!</i>  - it will be a very large number.  That is, we have a lot of plans, if we have a lot of tables, so you shouldn‚Äôt do queries with 20 join-s that a person cannot read normally, and the scheduler will be stupid at this point, and not will be able to choose the most optimal plan. <br><br>  So, we got the plan, then we send it to the executor, which the plan executes step by step and then generates the result to the client. <br><br><img src="https://habrastorage.org/web/ec5/d94/814/ec5d94814e7545089e9056b7dda3a3fb.jpg"><br><br>  Many execution plans are generated.  For each such elementary operation (reading data from a table, sorting, combining results), the number of rows and the execution time in abstract parrots are estimated. <br><br><img src="https://habrastorage.org/web/962/83f/e41/96283fe41adc47159a4f78b1b0dafc43.jpg"><br><br>  Create a test case.  Suppose we have an abstract news site, on this site we have news and each news has a category, a numerical rating, and a content field with text. <br><br><img src="https://habrastorage.org/web/c30/eb9/2c2/c30eb92c2e6447af8ec9539cf5399977.jpg"><br><br>  Let's see what happened: the <b>\ d</b> command shows information about the object in <b>psql</b> .  We see a lot of interesting things: what indexes, what fields, what attributes, in general, all that was expected. <br><br><img src="https://habrastorage.org/web/16e/b7f/908/16eb7f908637484fa6d6b83a6c4149bc.jpg"><br><br>  Now fill this table with test data.  The id category field will be numbers from 0 to 99 that occur with the same probability.  The content field will be the word "hello world", and at the end we will add the numeric indicator id to it.  And our rating will be a normal distribution with a mathematical expectation of 50 and a standard deviation of 10. We will generate 10,000 such records. <br><br><img src="https://habrastorage.org/web/cd0/daf/3df/cd0daf3dffc4400ebd3eba6a881cdd19.jpg"><br><br>  That's what happened.  Rating is a number about 50, category_id is integers and content field. <br><br><img src="https://habrastorage.org/web/705/e7e/415/705e7e41549847a893f6bfdea1e5dd77.jpg"><br><br>  Let's see the <b>COUNT</b> query execution plan.  Obviously, sequence scan, sequential reads.  What interests us is the number of lines (10,000).  How did the scheduler know that we have 10,000 lines?  Just created a table, filled it, and the scheduler already knows. <br><br><img src="https://habrastorage.org/web/49e/290/47a/49e29047a9534f308f598ca627a7cc61.jpg"><br><br>  There is a system table <b>pg_class</b> , which stores information about each table.  It has two such advantageous fields: <b>reltuples</b> (the number of rows in this table) and <b>relpages</b> (the number of pages this table occupies).  These numbers are not relevant, they are recorded in three cases: <br><br><ul><li>  the auto-vacuum process went through the table, read the table and updated the fields; </li><li>  the auto-analyze process went through the table, read all or part of the table and updated the same fields; </li><li>  we have created an index or have performed some other DDL operation on the table, in this case, all these fields can also be updated. </li></ul><br>  It seems to be good that we have some meanings, but they may not be relevant.  What to do in this case?  We would like to have actual values.  The scheduler in the application cannot quickly calculate the number of rows in a table (because it needs to read them all), but it can quickly count the number of pages that this table occupies.  And, assuming that the number of lines on the page almost did not change after <b>auto-vacuum</b> or <b>analyze</b> , with the help of this proportion you can estimate the number of lines quite accurately.  Why 10,000?  After I recorded the data, the <b>auto-analyze</b> process went through (you can see this in the <b>pg_stat_user_tables</b> table, it keeps all sorts of monitoring counters). <br><br><img src="https://habrastorage.org/web/046/ce2/f47/046ce2f47bae4d768f454f5fa13fbff0.jpg"><br><br>  Why did the auto-analyze process start at all, and what does it do?  It is launched if the sum of the inserted, updated and deleted lines exceeds a certain threshold value.  <b>The threshold value is</b> calculated based on two parameters: <br><br><ul><li>  fixed constant, which is set in the config or for a specific table via <b>ALTER TABLE</b> ( <i>autovacuum_analyze_threshold</i> , fixed part, it is 50 by default); </li><li>  <b>autovacuum_analyze_scale_factor</b> parameter: the proportion of rows in the table that, if changed, will start the analyze (by default, this is 0.1 or 10%). </li></ul><br>  10 percent is pretty good, but sometimes it's worth reducing it a little, in some difficult cases.  For example, the table in which we store the queue: there are now 5 records in it, and a minute later it is already a million, then it is desirable to update the statistics more often. <br><br>  Another parameter that auto-analyze has is <b>default_statistics_target</b> .  It indicates how many pages and lines we take from the table, and also affects a number of other parameters, which will be discussed later.  By default, this parameter is 100. What does auto-analyze do?  He reads 300 * stats_target pages, and from these pages he selects 300 * stats_target lines.  In total, by default, it will read 30,000 rows from a table and, based on this data, populate the pg_statistic table. <br><br><img src="https://habrastorage.org/web/e2e/0cc/52f/e2e0cc52f37a4dd28743fb86f62ea09c.jpg"><br><br>  This table is not very convenient to read, so we came up with <b>view pg_stats</b> , which contains the same, but in a more readable format.  What do we have here?  One line of this view represents information about one field in the table.  There is a field tablename, attname (table name, field name), and then the most interesting begins: <br><ul><li>  <b>null_frac</b> tells us how the percentage of rows for this table is null; </li><li>  <b>avg_width</b> - the average length of the field in the table (for fields of fixed length, this field will not tell us anything); </li><li>  <b>n_distinct</b> shows how many different values ‚Äã‚Äãare in this field; </li><li>  The <b>most_common_vals</b> and <b>most_common_freqs arrays</b> contain the most common field values ‚Äã‚Äãand their corresponding frequencies; </li><li>  <b>histogram_bounds</b> is an array of intervals, and the probability of falling into each interval is approximately the same. </li></ul><br><img src="https://habrastorage.org/web/60e/4ce/79d/60e4ce79d221451486fcbb7f4a78227f.jpg"><br><br>  We created tables, let's see what was written after <b>analyze</b> for the ID field.  We see that <i>null_frac</i> is zero, i.e.  all values ‚Äã‚Äãin the table are NOT NULL, because this is the primary key, and it is always NOT NULL.  The average length is 4 (integer), <i>n_distinct</i> is -1.  Why is -1, not ten thousand? <br><br>  <i>n_distinct</i> can be either greater than zero or less than zero.  If it is greater than zero, it shows the number of different values, and if less than zero, it shows a fraction of the number of lines that will take different values.  That is, suppose if it were -0.5, then this would mean that half of the lines we have contain a unique value, and the second half contains their duplicates.  In this case, it is -1, that is, all values ‚Äã‚Äãare different. <br><br>  In this case, the <b>most_common_vals</b> and <b>most_common_freqs fields</b> are empty, because all of the values ‚Äã‚Äãwe meet with the same probability, and there is no such that they are more common than others.  And histogram_bounds contains 100 intervals.  <i>most_common_vals</i> , <i>most_common_freqs</i> and <i>histogram_bounds</i> are set by the parameter <i>default_statistics_target</i> .  In this case, it is 100 intervals and 100 different values ‚Äã‚Äãcan be stored maximum. <br><br>  The last field is a <b>correlation</b> .  This is a statistical term indicating whether there is a linear relationship between two random variables.  In this case, there is a correlation between the value of the field and its physical position on the disk.  This parameter can take values ‚Äã‚Äãfrom -1 to 1. Take an example.  The correlation between random variables as a person's height and weight, what will it be?  Most likely, it will be more than zero.  This shows that with increasing growth in our country, most likely the weight will also grow.  Of course, not a fact, but it can be.  If it were less than zero, then you would have an inverse relationship - with increasing growth, your weight would decrease.  And if it were zero, it would mean that these things are most likely independent, that is, with any increase there can be any weight. <br><br><img src="https://habrastorage.org/web/e2f/a81/04d/e2fa8104dc8c44acb67c28483c2eefd3.jpg"><br><br>  How is the <b>selectivity of</b> different conditions calculated?  The query <b>SELECT COUNT (*)</b> , where ID &lt;250. The Index Only Scan plan is selected, and we see that 250 rows are extracted.  Why 250?  Since we have no values ‚Äã‚Äãin the <i>most_common_vals</i> and <i>most_common_freqs</i> array that are more common than others, the scheduler takes information from <i>histogram_bounds</i> .  Once again, the probability of getting into each interval is about the same.  By this criterion, he was created.  The scheduler looks at how many intervals fall under this condition.  Under it gets the first interval (from 1 to 100), the second interval (from 100 to 200) and half of the third.  That is two and a half intervals.  And in total there are 100 such intervals, and, thus, dividing 2.5 by 100, we get a selectivity of 2.5%.  This is the percentage of lines that satisfy this condition.  The number 100 is obtained as selectivity multiplied by cardinality.  <b>Cardinality</b> is the total number of lines, I have already said how it counts.  We get 2.5% of 10 thousand, that is 250 lines. <br><br><img src="https://habrastorage.org/web/7ac/e89/016/7ace89016ed748dbbda01f2303b25665.jpg"><br><br>  Now such an example.  The CategoryID field: for it <i>n_distinct</i> is 100, that is, in this field we recorded numbers from zero to 99, which are evenly distributed.  Here we see that <i>histogram_bounds is</i> empty, but the <i>most_common_vals</i> and <i>most_common_freqs</i> arrays are completely filled.  The numbers in them are sorted by frequency, that is, the most popular value in this table is 98, which occurs in 1.21% of cases.  The correlation here is at level 0, that is, all the data here are evenly mixed on the disk, there is no such that 1 is stored at the beginning of the table, and 99 is at the end of the table.  We have a total of 100 values, and our <i>default_statistics_target</i> is also 100, so all the values ‚Äã‚Äãwe have fit here.  If it didn‚Äôt fit, which will be in the following example, it will be different there. <br><br><img src="https://habrastorage.org/web/01e/116/252/01e1162523a44c68af92194c6b882478.jpg"><br><br>  How, in this case, is the <b>selectivity</b> calculated for the condition CategoryID = 98?  Just given the value of the <i>most_common_vals</i> .  If we have such a value, then we simply take the corresponding frequency and consider it to be equal to <i>selectivity</i> .  In this case, we have 121 lines selected. <br><br><img src="https://habrastorage.org/web/6e4/e80/075/6e4e800754834332b09514d5b6e2027b.jpg"><br><br>  Now let's try changing the <b>default_statistics_target</b> for this field.  We put it 10, although by default we had 100. Let's <b>analyze</b> .  The <b>\ d +</b> command also shows, among other things, the <b>stats_target</b> value, if we changed it.  That's what we did. <br><br><img src="https://habrastorage.org/web/5ea/a59/d55/5eaa59d55c5946eba9046b7bcb930eac.jpg"><br><br>  Now we have the <i>most_common_vals</i> and <i>most_common_freqs are</i> empty, but now we have the <i>histogram_bounds</i> field.  How is selectivity calculated in this case? <br><br><img src="https://habrastorage.org/web/0a2/60e/e9e/0a260ee9eae44c3cba8249c34c135e0b.jpg"><br><br>  According to this formula.  That is, we can have either <i>null</i> or <i>most_common_vals</i> or <i>histogram_bounds</i> .  In the numerator there is a probability that the value will be <i>histogram_bounds</i> , and in the denominator we have a number of different values, except for those already in <i>most_common_vals</i> .  <i>sumcommon</i> is the sum of all values ‚Äã‚Äãfrom the <i>most_common_freqs</i> array.  This is not an obvious formula, but if you look at it, it‚Äôs clear why this works that way.  Different values ‚Äã‚Äãare distributed evenly across the <b>histogram_bounds</b> array.  Although we get a selectivity of 1%, and this is a different estimate, in a hundred lines instead of 121. But 100 or 121 - in this case, this is not a problem, even if we have a half-order value, this is a good estimate. <br><br><img src="https://habrastorage.org/web/a8c/5e6/660/a8c5e666009047e9a2c8abf4676c980b.jpg"><br><br>  Now let's see when we have two conditions: <i>CategoryID = 98</i> and <i>id &lt;250</i> , that is, we combine two conditions.  Selectivity is considered here as a product of selectivity, that is, according to a formula from probability theory: the probability that two events occur at the same time is equal to the probability that the first event will occur, multiplied by the probability that the second event will occur.  This definition of statistical dependence, that is, it is assumed that these columns do not depend on each other.  In this case, it is that they are independent of each other.  It turns out a fair estimate, 2.5 lines.  We discard the fractional part and get 2 lines.  But realistically, 2.5 lines is also a good estimate. <br><br><img src="https://habrastorage.org/web/db4/488/e4a/db4488e4a06f4e8f9a510791c4f24727.jpg"><br><br>  As a demonstration, let's see how the uneven distribution in the <b>rating</b> field looks.  <i>Both most_common_vals</i> , and <i>most_common_freqs</i> , and even a histogram are filled in <i>here</i> .  This should be enough to understand that the data here is uneven.  Why is that?  If they were evenly distributed, then the probability for each value would be one 1/72, that is, about 1%.  We see that there are values ‚Äã‚Äãwith a probability of about 4%.  Noticeably uneven distribution. <br><br><img src="https://habrastorage.org/web/055/afd/a34/055afda348254260880494b0cea32841.jpg"><br><br>  In addition to collecting information about the distribution of individual fields, information about the distribution of functional index values ‚Äã‚Äãis also collected.  This is not documented, there is no such information anywhere, access to this information is also not very convenient.  If instead of <b>tablename</b> we put the name of the functional index, we get information about what is stored in it. <br><br>  Suppose you create an index that stores the value of a <b>rating</b> in a square.  Of course, there is no benefit from this, just as a demonstration to understand.  If we compare this with the previous one, we will see that the value is simply squared.  That is, if it was 50, then it became 2500. And <i>histogram_bounds</i> , respectively, will also be squared. <br><br>  There is still such an undocumented thing, how to change <i>statistics_target</i> for a functional index: <i>ALTER INDEX ALTER COLUMN ... set statistics</i> - for some reason this is also not in the ALTER INDEX documentation. <br><br><img src="https://habrastorage.org/web/bcc/321/74a/bcc32174aac54d0a8510fa6a7a9ab945.jpg"><br><br>  Before that, there were examples where we compared a number with some constant, the CategoryID is equal to 98. And if we do not have a constant, but a subquery or the result of a function, what then to do with it?  The scheduler assumes that there are some <b>default estimators</b> , that is, it simply takes the value of selectivity in the form of a constant.  The probability that the field is equal to something, most likely, somewhere 0.5%.  And the probability that something less than something will be somewhere around 33%.  When we compare one column with another, this can also be. <br><br><img src="https://habrastorage.org/web/b00/fef/c35/b00fefc35f6040abbb5616bb6582c473.jpg"><br><br>  As an example: <i>ID &lt;Select 100</i> .  There is no information, so the number of rows is estimated at one third, that is, selectivity = 0.33 (3). <br><br><img src="https://habrastorage.org/web/37f/8b9/7b2/37f8b97b2e70401dae23d45742ff972c.jpg"><br><br>  Everything that I am talking about can be viewed with hands, queries, without going to pg_stats.  We look at the number of rows as SELECT COUNT (*), the number of rows with different CategoryID ‚Äî as SELECT COUNT (DISTINCT category_id). <br><br><img src="https://habrastorage.org/web/fb2/dc6/91f/fb2dc691f32c4ac7b1a921c54dac7d99.jpg"><br><br>  This is all good, but we cannot look at it in large tables.  It will take a long time. <br><br><img src="https://habrastorage.org/web/3b3/ed2/184/3b3ed2184d4d4b2f8ae23541c66adeb4.jpg"><br><br>  <b>SELECT COUNT (*)</b> on a table of several gigabytes is already very slow, and if you still do groupings, then very slowly.  If we need more than one field, but several, it is worth looking at pg_stats.  More convenient format and more information. <br><br><img src="https://habrastorage.org/web/8a9/219/75b/8a921975bbcd456ea0b987913a8eaaea.jpg"><br><br>  A lot of useful information is in pg_stats, <i>stats_target</i> can be changed for individual columns in the tables, the autovacuum and autoanalyze settings can be changed for individual tables, and here the statistical independence of conditions is manifested.  If we have several conditions, they are considered independent, because there is no other information. <br><br><img src="https://habrastorage.org/web/186/8a3/638/1868a3638e6747f480f59d8a67866c6c.jpg"><br><br>  All this is good, but why is it necessary?  If we had a perfect planner, we would not need anything of this, everything would work for us, the plan would always be optimal.  But our planner is not perfect, and sometimes you have to go into it and see what you can do about it. <br><br><img src="https://habrastorage.org/web/e86/1c5/519/e861c5519974468fb59c796008db90d6.jpg"><br><br>  <b>There is a useful technique</b> : the foo table, 73GB, is very large, the number of rows can be viewed in <i>reltuples</i> .  It turns out that it has 73 million lines. <br><br><img src="https://habrastorage.org/web/6e2/068/a4b/6e2068a4b1084ac4b667559e1caa4fe6.jpg"><br><br>  We have a query: <i>SELECT * FROM foo WHERE bar_id = 183</i> , you need to select the last 20 records from them.  If we had a table of posts, it would be necessary to select 20 news of a certain category, for example.  Very typical request.  The <i>n_distinct</i> = 50 field, that is, 50 different values, and we have 70 million lines in total. And we see that the number 20 occurs in 55% of cases.  That is, the distribution is extremely uneven.  You can put the index on <i>(bar_id, id)</i> , it will work here, but the table is 73 GB.  It turns out that this index may well occupy 5-7 GB.  I do not really want to create such an index. <br><br><img src="https://habrastorage.org/web/a7d/d1d/3d8/a7dd1d3d8b6549eb822660e6f03c25d5.jpg"><br><br>  If we look, then 4 values ‚Äã‚Äãaccount for 88% of the records.  Such a thought arises: ‚ÄúOr maybe I should throw them out of the index?  Why are they needed there?  We will have an index 10 times less. ‚Äù <br><br><img src="https://habrastorage.org/web/42b/e80/8a1/42be808a1eb240eeb6b58f54aaa68ff6.jpg"><br><br>  Take and <i>discard</i> these four <i>bar_id</i> values ‚Äã‚Äãin part from the index.  The size of the index was 758 MB.  For all values ‚Äã‚Äãthat are not included in these 4, it will work for us, and everything will be very quickly executed. <br><br>  <i><b>A question from the audience</b> : what if the parameters for excluding bar_id change?</i> <br><br>  If we know that we have such very frequent meanings, then we can ‚Äúhard-code‚Äù.  And if this does not happen, that today we have a distribution, and tomorrow it is the opposite, then this does not fit obviously.  This is suitable for this case, when we know that our table is slowly growing, and if something does not work, then we will notice it.  That is, we will see that the index will grow. <br><br>  So, the index works for all values ‚Äã‚Äãexcept four.  It turns out that we do not need him.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If we have a value of 20 in each second line, then we simply take the index on the primary key, read the last 40 lines and, most likely, 20 of them will be the ones we need. And in the worst case, we consider not 40 lines, but 200 or even 2000. But this is nonsense, counting 2000 lines by index is not a problem. Thus, we have disassembled this case. </font></font><br><br><img src="https://habrastorage.org/web/3a7/1c8/17e/3a71c817e12d47288ef109de0ae51e6c.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">More such an abstract case. Suppose we have conditions: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is equal to some value and </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">equal to no one value, and we think how to create an index? You can create an index on the field a, on the field b. You can create two indexes or an index in the a and b fields simultaneously, or in reverse order. You can create a partial index of a, where b is equal to something. Or maybe we don't need an index at all. How can you understand what index is needed for this query? </font></font><br><br><img src="https://habrastorage.org/web/d71/beb/7dd/d71beb7dd64c4f39905ea06df7e69801.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It is necessary to look, with what parameters it is caused. If we have enabled request logging, we can catch the slowest ones. We can look, with what parameters they were caused, what distributions are on these values. Knowing with what parameters the request is called, what distributions we have in this data, we can estimate the selectivity of each of these conditions. It will be different for each value, but, on average, it may be constant.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If there is a condition with a small selectivity (in this case, it is the percentage of rows that satisfies this condition), then we take it and set an index. If there is another condition with a small selectivity, we can set both indices if we lack one field. But if the selectivity is large (the boolean type field, which is false in 90% of cases), then we probably don‚Äôt need an index for it. And if it is needed, then we will do some partial index, most likely, in order not to drag these 90% in the index, there will be no benefit from them. </font></font><br><br><img src="https://habrastorage.org/web/5d8/cb0/f17/5d8cb0f1700a4723ae341cb19eecca64.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What are all the rakes with the scheduler ... The </font></font><br><br><img src="https://habrastorage.org/web/d02/50e/302/d0250e302b7f483aa28282fff5322e0d.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">scheduler does not always work perfectly. For example, we do not have </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cross column</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> statistics. We do not store information about the dependence of one field on another. As an example, consider</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">content &lt;'hello world 250'</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . The condition is not very pleasant. We have 1600 lines selected, a sequential scan is obtained. And if we make two conditions: one of them is the same, and the second is </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">id &lt;250</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , then the estimate differs by half a row: 142 lines versus 1697 lines. This is not very bad. If we had not two conditions, but three, which depend on each other, or the selectivity was smaller, the estimate may differ by many orders of magnitude. </font></font><br><br><img src="https://habrastorage.org/web/194/e55/293/194e5529318d471fa5be98a5cae53ada.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is a problem that is difficult to get around in a good way. You can somehow ‚Äúzakhachit‚Äù, use the information that there is a default estimator, which will return us an estimate of 1/3 of all the lines, and here it is to screw it up. It is not recommended to do it all the time, but sometimes it can be done if nothing else can be done.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here the id field is taken and added to it by </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">abs (id) &lt;0</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font> What does this mean?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This condition is obviously false, abs is the modulus of the number, and the modulus of the number cannot be less than zero. This condition is always false, it does not affect the result, but it does affect the plan. The score here will increase by about one third for this condition, and the plan will be a little better. You can combine such hacks, use knowledge of default estimators. Perhaps you can come up with a better one, but in this case it turned out more or less normal. </font></font><br><br><img src="https://habrastorage.org/web/d4e/c20/d3d/d4ec20d3d36242fc86abadd7c4d4cd91.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Next problem: no statistics for JSON fields. There is no information on this field in the pg_stats table. If we have some condition with this field, where it is NULL, or JOIN is done on it, the scheduler does not know anything about it, the plan may not be entirely optimal. You can use the JSONB field, everything is there. </font></font><br><br><img src="https://habrastorage.org/web/59f/077/e49/59f077e495a941ffa9cb6b48cab4f0e3.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The following rake - </font><b><font style="vertical-align: inherit;">intarray</font></b><font style="vertical-align: inherit;"> operators</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Do not use statistics. Let's create a test table, in which we will write an array, in which the same value in each row: 100. If we look at the execution plan for the query ‚Äúdoes the value 100 enter this array,‚Äù then we see that everything is fine, all the rows have been selected and the plan shows everything correctly. </font></font><br><br><img src="https://habrastorage.org/web/278/a66/bf0/278a66bf01814735aaa8080a889fe2e3.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But, if we create an </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">extension intarray</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and execute the same query, it turns out that the default estimator is used and it selects 0.1% from us. Sometimes you can step on it, if such operators are used and there is an intarray, then the estimate may not be very good. </font></font><br><br> <i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fedor Sigaev, from the audience</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : I will comment, can I? This week there was a ‚Äúpatch‚Äù patch that cures this problem, but, unfortunately, it will only be in 9.6.</font></font></i> <br><br><img src="https://habrastorage.org/web/c6a/993/fc1/c6a993fc142b4b6391dd5ccd519521da.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">While this patch is not, you can somehow get around this. intarray rewrites the operator, replaces it with its own. If we use the post-statement operator in this case, then everything will work for us using the usual index without intarray. </font></font><br><br><img src="https://habrastorage.org/web/4b3/c63/7ac/4b3c637acdc5461f84ddb04f81b15be3.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The next problem is when we lack </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">statistics_target</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Suppose there are large tables that store a small number of different elements. In this case, the assessment of some rare element (which may not even be) may differ by several orders of magnitude. I already talked about this about this formula, she believes that all the remaining values ‚Äã‚Äãare evenly distributed, but usually it is not. In this case, we can unscrew the statistics up to 10,000 or up to 1,000. There are artifacts, of course. Analyze on this table will work slower and the plan will be built a little slower, but sometimes this has to be done. For example, when join goes on several tables and there is not enough statistics. </font></font><br><br><img src="https://habrastorage.org/web/a1e/aac/3cf/a1eaac3cfc8c408a8ce2b65085383da8.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The last part is about </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">monitoring.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. I talked about statistics on distributions (collected by the auto analyze process). In addition, the auto collector process collects statistics on all counters. There are quite a lot of interesting things here, I recommend to look into all the "views" </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pg_stat_ *</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . About some of them will tell. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pg_stat_user_tables</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- I already spoke about it, one line represents information on one table. What is interesting in it? How many sequence scans were on this table, how many scans selected rows, how many index scans were there, how many index scans did they select, when was the last autovacuum and autoanalyze, how many were there. There are also the number of records inserted, the number of records deleted, the number of live records. It seems, why is this necessary? Suppose if a table has a large number of rows that are extracted using sequence scan, and the table itself is also large, then, most likely, it lacks an index. We have such a query in the repository, which shows the TOP tables for which we have the most scans, and we can understand where to add the index. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pg_stat_user_indexes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- information on individual indexes is stored here. You can understand, say, how many times this index has been used. It is useful if we want to understand whether the index created by us is used, or we want to take and delete some extra indexes. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pg_stat_user_functions</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - information on function calls. For each function there are fields that show how many times it has been called, how long it took. It is useful to know if we use a lot of functions. </font></font><br><br><img src="https://habrastorage.org/web/db2/b17/ca2/db2b17ca26fe4f4fbc96221864d38429.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">These are stat collector statistics from the moment of launch, and it is not reset by itself, even when restarted. It can be reset with the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pg_stat_reset ()</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> command </font><font style="vertical-align: inherit;">. She will simply reset all counters. Most likely, there will be no problems from this, but you can see how the picture has changed after you have changed something.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The configuration parameter </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">track_io_timing</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> shows whether to collect statistics on disk I / </font><b><font style="vertical-align: inherit;">O.</font></b><font style="vertical-align: inherit;"> This is very useful for the next item about pg_stat_statements, I‚Äôll show you about it later. By default it is turned off, it is necessary to turn it on, but first check overhead, the documentation says how to do it. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Track_functions</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> can be enabled to collect statistics on pg_stat_user_functions function calls. Another such case, if we have a lot of tables or a lot of databases, then there can be a lot of statistics, and the stats collector writes it directly to the file, this constant disk load on the record is not very useful. We can render </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">stats_temp_directory</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">on a ramdisk, and then it will be written to memory. When you turn off the program, it simply writes to this directory. If there is an emergency shutdown, we will lose statistics, but there will be nothing terrible about it. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">track_activity_query_size</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> field </font><font style="vertical-align: inherit;">tells how long requests are collected in pg_stat_activity and pg_stat_statements. By default, 1024 bytes are collected from the request, sometimes it is worth raising it a little if we have long requests so that they can be read entirely.</font></font><br><br><img src="https://habrastorage.org/web/130/14d/eb9/13014deb9bd248529f99e2882b263929.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúExtension‚Äù pg_stat_statements, which collects all that is necessary. For some reason, they still don't use it. In fact, a very handy tool that collects information on the call of each request: how many times the request was called, how long it took to take, how many disk operations there were, how many rows were retrieved totally. </font></font><br><br><img src="https://habrastorage.org/web/d31/848/c4a/d31848c4ae554d1aa92dcb4e855bd682.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You can use specialized queries. We have made such a request, which accumulates a report, which states what generally happens in the database since the last reset of statistics. Real analyzed example, what do we see here?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In total, we performed requests for 50 hours, of which I / O took 0.6%. The very first request took the most time, it took 28% of the process time from the entire execution time in the program. A lot of useful information, very convenient. We are in the repository, it is called </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">query_stat_total.sql</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , the link will continue.</font></font><br><br><img src="https://habrastorage.org/web/296/bfc/d1e/296bfcd1e2d242f489b7922c931be61a.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">These parameters are regulated by this. There are some parameters, you can read documentation about them, there is nothing complicated. Sometimes it is necessary to turn off track_utility, some system commands (all ORM or in Java, for example) like to add something to the deallocate request, and deallocate will have some new identifier every time, and here it will overwrite the values ‚Äã‚Äãthat we have in pg_stat_statements. It tracks only the TOP requests, by default it is one thousand requests (you can raise the value more), but if these requests are deallocate an identifier by 90%, then we will lose some information. In this case, you should turn off track_utility. </font></font><br><br><img src="https://habrastorage.org/web/c3c/9a9/3bb/c3c9a93bb2e4498480d0adfd52e67d3e.jpg"><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: there are statistics on allocations, statistics on the use of resources, recorded by various processes, is also used in different ways. Statistics on distributions is used by the scheduler, and statistics on resources is hardly used by something, more for monitoring information. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Using these counters, you can identify bottlenecks, the scheduler can also be wrong, not a perfect world, is still being finalized, and </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pg_stat_statements</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> should be used to monitor performance. </font></font><br><br><img src="https://habrastorage.org/web/f8f/fee/a62/f8ffeea625634440bf3c040a09819eb9.jpg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Some useful links to the manual, about estimating the number of lines by the scheduler, statistics collector, a cycle of articles depesz about how the scheduler works (five articles, and each one looks at how it works). Link to our repository and link to our blog.</font></font><br><br><img src="https://habrastorage.org/files/a61/060/56f/a6106056fcce49a29cd997efd8bc97b9.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Like the report of Alexei? </font><font style="vertical-align: inherit;">Come visit us at </font></font><a href="http://pgday.ru/ru/2017/request/registration%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Dermakov"><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PG Day'17 Russia</font></font></b></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! </font><font style="vertical-align: inherit;">Alexey will read the cognitive material about the </font></font><a href="http://pgday.ru/ru/2017/papers/170%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Dermakov"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">features of the PostgreSQL scheduler device</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">We invite everyone who wants to know in detail how the planning of requests in the Posgres works. </font><font style="vertical-align: inherit;">What ways can you influence the process of building a query execution plan? </font><font style="vertical-align: inherit;">When should I try to force the scheduler to work correctly manually? </font></font><a href="http://pgday.ru/ru/2017/request/registration%3Futm_source%3Dhabr%26utm_medium%3Dpost%26utm_campaign%3Dermakov"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Come</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Alexey will tell everything :-)</font></font></div><p>Source: <a href="https://habr.com/ru/post/329542/">https://habr.com/ru/post/329542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../329530/index.html">What did you encounter when translating the project to Android Studio 3.0 Preview and Gradle 4.0-milestone-1</a></li>
<li><a href="../329532/index.html">Understanding the Conductor</a></li>
<li><a href="../329536/index.html">The path to transducers in pure javascript</a></li>
<li><a href="../329538/index.html">Do-it-yourself phishing. Experience of the company "Aktiv", part two</a></li>
<li><a href="../329540/index.html">Open days before launching a new Java course</a></li>
<li><a href="../329544/index.html">Start of big data project: 6 important issues</a></li>
<li><a href="../329546/index.html">To the question of constants</a></li>
<li><a href="../329550/index.html">Oddities of Generic Java Types</a></li>
<li><a href="../329552/index.html">Scrum in the real world. Overview of the meeting for scrum masters</a></li>
<li><a href="../329554/index.html">Open broadcast from the main conference hall of HolyJS 2017 Piter: Douglas Crockford, Lea Verou and someone else</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>