<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI, practical course. Deep learning to generate music</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This is the last article in a series of educational articles for developers in the field of artificial intelligence. It discusses steps to create a de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AI, practical course. Deep learning to generate music</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/zy/do/u4/zydou4yx-zh_x9qzbumtrbdhwy4.jpeg"><br><br>  This is the last article in a series of educational articles for developers in the field of artificial intelligence.  It discusses steps to create a deep learning model for generating music, selecting the appropriate model and preprocessing data, and describes the procedures for setting, training, testing and modifying BachBot. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Music generation - thinking about the task</font> </h2><br>  The first step in solving a set of problems using artificial intelligence (AI) is to reduce the problem to a basic problem, which is solved by means of AI.  One such problem is sequence prediction, which is used in applications for translating and processing natural language.  Our task of generating music can be reduced to the problem of predicting the sequence, while the prediction will be performed for a sequence of musical notes. <br><br><h2>  <font color="#0071c5">Model selection</font> </h2><br>  There are several different types of neural networks that can be considered as a model: direct distribution neural networks, recurrent neural networks and neural networks with long short-term memory. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Neurons are basic abstract elements that combine to form neural networks.  Essentially, a neuron is a function that accepts data at the input and outputs the result at the output. <br><br><img src="https://habrastorage.org/webt/56/pq/hs/56pqhseblx5mqec0apoegck7vd4.png"><br>  <i>Neuron</i> <br><br>  Layers of neurons that accept the same data as input and have connected outputs can be combined to build a <i>direct propagation neural network</i> .  Such neural networks demonstrate high results due to the composition of nonlinear activation functions when data passes through several layers (the so-called deep learning). <br><br><img src="https://habrastorage.org/webt/e8/ps/1v/e8ps1vchys7uap5mjucmyip5ob8.png"><br>  <i>Direct distribution neural network</i> <br><br>  The direct propagation neural network shows good results in a wide range of applications.  However, such a neural network has one drawback that does not allow its use in a task related to a musical composition (sequence prediction): it has a fixed dimensionality of the input data, and musical compositions may have different lengths.  In addition, the <i>forward propagation neural networks do not take into account the input data from previous time steps, which makes them not very useful for solving the sequence prediction problem!</i>  A model called a <i>recurrent neural network is</i> better suited for this task. <br><br>  Recurrent neural networks solve both of these problems by introducing connections between hidden nodes: at the same time, in the next time step, nodes can get information about the data in the previous time step. <br><br><img src="https://habrastorage.org/webt/xc/jv/dr/xcjvdrzlx66olpyziwbtfywxukq.png"><br>  <i>Expanded Recurrent Neural Network View</i> <br><br>  As you can see in the figure, each neuron now accepts input from both the previous neural layer and from the previous point in time. <br><br>  Recurrent neural networks dealing with large input sequences encounter the so-called <i>vanishing gradient problem</i> : this means that the influence from the earlier time steps is quickly disappearing.  This problem is characteristic of the task of a musical composition, since in music there are important long-term dependencies that must be taken into account. <br><br>  To solve the problem of a vanishing gradient, a modification of a recurrent network called a <i>neural network with a long short-term memory (or LSTM neural network) can be used</i> .  This problem is solved by the introduction of memory cells, which are carefully controlled by three types of "valves".  Click the following link for more information: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">General information about LSTM neural networks</a> . <br><br>  Thus, BachBot uses a model based on an LSTM neural network. <br><br><h2>  <font color="#0071c5">Preliminary processing</font> </h2><br>  Music is a very complex art form and includes various dimensions: the pitch of the sounds, rhythm, tempo, dynamic hues, articulation, and more.  To simplify music for the purposes of this project <i>, only the height and duration of the sounds are considered</i> .  Moreover, all chorals were <i>transposed</i> into the key in C major (C major) or A minor (A minor), and the duration of the notes were <i>quantized in time</i> (rounded) to the nearest value multiple of the sixteenth note.  These actions were taken to reduce the complexity of the songs and improve network performance, while the basic music content remained unchanged.  Operations on the normalization of the tonalities and durations of the notes were performed using the music21 library. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">standardize_key</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Converts into the key of C major or A minor. Adapted from https://gist.github.com/aldous-rey/68c6c43450517aa47474 """</span></span> <span class="hljs-comment"><span class="hljs-comment"># conversion tables: eg Ab -&gt; C is up 4 semitones, D -&gt; A is down 5 semitones majors = dict([("A-", 4),("A", 3),("B-", 2),("B", 1),("C", 0),("C#",-1), ("D-", -1),("D", -2),("E-", -3),("E", -4),("F", -5),("F#",6), ("G-", 6), ("G", 5)]) minors = dict([("A-", 1),("A", 0),("B-", -1),("B", -2),("C", -3),("C#",-4), ("D-", -4),("D", -5),("E-", 6),("E", 5),("F", 4),("F#",3), ("G-",3),("G", 2)]) # transpose score key = score.analyze('key') if key.mode == "major": halfSteps = majors[key.tonic.name] elif key.mode == "minor": halfSteps = minors[key.tonic.name] tScore = score.transpose(halfSteps) # transpose key signature for ks in tScore.flat.getKeySignatures(): ks.transpose(halfSteps, inPlace=True) return tScore</span></span></code> </pre> <br>  <i>The code used to standardize key characters in the collected works, the output uses C keys (C major) or A minor (A minor)</i> <br><br>  Quantization in time to the nearest value, multiple to the sixteenth note, was performed using the <i>Stream.quantize ()</i> function of the <i>music21</i> library.  The following is a comparison of the statistics associated with the data set before and after its preliminary processing: <br><br><img src="https://habrastorage.org/webt/kr/wh/5n/krwh5n0d1dubkwn0urbjmp7ovzs.png"><br>  <i>Use each note class before (left) and after preprocessing (right).</i>  <i>The class of notes is a note regardless of its octave.</i> <br><br><img src="https://habrastorage.org/webt/mz/rq/i0/mzrqi0fynco56dhr9kdk-nsfjrs.png"><br>  <i>The location of the notes before (left) and after preprocessing (right)</i> <br><br>  As can be seen in the figure above, the transposition of the original tone of the chorals into the key in C major (C major) or A minor (A minor) significantly influenced the class of notes used in the collected works.  In particular, the number of occurrences for notes in keys in C major (C major) and A minor (A minor) (C, D, E, F, G, A, B) increased.  You can also observe small peaks for the F # and G # notes due to their presence in the ascending melodic A minor sequence (A, B, C, D, E, F # and G #).  <i>On the other hand, time-slicing had a much smaller effect.</i>  This can be explained by the high resolution of quantization (similar to rounding to a set of significant digits). <br><br><h2>  <font color="#0071c5">Coding</font> </h2><br>  After the data has been pre-processed, it is necessary to encode the chorales in a format that can be easily processed using a recurrent neural network.  The required format is a <i>sequence of tokens</i> .  For the BachBot project, coding at the level of notes was chosen (each token represents a note) instead of the level of chords (each token represents a chord).  This solution reduced the size of the dictionary from 128 <sup>4</sup> possible chords to 128 possible notes, which made it possible to increase the efficiency of work. <br><br>  For the project BachBot was created the original coding scheme of musical compositions.  The choral is broken down into temporary steps corresponding to the sixteenth notes.  These steps are called frames.  Each frame contains a sequence of tuples representing the pitch of a note in the format of a digital musical instrument interface (MIDI) and a sign of the binding of this note to a previous note of the same height (note, sign of binding).  The notes within the frame are numbered in descending order of height (soprano ‚Üí alto ‚Üí tenor ‚Üí bass).  Each frame can also have a fermat indicating the end of a phrase;  A fermat is represented by a dot symbol (.) above a note.  The symbols <i>START</i> and <i>END</i> are added to the beginning and end of each choral.  These symbols cause the initialization of the model and allow the user to determine the end of the composition. <br><br> <code>START <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (.) <br> (57, False) <br> (52, False) <br> (48, False) <br> (45, False) <br> ||| <br> (.) <br> (57, True) <br> (52, True) <br> (48, True) <br> (45, True) <br> ||| <br> END</code> <br>  <i>An example of coding two chords.</i>  <i>Each chord lasts the eighth beat, the second chord is accompanied by a fermata.</i>  <i>The sequence "|||" denotes the end of the frame</i> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score, keep_fermatas=True, parts_to_mask=[])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Encodes a music21 score into a List of chords, where each chord is represented with a (Fermata :: Bool, List[(Note :: Integer, Tie :: Bool)]). If `keep_fermatas` is True, all `has_fermata`s will be False. All tokens from parts in `parts_to_mask` will have output tokens `BLANK_MASK_TXT`. Time is discretized such that each crotchet occupies `FRAMES_PER_CROTCHET` frames. """</span></span> encoded_score = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chord <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (score .quantize((FRAMES_PER_CROTCHET,)) .chordify(addPartIdAsGroup=bool(parts_to_mask)) .flat .notesAndRests): <span class="hljs-comment"><span class="hljs-comment"># aggregate parts, remove markup # expand chord/rest st constant timestep between frames if chord.isRest: encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET)) * [[]]) else: has_fermata = (keep_fermatas) and any(map(lambda e: e.isClassOrSubclass(('Fermata',)), chord.expressions)) encoded_chord = [] # </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> sorts Soprano, Bass, Alto, Tenor without breaking ties # c = chord.sortAscending() # sorted_notes = [c[-1], c[0]] + c[1:-1] # for note in sorted_notes: for note in chord: if parts_to_mask and note.pitch.groups[0] in parts_to_mask: encoded_chord.append(BLANK_MASK_TXT) else: has_tie = note.tie is not None and note.tie.type != 'start' encoded_chord.append((note.pitch.midi, has_tie)) encoded_score.append((has_fermata, encoded_chord)) # repeat pitches to expand chord into multiple frames # all repeated frames when expanding a chord should be tied encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET) - 1) * [ (has_fermata, map(lambda note: BLANK_MASK_TXT if note == BLANK_MASK_TXT else (note[0], True), encoded_chord)) ]) return encoded_score</span></span></code> </pre> <br>  <i>The code used to encode the music21 tone using a special coding scheme</i> <br><br><h2>  <font color="#0071c5">Model setting</font> </h2><br>  In the previous section, an explanation was given, showing that the task of automatic composition can be reduced to the task of predicting a sequence.  In particular, the model can predict the most likely next note based on previous notes.  For solving this type of problem, a neural network with long short-term memory (LSTM) is best suited.  Formally, the model should predict P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), the probability distribution for the following possible notes (x <sub>t + 1</sub> ) based on the current token (x <sub>t</sub> ) and the previous hidden state (h <sub>t-1</sub> ) .  Interestingly, the same operation is performed by language models based on recurrent neural networks. <br><br>  In composition mode, the model is initialized using the <i>START</i> token, after which it selects the next most likely token to follow.  After that, the model continues to select the next most likely token using the previous note and the previous hidden state until the END token is generated.  The system contains temperature elements that add a certain degree of randomness to prevent BachBot from writing the same piece over and over again. <br><br><h3>  <font color="#0071c5">Loss function</font> </h3><br>  When training a model for prediction, there is usually some function that needs to be minimized (called the loss function).  This function describes the difference between the prediction model and the ground truth property.  BachBot minimizes the loss of cross entropy between the predicted distribution (x <sub>t + 1</sub> ) and the actual distribution of the objective function.  Using cross entropy as a loss function is a good starting point for a wide range of tasks, but in some cases you can use your own loss function.  Another permissible approach is to attempt to use various loss functions and apply the model that minimizes the actual loss during the audit. <br><br><h3>  <font color="#0071c5">Training / Testing</font> </h3><br>  During the training of the recursive neural network, BachBot used token correction with x <sub>t + 1</sub> instead of applying model prediction.  This process, known as forced learning, is used to ensure convergence, since the predictions of the model will naturally produce poor results at the beginning of the training.  On the contrary, during testing and composition, the model prediction x <sub>t + 1</sub> should be reused as input to the next prediction. <br><br><h3>  <font color="#0071c5">Other considerations</font> </h3><br>  To improve the efficiency in this model, the following practical methods common to LSTM neural networks were used: normalized gradient truncation, elimination method, packet normalization, and truncated back error propagation over time (BPTT). <br><br>  <i>The method of normalized gradient truncation</i> eliminates the problem of uncontrolled growth of the gradient value (the inverse of the vanishing gradient problem, which was solved by using the LSTM-memory cell architecture).  When using this technique, gradient values ‚Äã‚Äãthat exceed a certain threshold are truncated or scaled. <br><br>  <i>The elimination method</i> is a technique in which some neurons <i>selected at random are</i> turned off (excluded) during network training.  This avoids over-fitting and improves the quality of generalization.  The overfitting problem occurs when the model becomes optimized for the training data set and is less applicable for samples outside this set.  The exclusion method often worsens the loss during training, but improves it during the verification phase (more on this below). <br><br>  The calculation of the gradient in a recurrent neural network for a sequence of 1000 elements is equivalent in cost to the forward and backward passage in the neural network of forward propagation from 1000 layers.  <i>The truncated back-propagation error</i> (BPTT) method over time is used to reduce the cost of updating the parameters in the learning process.  This means that errors propagate only for a fixed number of time steps, counting back from the current moment.  Note that long-term dependencies in learning are still possible with the BPTT method, since hidden states have already been manifested in many previous time steps. <br><br><h3>  <font color="#0071c5">Options</font> </h3><br>  The following is a list of relevant parameters for models of recurrent neural networks / neural networks with long short-term memory: <br><ul><li>  <i>The number of layers</i> .  Increasing this parameter may increase the efficiency of the model, but it will take more time to train it.  In addition, too many layers may lead to overfitting. </li><li>  <i>The dimension of the hidden state</i> .  Increasing this parameter may increase the complexity of the model, but this may lead to oversubstituting. </li><li>  <i>Dimension vector mappings</i> </li><li>  <i>The length of the sequence</i> / number of frames before performing the truncation of back-propagation errors in time. </li><li>  <i>The probability of exclusion of neurons</i> .  The probability with which a neuron will be excluded from the network at each update cycle. </li></ul><br>  The method of selecting the optimal set of parameters will be discussed later in this article. <br><br><h2>  <font color="#0071c5">Implementation, training and testing</font> </h2><br><h3>  <font color="#0071c5">Platform Selection</font> </h3><br>  Currently, there are many platforms that allow you to implement machine learning models in various programming languages ‚Äã‚Äã(including even JavaScript!).  Popular platforms include <a href="http://scikit-learn.org/stable/index.html">scikit-learn</a> , <a href="https://www.tensorflow.org/">TensorFlow</a> and <a href="http://pytorch.org/">Torch</a> . <br><br>  The Torch library was chosen as the platform for the BachBot project.  At first, the TensorFlow library was tried, but at that time it used deployed recurrent neural networks, which led to an overflow of the graphics processor's RAM.  Torch is a scientific computing platform that runs on the fast programming language LuaJIT *.  The Torch platform contains excellent libraries for working with neural networks and optimization. <br><br><h3>  <font color="#0071c5">Model implementation and training</font> </h3><br>  The implementation will obviously vary depending on the language and platform on which you choose.  To find out how BachBot implements neural networks with long short-term memory using Torch, check out the scripts used to train and set BachBot parameters.  These scripts are available on the <a href="https://github.com/feynmanliang/bachbot/tree/master/scripts">Feynman Liang GitHub</a> website <a href="https://github.com/feynmanliang/bachbot/tree/master/scripts">.</a> <br><br>  A good starting point for navigating the repository is the <a href="">1-train.zsh script</a> .  With it, you can find the path to the <a href="https://github.com/feynmanliang/bachbot/blob/master/scripts/bachbot.py">bachbot.py</a> file. <br><br>  More precisely, the main script for setting model parameters is the <a href="">LSTM.lua</a> file.  The script for training the model is the <a href="">train.lua</a> file. <br><br><h3>  <font color="#0071c5">Hyperparameter Optimization</font> </h3><br>  To search for optimal values ‚Äã‚Äãof hyperparameters, we used the grid search method using the following parameter grid. <br><br><img src="https://habrastorage.org/webt/91/7p/_3/917p_3g7mtewimqlykgaskxn8y0.png"><br>  <i>The grid of parameters used by BachBot when searching on the grid</i> <br><br>  The grid search is a complete enumeration of all possible combinations of parameters.  Other proposed methods for optimizing hyperparameters are random search and Bayesian optimization. <br><br>  The optimal set of hyperparameters detected by the grid search is as follows: the number of layers = 3, the dimension of the hidden state = 256, the dimension of vector mappings = 32, the length of the sequence = 128, the probability of excluding neurons = 0.3. <br><br>  This model achieved a loss of cross-entropy of 0.324 during training and 0.477 at the testing stage.  The learning curve graph demonstrates that the learning process converges after 30 iterations (‚âà28.5 minutes using a single graphics processor). <br><br>  The loss graphs during training and during the testing phase can also illustrate the effect of each hyperparameter.  Of particular interest to us is the probability of excluding neurons: <br><br><img src="https://habrastorage.org/webt/ad/zd/_s/adzd_s3hxek23oyz8dqg_d1pkys.png"><br>  <i>Learning curves for different exclusion method settings</i> <br><br>  In the figure, it can be seen that the elimination method really avoids over-fitting.  Although if the probability of elimination is 0.0, the loss during training is minimal, at the verification stage the loss has a maximum value.  Higher probability values ‚Äã‚Äãlead to an increase in losses during training and a decrease in losses during the verification phase.  The minimum loss value at the verification stage when working with BachBot was recorded with an exception probability of 0.3. <br><br><h3>  <font color="#0071c5">Alternative assessment methods (optional)</font> </h3><br>  For some models - especially for such creative applications as writing music - the loss may not be a suitable measure of the success of the system.  Instead, the subjective human perception may be the best criterion. <br><br>  The goal of the BachBot project is to automatically compose music that is indistinguishable from Bach's own compositions.  To assess the success of the results obtained, a survey of users was conducted on the Internet.  The survey was given the form of a competition in which users were asked to determine which works belong to the BachBot project, and which ones belong to the Bach project. <br><br>  The survey results showed that survey participants (759 people with different levels of training) were able to accurately distinguish between two samples only in 59 percent of cases.  This is only 9 percent higher than the result of random guessing!  Try the <a href="http://bachbot.com/">BachBot survey</a> yourself! <br><br><h2>  <font color="#0071c5">Adaptation of the model to harmonization</font> </h2><br>  Now BachBot can calculate P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), the probability distribution for the next possible notes based on the current note and the previous hidden state.  This consistent prediction model can be subsequently adapted to harmonize the melody.  Such an adapted model is required to harmonize the melody modulated with the help of emotions within a musical project with the display of slides. <br><br>  When working with the harmonization of the model, a predetermined tune is provided (usually this is a soprano part), and the model must then compose music for the remaining parts.  To perform this task, use the best-first greedy search with the restriction that the notes of the melody are fixed.  Greedy algorithms involve making decisions that are optimal from a local point of view.  So, below is a simple strategy used for harmonization: <br><blockquote>  Assume that x <sub>t</sub> are tokens in the proposed harmonization.  At the time step t, if the note corresponds to the melody, then x <sub>t</sub> is equal to the given note.  Otherwise, x <sub>t</sub> is the <i>most likely</i> next note in accordance with the predictions of the model.  The code for such an adaptation of the model can be found on Github Feynman Liang: <a href="">HarmModel.lua</a> , <a href="">harmonize.lua</a> . </blockquote><br>  Below is an example of harmonization of the lullaby Twinkle, Twinkle, Little Star with the help of BachBot, using the above strategy. <br><br><img src="https://habrastorage.org/webt/wl/mu/kf/wlmukfjpuyeswxwfr15lmkgfvrw.jpeg"><br>  <i>Harmonization of the lullaby of Twinkle, Twinkle, Little Star with the help of BachBot (in the soprano part).</i>  <i>The viola, tenor and bass parts were also filled with the BachBot</i> <br><br>  In this example, the melody of the lullaby Twinkle, Twinkle, Little Star is shown in the soprano part.  After that, the viola, tenor, and bass lines were filled with the BachBot using the harmonization strategy.  And <a href="https://soundcloud.com/bachbot/twinkle-twinkle-little-star%3Fin%3Dbachbot/sets/bachbot-com">here is how it sounds</a> . <br><br>  Despite the fact that BachBot has demonstrated good performance in this task, there are certain limitations associated with this model.  More precisely, the algorithm <i>does not look forward</i> to the melody and uses only the current note of the melody and the past context to generate subsequent notes.  When harmonizing a melody with people, they can cover the whole melody as a whole, which simplifies the derivation of suitable harmonizations.  The fact that this model is not able to do this can lead to <i>surprises</i> due to limitations in the use of subsequent information that cause errors.  To solve this problem, a so-called <i>ray search</i> can be used. <br><br>  When using ray search, various lines of motion are checked.  For example, instead of using only one, the most probable note that is being done at the moment, four or five of the most probable notes can be considered, after which the algorithm continues its work with each of these notes.  Consideration of various options can help the model to <i>recover from the appearance of errors</i> .  Radiation search is commonly used in natural language processing applications for creating sentences. <br><br>  Melodies modulated with emotions can now be passed through this harmonization model to complete them. </div><p>Source: <a href="https://habr.com/ru/post/423727/">https://habr.com/ru/post/423727/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../423713/index.html">‚ÄúMade in Russia‚Äù - WBASIC programming language for developing web server applications</a></li>
<li><a href="../423719/index.html">From Erlang / Elixir to Java and back. Adventure for 20 minutes</a></li>
<li><a href="../423721/index.html">"You're one ugly motherf ** ker": hate speech algorithms and methods for circumventing them</a></li>
<li><a href="../423723/index.html">(Non) commercial project: Redis change licenses, but remain in open source</a></li>
<li><a href="../423725/index.html">Design processes in the ISPsystem. How to introduce ideology, build a department and stay alive</a></li>
<li><a href="../423729/index.html">5 million accounts have already been registered in ProtonMail cryptographic mail.</a></li>
<li><a href="../423731/index.html">Character calculations using Python. Part 1. The basics</a></li>
<li><a href="../423733/index.html">The impact of GDPR on Russian personal data operators</a></li>
<li><a href="../423735/index.html">The ‚ÄúStartup Battle‚Äù will be held at the ‚ÄúInternet of Things‚Äù conference. We invite participants</a></li>
<li><a href="../423737/index.html">Severe optimization of work with market data for cryptobirds</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>