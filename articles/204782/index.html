<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Directional lighting and shading in 2D space</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, Habravchane! 
 I would like to talk about one of the ways of rendering lighting and shading in 2D-space, taking into account the geome...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Directional lighting and shading in 2D space</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/755/3c7/d9b/7553c7d9baed373c5a12b19c939cb29d.png" align="right"><br>  Good afternoon, Habravchane! <br>  I would like to talk about one of the ways of rendering lighting and shading in 2D-space, taking into account the geometry of the scene.  I really like the implementation of lighting in Gish and Super MeatBoy, although in mitboi it can only be seen at dynamic levels with collapsing or moving platforms, and in Guiche it is everywhere.  The lighting in such games seems to me to be so ‚Äúwarm‚Äù, tube-like, that I definitely wanted to implement something similar myself.  And that's what came of it. <br><a name="habracut"></a><br>  Thesis of what is and what needs to be done: <br><ul><li>  there is some 2D world in which you need to embed dynamic lighting + shading;  the world is not necessarily tiled, from any geometry; </li><li>  light sources should be, in principle, an unlimited number (limited only by the performance of the system); </li><li>  the presence of a large number of light sources at a single point, or a single light source with a large ‚Äúillumination‚Äù coefficient, should not only illuminate the area at 100%, but should light it; </li><li>  everything should be calculated, of course, in real-time; </li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/dcf/ee6/83d/dcfee683d651d083953b5668d1019344.png" align="right"><br>  All this required OpenGL, GLSL, FrameBuffer technology and a bit of math.  Limited to versions of OpenGL 3.3 and GLSL 3.30 because  the video card of one of my systems is quite outdated by today's standards (GeForce 310), and this is more than enough for 2D (and earlier versions cause rejection due to inconsistency between the versions of OpenGL and GLSL).  The algorithm itself is not complicated and is done in 3 steps: <br><ol><li>  Form a texture the size of the black render area and draw lighted areas in it (the so-called irradiance map), accumulating the illumination factor for all points; </li><li>  Render the scene to a separate texture; </li><li>  In the context of the render, output a quad that completely covers it, and in the fragment shader, mix the resulting textures.  At this stage, you can ‚Äúplay around‚Äù with a fragmentary shader, adding, for example, the effects of water / fire refraction, lenses, color correction for every taste and other post-processing. </li></ol><br><br><h2>  1. Lighting map </h2><br>  We will use one of the most common technologies - <s><a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D1%2582%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BE%25D1%2581%25D0%25B2%25D0%25B5%25D1%2589%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25B8_%25D0%25B7%25D0%25B0%25D1%2582%25D0%25B5%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">deferred shading</a></s> , porting it in 2D (PS I apologize, not deferred shading, but the <a href="http://steps3d.narod.ru/tutorials/shadow-map-tutorial.html">shadow map</a> , my joint, thanks for the correction).  The essence of this method is to render the scene by moving the camera to the position of the light source, having acquired the depth buffer.  Simple operations with the matrices of the camera and the light source in the shader pixel by pixel can learn about the shading by converting the pixel coordinates of the rendered scene to the texture coordinates of the buffer.  In 3D, z-buffer is used, here I decided to create my one-dimensional depth buffer, on the CPU. <br>  I do not pretend at all to the reasonableness and optimality of this approach, the lighting algorithms are enough and each has its own advantages and disadvantages.  While braining, the way seemed quite rightful to life, and I set about implementing it.  I note that at the time of writing this article I found <a href="https://github.com/mattdesl/lwjgl-basics/wiki/2D-Pixel-Perfect-Shadows">this way</a> ... well, okay, so the bicycle is a bicycle. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  1.1 Z-buffer aka depth buffer </h2><br>  The essence of the Z-buffer is the storage of the remoteness of the scene element from the camera, which allows you to cut off pixels that are invisible behind more near objects.  If in the 3D scene the depth buffer is a plane <br><img src="https://habrastorage.org/getpro/habr/post_images/fc8/420/ea5/fc8420ea5544f4fef9ebe5d7b5fa23aa.jpg"><br>  then in our flat world it will become a line or a one-dimensional array.  Light sources - point, emitting light from the center in all directions.  Accordingly, the buffer index and value will correspond to the polar coordinates of the location of the object closest to the source.  I determined the size of the buffer empirically, as a result of which I stopped at 1024 (of course, it depends on the window size).  The smaller the buffer dimension, the greater the difference between the object boundary and the illuminated area, especially in the presence of small objects, and in some places completely unacceptable artifacts will appear: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/0f6/84e/ad5/0f684ead5b94e4a634782a5910a08d95.png"></div></div><br><br>  Buffer Algorithm: <br><ul><li>  fill in the value of the radius of the light source (the distance at which the illumination power reaches zero); </li><li>  for each object located in the radius of the light source, take those edges that are turned to the light source face.  If you take the edges turned by the back side, the objects will automatically become highlighted, but there will be a problem with nearby: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/c65/f4e/fa6/c65f4efa6c5f2df01f20ca0b627e362e.png"></div></div><br></li><li>  project the resulting list of edges, converting their Cartesian coordinates into polar light sources.  Recalculate point (x; y) in (œÜ; r): <br>  œÜ = arccos (xAxis ‚Ä¢ normalize (point)) <br>  Where: <br>  ‚Ä¢ - scalar product of vectors; <br>  xAxis is the unit vector corresponding to the x (1; 0) axis, since  0 degrees correspond to the point right from the center of the circle; <br>  point is a vector directed from the center of the light source to the point belonging to the edge (coordinates of the edge point in the coordinate system of the light source); <br>  normalize - vector normalization; <br>  r = | point |  - distance to the point; <br>  We project the two extreme points of the edge and intermediate.  The number of points needed for conversion corresponds to the number of buffer cells that are covered by the projection of the edge. <br>  Calculate the buffer index corresponding to the angle œÜ: <br>  index = œÜ / (2 * œÄ) * size of the Buffer; <br>  Thus, we find two extreme buffer indices corresponding to the extreme points of the edge.  For each intermediate index, we convert to the angle value: <br>  œÜ = index * 2 * œÄ / Buffer size <br>  , we construct a <s>vector</s> segment from (0; 0) at this angle of length equal to or greater than the radius of the light source: <br>  v = vec2 (cos (œÜ), sin (œÜ)) * radius <br>  and find the point of intersection of the obtained segment and the edge, for example, like this: <br><ul><li>  2 lines with coefficients A <sub>1</sub> , B <sub>1</sub> , C <sub>1</sub> and A <sub>2</sub> , B <sub>2</sub> , C <sub>2 are set</sub> <br><img src="https://habrastorage.org/getpro/habr/post_images/a08/590/356/a0859035646da8af9eaaa76194b0d0d5.png"><br></li><li>  using the Kramer method to solve this system of equations, we obtain the intersection point: <br><img src="https://habrastorage.org/getpro/habr/post_images/b72/cf1/030/b72cf1030a929c2d042af5f49658502c.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/8d3/bde/3d7/8d3bde3d709610533ade0dbe5d066c67.png"><br></li><li>  if the denominator is zero (in our case, if the value of the denominator modulo less than some error value, for float), then there are no solutions ‚Äî the lines either coincide or are parallel; </li><li>  check the location of the resulting point within both segments. </li></ul><br>  And the last step is to translate all the obtained intermediate points into polar coordinates.  If the distance to the point is less than the value of the buffer at the current index, then write to the buffer.  The buffer is now ready for use.  On this, in principle, all mathematics ends. <br></li></ul><br><br><h2>  1.2 Vertex frame </h2><br>  Now it is necessary to construct a polygonal model, which covers the entire area that illuminates the light source, according to the data in the depth buffer.  For this, it is convenient to use the <a href="http://en.wikipedia.org/wiki/Triangle_fan">Triangle Fan</a> method. <br><img src="https://habrastorage.org/getpro/habr/post_images/4c2/990/e91/4c2990e914717501649023b38cfaaed2.png"><br>  The polygon is formed from the first point, the previous one and the current one.  Accordingly, the first point is the center of the light source, and the coordinates of the other points: <br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> index = <span class="hljs-number"><span class="hljs-number">0</span></span>; index &lt; bufferSize; ++index ) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> alpha = <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>( index ) / <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>( bufferSize ) * Math::TWO_PI; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> value = buffer[ index ]; <span class="hljs-function"><span class="hljs-function">Vec2 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">point</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( Math::Cos( alpha ) * value, Math::Sin( alpha ) * value )</span></span></span></span>; <span class="hljs-function"><span class="hljs-function">Vec4 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pointColor</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( color.R. color.G, color.B, ( </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0f</span></span></span></span><span class="hljs-function"><span class="hljs-params"> - value / range ) * color.A )</span></span></span></span>; ... }</code> </pre> <br>  and close the chain by duplicating the zero index.  The color of all points is the same after the difference in the brightness <s>transparency</s> value - in the center is the maximum brightness at the radius of the light source (range) 0.0.  The transparency value can also be useful in the fragment shader as an indicator of the distance of the point from the source center, thus it is possible to replace the linear dependence of the illumination on the distance with a more interesting one, up to the use of textures. <br>  At this stage, it is also possible to forcibly distance the obtained points by a certain value so that the surface on which the rays fall is illuminated, creating the appearance of volume. <br><br><h2>  1.3 Framebuffer </h2><br>  One texture bound to the framebuffer, the GL_RGBA16F format, is enough; such a format will allow storing values ‚Äã‚Äãbeyond [0.0;  1.0] with half-precision floating-point accuracy. <br><div class="spoiler">  <b class="spoiler_title">Little 'pseudocode'</b> <div class="spoiler_text"><pre> <code class="cpp hljs"> GLuint textureId; GLuint frameBufferObject; <span class="hljs-comment"><span class="hljs-comment">//. width  height -   glGenTextures( 1, &amp;textureId ); glBindTexture( GL_TEXTURE_2D, textureId ); glTexImage2D( GL_TEXTURE_2D, 0, GL_RGBA16F, width, height, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL ); glTexParameterf( GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE ); glTexParameterf( GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE ); glTexParameteri( GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR ); glTexParameteri( GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR ); glBindTexture( GL_TEXTURE_2D, 0 ); // glGenFramebuffers( 1, frameBufferObject ); glBindFramebuffer( GL_FRAMEBUFFER, frameBufferObject ); //    glFramebufferTexture2D( GL_FRAMEBUFFER_EXT, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, textureId, 0 ); //    glBindFramebuffer( GL_FRAMEBUFFER, 0 ); //    ,  -   ... if( glCheckFramebufferStatus( GL_FRAMEBUFFER_EXT ) != GL_FRAMEBUFFER_COMPLETE ) { ... } ...</span></span></code> </pre><br></div></div><br>  Bind the buffer, set the additive blend of glBlendFunc (GL_ONE, GL_ONE) and ‚Äúdraw‚Äù the lighted areas.  Thus, the alpha channel will accumulate the degree of illumination.  You can also add global illumination by drawing a quad in the whole window. <br><br><h2>  1.4 Shaders </h2><br>  Vertex shaders for drawing rays from light sources are standard, taking into account the camera position, and in the fragment shader we accumulate color with regard to brightness: <br><pre> <code class="cpp hljs"> layout(location = <span class="hljs-number"><span class="hljs-number">0</span></span>) out vec4 fragData; in vec4 vColor; ... <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ fragData = vColor * vColor.a; }</code> </pre><br>  As a result, we should get something like this: <br><img src="http://habrastorage.org/storage3/dc8/911/60d/dc891160dcb0272550ddceb8f772ce51.png"><br><br><h2>  2. Render scenes in texture </h2><br>  It is necessary to render the scene into a separate texture, for which we create another framebuffer, attach the usual GL_RGBA texture and render the render in the usual way. <br>  Suppose there is such a scene from the notorious platformer: <br><img src="http://habrastorage.org/storage3/7d3/765/20f/7d376520f47841464e09a875b0d97aca.png"><br><br><h2>  3. Combining a lighting map with a scene </h2><br>  The fragment shader should be something like this: <br><pre> <code class="cpp hljs"> uniform sampler2D texture0; uniform sampler2D texture1; ... vec4 color0 = texture( texture0, texCoords ); <span class="hljs-comment"><span class="hljs-comment">//     vec4 color1 = texture( texture1, texCoords ); //    fragData0 = color0 * color1;</span></span></code> </pre><br>  There is simply no place.  Here, before the multiplication of the color of the scene color0, you can add a certain coefficient in case the setting of the game is extremely dark and you need to see the rays of light. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><pre> <code class="cpp hljs">fragData0 = ( color0 + vec4( <span class="hljs-number"><span class="hljs-number">0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.0</span></span> ) ) * color1;</code> </pre> </div></div><br>  And here‚Ä¶ <br><img src="http://habrastorage.org/storage3/26d/dd5/850/26ddd58501e0ff43ca08cab57899350e.png"><br>  If the character does not describe a simple geometry, then the shadow of it will be very, very wrong.  Our shadows are built from geometry, respectively, the shadows from a sprite character are obtained as from a square (hmm, but Mitbay, I wonder, from what considerations is square?).  So the textures of the sprites should be drawn as ‚Äúsquare‚Äù as possible, leaving as few transparent areas as possible along the edges?  This is one of the options.  Can the character's geometry be described in more detail by smoothing the corners, but not describing the same geometry for each frame of the animation?  Suppose, smooth corners, now the character is almost an ellipse.  If the scene is completely dark, then such a shadow is strongly striking.  Adding anti-aliasing of the irradiance map and global illumination makes the picture more acceptable: <br><pre> <code class="cpp hljs"> vec2 offset = oneByWindowCoeff.xy * <span class="hljs-number"><span class="hljs-number">1.5f</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  fragData = ( texture( texture1, texCoords ) + texture( texture1, vec2( texCoords.x - offset.x, texCoords.y - offset.y ) ).r + texture( texture1, vec2( texCoords.x, texCoords.y - offset.y ) ).r + texture( texture1, vec2( texCoords.x + offset.x, texCoords.y - offset.y ) ).r + texture( texture1, vec2( texCoords.x - offset.x, texCoords.y ) ).r + texture( texture1, vec2( texCoords.x + offset.x, texCoords.y ) ).r + texture( texture1, vec2( texCoords.x - offset.x, texCoords.y + offset.y ) ).r + texture( texture1, vec2( texCoords.x, texCoords.y + offset.y ) ).r + texture( texture1, vec2( texCoords.x + offset.x, texCoords.y + offset.y ) ).r ) / 9.0;</span></span></code> </pre><br>  where oneByWindowCoeff is the coefficient for converting pixel coordinates to texel coordinates. <br>  In the absence of global illumination, it may be better to turn off shadows like ‚Äúcharacters‚Äù or make them luminous themselves (ideal, in my opinion, option), well, or be confused and describe the geometry of the object for all animations. <br><br>  I recorded a small demonstration that came out of all these reflections and finishings: <br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/WBQxB4DqY7Q%3Ffeature%3Doembed&amp;xid=17259,15700021,15700043,15700186,15700191,15700253&amp;usg=ALkJrhi7qOAHuRMM7D3LmL3QqZKU9XHRiA" frameborder="0" allowfullscreen=""></iframe><br><br><h2>  4. Optimization </h2><br>  As they say, "Write first and then optimize."  The original code was drafted quickly and roughly, so there was enough room for optimization.  The first thing that came to mind was to get rid of the excessive number of polygons that render the illuminated areas.  If there are no obstacles in the radius of the light source, then there is no point in drawing 1000+ polygons, we don‚Äôt need such a perfect circle, the eye simply does not perceive the difference (or maybe this monitor is too dirty for me). <br>  For example, for a depth buffer of 1024 without optimization: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="http://habrastorage.org/storage3/212/a49/6f7/212a496f74ea2f75da280f4d97eb21c1.png"></div></div><br>  and with optimization: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="http://habrastorage.org/storage3/420/412/53d/42041253d14f161184964823653f64b8.png"></div></div><br>  For scenes with an abundance of static objects, you can cache the results of calculations of projecting objects into the buffer, which gives a good gain, since the number of cosines / roots and other expensive mathematics is reduced.  Accordingly, for each buffer we set up a list of pointers to objects, check for changes in their parameters affecting the position or shape, and then either fill the cache straight into the buffer, or recalculate the object completely. <br><br><h2>  5. Conclusion </h2><br>  This lighting technique does not claim to be optimal, speed and accuracy, the goal was the fact of implementation.  There are different techniques, such as building some shadows (the same lighting, as I understand, dopilivaetsya additionally), <a href="http://archive.gamedev.net/archive/reference/programming/features/2dsoftshadow/">but soft</a> , with <a href="http://www.gamedev.net/page/resources/_/technical/graphics-programming-and-theory/walls-and-shadows-in-2d-r2711">an abundance of calculations,</a> or even <a href="https://github.com/mattdesl/lwjgl-basics/wiki/2D-Pixel-Perfect-Shadows">such extremely entertaining</a> , found already in the process of writing the article (in general, the logic is similar to that I used). <br>  In general, what was in the plans was realized, the objects cast shadows, the necessary oppressive atmosphere in the game was created, and the picture became more pleasant in my opinion. <br><br><h2>  6. References </h2><br><ul><li>  <a href="http://www.youtube.com/watch%3Fv%3DWBQxB4DqY7Q">Video demonstration of the result</a> ; </li><li>  <a href="https://github.com/KoMaTo3/lbuffer">source code (github) of the depth buffer</a> ; </li><li>  <a href="https://github.com/KoMaTo3/LightTest">the source code (github) of a</a> non-game demo (although currently in the game I use a more doped version, specially sharpened for it); </li><li>  <a href="">Win32-build mini-demo</a> ; </li><li>  <a href="http://www.opengl.org/registry/doc/glspec33.core.20100311.withchanges.pdf">OpenGL 3.3 specification</a> ; </li><li>  <a href="http://www.opengl.org/registry/doc/GLSLangSpec.3.30.6.pdf">GLSL 3.3 specification</a> . </li></ul></div><p>Source: <a href="https://habr.com/ru/post/204782/">https://habr.com/ru/post/204782/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../204766/index.html">Competition among users of the cloud player Listen! for Google Chrome</a></li>
<li><a href="../204768/index.html">3D VDI acceleration in practice. Part 1</a></li>
<li><a href="../204770/index.html">YotaPhone went on sale</a></li>
<li><a href="../204772/index.html">Group Policy: what's new? Cheat Sheet for all occasions</a></li>
<li><a href="../204780/index.html">Managed Service Accounts</a></li>
<li><a href="../204784/index.html">Solving Japanese Crosswords in Wolfram Mathematica</a></li>
<li><a href="../204788/index.html">Cobbler + puppet or Ubuntu 12.04 network installation</a></li>
<li><a href="../204792/index.html">A1Agregator terminates agreements with medium-sized partners</a></li>
<li><a href="../204794/index.html">The British company proposes to extract energy using drones hovering at a height of 15 kilometers.</a></li>
<li><a href="../204796/index.html">Alert users about password expiration and account validity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>