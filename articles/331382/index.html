<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Autoencoders in Keras, Part 1: Introduction</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content 


- Part 1: Introduction 
- Part 2: Manifold learning and latent variables 
- Part 3: Variational autoencoders ( VAE ) 
- Part 4: Conditional...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Autoencoders in Keras, Part 1: Introduction</h1><div class="post__text post__text-html js-mediator-article"><h3>  Content </h3><br><ul><li>  <strong>Part 1: Introduction</strong> <br></li><li>  Part 2: <a href="https://habrahabr.ru/post/331500/"><em>Manifold learning</em> and <em>latent</em> variables</a> <br></li><li>  Part 3: <a href="https://habrahabr.ru/post/331552//">Variational autoencoders ( <em>VAE</em> )</a> <br></li><li>  Part 4: <a href="https://habrahabr.ru/post/331664/"><em>Conditional VAE</em></a> <br></li><li>  Part 5: <a href="https://habrahabr.ru/post/332000/"><em>GAN</em> (Generative Adversarial Networks) and tensorflow</a> <br></li><li>  Part 6: <a href="https://habrahabr.ru/post/332074/"><em>VAE</em> + <em>GAN</em></a> <br></li></ul><br>  While diving into <em>Deep Learning, the</em> topic of auto-encoders caught me, especially in terms of generating new objects.  In an effort to improve the quality of generation, read various blogs and literature on the topic of generative approaches.  As a result, the accumulated experience decided to clothe in a small series of articles, in which he tried briefly and with examples to describe all those problem areas he had encountered himself, at the same time introducing <em>Keras</em> into the syntax. <br><br><h2>  Autoencoders </h2><br>  <strong><em>Autoencoders</em></strong> are direct propagation neural networks that regenerate the input signal at the output.  Inside they have a hidden layer, which is the <em>code</em> that describes the model.  <em>Autoencoders are</em> designed in such a way as to not be able to accurately copy the input to the output.  Usually they are limited in the dimension of the <em>code</em> (it is less than the dimension of the signal) or fined for activation in the <em>code</em> .  The input signal is recovered with errors due to coding losses, but in order to minimize them, the network has to learn to select the most important features. <br><br><img src="https://habrastorage.org/web/cf6/228/613/cf6228613fdc4f8fb819cbd41bb677eb.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Who cares, welcome under the cat <br><a name="habracut"></a><br><br>  <em>Autoencoders</em> consist of two parts: encoder <img src="https://habrastorage.org/getpro/habr/post_images/308/d99/fe8/308d99fe890a9575a6ff8fe85579b43b.svg" alt="g">  and decoder <img src="https://habrastorage.org/getpro/habr/post_images/549/83a/c9e/54983ac9e8a725208d9d1eedda7caad0.svg" alt="f">  .  The encoder translates the input signal into its presentation ( <em>code</em> ): <img src="https://habrastorage.org/getpro/habr/post_images/67f/4d8/cd5/67f4d8cd51ed570efffcffaa445061de.svg" alt="h = g (x)">  and the decoder recovers the signal by its <em>code</em> : <img src="https://habrastorage.org/getpro/habr/post_images/9de/62c/c74/9de62cc744783bed1de95702b6994ed5.svg" alt="x = f (h)">  . <br><br>  Autoencoder changing <img src="https://habrastorage.org/getpro/habr/post_images/549/83a/c9e/54983ac9e8a725208d9d1eedda7caad0.svg" alt="f">  and <img src="https://habrastorage.org/getpro/habr/post_images/308/d99/fe8/308d99fe890a9575a6ff8fe85579b43b.svg" alt="g">  seeking to learn the identity function <img src="https://habrastorage.org/getpro/habr/post_images/601/6f6/9a3/6016f69a394d63bbbfcd245a730bb331.svg" alt="x = f (g (x))">  minimizing some kind of error functional. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d81/9ba/814/d819ba814f46a2aea252d3c0f8215126.svg" alt="L (x, f (g (x)))."></div><br>  Moreover, the family of encoder functions <img src="https://habrastorage.org/getpro/habr/post_images/308/d99/fe8/308d99fe890a9575a6ff8fe85579b43b.svg" alt="g">  and decoder <img src="https://habrastorage.org/getpro/habr/post_images/549/83a/c9e/54983ac9e8a725208d9d1eedda7caad0.svg" alt="f">  somehow limited to autoencoder was forced to select the most important properties of the signal. <br><br>  The ability of autoencoders to compress data itself is rarely used, as they usually work worse than hand-written algorithms for specific data types like sounds or images.  It is also critically important for them that the data belong to the general population on which the network was trained.  Having trained the autoencoder on numbers, it cannot be used to encode something else (for example, human faces). <br><br>  However, autoencoders can be used for pre-training, for example, when there is a classification task, and there are too few marked pairs.  Or to reduce the dimension in the data for later visualization.  Or when you just need to learn to distinguish between the useful properties of the input signal. <br><br>  Moreover, some of their developments (which will also be described later), such as variational autoencoder ( <em>VAE</em> ), as well as its combination with competing generative networks ( <em>GAN</em> ), give very interesting results and are now at the forefront of the science of generative models. <br><br><h3>  Keras </h3><br>  <strong><em>Keras</em></strong> is a very convenient high-level library for deep learning, working on top of <em>theano</em> or <em>tensorflow</em> .  It is based on layers, connecting them together, we get the model.  Once created, the models and layers retain their internal parameters, and therefore, for example, you can train a layer in one model and use it in another, which is very convenient. <br><br>  <em>Keras</em> models are easy to save / load, they have a simple, but at the same time deeply customizable learning process;  models are freely embedded in the <em>tensorflow / theano</em> code (as operations on tensors). <br><br>  We will use dataset of handwritten numbers <strong><em>MNIST</em></strong> as data. <br><br>  Download it: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mnist <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test .astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_train = np.reshape(x_train, (len(x_train), <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x_test = np.reshape(x_test, (len(x_test), <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><h2>  Compression autoencoder </h2><br>  To begin with, we will create the simplest (compressing, undercomplete) autoencoder with <em>a</em> small-dimension <em>code</em> of two fully connected layers: an encoder and a decoder. <br><br>  Since the intensity of the color is normalized to unity, then we take sigmoid activation of the output layer. <br><br>  Let's write separate models for the encoder, decoder and the whole autoencoder.  To do this, create instances of the layers and apply them one by one, finally combining everything into models. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Flatten, Reshape <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_dense_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    encoding_dim = 49 #  #   input_img = Input(shape=(28, 28, 1)) # 28, 28, 1 -  , ,   ,  - #    flat_img = Flatten()(input_img) #     encoded = Dense(encoding_dim, activation='relu')(flat_img) #  #      input_encoded = Input(shape=(encoding_dim,)) flat_decoded = Dense(28*28, activation='sigmoid')(input_encoded) decoded = Reshape((28, 28, 1))(flat_decoded) # ,       ,     #          encoder = Model(input_img, encoded, name="encoder") decoder = Model(input_encoded, decoded, name="decoder") autoencoder = Model(input_img, decoder(encoder(input_img)), name="autoencoder") return encoder, decoder, autoencoder</span></span></code> </pre><br>  Create and compile the model (compilation in this case refers to the construction of the graph of calculations for <em>back propagation of error</em> ) <br><br><pre> <code class="python hljs">encoder, decoder, autoencoder = create_dense_ae() autoencoder.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>)</code> </pre><br>  Look at the number of parameters <br><br><pre> <code class="python hljs">autoencoder.summary()</code> </pre><br><pre> <code class="hljs markdown"><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span> Layer (type) Output Shape Param # ================================================================= input<span class="hljs-emphasis"><span class="hljs-emphasis">_1 (InputLayer) (None, 28, 28, 1) 0 _</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">____ encoder (Model) (None, 49) 38465 __</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">___ decoder (Model) (None, 28, 28, 1) 39200 ================================================================= Total params: 77,665.0 Trainable params: 77,665.0 Non-trainable params: 0.0 __</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-emphasis"><span class="hljs-emphasis">___</span></span></code> </pre><br>  Now we will train our autoencoder <br><br><pre> <code class="python hljs">autoencoder.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">256</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br><pre> <code class="hljs go">Epoch <span class="hljs-number"><span class="hljs-number">46</span></span>/<span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0785</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0777</span></span> Epoch <span class="hljs-number"><span class="hljs-number">47</span></span>/<span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">2s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0784</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0777</span></span> Epoch <span class="hljs-number"><span class="hljs-number">48</span></span>/<span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0784</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0777</span></span> Epoch <span class="hljs-number"><span class="hljs-number">49</span></span>/<span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">2s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0784</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0777</span></span> Epoch <span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0784</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0777</span></span></code> </pre><br>  Digit drawing function <br><br><pre> <code class="python hljs">%matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_digits</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(*args)</span></span></span><span class="hljs-function">:</span></span> args = [x.squeeze() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> args] n = min([x.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> args]) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*n, <span class="hljs-number"><span class="hljs-number">2</span></span>*len(args))) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(args)): ax = plt.subplot(len(args), n, i*n + j + <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.imshow(args[i][j]) plt.gray() ax.get_xaxis().set_visible(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) ax.get_yaxis().set_visible(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.show()</code> </pre><br>  Encode several images and, for the sake of interest, take a look at the sample code. <br><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> imgs = x_test[:n] encoded_imgs = encoder.predict(imgs, batch_size=n) encoded_imgs[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">array</span></span>([ <span class="hljs-number"><span class="hljs-number">6.64665604</span></span>, <span class="hljs-number"><span class="hljs-number">7.53528595</span></span>, <span class="hljs-number"><span class="hljs-number">3.81508064</span></span>, <span class="hljs-number"><span class="hljs-number">4.66803837</span></span>, <span class="hljs-number"><span class="hljs-number">1.50886345</span></span>, <span class="hljs-number"><span class="hljs-number">5.41063929</span></span>, <span class="hljs-number"><span class="hljs-number">9.28293324</span></span>, <span class="hljs-number"><span class="hljs-number">10.79530716</span></span>, <span class="hljs-number"><span class="hljs-number">0.39599913</span></span>, <span class="hljs-number"><span class="hljs-number">4.20529413</span></span>, <span class="hljs-number"><span class="hljs-number">6.53982353</span></span>, <span class="hljs-number"><span class="hljs-number">5.64758158</span></span>, <span class="hljs-number"><span class="hljs-number">5.25313473</span></span>, <span class="hljs-number"><span class="hljs-number">1.37336707</span></span>, <span class="hljs-number"><span class="hljs-number">9.37590599</span></span>, <span class="hljs-number"><span class="hljs-number">6.00672245</span></span>, <span class="hljs-number"><span class="hljs-number">4.39552879</span></span>, <span class="hljs-number"><span class="hljs-number">5.39900637</span></span>, <span class="hljs-number"><span class="hljs-number">4.11449528</span></span>, <span class="hljs-number"><span class="hljs-number">7.490417</span></span> , <span class="hljs-number"><span class="hljs-number">10.89267063</span></span>, <span class="hljs-number"><span class="hljs-number">7.74325705</span></span>, <span class="hljs-number"><span class="hljs-number">13.35806847</span></span>, <span class="hljs-number"><span class="hljs-number">3.59005809</span></span>, <span class="hljs-number"><span class="hljs-number">9.75185394</span></span>, <span class="hljs-number"><span class="hljs-number">2.87570286</span></span>, <span class="hljs-number"><span class="hljs-number">3.64097357</span></span>, <span class="hljs-number"><span class="hljs-number">7.86691713</span></span>, <span class="hljs-number"><span class="hljs-number">5.93383646</span></span>, <span class="hljs-number"><span class="hljs-number">5.52847338</span></span>, <span class="hljs-number"><span class="hljs-number">3.45317888</span></span>, <span class="hljs-number"><span class="hljs-number">1.88125253</span></span>, <span class="hljs-number"><span class="hljs-number">7.471385</span></span> , <span class="hljs-number"><span class="hljs-number">7.29820824</span></span>, <span class="hljs-number"><span class="hljs-number">10.02830505</span></span>, <span class="hljs-number"><span class="hljs-number">10.5430584</span></span> , <span class="hljs-number"><span class="hljs-number">3.2561543</span></span> , <span class="hljs-number"><span class="hljs-number">8.24713707</span></span>, <span class="hljs-number"><span class="hljs-number">2.2687614</span></span> , <span class="hljs-number"><span class="hljs-number">6.60069561</span></span>, <span class="hljs-number"><span class="hljs-number">7.58116722</span></span>, <span class="hljs-number"><span class="hljs-number">4.48140812</span></span>, <span class="hljs-number"><span class="hljs-number">6.13670635</span></span>, <span class="hljs-number"><span class="hljs-number">2.9162209</span></span> , <span class="hljs-number"><span class="hljs-number">8.05503941</span></span>, <span class="hljs-number"><span class="hljs-number">10.78182602</span></span>, <span class="hljs-number"><span class="hljs-number">4.26916027</span></span>, <span class="hljs-number"><span class="hljs-number">5.17175484</span></span>, <span class="hljs-number"><span class="hljs-number">6.18108797</span></span>], dtype=float32)</code> </pre><br>  We decode these codes and compare them with the originals. <br><br><pre> <code class="python hljs">decoded_imgs = decoder.predict(encoded_imgs, batch_size=n) plot_digits(imgs, decoded_imgs)</code> </pre><br><img src="https://habrastorage.org/web/c57/b27/940/c57b279409404863ad8384d251d445a0.png"><br><br><h2>  Deep autoencoder </h2><br>  No one bothers us to make the same autoencoder, but with a large number of layers.  In this case, he will be able to isolate more complex nonlinear patterns <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_deep_dense_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#    encoding_dim = 49 #  input_img = Input(shape=(28, 28, 1)) flat_img = Flatten()(input_img) x = Dense(encoding_dim*3, activation='relu')(flat_img) x = Dense(encoding_dim*2, activation='relu')(x) encoded = Dense(encoding_dim, activation='linear')(x) #  input_encoded = Input(shape=(encoding_dim,)) x = Dense(encoding_dim*2, activation='relu')(input_encoded) x = Dense(encoding_dim*3, activation='relu')(x) flat_decoded = Dense(28*28, activation='sigmoid')(x) decoded = Reshape((28, 28, 1))(flat_decoded) #  encoder = Model(input_img, encoded, name="encoder") decoder = Model(input_encoded, decoded, name="decoder") autoencoder = Model(input_img, decoder(encoder(input_img)), name="autoencoder") return encoder, decoder, autoencoder d_encoder, d_decoder, d_autoencoder = create_deep_dense_ae() d_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')</span></span></code> </pre><br>  Look at the <em>summary of</em> our model <br><br><pre> <code class="python hljs">d_autoencoder.summary()</code> </pre><br><pre> <code class="hljs markdown"><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span> Layer (type) Output Shape Param # ================================================================= input<span class="hljs-emphasis"><span class="hljs-emphasis">_3 (InputLayer) (None, 28, 28, 1) 0 _</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">____ encoder (Model) (None, 49) 134750 __</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-emphasis"><span class="hljs-emphasis">___</span></span> decoder (Model) (None, 28, 28, 1) 135485 ================================================================= Total params: 270,235.0 Trainable params: 270,235.0 Non-trainable params: 0.0</code> </pre><br>  The number of parameters has grown more than 3 times, let's see if the new model will cope better: <br><br><pre> <code class="python hljs">d_autoencoder.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">100</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">256</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br><pre> <code class="hljs go">Epoch <span class="hljs-number"><span class="hljs-number">96</span></span>/<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0722</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0724</span></span> Epoch <span class="hljs-number"><span class="hljs-number">97</span></span>/<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0722</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0719</span></span> Epoch <span class="hljs-number"><span class="hljs-number">98</span></span>/<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0721</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0722</span></span> Epoch <span class="hljs-number"><span class="hljs-number">99</span></span>/<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0721</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0720</span></span> Epoch <span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">3s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0721</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0720</span></span></code> </pre><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> imgs = x_test[:n] encoded_imgs = d_encoder.predict(imgs, batch_size=n) encoded_imgs[<span class="hljs-number"><span class="hljs-number">0</span></span>] decoded_imgs = d_decoder.predict(encoded_imgs, batch_size=n) plot_digits(imgs, decoded_imgs)</code> </pre><br><img src="https://habrastorage.org/web/796/90f/b10/79690fb10498442eb68ca775f782fe30.png"><br><br>  We see that the loss is saturated at a much lower value, and the numbers are a bit more pleasant. <br><br><h2>  Convolution autoencoder </h2><br>  Since we work with pictures, there must be some spatial invariance in the data.  Let's try to use this: <em>let's</em> build a <em>convolutional autoencoder</em> <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Conv2D, MaxPooling2D, UpSampling2D <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_deep_conv_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_img = Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x = Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(input_img) x = MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) x = MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) encoded = Conv2D(<span class="hljs-number"><span class="hljs-number">1</span></span>, (<span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) <span class="hljs-comment"><span class="hljs-comment">#     (7, 7, 1) .. 49- input_encoded = Input(shape=(7, 7, 1)) x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded) x = UpSampling2D((2, 2))(x) x = Conv2D(128, (2, 2), activation='relu', padding='same')(x) x = UpSampling2D((2, 2))(x) decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(x) #  encoder = Model(input_img, encoded, name="encoder") decoder = Model(input_encoded, decoded, name="decoder") autoencoder = Model(input_img, decoder(encoder(input_img)), name="autoencoder") return encoder, decoder, autoencoder c_encoder, c_decoder, c_autoencoder = create_deep_conv_ae() c_autoencoder.compile(optimizer='adam', loss='binary_crossentropy') c_autoencoder.summary()</span></span></code> </pre><br><pre> <code class="hljs markdown"><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span> Layer (type) Output Shape Param # ================================================================= input<span class="hljs-emphasis"><span class="hljs-emphasis">_5 (InputLayer) (None, 28, 28, 1) 0 _</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">____ encoder (Model) (None, 7, 7, 1) 24385 __</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-strong"><span class="hljs-strong">_____</span></span><span class="hljs-emphasis"><span class="hljs-emphasis">___</span></span> decoder (Model) (None, 28, 28, 1) 24385 ================================================================= Total params: 48,770.0 Trainable params: 48,770.0 Non-trainable params: 0.0</code> </pre><br><pre> <code class="python hljs">c_autoencoder.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">64</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">256</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br><pre> <code class="hljs go">Epoch <span class="hljs-number"><span class="hljs-number">60</span></span>/<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">24s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0698</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0695</span></span> Epoch <span class="hljs-number"><span class="hljs-number">61</span></span>/<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">24s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0699</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0705</span></span> Epoch <span class="hljs-number"><span class="hljs-number">62</span></span>/<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">24s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0699</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0694</span></span> Epoch <span class="hljs-number"><span class="hljs-number">63</span></span>/<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">24s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0698</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0691</span></span> Epoch <span class="hljs-number"><span class="hljs-number">64</span></span>/<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-number"><span class="hljs-number">60000</span></span>/<span class="hljs-number"><span class="hljs-number">60000</span></span> [==============================] - <span class="hljs-number"><span class="hljs-number">24s</span></span> - loss: <span class="hljs-number"><span class="hljs-number">0.0697</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0693</span></span></code> </pre><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> imgs = x_test[:n] encoded_imgs = c_encoder.predict(imgs, batch_size=n) decoded_imgs = c_decoder.predict(encoded_imgs, batch_size=n) plot_digits(imgs, decoded_imgs)</code> </pre><br><img src="https://habrastorage.org/web/434/61b/066/43461b0668ce49608066ceb8e0c3b377.png"><br><br>  Despite the fact that the number of parameters of this network is much less than that of fully connected networks, the error function is saturated at a much smaller value. <br><br><h2>  <em>Denoising</em> autoencoder </h2><br>  Autoencoders can be trained to remove noise from the data: to do this, it is necessary to input noisy data at the output and compare it with the data without noise: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9ae/c4c/8d9/9aec4c8d91eba3b3dce9345fa286e538.svg" alt="L (x, f (g (\ hat x))),"></div><br>  Where <img src="https://habrastorage.org/getpro/habr/post_images/ae6/3b6/671/ae63b6671a0c1fc2ea12deff262997cf.svg" alt="\ hat x">  - noisy data. <br><br>  In <em>Keras,</em> you can wrap arbitrary operations from the underlying framework into the Lambda layer.  You can access operations from <em>tensorflow</em> or <em>theano</em> through the <em>backend</em> module. <br><br>  Let's create a model that will noise the input image, and relieve any noise by retraining any of the already created autoencoders. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Lambda batch_size = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_denoising_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(autoencoder)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">add_noise</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> noise_factor = <span class="hljs-number"><span class="hljs-number">0.5</span></span> x = x + K.random_normal(x.get_shape(), <span class="hljs-number"><span class="hljs-number">0.5</span></span>, noise_factor) x = K.clip(x, <span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">1.</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x input_img = Input(batch_shape=(batch_size, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) noised_img = Lambda(add_noise)(input_img) noiser = Model(input_img, noised_img, name=<span class="hljs-string"><span class="hljs-string">"noiser"</span></span>) denoiser_model = Model(input_img, autoencoder(noiser(input_img)), name=<span class="hljs-string"><span class="hljs-string">"denoiser"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> noiser, denoiser_model noiser, denoiser_model = create_denoising_model(autoencoder) denoiser_model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>)</code> </pre><br><pre> <code class="python hljs">denoiser_model.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">200</span></span>, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> imgs = x_test[:batch_size] noised_imgs = noiser.predict(imgs, batch_size=batch_size) encoded_imgs = encoder.predict(noised_imgs[:n], batch_size=n) decoded_imgs = decoder.predict(encoded_imgs[:n], batch_size=n) plot_digits(imgs[:n], noised_imgs, decoded_imgs)</code> </pre><br><img src="https://habrastorage.org/web/536/ea3/ee9/536ea3ee99d84b5c96cdb93ae0a12b50.png"><br><br>  The numbers on noisy images are hard to <em>see</em> , but the <em>denoising autoencoder</em> removed the noise quite well and the numbers became quite readable. <br><br><h2>  Sparse autoencoder </h2><br>  A sparse autoencoder is simply an autoencoder whose penalty is added to the loss function for the values ‚Äã‚Äãin the <em>code</em> , that is, the autoencoder seeks to minimize such an error function: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/424/113/97b/42411397b14240e5421b3038c4e0668b.svg" alt="L (x, f (g (x))) + \ Omega (h),"></div><br>  Where <img src="https://habrastorage.org/getpro/habr/post_images/67f/4d8/cd5/67f4d8cd51ed570efffcffaa445061de.svg" alt="h = g (x)">  - code, <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b4c/cf0/470/b4ccf04707dff4f6a7578091dfae3e86.svg" alt="\ Omega (h)">  - the usual regularizer (for example, L1): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/48f/229/82a/48f22982a4ae6879cc2b666920c81667.svg" alt="\ Omega (h) = \ lambda * | h |"></div><br>  Sparse autoencoder does not necessarily taper to the center.  Its <em>code</em> may have a higher dimension than the input signal.  Learning to approximate the identical function <img src="https://habrastorage.org/getpro/habr/post_images/601/6f6/9a3/6016f69a394d63bbbfcd245a730bb331.svg" alt="x = f (g (x))">  , he learns in the <em>code</em> to highlight the useful properties of the signal.  Because of the regularizer, even a sparse autoencoder expanding towards the center cannot learn the identical function directly. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.regularizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> L1L2 <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_sparse_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> encoding_dim = <span class="hljs-number"><span class="hljs-number">16</span></span> lambda_l1 = <span class="hljs-number"><span class="hljs-number">0.00001</span></span> <span class="hljs-comment"><span class="hljs-comment">#  input_img = Input(shape=(28, 28, 1)) flat_img = Flatten()(input_img) x = Dense(encoding_dim*3, activation='relu')(flat_img) x = Dense(encoding_dim*2, activation='relu')(x) encoded = Dense(encoding_dim, activation='linear', activity_regularizer=L1L2(lambda_l1))(x) #  input_encoded = Input(shape=(encoding_dim,)) x = Dense(encoding_dim*2, activation='relu')(input_encoded) x = Dense(encoding_dim*3, activation='relu')(x) flat_decoded = Dense(28*28, activation='sigmoid')(x) decoded = Reshape((28, 28, 1))(flat_decoded) #  encoder = Model(input_img, encoded, name="encoder") decoder = Model(input_encoded, decoded, name="decoder") autoencoder = Model(input_img, decoder(encoder(input_img)), name="autoencoder") return encoder, decoder, autoencoder s_encoder, s_decoder, s_autoencoder = create_sparse_ae() s_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')</span></span></code> </pre><br><pre> <code class="python hljs">s_autoencoder.fit(x_train, x_train, epochs=<span class="hljs-number"><span class="hljs-number">400</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">256</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, validation_data=(x_test, x_test))</code> </pre><br>  Look at the codes <br><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> imgs = x_test[:n] encoded_imgs = s_encoder.predict(imgs, batch_size=n) encoded_imgs[<span class="hljs-number"><span class="hljs-number">1</span></span>]</code> </pre><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">array</span></span>([ <span class="hljs-number"><span class="hljs-number">7.13531828</span></span>, <span class="hljs-number"><span class="hljs-number">-0.61532277</span></span>, <span class="hljs-number"><span class="hljs-number">-5.95510817</span></span>, <span class="hljs-number"><span class="hljs-number">12.0058918</span></span> , <span class="hljs-number"><span class="hljs-number">-1.29253936</span></span>, <span class="hljs-number"><span class="hljs-number">-8.56000137</span></span>, <span class="hljs-number"><span class="hljs-number">-7.48944521</span></span>, <span class="hljs-number"><span class="hljs-number">-0.05415952</span></span>, <span class="hljs-number"><span class="hljs-number">-2.81205249</span></span>, <span class="hljs-number"><span class="hljs-number">-8.4289856</span></span> , <span class="hljs-number"><span class="hljs-number">-0.67815018</span></span>, <span class="hljs-number"><span class="hljs-number">-11.19531345</span></span>, <span class="hljs-number"><span class="hljs-number">-3.4353714</span></span> , <span class="hljs-number"><span class="hljs-number">3.18580866</span></span>, <span class="hljs-number"><span class="hljs-number">-0.21041733</span></span>, <span class="hljs-number"><span class="hljs-number">4.13229799</span></span>], dtype=float32)</code> </pre><br><pre> <code class="python hljs">decoded_imgs = s_decoder.predict(encoded_imgs, batch_size=n) plot_digits(imgs, decoded_imgs)</code> </pre><br><img src="https://habrastorage.org/web/1e0/800/ae8/1e0800ae8e2645b09347ae3bb001fcd0.png"><br><br>  Let's see if we can somehow interpret the dimensions in codes. <br>  Take the average of all codes, and then in turn each dimension in the averaged code is replaced by its maximum value. <br><br><pre> <code class="python hljs">imgs = x_test encoded_imgs = s_encoder.predict(imgs, batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>) codes = np.vstack([encoded_imgs.mean(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)]*<span class="hljs-number"><span class="hljs-number">10</span></span>) np.fill_diagonal(codes, encoded_imgs.max(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)) decoded_features = s_decoder.predict(codes, batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plot_digits(decoded_features)</code> </pre><br><img src="https://habrastorage.org/web/51c/ee8/8e7/51cee88e748442ebb9babfc3e0a6b2bd.png"><br><br>  Some features look, but nothing sensible here is not visible. <br><br>  The values ‚Äã‚Äãin the codes one by one do not carry any obvious meaning, only the cunning interaction between the values ‚Äã‚Äãthat occurs in the layers of the decoder allows it to restore the input signal by code. <br><br>  Is it possible to generate objects from codes at will? <br><br>  In order to answer this question, it is better to study what codes are and how they can be interpreted.  About this in the <a href="https://habrahabr.ru/post/331500/">next part</a> . <br><br><h2>  Useful links and literature </h2><br>  This post is based on our own interpretation of the first part of the post of the creator <em>Keras</em> <em>Francois Chollet</em> about <a href="https://blog.keras.io/building-autoencoders-in-keras.html">autoencoders in Keras</a> . <br><br>  As well as chapters about <a href="http://www.deeplearningbook.org/contents/autoencoders.html">autoencoders</a> in the <em>Deep Learning Book</em> . </div><p>Source: <a href="https://habr.com/ru/post/331382/">https://habr.com/ru/post/331382/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../331370/index.html">Features of the organization of the IT infrastructure for video surveillance</a></li>
<li><a href="../331374/index.html">How to implement configuration management processes</a></li>
<li><a href="../331376/index.html">Introduction to the ITIL methodology in ITSM</a></li>
<li><a href="../331378/index.html">Introduction to the ISO 20000 standard: Where it came from and how to certify a company</a></li>
<li><a href="../331380/index.html">Financial Management: How to estimate the cost of the services provided</a></li>
<li><a href="../331384/index.html">8 myths about the management of services, which are just myths: On the introduction, high cost and relevance</a></li>
<li><a href="../331386/index.html">How a video can change your content marketing strategy</a></li>
<li><a href="../331390/index.html">What happened last year: No.1 on IT services in the country, 2000+ projects, a lot of engineering stories</a></li>
<li><a href="../331394/index.html">The organization of the switching field of high-density SCS</a></li>
<li><a href="../331398/index.html">10 basic principles of visual design</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>